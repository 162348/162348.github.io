@inbook{Howard-Matheson1984,
    author          = {Ronald A. Howard and James E. Matheson},
    chapter        = {Influence Diagrams},
    editor         = {},
    pages          = {721-762},
    publisher      = {SDG Decision Systems},
    title          = {},
    year           = {1984}
}

@book{Diestel2017,
    author         = {Reinhard Diestel},
    year           = {2017},
    title          = {Graph Theory},
    series         = {Graduate Texts in Mathematics},
    volume         = {173},
    edition        = {5},
    url            = {https://link.springer.com/book/10.1007/978-3-662-53622-3},
    publisher      = {Springer Berlin Heidelberg}
}

@book{Preston1974,
    author         = {Christopher J. Preston},
    year           = {1974},
    title          = {Gibbs States on Countable Sets},
    series         = {Cambdirge Tracts in Mathematics},
    volume         = {68},
    edition        = {},
    url            = {https://www.cambridge.org/core/books/gibbs-states-on-countable-sets/970A88C66DA6E06BA1828142B3399272},
    publisher      = {Cambridge University Press}
}

@book{Kindermann-Snell1980,
    author         = {Ross Kindermann and J. Laurie Snell},
    year           = {1980},
    title          = {Markov Random Fields and Their Applications},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {https://www.ams.org/books/conm/001/},
    publisher      = {American Mathematical Society}
}

@unpublished{Hammersley-Clifford1971,
    author = {J. Hammersley and P. Clifford},
    year   = {1971},
    title  = {Markov Fields on Finite Graphs and Lattices},
    url    = {https://ora.ox.ac.uk/objects/uuid:4ea849da-1511-4578-bb88-6a8d02f457a6}
}

@book{Baxter1982,
    author         = {Rodney J. Baxter},
    year           = {1982},
    title          = {Exactly Solved Models in Statistical Mechanics},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {https://physics.anu.edu.au/research/ftp/mpg/baxter_book.php},
    publisher      = {Academic Press}
}
@book{Kittel2018,
    author         = {Charles Kittel},
    year           = {2018},
    title          = {Introduction to Solid State Physics},
    series         = {},
    volume         = {},
    edition        = {8},
    url            = {https://www.wiley.com/en-ie/Kittel%27s+Introduction+to+Solid+State+Physics%2C+Global+Edition%2C+8th+Edition-p-9781119454168},
    publisher      = {John Wiley}
}

@book{Huebener2019,
    author         = {Rudolf P. Huebener},
    year           = {2019},
    title          = {Conductors, Semiconductors, Superconductors: An Introduction to Solid-State Physics},
    series         = {Undergraduate Lecture Notes in Physics},
    volume         = {},
    edition        = {3},
    url            = {https://link-springer-com.utokyo.idm.oclc.org/book/10.1007/978-3-030-31420-0},
    publisher      = {Springer Cham}
}

@book{Boer-Pohl2018,
    author         = {Karl W Böer and Udo W. Pohl},
    year           = {2018},
    title          = {Semiconductor Physics},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {https://link.springer.com/referencework/10.1007/978-3-319-69150-3},
    publisher      = {Springer Cham}
}

@book{Richard2023,
    author         = {Corey Richard},
    year           = {2023},
    title          = {Understanding Semiconductors: A Technical Guide for Non-Technical People},
    series         = {Maker Innovations Series},
    volume         = {},
    edition        = {},
    url            = {https://link.springer.com/book/10.1007/978-1-4842-8847-4},
    publisher      = {Apress Berkeley}
}

@book{Miller2022,
    author         = {Chris Miller},
    year           = {2022},
    title          = {Chip War: The Fight for the World's Most Critical Technology},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {https://www.simonandschuster.com/books/Chip-War/Chris-Miller/9781982172008},
    publisher      = {Scribner}
}

@book{Evstigneev2022,
    author         = {Mykhaylo Evstigneev},
    year           = {2022},
    title          = {Introduction to Semiconductor Physics and Devices},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {https://link.springer.com/book/10.1007/978-3-031-08458-4},
    publisher      = {Springer Cham}
}

@book{Lau2021,
    author         = {John H. Lau},
    year           = {2021},
    title          = {Semiconductor Advanced Packaging},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {https://link.springer.com/book/10.1007/978-981-16-1376-0},
    publisher      = {Springer Singapore}
}

@book{SemiconductorHandbook2023,
    author         = {},
    editor         = {Massimo Rudan and Rossella Brunetti and Susanna Reggiani},
    year           = {2023},
    title          = {Springer Handbook of Semiconductor Devices},
    series         = {Springer Handbooks},
    volume         = {},
    edition        = {},
    url            = {https://link.springer.com/book/10.1007/978-3-030-79827-7},
    publisher      = {Springer Cham}
}

@book{菊池正典2023,
    author         = {菊池正典},
    year           = {2023},
    month          = {3},
    title          = {半導体産業のすべて：世界の先端企業から日本メーカーの展望まで},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {https://www.diamond.co.jp/book/9784478117118.html},
    publisher      = {ダイヤモンド社}
}

@book{ずーぼ2024,
    author         = {ずーぼ},
    year           = {2024},
    month          = {1},
    title          = {今と未来がわかる半導体},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {https://www.natsume.co.jp/books/19325},
    publisher      = {ナツメ社}
}

@book{May-Spanos2006,
    author         = {Gary S. May and Costas J. Spanos},
    year           = {2006},
    title          = {Fundamentals of Semiconductor Manufacturing and Process Control},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {https://onlinelibrary.wiley.com/doi/book/10.1002/0471790281},
    publisher      = {John Wiley \& Sons}
}

@book{Sze-Lee2012,
    author         = {Simon M. Sze and Ming-Kwei Lee},
    year           = {2012},
    title          = {Semiconductor Devices: Physics and Technology},
    series         = {},
    volume         = {},
    edition        = {3},
    url            = {https://www.wiley.com/en-us/Semiconductor+Devices:+Physics+and+Technology,+3rd+Edition-p-9780470537947},
    publisher      = {John Wiley \& Sons}
}

@book{May-Sze2003,
    author         = {Gary S. May and Simon M. Sze},
    year           = {2003},
    title          = {Fundamentals of Semiconductor Fabrication},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {https://www.wiley.com/en-us/Fundamentals+of+Semiconductor+Fabrication-p-9780471232797},
    publisher      = {John Wiley \& Sons}
}


@incollection{VanRossum2005,
	address = {Oxford},
	author = {M. {Van Rossum}},
	booktitle = {Encyclopedia of Condensed Matter Physics (Second Edition)},
	doi = {10.1016/B978-0-323-90800-9.00292-4},
	edition = {Second Edition},
	editor = {Tapash Chakraborty},
	isbn = {978-0-323-91408-6},
	keywords = {85.30.--z, 85.40.--e, 85.40.Hp, 85.40.Ls, 85.40.Qx, 85.40.Ry, 85.40.Sz},
	pages = {748-756},
	publisher = {Academic Press},
	title = {Integrated Circuits},
	url = {https://www.sciencedirect.com/science/article/pii/B9780323908009002924},
	year = {2005},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/B9780323908009002924},
	bdsk-url-2 = {https://doi.org/10.1016/B978-0-323-90800-9.00292-4}}

@book{Patterson-Hennessy2014,
    author         = {David A. Patterson and John L. Hennessy},
    year           = {2014},
    title          = {Computer Organization and Design: The Hardware/Software Interface},
    series         = {},
    volume         = {},
    edition        = {5},
    url            = {},
    publisher      = {Elsevier}
}

@book{Pierret2003,
    author         = {Robert F. Pierret},
    year           = {2003},
    title          = {Advanced Semiconductor Fundamentals},
    series         = {Modular Series on Solid State Devices},
    volume         = {VI},
    edition        = {2},
    url            = {https://www.pearson.com/en-us/subject-catalog/p/advanced-semiconductor-fundamentals/P200000003285/9780130617927},
    publisher      = {Pearson}
}

@book{Ng2002,
    author         = {Kwok K. Ng},
    year           = {2002},
    title          = {Complete Guide to Semiconductor Devices},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {https://onlinelibrary.wiley.com/doi/book/10.1002/9781118014769},
    publisher      = {John Wiley \& Sons}
}

@misc{Dennard1968,
    author       = {Robert H. Dennard},
    howpublished = {U.S. Patent 3,387,286A},
    title        = {Field Effect Transistor Memory},
    year         = {1968}
}

@article{Hoff+1996,
    author          = {M. E. Hoff and F. Faggin and S. Mazor and M. Shima},
    year            = {1996},
    title           = {The history of the 4004},
    journal         = {IEEE Micro},
    volume          = {16},
    number          = {6},
    pages           = {10-20},
    url             = {https://ieeexplore.ieee.org/document/546561}
}

@book{戸田+2011,
    author         = {戸田盛和 and 斎藤信彦 and 久保亮五 and 橋爪夏樹},
    year           = {2011},
    title          = {統計物理学},
    series         = {現代物理学の基礎},
    volume         = {5},
    edition        = {新装版},
    url            = {https://www.iwanami.co.jp/book/b259545.html},
    publisher      = {岩波書店}
}

@book{Gibbs1902,
    author         = {Josiah Willard Gibbs},
    year           = {1902},
    title          = {Elementary Principles in Statistical Mechanics: Developed with Especial Reference to the Rational Foundation of Thermodynamics},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {},
    publisher      = {Charles Scribner's Sons}
}

@article{Weiss1907,
    author          = {Pierre Weiss},
    year            = {1907},
    title           = {L'hypothèse du champ moléculaire et la propriété ferromagnétique},
    journal         = {Journal of Physics: Theories and Applications},
    volume          = {6},
    number          = {1},
    pages           = {661-690},
    url             = {https://hal.science/jpa-00241247/en}
}

@inbook{Villani-Mouhot2015,
    author         = {Cédric Villani and Clément Mouhot},
    chapter        = {Kinetic Theory},
    editor         = {Nicholas J. Higham},
    pages          = {},
    publisher      = {Princeton University Press},
    title          = {The Princeton Companion to Applied Mathematics},
    year           = {2015},
    url            = {https://press.princeton.edu/books/hardcover/9780691150390/the-princeton-companion-to-applied-mathematics},
}

@inbook{Villani2002,
    author         = {Cédric Villani},
    chapter        = {A Review of Mathemaical Topics in Collisional Kinetic Theory},
    editor         = {S. Friedlander and D. Serre},
    pages          = {71-305},
    publisher      = {North-Holland, Amsterdam},
    title          = {Handbook of Mathematical Fluid Dynamics},
    volume         = {I},
    year           = {2002},
    url            = {https://www.sciencedirect.com/science/article/abs/pii/S1874579202800040?via%3Dihub},
}

@article{Zadeh1989,
    author          = {Lotfi A. Zadeh},
    year            = {1989},
    title           = {Knowledge representation in fuzzy logic},
    journal         = {IEEE Transactions on Knowledge and Data Engineering},
    volume          = {1},
    number          = {1},
    pages           = {89-100},
    url             = {https://ieeexplore.ieee.org/document/43406}
}

@book{Li2009,
    author         = {Stan Z. Li},
    year           = {2009},
    title          = {Markov Random Field Modeling in Image Analysis},
    series         = {Advances in Computer Vision and Pattern Recognition},
    volume         = {},
    edition        = {3},
    url            = {https://link.springer.com/book/10.1007/978-1-84800-279-1},
    publisher      = {Springer London}
}

@article{Besag1974,
    author          = {Julian Besag},
    year            = {1974},
    title           = {Spatial Interaction and the Statistical Analysis of Lattice Systems},
    journal         = {Journal of the Royal Statistical Society. Series B (Methodological)},
    volume          = {36},
    number          = {2},
    pages           = {192-236},
    url             = {https://www.jstor.org/stable/2984812}
}

@unpublished{Grenander1983,
    author = {U. Grenander},
    year   = {1983},
    title  = {Tutorial in Pattern Theory},
    url    = {},
    publisher = {Brown University}
}

@article{Boltzmann1872,
    author          = {L. Boltzmann},
    year            = {1872},
    title           = {Weitere Studien über das Wärme gleichgenicht unfer Gasmoläkuler},
    journal         = {Sitzungsberichte der Akademie der Wissenschaften},
    volume          = {66},
    number          = {},
    pages           = {275-370},
    url             = {}
}

@article{Maxwell1867,
    author          = {J. Clerk Maxwell},
    year            = {1867},
    title           = {On the Dynamical Theory of Gases},
    journal         = {Philosophical Transactions of the Royal Society of London},
    volume          = {157},
    number          = {},
    pages           = {49-88},
    url             = {https://www.jstor.org/stable/108968}
}

@article{Maxwell1878,
    author          = {J. Clerk Maxwell},
    year            = {1878},
    title           = {On Stresses in Rarefied Gases Arising from Inequalities of Temperature},
    journal         = {Proceedings of the Royal Society of London},
    volume          = {27},
    number          = {},
    pages           = {304-308},
    url             = {https://www.jstor.org/stable/113680}
}

@article{Gidas1989,
    author          = {B. Gidas},
    year            = {1989},
    title           = {A Renormalization Group Approach to Image Processing Problems},
    journal         = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    volume          = {11},
    number          = {2},
    pages           = {164-180},
    url             = {https://ieeexplore.ieee.org/document/16712}
}

@phdthesis{Li1991,
    author      = {S. Ziqing Li},
    school      = {University of Surrey, Guildford Surrey, UK},
    title       = {Towards 3D Vision from Range Images: An Optimisation Framework and Parallel Distributed Networks},
    year        = {1991},
    url         = {https://www.sciencedirect.com/science/article/pii/104996609290023V},
}

@article{Faraday1833,
    author          = {Michael Faraday},
    year            = {1833},
    title           = {Experimental Researches in Electricity. Third Series},
    journal         = {Philosophical Transactions of the Royal Society of London},
    volume          = {123},
    number          = {},
    pages           = {23-54},
    url             = {https://www.jstor.org/stable/107985}
}

@article{Braun1874,
    author          = {Ferdinand Braun},
    year            = {1874},
    title           = {Über die Stromleitung durch Schwefelmetalic},
    journal         = {Annalen der Physik and Chemie},
    volume          = {153},
    number          = {4},
    pages           = {556-563},
    url             = {}
}

@article{Griffiths1967,
    author          = {Robert B. Griffiths},
    year            = {1967},
    title           = {Thermodynamic Functions for Fluids and Ferromagnets near the Critical Point},
    journal         = {Physical Review},
    volume          = {158},
    number          = {1},
    pages           = {176-187},
    url             = {https://journals.aps.org/pr/abstract/10.1103/PhysRev.158.176}
}

@article{Lenz1920,
    author          = {W. Lenz},
    year            = {1920},
    title           = {Beiträg zum Verständnis der magnetischen Eigenschaften in festen Körpern},
    journal         = {Physikalische Zeitschrift},
    volume          = {21},
    number          = {},
    pages           = {613-615},
    url             = {}
}

@article{Peieris1936,
    author          = {R. E. Peieris},
    year            = {1936},
    title           = {On Ising's Model of Ferromagnetism},
    journal         = {Mathematical Proceedings of the Cambridge Philosophical Society},
    volume          = {32},
    number          = {3},
    pages           = {477-481},
    url             = {https://www.cambridge.org/core/journals/mathematical-proceedings-of-the-cambridge-philosophical-society/article/abs/on-isings-model-of-ferromagnetism/C0584C5711BC3D25830B63A4C2F09609}
}

@article{Ising1925,
    author          = {Ernst Ising},
    year            = {1925},
    title           = {Beitrag zur Theorie des Ferromagnetismus},
    journal         = {Zeitschrift für Physik},
    volume          = {31},
    number          = {},
    pages           = {253-258},
    url             = {https://link.springer.com/article/10.1007/BF02980577}
}

@article{Fisher1966,
    author          = {Michael E. Fisher},
    year            = {1966},
    title           = {Quantum Corrections to Critical-Point Behavior},
    journal         = {Physical Review Letters},
    volume          = {16},
    number          = {1},
    pages           = {11-14},
    url             = {https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.16.11}
}

@book{Madelung1978,
    author         = {Otfried Madelung},
    year           = {1978},
    title          = {Introduction to Solid-State Theory},
    series         = {Springer Series in Solid-State Sciences},
    volume         = {2},
    edition        = {},
    url            = {https://link.springer.com/book/10.1007/978-3-642-61885-7},
    publisher      = {Springer Berlin, Heidelberg}
}

@article{Heisenberg1931,
    author          = {W. Heisenberg},
    year            = {1931},
    title           = {Zum Paulischen Ausschließungsprinzip},
    journal         = {Annalen der Physik},
    volume          = {402},
    number          = {7},
    pages           = {888-904},
    url             = {https://onlinelibrary.wiley.com/doi/10.1002/andp.19314020710}
}

@article{Criens+2023,
    author          = {David Criens and Peter Pfaffelhuber and Thorsten Schmidt},
    year            = {2023},
    title           = {The Martingale Problem Method Revisited},
    journal         = {Electronic Journal of Probability},
    volume          = {28},
    number          = {},
    pages           = {1-46},
    url             = {https://projecteuclid.org/journals/electronic-journal-of-probability/volume-28/issue-none/The-martingale-problem-method-revisited/10.1214/23-EJP902.full}
}

@article{Stroock-Varadhan1969,
    author          = {Daniel W. Stroock and S. R. S. Varadhan},
    year            = {1969},
    title           = {Diffusion Processes with Continuous Coefficients, I, II},
    journal         = {Communications on Pure and Applied Mathematics},
    volume          = {22},
    number          = {4},
    pages           = {345-400, 479-530},
    url             = {https://onlinelibrary.wiley.com/doi/10.1002/cpa.3160220404}
}

@unpublished{Hoh1998,
    author         = {Walter Hoh},
    year           = {1998},
    title          = {Pseudo-Differential operators generating Markov processes},
    note           = {Habilitationsschrift Universität Bielefeld},
    url    = {http://www.mathematik.uni-bielefeld.de/%7Ehoh/pdo_mp.ps}
}

@article{Valiant1984,
    author          = {L. G. Valiant},
    year            = {1984},
    title           = {A Theory of the Learnable},
    journal         = {Communications of the ACM},
    volume          = {27},
    number          = {11},
    pages           = {1134-1142},
    url             = {https://dl.acm.org/doi/10.1145/1968.1972}
}

@article{Seeger2002,
    author          = {Matthias Seeger},
    year            = {2002},
    title           = {PAC-Bayesian Generalisation Error Bounds for Gaussian Process Classification},
    journal         = {Journal of Machine Learning Research},
    volume          = {3},
    number          = {},
    pages           = {233-269},
    url             = {https://www.jmlr.org/papers/v3/seeger02a.html}
}

@inbook{Haussler-Warmuth1993,
    author         = {David Haussler and Manfred Warmuth},
    chapter        = {The Probably Approximately Correct (PAC) and Other Learning Models},
    editor         = {Alan L. Meyrowitz and Susan Chipman},
    pages          = {291-312},
    publisher      = {Springer New York},
    title          = {Foundations of Knowledge Acquisition: Machine Learning},
    year           = {1993},
    url            = {https://link.springer.com/book/10.1007/b102257},
}

@inproceedings{Shawe-Taylor-Williamson1997,
    author          = {John Shawe-Taylor and Robert C. Williamson},
    booktitle       = {Proceedings of the Tenth Annual Conference on Computational Learning Theory},
    editor          = {},
    title           = {A PAC Analysis of a Bayesian Estimator},
    year            = {1997},
    pages           = {2-9},
    url             = {https://dl.acm.org/doi/10.1145/267460.267466},
}

@article{McAllester1999,
    author          = {David A. McAllester},
    year            = {1999},
    title           = {Some PAC-Bayesian Theorems},
    journal         = {Machine Learning},
    volume          = {37},
    number          = {},
    pages           = {355-363},
    url             = {https://link.springer.com/article/10.1023/A:1007618624809}
}

@book{Devroye+1996,
    author         = {Luc Devroye and László Györfi and Gábor Lugosi},
    year           = {1996},
    title          = {A Probabilistic Theory of Pattern Recognition},
    series         = {Stochastic Modelling and Applied Probability},
    volume         = {31},
    edition        = {},
    url            = {https://link.springer.com/book/10.1007/978-1-4612-0711-5},
    publisher      = {Springer New York}
}

@book{Vapnik1998,
    author         = {Vladimir N. Vapnik},
    year           = {1998},
    title          = {Statistical Learning Theory},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {https://www.wiley.com/en-us/Statistical+Learning+Theory-p-9780471030034},
    publisher      = {Wiley-Blackwell}
}

@book{Catoni2007,
    author         = {Olivier Catoni},
    year           = {2007},
    title          = {PAC-Bayesian Supervised Classification: The Thermodynamics of Statistical Learning},
    series         = {IMS Lecture Notes - Monograph Series},
    volume         = {56},
    edition        = {},
    url            = {https://projecteuclid.org/ebooks/institute-of-mathematical-statistics-lecture-notes-monograph-series/Pac-Bayesian-Supervised-Classification/toc/10.1214/074921707000000391},
    publisher      = {Institute of Mathematical Statistics}
}

@article{Blei+2017,
    author          = {David M. Blei and Alp Kucukelbir and Jon D. McAuliffe},
    year            = {2017},
    title           = {Variational Inference: A Review for Statisticians},
    journal         = {Journal of the American Statistical Association},
    volume          = {112},
    number          = {518},
    pages           = {859-877},
    url             = {https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1285773}
}

@article{Scheffe1947,
    author          = {H Scheffé},
    year            = {1947},
    title           = {A Useful Convergence Theorem for Probability Discributions},
    journal         = {The Annals of Mathematical Statistics},
    volume          = {18},
    number          = {3},
    pages           = {434-438},
    url             = {https://www.jstor.org/stable/2235739}
}

@book{Bishop2006,
    author         = {Christopher M. Bishop},
    year           = {2006},
    title          = {Pattern Recognition and Machine Learning},
    series         = {Information Science and Statistics},
    volume         = {},
    edition        = {},
    url            = {https://link.springer.com/book/9780387310732},
    publisher      = {Springer New York}
}

@book{須山敦志2019,
    author         = {須山敦志},
    year           = {2019},
    month          = {8},
    title          = {ベイズ深層学習},
    series         = {機械学習プロフェッショナルシリーズ},
    volume         = {},
    edition        = {},
    url            = {https://www.kspub.co.jp/book/detail/5168707.html},
    publisher      = {講談社サイエンティフィク}
}

@article{Hinton+2006,
    author          = {Geoffrey E. Hinton and R. R. Salakhutdinov},
    journal         = {Science},
    number          = {5786},
    title           = {Reducing the Dimensionality of Data with Neural Networks},
    volume          = {313},
    year            = {2006},
    pages           = {504-507},
    url             = {https://www.science.org/doi/10.1126/science.1127647},
}

@article{大王製紙CB発行事件,
    author          = {東京地判},
    year            = {平成30年９月20日},
    title           = {判決〔控訴〕},
    journal         = {資料版商事法務},
    volume          = {415},
    number          = {},
    pages           = {83},
    url             = {https://www.shojihomu.co.jp/publishing/subscription_detail?id=509&category=2&sub_category=8&publish_id=509&cd=850415}
}

@article{川島いづみ2021,
    author          = {川島いづみ},
    year            = {2021},
    title           = {新株予約権付社債の有利発行・不公正発行該当性},
    journal         = {TKC ローライブラリー 新・判例解説 Watch 商法},
    volume          = {146},
    number          = {},
    pages           = {},
    url             = {http://lex.lawlibrary.jp/commentary/pdf/z18817009-00-051462025_tkc.pdf}
}

@article{潘阿憲2020,
    author          = {潘阿憲},
    year            = {2020},
    title           = {新株予約権付社債の不公正発行と取締役の責任},
    journal         = {法学教室},
    volume          = {},
    number          = {473},
    pages           = {129},
    url             = {https://www.yuhikaku.co.jp/hougaku/detail/020394}
}

@book{Pazy1983,
    author         = {A. Pazy},
    year           = {1983},
    title          = {Semigroups of Linear Operators and Applications to Partial Differential Equations},
    series         = {Applied Mathematical Sciences},
    volume         = {44},
    edition        = {},
    url            = {https://link.springer.com/book/10.1007/978-1-4612-5561-1},
    publisher      = {Springer New York}
}

@article{Davis1984,
    author          = {M. H. A. Davis},
    year            = {1984},
    title           = {Piecewise-Deterministic Markov Processes: A General Class of Non-Diffusion Stochastic Models},
    journal         = {Journal of the Royal Statistical Society. Series B (Methodological)},
    volume          = {46},
    number          = {3},
    pages           = {353-388},
    url             = {https://www.jstor.org/stable/2345677}
}

@article{Singh+2017,
    author          = {Sumeetpal S. Singh and F. Lindsten and E. Moulines},
    year            = {2017},
    title           = {Blocking Strategies and Stability of Particle Gibbs Samplers},
    journal         = {Biometrika},
    volume          = {104},
    number          = {4},
    pages           = {953-969},
    url             = {https://academic.oup.com/biomet/article/104/4/953/4554443}
}

@article{Goldman-Singh2021,
    author          = {Jacob Vorstrup Goldman and Sumeetpal S. Singh},
    year            = {2021},
    title           = {Spatiotemporal Blocking of the Bouncy Particle Sampler for Efficient Inference in State-Space Models},
    journal         = {Statistics and Computing},
    volume          = {31},
    number          = {68},
    pages           = {67-81},
    url             = {https://link.springer.com/article/10.1007/s11222-021-10034-6}
}

@article{Bierkens+2020,
    author          = {Joris Bierkens and Sebastiano Grazzi and Kengo Kamatani and Gareth O. Roberts},
    year            = {2020},
    title           = {The Boomerang Sampler},
    journal         = {Proceedings of the 37th International Conference on Machine Learning},
    volume          = {119},
    number          = {},
    pages           = {908-918},
    url             = {https://proceedings.mlr.press/v119/bierkens20a.html}
}

@book{Sutton-Barto2018,
    author         = {Richard S. Sutton and Andrew G. Barto},
    year           = {2018},
    title          = {Reinforcement Learning: An Introduction},
    series         = {Adaptive Computation and Machine Learning Series},
    volume         = {},
    edition        = {2},
    url            = {https://mitpress.mit.edu/9780262352703/reinforcement-learning/},
    publisher      = {MIT Press}
}

@book{Powell2011,
    author         = {Warren B. Powell},
    year           = {2011},
    title          = {Approximate Dynamic Programming: Solving the Curses of Dimensionality},
    series         = {Wiley Series in Probability and Statistics},
    volume         = {},
    edition        = {2},
    url            = {https://onlinelibrary.wiley.com/doi/book/10.1002/9781118029176},
    publisher      = {John Wiley \& Sons}
}

@inproceedings{Singh-Bertsekas1996,
    author          = {Satinder Singh and Dimitri Bertsekas},
    year            = {1996},
    title           = {Reinforcement Learning for Dynamic Channel Allocation in Cellular Telephone Systems},
    booktitle       = {Advances in Neural Information Processing Systems 9},
    pages           = {},
    url             = {https://proceedings.neurips.cc/paper/1996/hash/3948ead63a9f2944218de038d8934305-Abstract.html}
}

@article{Silver+2018,
    author          = {David Silver and Thomas Hubert and Julian Schrittwieser and Ioannis Antonoglou and Matthew Lai and Arthur Guez and Marc Lanctot and Laurent Sifre and Dharshan Kumaran and Thore Graepel and Timothy Lillicrap and Karen Simonyan and Demis Hassabis},
    year            = {2018},
    title           = {A General Reinforcement Learning Algorithm that Masters Chess, Shogi, and Go through Self-Play},
    journal         = {Science},
    volume          = {362},
    number          = {6419},
    pages           = {1140-1144},
    url             = {https://www.science.org/doi/10.1126/science.aar6404}
}

@inproceedings{VanRoy+1997,
    author          = {B. Van{\ }Roy and D. P. Bertsekas and Y. Lee and J. N. Tsitsiklis},
    year            = {1997},
    title           = {A Neuro-dynamic Programming Approach to Retailer Inventory Management},
    booktitle       = {Proceedings of the 36th IEEE Conference on Decision and Control},
    pages           = {},
    url             = {https://ieeexplore.ieee.org/abstract/document/652501}
}

@article{Crites-Barto1998,
    author          = {Robert H. Crites and Andrew G. Barto},
    year            = {1998},
    title           = {Elevator Group Control Using Multiple Reinforcement Learning Agents},
    journal         = {Machine Learning},
    volume          = {33},
    number          = {},
    pages           = {235-262},
    url             = {https://link.springer.com/article/10.1023/A:1007518724497}
}

@article{Rolnick+2022,
    author = {Rolnick, David and Donti, Priya L. and Kaack, Lynn H. and Kochanski, Kelly and Lacoste, Alexandre and Sankaran, Kris and Ross, Andrew Slavin and Milojevic-Dupont, Nikola and Jaques, Natasha and Waldman-Brown, Anna and Luccioni, Alexandra Sasha and Maharaj, Tegan and Sherwin, Evan D. and Mukkavilli, S. Karthik and Kording, Konrad P. and Gomes, Carla P. and Ng, Andrew Y. and Hassabis, Demis and Platt, John C. and Creutzig, Felix and Chayes, Jennifer and Bengio, Yoshua},
    title = {Tackling Climate Change with Machine Learning},
    year = {2022},
    issue_date = {February 2023},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {55},
    number = {2},
    issn = {0360-0300},
    url = {https://doi.org/10.1145/3485128},
    doi = {10.1145/3485128},
    abstract = {Climate change is one of the greatest challenges facing humanity, and we, as machine learning (ML) experts, may wonder how we can help. Here we describe how ML can be a powerful tool in reducing greenhouse gas emissions and helping society adapt to a changing climate. From smart grids to disaster management, we identify high impact problems where existing gaps can be filled by ML, in collaboration with other fields. Our recommendations encompass exciting research questions as well as promising business opportunities. We call on the ML community to join the global effort against climate change.},
    journal = {ACM Computing Survey},
    month = {feb},
    articleno = {42},
    numpages = {96},
    keywords = {artificial intelligence, machine learning, adaptation, mitigation, Climate change}
}



@phdthesis{Watkins1989,
    author      = {Christopher J. C. H. Watkins},
    school      = {University of London},
    title       = {Learning from Delayed Rewards},
    year        = {1989},
    url         = {https://www.cs.rhul.ac.uk/~chrisw/thesis.html},
}

@article{Watkins-Dayan1992,
    author          = {Christopher J. C. H. Watkins and Peter Dayan},
    year            = {1992},
    title           = {Q-Leraning},
    journal         = {Machine Learning},
    volume          = {8},
    number          = {},
    pages           = {279-292},
    url             = {https://link.springer.com/article/10.1007/BF00992698}
}

@article{Sutton1988,
    author          = {Richard S. Sutton},
    year            = {1988},
    title           = {Learning to Predict by the Methods of Temporal Differences},
    journal         = {Machine Learning},
    volume          = {3},
    number          = {},
    pages           = {9-44},
    url             = {https://link.springer.com/article/10.1007/BF00115009}
}

@article{Sun+2016,
    author          = {Ying Sun and Prabhu Babu and Daniel P. Palomar},
    year            = {2016},
    title           = {Majorization-Minimization Algorithms in Signal Processing, Communications, and Machine Learning},
    journal         = {IEEE Transactions on Signal Processing},
    volume          = {65},
    number          = {3},
    pages           = {794-816},
    url             = {https://ieeexplore.ieee.org/document/7547360}
}

@article{Fisher1912,
    author          = {R. A. Fisher},
    year            = {1912},
    title           = {On an Absolute Criterion for Fitting Frequency Curves},
    journal         = {Messenger of Mathematics},
    volume          = {41},
    number          = {},
    pages           = {155-160},
    url             = {https://www.jstor.org/stable/2246266}
}

@article{Wu-Lange2010,
    author          = {Tong Tong Wu and Kenneth Lange},
    year            = {2010},
    title           = {The MM Alternative to EM},
    journal         = {Statistical Science},
    volume          = {25},
    number          = {4},
    pages           = {492-505},
    url             = {https://www.jstor.org/stable/23061097}
}

@book{Neal1996,
    author         = {Radford M. Neal},
    year           = {1996},
    title          = {Bayesian Learning for Neural Networks},
    series         = {Lecture Notes in Statistics},
    volume         = {118},
    edition        = {},
    url            = {https://link.springer.com/book/10.1007/978-1-4612-0745-0},
    publisher      = {Springer New York}
}

@techreport{MacKay1994,
    author      = {D. J. C. MacKay},
    institution = {American Society of Heating, Refrigerating, and Air Conditioning Engineers (ASHRAE)},
    title       = {Bayesian nonlinear modeling for the prediction competition},
    volume          = {100},
    number          = {2},
    year        = {1994},
    url         = {https://www.osti.gov/biblio/33309},
}

@book{Rasmussen-Williams2006,
    author         = {Carl Edward Rasmussen and Christopher K. I. Williams},
    year           = {2006},
    title          = {Gaussian Processes for Machine Learning},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {https://direct.mit.edu/books/book/2320/Gaussian-Processes-for-Machine-Learning},
    publisher      = {The MIT Press}
}

@article{Rumelhart+1986,
    author          = {David E. Rumelhart and Geoffrey E. Hinton and Ronald J. Williams},
    year            = {1986},
    title           = {Learning Representations by Back-Propagating Errors},
    journal         = {Nature},
    volume          = {323},
    number          = {},
    pages           = {533-536},
    url             = {https://www.nature.com/articles/323533a0}
}

@inproceedings{Williams1996,
    author          = {Christopher K. I. Williams},
    year            = {1996},
    title           = {Computing with Infinite Networks},
    booktitle       = {Advances in Neural Information Processing Systems 9},
    pages           = {295-301},
    url             = {https://papers.nips.cc/paper_files/paper/1996/hash/ae5e3ce40e0404a45ecacaaf05e5f735-Abstract.html}
}

@inproceedings{Lee+2018,
title={Deep Neural Networks as Gaussian Processes},
author={Jaehoon Lee and Jascha Sohl-dickstein and Jeffrey Pennington and Roman Novak and Sam Schoenholz and Yasaman Bahri},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=B1EA-M-0Z},
}

@book{Bishop-Bishop2024,
    author         = {Christopher M. Bishop and Hugo Bishop},
    year           = {2024},
    title          = {Deep Learning: Foundations and Concepts},
    url            = {https://link.springer.com/book/10.1007/978-3-031-45468-4},
    publisher      = {Springer Cham}
}

@article{LeCun1998,
    author          = {Yan LeCun and L. Bottou and Y. Bengio and P. Haffner},
    year            = {1998},
    title           = {Gradient-Based Learning Applied to Document Recognition},
    journal         = {Proceedings of the IEEE},
    volume          = {86},
    number          = {11},
    pages           = {2278-2324},
    url             = {https://ieeexplore.ieee.org/document/726791}
}

@article{Schmidhuber2015,
    author          = {Jürgen Schmidhuber},
    year            = {2015},
    title           = {Deep Learning in Neural Networks: An Overview},
    journal         = {Neural Networks},
    volume          = {61},
    number          = {},
    pages           = {85-117},
    url             = {https://www.sciencedirect.com/science/article/pii/S0893608014002135}
}

@inproceedings{Goodfellow+2014,
    author          = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
    year            = {2014},
    title           = {Generative Adversarial Nets},
    booktitle       = {Advances in Neural Information Processing Systems},
    volume          = {27},
    pages           = {1-9},
    url             = {https://papers.nips.cc/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html}
}

@inproceedings{Krizhevsky+2012,
    author          = {Alex Krizhevsky and Ilya Sutskever and Geoffrey E. Hinton},
    year            = {2012},
    title           = {ImageNet Classification with Deep Convolutional Neural Networks},
    booktitle       = {Advances in Neural Information Processing Systems},
    volume          = {25},
    pages           = {},
    url             = {https://papers.nips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html}
}

@unpublished{Hinton+2012,
    title={Improving neural networks by preventing co-adaptation of feature detectors}, 
    author={Geoffrey E. Hinton and Nitish Srivastava and Alex Krizhevsky and Ilya Sutskever and Ruslan R. Salakhutdinov},
    year   = {2012},
    url    = {https://arxiv.org/abs/1207.0580}
}

@article{Srivastava+2014,
    author          = {Nitish Srivastava and Geoffrey E. Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
    year            = {2014},
    title           = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
    journal         = {The Journal of Machine Learning Research},
    volume          = {15},
    number          = {56},
    pages           = {1929-1958},
    url             = {https://jmlr.org/papers/v15/srivastava14a.html}
}

@inproceedings{Salakhutdinov-Hinton2009,
    author          = {Ruslan Salakhutdinov and Geoffrey Hinton},
    year            = {2009},
    title           = {Deep Boltzmann Machines},
    booktitle       = {Proceedings of the Twelth International Conference on Artificial Intelligence and Statistics},
    volume          = {5},
    pages           = {448-455},
    url             = {https://proceedings.mlr.press/v5/salakhutdinov09a.html}
}

@inproceedings{Bengio+2014,
    author          = {Yoshua Bengio and Eric Laufer and Guillaume Alain and Jason Yosinski},
    year            = {2014},
    title           = {Deep Generative Stochastic Networks Trainable by Backprop},
    booktitle       = {Proceedings of the 31st International Conference on Machine Learning},
    volume          = {32},
    number          = {2},
    pages           = {226-234},
    url             = {https://proceedings.mlr.press/v32/bengio14.html}
}

@article{Endres-Schindelin2003,
    author          = {D. M. Endres and J. E. Schindelin},
    year            = {2003},
    title           = {A New Metric for Probability Distributions},
    journal         = {IEEE Transactions on Information Theory},
    volume          = {49},
    number          = {7},
    pages           = {1858-1860},
    url             = {https://ieeexplore.ieee.org/document/1207388}
}

@article{Osan+2018,
    author          = {Tristán M. Osán and Diego G. Bussandri and Pedro W. Lamberti},
    year            = {2018},
    title           = {Monoparametric Family of Metrics Derived from Classical Jensen-Shannon Divergence},
    journal         = {Physica A: Statistical Mechanics and its Applications},
    volume          = {495},
    number          = {},
    pages           = {336-344},
    url             = {https://www.sciencedirect.com/science/article/pii/S0378437117313225}
}

@article{Rao1987,
    author          = {C. R. Rao},
    year            = {1987},
    title           = {Differential Metrics in Probability Spaces},
    journal         = {IMS Lecture Notes Monograph Series},
    volume          = {10},
    number          = {},
    pages           = {217-240},
    url             = {https://projecteuclid.org/ebooks/institute-of-mathematical-statistics-lecture-notes-monograph-series/Differential-geometry-in-statistical-inference/chapter/Chapter-5-Differential-Metrics-in-Probability-Spaces/10.1214/lnms/1215467062}
}

@article{Rao1982,
    author          = {C. R. Rao},
    year            = {1982},
    title           = {Diversity and Dissimilarity Coefficients: A Unified Approach},
    journal         = {Theoretical Population Biology},
    volume          = {21},
    number          = {1},
    pages           = {24-43},
    url             = {https://www.sciencedirect.com/science/article/abs/pii/0040580982900041}
}

@article{Lin1991,
    author          = {J. Lin},
    year            = {1991},
    title           = {Divergence Measures Based on the Shannon Entropy},
    journal         = {IEEE Transactions on Information Theory},
    volume          = {37},
    number          = {1},
    pages           = {145-151},
    url             = {https://ieeexplore.ieee.org/document/61115}
}


@article{Nielsen2021,
    author          = {Frank Nielsen},
    year            = {2021},
    title           = {On a Variational Definition for the Jensen-Shannon Symmetrization of Distances Based on the Information Radius},
    journal         = {Entropy},
    volume          = {23},
    number          = {4},
    pages           = {464},
    url             = {https://www.mdpi.com/1099-4300/23/4/464}
}

@article{Ali-Silvey1966,
    author          = {S. M. Ali and S. D. Silvey},
    year            = {1966},
    title           = {A General Class of Coefficients of Divergence of One Distribution from Another},
    journal         = {Journal of the Royal Statistical Society. Series B (Methodological)},
    volume          = {28},
    number          = {1},
    pages           = {131-142},
    url             = {https://www.jstor.org/stable/2984279}
}

@inproceedings{Renyi1961,
    author          = {Alfréd Rényi},
    year            = {1961},
    title           = {On Measures of Entropy and Information},
    booktitle       = {Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability},
    volume          = {1},
    pages           = {547-561},
    url             = {https://projecteuclid.org/proceedings/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-Fourth-Berkeley-Symposium-on-Mathematical-Statistics-and/Chapter/On-Measures-of-Entropy-and-Information/bsmsp/1200512181}
}

@article{Csiszar1963,
    author          = {Imere Csiszár},
    year            = {1963},
    title           = {Eine informationstheoretische Ungleichung und ihre Anwendung auf Beweis der Ergodizitaet von Markoffschen Ketten},
    journal         = {Magyár Tudomá Akadémia Mahematikai Kutató Intézetének Köezleményei},
    volume          = {6},
    number          = {},
    pages           = {85-108},
    url             = {https://www.fuw.edu.pl/~kostecki/scans/csiszar1963.pdf}
}

@article{Morimoto1963,
    author          = {Tetsuzo Morimoto},
    year            = {1963},
    title           = {Markov Processes and the $H$-Theorem},
    journal         = {Journal of the Physical Society of Japan},
    volume          = {18},
    number          = {3},
    pages           = {328-331},
    url             = {https://journals.jps.jp/doi/abs/10.1143/JPSJ.18.328?journalCode=jpsj}
}

@book{Robert2007,
    author         = {Christian P. Robert},
    year           = {2007},
    title          = {The Bayesian Choice: From Decision-Theoretic Foundations to Computational Implementation},
    series         = {Springer Texts in Statistics},
    volume         = {},
    edition        = {2},
    url            = {https://link.springer.com/book/10.1007/0-387-71599-1},
    publisher      = {Springer New York}
}

@article{Wu1983,
    author          = {C. F. Jeff Wu},
    year            = {1983},
    title           = {On the Convergence Properties of the EM Algorithm},
    journal         = {The Annals of Statistics},
    volume          = {11},
    number          = {1},
    pages           = {95-103},
    url             = {https://www.jstor.org/stable/2240463}
}

@article{Finch+1989,
    author          = {Stephen J. Finch and Nancy R. Mendell and Henry C. Thode{\ }Jr.},
    year            = {1989},
    title           = {Probabilistic Measures of Adequacy of a Numerical Search for a Global Maximum},
    journal         = {Journal of the American Statistical Association},
    volume          = {84},
    number          = {408},
    pages           = {1020-1023},
    url             = {https://www.jstor.org/stable/2290078}
}

@article{Boyles1983,
    author          = {Russell A. Boyles},
    year            = {1983},
    title           = {On the Convergence of the EM Algorithm},
    journal         = {Journal of the Royal Statistical Society. Series B (Methodological)},
    volume          = {45},
    number          = {1},
    pages           = {47-50},
    url             = {https://www.jstor.org/stable/2345622}
}

@inproceedings{Attias1999,
    author          = {Hagai Attias},
    year            = {1999},
    title           = {Inferring Parameters and Structure of Latent Variable Models by Variational Bayes},
    booktitle       = {Proceedings of the Fifteenth Conference in Artificial Intelligence},
    volume          = {},
    pages           = {21-30},
    url             = {https://dl.acm.org/doi/10.5555/2073796.2073799}
}

@article{Kingma-Welling2019,
    author          = {Diederik P. Kingma and Max Welling},
    year            = {2019},
    title           = {An Introduction to Variational Autoencoders},
    journal         = {Foundations and Treands in Machine Learning},
    volume          = {12},
    number          = {4},
    pages           = {307-392},
    url             = {https://www.nowpublishers.com/article/Details/MAL-056}
}

@inproceedings{Kingma-Welling2014,
    author          = {Dieferik P. Kingma and Max Welling},
    year            = {2014},
    title           = {Auto-Encoding Variational Bayes},
    booktitle       = {International Conference on Learning Representations},
    volume          = {2},
    pages           = {},
    url             = {https://openreview.net/forum?id=33X9fd2-9FyZd}
}

@article{Jordan+1999,
    author          = {Michael I. Jordan and Zoubin Ghahramani and Tommi S. Jaakkola and Lawrence K. Saul},
    year            = {1999},
    title           = {An Introduction to Variational Methods for Graphical Models},
    journal         = {Machine Learning},
    volume          = {37},
    number          = {},
    pages           = {183-233},
    url             = {https://link.springer.com/article/10.1023/A:1007665907178}
}

@article{Peterson-Anderson1987,
    author          = {Carsten Peterson and James R. Anderson},
    year            = {},
    title           = {A Mean Field Theory Learning Algorithm for Neural Networks},
    journal         = {Complex Systems},
    volume          = {1},
    number          = {5},
    pages           = {1987},
    url             = {https://www.complex-systems.com/abstracts/v01_i05_a06/}
}

@book{Parisi1988,
    author         = {Giorgio Parisi},
    year           = {1988},
    title          = {Statistical Field Theory},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {},
    publisher      = {Addison-Wesley}
}

@book{Bathe1996,
    author         = {Klaus-Jürgen Bathe},
    year           = {1996},
    title          = {Finite Element Procedures},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {},
    publisher      = {Prentice-Hall}
}

@book{Sakurai1985,
    author         = {J. Sakurai},
    year           = {1985},
    title          = {Modern Quantum Mechanics},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {},
    publisher      = {Addison-Wesley}
}

@book{Rustagi1976,
    author         = {J. Rustagi},
    year           = {1976},
    title          = {Variational Methods in Statistics},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {},
    publisher      = {Academic Press}
}

@inbook{Neal-Hinton1998,
    author         = {Radford M. Neal and Geoffrey E. Hinton},
    chapter        = {A View of the EM Algorithm that Justifies Incremental, Sparse and Other Variants},
    editor         = {Michael I. Jordan},
    pages          = {355-368},
    publisher      = {Springer Dordrecht},
    title          = {Learning in Graphical Models},
    year           = {1998},
    url            = {https://link.springer.com/chapter/10.1007/978-94-011-5014-9_12},
}

@inproceedings{Rezende+2014,
    author          = {Danilo Jimenez Rezende and Shakir Mohamed and Daan Wierstra},
    year            = {2014},
    title           = {Approximate Inference in Deep Generative Models},
    booktitle       = {Proceedings of the 31st International Conference on Machine Learning},
    volume          = {32},
    pages           = {1278-1286},
    url             = {https://proceedings.mlr.press/v32/rezende14.html}
}

@article{Rosenblatt1958,
    author          = {F. Rosenblatt},
    year            = {1958},
    title           = {The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain},
    journal         = {Psychological Review},
    volume          = {65},
    number          = {6},
    pages           = {386-408},
    url             = {https://psycnet.apa.org/record/1959-09865-001}
}

@book{Minsky-Papert1969,
    author         = {Marvin Minsky and Seymour A. Papert},
    year           = {1969},
    title          = {Perceptrons: An Introduction to Computational Geometry},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {https://direct.mit.edu/books/book/3132/PerceptronsAn-Introduction-to-Computational},
    publisher      = {The MIT Press}
}

@book{Hebb1949,
    author         = {D. O.Hebb},
    year           = {1949},
    title          = {The Organization of Behavior: A Neuropsychological Theory},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {https://www.taylorfrancis.com/books/mono/10.4324/9781410612403/organization-behavior-hebb},
    publisher      = {John Wiley \& Sons, Chapman and Hall}
}

@article{McCulloch-Pitts1943,
    author          = {W. McCulloch and W. Pitts},
    year            = {1943},
    title           = {A Logical Calculus of the Ideas Immanent in Nervous Activity},
    journal         = {Bulletin of Mathematical Biophysics},
    volume          = {7},
    number          = {},
    pages           = {115-133},
    url             = {https://link.springer.com/article/10.1007/BF02478259}
}

@article{Siegelmann-Sontag1991,
    author          = {Hava T. Siegelmann and Eduardo D. Sontag},
    year            = {1991},
    title           = {Turing Computability with Neural Nets},
    journal         = {Applied Mathematics Letters},
    volume          = {4},
    number          = {6},
    pages           = {77-80},
    url             = {https://www.sciencedirect.com/science/article/pii/089396599190080F}
}

@book{人工知能学会2015,
    author         = {麻生英樹 and 安田宗樹 and 前田新一 and 岡野原大輔 and 岡谷貴之 and 久保陽太郎 and ボレガラダヌシカ},
    year           = {2015},
    title          = {深層学習},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {https://www.kindaikagaku.co.jp/book_list/detail/9784764904873/},
    publisher      = {近代科学社}
}

@book{甘利俊一1989,
    author         = {甘利俊一},
    year           = {1989},
    title          = {神経回路網モデルとコネクショニズム},
    series         = {認知科学選書},
    volume         = {22},
    edition        = {},
    url            = {https://www.utp.or.jp/book/b305707.html},
    publisher      = {東京大学出版会}
}

@article{Amari1967,
    author          = {Shunichi Amari},
    year            = {1967},
    title           = {A Theory of Adaptive Pattern Classifiers},
    journal         = {IEEE Transactions on Electronic Computers},
    volume          = {EC-16},
    number          = {3},
    pages           = {299-307},
    url             = {https://ieeexplore.ieee.org/document/4039068}
}

@book{Amari1985,
    author         = {Shun-ichi Amari},
    year           = {1985},
    title          = {Differential-Geometrical Methods in Statistics},
    series         = {Lecture Notes in Statistics},
    volume         = {28},
    edition        = {},
    url            = {https://link.springer.com/book/10.1007/978-1-4612-5056-2},
    publisher      = {Springer New York}
}

@article{Fukushima1980,
    author          = {K. Fukushima},
    year            = {1980},
    title           = {Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position--Neocognitron},
    journal         = {Biological Cybernetics},
    volume          = {36},
    number          = {},
    pages           = {193-202},
    url             = {https://link.springer.com/article/10.1007/BF00344251}
}

@article{Hubel-Wiesel1959,
    author          = {D. H. Wiesel and T. N. Hubel},
    year            = {1959},
    title           = {Receptive Fields of Single Neurones in the Cat's Striate Cortex},
    journal         = {Journal of Physiology},
    volume          = {148},
    number          = {3},
    pages           = {574-591},
    url             = {https://physoc.onlinelibrary.wiley.com/doi/10.1113/jphysiol.1959.sp006308}
}

@article{Fukushima1975,
    author          = {K. Fukushima},
    year            = {1975},
    title           = {Cognitron: a Self-Organizing Multilayered Neural Network},
    journal         = {Biological Cybernetics},
    volume          = {20},
    number          = {},
    pages           = {121-136},
    url             = {}
}

@article{Malsburg1973,
    author          = {C. von{\ }der{\ }Malsburg},
    year            = {1973},
    title           = {Self-Organization of Orientation Sensitive Cells in the Striate Cortex},
    journal         = {Kybernetik},
    volume          = {14},
    number          = {},
    pages           = {85-100},
    url             = {}
}

@article{Hubel1967,
    author          = {David H. Hubel},
    year            = {1967},
    title           = {Effects of Distortion of Sensory Input on the Visual System of Kittens},
    journal         = {The Physiologist},
    volume          = {10},
    number          = {},
    pages           = {17-45},
    url             = {}
}

@article{Sejnowski-Rosenberg1987,
    author          = {Terrence J. Sejnowski and Charles R. Rosenberg},
    year            = {1987},
    title           = {Parallel Networks that Learn to Pronounce English Text},
    journal         = {Complex Systems},
    volume          = {1},
    number          = {1},
    pages           = {145-168},
    url             = {https://www.complex-systems.com/abstracts/v01_i01_a10/}
}

@inproceedings{Bengio+2006,
    author          = {Yoshua Bengio and Pascal Lamblin and Dan Popovici and Hugo Larochelle},
    year            = {2006},
    title           = {Greedy Layer-Wise Training of Deep Networks},
    booktitle       = {Advances in Neural Information Processing Systems},
    volume          = {19},
    pages           = {153-160},
    url             = {https://papers.nips.cc/paper_files/paper/2006/hash/5da713a690c067105aeb2fae32403405-Abstract.html}
}

@inproceedings{Cottrell-Munro1988,
    author          = {Garrison W. Cottrell and Paul Munro},
    year            = {1988},
    title           = {Principal Component Analysis of Images via Back Propagation},
    booktitle       = {Proceedings of SPIE Visual Communications and Image Processings},
    volume          = {1001},
    pages           = {1070-1076},
    url             = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/1001/1/Principal-Components-Analysis-Of-Images-Via-Back-Propagation/10.1117/12.969060.short}
}

@article{Baldi-Hornik1989,
    author          = {Pierre Baldi and Kurt Hornik},
    year            = {1989},
    title           = {Neural Networks and Principal Component Analysis: Learning from Examples without Local Minima},
    journal         = {Neural Networks},
    volume          = {2},
    number          = {1},
    pages           = {53-58},
    url             = {https://www.sciencedirect.com/science/article/pii/0893608089900142}
}

@inproceedings{DeMers-Cottrell1992,
    author          = {David DeMers and Garrison Cottrell},
    year            = {1992},
    title           = {Non-Linear Dimensionality Reduction},
    booktitle       = {Advances in Neural Information Processing Systems},
    volume          = {5},
    pages           = {580-587},
    url             = {https://proceedings.neurips.cc/paper/1992/hash/cdc0d6e63aa8e41c89689f54970bb35f-Abstract.html}
}

@inproceedings{He+2016,
    author          = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
    year            = {2016},
    title           = {Deep Residual Learning for Image Recognition},
    booktitle       = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
    volume          = {},
    pages           = {770-778},
    url             = {https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html}
}

@inproceedings{Vaswani+2017,
    author          = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Łukasz Kaiser and Illia Polosukhin},
    year            = {2017},
    title           = {Attention is All you Need},
    booktitle       = {Advances in Neural Information Processing Systems},
    volume          = {30},
    pages           = {},
    url             = {https://papers.nips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html}
}

@inproceedings{Hecht-Nielsen1989,
    author          = {R. Hecht-Nielsen},
    year            = {1989},
    title           = {Theory of the Backpropagation Neural Network},
    booktitle       = {International 1989 Joint Conference on Neural Networks},
    volume          = {},
    pages           = {},
    url             = {https://ieeexplore.ieee.org/document/118638}
}

@article{Ballard1987,
    author          = {Dana H. Ballard},
    year            = {1987},
    title           = {Modular Learning in Neural Networks},
    journal         = {Proceedings of the Sixth National Conference on Artificial Intelligence},
    volume          = {1},
    number          = {},
    pages           = {279-284},
    url             = {https://dl.acm.org/doi/10.5555/1863696.1863746}
}

@article{Hinton+2006,
    author          = {Geoffrey E. Hinton and Simon Esindero and Yee-Whye Teh},
    year            = {2006},
    title           = {A Fast Learning Algorithm for Deep Belief Nets},
    journal         = {Naural Computation},
    volume          = {18},
    number          = {7},
    pages           = {1527-1554},
    url             = {https://direct.mit.edu/neco/article/18/7/1527/7065/A-Fast-Learning-Algorithm-for-Deep-Belief-Nets}
}

@article{Hopfield1982,
    author          = {J. J. Hopfield},
    year            = {1982},
    title           = {Neural Networks and Physical Systems with Emergent Collective Computational Abilities},
    journal         = {Proceedings of the National Academy of Science},
    volume          = {79},
    number          = {8},
    pages           = {2554-2558},
    url             = {https://www.pnas.org/doi/10.1073/pnas.79.8.2554}
}

@article{Hopfield-Tank1985,
    author          = {J. J. Hopfield and D. W. Tank},
    year            = {1985},
    title           = {"Neural" Computation of Decisions in Optimization Problems},
    journal         = {Biological Cybernetics},
    volume          = {52},
    number          = {},
    pages           = {141-152},
    url             = {https://link.springer.com/article/10.1007/BF00339943}
}

@article{Robbins-Monro1951,
    author          = {Herbert Robbins and Sutton Monro},
    year            = {1951},
    title           = {A Stochastic Approximation Method},
    journal         = {The Annals of Mathematical Statistics},
    volume          = {22},
    number          = {3},
    pages           = {400-407},
    url             = {https://www.jstor.org/stable/2236626}
}

@article{Kiefer-Wolfowitz1952,
    author          = {J. Kiefer and J. Wolfowitz},
    year            = {1952},
    title           = {Stochastic Estimation of the Maximum of a Regression Function},
    journal         = {The Annals of Mathematical Statistics},
    volume          = {22},
    number          = {3},
    pages           = {462-466},
    url             = {https://www.jstor.org/stable/2236690}
}

@inproceedings{Duchi+2011,
    author          = {John Duchi and Elad Hazan and Yoram Singer},
    year            = {2011},
    title           = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
    booktitle       = {Journal of Machine Learning Research},
    volume          = {12},
    number          = {61},
    pages           = {2121-2159},
    url             = {https://jmlr.org/papers/v12/duchi11a.html}
}

@unpublished{Tieleman-Hinton2012,
    author = {T. Tieleman and Geoffrey Hinton},
    year   = {2012},
    title  = {Neural Networks for Machine Learning. Lecture 6.5: Divide the Gradient by a Running Average of its Recent Magnitude},
    url    = {https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf}
}

@inproceedings{Nowozin+2016,
    author          = {Sebastian Nowozin and Botond Cseke and Ryota Tomioka},
    year            = {2016},
    title           = {f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization},
    booktitle       = {Advances in Neural Information Processing Systems},
    volume          = {29},
    pages           = {},
    url             = {https://papers.nips.cc/paper/2016/hash/cedebb6e872f539bef8c3f919874e9d7-Abstract.html}
}

@inproceedings{Arjovsky+2017,
    author          = {Martin Arjovsky and Soumith Chintala and Léon Bottou},
    year            = {2017},
    title           = {Wasserstein Generative Adversarial Networks},
    booktitle       = {Proceedings of the 34th International Conference on Machine Learning},
    volume          = {70},
    pages           = {214-223},
    url             = {http://proceedings.mlr.press/v70/arjovsky17a.html}
}

@inbook{Robert1996,
    author         = {C. P. Robert},
    chapter        = {Inference in Mixture Models},
    editor         = {W. R. Gilks and David Spiegelhalter},
    pages          = {441-464},
    publisher      = {Chapman \& Hall, London},
    title          = {Markov Chain Monte Carlo in Practice},
    year           = {1996}
}

@inproceedings{Mengersen-Robert1996,
    author          = {Kerrie L. Mengersen and Christian P. Robert},
    year            = {1996},
    title           = {Testing for Mixtures: A Bayesian Entropic Approach},
    booktitle       = {Bayesian Statistics 5: Proceedings of the Fifth Valencia International Meetings},
    pages           = {255-276},
    url             = {https://academic.oup.com/book/54042/chapter-abstract/422209682}
}

@article{Wei-Tanner1990,
    author          = {Greg C. G. Wei and Martin A. Tanner},
    year            = {1990},
    title           = {A Monte Carlo Implementation of the EM Algorithm and the Poor Man's Data Augmentation Algorithm},
    journal         = {Journal of the American Statistical Association},
    volume          = {85},
    number          = {411},
    pages           = {699-704},
    url             = {https://www.jstor.org/stable/2290005}
}

@article{Wei-Tanner1990b,
    author          = {Greg C. G. Wei and Martin A. Tanner},
    year            = {1990},
    title           = {Posterior Computations for Censored Regression Data},
    journal         = {Journal of the American Statistical Association},
    volume          = {85},
    number          = {411},
    pages           = {829-839},
    url             = {https://www.jstor.org/stable/2290022}
}

@article{Dieblot-Robert1994,
    author          = {Jean Diebolt and Christian P. Robert},
    year            = {1994},
    title           = {Estimation of Finite Mixture Distributions through Bayesian Sampling},
    journal         = {Journal of the Royal Statistical Society. Series B (Methodological)},
    volume          = {56},
    number          = {2},
    pages           = {363-375},
    url             = {https://www.jstor.org/stable/2345907}
}

@article{Lloyd1982,
    author          = {S. Lloyd},
    year            = {1982},
    title           = {Least Squares Quantization in PCM},
    journal         = {IEEE Transactions on Information Theory},
    volume          = {28},
    number          = {2},
    pages           = {129-137},
    url             = {https://ieeexplore.ieee.org/document/1056489}
}

@book{Fletcher1987,
    author         = {R. Fletcher},
    year           = {1987},
    title          = {Practical Methods of Optimization},
    series         = {},
    volume         = {},
    edition        = {2},
    url            = {https://onlinelibrary.wiley.com/doi/book/10.1002/9781118723203},
    publisher      = {John Wiley \& Sons}
}

@article{Meng-Rubin1993,
    author          = {Xiao-Li Meng and Donald B. Rubin},
    year            = {1993},
    title           = {Maximum Likelihood Estimation via the ECM Algorithm: A General Framework},
    journal         = {Biometrika},
    volume          = {80},
    number          = {2},
    pages           = {267-278},
    url             = {https://www.jstor.org/stable/2337198}
}

@book{Hrafnkelsson2023,
    author         = {},
    editor         = {Birgir Hrafnkelsson},
    year           = {2023},
    title          = {Statistical Modeling Using Bayesian Latent Gaussian Models: With Applications in Geophysics and Encironmental Sciences},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {https://link.springer.com/book/10.1007/978-3-031-39791-2},
    publisher      = {Springer Cham}
}

@inproceedings{MacQueen1967,
    author          = {J. MacQueen},
    year            = {1967},
    title           = {Some Methods for Classification and Analysis of Multivariate Observations},
    booktitle       = {Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability},
    volume          = {1},
    pages           = {281-297},
    url             = {https://projecteuclid.org/ebooks/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-Fifth-Berkeley-Symposium-on-Mathematical-Statistics-and/chapter/Some-methods-for-classification-and-analysis-of-multivariate-observations/bsmsp/1200512992}
}

@book{Kapur1989,
    author         = {J. N. Kapur},
    year           = {1989},
    title          = {Maximum-Entropy Models in Science and Engineering},
    series         = {},
    volume         = {},
    edition        = {2},
    url            = {},
    publisher      = {Wiley}
}

@inbook{Fenyman+1964,
    author         = {Richard P. Feynman and R. B. Leighton and M. Sands},
    chapter        = {19. The Principle of Least Action},
    volume         = {II},
    editor         = {},
    pages          = {},
    publisher      = {Addison-Wesley},
    title          = {The Feynman Lectures of Physics},
    year           = {1964},
    url            = {https://www.feynmanlectures.caltech.edu/II_19.html},
}

@book{Schwarz1988,
    author         = {H. R. Schwarz},
    year           = {1988},
    title          = {Finite Element Methods},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {},
    publisher      = {Academic Press}
}

@book{Boyd-Vandenberghe2004,
    author         = {Stephen Boyd and Lieven Vandenberghe},
    year           = {2004},
    title          = {Convex Optimization},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {https://www.cambridge.org/core/books/convex-optimization/E413CEF23D00BD463DCCE0600810D3FA},
    publisher      = {Cambridge University Press}
}

@inproceedings{Minka2001,
    author          = {Thomas P. Minka},
    year            = {2001},
    title           = {Expectation Propagation for Approximate Bayesian Inference},
    booktitle       = {Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence},
    volume          = {},
    pages           = {362-369},
    url             = {https://dl.acm.org/doi/10.5555/2074022.2074067}
}

@phdthesis{Minka2001b,
    author      = {Thomas P. Minka},
    school      = {MIT},
    title       = {A Family of Approximation Algorithms for Bayesian Inference},
    year        = {2001}
}

@article{Cichocki+2008,
    author          = {Andrzej Cichocki and Hyekyoung Lee and Yong-Deok Kim and Seungjin Choi},
    year            = {2008},
    title           = {Non-negative Matrix Factorization with $\alpha$-divergence},
    journal         = {Pattern Recognition Letters},
    volume          = {29},
    number          = {9},
    pages           = {1433-1440},
    url             = {https://www.sciencedirect.com/science/article/abs/pii/S0167865508000767}
}

@techreport{Minka2004,
    author      = {Tomas P. Minka},
    institution = {Microsoft Research Cambridge},
    title       = {Power EP},
    year        = {2004},
    url         = {https://www.microsoft.com/en-us/research/publication/power-ep/},
}

@techreport{Minka2005,
    author      = {Tomas P. Minka},
    institution = {Microsoft Research Cambridge},
    title       = {Divergence Measures and Message Passing},
    year        = {2005},
    url         = {https://www.microsoft.com/en-us/research/publication/divergence-measures-and-message-passing/},
}

@techreport{Brooks+2024,
    author      = {Tim Brooks and Bill Peebles and Connor Holmes and Will DePue and Yufei Guo and Li Jing and David Schnurr and Joe Taylor and Troy Luhman and Eric Luhman and Clarence Wing Yin Ng and Ricky Wang and Aditya Ramesh},
    institution = {OpenAI},
    title       = {Video generation models as world simulators},
    year        = {2024},
    url         = {https://openai.com/research/video-generation-models-as-world-simulators},
}

@inproceedings{Razavi+2019,
    author          = {Ali Razavi and Aaron van{\ }den{\ }Oord and Oriol Vinyals},
    year            = {2019},
    title           = {Generating Diverse High-Fidelity Images with VQ-VAE-2},
    booktitle       = {Advances in Neural Information Processing Systems},
    volume          = {32},
    pages           = {},
    url             = {https://papers.nips.cc/paper_files/paper/2019/hash/5f8e2fa1718d1bbcadf1cd9c7a54fb8c-Abstract.html}
}

@inproceedings{vandenOord+2017,
    author          = {Aaron van{\ }den{\ }Oord and Oriol Vinyals and Koray Kavukcuoglu},
    year            = {2017},
    title           = {Neural Discrete Representation Learning},
    booktitle       = {Advances in Neural Information Processing Systems},
    volume          = {30},
    pages           = {},
    url             = {https://papers.nips.cc/paper_files/paper/2017/hash/7a98af17e63a0ac09ce2e96d03992fbc-Abstract.html}
}

@inproceedings{Wallace1992,
    author          = {G. K. Wallace},
    year            = {1992},
    title           = {The JPEG Still Picture Compression Standard},
    booktitle       = {IEEE Transactions on Consumer Electronics},
    volume          = {38},
    pages           = {1},
    url             = {https://ieeexplore.ieee.org/document/125072}
}

@inproceedings{Paisley+2012,
    author          = {John Paisley and David M. Blei and Michael I. Jordan},
    year            = {2012},
    title           = {Variational Bayesian Inference with Stochastic Search},
    booktitle       = {Proceedings of the 29th International Conference on Machine Learning},
    volume          = {},
    pages           = {1363-1370},
    url             = {https://dl.acm.org/doi/10.5555/3042573.3042748}
}

@inbook{Diebolt-Ip1996,
    author         = {J. Diebolt and E. Ip},
    chapter        = {Stochastic EM: Method and Application},
    editor         = {W. R. Gilks and S. Richardson and David Spiegelhalter},
    pages          = {259-274},
    publisher      = {Chapman and Hall},
    title          = {Markov Chain Monte Carlo in Practice},
    year           = {1996},
    url            = {https://www.taylorfrancis.com/books/mono/10.1201/b14835/markov-chain-monte-carlo-practice-david-spiegelhalter-gilks-richardson},
}

@article{Celeux-Diebolt1985,
    author          = {G. Celeux and J. Diebolt},
    year            = {1985},
    title           = {The SEM Algorithm: A Probabilistic Teacher Algorithm Derived from the EM Algorithm for the Mixture Problem},
    journal         = {Computational Statistics Quarterly},
    volume          = {2},
    number          = {},
    pages           = {73-82},
    url             = {}
}

@article{Meng-Rubin1991,
    author          = {Xiao-Li Meng and Donald B. Rubin},
    year            = {1991},
    title           = {Using EM to Obtain Asymptotic Variance-Covariance Matrices: The SEM Algorithm},
    journal         = {Journal of the American Statistical Association},
    volume          = {86},
    number          = {416},
    pages           = {899-909},
    url             = {https://www.jstor.org/stable/2290503}
}

@article{Doucet+2002,
    author          = {Arnaud Doucet and Simon J. Godsill and Christian P. Robert},
    year            = {2002},
    title           = {Marginal Maximum a Posteriori Estimation using Markov Chain Monte Carlo},
    journal         = {Statistics and Computing},
    volume          = {12},
    number          = {},
    pages           = {77-84},
    url             = {https://link.springer.com/article/10.1023/A:1013172322619}
}

@book{Bouleau-Lepingle1993,
    author         = {Nicolas Bouleau and Dominique Lépingle},
    year           = {1993},
    title          = {Numerical Methods for Stochastic Processes},
    series         = {},
    volume         = {},
    edition        = {},
    url            = {https://www.wiley.com/en-ca/Numerical+Methods+for+Stochastic+Processes-p-9780471546412},
    publisher      = {Wiley}
}

@inbook{Geyer1996,
    author         = {C. Geyer},
    chapter        = {Estimation and Optimization of Functions},
    editor         = {W. R. Gilks and S. Richardson and David Spiegelhalter},
    pages          = {241-258},
    publisher      = {Chapman and Hall},
    title          = {Markov Chain Monte Carlo in Practice},
    year           = {1996},
    url            = {https://www.taylorfrancis.com/books/mono/10.1201/b14835/markov-chain-monte-carlo-practice-david-spiegelhalter-gilks-richardson},
}

@unpublished{Radford+2019,
    author = {Alec Radford and Jeffrey Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
    year   = {2019},
    title  = {Language Models are Unsupervised Multitask Learners},
    url    = {https://github.com/openai/gpt-2?tab=readme-ov-file}
}

@inproceedings{Brown+2020,
    author          = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
    year            = {2020},
    title           = {Language Models are Few-Shot Learners},
    booktitle       = {Advances in Neural Information Processing Systems},
    volume          = {33},
    pages           = {1877-1901},
    url             = {https://papers.nips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html}
}

@unpublished{OpenAI2023,
    author = {OpenAI},
    year   = {2023},
    title  = {GPT-4 Technical Report},
    url    = {https://arxiv.org/abs/2303.08774}
}

@unpublished{Sutton2019,
    author = {Rich Sutton},
    year   = {2019},
    title  = {The Bitter Lesson},
    url    = {http://www.incompleteideas.net/IncIdeas/BitterLesson.html}
}

@unpublished{Kaplan+2020,
author       = {Jared Kaplan and
                  Sam McCandlish and
                  Tom Henighan and
                  Tom B. Brown and
                  Benjamin Chess and
                  Rewon Child and
                  Scott Gray and
                  Alec Radford and
                  Jeffrey Wu and
                  Dario Amodei},
    year   = {2020},
    title  = {Scaling Laws for Neural Language Models},
    url    = {https://arxiv.org/abs/2001.08361}
}

@article{Bommasani+2021,
title={On the Opportunities and Risks of Foundation Models},
author={Rishi Bommasani and Drew A. Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S. Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and S. Buch and Dallas Card and Rodrigo Castellon and Niladri S. Chatterji and Annie S. Chen and Kathleen A. Creel and Jared Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren E. Gillespie and Karan Goel and Noah D. Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E. Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas F. Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and O. Khattab and Pang Wei Koh and Mark S. Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D. Manning and Suvir P. Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Benjamin Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and J. F. Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Robert Reich and Hongyu Ren and Frieda Rong and Yusuf H. Roohani and Camilo Ruiz and Jack Ryan and Christopher R'e and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishna Parasuram Srinivasan and Alex Tamkin and Rohan Taori and Armin W. Thomas and Florian Tram{\`e}r and Rose E. Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei A. Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang},
journal={ArXiv},
year={2021},
url={https://crfm.stanford.edu/report.html}
}

@unpublished{Hu+2021,
  author       = {Edward J. Hu and
                  Yelong Shen and
                  Phillip Wallis and
                  Zeyuan Allen{-}Zhu and
                  Yuanzhi Li and
                  Shean Wang and
                  Weizhu Chen},
    year   = {2021},
    title  = {LoRA: Low-Rank Adaptation of Large Language Models},
    url    = {https://arxiv.org/abs/2106.09685}
}

@inproceedings{Aghajanyan+2021,
    author          = {Armen Aghajanyan and Sonal Gupta and Luke Zettlemoyer},
    year            = {2021},
    title           = {Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning},
    booktitle       = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing},
    volume          = {1},
    pages           = {7319-7328},
    url             = {https://aclanthology.org/2021.acl-long.568/}
}

@inproceedings{Christiano+2017,
    author          = {Paul F. Christiano and Jan Leike and Tom Brown and Miljan Martic and Shane Legg and Dario Amodei},
    year            = {2017},
    title           = {Deep Reinforcement Learning from Human Preferences},
    booktitle       = {Advances in Neural Information Processing Systems},
    volume          = {30},
    pages           = {},
    url             = {https://papers.nips.cc/paper_files/paper/2017/hash/d5e2c0adad503c91f91df240d0cd4e49-Abstract.html}
}

@article{Liu+2023,
    author          = {Pengfei Liu and Weizhe Yuan and Jinlan Fu and Zhengbao Jiang and Hiroaki Hayashi and Graham Neubig},
    year            = {2023},
    title           = {Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing},
    journal         = {ACM Computing Surveys},
    volume          = {55},
    number          = {9},
    pages           = {1-35},
    url             = {https://dl.acm.org/doi/full/10.1145/3560815}
}

@unpublished{Bubeck+2023,
      author={Sébastien Bubeck and Varun Chandrasekaran and Ronen Eldan and Johannes Gehrke and Eric Horvitz and Ece Kamar and Peter Lee and Yin Tat Lee and Yuanzhi Li and Scott Lundberg and Harsha Nori and Hamid Palangi and Marco Tulio Ribeiro and Yi Zhang},
    year   = {2023},
    title  = {Sparks of Artificial General Intelligence: Early Experiments with GPT-4},
    url    = {https://arxiv.org/abs/2303.12712}
}

@unpublished{Bahdanau+2015,
    author = {Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
    year   = {2015},
    title  = {Neural Machine Translation by Jointly Learning to Align and Translate},
    url    = {https://arxiv.org/abs/1409.0473}
}

@unpublished{Ba+2016,
    author = {Jimmy Lei Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
    year   = {2016},
    title  = {Layer Normalization},
    url    = {https://arxiv.org/abs/1607.06450}
}

@unpublished{Dufter+2021,
    author = {Philipp Dufter and Martin Schmitt and Hinrich Schütze},
    year   = {2021},
    title  = {Position Information in Transformers: An Overview},
    url    = {https://arxiv.org/abs/2102.11090}
}

@unpublished{Mikolov2013,
    author = {Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
    year   = {2013},
    title  = {Efficient Estimation of Word Representations in Vector Space},
    url    = {https://arxiv.org/abs/1301.3781}
}

@inproceedings{Bengio+2000,
    author          = {Yoshua Bengio and Réjean Ducharme and Pascal Vincent},
    year            = {2000},
    title           = {A Neural Probabilistic Language Model},
    booktitle       = {Advances in Neural Information Processing Systems},
    volume          = {13},
    pages           = {},
    url             = {https://papers.nips.cc/paper_files/paper/2000/hash/728f206c2a01bf572b5940d7d9a8fa4c-Abstract.html}
}

@inproceedings{Sennrich+2016,
    author          = {Rico Sennrich and Barry Haddow and Alexandra Birch},
    year            = {2016},
    title           = {Neural Machine Translation of Rare Words with Subword Units},
    booktitle       = {Proceedings of the 54th Annual Meetings of the Association for Computational Linguistics},
    volume          = {1},
    pages           = {1715-1725},
    url             = {https://aclanthology.org/P16-1162/}
}

@unpublished{Zhao+2023,
          author={Wayne Xin Zhao and Kun Zhou and Junyi Li and Tianyi Tang and Xiaolei Wang and Yupeng Hou and Yingqian Min and Beichen Zhang and Junjie Zhang and Zican Dong and Yifan Du and Chen Yang and Yushuo Chen and Zhipeng Chen and Jinhao Jiang and Ruiyang Ren and Yifan Li and Xinyu Tang and Zikang Liu and Peiyu Liu and Jian-Yun Nie and Ji-Rong Wen},
    year   = {2023},
    title  = {A Survey of Large Language Models},
    url    = {https://arxiv.org/abs/2303.18223}
}

@inproceedings{Devlin+2019,
    author          = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
    year            = {2019},
    title           = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    booktitle       = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human language Technologies},
    volume          = {1},
    pages           = {4171-4186},
    url             = {https://aclanthology.org/N19-1423/}
}

@inproceedings{Holtzman+2020,
    author          = {Ari Holtzman and Jan Buys and Li Du and Maxwell Forbes and Yejin Choi},
    year            = {2020},
    title           = {The Curious Case of Neural Text Degeneration},
    booktitle       = {International Conference on Learning Representation},
    volume          = {},
    pages           = {},
    url             = {https://arxiv.org/abs/1904.09751}
}

@inproceedings{Mikolov+2010,
    author          = {T. Mikolov and J. Kopecky and L. Burget and J. \u{C}ernocky and S. Khudanpur},
    year            = {2010},
    title           = {Recurrent Neural Network Based Language Model},
    booktitle       = {Proceedings of Interspeech},
    volume          = {},
    pages           = {},
    url             = {http://www.fit.vutbr.cz/research/groups/speech/servite/2010/rnnlm_mikolov.pdf}
}

@article{Hochreiter-Schmidhuber1997,
    author          = {Sepp Hochreiter and Jürgen Schmidhuber},
    year            = {1997},
    title           = {Long Short-Time Memory},
    journal         = {Neural Computation},
    volume          = {9},
    number          = {8},
    pages           = {1735-1780},
    url             = {https://direct.mit.edu/neco/article-abstract/9/8/1735/6109/Long-Short-Term-Memory?redirectedFrom=fulltext}
}

@inproceedings{Cho+2014,
    title = "Learning Phrase Representations using {RNN} Encoder{--}Decoder for Statistical Machine Translation",
    author = {Cho, Kyunghyun  and
      van Merri{\"e}nboer, Bart  and
      Gulcehre, Caglar  and
      Bahdanau, Dzmitry  and
      Bougares, Fethi  and
      Schwenk, Holger  and
      Bengio, Yoshua},
    editor = "Moschitti, Alessandro  and
      Pang, Bo  and
      Daelemans, Walter",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1179",
    doi = "10.3115/v1/D14-1179",
    pages = "1724--1734",
    url             = {https://aclanthology.org/D14-1179/},
}

@inproceedings{Dosovitskiy+2021,
    author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
    year            = {2021},
    title           = {An Image is Worth 16×16 Words: Transformers for Image Recognition at Scale},
    booktitle       = {International Conference on Learning Representations},
    volume          = {},
    pages           = {},
    url             = {https://openreview.net/forum?id=YicbFdNTTy}
}

@inproceedings{Radford+2023,
author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
title = {Robust speech recognition via large-scale weak supervision},
year = {2023},
publisher = {JMLR.org},
abstract = {We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet. When scaled to 680,000 hours of multilingual and multitask supervision, the resulting models generalize well to standard benchmarks and are often competitive with prior fully supervised results without the need for any dataset specific fine-tuning. When compared to humans, the models approach their accuracy and robustness. We are releasing models and inference code to serve as a foundation for further work on robust speech processing.},
booktitle = {Proceedings of the 40th International Conference on Machine Learning},
articleno = {1182},
numpages = {27},
location = {Honolulu, Hawaii, USA},
series = {ICML'23},
url             = {https://dl.acm.org/doi/10.5555/3618408.3619590},
}

@inproceedings{Ioffe-Szegedy2015,
author = {Ioffe, Sergey and Szegedy, Christian},
title = {Batch normalization: accelerating deep network training by reducing internal covariate shift},
year = {2015},
publisher = {JMLR.org},
abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82\% top-5 test error, exceeding the accuracy of human raters.},
booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
pages = {448–456},
numpages = {9},
location = {Lille, France},
series = {ICML'15},
url             = {https://dl.acm.org/doi/10.5555/3045118.3045167},
}

@inproceedings{Bjorck+2018,
    author          = {Bjorck, Nils and Gomes, Carla P and Selman, Bart and Weinberger, Kilian Q},
    year            = {2018},
    title           = {Understanding Batch Normalization},
    booktitle       = {Advances in Neural Information Processing Systems},
    volume          = {31},
    pages           = {},
    url             = {https://papers.nips.cc/paper_files/paper/2018/hash/36072923bfc3cf47745d704feb489480-Abstract.html}
}

@inbook{LeCun+2012,
    author         = {Yann A. LeCun and Léon Bottou and Genevieve B. Orr and Klaus-Robert Müller},
    chapter        = {Efficient BackProp},
    editor         = {Grégoire Montavon and Geneviéve B. Orr and Klaus-Robert Müller},
    pages          = {9-48},
    publisher      = {Springer Berlin, Heidelberg},
    title          = {Neural Networks: Tricks of the Trade},
    year           = {2012},
    edition        = {2},
    url            = {https://link.springer.com/book/10.1007/978-3-642-35289-8},
}

@inproceedings{Lepikhin+2021,
      author       = {Dmitry Lepikhin and
                  HyoukJoong Lee and
                  Yuanzhong Xu and
                  Dehao Chen and
                  Orhan Firat and
                  Yanping Huang and
                  Maxim Krikun and
                  Noam Shazeer and
                  Zhifeng Chen},
    year            = {2021},
    title           = {GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding},
    booktitle       = {International Conference on Learning Representation},
    volume          = {},
    pages           = {},
    url             = {https://openreview.net/forum?id=qrwe7XHTmYb}
}

@article{Fedus+2022,
    author          = {William Fedus and Barret Zoph and Noam Shazeer},
    year            = {2022},
    title           = {Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity},
    journal         = {The Journal of Machine Learning Research},
    volume          = {23},
    number          = {120},
    pages           = {1-39},
    url             = {https://jmlr.org/papers/v23/21-0998.html}
}

@techreport{Rae+2021,
    author       = {Jack W. Rae and
                  Sebastian Borgeaud and
                  Trevor Cai and
                  Katie Millican and
                  Jordan Hoffmann and
                  H. Francis Song and
                  John Aslanides and
                  Sarah Henderson and
                  Roman Ring and
                  Susannah Young and
                  Eliza Rutherford and
                  Tom Hennigan and
                  Jacob Menick and
                  Albin Cassirer and
                  Richard Powell and
                  George van den Driessche and
                  Lisa Anne Hendricks and
                  Maribeth Rauh and
                  Po{-}Sen Huang and
                  Amelia Glaese and
                  Johannes Welbl and
                  Sumanth Dathathri and
                  Saffron Huang and
                  Jonathan Uesato and
                  John Mellor and
                  Irina Higgins and
                  Antonia Creswell and
                  Nat McAleese and
                  Amy Wu and
                  Erich Elsen and
                  Siddhant M. Jayakumar and
                  Elena Buchatskaya and
                  David Budden and
                  Esme Sutherland and
                  Karen Simonyan and
                  Michela Paganini and
                  Laurent Sifre and
                  Lena Martens and
                  Xiang Lorraine Li and
                  Adhiguna Kuncoro and
                  Aida Nematzadeh and
                  Elena Gribovskaya and
                  Domenic Donato and
                  Angeliki Lazaridou and
                  Arthur Mensch and
                  Jean{-}Baptiste Lespiau and
                  Maria Tsimpoukelli and
                  Nikolai Grigorev and
                  Doug Fritz and
                  Thibault Sottiaux and
                  Mantas Pajarskas and
                  Toby Pohlen and
                  Zhitao Gong and
                  Daniel Toyama and
                  Cyprien de Masson d'Autume and
                  Yujia Li and
                  Tayfun Terzi and
                  Vladimir Mikulik and
                  Igor Babuschkin and
                  Aidan Clark and
                  Diego de Las Casas and
                  Aurelia Guy and
                  Chris Jones and
                  James Bradbury and
                  Matthew J. Johnson and
                  Blake A. Hechtman and
                  Laura Weidinger and
                  Iason Gabriel and
                  William Isaac and
                  Edward Lockhart and
                  Simon Osindero and
                  Laura Rimell and
                  Chris Dyer and
                  Oriol Vinyals and
                  Kareem Ayoub and
                  Jeff Stanway and
                  Lorrayne Bennett and
                  Demis Hassabis and
                  Koray Kavukcuoglu and
                  Geoffrey Irving},
    institution = {Google DeepMind},
    title       = {Scaling Language Models: Methods, Analysis & Insights from Training Gopher},
    year        = {2021},
    url         = {https://arxiv.org/abs/2112.11446},
}

@techreport{Radford+2018,
    author      = {Alec Radford and Karthik narasimhan and Tim Salimans and Ilya Sutskever},
    institution = {OpenAI},
    title       = {Improving Language Understanding with Unsupervised Learning},
    year        = {2018},
    url         = {https://openai.com/research/language-unsupervised},
}

@article{vandenOord+2016,
    author          = {Aäron van{\ }den{\ }Oord and Nal Kalchbrenner and Koray Kavukcuoglu},
    year            = {2016},
    title           = {Pixel Recurrent Neural Networks},
    journal         = {Proceedings of the 33rd International Conference on Machine Learning},
    volume          = {},
    number          = {},
    pages           = {},
    url             = {https://proceedings.mlr.press/v48/oord16.html}
}

@inproceedings{vandenOord+2016b,
author = {A\"{a}ron van{\ }den{\ }Oord and Kalchbrenner, Nal and Vinyals, Oriol and Espeholt, Lasse and Graves, Alex and Kavukcuoglu, Koray},
title = {Conditional image generation with PixelCNN decoders},
year = {2016},
isbn = {9781510838819},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {This work explores conditional image generation with a new image density model based on the PixelCNN architecture. The model can be conditioned on any vector, including descriptive labels or tags, or latent embeddings created by other networks. When conditioned on class labels from the ImageNet database, the model is able to generate diverse, realistic scenes representing distinct animals, objects, landscapes and structures. When conditioned on an embedding produced by a convolutional network given a single image of an unseen face, it generates a variety of new portraits of the same person with different facial expressions, poses and lighting conditions. We also show that conditional PixelCNN can serve as a powerful decoder in an image autoencoder. Additionally, the gated convolutional layers in the proposed model improve the log-likelihood of PixelCNN to match the state-of-the-art performance of PixelRNN on ImageNet, with greatly reduced computational cost.},
booktitle = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
pages = {4797–4805},
numpages = {9},
location = {Barcelona, Spain},
series = {NIPS'16},
url             = {https://dl.acm.org/doi/10.5555/3157382.3157633},
}

@inproceedings{Chen+2020,
    author          = {Mark Chen and Alec Radford and Rewon Child and Jeffrey Wu and Heewoo Jun and David Luan and Ilya Sutskever},
    year            = {2020},
    title           = {Generative Pretraining from Pixels},
    booktitle       = {Proceedings of the 37th International Conference on Machine Learning},
    volume          = {},
    pages           = {},
    url             = {https://proceedings.mlr.press/v119/chen20s.html}
}

@misc{Rakhimov+2020,
      title={Latent Video Transformer}, 
      author={Ruslan Rakhimov and Denis Volkhonskiy and Alexey Artemov and Denis Zorin and Evgeny Burnaev},
      year={2020},
    url          = {https://arxiv.org/abs/2006.10704},
}

@unpublished{Yan+2021,
  author       = {Wilson Yan and
                  Yunzhi Zhang and
                  Pieter Abbeel and
                  Aravind Srinivas},
    year   = {2021},
    title  = {VideoGPT: Video Generation using VQ-VAE and Transformers},
    url    = {https://arxiv.org/abs/2104.10157}
}

@inproceedings{Micheli+2023,
    author          = {Vincent Micheli and Eloi Alonso and François Fleuret},
    year            = {2023},
    title           = {Transformers are Sample-Efficient World Models},
    booktitle       = {International Conference on Learning Representation},
    volume          = {},
    pages           = {},
    url             = {https://openreview.net/forum?id=vhFu1Acb0xb}
}

@inproceedings{Ha-Schmidthuber2018,
    author          = {David Ha and Jürgen Schmidhuber},
    year            = {2018},
    title           = {Recurrent World Models Facilitate Policy Evaluation},
    booktitle       = {Advances in Neural Information Processing Systems},
    volume          = {31},
    pages           = {},
    url             = {https://papers.nips.cc/paper_files/paper/2018/hash/2de5d16682c3c35007e4e92982f1a2ba-Abstract.html}
}

@inproceedings{Racaniere+2017,
author = {Racani\`{e}re, S\'{e}bastien and Weber, Th\'{e}ophane and Reichert, David P. and Buesing, Lars and Guez, Arthur and Rezende, Danilo and Badia, Adria Puigdom\`{e}nech and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and Pascanu, Razvan and Battaglia, Peter and Hassabis, Demis and Silver, David and Wierstra, Daan},
title = {Imagination-augmented agents for deep reinforcement learning},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We introduce Imagination-Augmented Agents (I2As), a novel architecture for deep reinforcement learning combining model-free and model-based aspects. In contrast to most existing model-based reinforcement learning and planning methods, which prescribe how a model should be used to arrive at a policy, I2As learn to interpret predictions from a learned environment model to construct implicit plans in arbitrary ways, by using the predictions as additional context in deep policy networks. I2As show improved data efficiency, performance, and robustness to model misspecification compared to several baselines.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {5694–5705},
numpages = {12},
location = {Long Beach, California, USA},
series = {NIPS'17},
url             = {https://dl.acm.org/doi/10.5555/3295222.3295320},
}

@inproceedings{Kaiser+2020,
title={Model Based Reinforcement Learning for Atari},
author={Łukasz Kaiser and Mohammad Babaeizadeh and Piotr Miłos and Błażej Osiński and Roy H Campbell and Konrad Czechowski and Dumitru Erhan and Chelsea Finn and Piotr Kozakowski and Sergey Levine and Afroz Mohiuddin and Ryan Sepassi and George Tucker and Henryk Michalewski},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=S1xCPJHtDB}
}

@inproceedings{Hafner+2021,
title={Mastering Atari with Discrete World Models},
author={Danijar Hafner and Timothy P Lillicrap and Mohammad Norouzi and Jimmy Ba},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=0oabwyZbOu}
}

@article{Raffel+2020,
author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
title = {Exploring the limits of transfer learning with a unified text-to-text transformer},
year = {2020},
issue_date = {January 2020},
publisher = {JMLR.org},
volume = {21},
number = {1},
issn = {1532-4435},
abstract = {Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pretraining objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new "Colossal Clean Crawled Corpus", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.},
journal = {J. Mach. Learn. Res.},
month = {jan},
articleno = {140},
numpages = {67},
keywords = {deep learning, attention based models, multi-task learning, natural language processing, transfer learning}
}


@inproceedings{Chang+2023,
  title = 	 {Muse: Text-To-Image Generation via Masked Generative Transformers},
  author =       {Chang, Huiwen and Zhang, Han and Barber, Jarred and Maschinot, Aaron and Lezama, Jose and Jiang, Lu and Yang, Ming-Hsuan and Murphy, Kevin Patrick and Freeman, William T. and Rubinstein, Michael and Li, Yuanzhen and Krishnan, Dilip},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {4055--4075},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/chang23b/chang23b.pdf},
  url = 	 {https://proceedings.mlr.press/v202/chang23b.html},
  abstract = 	 {We present Muse, a text-to-image Transformermodel that achieves state-of-the-art image genera-tion performance while being significantly moreefficient than diffusion or autoregressive models.Muse is trained on a masked modeling task indiscrete token space: given the text embeddingextracted from a pre-trained large language model(LLM), Muse learns to predict randomly maskedimage tokens. Compared to pixel-space diffusionmodels, such as Imagen and DALL-E 2, Muse issignificantly more efficient due to the use of dis-crete tokens and requires fewer sampling itera-tions; compared to autoregressive models such asParti, Muse is more efficient due to the use of par-allel decoding. The use of a pre-trained LLM en-ables fine-grained language understanding, whichtranslates to high-fidelity image generation andthe understanding of visual concepts such as ob-jects, their spatial relationships, pose, cardinalityetc. Our 900M parameter model achieves a newSOTA on CC3M, with an FID score of 6.06. TheMuse 3B parameter model achieves an FID of7.88 on zero-shot COCO evaluation, along with aCLIP score of 0.32. Muse also directly enables anumber of image editing applications without theneed to fine-tune or invert the model: inpainting,outpainting, and mask-free editing. More resultsand videos demonstrating editing are available at https://muse-icml.github.io/}
}


@inproceedings{Ramesh+2021,
  title = 	 {Zero-Shot Text-to-Image Generation},
  author =       {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {8821--8831},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/ramesh21a/ramesh21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/ramesh21a.html},
  abstract = 	 {Text-to-image generation has traditionally focused on finding better modeling assumptions for training on a fixed dataset. These assumptions might involve complex architectures, auxiliary losses, or side information such as object part labels or segmentation masks supplied during training. We describe a simple approach for this task based on a transformer that autoregressively models the text and image tokens as a single stream of data. With sufficient data and scale, our approach is competitive with previous domain-specific models when evaluated in a zero-shot fashion.}
}

@misc{Dhariwal+2020,
      title={Jukebox: A Generative Model for Music}, 
      author={Prafulla Dhariwal and Heewoo Jun and Christine Payne and Jong Wook Kim and Alec Radford and Ilya Sutskever},
      year={2020},
      eprint={2005.00341},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url          = {https://arxiv.org/abs/2005.00341},
}

@misc{Child+2019,
      title={Generating Long Sequences with Sparse Transformers}, 
      author={Rewon Child and Scott Gray and Alec Radford and Ilya Sutskever},
      year={2019},
      eprint={1904.10509},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url          = {https://arxiv.org/abs/1904.10509},
}

@inproceedings{Lewis+2020,
    author          = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K\"{u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt\"{a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
    year            = {2020},
    title           = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
    booktitle       = {Advances in Neural Information Processing Systems},
    volume          = {33},
    pages           = {9459-9474},
    url             = {https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html}
}

@inproceedings{Petroni+2019,
    title = "Language Models as Knowledge Bases?",
    author = {Petroni, Fabio  and
      Rockt{\"a}schel, Tim  and
      Riedel, Sebastian  and
      Lewis, Patrick  and
      Bakhtin, Anton  and
      Wu, Yuxiang  and
      Miller, Alexander},
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1250",
    doi = "10.18653/v1/D19-1250",
    pages = "2463--2473",
    abstract = "Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as {``}fill-in-the-blank{''} cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at \url{https://github.com/facebookresearch/LAMA}.",
}

@inproceedings{Roberts+2020,
    title = "How Much Knowledge Can You Pack Into the Parameters of a Language Model?",
    author = "Roberts, Adam  and
      Raffel, Colin  and
      Shazeer, Noam",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.437",
    doi = "10.18653/v1/2020.emnlp-main.437",
    pages = "5418--5426",
    abstract = "It has recently been observed that neural language models trained on unstructured text can implicitly store and retrieve knowledge using natural language queries. In this short paper, we measure the practical utility of this approach by fine-tuning pre-trained models to answer questions without access to any external context or knowledge. We show that this approach scales with model size and performs competitively with open-domain systems that explicitly retrieve answers from an external knowledge source when answering questions. To facilitate reproducibility and future work, we release our code and trained models.",
}

@misc{Marcus2020,
      title={The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence}, 
      author={Gary Marcus},
      year={2020},
      eprint={2002.06177},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url          = {https://arxiv.org/abs/2002.06177},
}

@misc{Aghajanyan+2022,
      title={CM3: A Causal Masked Multimodal Model of the Internet}, 
      author={Armen Aghajanyan and Bernie Huang and Candace Ross and Vladimir Karpukhin and Hu Xu and Naman Goyal and Dmytro Okhonko and Mandar Joshi and Gargi Ghosh and Mike Lewis and Luke Zettlemoyer},
      year={2022},
      eprint={2201.07520},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url          = {https://arxiv.org/abs/2201.07520},
}

@misc{Alayrac+2022,
      title={Flamingo: a Visual Language Model for Few-Shot Learning}, 
      author={Jean-Baptiste Alayrac and Jeff Donahue and Pauline Luc and Antoine Miech and Iain Barr and Yana Hasson and Karel Lenc and Arthur Mensch and Katie Millican and Malcolm Reynolds and Roman Ring and Eliza Rutherford and Serkan Cabi and Tengda Han and Zhitao Gong and Sina Samangooei and Marianne Monteiro and Jacob Menick and Sebastian Borgeaud and Andrew Brock and Aida Nematzadeh and Sahand Sharifzadeh and Mikolaj Binkowski and Ricardo Barreira and Oriol Vinyals and Andrew Zisserman and Karen Simonyan},
      year={2022},
      eprint={2204.14198},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url          = {https://arxiv.org/abs/2204.14198},
}

@misc{Chowdhery+2022,
      title={PaLM: Scaling Language Modeling with Pathways}, 
      author={Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Ben Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garcia and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark Diaz and Orhan Firat and Michele Catasta and Jason Wei and Kathy Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},
      year={2022},
      eprint={2204.02311},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url          = {https://arxiv.org/abs/2204.02311},
}

@article{Yu+2022,
title={Scaling Autoregressive Models for Content-Rich Text-to-Image Generation},
author={Jiahui Yu and Yuanzhong Xu and Jing Yu Koh and Thang Luong and Gunjan Baid and Zirui Wang and Vijay Vasudevan and Alexander Ku and Yinfei Yang and Burcu Karagol Ayan and Ben Hutchinson and Wei Han and Zarana Parekh and Xin Li and Han Zhang and Jason Baldridge and Yonghui Wu},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2022},
url={https://openreview.net/forum?id=AFDcYJKhND},
note={Featured Certification}
}

@inproceedings{Karpukhin+2020,
    title = "Dense Passage Retrieval for Open-Domain Question Answering",
    author = "Karpukhin, Vladimir  and
      Oguz, Barlas  and
      Min, Sewon  and
      Lewis, Patrick  and
      Wu, Ledell  and
      Edunov, Sergey  and
      Chen, Danqi  and
      Yih, Wen-tau",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.550",
    doi = "10.18653/v1/2020.emnlp-main.550",
    pages = "6769--6781",
    abstract = "Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dual-encoder framework. When evaluated on a wide range of open-domain QA datasets, our dense retriever outperforms a strong Lucene-BM25 system greatly by 9{\%}-19{\%} absolute in terms of top-20 passage retrieval accuracy, and helps our end-to-end QA system establish new state-of-the-art on multiple open-domain QA benchmarks.",
}


@inproceedings{Radford+2021,
  title = 	 {Learning Transferable Visual Models From Natural Language Supervision},
  author =       {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {8748--8763},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/radford21a/radford21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/radford21a.html},
  abstract = 	 {State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on.}
}

@misc{Touvron+2023,
      title={LLaMA: Open and Efficient Foundation Language Models}, 
      author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
      year={2023},
      eprint={2302.13971},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url          = {https://arxiv.org/abs/2302.13971},
}

@inproceedings{Wang+2023,
    title = "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
    author = "Wang, Yizhong  and
      Kordi, Yeganeh  and
      Mishra, Swaroop  and
      Liu, Alisa  and
      Smith, Noah A.  and
      Khashabi, Daniel  and
      Hajishirzi, Hannaneh",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.754",
    doi = "10.18653/v1/2023.acl-long.754",
    pages = "13484--13508",
    abstract = "Large {``}instruction-tuned{''} language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks. Nevertheless, they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model. We introduce Self-Instruct, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations. Our pipeline generates instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model. Applying our method to the vanilla GPT3, we demonstrate a 33{\%} absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT-001, which was trained with private user data and human annotations. For further evaluation, we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with Self-Instruct outperforms using existing public instruction datasets by a large margin, leaving only a 5{\%} absolute gap behind InstructGPT-001. Self-Instruct provides an almost annotation-free method for aligning pre-trained language models with instructions, and we release our large synthetic dataset to facilitate future studies on instruction tuning.",
}

@inproceedings{Lewis+2020-BART,
    title = "{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
    author = "Lewis, Mike  and
      Liu, Yinhan  and
      Goyal, Naman  and
      Ghazvininejad, Marjan  and
      Mohamed, Abdelrahman  and
      Levy, Omer  and
      Stoyanov, Veselin  and
      Zettlemoyer, Luke",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.703",
    doi = "10.18653/v1/2020.acl-main.703",
    pages = "7871--7880",
    abstract = "We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance.",
}


@inproceedings{Yasunaga+2023,
  title = 	 {Retrieval-Augmented Multimodal Language Modeling},
  author =       {Yasunaga, Michihiro and Aghajanyan, Armen and Shi, Weijia and James, Richard and Leskovec, Jure and Liang, Percy and Lewis, Mike and Zettlemoyer, Luke and Yih, Wen-Tau},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {39755--39769},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/yasunaga23a/yasunaga23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/yasunaga23a.html},
  abstract = 	 {Recent multimodal models such as DALL-E and CM3 have achieved remarkable progress in text-to-image and image-to-text generation. However, these models store all their knowledge (e.g., the appearance of the Eiffel Tower) in the model parameters, requiring increasingly larger models and training data to capture more knowledge. To integrate knowledge in a more scalable and modular way, we propose a retrieval-augmented multimodal model, which enables a base multimodal model (generator) to refer to relevant text and images fetched by a retriever from external memory (e.g., documents on the web). Specifically, for the retriever, we use a pretrained CLIP, and for the generator, we train a CM3 Transformer on the LAION dataset. Our resulting model, named Retrieval-Augmented CM3 (RA-CM3), is the first multimodal model that can retrieve and generate both text and images. We show that RA-CM3 significantly outperforms baseline multimodal models such as DALL-E and CM3 on both image and caption generation tasks (12 FID and 17 CIDEr improvements on MS-COCO), while requiring much less compute for training ($&lt;$30% of DALL-E). Moreover, we show that RA-CM3 exhibits novel capabilities such as faithful image generation and multimodal in-context learning (e.g., image generation from demonstrations).}
}

@misc{Hu+2023,
      title={GAIA-1: A Generative World Model for Autonomous Driving}, 
      author={Anthony Hu and Lloyd Russell and Hudson Yeo and Zak Murez and George Fedoseev and Alex Kendall and Jamie Shotton and Gianluca Corrado},
      year={2023},
      eprint={2309.17080},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url          = {https://arxiv.org/abs/2309.17080},
}

@misc{Wang+2023,
      title={Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers}, 
      author={Chengyi Wang and Sanyuan Chen and Yu Wu and Ziqiang Zhang and Long Zhou and Shujie Liu and Zhuo Chen and Yanqing Liu and Huaming Wang and Jinyu Li and Lei He and Sheng Zhao and Furu Wei},
      year={2023},
      eprint={2301.02111},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url          = {https://arxiv.org/abs/2301.02111},
}

@misc{Yu+2023,
      title={Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning}, 
      author={Lili Yu and Bowen Shi and Ramakanth Pasunuru and Benjamin Muller and Olga Golovneva and Tianlu Wang and Arun Babu and Binh Tang and Brian Karrer and Shelly Sheynin and Candace Ross and Adam Polyak and Russell Howes and Vasu Sharma and Puxin Xu and Hovhannes Tamoyan and Oron Ashual and Uriel Singer and Shang-Wen Li and Susan Zhang and Richard James and Gargi Ghosh and Yaniv Taigman and Maryam Fazel-Zarandi and Asli Celikyilmaz and Luke Zettlemoyer and Armen Aghajanyan},
      year={2023},
      eprint={2309.02591},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url          = {https://arxiv.org/abs/2309.02591},
}

@misc{Tamkin+2021,
      title={Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models}, 
      author={Alex Tamkin and Miles Brundage and Jack Clark and Deep Ganguli},
      year={2021},
      eprint={2102.02503},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url          = {https://arxiv.org/abs/2102.02503},
}

@misc{Leng-Yuan2023,
      title={Do LLM Agents Exhibit Social Behavior?}, 
      author={Yan Leng and Yuan Yuan},
      year={2023},
      eprint={2312.15198},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url          = {https://arxiv.org/abs/2312.15198},
}

@misc{Nakano+2022,
      title={WebGPT: Browser-assisted question-answering with human feedback}, 
      author={Reiichiro Nakano and Jacob Hilton and Suchir Balaji and Jeff Wu and Long Ouyang and Christina Kim and Christopher Hesse and Shantanu Jain and Vineet Kosaraju and William Saunders and Xu Jiang and Karl Cobbe and Tyna Eloundou and Gretchen Krueger and Kevin Button and Matthew Knight and Benjamin Chess and John Schulman},
      year={2022},
      eprint={2112.09332},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url          = {https://arxiv.org/abs/2112.09332},
}

@inproceedings{Guu+2020,
author = {Guu, Kelvin and Lee, Kenton and Tung, Zora and Pasupat, Panupong and Chang, Ming-Wei},
title = {REALM: retrieval-augmented language model pre-training},
year = {2020},
publisher = {JMLR.org},
abstract = {Language model pre-training has been shown to capture a surprising amount of world knowledge, crucial for NLP tasks such as question answering. However, this knowledge is stored implicitly in the parameters of a neural network, requiring everlarger networks to cover more facts.To capture knowledge in a more modular and interpretable way, we augment language model pretraining with a latent knowledge retriever, which allows the model to retrieve and attend over documents from a large corpus such as Wikipedia, used during pre-training, fine-tuning and inference. For the first time, we show how to pre-train such a knowledge retriever in an unsupervised manner, using masked language modeling as the learning signal and backpropagating through a retrieval step that considers millions of documents.We demonstrate the effectiveness of Retrieval-Augmented Language Model pretraining (REALM) by fine-tuning on the challenging task of Open-domain Question Answering (Open-QA). We compare against state-of-the-art models for both explicit and implicit knowledge storage on three popular Open-QA benchmarks, and find that we outperform all previous methods by a significant margin (4-16\% absolute accuracy), while also providing qualitative benefits such as interpretability and modularity.},
booktitle = {Proceedings of the 37th International Conference on Machine Learning},
articleno = {368},
numpages = {10},
series = {ICML'20}
}

@misc{Ouyang+2022,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url          = {https://arxiv.org/abs/2203.02155},
}

@misc{Schulman+2017,
      title={Proximal Policy Optimization Algorithms}, 
      author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
      year={2017},
      eprint={1707.06347},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url          = {https://arxiv.org/abs/1707.06347},
}

@misc{Thoppilan+2022,
      title={LaMDA: Language Models for Dialog Applications}, 
      author={Romal Thoppilan and Daniel De Freitas and Jamie Hall and Noam Shazeer and Apoorv Kulshreshtha and Heng-Tze Cheng and Alicia Jin and Taylor Bos and Leslie Baker and Yu Du and YaGuang Li and Hongrae Lee and Huaixiu Steven Zheng and Amin Ghafouri and Marcelo Menegali and Yanping Huang and Maxim Krikun and Dmitry Lepikhin and James Qin and Dehao Chen and Yuanzhong Xu and Zhifeng Chen and Adam Roberts and Maarten Bosma and Vincent Zhao and Yanqi Zhou and Chung-Ching Chang and Igor Krivokon and Will Rusch and Marc Pickett and Pranesh Srinivasan and Laichee Man and Kathleen Meier-Hellstern and Meredith Ringel Morris and Tulsee Doshi and Renelito Delos Santos and Toju Duke and Johnny Soraker and Ben Zevenbergen and Vinodkumar Prabhakaran and Mark Diaz and Ben Hutchinson and Kristen Olson and Alejandra Molina and Erin Hoffman-John and Josh Lee and Lora Aroyo and Ravi Rajakumar and Alena Butryna and Matthew Lamm and Viktoriya Kuzmina and Joe Fenton and Aaron Cohen and Rachel Bernstein and Ray Kurzweil and Blaise Aguera-Arcas and Claire Cui and Marian Croak and Ed Chi and Quoc Le},
      year={2022},
      eprint={2201.08239},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url          = {https://arxiv.org/abs/2201.08239},
}

@misc{Schulman+2015,
      title={Trust Region Policy Optimization}, 
      author={John Schulman and Sergey Levine and Philipp Moritz and Michael I. Jordan and Pieter Abbeel},
      year={2015},
      eprint={1502.05477},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url          = {https://arxiv.org/abs/1502.05477},
}

@misc{Zheng+2023,
      title={Secrets of RLHF in Large Language Models Part I: PPO}, 
      author={Rui Zheng and Shihan Dou and Songyang Gao and Yuan Hua and Wei Shen and Binghai Wang and Yan Liu and Senjie Jin and Qin Liu and Yuhao Zhou and Limao Xiong and Lu Chen and Zhiheng Xi and Nuo Xu and Wenbin Lai and Minghao Zhu and Cheng Chang and Zhangyue Yin and Rongxiang Weng and Wensen Cheng and Haoran Huang and Tianxiang Sun and Hang Yan and Tao Gui and Qi Zhang and Xipeng Qiu and Xuanjing Huang},
      year={2023},
      eprint={2307.04964},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url          = {https://arxiv.org/abs/2307.04964},
}

@inproceedings{Radford+2023-Whisper,
author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
title = {Robust speech recognition via large-scale weak supervision},
year = {2023},
publisher = {JMLR.org},
abstract = {We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet. When scaled to 680,000 hours of multilingual and multitask supervision, the resulting models generalize well to standard benchmarks and are often competitive with prior fully supervised results without the need for any dataset specific fine-tuning. When compared to humans, the models approach their accuracy and robustness. We are releasing models and inference code to serve as a foundation for further work on robust speech processing.},
booktitle = {Proceedings of the 40th International Conference on Machine Learning},
articleno = {1182},
numpages = {27},
location = {Honolulu, Hawaii, USA},
series = {ICML'23},
url             = {https://dl.acm.org/doi/10.5555/3618408.3619590},
}

@misc{Baker+2022,
      title={Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos}, 
      author={Bowen Baker and Ilge Akkaya and Peter Zhokhov and Joost Huizinga and Jie Tang and Adrien Ecoffet and Brandon Houghton and Raul Sampedro and Jeff Clune},
      year={2022},
      eprint={2206.11795},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url          = {https://arxiv.org/abs/2206.11795},
}

@misc{Ramesh+2022,
      title={Hierarchical Text-Conditional Image Generation with CLIP Latents}, 
      author={Aditya Ramesh and Prafulla Dhariwal and Alex Nichol and Casey Chu and Mark Chen},
      year={2022},
      eprint={2204.06125},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url          = {https://arxiv.org/abs/2204.06125},
}

@techreport{Manning+2022,
    author      = {Sam Manning and Pamela Mishkin and Gillian Hadfield and Tyna Eloundou and Emily Eisne},
    institution = {OpenAI},
    title       = {A Research Agenda for Assessing the Economic Impacts of Code Generation Models},
    year        = {2022},
    url         = {https://openai.com/research/economic-impacts},
}


@inproceedings{Dickstein+2015,
  title = 	 {Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
  author = 	 {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {2256--2265},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/sohl-dickstein15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/sohl-dickstein15.html},
  abstract = 	 {A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.}
}

@inproceedings{Song-Ermon2020,
    author          = {Yang Song and Stefano Ermon},
    year            = {2020},
    title           = {Improved Techniques for Training Score-Based Generative Models},
    booktitle       = {Advances in Neural Information Processing Systems},
    volume          = {33},
    pages           = {},
    url             = {https://proceedings.neurips.cc/paper/2020/hash/92c3b916311a5517d9290576e3ea37ad-Abstract.html}
}

@inproceedings{Ho+2020,
    author          = {Jonathan Ho and Ajay Jain and Pieter Abbeel},
    year            = {2020},
    title           = {Denoising Diffusion Probabilistic Models},
    booktitle       = {Advances in Neural Information Processing Systems},
    volume          = {33},
    pages           = {},
    url             = {https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html}
}

@inproceedings{Aharoni+2019,
    title = "Massively Multilingual Neural Machine Translation",
    author = "Aharoni, Roee  and
      Johnson, Melvin  and
      Firat, Orhan",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1388",
    doi = "10.18653/v1/N19-1388",
    pages = "3874--3884",
    abstract = "Multilingual Neural Machine Translation enables training a single model that supports translation from multiple source languages into multiple target languages. We perform extensive experiments in training massively multilingual NMT models, involving up to 103 distinct languages and 204 translation directions simultaneously. We explore different setups for training such models and analyze the trade-offs between translation quality and various modeling decisions. We report results on the publicly available TED talks multilingual corpus where we show that massively multilingual many-to-many models are effective in low resource settings, outperforming the previous state-of-the-art while supporting up to 59 languages in 116 translation directions in a single model. Our experiments on a large-scale dataset with 103 languages, 204 trained directions and up to one million examples per direction also show promising results, surpassing strong bilingual baselines and encouraging future work on massively multilingual NMT.",
}

@misc{Geminiteam+2023,
      title={Gemini: A Family of Highly Capable Multimodal Models}, 
      author={Gemini Team and Rohan Anil and Sebastian Borgeaud and Yonghui Wu and Jean-Baptiste Alayrac and Jiahui Yu and Radu Soricut and Johan Schalkwyk and Andrew M. Dai and Anja Hauth and Katie Millican and David Silver and Slav Petrov and Melvin Johnson and Ioannis Antonoglou and Julian Schrittwieser and Amelia Glaese and Jilin Chen and Emily Pitler and Timothy Lillicrap and Angeliki Lazaridou and Orhan Firat and James Molloy and Michael Isard and Paul R. Barham and Tom Hennigan and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and Ryan Doherty and Eli Collins and Clemens Meyer and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and George Tucker and Enrique Piqueras and Maxim Krikun and Iain Barr and Nikolay Savinov and Ivo Danihelka and Becca Roelofs and Anaïs White and Anders Andreassen and Tamara von Glehn and Lakshman Yagati and Mehran Kazemi and Lucas Gonzalez and Misha Khalman and Jakub Sygnowski and Alexandre Frechette and Charlotte Smith and Laura Culp and Lev Proleev and Yi Luan and Xi Chen and James Lottes and Nathan Schucher and Federico Lebron and Alban Rrustemi and Natalie Clay and Phil Crone and Tomas Kocisky and Jeffrey Zhao and Bartek Perz and Dian Yu and Heidi Howard and Adam Bloniarz and Jack W. Rae and Han Lu and Laurent Sifre and Marcello Maggioni and Fred Alcober and Dan Garrette and Megan Barnes and Shantanu Thakoor and Jacob Austin and Gabriel Barth-Maron and William Wong and Rishabh Joshi and Rahma Chaabouni and Deeni Fatiha and Arun Ahuja and Ruibo Liu and Yunxuan Li and Sarah Cogan and Jeremy Chen and Chao Jia and Chenjie Gu and Qiao Zhang and Jordan Grimstad and Ale Jakse Hartman and Martin Chadwick and Gaurav Singh Tomar and Xavier Garcia and Evan Senter and Emanuel Taropa and Thanumalayan Sankaranarayana Pillai and Jacob Devlin and Michael Laskin and Diego de Las Casas and Dasha Valter and Connie Tao and Lorenzo Blanco and Adrià Puigdomènech Badia and David Reitter and Mianna Chen and Jenny Brennan and Clara Rivera and Sergey Brin and Shariq Iqbal and Gabriela Surita and Jane Labanowski and Abhi Rao and Stephanie Winkler and Emilio Parisotto and Yiming Gu and Kate Olszewska and Yujing Zhang and Ravi Addanki and Antoine Miech and Annie Louis and Laurent El Shafey and Denis Teplyashin and Geoff Brown and Elliot Catt and Nithya Attaluri and Jan Balaguer and Jackie Xiang and Pidong Wang and Zoe Ashwood and Anton Briukhov and Albert Webson and Sanjay Ganapathy and Smit Sanghavi and Ajay Kannan and Ming-Wei Chang and Axel Stjerngren and Josip Djolonga and Yuting Sun and Ankur Bapna and Matthew Aitchison and Pedram Pejman and Henryk Michalewski and Tianhe Yu and Cindy Wang and Juliette Love and Junwhan Ahn and Dawn Bloxwich and Kehang Han and Peter Humphreys and Thibault Sellam and James Bradbury and Varun Godbole and Sina Samangooei and Bogdan Damoc and Alex Kaskasoli and Sébastien M. R. Arnold and Vijay Vasudevan and Shubham Agrawal and Jason Riesa and Dmitry Lepikhin and Richard Tanburn and Srivatsan Srinivasan and Hyeontaek Lim and Sarah Hodkinson and Pranav Shyam and Johan Ferret and Steven Hand and Ankush Garg and Tom Le Paine and Jian Li and Yujia Li and Minh Giang and Alexander Neitz and Zaheer Abbas and Sarah York and Machel Reid and Elizabeth Cole and Aakanksha Chowdhery and Dipanjan Das and Dominika Rogozińska and Vitaly Nikolaev and Pablo Sprechmann and Zachary Nado and Lukas Zilka and Flavien Prost and Luheng He and Marianne Monteiro and Gaurav Mishra and Chris Welty and Josh Newlan and Dawei Jia and Miltiadis Allamanis and Clara Huiyi Hu and Raoul de Liedekerke and Justin Gilmer and Carl Saroufim and Shruti Rijhwani and Shaobo Hou and Disha Shrivastava and Anirudh Baddepudi and Alex Goldin and Adnan Ozturel and Albin Cassirer and Yunhan Xu and Daniel Sohn and Devendra Sachan and Reinald Kim Amplayo and Craig Swanson and Dessie Petrova and Shashi Narayan and Arthur Guez and Siddhartha Brahma and Jessica Landon and Miteyan Patel and Ruizhe Zhao and Kevin Villela and Luyu Wang and Wenhao Jia and Matthew Rahtz and Mai Giménez and Legg Yeung and Hanzhao Lin and James Keeling and Petko Georgiev and Diana Mincu and Boxi Wu and Salem Haykal and Rachel Saputro and Kiran Vodrahalli and James Qin and Zeynep Cankara and Abhanshu Sharma and Nick Fernando and Will Hawkins and Behnam Neyshabur and Solomon Kim and Adrian Hutter and Priyanka Agrawal and Alex Castro-Ros and George van den Driessche and Tao Wang and Fan Yang and Shuo-yiin Chang and Paul Komarek and Ross McIlroy and Mario Lučić and Guodong Zhang and Wael Farhan and Michael Sharman and Paul Natsev and Paul Michel and Yong Cheng and Yamini Bansal and Siyuan Qiao and Kris Cao and Siamak Shakeri and Christina Butterfield and Justin Chung and Paul Kishan Rubenstein and Shivani Agrawal and Arthur Mensch and Kedar Soparkar and Karel Lenc and Timothy Chung and Aedan Pope and Loren Maggiore and Jackie Kay and Priya Jhakra and Shibo Wang and Joshua Maynez and Mary Phuong and Taylor Tobin and Andrea Tacchetti and Maja Trebacz and Kevin Robinson and Yash Katariya and Sebastian Riedel and Paige Bailey and Kefan Xiao and Nimesh Ghelani and Lora Aroyo and Ambrose Slone and Neil Houlsby and Xuehan Xiong and Zhen Yang and Elena Gribovskaya and Jonas Adler and Mateo Wirth and Lisa Lee and Music Li and Thais Kagohara and Jay Pavagadhi and Sophie Bridgers and Anna Bortsova and Sanjay Ghemawat and Zafarali Ahmed and Tianqi Liu and Richard Powell and Vijay Bolina and Mariko Iinuma and Polina Zablotskaia and James Besley and Da-Woon Chung and Timothy Dozat and Ramona Comanescu and Xiance Si and Jeremy Greer and Guolong Su and Martin Polacek and Raphaël Lopez Kaufman and Simon Tokumine and Hexiang Hu and Elena Buchatskaya and Yingjie Miao and Mohamed Elhawaty and Aditya Siddhant and Nenad Tomasev and Jinwei Xing and Christina Greer and Helen Miller and Shereen Ashraf and Aurko Roy and Zizhao Zhang and Ada Ma and Angelos Filos and Milos Besta and Rory Blevins and Ted Klimenko and Chih-Kuan Yeh and Soravit Changpinyo and Jiaqi Mu and Oscar Chang and Mantas Pajarskas and Carrie Muir and Vered Cohen and Charline Le Lan and Krishna Haridasan and Amit Marathe and Steven Hansen and Sholto Douglas and Rajkumar Samuel and Mingqiu Wang and Sophia Austin and Chang Lan and Jiepu Jiang and Justin Chiu and Jaime Alonso Lorenzo and Lars Lowe Sjösund and Sébastien Cevey and Zach Gleicher and Thi Avrahami and Anudhyan Boral and Hansa Srinivasan and Vittorio Selo and Rhys May and Konstantinos Aisopos and Léonard Hussenot and Livio Baldini Soares and Kate Baumli and Michael B. Chang and Adrià Recasens and Ben Caine and Alexander Pritzel and Filip Pavetic and Fabio Pardo and Anita Gergely and Justin Frye and Vinay Ramasesh and Dan Horgan and Kartikeya Badola and Nora Kassner and Subhrajit Roy and Ethan Dyer and Víctor Campos and Alex Tomala and Yunhao Tang and Dalia El Badawy and Elspeth White and Basil Mustafa and Oran Lang and Abhishek Jindal and Sharad Vikram and Zhitao Gong and Sergi Caelles and Ross Hemsley and Gregory Thornton and Fangxiaoyu Feng and Wojciech Stokowiec and Ce Zheng and Phoebe Thacker and Çağlar Ünlü and Zhishuai Zhang and Mohammad Saleh and James Svensson and Max Bileschi and Piyush Patil and Ankesh Anand and Roman Ring and Katerina Tsihlas and Arpi Vezer and Marco Selvi and Toby Shevlane and Mikel Rodriguez and Tom Kwiatkowski and Samira Daruki and Keran Rong and Allan Dafoe and Nicholas FitzGerald and Keren Gu-Lemberg and Mina Khan and Lisa Anne Hendricks and Marie Pellat and Vladimir Feinberg and James Cobon-Kerr and Tara Sainath and Maribeth Rauh and Sayed Hadi Hashemi and Richard Ives and Yana Hasson and YaGuang Li and Eric Noland and Yuan Cao and Nathan Byrd and Le Hou and Qingze Wang and Thibault Sottiaux and Michela Paganini and Jean-Baptiste Lespiau and Alexandre Moufarek and Samer Hassan and Kaushik Shivakumar and Joost van Amersfoort and Amol Mandhane and Pratik Joshi and Anirudh Goyal and Matthew Tung and Andrew Brock and Hannah Sheahan and Vedant Misra and Cheng Li and Nemanja Rakićević and Mostafa Dehghani and Fangyu Liu and Sid Mittal and Junhyuk Oh and Seb Noury and Eren Sezener and Fantine Huot and Matthew Lamm and Nicola De Cao and Charlie Chen and Gamaleldin Elsayed and Ed Chi and Mahdis Mahdieh and Ian Tenney and Nan Hua and Ivan Petrychenko and Patrick Kane and Dylan Scandinaro and Rishub Jain and Jonathan Uesato and Romina Datta and Adam Sadovsky and Oskar Bunyan and Dominik Rabiej and Shimu Wu and John Zhang and Gautam Vasudevan and Edouard Leurent and Mahmoud Alnahlawi and Ionut Georgescu and Nan Wei and Ivy Zheng and Betty Chan and Pam G Rabinovitch and Piotr Stanczyk and Ye Zhang and David Steiner and Subhajit Naskar and Michael Azzam and Matthew Johnson and Adam Paszke and Chung-Cheng Chiu and Jaume Sanchez Elias and Afroz Mohiuddin and Faizan Muhammad and Jin Miao and Andrew Lee and Nino Vieillard and Sahitya Potluri and Jane Park and Elnaz Davoodi and Jiageng Zhang and Jeff Stanway and Drew Garmon and Abhijit Karmarkar and Zhe Dong and Jong Lee and Aviral Kumar and Luowei Zhou and Jonathan Evens and William Isaac and Zhe Chen and Johnson Jia and Anselm Levskaya and Zhenkai Zhu and Chris Gorgolewski and Peter Grabowski and Yu Mao and Alberto Magni and Kaisheng Yao and Javier Snaider and Norman Casagrande and Paul Suganthan and Evan Palmer and Geoffrey Irving and Edward Loper and Manaal Faruqui and Isha Arkatkar and Nanxin Chen and Izhak Shafran and Michael Fink and Alfonso Castaño and Irene Giannoumis and Wooyeol Kim and Mikołaj Rybiński and Ashwin Sreevatsa and Jennifer Prendki and David Soergel and Adrian Goedeckemeyer and Willi Gierke and Mohsen Jafari and Meenu Gaba and Jeremy Wiesner and Diana Gage Wright and Yawen Wei and Harsha Vashisht and Yana Kulizhskaya and Jay Hoover and Maigo Le and Lu Li and Chimezie Iwuanyanwu and Lu Liu and Kevin Ramirez and Andrey Khorlin and Albert Cui and Tian LIN and Marin Georgiev and Marcus Wu and Ricardo Aguilar and Keith Pallo and Abhishek Chakladar and Alena Repina and Xihui Wu and Tom van der Weide and Priya Ponnapalli and Caroline Kaplan and Jiri Simsa and Shuangfeng Li and Olivier Dousse and Fan Yang and Jeff Piper and Nathan Ie and Minnie Lui and Rama Pasumarthi and Nathan Lintz and Anitha Vijayakumar and Lam Nguyen Thiet and Daniel Andor and Pedro Valenzuela and Cosmin Paduraru and Daiyi Peng and Katherine Lee and Shuyuan Zhang and Somer Greene and Duc Dung Nguyen and Paula Kurylowicz and Sarmishta Velury and Sebastian Krause and Cassidy Hardin and Lucas Dixon and Lili Janzer and Kiam Choo and Ziqiang Feng and Biao Zhang and Achintya Singhal and Tejasi Latkar and Mingyang Zhang and Quoc Le and Elena Allica Abellan and Dayou Du and Dan McKinnon and Natasha Antropova and Tolga Bolukbasi and Orgad Keller and David Reid and Daniel Finchelstein and Maria Abi Raad and Remi Crocker and Peter Hawkins and Robert Dadashi and Colin Gaffney and Sid Lall and Ken Franko and Egor Filonov and Anna Bulanova and Rémi Leblond and Vikas Yadav and Shirley Chung and Harry Askham and Luis C. Cobo and Kelvin Xu and Felix Fischer and Jun Xu and Christina Sorokin and Chris Alberti and Chu-Cheng Lin and Colin Evans and Hao Zhou and Alek Dimitriev and Hannah Forbes and Dylan Banarse and Zora Tung and Jeremiah Liu and Mark Omernick and Colton Bishop and Chintu Kumar and Rachel Sterneck and Ryan Foley and Rohan Jain and Swaroop Mishra and Jiawei Xia and Taylor Bos and Geoffrey Cideron and Ehsan Amid and Francesco Piccinno and Xingyu Wang and Praseem Banzal and Petru Gurita and Hila Noga and Premal Shah and Daniel J. Mankowitz and Alex Polozov and Nate Kushman and Victoria Krakovna and Sasha Brown and MohammadHossein Bateni and Dennis Duan and Vlad Firoiu and Meghana Thotakuri and Tom Natan and Anhad Mohananey and Matthieu Geist and Sidharth Mudgal and Sertan Girgin and Hui Li and Jiayu Ye and Ofir Roval and Reiko Tojo and Michael Kwong and James Lee-Thorp and Christopher Yew and Quan Yuan and Sumit Bagri and Danila Sinopalnikov and Sabela Ramos and John Mellor and Abhishek Sharma and Aliaksei Severyn and Jonathan Lai and Kathy Wu and Heng-Tze Cheng and David Miller and Nicolas Sonnerat and Denis Vnukov and Rory Greig and Jennifer Beattie and Emily Caveness and Libin Bai and Julian Eisenschlos and Alex Korchemniy and Tomy Tsai and Mimi Jasarevic and Weize Kong and Phuong Dao and Zeyu Zheng and Frederick Liu and Fan Yang and Rui Zhu and Mark Geller and Tian Huey Teh and Jason Sanmiya and Evgeny Gladchenko and Nejc Trdin and Andrei Sozanschi and Daniel Toyama and Evan Rosen and Sasan Tavakkol and Linting Xue and Chen Elkind and Oliver Woodman and John Carpenter and George Papamakarios and Rupert Kemp and Sushant Kafle and Tanya Grunina and Rishika Sinha and Alice Talbert and Abhimanyu Goyal and Diane Wu and Denese Owusu-Afriyie and Cosmo Du and Chloe Thornton and Jordi Pont-Tuset and Pradyumna Narayana and Jing Li and Sabaer Fatehi and John Wieting and Omar Ajmeri and Benigno Uria and Tao Zhu and Yeongil Ko and Laura Knight and Amélie Héliou and Ning Niu and Shane Gu and Chenxi Pang and Dustin Tran and Yeqing Li and Nir Levine and Ariel Stolovich and Norbert Kalb and Rebeca Santamaria-Fernandez and Sonam Goenka and Wenny Yustalim and Robin Strudel and Ali Elqursh and Balaji Lakshminarayanan and Charlie Deck and Shyam Upadhyay and Hyo Lee and Mike Dusenberry and Zonglin Li and Xuezhi Wang and Kyle Levin and Raphael Hoffmann and Dan Holtmann-Rice and Olivier Bachem and Summer Yue and Sho Arora and Eric Malmi and Daniil Mirylenka and Qijun Tan and Christy Koh and Soheil Hassas Yeganeh and Siim Põder and Steven Zheng and Francesco Pongetti and Mukarram Tariq and Yanhua Sun and Lucian Ionita and Mojtaba Seyedhosseini and Pouya Tafti and Ragha Kotikalapudi and Zhiyu Liu and Anmol Gulati and Jasmine Liu and Xinyu Ye and Bart Chrzaszcz and Lily Wang and Nikhil Sethi and Tianrun Li and Ben Brown and Shreya Singh and Wei Fan and Aaron Parisi and Joe Stanton and Chenkai Kuang and Vinod Koverkathu and Christopher A. Choquette-Choo and Yunjie Li and TJ Lu and Abe Ittycheriah and Prakash Shroff and Pei Sun and Mani Varadarajan and Sanaz Bahargam and Rob Willoughby and David Gaddy and Ishita Dasgupta and Guillaume Desjardins and Marco Cornero and Brona Robenek and Bhavishya Mittal and Ben Albrecht and Ashish Shenoy and Fedor Moiseev and Henrik Jacobsson and Alireza Ghaffarkhah and Morgane Rivière and Alanna Walton and Clément Crepy and Alicia Parrish and Yuan Liu and Zongwei Zhou and Clement Farabet and Carey Radebaugh and Praveen Srinivasan and Claudia van der Salm and Andreas Fidjeland and Salvatore Scellato and Eri Latorre-Chimoto and Hanna Klimczak-Plucińska and David Bridson and Dario de Cesare and Tom Hudson and Piermaria Mendolicchio and Lexi Walker and Alex Morris and Ivo Penchev and Matthew Mauger and Alexey Guseynov and Alison Reid and Seth Odoom and Lucia Loher and Victor Cotruta and Madhavi Yenugula and Dominik Grewe and Anastasia Petrushkina and Tom Duerig and Antonio Sanchez and Steve Yadlowsky and Amy Shen and Amir Globerson and Adam Kurzrok and Lynette Webb and Sahil Dua and Dong Li and Preethi Lahoti and Surya Bhupatiraju and Dan Hurt and Haroon Qureshi and Ananth Agarwal and Tomer Shani and Matan Eyal and Anuj Khare and Shreyas Rammohan Belle and Lei Wang and Chetan Tekur and Mihir Sanjay Kale and Jinliang Wei and Ruoxin Sang and Brennan Saeta and Tyler Liechty and Yi Sun and Yao Zhao and Stephan Lee and Pandu Nayak and Doug Fritz and Manish Reddy Vuyyuru and John Aslanides and Nidhi Vyas and Martin Wicke and Xiao Ma and Taylan Bilal and Evgenii Eltyshev and Daniel Balle and Nina Martin and Hardie Cate and James Manyika and Keyvan Amiri and Yelin Kim and Xi Xiong and Kai Kang and Florian Luisier and Nilesh Tripuraneni and David Madras and Mandy Guo and Austin Waters and Oliver Wang and Joshua Ainslie and Jason Baldridge and Han Zhang and Garima Pruthi and Jakob Bauer and Feng Yang and Riham Mansour and Jason Gelman and Yang Xu and George Polovets and Ji Liu and Honglong Cai and Warren Chen and XiangHai Sheng and Emily Xue and Sherjil Ozair and Adams Yu and Christof Angermueller and Xiaowei Li and Weiren Wang and Julia Wiesinger and Emmanouil Koukoumidis and Yuan Tian and Anand Iyer and Madhu Gurumurthy and Mark Goldenson and Parashar Shah and MK Blake and Hongkun Yu and Anthony Urbanowicz and Jennimaria Palomaki and Chrisantha Fernando and Kevin Brooks and Ken Durden and Harsh Mehta and Nikola Momchev and Elahe Rahimtoroghi and Maria Georgaki and Amit Raul and Sebastian Ruder and Morgan Redshaw and Jinhyuk Lee and Komal Jalan and Dinghua Li and Ginger Perng and Blake Hechtman and Parker Schuh and Milad Nasr and Mia Chen and Kieran Milan and Vladimir Mikulik and Trevor Strohman and Juliana Franco and Tim Green and Demis Hassabis and Koray Kavukcuoglu and Jeffrey Dean and Oriol Vinyals},
      year={2023},
      eprint={2312.11805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url          = {https://arxiv.org/abs/2312.11805},
}

@inproceedings{Shazeer+2017,
      title={Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer}, 
      author={Noam Shazeer and Azalia Mirhoseini and Krzysztof Maziarz and Andy Davis and Quoc Le and Geoffrey Hinton and Jeff Dean},
      year={2017},
    booktitle       = {International Conference on Learning Representation},
    volume          = {},
    pages           = {},
    url             = {https://openreview.net/forum?id=B1ckMDqlg}
}


@inproceedings{Nichol+2022,
  title = 	 {{GLIDE}: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models},
  author =       {Nichol, Alexander Quinn and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and Mcgrew, Bob and Sutskever, Ilya and Chen, Mark},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {16784--16804},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/nichol22a/nichol22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/nichol22a.html},
  abstract = 	 {Diffusion models have recently been shown to generate high-quality synthetic images, especially when paired with a guidance technique to trade off diversity for fidelity. We explore diffusion models for the problem of text-conditional image synthesis and compare two different guidance strategies: CLIP guidance and classifier-free guidance. We find that the latter is preferred by human evaluators for both photorealism and caption similarity, and often produces photorealistic samples. Samples from a 3.5&nbsp;billion parameter text-conditional diffusion model using classifier-free guidance are favored by human evaluators to those from DALL-E, even when the latter uses expensive CLIP reranking. Additionally, we find that our models can be fine-tuned to perform image inpainting, enabling powerful text-driven image editing. We train a smaller model on a filtered dataset and release the code and weights at https://github.com/openai/glide-text2im.}
}

@inproceedings{Lin+2022,
    author          = {Stephanie Lin and Jacob Hilton and Owain Evans},
    year            = {2022},
    title           = {Teaching Models to Express Their Uncertainty in Words},
    booktitle       = {Transactions on Machine Learning Research},
    volume          = {},
    pages           = {},
    url             = {https://openai.com/research/teaching-models-to-express-their-uncertainty-in-words}
}

@techreport{Weng-Brockman2022,
    author      = {Lilian Weng and Greg Brockman},
    institution = {OpenAI},
    title       = {Techniques for Training Large Neural Networks},
    url        = {https://openai.com/research/techniques-for-training-large-neural-networks},
    year       = {2022}
}

@techreport{Nichol2022,
    author      = {Alex Nichol},
    institution = {OpenAI},
    title       = {DALL-E2 Pre-training Mitigations},
    year        = {2022},
    url         = {https://openai.com/research/dall-e-2-pre-training-mitigations},
}

@inbook{Lehman+2024,
    author         = {Joel Lehman and Jonathan Gordon Shawn Jain and Kamal Ndousse and Cathy Yah and Kenneth O. Stanley},
    chapter        = {Evolution through Large Models},
    editor         = {Wolfgang Banzhaf and Penousal Machado and Mengjie Zhang},
    pages          = {331-366},
    publisher      = {Springer Singapore},
    title          = {Handbook of Evolutionary Machine Learning},
    year           = {2024},
    url            = {https://link.springer.com/chapter/10.1007/978-981-99-3814-8_11},
}

@misc{Saunders+2022,
      title={Self-critiquing models for assisting human evaluators}, 
      author={William Saunders and Catherine Yeh and Jeff Wu and Steven Bills and Long Ouyang and Jonathan Ward and Jan Leike},
      year={2022},
      eprint={2206.05802},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url          = {https://openai.com/research/critiques},
}

@misc{Khlaaf+2022,
      title={A Hazard Analysis Framework for Code Synthesis Large Language Models}, 
      author={Heidy Khlaaf and Pamela Mishkin and Joshua Achiam and Gretchen Krueger and Miles Brundage},
      year={2022},
      eprint={2207.14157},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url          = {https://openai.com/research/a-hazard-analysis-framework-for-code-synthesis-large-language-models},
}

@misc{Goldstein+2023,
      title={Generative Language Models and Automated Influence Operations: Emerging Threats and Potential Mitigations}, 
      author={Josh A. Goldstein and Girish Sastry and Micah Musser and Renee DiResta and Matthew Gentzel and Katerina Sedova},
      year={2023},
      eprint={2301.04246},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url          = {https://openai.com/research/forecasting-misuse},
}

@misc{Eloundou+2023,
      title={GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models}, 
      author={Tyna Eloundou and Sam Manning and Pamela Mishkin and Daniel Rock},
      year={2023},
      eprint={2303.10130},
      archivePrefix={arXiv},
      primaryClass={econ.GN},
      url          = {https://openai.com/research/gpts-are-gpts},
}

@misc{Chen+2021,
      title={Evaluating Large Language Models Trained on Code}, 
      author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
      year={2021},
      eprint={2107.03374},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url          = {https://arxiv.org/abs/2107.03374},
}

@techreport{Leike+2022,
    author      = {Jan Leike and John Schulman and Jeffrey Wu},
    institution = {OpenAI},
    title       = {Our Approach to Alignment Research},
    year        = {2022},
    url         = {https://openai.com/blog/our-approach-to-alignment-research},
}

@techreport{Leike+2023,
    author      = {Jan Leike and Jeffrey Wu and Steven Bills and William Saunders and Leo Gao and Henk Tillman and Daniel Mossing},
    institution = {OpenAI},
    title       = {Language Models Can Explain Neurons in Language Models},
    year        = {2023},
    url         = {https://openai.com/research/language-models-can-explain-neurons-in-language-models},
}

@misc{Anderljung+2023,
      title={Frontier AI Regulation: Managing Emerging Risks to Public Safety}, 
      author={Markus Anderljung and Joslyn Barnhart and Anton Korinek and Jade Leung and Cullen O'Keefe and Jess Whittlestone and Shahar Avin and Miles Brundage and Justin Bullock and Duncan Cass-Beggs and Ben Chang and Tantum Collins and Tim Fist and Gillian Hadfield and Alan Hayes and Lewis Ho and Sara Hooker and Eric Horvitz and Noam Kolt and Jonas Schuett and Yonadav Shavit and Divya Siddarth and Robert Trager and Kevin Wolf},
      year={2023},
      eprint={2307.03718},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      institution = {OpenAI},
      url          = {https://openai.com/research/frontier-ai-regulation},
}

@misc{Shoker+2023,
      title={Confidence-Building Measures for Artificial Intelligence: Workshop Proceedings}, 
      author={Sarah Shoker and Andrew Reddie and Sarah Barrington and Ruby Booth and Miles Brundage and Husanjot Chahal and Michael Depp and Bill Drexel and Ritwik Gupta and Marina Favaro and Jake Hecla and Alan Hickey and Margarita Konaev and Kirthi Kumar and Nathan Lambert and Andrew Lohn and Cullen O'Keefe and Nazneen Rajani and Michael Sellitto and Robert Trager and Leah Walker and Alexa Wehsener and Jessica Young},
      year={2023},
      eprint={2308.00862},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url          = {https://openai.com/research/confidence-building-measures-for-artificial-intelligence},
}

@techreport{OpenAI2023-GPT4V,
    author      = {OpenAI},
    institution = {OpenAI},
    title       = {GPT-4V(ision) System Card},
    year        = {2023},
    url         = {https://openai.com/research/gpt-4v-system-card},
}

@misc{Yang+2023,
      title={The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)}, 
      author={Zhengyuan Yang and Linjie Li and Kevin Lin and Jianfeng Wang and Chung-Ching Lin and Zicheng Liu and Lijuan Wang},
      year={2023},
      eprint={2309.17421},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url          = {https://arxiv.org/abs/2309.17421},
}

@misc{Perot+2023,
      title={LMDX: Language Model-based Document Information Extraction and Localization}, 
      author={Vincent Perot and Kai Kang and Florian Luisier and Guolong Su and Xiaoyu Sun and Ramya Sree Boppana and Zilong Wang and Jiaqi Mu and Hao Zhang and Nan Hua},
      year={2023},
      eprint={2309.10952},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url          = {https://arxiv.org/abs/2309.10952},
}

@techreport{OpenAI2023DallE3,
    author      = {OpenAI},
    institution = {OpenAI},
    title       = {DALL-E3 System Card},
    year        = {2023},
    url         = {https://openai.com/research/dall-e-3-system-card},
}

@techreport{Shavit+2023,
    author      = {Yonadav Shavit and Sandhini Agarwal and Miles Brundage},
    institution = {OpenAI},
    title       = {Practices for Governing Agentic AI Systems},
    year        = {2023},
    url         = {https://openai.com/research/practices-for-governing-agentic-ai-systems},
}

@misc{Burns+2023,
      title={Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision}, 
      author={Collin Burns and Pavel Izmailov and Jan Hendrik Kirchner and Bowen Baker and Leo Gao and Leopold Aschenbrenner and Yining Chen and Adrien Ecoffet and Manas Joglekar and Jan Leike and Ilya Sutskever and Jeff Wu},
      year={2023},
      eprint={2312.09390},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url          = {https://openai.com/research/weak-to-strong-generalization},
}

@techreport{Patwardhan+2024,
    author      = {Tejal Patwardhan and Kevin Liu and Todor Markov and Neil Chowdhury and Dillon Leet and Natalie Cone and Caitlin Maltbie and Joost Huizinga and Carroll Wainwright and Shawn (Froggi) Jackson and Steven Adler and Rocco Casagrande and Aleksander Mandry},
    institution = {OpenAI},
    title       = {Building an early warning system for LLM-aided biological threat creation},
    year        = {2024},
    url         = {https://openai.com/research/building-an-early-warning-system-for-llm-aided-biological-threat-creation},
}

@inproceedings{Fu+2023,
title={Hungry Hungry Hippos: Towards Language Modeling with State Space Models},
author={Daniel Y Fu and Tri Dao and Khaled Kamal Saab and Armin W Thomas and Atri Rudra and Christopher Re},
booktitle={The Eleventh International Conference on Learning Representations},
year={2023},
url={https://openreview.net/forum?id=COZDy0WYGg}
}

@inproceedings{Gu+2022,
title={Efficiently Modeling Long Sequences with Structured State Spaces},
author={Albert Gu and Karan Goel and Christopher Re},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=uYLFoz1vlAC}
}

@article{Zhou+2020,
	author = {Jie Zhou and Ganqu Cui and Shengding Hu and Zhengyan Zhang and Cheng Yang and Zhiyuan Liu and Lifeng Wang and Changcheng Li and Maosong Sun},
	journal = {AI Open},
	pages = {57-81},
	title = {Graph neural networks: A review of methods and applications},
	volume = {1},
	year = {2020},
    url             = {https://www.sciencedirect.com/science/article/pii/S2666651021000012},
}

@article{Wu+2021,
   title={A Comprehensive Survey on Graph Neural Networks},
   volume={32},
   ISSN={2162-2388},
   url={http://dx.doi.org/10.1109/TNNLS.2020.2978386},
   DOI={10.1109/tnnls.2020.2978386},
   number={1},
   journal={IEEE Transactions on Neural Networks and Learning Systems},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
   year={2021},
   month={jan}, pages={4–24} 
}

@article{Velickovic2023,
	author = {Petar Veli{\v c}kovi{\'c}},
	journal = {Current Opinion in Structural Biology},
	pages = {102538},
	title = {Everything is connected: Graph neural networks},
	volume = {79},
	year = {2023},
    url             = {https://www.sciencedirect.com/science/article/pii/S0959440X2300012X},
}

@inproceedings{Dhariwal-Nichol2021,
title={Diffusion Models Beat {GAN}s on Image Synthesis},
author={Prafulla Dhariwal and Alexander Quinn Nichol},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=AAWuCvzaVt}
}

@misc{Luo2022,
      title={Understanding Diffusion Models: A Unified Perspective}, 
      author={Calvin Luo},
      year={2022},
      eprint={2208.11970},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url          = {https://arxiv.org/abs/2208.11970},
}

@article{Hyvarinen2005,
    author          = {Aapo Hyvärinen},
    year            = {2005},
    title           = {Estimation of Non-Normalized Statistical Models by Score Matching},
    journal         = {Journal of Machine Learning Research},
    volume          = {6},
    number          = {24},
    pages           = {695-709},
    url             = {https://jmlr.org/papers/v6/hyvarinen05a.html}
}

@inproceedings{Rombach+2022,
    author          = {Rbin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
    year            = {2022},
    title           = {High-Resolution Image Systhesis with Latent Diffusion Models},
    booktitle       = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    volume          = {},
    pages           = {10684-10695},
    url             = {https://openaccess.thecvf.com/content/CVPR2022/html/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.html}
}


@inproceedings{Ronneberger+2015,
	address = {Cham},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	booktitle = {Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015},
	editor = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
	pages = {234--241},
	publisher = {Springer International Publishing},
	title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	year = {2015},
    url             = {https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28},
}


@article{Yang+2023,
	author = {Yang, Ruihan and Srivastava, Prakhar and Mandt, Stephan},
	journal = {Entropy},
	number = {10},
	title = {Diffusion Probabilistic Modeling for Video Generation},
	volume = {25},
	year = {2023},
    url             = {https://www.mdpi.com/1099-4300/25/10/1469},
}

@article{Kobyzev+2021,
author = {I. Kobyzev and S. D. Prince and M. A. Brubaker},
journal = {IEEE Transactions on Pattern Analysis &amp; Machine Intelligence},
title = {Normalizing Flows: An Introduction and Review of Current Methods},
year = {2021},
volume = {43},
number = {11},
issn = {1939-3539},
pages = {3964-3979},
abstract = {Normalizing Flows are generative models which produce tractable distributions where both sampling and density evaluation can be efficient and exact. The goal of this survey article is to give a coherent and comprehensive review of the literature around the construction and use of Normalizing Flows for distribution learning. We aim to provide context and explanation of the models, review current state-of-the-art literature, and identify open questions and promising future directions.},
keywords = {estimation;jacobian matrices;mathematical model;training;computational modeling;context modeling;random variables},
doi = {10.1109/TPAMI.2020.2992934},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {nov},
url             = {https://www.computer.org/csdl/journal/tp/2021/11/09089305/1jDwlyVxAwE},
}

@article{Papamakarios+2021,
author = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
title = {Normalizing flows for probabilistic modeling and inference},
year = {2021},
issue_date = {January 2021},
publisher = {JMLR.org},
volume = {22},
number = {1},
issn = {1532-4435},
abstract = {Normalizing flows provide a general mechanism for defining expressive probability distributions, only requiring the specification of a (usually simple) base distribution and a series of bijective transformations. There has been much recent work on normalizing flows, ranging from improving their expressive power to expanding their application. We believe the field has now matured and is in need of a unified perspective. In this review, we attempt to provide such a perspective by describing flows through the lens of probabilistic modeling and inference. We place special emphasis on the fundamental principles of flow design, and discuss foundational topics such as expressive power and computational trade-offs. We also broaden the conceptual framing of flows by relating them to more general probability transformations. Lastly, we summarize the use of flows for tasks such as generative modeling, approximate inference, and supervised learning.},
journal = {J. Mach. Learn. Res.},
month = {jan},
articleno = {57},
numpages = {64},
keywords = {generative models, probabilistic inference, probabilistic modeling, invertible neural networks, normalizing flows},
url             = {https://dl.acm.org/doi/abs/10.5555/3546258.3546315},
}

@misc{Brock+2019,
      title={Large Scale GAN Training for High Fidelity Natural Image Synthesis}, 
      author={Andrew Brock and Jeff Donahue and Karen Simonyan},
      year={2019},
      eprint={1809.11096},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url          = {https://arxiv.org/abs/1809.11096},
}

@inproceedings{Saharia+2022,
title={Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
author={Chitwan Saharia and William Chan and Saurabh Saxena and Lala Li and Jay Whang and Emily Denton and Seyed Kamyar Seyed Ghasemipour and Raphael Gontijo-Lopes and Burcu Karagol Ayan‎ and Tim Salimans and Jonathan Ho and David J. Fleet and Mohammad Norouzi},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=08Yk-n5l2Al}
}


@inproceedings{Jaegle+2021,
  title = 	 {Perceiver: General Perception with Iterative Attention},
  author =       {Jaegle, Andrew and Gimeno, Felix and Brock, Andy and Vinyals, Oriol and Zisserman, Andrew and Carreira, Joao},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {4651--4664},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/jaegle21a/jaegle21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/jaegle21a.html},
  abstract = 	 {Biological systems understand the world by simultaneously processing high-dimensional inputs from modalities as diverse as vision, audition, touch, proprioception, etc. The perception models used in deep learning on the other hand are designed for individual modalities, often relying on domain-specific assumptions such as the local grid structures exploited by virtually all existing vision models. These priors introduce helpful inductive biases, but also lock models to individual modalities. In this paper we introduce the Perceiver {–} a model that builds upon Transformers and hence makes few architectural assumptions about the relationship between its inputs, but that also scales to hundreds of thousands of inputs, like ConvNets. The model leverages an asymmetric attention mechanism to iteratively distill inputs into a tight latent bottleneck, allowing it to scale to handle very large inputs. We show that this architecture is competitive with or outperforms strong, specialized models on classification tasks across various modalities: images, point clouds, audio, video and video+audio. The Perceiver obtains performance comparable to ResNet-50 and ViT on ImageNet without 2D convolutions by directly attending to 50,000 pixels. It is also competitive in all modalities in AudioSet.}
}

@inproceedings{Huang+2021,
title={A Variational Perspective on Diffusion-Based Generative Models and Score Matching},
author={Chin-Wei Huang and Jae Hyun Lim and Aaron Courville},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=bXehDYUjjXi}
}

@article{Vincent2011,
    author          = {Pascal Vincent},
    year            = {2011},
    title           = {A Connection between Score Matching and Denoising Autoencoders},
    journal         = {Neural Computation},
    volume          = {23},
    number          = {7},
    pages           = {1661-1674},
    url             = {https://direct.mit.edu/neco/article/23/7/1661/7677/A-Connection-Between-Score-Matching-and-Denoising}
}

@inproceedings{Song+2021NeurIPS,
    author          = {Yang Song and Conor Durkan and Iain Murray and Stefano Ermon},
    year            = {2021},
    title           = {Maximum Likelihood Training of Score-Based Diffusion Models},
    booktitle       = {Advances in Neural Information Processing Systems},
    volume          = {34},
    pages           = {},
    url             = {2021}
}

@misc{Tzen-Raginsky2019,
      title={Neural Stochastic Differential Equations: Deep Latent Gaussian Models in the Diffusion Limit}, 
      author={Belinda Tzen and Maxim Raginsky},
      year={2019},
      eprint={1905.09883},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url          = {https://arxiv.org/abs/1905.09883},
}

@inproceedings{Song+2021ICLR,
title={Score-Based Generative Modeling through Stochastic Differential Equations},
author={Yang Song and Jascha Sohl-Dickstein and Diederik P Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=PxTIG12RRHS}
}

@inproceedings{Jang+2017,
title={Categorical Reparameterization with Gumbel-Softmax},
author={Eric Jang and Shixiang Gu and Ben Poole},
booktitle={International Conference on Learning Representations},
year={2017},
url={https://openreview.net/forum?id=rkE3y85ee}
}

@inproceedings{Maddison+2017,
title={The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables},
author={Chris J. Maddison and Andriy Mnih and Yee Whye Teh},
booktitle={International Conference on Learning Representations},
year={2017},
url={https://openreview.net/forum?id=S1jE5L5gl}
}


@inproceedings{Reed+2016,
  title = 	 {Generative Adversarial Text to Image Synthesis},
  author = 	 {Reed, Scott and Akata, Zeynep and Yan, Xinchen and Logeswaran, Lajanugen and Schiele, Bernt and Lee, Honglak},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1060--1069},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/reed16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/reed16.html},
  abstract = 	 {Automatic synthesis of realistic images from text would be interesting and useful, but current AI systems are still far from this goal. However, in recent years generic and powerful recurrent neural network architectures have been developed to learn discriminative text feature representations. Meanwhile, deep convolutional generative adversarial networks (GANs) have begun to generate highly compelling images of specific categories such as faces, album covers, room interiors and flowers. In this work, we develop a novel deep architecture and GAN formulation to effectively bridge these advances in text and image modeling, translating visual concepts from characters to pixels. We demonstrate the capability of our model to generate plausible images of birds and flowers from detailed text descriptions.}
}

@inproceedings{Peebles-Xie2023,
    author    = {Peebles, William and Xie, Saining},
    title     = {Scalable Diffusion Models with Transformers},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2023},
    pages     = {4195-4205},
    url             = {https://openaccess.thecvf.com/content/ICCV2023/html/Peebles_Scalable_Diffusion_Models_with_Transformers_ICCV_2023_paper.html},
}

@inproceedings{Arnab+2021,
  author={Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lučić, Mario and Schmid, Cordelia},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={ViViT: A Video Vision Transformer}, 
  year={2021},
  volume={},
  number={},
  pages={6816-6826},
  keywords={Training;Computer vision;Three-dimensional displays;Benchmark testing;Transformers;Spatiotemporal phenomena;Kinetic theory;Video analysis and understanding;Action and behavior recognition},
  doi={10.1109/ICCV48922.2021.00676},
  url             = {https://ieeexplore.ieee.org/abstract/document/9710415},
}

@inproceedings{Dehghani+2023,
title={Patch n{\textquoteright} Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution},
author={Mostafa Dehghani and Basil Mustafa and Josip Djolonga and Jonathan Heek and Matthias Minderer and Mathilde Caron and Andreas Peter Steiner and Joan Puigcerver and Robert Geirhos and Ibrahim Alabdulmohsin and Avital Oliver and Piotr Padlewski and Alexey A. Gritsenko and Mario Lucic and Neil Houlsby},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=VpGFHmI7e5}
}

@misc{Ma+2024,
      title={SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant Transformers}, 
      author={Nanye Ma and Mark Goldstein and Michael S. Albergo and Nicholas M. Boffi and Eric Vanden-Eijnden and Saining Xie},
      year={2024},
      eprint={2401.08740},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url          = {https://arxiv.org/abs/2401.08740},
}

@inproceedings{Albergo-Vanden-Eijnden2023,
title={Building Normalizing Flows with Stochastic Interpolants},
author={Michael Samuel Albergo and Eric Vanden-Eijnden},
booktitle={The Eleventh International Conference on Learning Representations},
year={2023},
url={https://openreview.net/forum?id=li7qeBbCR1t}
}

@misc{Albergo+2023,
      title={Stochastic Interpolants: A Unifying Framework for Flows and Diffusions}, 
      author={Michael S. Albergo and Nicholas M. Boffi and Eric Vanden-Eijnden},
      year={2023},
      eprint={2303.08797},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url          = {https://arxiv.org/abs/2303.08797},
}

@inproceedings{Lipman+2023,
title={Flow Matching for Generative Modeling},
author={Yaron Lipman and Ricky T. Q. Chen and Heli Ben-Hamu and Maximilian Nickel and Matthew Le},
booktitle={The Eleventh International Conference on Learning Representations},
year={2023},
url={https://openreview.net/forum?id=PqvMRDCJT9t}
}

@inproceedings{Liu+2023,
title={Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow},
author={Xingchao Liu and Chengyue Gong and qiang liu},
booktitle={The Eleventh International Conference on Learning Representations},
year={2023},
url={https://openreview.net/forum?id=XVjTT1nw5z}
}

@book{伊藤-加藤2005,
    author         = {伊藤正己 and 加藤一郎},
    year           = {2005},
    month          = {3},
    title          = {現代法学入門},
    series         = {有斐閣双書},
    volume         = {},
    edition        = {4},
    url            = {https://www.yuhikaku.co.jp/books/detail/4641112568},
    publisher      = {有斐閣}
}

@book{渡辺洋三1993,
    author         = {渡辺洋三},
    year           = {1993},
    month          = {6},
    title          = {法の常識},
    series         = {有斐閣双書},
    volume         = {},
    edition        = {3},
    url            = {https://www.yuhikaku.co.jp/books/detail/4641111014},
    publisher      = {有斐閣}
}

@inbook{実質的違法論について2004,
    author         = {厚生労働省},
    chapter        = {実質的違法論について},
    editor         = {},
    pages          = {},
    publisher      = {},
    title          = {在宅及び養護学校における日常的な医療の医学的・法律学的整理に関する研究会（第１回）},
    year           = {2004},
    url            = {https://www.mhlw.go.jp/shingi/2004/05/s0531-11b4.html},
}

@article{Bezanson+2017,
    author          = {Jeff Bezanson and Alan Edelman and Stefan Karpinski and Viral B. Shah},
    year            = {2017},
    title           = {Julia: A Fresh Approach to Numerical Computing},
    journal         = {SIAM Review},
    volume          = {59},
    number          = {1},
    pages           = {65-98},
    url             = {https://epubs.siam.org/doi/10.1137/141000671}
}