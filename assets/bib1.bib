@article{Kirsch2019,
	abstract = {A sequence of random variables is called exchangeable if the joint distribution of the sequence is unchanged by any permutation of the indices. De Finetti's theorem characterizes all {0,1}-valued exchangeable sequences as a `mixture' of sequences of independent random variables. We present a new, elementary proof of de Finetti's Theorem. The purpose of this paper is to make this theorem accessible to a broader community through an essentially self-contained proof.},
	author = {Werner Kirsch},
	doi = {https://doi.org/10.1016/j.spl.2019.03.014},
	issn = {0167-7152},
	journal = {Statistics \& Probability Letters},
	keywords = {Exchangeable random variables, de Finetti's Theorem, Moment method},
	pages = {84-88},
	title = {An elementary proof of de Finetti's theorem},
	url = {https://www.sciencedirect.com/science/article/pii/S0167715219300902},
	volume = {151},
	year = {2019},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0167715219300902},
	bdsk-url-2 = {https://doi.org/10.1016/j.spl.2019.03.014}}
@book{Castillo2024,
  author = {Ismaël Castillo},
  year = {2024},
  title = {Bayesian Nonparametric Statistics},
  series = {École d’Été de Probabilités de Saint-Flour LI - 2023},
  volume = {},
  edition = {},
  url = {https://doi.org/10.1007/978-3-031-74035-0},
  publisher = {Springer Cham}
}
@article{Ferguson1973,
 ISSN = {00905364},
 URL = {http://www.jstor.org/stable/2958008},
 author = {Thomas S. Ferguson},
 journal = {The Annals of Statistics},
 number = {2},
 pages = {209--230},
 publisher = {Institute of Mathematical Statistics},
 title = {A Bayesian Analysis of Some Nonparametric Problems},
 urldate = {2024-07-01},
 volume = {1},
 year = {1973}
}
@article{Freedman1963,
author = {David A. Freedman},
title = {{On the Asymptotic Behavior of Bayes' Estimates in the Discrete Case}},
volume = {34},
journal = {The Annals of Mathematical Statistics},
number = {4},
publisher = {Institute of Mathematical Statistics},
pages = {1386 -- 1403},
year = {1963},
doi = {10.1214/aoms/1177703871},
URL = {https://doi.org/10.1214/aoms/1177703871}
}
@article{Fabius1964,
author = {J. Fabius},
title = {{Asymptotic Behavior of Bayes' Estimates}},
volume = {35},
journal = {The Annals of Mathematical Statistics},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {846 -- 856},
year = {1964},
doi = {10.1214/aoms/1177703584},
URL = {https://doi.org/10.1214/aoms/1177703584}
}
@article{Lavine1992,
author = {Michael Lavine},
title = {{Some Aspects of Polya Tree Distributions for Statistical Modelling}},
volume = {20},
journal = {The Annals of Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {1222 -- 1235},
keywords = {Dirichlet processes, nonparametric Bayes, tailfree processes},
year = {1992},
doi = {10.1214/aos/1176348767},
URL = {https://doi.org/10.1214/aos/1176348767}
}
@article{Mauldin+1992,
author = {R. Daniel Mauldin and William D. Sudderth and S. C. Williams},
title = {{Polya Trees and Random Distributions}},
volume = {20},
journal = {The Annals of Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {1203 -- 1221},
keywords = {Derechlet distributions, Polya urns, Prior distributions, Random measures},
year = {1992},
doi = {10.1214/aos/1176348766},
URL = {https://doi.org/10.1214/aos/1176348766}
}
@article{Castillo2017,
author = {Isma{\"e}l Castillo},
title = {{Pólya tree posterior distributions on densities}},
volume = {53},
journal = {Annales de l'Institut Henri Poincaré, Probabilités et Statistiques},
number = {4},
publisher = {Institut Henri Poincaré},
pages = {2074 -- 2102},
keywords = {Bayesian Donsker theorem, Bayesian nonparametrics, Bernstein–von Mises theorem, Minimax rate, Pólya tree distribution, Supremum norm convergence},
year = {2017},
doi = {10.1214/16-AIHP784},
URL = {https://doi.org/10.1214/16-AIHP784}
}
@article{荒木信一2019,
  title={III．DKD重症化予防のための集学的治療},
  author={荒木信一},
  journal={日本内科学会雑誌},
  volume={108},
  number={5},
  pages={916-922},
  year={2019},
  doi={10.2169/naika.108.916}
}

@article{Araki2018,
	abstract = {Diabetic kidney disease (DKD) in patients with type 2 diabetes mellitus is a leading cause of end-stage renal disease worldwide. An increase in the severity of albuminuria and a decrease in the glomerular filtration rate, by which the DKD stages are categorized, are associated with higher risks of not only end-stage renal disease but also all-cause mortality and cardiovascular mortality. Thus, an optimal management strategy and adequate assessment of therapeutic success are of great clinical and societal relevance to improve the prognosis in patients with type 2 diabetes mellitus and DKD. At present, comprehensive risk management for glycemia, blood pressure, lipid profile, and lifestyle habits is emphasized with respect to cardio-renal protection, rather than one single risk management approach. However, the pharmacological therapy aiming at strict control of these risk factors may be associated with an increased risk of adverse effects, particularly in older adults with diabetes. Accordingly, in the clinical practice of diabetes care, we need to individualize the treatment goals for each risk factor according to the health and social status of each patient with type 2 diabetes mellitus and DKD.},
	author = {Araki, Shin-ichi},
	date = {2018/05/01},
	date-added = {2024-12-25 21:04:15 +0900},
	date-modified = {2024-12-25 21:04:15 +0900},
	doi = {10.1007/s13340-018-0351-5},
	id = {Araki2018},
	isbn = {2190-1686},
	journal = {Diabetology International},
	number = {2},
	pages = {100--107},
	title = {Comprehensive risk management of diabetic kidney disease in patients with type 2 diabetes mellitus},
	url = {https://doi.org/10.1007/s13340-018-0351-5},
	volume = {9},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1007/s13340-018-0351-5}}

@article{Oellgaard+2017,
	annote = {doi: 10.1016/j.kint.2016.11.023},
	author = {Oellgaard, Jens and G{\ae}de, Peter and Rossing, Peter and Persson, Frederik and Parving, Hans-Henrik and Pedersen, Oluf},
	date = {2017/04/01},
	date-added = {2024-12-25 21:13:07 +0900},
	date-modified = {2024-12-25 21:13:07 +0900},
	doi = {10.1016/j.kint.2016.11.023},
	isbn = {0085-2538},
	journal = {Kidney International},
	journal1 = {Kidney International},
	month = {2024/12/25},
	number = {4},
	pages = {982--988},
	publisher = {Elsevier},
	title = {Intensified multifactorial intervention in type 2 diabetics with microalbuminuria leads to long-term renal benefits},
	type = {doi: 10.1016/j.kint.2016.11.023},
	url = {https://doi.org/10.1016/j.kint.2016.11.023},
	volume = {91},
	year = {2017},
	year1 = {2017},
	bdsk-url-1 = {https://doi.org/10.1016/j.kint.2016.11.023}}

@InProceedings{Lopez-Paz+2013,
  title = 	 {Gaussian Process Vine Copulas for Multivariate Dependence},
  author = 	 {Lopez-Paz, David and Hernández-Lobato, Jose Miguel and Zoubin, Ghahramani},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
  pages = 	 {10--18},
  year = 	 {2013},
  editor = 	 {Dasgupta, Sanjoy and McAllester, David},
  volume = 	 {28},
  number =       {2},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Atlanta, Georgia, USA},
  month = 	 {17--19 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v28/lopez-paz13.pdf},
  url = 	 {https://proceedings.mlr.press/v28/lopez-paz13.html},
  abstract = 	 {Copulas allow to learn marginal distributions separately from the multivariate dependence structure (copula) that links them together into a density function.  Vine factorizations ease the learning of high-dimensional copulas by constructing a hierarchy of conditional bivariate copulas. However, to simplify inference, it is common to assume that each of these conditional bivariate copulas is independent from its conditioning variables.  In this paper, we relax this assumption by discovering the latent functions that specify the shape of a conditional copula given its conditioning variables.  We learn these functions by following a Bayesian approach based on sparse Gaussian processes with expectation propagation for scalable, approximate inference. Experiments on real-world datasets show that, when modeling all conditional dependencies, we obtain better estimates of the underlying copula of the data.}
}
@article{Stephens2000,
author = {Matthew Stephens},
title = {{Bayesian analysis of mixture models with an unknown number of components—an alternative to reversible jump methods}},
volume = {28},
journal = {The Annals of Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {40 -- 74},
keywords = {Bayesian analysis, birth-death process, Markov process, MCMC, mixture model, model choice, Reversible jump, spatial point process},
year = {2000},
doi = {10.1214/aos/1016120364},
URL = {https://doi.org/10.1214/aos/1016120364}
}
@article{Cappe+2003,
    author = {Cappé, Olivier and Robert, Christian P. and Rydén, Tobias},
    title = {Reversible Jump, Birth-and-Death and More General Continuous Time Markov Chain Monte Carlo Samplers},
    journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
    volume = {65},
    number = {3},
    pages = {679-700},
    year = {2003},
    month = {07},
    abstract = { Reversible jump methods are the most commonly used Markov chain Monte Carlo tool for exploring variable dimension statistical models. Recently, however, an alternative approach based on birth-and-death processes has been proposed by Stephens for mixtures of distributions. We show that the birth-and-death setting can be generalized to include other types of continuous time jumps like split-and-combine moves in the spirit of Richardson and Green. We illustrate these extensions both for mixtures of distributions and for hidden Markov models. We demonstrate the strong similarity of reversible jump and continuous time methodologies by showing that, on appropriate rescaling of time, the reversible jump chain converges to a limiting continuous time birth-and-death process. A numerical comparison in the setting of mixtures of distributions highlights this similarity.},
    issn = {1369-7412},
    doi = {10.1111/1467-9868.00409},
    url = {https://doi.org/10.1111/1467-9868.00409},
    eprint = {https://academic.oup.com/jrsssb/article-pdf/65/3/679/49795366/jrsssb\_65\_3\_679.pdf},
}
@article{Carlin-Polson1991,
 ISSN = {03195724},
 URL = {http://www.jstor.org/stable/3315430},
 abstract = {A Bayesian approach to modeling a rich class of nonconjugate problems is presented. An adaptive Monte Carlo integration technique known as the Gibbs sampler is proposed as a mechanism for implementing a conceptually and computationally simple solution in such a framework. The result is a general strategy for obtaining marginal posterior densities under changing specification of the model error densities and related prior densities. We illustrate the approach in a nonlinear regression setting, comparing the merits of three candidate error distributions. /// Une approche bayesienne est présentée afin d'aborder une classe étendue de problèmes du type non conjugué. Une technique adaptative d'intégration Monte Carlo, l'échantillonneur de Gibbs, est proposée; elle apporte une solution simple tant du point de vue conceptuel que du point de vue calculatoire. Le résultat procure une stratégie générale dans le but d'obtenir des densités a posteriori marginales lorsque les lois des erreurs, et les lois a priori correspondantes, sont altérées. L'approche est illustrée dans un contexte de régression non linéaire où les mérites de trois lois pour les erreurs sont comparés.},
 author = {Bradley P. Carlin and Nicholas G. Polson},
 journal = {The Canadian Journal of Statistics / La Revue Canadienne de Statistique},
 number = {4},
 pages = {399--405},
 publisher = {[Statistical Society of Canada, Wiley]},
 title = {Inference for Nonconjugate Bayesian Models Using the Gibbs Sampler},
 urldate = {2024-12-28},
 volume = {19},
 year = {1991}
}

@article{Chib1995,
	annote = {doi: 10.1080/01621459.1995.10476635},
	author = {Chib ,Siddhartha},
	date = {1995/12/01},
	date-added = {2024-12-28 21:25:00 +0900},
	date-modified = {2024-12-28 21:25:00 +0900},
	doi = {10.1080/01621459.1995.10476635},
	isbn = {0162-1459},
	journal = {Journal of the American Statistical Association},
	journal1 = {Journal of the American Statistical Association},
	journal2 = {Journal of the American Statistical Association},
	month = {12},
	number = {432},
	pages = {1313--1321},
	publisher = {ASA Website},
	title = {Marginal Likelihood from the Gibbs Output},
	type = {doi: 10.1080/01621459.1995.10476635},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1995.10476635},
	volume = {90},
	year = {1995},
	year1 = {1995},
	bdsk-url-1 = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1995.10476635},
	bdsk-url-2 = {https://doi.org/10.1080/01621459.1995.10476635}}

@article{Han-Carlin2001,
	annote = {doi: 10.1198/016214501753208780},
	author = {Han ,Cong and Carlin ,Bradley P},
	date = {2001/09/01},
	date-added = {2024-12-28 21:26:23 +0900},
	date-modified = {2024-12-28 21:26:23 +0900},
	doi = {10.1198/016214501753208780},
	isbn = {0162-1459},
	journal = {Journal of the American Statistical Association},
	journal1 = {Journal of the American Statistical Association},
	journal2 = {Journal of the American Statistical Association},
	month = {09},
	number = {455},
	pages = {1122--1132},
	publisher = {ASA Website},
	title = {Markov Chain Monte Carlo Methods for Computing Bayes Factors},
	type = {doi: 10.1198/016214501753208780},
	url = {https://doi.org/10.1198/016214501753208780},
	volume = {96},
	year = {2001},
	year1 = {2001},
	bdsk-url-1 = {https://doi.org/10.1198/016214501753208780}}
@article{Carlin-Chib1995,
    author = {Carlin, Bradley P. and Chib, Siddhartha},
    title = {Bayesian Model Choice Via Markov Chain Monte Carlo Methods},
    journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
    volume = {57},
    number = {3},
    pages = {473-484},
    year = {1995},
    month = {12},
    abstract = {Markov chain Monte Carlo (MCMC) integration methods enable the fitting of models of virtually unlimited complexity, and as such have revolutionized the practice of Bayesian data analysis. However, comparison across models may not proceed in a completely analogous fashion, owing to violations of the conditions sufficient to ensure convergence of the Markov chain. In this paper we present a framework for Bayesian model choice, along with an MCMC algorithm that does not suffer from convergence difficulties. Our algorithm applies equally well to problems where only one model is contemplated but its proper size is not known at the outset, such as problems involving integer-valued parameters, multiple changepoints or finite mixture distributions. We illustrate our approach with two published examples.},
    issn = {0035-9246},
    doi = {10.1111/j.2517-6161.1995.tb02042.x},
    url = {https://doi.org/10.1111/j.2517-6161.1995.tb02042.x},
    eprint = {https://academic.oup.com/jrsssb/article-pdf/57/3/473/49100124/jrsssb\_57\_3\_473.pdf},
}



@article{Godsill2001,
	annote = {doi: 10.1198/10618600152627924},
	author = {Godsill ,Simon J},
	date = {2001/06/01},
	date-added = {2024-12-28 21:53:00 +0900},
	date-modified = {2024-12-28 21:53:00 +0900},
	doi = {10.1198/10618600152627924},
	isbn = {1061-8600},
	journal = {Journal of Computational and Graphical Statistics},
	journal1 = {Journal of Computational and Graphical Statistics},
	journal2 = {Journal of Computational and Graphical Statistics},
	month = {06},
	number = {2},
	pages = {230--248},
	publisher = {ASA Website},
	title = {On the Relationship Between Markov chain Monte Carlo Methods for Model Uncertainty},
	type = {doi: 10.1198/10618600152627924},
	url = {https://doi.org/10.1198/10618600152627924},
	volume = {10},
	year = {2001},
	year1 = {2001},
	bdsk-url-1 = {https://doi.org/10.1198/10618600152627924}}
@article{Hoeting+1999,
author = {Jennifer A. Hoeting and David Madigan and Adrian E. Raftery and Chris T. Volinsky},
title = {{Bayesian model averaging: a tutorial (with comments by M. Clyde, David Draper and E. I. George, and a rejoinder by the authors}},
volume = {14},
journal = {Statistical Science},
number = {4},
publisher = {Institute of Mathematical Statistics},
pages = {382 -- 417},
keywords = {Bayesian graphical models, Bayesian model averaging, learning, Markov chain Monte Carlo, model uncertainty},
year = {1999},
doi = {10.1214/ss/1009212519},
URL = {https://doi.org/10.1214/ss/1009212519}
}
@book{Hastie+2015,
  author = {Trevor Hastie and Robert Tibshirani and Martin Wainwright},
  year = {2015},
  title = {Statistical Learning with Sparsity: The Lasso and Generalizations},
  series = {},
  volume = {},
  edition = {},
  url = {https://doi.org/10.1201/b18401},
  publisher = {Chapman and Hall/CRC}
}
@article{George-McCulloch1997,
 ISSN = {10170405, 19968507},
 URL = {http://www.jstor.org/stable/24306083},
 abstract = {This paper describes and compares various hierarchical mixture prior formulations of variable selection uncertainty in normal linear regression models. These include the nonconjugate SSVS formulation of George and McCulloch (1993), as well as conjugate formulations which allow for analytical simplification. Hyperparameter settings which base selection on practical significance, and the implications of using mixtures with point priors are discussed. Computational methods for posterior evaluation and exploration are considered. Rapid updating methods are seen to provide feasible methods for exhaustive evaluation using Gray Code sequencing in moderately sized problems, and fast Markov Chain Monte Carlo exploration in large problems. Estimation of normalization constants is seen to provide improved posterior estimates of individual model probabilities and the total visited probability. Various procedures are illustrated on simulated sample problems and on a real problem concerning the construction of financial index tracking portfolios.},
 author = {Edward I. George and Robert E. McCulloch},
 journal = {Statistica Sinica},
 number = {2},
 pages = {339--373},
 publisher = {Institute of Statistical Science, Academia Sinica},
 title = {APPROACHES FOR BAYESIAN VARIABLE SELECTION},
 urldate = {2024-12-28},
 volume = {7},
 year = {1997}
}
@article{Bhadra+2019,
author = {Anindya Bhadra and Jyotishka Datta and Nicholas G. Polson and Brandon Willard},
title = {{Lasso Meets Horseshoe: A Survey}},
volume = {34},
journal = {Statistical Science},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {405 -- 427},
keywords = {Global-local priors, horseshoe, horseshoe+, hyper-parameter tuning, Lasso, regression, regularization, Sparsity},
year = {2019},
doi = {10.1214/19-STS700},
URL = {https://doi.org/10.1214/19-STS700}
}
@misc{Griffin2024,
      title={Expressing and visualizing model uncertainty in Bayesian variable selection using Cartesian credible sets}, 
      author={Jim E. Griffin},
      year={2024},
      eprint={2402.12323},
      archivePrefix={arXiv},
      primaryClass={stat.ME},
      url={https://arxiv.org/abs/2402.12323}, 
}
@article{Porwal-Raftery2022,
author = {Anupreet Porwal  and Adrian E. Raftery},
title = {Comparing methods for statistical inference with model uncertainty},
journal = {Proceedings of the National Academy of Sciences},
volume = {119},
number = {16},
pages = {e2120737119},
year = {2022},
doi = {10.1073/pnas.2120737119},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.2120737119},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.2120737119},
abstract = {Choosing a statistical model and accounting for uncertainty about this choice are important parts of the scientific process and are required for common statistical tasks such as parameter estimation, interval estimation, statistical inference, point prediction, and interval prediction. A canonical example is the choice of variables in a linear regression model. Many ways of doing this have been proposed, including Bayesian and penalized regression methods, and it is not clear which are best. We compare 21 popular methods via an extensive simulation study based on a wide range of real datasets. We found that three adaptive Bayesian model averaging methods performed best across all the statistical tasks and that two of these were also among the most computationally efficient. Probability models are used for many statistical tasks, notably parameter estimation, interval estimation, inference about model parameters, point prediction, and interval prediction. Thus, choosing a statistical model and accounting for uncertainty about this choice are important parts of the scientific process. Here we focus on one such choice, that of variables to include in a linear regression model. Many methods have been proposed, including Bayesian and penalized likelihood methods, and it is unclear which one to use. We compared 21 of the most popular methods by carrying out an extensive set of simulation studies based closely on real datasets that span a range of situations encountered in practical data analysis. Three adaptive Bayesian model averaging (BMA) methods performed best across all statistical tasks. These used adaptive versions of Zellner’s g-prior for the parameters, where the prior variance parameter g is a function of sample size or is estimated from the data. We found that for BMA methods implemented with Markov chain Monte Carlo, 10,000 iterations were enough. Computationally, we found two of the three best methods (BMA with g=n and empirical Bayes-local) to be competitive with the least absolute shrinkage and selection operator (LASSO), which is often preferred as a variable selection technique because of its computational efficiency. BMA performed better than Bayesian model selection (in which just one model is selected).}}
@article{Castillo+2015,
author = {Isma{\"e}l Castillo and Johannes Schmidt-Hieber and Aad van der Vaart},
title = {{Bayesian linear regression with sparse priors}},
volume = {43},
journal = {The Annals of Statistics},
number = {5},
publisher = {Institute of Mathematical Statistics},
pages = {1986 -- 2018},
keywords = {Bayesian inference, Sparsity},
year = {2015},
doi = {10.1214/15-AOS1334},
URL = {https://doi.org/10.1214/15-AOS1334}
}
@article{West1987,
    author = {Mike West},
    title = {On scale mixtures of normal distributions},
    journal = {Biometrika},
    volume = {74},
    number = {3},
    pages = {646-648},
    year = {1987},
    month = {09},
    abstract = {The exponential power family of distributions of Box \&amp; Tiao (1973) is shown to be a subset of the class of scale mixtures of normals. The corresponding mixing distributions are explicitly obtained, identifying a close relationship between the exponential power family and a further class of normal scale mixtures, namely the stable distributions.},
    issn = {0006-3444},
    doi = {10.1093/biomet/74.3.646},
    url = {https://doi.org/10.1093/biomet/74.3.646},
    eprint = {https://academic.oup.com/biomet/article-pdf/74/3/646/656269/74-3-646.pdf},
}

@incollection{Polson-Scott2011,
    author = {Polson, Nicholas G. and Scott, James G.},
    isbn = {9780199694587},
    title = {501Shrink Globally, Act Locally: Sparse Bayesian Regularization and Prediction},
    booktitle = {Bayesian Statistics 9},
    publisher = {Oxford University Press},
    year = {2011},
    month = {10},
    abstract = {We study the classic problem of choosing a prior distribution for a location parameter β = (β  1,…, β  p) as p grows large. First, we study the standard “global‐local shrinkage” approach, based on scale mixtures of normals. Two theorems are presented which characterize certain desirable properties of shrinkage priors for sparse problems. Next, we review some recent results showing how Lévy processes can be used to generate infinite‐dimensional versions of standard normal scale‐mixture priors, along with new priors that have yet to be seriously studied in the literature. This approach provides an intuitive framework both for generating new regularization penalties and shrinkage rules, and for performing asymptotic analysis on existing models.},
    doi = {10.1093/acprof:oso/9780199694587.003.0017},
    url = {https://doi.org/10.1093/acprof:oso/9780199694587.003.0017},
    eprint = {https://academic.oup.com/book/0/chapter/141655378/chapter-ag-pdf/45229839/book\_1879\_section\_141655378.ag.pdf},
}

@article{Hans2011,
	annote = {doi: 10.1198/jasa.2011.tm09241},
	author = {Hans ,Chris},
	date = {2011/12/01},
	date-added = {2024-12-29 13:41:47 +0900},
	date-modified = {2024-12-29 13:41:47 +0900},
	doi = {10.1198/jasa.2011.tm09241},
	isbn = {0162-1459},
	journal = {Journal of the American Statistical Association},
	journal1 = {Journal of the American Statistical Association},
	journal2 = {Journal of the American Statistical Association},
	month = {12},
	number = {496},
	pages = {1383--1393},
	publisher = {ASA Website},
	title = {Elastic Net Regression Modeling With the Orthant Normal Prior},
	type = {doi: 10.1198/jasa.2011.tm09241},
	url = {https://doi.org/10.1198/jasa.2011.tm09241},
	volume = {106},
	year = {2011},
	year1 = {2011},
	bdsk-url-1 = {https://doi.org/10.1198/jasa.2011.tm09241}}
@article{Hans2009,
 ISSN = {00063444, 14643510},
 URL = {http://www.jstor.org/stable/27798870},
 abstract = {The lasso estimate for linear regression corresponds to a posterior mode when independent, double-exponential prior distributions are placed on the regression coefficients. This paper introduces new aspects of the broader Bayesian treatment of lasso regression. A direct characterization of the regression coefficients' posterior distribution is provided, and computation and inference under this characterization is shown to be straightforward. Emphasis is placed on point estimation using the posterior mean, which facilitates prediction of future observations via the posterior predictive distribution. It is shown that the standard lasso prediction method does not necessarily agree with model-based, Bayesian predictions. A new Gibbs sampler for Bayesian lasso regression is introduced.},
 author = {Chris Hans},
 journal = {Biometrika},
 number = {4},
 pages = {835--845},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {Bayesian lasso regression},
 urldate = {2024-12-28},
 volume = {96},
 year = {2009}
}
@article{Tibshirani1996,
    author = {Tibshirani, Robert},
    title = {Regression Shrinkage and Selection Via the Lasso},
    journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
    volume = {58},
    number = {1},
    pages = {267-288},
    year = {1996},
    month = {12},
    abstract = {We propose a new method for estimation in linear models. The ‘lasso’ minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.},
    issn = {0035-9246},
    doi = {10.1111/j.2517-6161.1996.tb02080.x},
    url = {https://doi.org/10.1111/j.2517-6161.1996.tb02080.x},
    eprint = {https://academic.oup.com/jrsssb/article-pdf/58/1/267/49098631/jrsssb\_58\_1\_267.pdf},
}

@article{Ishwaran-Rao2005,
author = {Hemant Ishwaran and J. Sunil Rao},
title = {{Spike and slab variable selection: Frequentist and Bayesian strategies}},
volume = {33},
journal = {The Annals of Statistics},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {730 -- 773},
keywords = {Generalized ridge regression, hypervariance, model averaging, model uncertainty, ordinary least squares, Penalization, rescaling, shrinkage, stochastic variable selection, Zcut},
year = {2005},
doi = {10.1214/009053604000001147},
URL = {https://doi.org/10.1214/009053604000001147}
}
@article{Piironen+2020,
author = {Juho Piironen and Markus Paasiniemi and Aki Vehtari},
title = {{Projective inference in high-dimensional problems: Prediction and feature selection}},
volume = {14},
journal = {Electronic Journal of Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics and Bernoulli Society},
pages = {2155 -- 2197},
keywords = {Feature selection, Post-selection inference, prediction, projection, Sparsity},
year = {2020},
doi = {10.1214/20-EJS1711},
URL = {https://doi.org/10.1214/20-EJS1711}
}
@article{Li-Dutta-Roy2023,
author = {Dongjin Li, Somak Dutta and Vivekananda Roy},
title = {Model Based Screening Embedded Bayesian Variable Selection for Ultra-high Dimensional Settings},
journal = {Journal of Computational and Graphical Statistics},
volume = {32},
number = {1},
pages = {61--73},
year = {2023},
publisher = {ASA Website},
doi = {10.1080/10618600.2022.2074428},
URL = {https://doi.org/10.1080/10618600.2022.2074428}}
@article{Smith-Gelfand1992,
 ISSN = {00031305},
 URL = {http://www.jstor.org/stable/2684170},
 abstract = {Even to the initiated, statistical calculations based on Bayes's Theorem can be daunting because of the numerical integrations required in all but the simplest applications. Moreover, from a teaching perspective, introductions to Bayesian statistics-if they are given at all-are circumscribed by these apparent calculational difficulties. Here we offer a straightforward sampling-resampling perspective on Bayesian inference, which has both pedagogic appeal and suggests easily implemented calculation strategies.},
 author = {A. F. M. Smith and A. E. Gelfand},
 journal = {The American Statistician},
 number = {2},
 pages = {84--88},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Bayesian Statistics without Tears: A Sampling-Resampling Perspective},
 urldate = {2024-12-29},
 volume = {46},
 year = {1992}
}
@book{Ripley1987,
  author = {Brian D. Ripley},
  year = {1987},
  title = {Stochastic Simulation},
  series = {Wiley Series in Probability and Statistics},
  volume = {},
  edition = {},
  doi = {10.1002/9780470316726},
  publisher = {John Wiley \& Sons}
}
@article{Zanella-Roberts2019,
    author = {Zanella, Giacomo and Roberts, Gareth},
    title = {Scalable Importance Tempering and Bayesian Variable Selection},
    journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
    volume = {81},
    number = {3},
    pages = {489-517},
    year = {2019},
    month = {03},
    abstract = {We propose a Monte Carlo algorithm to sample from high dimensional probability distributions that combines Markov chain Monte Carlo and importance sampling. We provide a careful theoretical analysis, including guarantees on robustness to high dimensionality, explicit comparison with standard Markov chain Monte Carlo methods and illustrations of the potential improvements in efficiency. Simple and concrete intuition is provided for when the novel scheme is expected to outperform standard schemes. When applied to Bayesian variable-selection problems, the novel algorithm is orders of magnitude more efficient than available alternative sampling schemes and enables fast and reliable fully Bayesian inferences with tens of thousand regressors.},
    issn = {1369-7412},
    doi = {10.1111/rssb.12316},
    url = {https://doi.org/10.1111/rssb.12316},
    eprint = {https://academic.oup.com/jrsssb/article-pdf/81/3/489/49269619/jrsssb\_81\_3\_489.pdf},
}
@article{Brown+1998,
author = {Brown, P. J. and Vannucci, M. and Fearn, T.},
title = {Bayesian wavelength selection in multicomponent analysis},
journal = {Journal of Chemometrics},
volume = {12},
number = {3},
pages = {173-182},
keywords = {multivariate regression, Bayesian wavelength selection, Markov chain Monte Carlo (MCMC), Metropolis algorithm, NIR spectroscopy, multicomponent analysis, selection bias, model averaging},
doi = {https://doi.org/10.1002/(SICI)1099-128X(199805/06)12:3<173::AID-CEM505>3.0.CO;2-0},
url = {https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291099-128X%28199805/06%2912%3A3%3C173%3A%3AAID-CEM505%3E3.0.CO%3B2-0},
eprint = {https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/pdf/10.1002/%28SICI%291099-128X%28199805/06%2912%3A3%3C173%3A%3AAID-CEM505%3E3.0.CO%3B2-0},
abstract = {Abstract Multicomponent analysis attempts to simultaneously predict the ingredients of a mixture. If near-infrared spectroscopy provides the predictor variables, then modern scanning instruments may offer absorbances at a very large number of wavelengths. Although it is perfectly possible to use whole spectrum methods (e.g. PLS, ridge and principal component regression), for a number of reasons it is often desirable to select a small number of wavelengths from which to construct the prediction equation relating absorbances to composition. This paper considers wavelength selection with a view to using the chosen wavelengths to simultaneously predict the compositional ingredients and is therefore an example of multivariate variable selection. It adopts a binary exclusion/inclusion latent variable formulation of selection and uses a Bayesian approach. Problems of search of the vast number of possible selected models are overcome by a Markov chain Monte Carlo sampling technique. © 1998 John Wiley \& Sons, Ltd.},
year = {1998}
}
@article{Yang+2016,
author = {Yun Yang and Martin J. Wainwright and Michael I. Jordan},
title = {{On the computational complexity of high-dimensional Bayesian variable selection}},
volume = {44},
journal = {The Annals of Statistics},
number = {6},
publisher = {Institute of Mathematical Statistics},
pages = {2497 -- 2532},
keywords = {Bayesian variable selection, high-dimensional inference, Markov chain, rapid mixing, spectral gap},
year = {2016},
doi = {10.1214/15-AOS1417},
URL = {https://doi.org/10.1214/15-AOS1417}
}
@article{Tierney1998,
 ISSN = {10505164},
 URL = {http://www.jstor.org/stable/2667233},
 abstract = {The Metropolis-Hastings algorithm is a method of constructing a reversible Markov transition kernel with a specified invariant distribution. This note describes necessary and sufficient conditions on the candidate generation kernel and the acceptance probability function for the resulting transition kernel and invariant distribution to satisfy the detailed balance conditions. A simple general formulation is used that covers a range of special cases treated separately in the literature. In addition, results on a useful partial ordering of finite state space reversible transition kernels are extended to general state spaces and used to compare the performance of two approaches to using mixtures in Metropolis-Hastings kernels.},
 author = {Luke Tierney},
 journal = {The Annals of Applied Probability},
 number = {1},
 pages = {1--9},
 publisher = {Institute of Mathematical Statistics},
 title = {A Note on Metropolis-Hastings Kernels for General State Spaces},
 urldate = {2024-12-29},
 volume = {8},
 year = {1998}
}
@article{Zhou+2022,
    author = {Zhou, Quan and Yang, Jun and Vats, Dootika and Roberts, Gareth O. and Rosenthal, Jeffrey S.},
    title = {Dimension-Free Mixing for High-Dimensional Bayesian Variable Selection},
    journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
    volume = {84},
    number = {5},
    pages = {1751-1784},
    year = {2022},
    month = {10},
    abstract = {Yang et al. proved that the symmetric random walk Metropolis–Hastings algorithm for Bayesian variable selection is rapidly mixing under mild high-dimensional assumptions. We propose a novel Markov chain Monte Carlo (MCMC) sampler using an informed proposal scheme, which we prove achieves a much faster mixing time that is independent of the number of covariates, under the assumptions of Yang et al. To the best of our knowledge, this is the first high-dimensional result which rigorously shows that the mixing rate of informed MCMC methods can be fast enough to offset the computational cost of local posterior evaluation. Motivated by the theoretical analysis of our sampler, we further propose a new approach called ‘two-stage drift condition’ to studying convergence rates of Markov chains on general state spaces, which can be useful for obtaining tight complexity bounds in high-dimensional settings. The practical advantages of our algorithm are illustrated by both simulation studies and real data analysis.},
    issn = {1369-7412},
    doi = {10.1111/rssb.12546},
    url = {https://doi.org/10.1111/rssb.12546},
    eprint = {https://academic.oup.com/jrsssb/article-pdf/84/5/1751/49458965/jrsssb\_84\_5\_1751.pdf},
}
@misc{Ding2024LinearModels,
      title={Linear Model and Extensions}, 
      author={Peng Ding},
      year={2024},
      eprint={2401.00649},
      archivePrefix={arXiv},
      primaryClass={stat.ME},
      url={https://arxiv.org/abs/2401.00649}, 
}
@inbook{McFadden1974,
  author = {Daniel McFadden},
  chapter = {Conditional Logit Analysis of Qualitative Choice Behavior},
  editor = {P. Zarembka},
  pages = {105-142},
  publisher = {Academic Press},
  title = {Frontiers in Econometrics},
  year = {1974},
  url = {https://eml.berkeley.edu/reprints/mcfadden/zarembka.pdf},
}
@article{Yule1907,
author = {Yule, George Udny},
title = {On the theory of correlation for any number of variables, treated by a new system of notation},
journal = {Proceedings of the Royal Society of London. Series A, Containing Papers of a Mathematical and Physical Character},
volume = {79},
number = {529},
pages = {182-193},
year = {1907},
doi = {10.1098/rspa.1907.0028},
URL = {https://royalsocietypublishing.org/doi/abs/10.1098/rspa.1907.0028},
eprint = {https://royalsocietypublishing.org/doi/pdf/10.1098/rspa.1907.0028}
}
@TechReport{Lovell1963,
  author={Michael C. Lovell},
  title={{Seasonal Adjustment of Economic Time Series and Multiple Regression}},
  year=1963,
  month=,
  institution={Cowles Foundation for Research in Economics, Yale University},
  type={Cowles Foundation Discussion Papers},
  url={https://ideas.repec.org/p/cwl/cwldpp/151.html},
  number={151},
  abstract={After demonstrating that any nontrivial technique for seasonally adjusting time series inevitably leads to certain distortions of the data, an effort is made to provide explicit motivation for the process of seasonal adjustment for purposes of appraising current economic conditions. Inherent advantages in terms of certain consistency requirements of a least square procedure for seasonal adjustment are pointed out. Problems encountered by the econometrician when seasonally adjusted time series are to be employed in regression analysis are also explored. The dummy variable technique for dealing with seasonal fluctuations is generalized to encompass a flexible pattern of seasonal movement. It is argued that when seasonally adjusted data rather than the dummy variable procedure are employed, there is an inherent tendency to overstate the significance of regression coefficients; a correction procedure is suggested. Consideration is given to certain special problems created by autocorrelated residuals when seasonally adjusted data are utilized in regression analysis.},
  keywords={},
  doi={},
}
@article{Frisch-Waugh1933,
 ISSN = {00129682, 14680262},
 URL = {http://www.jstor.org/stable/1907330},
 author = {Ragnar Frisch and Frederick V. Waugh},
 journal = {Econometrica},
 number = {4},
 pages = {387--401},
 publisher = {[Wiley, Econometric Society]},
 title = {Partial Time Regressions as Compared with Individual Trends},
 urldate = {2024-12-29},
 volume = {1},
 year = {1933}
}
@article{Cochran1938,
 ISSN = {14666162},
 URL = {http://www.jstor.org/stable/2983654},
 author = {W. G. Cochran},
 journal = {Supplement to the Journal of the Royal Statistical Society},
 number = {2},
 pages = {171--176},
 publisher = {[Oxford University Press, Royal Statistical Society]},
 title = {The Omission or Addition of an Independent Variate in Multiple Linear Regression},
 urldate = {2024-12-29},
 volume = {5},
 year = {1938}
}
@article{Simpson1951,
 ISSN = {00359246},
 URL = {http://www.jstor.org/stable/2984065},
 abstract = {The definition of second order interaction in a (2 × 2 × 2) table given by Bartlett is accepted, but it is shown by an example that the vanishing of this second order interaction does not necessarily justify the mechanical procedure of forming the three component 2 × 2 tables and testing each of these for significance by standard methods.},
 author = {E. H. Simpson},
 journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 number = {2},
 pages = {238--241},
 publisher = {[Royal Statistical Society, Oxford University Press]},
 title = {The Interpretation of Interaction in Contingency Tables},
 urldate = {2024-12-29},
 volume = {13},
 year = {1951}
}
@article{White1980,
 ISSN = {00129682, 14680262},
 URL = {http://www.jstor.org/stable/1912934},
 abstract = {This paper presents a parameter covariance matrix estimator which is consistent even when the disturbances of a linear regression model are heteroskedastic. This estimator does not depend on a formal model of the structure of the heteroskedasticity. By comparing the elements of the new estimator to those of the usual covariance estimator, one obtains a direct test for heteroskedasticity, since in the absence of heteroskedasticity, the two estimators will be approximately equal, but will generally diverge otherwise. The test has an appealing least squares interpretation.},
 author = {Halbert White},
 journal = {Econometrica},
 number = {4},
 pages = {817--838},
 publisher = {[Wiley, Econometric Society]},
 title = {A Heteroskedasticity-Consistent Covariance Matrix Estimator and a Direct Test for Heteroskedasticity},
 urldate = {2024-12-29},
 volume = {48},
 year = {1980}
}
@inproceedings{Eicker1967,
  author = {Friedhelm Eicker},
  year = {1967},
  title = {Limit theorems for regressions with unequal and dependent errors},
  booktitle = {Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Statistics},
  volume = {1},
  pages = {59-82},
  editor = {Lucien M. Le{\ }Cam and Jerzy Neyman},
  url = {https://projecteuclid.org/proceedings/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-Fifth-Berkeley-Symposium-on-Mathematical-Statistics-and/Chapter/Limit-theorems-for-regressions-with-unequal-and-dependent-errors/bsmsp/1200512981}
}
@inproceedings{Huber1967,
  author = {Peter J. Huber},
  year = {1967},
  title = {The behavior of maximum likelihood estimates under nonstandard conditions},
  booktitle = {Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Statistics},
  volume = {1},
  pages = {221-233},
  editor = {Lucien M. Le{\ }Cam and Jerzy Neyman},
  url = {https://projecteuclid.org/proceedings/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-Fifth-Berkeley-Symposium-on-Mathematical-Statistics-and/Chapter/The-behavior-of-maximum-likelihood-estimates-under-nonstandard-conditions/bsmsp/1200512988}
}

@article{Altonji-Segal1996,
 ISSN = {07350015},
 URL = {http://www.jstor.org/stable/1392447},
 abstract = {We examine the small-sample properties of the generalized method of moments estimator applied to models of covariance structures, in which case it is commonly known as the optimal minimum distance (OMD) estimator. We find that OMD is almost always biased downward in absolute value. The bias arises because sampling errors in the second moments are correlated with sampling errors in the weighting matrix used by OMD. Furthermore, OMD is usually dominated by equally weighted minimum distance (EWMD). We also propose an alternative estimator that is unbiased and asymptotically equivalent to OMD. The Monte Carlo evidence indicates, however, that it is usually dominated by EWMD.},
 author = {Joseph G. Altonji and Lewis M. Segal},
 journal = {Journal of Business & Economic Statistics},
 number = {3},
 pages = {353--366},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Small-Sample Bias in GMM Estimation of Covariance Structures},
 urldate = {2024-12-30},
 volume = {14},
 year = {1996}
}
@article{Newey-Smith2004,
 ISSN = {00129682, 14680262},
 URL = {http://www.jstor.org/stable/3598854},
 abstract = {In an effort to improve the small sample properties of generalized method of moments (GMM) estimators, a number of alternative estimators have been suggested. These include empirical likelihood (EL), continuous updating, and exponential tilting estimators. We show that these estimators share a common structure, being members of a class of generalized empirical likelihood (GEL) estimators. We use this structure to compare their higher order asymptotic properties. We find that GEL has no asymptotic bias due to correlation of the moment functions with their Jacobian, eliminating an important source of bias for GMM in models with endogeneity. We also find that EL has no asymptotic bias from estimating the optimal weight matrix, eliminating a further important source of bias for GMM in panel data models. We give bias corrected GMM and GEL estimators. We also show that bias corrected EL inherits the higher order property of maximum likelihood, that it is higher order asymptotically efficient relative to the other bias corrected estimators.},
 author = {Whitney K. Newey and Richard J. Smith},
 journal = {Econometrica},
 number = {1},
 pages = {219--255},
 publisher = {[Wiley, Econometric Society]},
 title = {Higher Order Properties of GMM and Generalized Empirical Likelihood Estimators},
 urldate = {2024-12-30},
 volume = {72},
 year = {2004}
}
