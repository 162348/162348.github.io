<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Hirofumi Shiba</title>
<link>https://162348.github.io/blog.html</link>
<atom:link href="https://162348.github.io/blog.xml" rel="self" type="application/rss+xml"/>
<description>A Blog by a Bayesian Computation Researcher</description>
<image>
<url>https://162348.github.io/assets/categories.png</url>
<title>Hirofumi Shiba</title>
<link>https://162348.github.io/blog.html</link>
</image>
<generator>quarto-1.6.39</generator>
<lastBuildDate>Sun, 01 Dec 2024 00:00:00 GMT</lastBuildDate>
<item>
  <title>英国研究滞在記</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Life/UCL.html</link>
  <description><![CDATA[ 





<section id="はじまり" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="はじまり"><span class="header-section-number">1</span> はじまり</h2>
<div class="article-card-container">
  <blockquote class="twitter-tweet blockquote"><p lang="ja" dir="ltr">11/4 からロンドンに１ヶ月ほど滞在します。<br><br>ロンドン（広くイギリス）は自分の中ではベイズ計算の中心地の１つと目してますので大変楽しみです。 <a href="https://t.co/gaGrnnLTRl">https://t.co/gaGrnnLTRl</a></p>— Hirofumi Shiba (@ano2math5) <a href="https://twitter.com/ano2math5/status/1839560243795386756?ref_src=twsrc%5Etfw">September 27, 2024</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 
</div>
<p>11月3日から12月3日までの１ヶ月間，総研大の<a href="https://www.soken.ac.jp/education/dispatch/sokendai_studentdispatchprogram/">研究派遣プログラム</a>の援助を受けて，イギリス・ロンドンの <a href="https://en.wikipedia.org/wiki/University_College_London">UCL</a> (University College London) の Alexandros Beskos 教授を訪問した．</p>
<p>Alex は拡散過程の Monte Carlo シミュレーションや MCMC (Markov Chain Monte Carlo)，さらには SMC (Sequential Monte Carlo) と幅広い守備範囲を持つベイズ計算 (Bayesian Computation) の大家である．</p>
<p>UCL はロンドン大学 (University of London) に所属するカレッジの１つであり，「功利主義」の哲学で有名な Jeremy Bentham によって，世界で初めての性別・宗教・出自・肌の色に依らず入学できる大学として 19 世紀前半に創立された．</p>
<!--
> 当時のオックスフォード大学・ケンブリッジ大学が、男性・イギリス国教徒・貴族出身者という差別的な入学条件を設けていたのに対して、UCLはイギリスで初めて平等な基準によって女性を受け入れ、宗教・政治的思想・人種による入学差別を撤廃した。このような歴史から、UCLは自由主義・平等主義の大学として知られている。
> [Wikipedia](https://ja.wikipedia.org/wiki/%E3%83%A6%E3%83%8B%E3%83%B4%E3%82%A1%E3%83%BC%E3%82%B7%E3%83%86%E3%82%A3%E3%83%BB%E3%82%AB%E3%83%AC%E3%83%83%E3%82%B8%E3%83%BB%E3%83%AD%E3%83%B3%E3%83%89%E3%83%B3) より 

この動きには当然反動もあり，ロンドン大学の別のカレッジである King's College London が，その後すぐに男性・イギリス国教徒・貴族出身に限定された Oxford や Cambridge を踏襲する大学として設立されたという．
-->
<p>このような歴史もあり，UCL の統計の博士課程には極めて多様な背景（国籍・人種・宗教など）を持った学生が揃っている．自分はそのことが最も気に入った．Alex の学生にはイギリス出身の Chris や日本出身の井口さんがいた．他に筆者と仲良くしてくれた学生は，カナダ，ギリシャ，マレーシア，中国出身と，誰ひとり被っていなかった．</p>
<p>受入教員である Alex も元はギリシャの出身であり，滞在最後に一緒にご飯を食べたときには UCL で採用に至るまでの面接の苦労を話してくれた．</p>
<p>この多様性にみんな慣れていることもあってか，初のヨーロッパ体験に借りてきた猫状態だった自分も，滞在一週間も経たずに「馴染めた」「仲間にしてもらえた」と感じた．それにはイギリスのパブ文化の影響もあっただろう．</p>
<p>金曜日の夜にパブに行く文化があると事前に聞いていたから，勇気を出して Ph.D.&nbsp;部屋に残っていた人を誘ってみた．５時だったが部屋にはほとんど人はいなかった．UCL はロンドンの中心にあり，その近くは大変家賃が高いため，多くの生徒は郊外に住む（Oxford から通っている学生もいる）．そのため５時には大抵の学生は帰ろうとし始めるのだ．（そして寮は博士１年生しか利用できない．）</p>
<p>中でも Teresa は帰って作り置きの夕飯を食べる予定だったところを変更してまで，僕の誘いを快諾してくれた．結局メンバーは５人にまで増え，まずはピザを食べにいき，その後パブで一杯飲んだ．</p>
<p>Teresa は台湾の出身であるが，カナダの McGill 大学で数学を専攻してから UCL の統計博士課程に進み，今は同時に医局で統計スタッフとして働いてもいる．自分が「イギリスどころかヨーロッパが初めてで，パブに行ってみたいが勇気が出ない」と素直に伝えると，当時の自分の境遇と重なったこともあってか，大変歓迎して友人も誘い合わせてパブへ連れて行ってくれたのである．</p>
<p>日本の飲み屋は食事とアルコールを同時に提供するが，イギリスではその２つの機能はレストランとパブが別々に担っているのだと自分は理解した．するとパブが必然的に「二軒目」になっており，その頃にはすっかり仲間だという感じになって腹をわった話ができる．大変不思議な感覚である．</p>
</section>
<section id="研究環境" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="研究環境"><span class="header-section-number">2</span> 研究環境</h2>
<p>正直学生のレベル感は ISM とほとんど差を感じない．だが「ロンドン界隈」全体としては，総じて環境は全く違うと言わざるを得ないと感じた．</p>
<p>かの Thomas Bayes もロンドンがうんだように，イギリスでは現在もベイズの豊かな土壌があり，一週間のうちに必ずどこかではベイズ計算に関連するセミナーが開催されている．そして大変多くの人が集まるのである．この環境だけは世界の他のどこにもないだろう．</p>
<p>さらに滞在の最後に当たる 11/25（月）から 11/29（金）までの５日間，<a href="https://en.wikipedia.org/wiki/Isaac_Newton_Institute">INI</a> (Isaac Newton Institute) にてベイズ計算に特化したワークショップ <a href="https://www.newton.ac.uk/event/ssdw04/">Monte Carlo Sampling: Beyond the Diffusive Regime</a> が行われた．</p>
<div class="article-card-container">
  <blockquote class="twitter-tweet blockquote"><p lang="en" dir="ltr">I’m here! <a href="https://t.co/N4YTmmJFCo">https://t.co/N4YTmmJFCo</a></p>— Hirofumi Shiba (@ano2math5) <a href="https://twitter.com/ano2math5/status/1861151663911817696?ref_src=twsrc%5Etfw">November 25, 2024</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
<p>この INI というのが大変興味深い組織である．1992 年に Cambridge 大学の２つのカレッジ St.&nbsp;Jones と Trinity の出資により設立された数理に特化した研究施設であるが，ここにパーマネントに所属する研究者というのは原則存在せず，基本は６ヶ月ごとに入れ替わる．しかしこの６ヶ月間というのは，テーマを決めてそれに関連する研究者を世界中から呼び込み，INI という一箇所に集めての「６ヶ月」なのである．</p>
<p>私が参加したこの５日間のワークショップも，Monte Carlo 法に関する研究プログラム <a href="https://www.newton.ac.uk/event/ssd/">Stochastic systems for anomalous diffusion</a> の一環として開催されている．このワークショップの参加者も，希望すれば一定期間オフィスをもらい，ワークショップの前後に渡って滞在することができる．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Life/Images/INI.jpeg" class="img-fluid figure-img"></p>
<figcaption>INI 最上階からの写真．写真左手前が Alex である．</figcaption>
</figure>
</div>
<p>INI にはありとあらゆるところに黒板が用意されている．トイレの中にもある．そのことがこんなにも違いを生むとは思わなかった．参加者は年齢に依らず，休み時間になると活発に議論をした．</p>
<div class="article-card-container">
  <blockquote class="twitter-tweet blockquote"><p lang="en" dir="ltr">Even in the bathroom, we have blackboard here.<br><br>Really good environment. <a href="https://t.co/61nZzXMSaw">pic.twitter.com/61nZzXMSaw</a></p>— Hirofumi Shiba (@ano2math5) <a href="https://twitter.com/ano2math5/status/1862170446273135070?ref_src=twsrc%5Etfw">November 28, 2024</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</section>
<section id="monte-carlo-ワークショップ" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="monte-carlo-ワークショップ"><span class="header-section-number">3</span> Monte Carlo ワークショップ</h2>
<p>このワークショップの最大の特徴は統計と物理の２分野の邂逅であった．Monte Carlo 法は物理学に端を発する計算技術であるが，今では統計学にも大きな研究コミュニティがあり，「ベイズ計算」はその一つである．統計と物理の研究者が語彙をすり合わせながら互いに歩み寄る極めて貴重な機会だったと言えるだろう．</p>
<div class="article-card-container">
  <blockquote class="twitter-tweet blockquote"><p lang="ja" dir="ltr">Mpemba 効果（より熱い水の方が冷たい水より先に凍ることがある）への理解を深めれば，より速く収束する MCMC が作れるかもしれない……？<br><br>Check out "Anomalous thermal relaxation on dense graphs with Metropolis-Hastings dynamics" by Marija Vucelja<a href="https://t.co/c9N7Eftmqx">https://t.co/c9N7Eftmqx</a></p>— Hirofumi Shiba (@ano2math5) <a href="https://twitter.com/ano2math5/status/1861411397676007652?ref_src=twsrc%5Etfw">November 26, 2024</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 
</div>
<p>最初の講演は “beyond the diffusive regime” という副題を象徴する統計物理学者である Werner Krauth 氏の発表から始まった．公式 YouTube チャンネルに <a href="https://www.youtube.com/watch?v=PNtIrA88ae4">アーカイブ</a> が残っている．Werner は ECMC (Event Chain Monte Carlo) という新たな Monte Carlo 法を開発することで，水の融解の全粒子シミュレーションを世界で初めて成功させた．</p>
<p><a href="https://www.youtube.com/watch?v=PNtIrA88ae4"><img src="https://162348.github.io/posts/2024/Life/Images/WernerKrauth.png" class="img-fluid"></a></p>
<p>diffusive regime とは熱平衡にある系が示す特徴である．したがって多峰性分布からも効率的にサンプリングができるような次世代の Monte Carlo 法をデザインするためには，diffusive regime から脱すること (= beyond the diffusive regime) がいくらか必要条件になる，ということから始まった．</p>
<p>続いて Werner は diffusive regime を超越する Monte Carlo 法に，「局所性」を破る HMC (Hamiltonian / Hybrid Monte Carlo) と「対称性」を破る ECMC / PDMP (Piecewise Deterministic Markov Process) の２つがあるとして，現状のベイズ計算を概観した．（ここでも二分野の語彙の違いが出ている，統計が PDMP と呼ぶものを物理は ECMC と呼ぶ．）</p>
<p>このプレゼンはワークショップ全体のアジェンダを設定したと言えるものであった．それだけでなく，その後ワークショップの全体を通して，Werner は最も影響力を持つ存在であった．何より，５日間を通して最前列で最も活発に質問するだけでなく，筆者のような修士の学生とも議論する時間を惜しまなかった．「英語では教授は Sir をつけて呼ぶべきなのだろうか」とか考えてひたすら恐れ入っている自分に “I’m also a learner here.” と対等に議論しようとふっかけてくれたことが嬉しかった．</p>
<p>Werner は７時にお腹が空いてどうしようもなくなるまで INI に残っていた．言語の壁を超えて伝わってくる人格があった．どこか現代の Feynman に出会ったような感覚であった．僕はこの仕事がますます好きになるばかりだ．</p>
<p>そこで翌日も INI に残っていたらどんな人に出会うかとワクワクしていたが，気づけば 10 時過ぎまでカードゲームをしていた．Andi Q. Wang 氏は MCMC の収束を関数不等式を用いて議論する研究をしている．彼はどの学会にもスウェーデンで買ったカードゲームを持参するようで，今回は Blood on Clocktower という人狼をさらに複雑にしたようなゲームを８人でプレイした．スウェーデンでは毎年１つボードゲームが無料でもらえるらしい．</p>
<p>研究の話じゃなくなると本当に英語は難しい．オランダ・ギリシャ・スロベニア・インドと，英語が母語じゃない研究者もたくさんプレイしていたはずであるが，彼らはとんでもなく英語がうまい．全く気後れしている様子がなかった．やはりインド・ヨーロッパ語族から外れた母語を持つと，ハンディキャップが大きいのだろうかなどと考えざるを得なかった．正直，ゲームは楽しいというより苦しかった．</p>
<div class="article-card-container">
  <blockquote class="twitter-tweet blockquote"><p lang="en" dir="ltr">Although some of my colleagues (might) praise me for my Englisg skills, I am useless itself when playing cardgame with people here.</p>— Hirofumi Shiba (@ano2math5) <a href="https://twitter.com/ano2math5/status/1861569171902865744?ref_src=twsrc%5Etfw">November 27, 2024</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</section>
<section id="共同研究" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="共同研究"><span class="header-section-number">4</span> 共同研究</h2>
<p>今回のロンドン滞在の話は，実は最初は断るつもりであった．英語以前にも，そもそも自分は修士２年でまだ論文もなく，「滞在先の先生に何も提供できないのではないか」という懸念が後ろ髪を引いた．しかし，副指導教員の先生や家族に「失敗しても失うものはない」と大きく背中を押されたこともあり，自分の運命を受け入れることにした．</p>
<p>修士２年で夏休みを終えたばかりの自分はというと，いまいち指導教員の先生がやっているような MCMC や SMC の理論解析には踏み切れずにいた．MCMC や PDMP のアルゴリズムは十分理解したつもりだったし，使う数学にも慣れてきたが，いまいち心がついてこなかった．</p>
<p>そのような中で９月に奇縁でソウル大学の政治学者（かつベイジアン！）である Jong Hee Park （박종희）氏に PDMP について発表する機会があった．全く新しい MCMC であるからしばらくは戸惑っていたようであるが，話すうちに「これは使える！」という反応をもらった．</p>
<p>そのアイデアは要するに「モデル選択に使えるのではないか？」ということであった．すごく意外だった．</p>
<p>PDMP とは，従来の Metropolis-Hastings 法を非可逆化したアルゴリズムの，さらに提案分布の分散を小さくしていく極限を取ったものと考えることができる．その結果，割り切った (ballistic) ダイナミクスとより速いエルゴード収束レートをもつ．これにより Monte Carlo 分散を従来の MCMC より小さくできることが期待されていた．</p>
<p>自分はこのことを数学的に証明できたかもしれないが，だからといって PDMP が何の役に立つかを全く知らなかったのである．</p>
<p>そこで出発までの１ヶ月で PDMP サンプリングを実行するための <a href="../../../posts/2024/Julia/PDMPFlux.html">パッケージ</a> を作ってみた．ギリギリ動くものができた段階でロンドンに向かったのである．</p>
<p>正直，本当の興味はどちらかというと SMC と最適輸送の関係にあった．こちらの話も，なるほど interesting だと共感はしてもらえたが，アイデアが未成熟で具体的に次のステップに繋げることができなかった．しかしこの PDMP パッケージの話が出ると新たな方向が見えた．Alex 自身に PDMP に関する著作はないが，昨今 Graphical Model のベイズモデル選択には大きな興味があった．</p>
<p>そこで，パッケージの応用先の例として筆者がそれとなく挙げた巨大な階層モデル（<a href="../../../posts/2024/TransDimensionalModels/IdealPoint.html">理想点モデル</a>）を PDMP で推定することと，そのモデル選択のための新種のトリックに大きく興味を持ったようだった．</p>
<p>INI の３日目（中間日）は午後には講演はなく，参加者は思い思いの場所で議論に耽っていた．Alex は自分のアイデアに大変興味を持ってくれて，PDMP の大家である Samuel Livingstone とその学生である Luke も誘い合わせてミーティングを企画してくれた．Luke は，殊に PDMP の具体的な統計モデルへの応用については現時点で世界で最も詳しい人間かもしれない．</p>
<p>僕が黒板に文字を書くなり，奥から Samuel が羽衣チョークを持ち出してきたときには笑った．Samuel は６ヶ月 INI に滞在しているメンバーであり，自室に羽衣チョークのストックを作っていたのである（UCL に黒板はない）．他の INI 滞在メンバーである，これまた PDMP の専門家である Georgios Vasdekis に至っては，６ヶ月の会期が終わると使い所がないからと１本プレゼントしてくれた．</p>
<div class="article-card-container">
  <blockquote class="twitter-tweet blockquote"><p lang="en" dir="ltr">Hagoromo （羽衣） chalk presented by Georgios <a href="https://t.co/3x9POrgti3">pic.twitter.com/3x9POrgti3</a></p>— Hirofumi Shiba (@ano2math5) <a href="https://twitter.com/ano2math5/status/1862128963239256497?ref_src=twsrc%5Etfw">November 28, 2024</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 
</div>
</section>
<section id="終わりに" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="終わりに"><span class="header-section-number">5</span> 終わりに</h2>
<p>３週間という長い期間 UCL に滞在でき，他の Ph.D.&nbsp;学生と交流できたことと，今回の極めて自分の専門に焦点のあった INI のワークショップに参加できた意義は，計り知れないほど大きい．</p>
<p>自分は海を隔てれば同志がいることを知った．また INI ワークショップの講演者は，まるで自分が読んできた論文の著者リストであった．</p>
<p>論文を読むだけでなく，それについて他人とディスカッションすることは，全く別の行為であることを学んだ．ディスカッションを通じて，既存のリテラチャーに +1 をするような考え方だけでなく，遠く離れた２つのアイデアを結びつける「核」というものが特定できる気がする．</p>
<!-- 自分は論文というものが好きだ．それ自体で完結しており，世界中のどこに生まれようとも，数学と英語を学べばその最先端の発見を共有できる．身近に識者がおらずとも，参考文献を辿れば真実に辿り着ける．博士学生にとって真の師とは論文であり，指導教員は補助をしたり，読むべき論文を教えたりすることしかできない．

だが論文を書くことは，論文を読んでいるだけ -->
<p>実際，自分の原稿であろうと，いざ黒板の前に立って思い出せることはごく一部なのである．アイデアは論文ではなく人に宿るのである……．</p>
<div class="article-card-container">
  <blockquote class="twitter-tweet blockquote"><p lang="ja" dir="ltr">いろんな人と将来コラボしたいから広い知見と深い数学が欲しい。だが自分だけのオリジナルな結果も博士で欲しい。二つのバランスをずっと考えている。</p>— Hirofumi Shiba (@ano2math5) <a href="https://twitter.com/ano2math5/status/1861567988073222543?ref_src=twsrc%5Etfw">November 27, 2024</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>


</section>

 ]]></description>
  <category>Life</category>
  <guid>https://162348.github.io/posts/2024/Life/UCL.html</guid>
  <pubDate>Sun, 01 Dec 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Life/Images/INI.jpeg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>雑音除去拡散サンプラー</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Bridges/SB2-HandsOn.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="関連ページ" class="level3 unnumbered unlisted">
<h3 class="unnumbered unlisted anchored" data-anchor-id="関連ページ">関連ページ</h3>
<div id="listing-diffusion-listing" class="quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="UHJvY2VzcyUyQ1NhbXBsaW5nJTJDUChYKQ==" data-listing-date-sort="1722643200000" data-listing-file-modified-sort="1733137935916" data-listing-date-modified-sort="1728691200000" data-listing-reading-time-sort="2" data-listing-word-count-sort="300">
<a href="../../../posts/2024/Bridges/SB0.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<!-- img(9CEB782EFEE6)[progressive=false, height=150px]:diffusion-listing:posts/2024/Bridges/SB0.html -->
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
拡散モデルによる事後分布サンプリング
</h5>
<div class="card-subtitle listing-subtitle">
Langevin 拡散の時間反転を用いたシミュレーションベースのサンプリング法
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-03
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="UHJvY2VzcyUyQ1NhbXBsaW5nJTJDUChYKQ==" data-listing-date-sort="1722643200000" data-listing-file-modified-sort="1733137935916" data-listing-date-modified-sort="1728604800000" data-listing-reading-time-sort="2" data-listing-word-count-sort="219">
<a href="../../../posts/2024/Bridges/SB1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Bridges/Files/SB.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
拡散モデルからシュレディンガー橋へ
</h5>
<div class="card-subtitle listing-subtitle">
Iterative Proportional Fitting アルゴリズムについて
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-03
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="U2FtcGxpbmclMkNQcm9jZXNz" data-listing-date-sort="1722643200000" data-listing-file-modified-sort="1733137935916" data-listing-date-modified-sort="1728172800000" data-listing-reading-time-sort="1" data-listing-word-count-sort="96">
<a href="../../../posts/2024/Bridges/SB2.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Bridges/Files/sde_animation.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
雑音除去拡散サンプラー
</h5>
<div class="card-subtitle listing-subtitle">
デノイジング・ディフュージョンによるベイズ計算
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-03
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>
<section id="はじめに" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="はじめに"><span class="header-section-number">1</span> はじめに</h2>
<section id="雑音除去過程サンプラー" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="雑音除去過程サンプラー"><span class="header-section-number">1.1</span> 雑音除去過程サンプラー</h3>
<p>DDS (Denoising Diffusion Sampler) は <span class="citation" data-cites="Vargas-Grathwohl-Doucet2023">(Vargas et al., 2023)</span> によって提案された，雑音除去過程 (Denoising Process) を用いたサンプリング法である．</p>
<p>雑音除去過程に関しては次の記事を参照：</p>
<div id="listing-lst-embedding" class="listing quarto-float quarto-figure quarto-figure-left quarto-listing quarto-listing-container-grid anchored">
<div class="list grid quarto-listing-cols-1">
<div class="g-col-1" data-index="0" data-categories="UHJvY2VzcyUyQ1NhbXBsaW5n" data-listing-date-sort="1724630400000" data-listing-file-modified-sort="1733137937708" data-listing-date-modified-sort="1724803200000" data-listing-reading-time-sort="2" data-listing-word-count-sort="350">
<a href="../../../posts/2024/Samplers/DD1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-center">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Samplers/Files/DSM.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
雑音除去過程
</h5>
<div class="card-subtitle listing-subtitle">
Ornstein-Uhlenbeck 過程の時間反転
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-26
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
<p>DDS については次の記事を参照：</p>
<div id="listing-lst-embedding1" class="listing quarto-float quarto-figure quarto-figure-left quarto-listing quarto-listing-container-grid anchored">
<div class="list grid quarto-listing-cols-1">
<div class="g-col-1" data-index="0" data-categories="U2FtcGxpbmclMkNQcm9jZXNz" data-listing-date-sort="1722643200000" data-listing-file-modified-sort="1733137935916" data-listing-date-modified-sort="1728172800000" data-listing-reading-time-sort="1" data-listing-word-count-sort="96">
<a href="../../../posts/2024/Bridges/SB2.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-center">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Bridges/Files/sde_animation.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
雑音除去拡散サンプラー
</h5>
<div class="card-subtitle listing-subtitle">
デノイジング・ディフュージョンによるベイズ計算
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-03
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
<p>本記事では <a href="https://github.com/franciscovargas/denoising_diffusion_samplers">著者の GitHub</a> を参照にして DDS の実装を吟味する．</p>
</section>
<section id="funnel-分布" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="funnel-分布"><span class="header-section-number">1.2</span> <code>funnel</code> 分布</h3>
<p><span class="citation" data-cites="Neal2003">(Neal, 2003)</span> が slice sampling のデモ用に定義した <strong>漏斗分布</strong> を考える： <img src="https://latex.codecogs.com/png.latex?%0Ap(y,x)=%5Cphi(y;0,3)%5Cprod_%7Bi=1%7D%5E9%5Cphi(x_i;0,e%5E%7By/2%7D),%5Cqquad%20y%5Cin%5Cmathbb%7BR%7D,x%5Cin%5Cmathbb%7BR%7D%5E9.%0A"></p>
<div id="aee4d390" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>漏斗分布 <code>funnel()</code> を定義</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> jax</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> jax.scipy.stats <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> multivariate_normal</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> jax.scipy.stats <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> norm</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> jax.numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> jnp</span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> funnel(d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, sig<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, clip_y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>):</span>
<span id="cb1-8">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Funnel distribution for testing. Returns energy and sample functions."""</span></span>
<span id="cb1-9"></span>
<span id="cb1-10">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> neg_energy(x):</span>
<span id="cb1-11">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> unbatched(x):</span>
<span id="cb1-12">      v <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb1-13">      log_density_v <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> norm.logpdf(v,</span>
<span id="cb1-14">                                  loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span>,</span>
<span id="cb1-15">                                  scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3.</span>)</span>
<span id="cb1-16">      variance_other <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> jnp.exp(v)</span>
<span id="cb1-17">      other_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb1-18">      cov_other <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> jnp.eye(other_dim) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> variance_other</span>
<span id="cb1-19">      mean_other <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> jnp.zeros(other_dim)</span>
<span id="cb1-20">      log_density_other <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> multivariate_normal.logpdf(x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:],</span>
<span id="cb1-21">                                                     mean<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>mean_other,</span>
<span id="cb1-22">                                                     cov<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cov_other)</span>
<span id="cb1-23">      <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> log_density_v <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> log_density_other</span>
<span id="cb1-24">    output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> jax.vmap(unbatched)(x)</span>
<span id="cb1-25">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> output</span>
<span id="cb1-26"></span>
<span id="cb1-27">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> sample_data(n_samples):</span>
<span id="cb1-28">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># sample from Nd funnel distribution</span></span>
<span id="cb1-29">    y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (sig <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> jnp.array(np.random.randn(n_samples, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))).clip(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>clip_y, clip_y)</span>
<span id="cb1-30">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> jnp.array(np.random.randn(n_samples, d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> jnp.exp(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb1-31">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> jnp.concatenate((y, x), axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb1-32"></span>
<span id="cb1-33">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> neg_energy, sample_data</span></code></pre></div>
</details>
</div>
<div id="41fcba53" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>サンプルデータを生成 (ground truth)</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb2-3"></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ファンネル分布のサンプルデータを生成</span></span>
<span id="cb2-5">neg_energy, sample_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> funnel(d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb2-6">n_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># サンプル数</span></span>
<span id="cb2-7">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sample_data(n_samples)</span>
<span id="cb2-8"></span>
<span id="cb2-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 最初の2次元を抽出（yとx1）</span></span>
<span id="cb2-10">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb2-11">x1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb2-12"></span>
<span id="cb2-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 散布図をプロット</span></span>
<span id="cb2-14">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb2-15">plt.scatter(y, x1, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb2-16">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>)</span>
<span id="cb2-17">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x1'</span>)</span>
<span id="cb2-18">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Funnel Distribution (First Two Dimensions)'</span>)</span>
<span id="cb2-19">plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb2-20"></span>
<span id="cb2-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># xlim と ylim を追加</span></span>
<span id="cb2-22">plt.xlim(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># x軸の範囲を -10 から 10 に設定</span></span>
<span id="cb2-23">plt.ylim(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># y軸の範囲を -20 から 20 に設定</span></span>
<span id="cb2-24"></span>
<span id="cb2-25">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Bridges/SB2-HandsOn_files/figure-html/cell-3-output-1.png" width="666" height="523" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="f5e6c573" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>3Dプロットの作成</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">neg_energy, sample_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> funnel(d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb3-2"></span>
<span id="cb3-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># y と x1 の範囲を設定</span></span>
<span id="cb3-4">y_min, y_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span></span>
<span id="cb3-5">x1_min, x1_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span></span>
<span id="cb3-6">num_points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># グリッドの解像度</span></span>
<span id="cb3-7"></span>
<span id="cb3-8">y_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(y_min, y_max, num_points)</span>
<span id="cb3-9">x1_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(x1_min, x1_max, num_points)</span>
<span id="cb3-10">Y, X1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.meshgrid(y_values, x1_values)</span>
<span id="cb3-11"></span>
<span id="cb3-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># グリッド上の点を作成</span></span>
<span id="cb3-13">inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.stack([Y.ravel(), X1.ravel()], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-14"></span>
<span id="cb3-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 対数密度を計算</span></span>
<span id="cb3-16">log_density <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> neg_energy(inputs)</span>
<span id="cb3-17">density <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.exp(log_density)</span>
<span id="cb3-18"></span>
<span id="cb3-19">log_density <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.sqrt(density)</span>
<span id="cb3-20"></span>
<span id="cb3-21">Density <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> log_density.reshape(Y.shape)</span>
<span id="cb3-22"></span>
<span id="cb3-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3Dプロットの作成</span></span>
<span id="cb3-24">fig <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>))</span>
<span id="cb3-25">ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fig.add_subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">111</span>, projection<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'3d'</span>)</span>
<span id="cb3-26"></span>
<span id="cb3-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 軸のラベルを設定</span></span>
<span id="cb3-28">ax.set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>)</span>
<span id="cb3-29">ax.set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x1'</span>)</span>
<span id="cb3-30">ax.set_zlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Density (Transformed)'</span>)</span>
<span id="cb3-31"></span>
<span id="cb3-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># サーフェスプロットを作成</span></span>
<span id="cb3-33">surf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ax.plot_surface(Y, X1, Density, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>, edgecolor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'none'</span>)</span>
<span id="cb3-34"></span>
<span id="cb3-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># カラーバーを追加</span></span>
<span id="cb3-36">fig.colorbar(surf, shrink<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, aspect<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb3-37"></span>
<span id="cb3-38"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># タイトルを設定</span></span>
<span id="cb3-39">ax.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Funnel Distribution Density on (x1,y)'</span>)</span>
<span id="cb3-40"></span>
<span id="cb3-41">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Bridges/SB2-HandsOn_files/figure-html/cell-4-output-1.png" width="753" height="631" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="962d87cd" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>2Dヒートマップの作成</summary>
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2Dヒートマップの作成</span></span>
<span id="cb4-2">fig, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># pcolormeshを使用してヒートマップを作成</span></span>
<span id="cb4-5">im <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ax.pcolormesh(X1, Y, Density, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'binary'</span>, shading<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'auto'</span>)</span>
<span id="cb4-6"></span>
<span id="cb4-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 軸のラベルを設定</span></span>
<span id="cb4-8">ax.set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x1'</span>)</span>
<span id="cb4-9">ax.set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>)</span>
<span id="cb4-10"></span>
<span id="cb4-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># カラーバーを追加</span></span>
<span id="cb4-12">cbar <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fig.colorbar(im, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Density (Transformed)'</span>)</span>
<span id="cb4-13"></span>
<span id="cb4-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># タイトルを設定</span></span>
<span id="cb4-15">ax.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Funnel Distribution Density over y and x1'</span>)</span>
<span id="cb4-16"></span>
<span id="cb4-17">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Bridges/SB2-HandsOn_files/figure-html/cell-5-output-1.png" width="665" height="523" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="実験" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="実験"><span class="header-section-number">2</span> 実験</h2>
<p>DDS を Funnel 分布からのサンプリングに適用してみる．</p>
<p>実際の実験は <a href="https://colab.research.google.com/drive/1TU8IhZ-U_BNdhiQbTJ_E3_NhtEWu57l6?usp=sharing">こちらの Colab</a> で行なった．</p>
<p>途中で <a href="https://www.wandb.jp/">WandB (Weights &amp; Biases)</a> を使う．</p>
<div id="b3e8acdc" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>データの読み込み</summary>
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb5-2"></span>
<span id="cb5-3">sde_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.load(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Files/sde_data.npy'</span>)</span>
<span id="cb5-4">ode_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.load(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Files/ode_data.npy'</span>)</span></code></pre></div>
</details>
</div>
<div id="02952d31" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>データのプロット</summary>
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb6-2"></span>
<span id="cb6-3">ode_targ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ode_data[:, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb6-4">sde_targ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sde_data[:, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb6-5"></span>
<span id="cb6-6">plt.plot(ode_targ[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], ode_targ[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"."</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>)</span>
<span id="cb6-7">plt.plot(sde_targ[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], sde_targ[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"."</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'orange'</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Bridges/SB2-HandsOn_files/figure-html/cell-7-output-1.png" width="590" height="411" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="70b1230f" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>SDE サンプルのアニメーション</summary>
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.animation <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> animation</span>
<span id="cb7-2"></span>
<span id="cb7-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Density のヒートマップ作成（前述のコードから）</span></span>
<span id="cb7-4">neg_energy, sample_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> funnel(d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb7-5"></span>
<span id="cb7-6">y_min, y_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span></span>
<span id="cb7-7">x1_min, x1_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span></span>
<span id="cb7-8">num_points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># グリッドの解像度を下げて処理を軽くする</span></span>
<span id="cb7-9"></span>
<span id="cb7-10">y_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(y_min, y_max, num_points)</span>
<span id="cb7-11">x1_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(x1_min, x1_max, num_points)</span>
<span id="cb7-12">Y, X1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.meshgrid(y_values, x1_values)</span>
<span id="cb7-13"></span>
<span id="cb7-14">inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.stack([Y.ravel(), X1.ravel()], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb7-15">log_density <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> neg_energy(inputs)</span>
<span id="cb7-16">density <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.sqrt(np.exp(log_density))</span>
<span id="cb7-17">Density <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> density.reshape(Y.shape)</span>
<span id="cb7-18"></span>
<span id="cb7-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># プロットの設定</span></span>
<span id="cb7-20">fig, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>))</span>
<span id="cb7-21"></span>
<span id="cb7-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ヒートマップを描画（Density.T ではなく Density を使用）</span></span>
<span id="cb7-23">im <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ax.imshow(Density, extent<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[y_min, y_max, x1_min, x1_max], </span>
<span id="cb7-24">               origin<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'lower'</span>, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'binary'</span>, aspect<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'auto'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>)</span>
<span id="cb7-25"></span>
<span id="cb7-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># カラーバーを追加</span></span>
<span id="cb7-27">plt.colorbar(im, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Density'</span>)</span>
<span id="cb7-28"></span>
<span id="cb7-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 初期データの取得</span></span>
<span id="cb7-30">y0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sde_data[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># y軸（第1次元）</span></span>
<span id="cb7-31">x0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sde_data[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># x軸（第2次元）</span></span>
<span id="cb7-32">data0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.column_stack((y0, x0))</span>
<span id="cb7-33"></span>
<span id="cb7-34"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 散布図を描画</span></span>
<span id="cb7-35">scat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ax.scatter(data0[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], data0[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'orange'</span>)</span>
<span id="cb7-36"></span>
<span id="cb7-37"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 軸の範囲を設定</span></span>
<span id="cb7-38">ax.set_xlim(y_min, y_max)</span>
<span id="cb7-39">ax.set_ylim(x1_min, x1_max)</span>
<span id="cb7-40">ax.set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>)</span>
<span id="cb7-41">ax.set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x1'</span>)</span>
<span id="cb7-42">ax.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'SDE Samples Animation'</span>)</span>
<span id="cb7-43"></span>
<span id="cb7-44"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 初期化関数</span></span>
<span id="cb7-45"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> init():</span>
<span id="cb7-46">    scat.set_offsets(data0)</span>
<span id="cb7-47">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> scat,</span>
<span id="cb7-48"></span>
<span id="cb7-49"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># フレームごとの更新関数</span></span>
<span id="cb7-50"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> animate(i):</span>
<span id="cb7-51">    y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sde_data[:, i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># y軸（第1次元）</span></span>
<span id="cb7-52">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sde_data[:, i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># x軸（第2次元）</span></span>
<span id="cb7-53">    data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.column_stack((y, x))</span>
<span id="cb7-54">    scat.set_offsets(data)</span>
<span id="cb7-55">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> scat,</span>
<span id="cb7-56"></span>
<span id="cb7-57"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># アニメーションの作成</span></span>
<span id="cb7-58">ani <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> animation.FuncAnimation(</span>
<span id="cb7-59">    fig, animate, init_func<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>init, frames<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sde_data.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb7-60">    interval<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, blit<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb7-61"></span>
<span id="cb7-62"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># アニメーションの保存</span></span>
<span id="cb7-63">ani.save(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sde_animation.gif'</span>, writer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pillow'</span>, fps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span></code></pre></div>
</details>
</div>
<p><img src="https://162348.github.io/posts/2024/Bridges/Files/sde_animation.gif" class="img-fluid"></p>
<p><img src="https://162348.github.io/posts/2024/Bridges/Files/ode_animation.gif" class="img-fluid"></p>
</section>
<section id="実装" class="level2" data-number="3">





</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">3 実装</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Neal2003" class="csl-entry">
Neal, R. M. (2003). <a href="https://doi.org/10.1214/aos/1056562461"><span class="nocase">Slice sampling</span></a>. <em>The Annals of Statistics</em>, <em>31</em>(3), 705–767.
</div>
<div id="ref-Vargas-Grathwohl-Doucet2023" class="csl-entry">
Vargas, F., Grathwohl, W. S., and Doucet, A. (2023). <a href="https://openreview.net/forum?id=8pvnfTAbu1f"><span>Denoising Diffusion Samplers</span></a>. In <em>The eleventh international conference on learning representations</em>.
</div>
</div></section></div> ]]></description>
  <category>Sampling</category>
  <category>Process</category>
  <category>Python</category>
  <guid>https://162348.github.io/posts/2024/Bridges/SB2-HandsOn.html</guid>
  <pubDate>Sun, 06 Oct 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Bridges/Files/Funnel.png" medium="image" type="image/png" height="113" width="144"/>
</item>
<item>
  <title>流体モデル概観</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Particles/Lorenz95.html</link>
  <description><![CDATA[ 





<section id="関連記事" class="level2 unnumbered unlisted">
<h2 class="unnumbered unlisted anchored" data-anchor-id="関連記事">関連記事</h2>
<div id="listing-lst-listing" class="listing quarto-float quarto-figure quarto-figure-left quarto-listing quarto-listing-container-grid anchored">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="UGFydGljbGVzJTJDU3VydmV5" data-listing-date-sort="1712448000000" data-listing-file-modified-sort="1733137936336" data-listing-date-modified-sort="1728345600000" data-listing-reading-time-sort="2" data-listing-word-count-sort="353">
<a href="../../../posts/2024/Particles/ParticleMethods.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Particles/Files/lorenz96_animation.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
粒子法の概観
</h5>
<div class="card-subtitle listing-subtitle">
分子動力学法から SMC サンプラーまで
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-04-07
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="UGFydGljbGVzJTJDTUNNQyUyQ1N1cnZleQ==" data-listing-date-sort="1702512000000" data-listing-file-modified-sort="1733137938572" data-listing-date-modified-sort="1722816000000" data-listing-reading-time-sort="3" data-listing-word-count-sort="488">
<a href="../../../posts/Surveys/SMCSamplers.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/Surveys/SMCSamplers_LowResolution.jpg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
粒子フィルターを用いたサンプリング | About SMC Samplers
</h5>
<div class="card-subtitle listing-subtitle">
テンパリングを通じたもう一つの万能サンプラー
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2023-12-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="UGFydGljbGVzJTJDU3VydmV5JTJDQ29tcHV0YXRpb24=" data-listing-date-sort="1700870400000" data-listing-file-modified-sort="1733137935656" data-listing-date-modified-sort="1702598400000" data-listing-reading-time-sort="5" data-listing-word-count-sort="821">
<a href="../../../posts/2023/Surveys/ParticleFilter.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2023/Surveys/cover_LowResolution.jpg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
粒子フィルターとは何か
</h5>
<div class="card-subtitle listing-subtitle">
非線型フィルタリング手法としての粒子フィルタ
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2023-11-25
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li><a href="https://github.com/milankl/Lorenz96.jl/tree/v0.3.0"><code>Loorenz96.jl</code></a> パッケージ <span class="citation" data-cites="Milan2021">(K, 2021)</span></li>
<li><code>DynamicalSystems.jl</code> (<a href="https://github.com/JuliaDynamics/DynamicalSystems.jl">GitHub</a> / <a href="https://juliadynamics.github.io/DynamicalSystems.jl/dev/">Docs</a>) パッケージ</li>
<li><code>EnsembleKalmanProcesses.jl</code> (<a href="https://github.com/CliMA/EnsembleKalmanProcesses.jl">GitHub</a> / <a href="https://clima.github.io/EnsembleKalmanProcesses.jl/dev/examples/lorenz_example/">Docs</a>) パッケージ</li>
</ul>
</div>
</div>
</div>
</section>
<section id="lorenz-96-モデル" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="lorenz-96-モデル"><span class="header-section-number">1</span> Lorenz 96 モデル</h2>
<section id="モデル定義" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="モデル定義"><span class="header-section-number">1.1</span> モデル定義</h3>
<p>Lorenz 96 とは，<span class="citation" data-cites="Lorenz1995">(Lorenz, 1995)</span> によって導入された力学系の通称である：</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7Bd%20x_i%7D%7Bd%20t%7D=%5Cbiggr(x_%7Bi+1%7D-x_%7Bi-2%7D%5Cbiggl)x_%7Bi-1%7D-x_i+F,%5Cqquad%20F%5Cin%5Cmathbb%7BR%7D.%0A"></p>
<p>ただし，係数については，空間の次元 <img src="https://latex.codecogs.com/png.latex?x%5Cin%5Cmathbb%7BR%7D%5EN"> について <img src="https://latex.codecogs.com/png.latex?x_%7Bi-N%7D=x_%7Bi+N%7D=x_i"> と約束する．</p>
</section>
<section id="dynamicalsystems.jl-でシミュレーション" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="dynamicalsystems.jl-でシミュレーション"><span class="header-section-number">1.2</span> <code>DynamicalSystems.jl</code> でシミュレーション</h3>
<p><code>DynamicalSystems.jl</code> (<a href="https://github.com/JuliaDynamics/DynamicalSystems.jl">GitHub</a> / <a href="https://juliadynamics.github.io/DynamicalSystems.jl/dev/">Docs</a>) パッケージの<a href="https://juliadynamics.github.io/DynamicalSystems.jl/dev/tutorial/#Example:-Lorenz96">チュートリアルに Lorenz96 の例がある</a>．</p>
<p><img src="https://latex.codecogs.com/png.latex?F=8"> の場合はカオス的な振る舞いを示す：</p>
<div id="ba454242" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">DynamicalSystems</span></span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">lorenz96_rule!</span>(du, u, p, t)</span>
<span id="cb1-4">    F <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> p[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]; N <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">length</span>(u)</span>
<span id="cb1-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3 edge cases</span></span>
<span id="cb1-6">    du[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (u[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> u[N <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> u[N] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> u[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> F</span>
<span id="cb1-7">    du[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (u[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> u[N]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> u[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> u[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> F</span>
<span id="cb1-8">    du[N] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (u[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> u[N <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> u[N <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> u[N] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> F</span>
<span id="cb1-9">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># then the general case</span></span>
<span id="cb1-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> n <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>(N <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb1-11">        du[n] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (u[n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> u[n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> u[n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> u[n] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> F</span>
<span id="cb1-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">end</span></span>
<span id="cb1-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">nothing</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># always `return nothing` for in-place form!</span></span>
<span id="cb1-14"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">end</span></span>
<span id="cb1-15"></span>
<span id="cb1-16">N <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span></span>
<span id="cb1-17">u0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">range</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>; length <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> N)</span>
<span id="cb1-18">p0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.0</span>]</span>
<span id="cb1-19">lorenz96 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">CoupledODEs</span>(lorenz96_rule!, u0, p0)</span>
<span id="cb1-20"></span>
<span id="cb1-21">total_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">12.5</span></span>
<span id="cb1-22">sampling_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.02</span></span>
<span id="cb1-23">Y, t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">trajectory</span>(lorenz96, total_time; Ttr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.2</span>, Δt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sampling_time)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>(6-dimensional StateSpaceSet{Float64} with 626 points, 2.2:0.02:14.7)</code></pre>
</div>
</div>
<div id="dba37dcc" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Plots</span></span>
<span id="cb3-2"></span>
<span id="cb3-3">p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(xlabel <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"time"</span>, ylabel <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"variable"</span>, legend <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">false</span>)</span>
<span id="cb3-4"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> var <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">eachcol</span>(Y)</span>
<span id="cb3-5">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot!</span>(p, t, var)</span>
<span id="cb3-6"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">end</span></span>
<span id="cb3-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(p)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<!--?xml version="1.0" encoding="utf-8"?-->
<svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" width="672" height="480" viewbox="0 0 2688 1920">
<defs>
  <clippath id="clip350">
    <rect x="0" y="0" width="2688" height="1920"></rect>
  </clippath>
</defs>
<path clip-path="url(#clip350)" d="M0 1920 L2688 1920 L2688 -4.26326e-14 L0 -4.26326e-14  Z" fill="#ffffff" fill-rule="evenodd" fill-opacity="1"></path>
<defs>
  <clippath id="clip351">
    <rect x="537" y="0" width="1883" height="1883"></rect>
  </clippath>
</defs>
<path clip-path="url(#clip350)" d="M217.252 1734.12 L2640.76 1734.12 L2640.76 47.2441 L217.252 47.2441  Z" fill="#ffffff" fill-rule="evenodd" fill-opacity="1"></path>
<defs>
  <clippath id="clip352">
    <rect x="217" y="47" width="2425" height="1688"></rect>
  </clippath>
</defs>
<polyline clip-path="url(#clip352)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="249.26,1734.12 249.26,47.2441 "></polyline>
<polyline clip-path="url(#clip352)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="615.072,1734.12 615.072,47.2441 "></polyline>
<polyline clip-path="url(#clip352)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="980.884,1734.12 980.884,47.2441 "></polyline>
<polyline clip-path="url(#clip352)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1346.7,1734.12 1346.7,47.2441 "></polyline>
<polyline clip-path="url(#clip352)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1712.51,1734.12 1712.51,47.2441 "></polyline>
<polyline clip-path="url(#clip352)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="2078.32,1734.12 2078.32,47.2441 "></polyline>
<polyline clip-path="url(#clip352)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="2444.13,1734.12 2444.13,47.2441 "></polyline>
<polyline clip-path="url(#clip352)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="217.252,1526.03 2640.76,1526.03 "></polyline>
<polyline clip-path="url(#clip352)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="217.252,1092.66 2640.76,1092.66 "></polyline>
<polyline clip-path="url(#clip352)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="217.252,659.284 2640.76,659.284 "></polyline>
<polyline clip-path="url(#clip352)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="217.252,225.913 2640.76,225.913 "></polyline>
<polyline clip-path="url(#clip350)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="217.252,1734.12 2640.76,1734.12 "></polyline>
<polyline clip-path="url(#clip350)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="249.26,1734.12 249.26,1715.22 "></polyline>
<polyline clip-path="url(#clip350)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="615.072,1734.12 615.072,1715.22 "></polyline>
<polyline clip-path="url(#clip350)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="980.884,1734.12 980.884,1715.22 "></polyline>
<polyline clip-path="url(#clip350)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1346.7,1734.12 1346.7,1715.22 "></polyline>
<polyline clip-path="url(#clip350)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1712.51,1734.12 1712.51,1715.22 "></polyline>
<polyline clip-path="url(#clip350)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="2078.32,1734.12 2078.32,1715.22 "></polyline>
<polyline clip-path="url(#clip350)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="2444.13,1734.12 2444.13,1715.22 "></polyline>
<path clip-path="url(#clip350)" d="M243.913 1794.89 L260.232 1794.89 L260.232 1798.82 L238.288 1798.82 L238.288 1794.89 Q240.95 1792.13 245.533 1787.5 Q250.14 1782.85 251.32 1781.51 Q253.566 1778.98 254.445 1777.25 Q255.348 1775.49 255.348 1773.8 Q255.348 1771.04 253.404 1769.31 Q251.482 1767.57 248.381 1767.57 Q246.182 1767.57 243.728 1768.34 Q241.297 1769.1 238.52 1770.65 L238.52 1765.93 Q241.344 1764.79 243.797 1764.21 Q246.251 1763.64 248.288 1763.64 Q253.658 1763.64 256.853 1766.32 Q260.047 1769.01 260.047 1773.5 Q260.047 1775.63 259.237 1777.55 Q258.45 1779.45 256.344 1782.04 Q255.765 1782.71 252.663 1785.93 Q249.561 1789.12 243.913 1794.89 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M618.081 1768.34 L606.276 1786.78 L618.081 1786.78 L618.081 1768.34 M616.855 1764.26 L622.734 1764.26 L622.734 1786.78 L627.665 1786.78 L627.665 1790.67 L622.734 1790.67 L622.734 1798.82 L618.081 1798.82 L618.081 1790.67 L602.48 1790.67 L602.48 1786.16 L616.855 1764.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M981.289 1779.68 Q978.141 1779.68 976.289 1781.83 Q974.461 1783.98 974.461 1787.73 Q974.461 1791.46 976.289 1793.64 Q978.141 1795.79 981.289 1795.79 Q984.437 1795.79 986.266 1793.64 Q988.118 1791.46 988.118 1787.73 Q988.118 1783.98 986.266 1781.83 Q984.437 1779.68 981.289 1779.68 M990.572 1765.02 L990.572 1769.28 Q988.812 1768.45 987.007 1768.01 Q985.224 1767.57 983.465 1767.57 Q978.836 1767.57 976.382 1770.7 Q973.951 1773.82 973.604 1780.14 Q974.97 1778.13 977.03 1777.06 Q979.09 1775.97 981.567 1775.97 Q986.775 1775.97 989.785 1779.15 Q992.817 1782.29 992.817 1787.73 Q992.817 1793.06 989.669 1796.27 Q986.521 1799.49 981.289 1799.49 Q975.294 1799.49 972.123 1794.91 Q968.951 1790.3 968.951 1781.58 Q968.951 1773.38 972.84 1768.52 Q976.729 1763.64 983.28 1763.64 Q985.039 1763.64 986.822 1763.98 Q988.627 1764.33 990.572 1765.02 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M1346.7 1782.41 Q1343.36 1782.41 1341.44 1784.19 Q1339.54 1785.97 1339.54 1789.1 Q1339.54 1792.22 1341.44 1794.01 Q1343.36 1795.79 1346.7 1795.79 Q1350.03 1795.79 1351.95 1794.01 Q1353.87 1792.2 1353.87 1789.1 Q1353.87 1785.97 1351.95 1784.19 Q1350.05 1782.41 1346.7 1782.41 M1342.02 1780.42 Q1339.01 1779.68 1337.32 1777.62 Q1335.65 1775.56 1335.65 1772.59 Q1335.65 1768.45 1338.59 1766.04 Q1341.56 1763.64 1346.7 1763.64 Q1351.86 1763.64 1354.8 1766.04 Q1357.74 1768.45 1357.74 1772.59 Q1357.74 1775.56 1356.05 1777.62 Q1354.38 1779.68 1351.4 1780.42 Q1354.77 1781.21 1356.65 1783.5 Q1358.55 1785.79 1358.55 1789.1 Q1358.55 1794.12 1355.47 1796.81 Q1352.41 1799.49 1346.7 1799.49 Q1340.98 1799.49 1337.9 1796.81 Q1334.84 1794.12 1334.84 1789.1 Q1334.84 1785.79 1336.74 1783.5 Q1338.64 1781.21 1342.02 1780.42 M1340.31 1773.03 Q1340.31 1775.72 1341.97 1777.22 Q1343.66 1778.73 1346.7 1778.73 Q1349.71 1778.73 1351.4 1777.22 Q1353.11 1775.72 1353.11 1773.03 Q1353.11 1770.35 1351.4 1768.84 Q1349.71 1767.34 1346.7 1767.34 Q1343.66 1767.34 1341.97 1768.84 Q1340.31 1770.35 1340.31 1773.03 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M1687.2 1794.89 L1694.83 1794.89 L1694.83 1768.52 L1686.52 1770.19 L1686.52 1765.93 L1694.79 1764.26 L1699.46 1764.26 L1699.46 1794.89 L1707.1 1794.89 L1707.1 1798.82 L1687.2 1798.82 L1687.2 1794.89 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M1726.55 1767.34 Q1722.94 1767.34 1721.11 1770.9 Q1719.3 1774.45 1719.3 1781.58 Q1719.3 1788.68 1721.11 1792.25 Q1722.94 1795.79 1726.55 1795.79 Q1730.18 1795.79 1731.99 1792.25 Q1733.82 1788.68 1733.82 1781.58 Q1733.82 1774.45 1731.99 1770.9 Q1730.18 1767.34 1726.55 1767.34 M1726.55 1763.64 Q1732.36 1763.64 1735.41 1768.24 Q1738.49 1772.83 1738.49 1781.58 Q1738.49 1790.3 1735.41 1794.91 Q1732.36 1799.49 1726.55 1799.49 Q1720.74 1799.49 1717.66 1794.91 Q1714.6 1790.3 1714.6 1781.58 Q1714.6 1772.83 1717.66 1768.24 Q1720.74 1763.64 1726.55 1763.64 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M2053.81 1794.89 L2061.45 1794.89 L2061.45 1768.52 L2053.13 1770.19 L2053.13 1765.93 L2061.4 1764.26 L2066.07 1764.26 L2066.07 1794.89 L2073.71 1794.89 L2073.71 1798.82 L2053.81 1798.82 L2053.81 1794.89 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M2087.19 1794.89 L2103.51 1794.89 L2103.51 1798.82 L2081.56 1798.82 L2081.56 1794.89 Q2084.22 1792.13 2088.81 1787.5 Q2093.41 1782.85 2094.59 1781.51 Q2096.84 1778.98 2097.72 1777.25 Q2098.62 1775.49 2098.62 1773.8 Q2098.62 1771.04 2096.68 1769.31 Q2094.76 1767.57 2091.65 1767.57 Q2089.45 1767.57 2087 1768.34 Q2084.57 1769.1 2081.79 1770.65 L2081.79 1765.93 Q2084.62 1764.79 2087.07 1764.21 Q2089.52 1763.64 2091.56 1763.64 Q2096.93 1763.64 2100.13 1766.32 Q2103.32 1769.01 2103.32 1773.5 Q2103.32 1775.63 2102.51 1777.55 Q2101.72 1779.45 2099.62 1782.04 Q2099.04 1782.71 2095.94 1785.93 Q2092.83 1789.12 2087.19 1794.89 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M2418.58 1794.89 L2426.22 1794.89 L2426.22 1768.52 L2417.91 1770.19 L2417.91 1765.93 L2426.17 1764.26 L2430.85 1764.26 L2430.85 1794.89 L2438.48 1794.89 L2438.48 1798.82 L2418.58 1798.82 L2418.58 1794.89 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M2460.78 1768.34 L2448.97 1786.78 L2460.78 1786.78 L2460.78 1768.34 M2459.55 1764.26 L2465.43 1764.26 L2465.43 1786.78 L2470.36 1786.78 L2470.36 1790.67 L2465.43 1790.67 L2465.43 1798.82 L2460.78 1798.82 L2460.78 1790.67 L2445.17 1790.67 L2445.17 1786.16 L2459.55 1764.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M1368.16 1837.53 L1368.16 1847.65 L1380.23 1847.65 L1380.23 1852.2 L1368.16 1852.2 L1368.16 1871.56 Q1368.16 1875.92 1369.34 1877.16 Q1370.55 1878.4 1374.21 1878.4 L1380.23 1878.4 L1380.23 1883.3 L1374.21 1883.3 Q1367.43 1883.3 1364.85 1880.79 Q1362.28 1878.24 1362.28 1871.56 L1362.28 1852.2 L1357.98 1852.2 L1357.98 1847.65 L1362.28 1847.65 L1362.28 1837.53 L1368.16 1837.53 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M1387.93 1847.65 L1393.79 1847.65 L1393.79 1883.3 L1387.93 1883.3 L1387.93 1847.65 M1387.93 1833.78 L1393.79 1833.78 L1393.79 1841.19 L1387.93 1841.19 L1387.93 1833.78 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M1433.79 1854.5 Q1435.99 1850.55 1439.05 1848.67 Q1442.1 1846.79 1446.24 1846.79 Q1451.81 1846.79 1454.83 1850.71 Q1457.86 1854.59 1457.86 1861.78 L1457.86 1883.3 L1451.97 1883.3 L1451.97 1861.98 Q1451.97 1856.85 1450.15 1854.37 Q1448.34 1851.89 1444.62 1851.89 Q1440.06 1851.89 1437.42 1854.91 Q1434.78 1857.93 1434.78 1863.15 L1434.78 1883.3 L1428.89 1883.3 L1428.89 1861.98 Q1428.89 1856.82 1427.08 1854.37 Q1425.26 1851.89 1421.48 1851.89 Q1416.99 1851.89 1414.35 1854.94 Q1411.71 1857.97 1411.71 1863.15 L1411.71 1883.3 L1405.82 1883.3 L1405.82 1847.65 L1411.71 1847.65 L1411.71 1853.19 Q1413.71 1849.91 1416.51 1848.35 Q1419.31 1846.79 1423.16 1846.79 Q1427.05 1846.79 1429.75 1848.77 Q1432.49 1850.74 1433.79 1854.5 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M1500.03 1864.01 L1500.03 1866.88 L1473.1 1866.88 Q1473.48 1872.92 1476.73 1876.11 Q1480.01 1879.26 1485.83 1879.26 Q1489.21 1879.26 1492.36 1878.43 Q1495.54 1877.6 1498.66 1875.95 L1498.66 1881.49 Q1495.51 1882.82 1492.2 1883.52 Q1488.89 1884.22 1485.48 1884.22 Q1476.95 1884.22 1471.96 1879.26 Q1466.99 1874.29 1466.99 1865.83 Q1466.99 1857.07 1471.7 1851.95 Q1476.44 1846.79 1484.47 1846.79 Q1491.66 1846.79 1495.83 1851.44 Q1500.03 1856.06 1500.03 1864.01 M1494.17 1862.29 Q1494.11 1857.49 1491.47 1854.62 Q1488.86 1851.76 1484.53 1851.76 Q1479.63 1851.76 1476.67 1854.53 Q1473.74 1857.3 1473.29 1862.33 L1494.17 1862.29 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><polyline clip-path="url(#clip350)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="217.252,1734.12 217.252,47.2441 "></polyline>
<polyline clip-path="url(#clip350)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="217.252,1526.03 236.149,1526.03 "></polyline>
<polyline clip-path="url(#clip350)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="217.252,1092.66 236.149,1092.66 "></polyline>
<polyline clip-path="url(#clip350)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="217.252,659.284 236.149,659.284 "></polyline>
<polyline clip-path="url(#clip350)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="217.252,225.913 236.149,225.913 "></polyline>
<path clip-path="url(#clip350)" d="M116.214 1526.48 L145.89 1526.48 L145.89 1530.41 L116.214 1530.41 L116.214 1526.48 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M156.029 1508.75 L174.385 1508.75 L174.385 1512.68 L160.311 1512.68 L160.311 1521.15 Q161.33 1520.81 162.348 1520.64 Q163.367 1520.46 164.385 1520.46 Q170.172 1520.46 173.552 1523.63 Q176.932 1526.8 176.932 1532.22 Q176.932 1537.8 173.46 1540.9 Q169.987 1543.98 163.668 1543.98 Q161.492 1543.98 159.223 1543.61 Q156.978 1543.24 154.571 1542.5 L154.571 1537.8 Q156.654 1538.93 158.876 1539.49 Q161.098 1540.04 163.575 1540.04 Q167.58 1540.04 169.918 1537.94 Q172.256 1535.83 172.256 1532.22 Q172.256 1528.61 169.918 1526.5 Q167.58 1524.39 163.575 1524.39 Q161.7 1524.39 159.825 1524.81 Q157.973 1525.23 156.029 1526.11 L156.029 1508.75 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M164.987 1078.45 Q161.376 1078.45 159.548 1082.02 Q157.742 1085.56 157.742 1092.69 Q157.742 1099.8 159.548 1103.36 Q161.376 1106.9 164.987 1106.9 Q168.622 1106.9 170.427 1103.36 Q172.256 1099.8 172.256 1092.69 Q172.256 1085.56 170.427 1082.02 Q168.622 1078.45 164.987 1078.45 M164.987 1074.75 Q170.797 1074.75 173.853 1079.36 Q176.932 1083.94 176.932 1092.69 Q176.932 1101.42 173.853 1106.02 Q170.797 1110.61 164.987 1110.61 Q159.177 1110.61 156.098 1106.02 Q153.043 1101.42 153.043 1092.69 Q153.043 1083.94 156.098 1079.36 Q159.177 1074.75 164.987 1074.75 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M156.029 642.004 L174.385 642.004 L174.385 645.939 L160.311 645.939 L160.311 654.411 Q161.33 654.064 162.348 653.902 Q163.367 653.717 164.385 653.717 Q170.172 653.717 173.552 656.888 Q176.932 660.06 176.932 665.476 Q176.932 671.055 173.46 674.157 Q169.987 677.235 163.668 677.235 Q161.492 677.235 159.223 676.865 Q156.978 676.495 154.571 675.754 L154.571 671.055 Q156.654 672.189 158.876 672.745 Q161.098 673.3 163.575 673.3 Q167.58 673.3 169.918 671.194 Q172.256 669.087 172.256 665.476 Q172.256 661.865 169.918 659.759 Q167.58 657.652 163.575 657.652 Q161.7 657.652 159.825 658.069 Q157.973 658.486 156.029 659.365 L156.029 642.004 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M125.636 239.258 L133.275 239.258 L133.275 212.892 L124.964 214.559 L124.964 210.299 L133.228 208.633 L137.904 208.633 L137.904 239.258 L145.543 239.258 L145.543 243.193 L125.636 243.193 L125.636 239.258 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M164.987 211.711 Q161.376 211.711 159.548 215.276 Q157.742 218.818 157.742 225.948 Q157.742 233.054 159.548 236.619 Q161.376 240.16 164.987 240.16 Q168.622 240.16 170.427 236.619 Q172.256 233.054 172.256 225.948 Q172.256 218.818 170.427 215.276 Q168.622 211.711 164.987 211.711 M164.987 208.008 Q170.797 208.008 173.853 212.614 Q176.932 217.198 176.932 225.948 Q176.932 234.674 173.853 239.281 Q170.797 243.864 164.987 243.864 Q159.177 243.864 156.098 239.281 Q153.043 234.674 153.043 225.948 Q153.043 217.198 156.098 212.614 Q159.177 208.008 164.987 208.008 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M25.9905 1019.46 L25.9905 1013.25 L55.9093 1002.11 L25.9905 990.972 L25.9905 984.766 L61.6384 998.134 L61.6384 1006.09 L25.9905 1019.46 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M43.719 960.481 Q43.719 967.578 45.3422 970.316 Q46.9655 973.053 50.8804 973.053 Q53.9996 973.053 55.8457 971.016 Q57.6599 968.947 57.6599 965.414 Q57.6599 960.544 54.2224 957.616 Q50.7531 954.656 45.0239 954.656 L43.719 954.656 L43.719 960.481 M41.3 948.799 L61.6384 948.799 L61.6384 954.656 L56.2276 954.656 Q59.4741 956.661 61.0337 959.653 Q62.5615 962.645 62.5615 966.974 Q62.5615 972.448 59.5059 975.695 Q56.4186 978.909 51.2623 978.909 Q45.2467 978.909 42.1912 974.899 Q39.1357 970.857 39.1357 962.868 L39.1357 954.656 L38.5628 954.656 Q34.5205 954.656 32.3244 957.329 Q30.0964 959.971 30.0964 964.777 Q30.0964 967.833 30.8284 970.729 Q31.5605 973.626 33.0246 976.299 L27.6137 976.299 Q26.3724 973.085 25.7677 970.061 Q25.1311 967.037 25.1311 964.173 Q25.1311 956.438 29.1415 952.619 Q33.1519 948.799 41.3 948.799 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M31.465 916.08 Q30.8921 917.066 30.6375 918.244 Q30.351 919.39 30.351 920.79 Q30.351 925.756 33.5975 928.429 Q36.8122 931.071 42.8596 931.071 L61.6384 931.071 L61.6384 936.959 L25.9905 936.959 L25.9905 931.071 L31.5287 931.071 Q28.2821 929.225 26.7225 926.265 Q25.1311 923.305 25.1311 919.072 Q25.1311 918.467 25.2266 917.735 Q25.2903 917.003 25.4494 916.112 L31.465 916.08 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M25.9905 909.937 L25.9905 904.08 L61.6384 904.08 L61.6384 909.937 L25.9905 909.937 M12.1132 909.937 L12.1132 904.08 L19.5293 904.08 L19.5293 909.937 L12.1132 909.937 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M43.719 875.626 Q43.719 882.723 45.3422 885.461 Q46.9655 888.198 50.8804 888.198 Q53.9996 888.198 55.8457 886.161 Q57.6599 884.092 57.6599 880.559 Q57.6599 875.689 54.2224 872.761 Q50.7531 869.801 45.0239 869.801 L43.719 869.801 L43.719 875.626 M41.3 863.945 L61.6384 863.945 L61.6384 869.801 L56.2276 869.801 Q59.4741 871.806 61.0337 874.798 Q62.5615 877.79 62.5615 882.119 Q62.5615 887.593 59.5059 890.84 Q56.4186 894.054 51.2623 894.054 Q45.2467 894.054 42.1912 890.044 Q39.1357 886.002 39.1357 878.013 L39.1357 869.801 L38.5628 869.801 Q34.5205 869.801 32.3244 872.475 Q30.0964 875.116 30.0964 879.922 Q30.0964 882.978 30.8284 885.874 Q31.5605 888.771 33.0246 891.444 L27.6137 891.444 Q26.3724 888.23 25.7677 885.206 Q25.1311 882.182 25.1311 879.318 Q25.1311 871.583 29.1415 867.764 Q33.1519 863.945 41.3 863.945 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M43.8463 826.291 Q37.3851 826.291 33.7248 828.965 Q30.0327 831.607 30.0327 836.254 Q30.0327 840.901 33.7248 843.574 Q37.3851 846.216 43.8463 846.216 Q50.3075 846.216 53.9996 843.574 Q57.6599 840.901 57.6599 836.254 Q57.6599 831.607 53.9996 828.965 Q50.3075 826.291 43.8463 826.291 M31.4013 846.216 Q28.2185 844.37 26.6907 841.569 Q25.1311 838.736 25.1311 834.821 Q25.1311 828.328 30.2873 824.286 Q35.4436 820.212 43.8463 820.212 Q52.249 820.212 57.4052 824.286 Q62.5615 828.328 62.5615 834.821 Q62.5615 838.736 61.0337 841.569 Q59.4741 844.37 56.2912 846.216 L61.6384 846.216 L61.6384 852.104 L12.1132 852.104 L12.1132 846.216 L31.4013 846.216 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M12.1132 810.504 L12.1132 804.648 L61.6384 804.648 L61.6384 810.504 L12.1132 810.504 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip350)" d="M42.3504 761.902 L45.2149 761.902 L45.2149 788.829 Q51.2623 788.447 54.4452 785.201 Q57.5962 781.922 57.5962 776.098 Q57.5962 772.724 56.7687 769.573 Q55.9411 766.39 54.2861 763.271 L59.8242 763.271 Q61.161 766.422 61.8612 769.732 Q62.5615 773.042 62.5615 776.448 Q62.5615 784.978 57.5962 789.975 Q52.631 794.94 44.1646 794.94 Q35.4117 794.94 30.2873 790.23 Q25.1311 785.487 25.1311 777.466 Q25.1311 770.273 29.7781 766.104 Q34.3932 761.902 42.3504 761.902 M40.6316 767.759 Q35.8255 767.822 32.9609 770.464 Q30.0964 773.074 30.0964 777.403 Q30.0964 782.304 32.8654 785.264 Q35.6345 788.193 40.6634 788.638 L40.6316 767.759 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><polyline clip-path="url(#clip352)" style="stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="285.841,819.313 289.5,857.437 293.158,897.563 296.816,939.181 300.474,981.727 304.132,1024.58 307.79,1067.06 311.448,1108.42 315.106,1147.91 318.765,1184.71 322.423,1218.02 326.081,1247.06 329.739,1271.14 333.397,1289.63 337.055,1302.07 340.713,1308.13 344.371,1307.66 348.029,1300.71 351.688,1287.51 355.346,1268.53 359.004,1244.41 362.662,1216.05 366.32,1184.51 369.978,1151.04 373.636,1116.96 377.294,1083.62 380.953,1052.29 384.611,1024.12 388.269,1000.02 391.927,980.625 395.585,966.249 399.243,956.872 402.901,952.131 406.559,951.343 410.218,953.55 413.876,957.593 417.534,962.216 421.192,966.184 424.85,968.422 428.508,968.133 432.166,964.882 435.824,958.631 439.482,949.706 443.141,938.708 446.799,926.38 450.457,913.461 454.115,900.552 457.773,888.026 461.431,875.994 465.089,864.333 468.747,852.751 472.406,840.871 476.064,828.314 479.722,814.753 483.38,799.96 487.038,783.824 490.696,766.353 494.354,747.678 498.012,728.039 501.671,707.776 505.329,687.321 508.987,667.188 512.645,647.977 516.303,630.377 519.961,615.165 523.619,603.203 527.277,595.425 530.935,592.817 534.594,596.381 538.252,607.087 541.91,625.8 545.568,653.189 549.226,689.615 552.884,735.019 556.542,788.831 560.2,849.922 563.859,916.629 567.517,986.85 571.175,1058.2 574.833,1128.2 578.491,1194.5 582.149,1255.1 585.807,1308.42 589.465,1353.47 593.123,1389.78 596.782,1417.4 600.44,1436.74 604.098,1448.46 607.756,1453.32 611.414,1452.05 615.072,1445.27 618.73,1433.46 622.388,1416.98 626.047,1396.09 629.705,1371.06 633.363,1342.25 637.021,1310.23 640.679,1275.86 644.337,1240.29 647.995,1204.96 651.653,1171.48 655.312,1141.45 658.97,1116.28 662.628,1096.98 666.286,1083.98 669.944,1077.09 673.602,1075.5 677.26,1077.86 680.918,1082.55 684.576,1087.88 688.235,1092.32 691.893,1094.75 695.551,1094.51 699.209,1091.42 702.867,1085.69 706.525,1077.79 710.183,1068.27 713.841,1057.67 717.5,1046.37 721.158,1034.6 724.816,1022.41 728.474,1009.74 732.132,996.454 735.79,982.41 739.448,967.482 743.106,951.572 746.765,934.598 750.423,916.484 754.081,897.142 757.739,876.474 761.397,854.397 765.055,830.882 768.713,806.007 772.371,780.019 776.029,753.39 779.688,726.845 783.346,701.364 787.004,678.135 790.662,658.468 794.32,643.676 797.978,634.942 801.636,633.2 805.294,639.047 808.953,652.703 812.611,674.018 816.269,702.524 819.927,737.508 823.585,778.102 827.243,823.36 830.901,872.311 834.559,924 838.218,977.495 841.876,1031.88 845.534,1086.27 849.192,1139.74 852.85,1191.4 856.508,1240.35 860.166,1285.72 863.824,1326.74 867.482,1362.73 871.141,1393.18 874.799,1417.73 878.457,1436.18 882.115,1448.48 885.773,1454.66 889.431,1454.8 893.089,1449.06 896.747,1437.72 900.406,1421.23 904.064,1400.33 907.722,1376.11 911.38,1349.98 915.038,1323.52 918.696,1298.3 922.354,1275.53 926.012,1255.91 929.67,1239.39 933.329,1225.3 936.987,1212.43 940.645,1199.31 944.303,1184.49 947.961,1166.74 951.619,1145.2 955.277,1119.43 958.935,1089.38 962.594,1055.33 966.252,1017.8 969.91,977.473 973.568,935.072 977.226,891.337 980.884,846.973 984.542,802.62 988.2,758.849 991.859,716.157 995.517,674.966 999.175,635.625 1002.83,598.405 1006.49,563.496 1010.15,531.003 1013.81,500.95 1017.47,473.292 1021.12,447.932 1024.78,424.758 1028.44,403.667 1032.1,384.593 1035.76,367.524 1039.41,352.498 1043.07,339.599 1046.73,328.949 1050.39,320.699 1054.05,315.025 1057.7,312.127 1061.36,312.234 1065.02,315.589 1068.68,322.448 1072.34,333.061 1076,347.653 1079.65,366.406 1083.31,389.442 1086.97,416.811 1090.63,448.482 1094.29,484.334 1097.94,524.158 1101.6,567.654 1105.26,614.422 1108.92,663.961 1112.58,715.655 1116.23,768.752 1119.89,822.343 1123.55,875.346 1127.21,926.494 1130.87,974.349 1134.53,1017.36 1138.18,1053.96 1141.84,1082.71 1145.5,1102.49 1149.16,1112.66 1152.82,1113.27 1156.47,1105.07 1160.13,1089.52 1163.79,1068.64 1167.45,1044.77 1171.11,1020.31 1174.76,997.37 1178.42,977.582 1182.08,961.902 1185.74,950.543 1189.4,942.992 1193.06,938.102 1196.71,934.255 1200.37,929.573 1204.03,922.154 1207.69,910.301 1211.35,892.725 1215,868.679 1218.66,838.027 1222.32,801.237 1225.98,759.325 1229.64,713.746 1233.29,666.272 1236.95,618.85 1240.61,573.441 1244.27,531.86 1247.93,495.612 1251.59,465.76 1255.24,442.84 1258.9,426.857 1262.56,417.343 1266.22,413.461 1269.88,414.119 1273.53,418.083 1277.19,424.078 1280.85,430.889 1284.51,437.46 1288.17,442.981 1291.82,446.946 1295.48,449.173 1299.14,449.786 1302.8,449.174 1306.46,447.935 1310.11,446.835 1313.77,446.781 1317.43,448.803 1321.09,454.053 1324.75,463.794 1328.41,479.364 1332.06,502.107 1335.72,533.257 1339.38,573.77 1343.04,624.13 1346.7,684.16 1350.35,752.863 1354.01,828.369 1357.67,907.987 1361.33,988.392 1364.99,1065.93 1368.64,1136.98 1372.3,1198.33 1375.96,1247.47 1379.62,1282.77 1383.28,1303.52 1386.94,1309.84 1390.59,1302.53 1394.25,1282.93 1397.91,1252.72 1401.57,1213.87 1405.23,1168.49 1408.88,1118.76 1412.54,1066.81 1416.2,1014.64 1419.86,963.977 1423.52,916.222 1427.17,872.396 1430.83,833.133 1434.49,798.709 1438.15,769.101 1441.81,744.058 1445.47,723.172 1449.12,705.945 1452.78,691.843 1456.44,680.337 1460.1,670.925 1463.76,663.151 1467.41,656.606 1471.07,650.933 1474.73,645.818 1478.39,640.984 1482.05,636.185 1485.7,631.198 1489.36,625.813 1493.02,619.833 1496.68,613.066 1500.34,605.331 1504,596.453 1507.65,586.282 1511.31,574.696 1514.97,561.621 1518.63,547.055 1522.29,531.098 1525.94,513.982 1529.6,496.118 1533.26,478.145 1536.92,460.984 1540.58,445.888 1544.23,434.486 1547.89,428.79 1551.55,431.147 1555.21,444.1 1558.87,470.114 1562.53,511.172 1566.18,568.222 1569.84,640.586 1573.5,725.472 1577.16,817.796 1580.82,910.482 1584.47,995.306 1588.13,1064.11 1591.79,1110.11 1595.45,1129.06 1599.11,1120.07 1602.76,1086.13 1606.42,1034.13 1610.08,974.173 1613.74,918.081 1617.4,877.21 1621.06,860.19 1624.71,871.08 1628.37,908.377 1632.03,965.245 1635.69,1031.3 1639.35,1095.72 1643,1150.56 1646.66,1192.55 1650.32,1222.65 1653.98,1243.83 1657.64,1258.72 1661.29,1268.43 1664.95,1272.63 1668.61,1270.59 1672.27,1262.23 1675.93,1248.64 1679.58,1231.92 1683.24,1214.66 1686.9,1199.24 1690.56,1187.43 1694.22,1180.13 1697.88,1177.46 1701.53,1178.93 1705.19,1183.65 1708.85,1190.52 1712.51,1198.39 1716.17,1206.09 1719.82,1212.53 1723.48,1216.72 1727.14,1217.79 1730.8,1215.13 1734.46,1208.43 1738.11,1197.83 1741.77,1183.96 1745.43,1167.97 1749.09,1151.32 1752.75,1135.46 1756.41,1121.46 1760.06,1109.65 1763.72,1099.56 1767.38,1090.09 1771.04,1079.95 1774.7,1068.09 1778.35,1054.07 1782.01,1038.09 1785.67,1020.77 1789.33,1002.88 1792.99,984.992 1796.64,967.326 1800.3,949.739 1803.96,931.856 1807.62,913.246 1811.28,893.532 1814.94,872.407 1818.59,849.582 1822.25,824.722 1825.91,797.443 1829.57,767.407 1833.23,734.498 1836.88,699.055 1840.54,662.064 1844.2,625.227 1847.86,590.826 1851.52,561.378 1855.17,539.153 1858.83,525.726 1862.49,521.713 1866.15,526.751 1869.81,539.711 1873.47,559.027 1877.12,583.028 1880.78,610.189 1884.44,639.266 1888.1,669.334 1891.76,699.752 1895.41,730.1 1899.07,760.118 1902.73,789.647 1906.39,818.594 1910.05,846.911 1913.7,874.584 1917.36,901.627 1921.02,928.081 1924.68,954.003 1928.34,979.462 1932,1004.52 1935.65,1029.21 1939.31,1053.52 1942.97,1077.37 1946.63,1100.57 1950.29,1122.82 1953.94,1143.71 1957.6,1162.72 1961.26,1179.25 1964.92,1192.68 1968.58,1202.46 1972.23,1208.18 1975.89,1209.65 1979.55,1206.94 1983.21,1200.46 1986.87,1190.82 1990.53,1178.84 1994.18,1165.37 1997.84,1151.14 2001.5,1136.63 2005.16,1121.99 2008.82,1106.98 2012.47,1091.08 2016.13,1073.5 2019.79,1053.4 2023.45,1029.95 2027.11,1002.53 2030.76,970.722 2034.42,934.395 2038.08,893.685 2041.74,848.959 2045.4,800.771 2049.06,749.818 2052.71,696.901 2056.37,642.884 2060.03,588.675 2063.69,535.186 2067.35,483.302 2071,433.837 2074.66,387.491 2078.32,344.816 2081.98,306.202 2085.64,271.886 2089.29,241.982 2092.95,216.515 2096.61,195.454 2100.27,178.733 2103.93,166.27 2107.58,157.986 2111.24,153.835 2114.9,153.823 2118.56,158.022 2122.22,166.567 2125.88,179.633 2129.53,197.399 2133.19,220.011 2136.85,247.542 2140.51,279.965 2144.17,317.136 2147.82,358.794 2151.48,404.563 2155.14,453.965 2158.8,506.432 2162.46,561.315 2166.11,617.883 2169.77,675.311 2173.43,732.656 2177.09,788.838 2180.75,842.619 2184.41,892.617 2188.06,937.354 2191.72,975.356 2195.38,1005.32 2199.04,1026.29 2202.7,1037.88 2206.35,1040.38 2210.01,1034.8 2213.67,1022.83 2217.33,1006.57 2220.99,988.288 2224.64,970.081 2228.3,953.595 2231.96,939.822 2235.62,929.009 2239.28,920.663 2242.94,913.661 2246.59,906.438 2250.25,897.214 2253.91,884.244 2257.57,866.047 2261.23,841.575 2264.88,810.323 2268.54,772.358 2272.2,728.287 2275.86,679.188 2279.52,626.514 2283.17,571.987 2286.83,517.494 2290.49,464.962 2294.15,416.223 2297.81,372.867 2301.47,336.099 2305.12,306.63 2308.78,284.633 2312.44,269.76 2316.1,261.22 2319.76,257.897 2323.41,258.48 2327.07,261.608 2330.73,266.01 2334.39,270.639 2338.05,274.768 2341.7,278.047 2345.36,280.51 2349.02,282.558 2352.68,284.919 2356.34,288.61 2360,294.898 2363.65,305.254 2367.31,321.281 2370.97,344.618 2374.63,376.796 2378.29,419.058 2381.94,472.165 2385.6,536.211 2389.26,610.477 2392.92,693.342 2396.58,782.275 2400.23,873.907 2403.89,964.202 2407.55,1048.73 2411.21,1123.07 2414.87,1183.2 2418.53,1226.02 2422.18,1249.62 2425.84,1253.54 2429.5,1238.7 2433.16,1207.22 2436.82,1162.16 2440.47,1107.13 2444.13,1045.97 2447.79,982.402 2451.45,919.747 2455.11,860.743 2458.76,807.429 2462.42,761.134 2466.08,722.544 2469.74,691.817 2473.4,668.73 2477.06,652.818 2480.71,643.491 2484.37,640.123 2488.03,642.097 2491.69,648.821 2495.35,659.713 2499,674.175 2502.66,691.551 2506.32,711.096 2509.98,731.95 2513.64,753.133 2517.29,773.57 2520.95,792.133 2524.61,807.724 2528.27,819.37 2531.93,826.337 2535.58,828.244 2539.24,825.165 2542.9,817.686 2546.56,806.916 2550.22,794.412 2553.88,782.026 2557.53,771.65 2561.19,764.909 2564.85,762.84 2568.51,765.63 2572.17,772.532 "></polyline>
<polyline clip-path="url(#clip352)" style="stroke:#e26f46; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="285.841,1474.45 289.5,1473.42 293.158,1468.55 296.816,1460.19 300.474,1448.65 304.132,1434.16 307.79,1416.9 311.448,1397.07 315.106,1374.92 318.765,1350.78 322.423,1325.11 326.081,1298.51 329.739,1271.73 333.397,1245.56 337.055,1220.82 340.713,1198.23 344.371,1178.32 348.029,1161.34 351.688,1147.26 355.346,1135.71 359.004,1126.06 362.662,1117.46 366.32,1109 369.978,1099.74 373.636,1088.89 377.294,1075.82 380.953,1060.17 384.611,1041.81 388.269,1020.85 391.927,997.628 395.585,972.614 399.243,946.381 402.901,919.532 406.559,892.642 410.218,866.199 413.876,840.563 417.534,815.937 421.192,792.356 424.85,769.702 428.508,747.74 432.166,726.164 435.824,704.656 439.482,682.944 443.141,660.852 446.799,638.343 450.457,615.544 454.115,592.753 457.773,570.426 461.431,549.142 465.089,529.567 468.747,512.401 472.406,498.342 476.064,488.054 479.722,482.148 483.38,481.165 487.038,485.559 490.696,495.682 494.354,511.768 498.012,533.923 501.671,562.112 505.329,596.164 508.987,635.776 512.645,680.524 516.303,729.874 519.961,783.184 523.619,839.707 527.277,898.579 530.935,958.813 534.594,1019.28 538.252,1078.72 541.91,1135.72 545.568,1188.78 549.226,1236.35 552.884,1276.91 556.542,1309.11 560.2,1331.82 563.859,1344.28 567.517,1346.11 571.175,1337.41 574.833,1318.73 578.491,1291.1 582.149,1256 585.807,1215.27 589.465,1171.03 593.123,1125.52 596.782,1080.94 600.44,1039.33 604.098,1002.37 607.756,971.35 611.414,947.109 615.072,930.011 618.73,919.977 622.388,916.506 626.047,918.721 629.705,925.422 633.363,935.161 637.021,946.336 640.679,957.322 644.337,966.608 647.995,972.957 651.653,975.526 655.312,973.951 658.97,968.368 662.628,959.348 666.286,947.786 669.944,934.726 673.602,921.191 677.26,908.024 680.918,895.779 684.576,884.684 688.235,874.666 691.893,865.429 695.551,856.551 699.209,847.581 702.867,838.109 706.525,827.811 710.183,816.465 713.841,803.955 717.5,790.259 721.158,775.435 724.816,759.617 728.474,743.002 732.132,725.857 735.79,708.523 739.448,691.425 743.106,675.074 746.765,660.075 750.423,647.116 754.081,636.955 757.739,630.411 761.397,628.341 765.055,631.618 768.713,641.093 772.371,657.546 776.029,681.615 779.688,713.693 783.346,753.833 787.004,801.644 790.662,856.227 794.32,916.162 797.978,979.568 801.636,1044.24 805.294,1107.82 808.953,1168.04 812.611,1222.91 816.269,1270.84 819.927,1310.79 823.585,1342.18 827.243,1364.9 830.901,1379.15 834.559,1385.32 838.218,1383.88 841.876,1375.31 845.534,1360.06 849.192,1338.58 852.85,1311.38 856.508,1279.08 860.166,1242.55 863.824,1202.92 867.482,1161.66 871.141,1120.48 874.799,1081.28 878.457,1045.98 882.115,1016.32 885.773,993.744 889.431,979.166 893.089,972.894 896.747,974.56 900.406,983.139 904.064,997.068 907.722,1014.44 911.38,1033.27 915.038,1051.78 918.696,1068.56 922.354,1082.73 926.012,1093.87 929.67,1101.89 933.329,1106.89 936.987,1109 940.645,1108.34 944.303,1104.96 947.961,1098.96 951.619,1090.48 955.277,1079.74 958.935,1067.05 962.594,1052.75 966.252,1037.12 969.91,1020.41 973.568,1002.74 977.226,984.106 980.884,964.444 984.542,943.622 988.2,921.521 991.859,898.095 995.517,873.442 999.175,847.866 1002.83,821.929 1006.49,796.471 1010.15,772.608 1013.81,751.668 1017.47,735.108 1021.12,724.372 1024.78,720.752 1028.44,725.237 1032.1,738.4 1035.76,760.333 1039.41,790.627 1043.07,828.424 1046.73,872.493 1050.39,921.342 1054.05,973.33 1057.7,1026.77 1061.36,1080.01 1065.02,1131.51 1068.68,1179.93 1072.34,1224.14 1076,1263.29 1079.65,1296.81 1083.31,1324.48 1086.97,1346.36 1090.63,1362.76 1094.29,1374.18 1097.94,1381.23 1101.6,1384.56 1105.26,1384.74 1108.92,1382.27 1112.58,1377.48 1116.23,1370.6 1119.89,1361.74 1123.55,1350.94 1127.21,1338.29 1130.87,1323.92 1134.53,1308.1 1138.18,1291.26 1141.84,1273.93 1145.5,1256.62 1149.16,1239.75 1152.82,1223.48 1156.47,1207.65 1160.13,1191.84 1163.79,1175.44 1167.45,1157.84 1171.11,1138.57 1174.76,1117.44 1178.42,1094.55 1182.08,1070.24 1185.74,1045.01 1189.4,1019.41 1193.06,993.931 1196.71,968.918 1200.37,944.539 1204.03,920.779 1207.69,897.469 1211.35,874.334 1215,851.042 1218.66,827.237 1222.32,802.565 1225.98,776.692 1229.64,749.346 1233.29,720.382 1236.95,689.881 1240.61,658.27 1244.27,626.42 1247.93,595.691 1251.59,567.848 1255.24,544.861 1258.9,528.603 1262.56,520.527 1266.22,521.424 1269.88,531.34 1273.53,549.652 1277.19,575.269 1280.85,606.881 1284.51,643.176 1288.17,682.992 1291.82,725.39 1295.48,769.66 1299.14,815.294 1302.8,861.942 1306.46,909.357 1310.11,957.355 1313.77,1005.77 1317.43,1054.4 1321.09,1103.01 1324.75,1151.21 1328.41,1198.48 1332.06,1244.1 1335.72,1287.15 1339.38,1326.51 1343.04,1360.92 1346.7,1389.1 1350.35,1409.86 1354.01,1422.25 1357.67,1425.74 1361.33,1420.3 1364.99,1406.55 1368.64,1385.75 1372.3,1359.71 1375.96,1330.63 1379.62,1300.81 1383.28,1272.26 1386.94,1246.51 1390.59,1224.35 1394.25,1205.82 1397.91,1190.32 1401.57,1176.8 1405.23,1164.01 1408.88,1150.68 1412.54,1135.78 1416.2,1118.56 1419.86,1098.64 1423.52,1075.97 1427.17,1050.78 1430.83,1023.51 1434.49,994.672 1438.15,964.824 1441.81,934.483 1445.47,904.09 1449.12,873.99 1452.78,844.428 1456.44,815.558 1460.1,787.455 1463.76,760.132 1467.41,733.563 1471.07,707.696 1474.73,682.467 1478.39,657.822 1482.05,633.721 1485.7,610.152 1489.36,587.145 1493.02,564.776 1496.68,543.177 1500.34,522.55 1504,503.173 1507.65,485.41 1511.31,469.721 1514.97,456.671 1518.63,446.934 1522.29,441.286 1525.94,440.6 1529.6,445.805 1533.26,457.843 1536.92,477.584 1540.58,505.712 1544.23,542.585 1547.89,588.061 1551.55,641.325 1555.21,700.732 1558.87,763.731 1562.53,826.913 1566.18,886.266 1569.84,937.65 1573.5,977.48 1577.16,1003.51 1580.82,1015.5 1584.47,1015.45 1588.13,1007.23 1591.79,995.425 1595.45,983.713 1599.11,973.41 1602.76,962.856 1606.42,948.074 1610.08,924.498 1613.74,889.037 1617.4,841.595 1621.06,785.503 1624.71,726.834 1628.37,672.876 1632.03,630.223 1635.69,603.045 1639.35,592.225 1643,595.76 1646.66,610.14 1650.32,631.832 1653.98,658.106 1657.64,687.092 1661.29,717.358 1664.95,747.482 1668.61,775.879 1672.27,800.962 1675.93,821.482 1679.58,836.816 1683.24,847.05 1686.9,852.837 1690.56,855.138 1694.22,854.953 1697.88,853.157 1701.53,850.431 1705.19,847.292 1708.85,844.15 1712.51,841.372 1716.17,839.316 1719.82,838.328 1723.48,838.707 1727.14,840.637 1730.8,844.105 1734.46,848.835 1738.11,854.267 1741.77,859.607 1745.43,863.964 1749.09,866.539 1752.75,866.801 1756.41,864.579 1760.06,860.003 1763.72,853.34 1767.38,844.801 1771.04,834.409 1774.7,821.99 1778.35,807.256 1782.01,789.933 1785.67,769.877 1789.33,747.147 1792.99,722.035 1796.64,695.066 1800.3,666.973 1803.96,638.68 1807.62,611.303 1811.28,586.145 1814.94,564.694 1818.59,548.595 1822.25,539.598 1825.91,539.504 1829.57,550.1 1833.23,573.065 1836.88,609.806 1840.54,661.191 1844.2,727.208 1847.86,806.613 1851.52,896.735 1855.17,993.559 1858.83,1092.14 1862.49,1187.3 1866.15,1274.3 1869.81,1349.55 1873.47,1410.82 1877.12,1457.36 1880.78,1489.65 1884.44,1509.05 1888.1,1517.5 1891.76,1517.1 1895.41,1509.93 1899.07,1497.88 1902.73,1482.54 1906.39,1465.17 1910.05,1446.72 1913.7,1427.89 1917.36,1409.1 1921.02,1390.6 1924.68,1372.49 1928.34,1354.77 1932,1337.35 1935.65,1320.1 1939.31,1302.89 1942.97,1285.59 1946.63,1268.12 1950.29,1250.47 1953.94,1232.71 1957.6,1215.01 1961.26,1197.64 1964.92,1180.91 1968.58,1165.15 1972.23,1150.63 1975.89,1137.51 1979.55,1125.79 1983.21,1115.29 1986.87,1105.69 1990.53,1096.59 1994.18,1087.57 1997.84,1078.26 2001.5,1068.38 2005.16,1057.76 2008.82,1046.29 2012.47,1033.93 2016.13,1020.68 2019.79,1006.51 2023.45,991.44 2027.11,975.469 2030.76,958.605 2034.42,940.846 2038.08,922.165 2041.74,902.503 2045.4,881.766 2049.06,859.844 2052.71,836.657 2056.37,812.223 2060.03,786.746 2063.69,760.719 2067.35,735.019 2071,710.966 2074.66,690.311 2078.32,675.134 2081.98,667.629 2085.64,669.814 2089.29,683.211 2092.95,708.576 2096.61,745.747 2100.27,793.643 2103.93,850.398 2107.58,913.596 2111.24,980.52 2114.9,1048.4 2118.56,1114.6 2122.22,1176.79 2125.88,1233.03 2129.53,1281.9 2133.19,1322.52 2136.85,1354.59 2140.51,1378.35 2144.17,1394.5 2147.82,1404.03 2151.48,1408.11 2155.14,1407.89 2158.8,1404.41 2162.46,1398.51 2166.11,1390.77 2169.77,1381.55 2173.43,1371 2177.09,1359.17 2180.75,1346.03 2184.41,1331.6 2188.06,1315.95 2191.72,1299.32 2195.38,1281.99 2199.04,1264.28 2202.7,1246.43 2206.35,1228.48 2210.01,1210.28 2213.67,1191.52 2217.33,1171.8 2220.99,1150.8 2224.64,1128.39 2228.3,1104.63 2231.96,1079.79 2235.62,1054.29 2239.28,1028.57 2242.94,1003.02 2246.59,977.899 2250.25,953.333 2253.91,929.29 2257.57,905.625 2261.23,882.113 2264.88,858.485 2268.54,834.44 2272.2,809.665 2275.86,783.854 2279.52,756.753 2283.17,728.246 2286.83,698.472 2290.49,667.959 2294.15,637.738 2297.81,609.388 2301.47,584.943 2305.12,566.653 2308.78,556.628 2312.44,556.461 2316.1,566.946 2319.76,587.992 2323.41,618.736 2327.07,657.796 2330.73,703.575 2334.39,754.504 2338.05,809.209 2341.7,866.566 2345.36,925.694 2349.02,985.898 2352.68,1046.6 2356.34,1107.25 2360,1167.26 2363.65,1225.99 2367.31,1282.62 2370.97,1336.24 2374.63,1385.83 2378.29,1430.34 2381.94,1468.78 2385.6,1500.27 2389.26,1524.16 2392.92,1539.98 2396.58,1547.52 2400.23,1546.77 2403.89,1538.07 2407.55,1522.19 2411.21,1500.4 2414.87,1474.51 2418.53,1446.66 2422.18,1418.97 2425.84,1393.09 2429.5,1369.91 2433.16,1349.38 2436.82,1330.74 2440.47,1312.8 2444.13,1294.33 2447.79,1274.37 2451.45,1252.44 2455.11,1228.53 2458.76,1203.12 2462.42,1176.98 2466.08,1151.05 2469.74,1126.29 2473.4,1103.53 2477.06,1083.4 2480.71,1066.29 2484.37,1052.31 2488.03,1041.34 2491.69,1033.04 2495.35,1026.89 2499,1022.29 2502.66,1018.55 2506.32,1014.97 2509.98,1010.92 2513.64,1005.81 2517.29,999.187 2520.95,990.689 2524.61,980.055 2528.27,967.079 2531.93,951.557 2535.58,933.233 2539.24,911.766 2542.9,886.726 2546.56,857.641 2550.22,824.091 2553.88,785.83 2557.53,742.914 2561.19,695.792 2564.85,645.32 2568.51,592.683 2572.17,539.234 "></polyline>
<polyline clip-path="url(#clip352)" style="stroke:#3da44d; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="285.841,1089.95 289.5,1058.42 293.158,1032.51 296.816,1012.52 300.474,998.479 304.132,990.104 307.79,986.869 311.448,988.023 315.106,992.633 318.765,999.651 322.423,1007.98 326.081,1016.55 329.739,1024.42 333.397,1030.81 337.055,1035.2 340.713,1037.28 344.371,1037.02 348.029,1034.54 351.688,1030.12 355.346,1024.07 359.004,1016.67 362.662,1008.16 366.32,998.665 369.978,988.218 373.636,976.769 377.294,964.212 380.953,950.409 384.611,935.219 388.269,918.502 391.927,900.14 395.585,880.043 399.243,858.166 402.901,834.532 406.559,809.266 410.218,782.625 413.876,755.035 417.534,727.105 421.192,699.638 424.85,673.61 428.508,650.136 432.166,630.42 435.824,615.689 439.482,607.122 443.141,605.779 446.799,612.527 450.457,627.97 454.115,652.389 457.773,685.7 461.431,727.435 465.089,776.756 468.747,832.493 472.406,893.205 476.064,957.26 479.722,1022.91 483.38,1088.36 487.038,1151.89 490.696,1211.87 494.354,1266.89 498.012,1315.83 501.671,1357.88 505.329,1392.62 508.987,1419.96 512.645,1440.12 516.303,1453.51 519.961,1460.67 523.619,1462.15 527.277,1458.42 530.935,1449.87 534.594,1436.78 538.252,1419.43 541.91,1398.16 545.568,1373.49 549.226,1346.22 552.884,1317.42 556.542,1288.44 560.2,1260.74 563.859,1235.66 567.517,1214.23 571.175,1196.93 574.833,1183.63 578.491,1173.58 582.149,1165.54 585.807,1158.05 589.465,1149.63 593.123,1138.98 596.782,1125.18 600.44,1107.74 604.098,1086.56 607.756,1061.94 611.414,1034.45 615.072,1004.82 618.73,973.903 622.388,942.55 626.047,911.549 629.705,881.569 633.363,853.111 637.021,826.477 640.679,801.756 644.337,778.833 647.995,757.424 651.653,737.124 655.312,717.472 658.97,698.017 662.628,678.379 666.286,658.302 669.944,637.687 673.602,616.616 677.26,595.357 680.918,574.339 684.576,554.121 688.235,535.33 691.893,518.607 695.551,504.561 699.209,493.733 702.867,486.577 706.525,483.46 710.183,484.652 713.841,490.34 717.5,500.621 721.158,515.513 724.816,534.957 728.474,558.826 732.132,586.933 735.79,619.038 739.448,654.856 743.106,694.059 746.765,736.276 750.423,781.084 754.081,827.998 757.739,876.463 761.397,925.832 765.055,975.352 768.713,1024.15 772.371,1071.21 776.029,1115.41 779.688,1155.52 783.346,1190.27 787.004,1218.41 790.662,1238.87 794.32,1250.79 797.978,1253.71 801.636,1247.6 805.294,1232.95 808.953,1210.76 812.611,1182.48 816.269,1149.95 819.927,1115.21 823.585,1080.34 827.243,1047.27 830.901,1017.66 834.559,992.732 838.218,973.251 841.876,959.452 845.534,951.074 849.192,947.391 852.85,947.277 856.508,949.304 860.166,951.863 863.824,953.306 867.482,952.107 871.141,947.018 874.799,937.194 878.457,922.285 882.115,902.465 885.773,878.403 889.431,851.179 893.089,822.158 896.747,792.828 900.406,764.628 904.064,738.789 907.722,716.206 911.38,697.366 915.038,682.352 918.696,670.902 922.354,662.521 926.012,656.585 929.67,652.439 933.329,649.453 936.987,647.048 940.645,644.708 944.303,641.986 947.961,638.527 951.619,634.09 955.277,628.581 958.935,622.066 962.594,614.781 966.252,607.109 969.91,599.555 973.568,592.718 977.226,587.261 980.884,583.895 984.542,583.365 988.2,586.452 991.859,593.954 995.517,606.665 999.175,625.336 1002.83,650.599 1006.49,682.879 1010.15,722.285 1013.81,768.501 1017.47,820.711 1021.12,877.566 1024.78,937.23 1028.44,997.493 1032.1,1055.95 1035.76,1110.23 1039.41,1158.18 1043.07,1198.03 1046.73,1228.54 1050.39,1248.93 1054.05,1258.93 1057.7,1258.67 1061.36,1248.61 1065.02,1229.48 1068.68,1202.26 1072.34,1168.15 1076,1128.58 1079.65,1085.12 1083.31,1039.5 1086.97,993.47 1090.63,948.733 1094.29,906.853 1097.94,869.176 1101.6,836.781 1105.26,810.455 1108.92,790.691 1112.58,777.695 1116.23,771.399 1119.89,771.473 1123.55,777.334 1127.21,788.163 1130.87,802.936 1134.53,820.485 1138.18,839.578 1141.84,859.021 1145.5,877.757 1149.16,894.929 1152.82,909.9 1156.47,922.223 1160.13,931.586 1163.79,937.75 1167.45,940.516 1171.11,939.709 1174.76,935.192 1178.42,926.877 1182.08,914.736 1185.74,898.816 1189.4,879.249 1193.06,856.278 1196.71,830.275 1200.37,801.773 1204.03,771.479 1207.69,740.292 1211.35,709.308 1215,679.808 1218.66,653.247 1222.32,631.224 1225.98,615.444 1229.64,607.663 1233.29,609.616 1236.95,622.904 1240.61,648.841 1244.27,688.233 1247.93,741.131 1251.59,806.58 1255.24,882.471 1258.9,965.585 1262.56,1051.87 1266.22,1136.92 1269.88,1216.56 1273.53,1287.4 1277.19,1347.14 1280.85,1394.73 1284.51,1430.24 1288.17,1454.56 1291.82,1469.16 1295.48,1475.68 1299.14,1475.77 1302.8,1470.84 1306.46,1462.04 1310.11,1450.13 1313.77,1435.61 1317.43,1418.66 1321.09,1399.27 1324.75,1377.38 1328.41,1352.89 1332.06,1325.92 1335.72,1296.85 1339.38,1266.45 1343.04,1235.9 1346.7,1206.74 1350.35,1180.65 1354.01,1159.22 1357.67,1143.59 1361.33,1134.18 1364.99,1130.61 1368.64,1131.75 1372.3,1135.93 1375.96,1141.36 1379.62,1146.42 1383.28,1149.94 1386.94,1151.22 1390.59,1150.05 1394.25,1146.51 1397.91,1140.85 1401.57,1133.33 1405.23,1124.21 1408.88,1113.72 1412.54,1102.08 1416.2,1089.54 1419.86,1076.36 1423.52,1062.86 1427.17,1049.34 1430.83,1036.06 1434.49,1023.24 1438.15,1010.98 1441.81,999.32 1445.47,988.216 1449.12,977.572 1452.78,967.258 1456.44,957.133 1460.1,947.066 1463.76,936.951 1467.41,926.716 1471.07,916.336 1474.73,905.836 1478.39,895.298 1482.05,884.861 1485.7,874.73 1489.36,865.17 1493.02,856.507 1496.68,849.127 1500.34,843.458 1504,839.964 1507.65,839.113 1511.31,841.348 1514.97,847.045 1518.63,856.468 1522.29,869.712 1525.94,886.657 1529.6,906.921 1533.26,929.833 1536.92,954.43 1540.58,979.482 1544.23,1003.56 1547.89,1025.12 1551.55,1042.68 1555.21,1055 1558.87,1061.24 1562.53,1061.21 1566.18,1055.39 1569.84,1044.93 1573.5,1031.25 1577.16,1015.66 1580.82,998.852 1584.47,980.717 1588.13,960.638 1591.79,938.013 1595.45,912.748 1599.11,885.312 1602.76,856.342 1606.42,826.088 1610.08,794.095 1613.74,759.279 1617.4,720.267 1621.06,675.785 1624.71,625.085 1628.37,568.5 1632.03,508.067 1635.69,447.805 1639.35,393.141 1643,349.508 1646.66,320.746 1650.32,308.169 1653.98,310.588 1657.64,325.043 1661.29,347.793 1664.95,375.184 1668.61,404.223 1672.27,432.808 1675.93,459.68 1679.58,484.207 1683.24,506.121 1686.9,525.294 1690.56,541.599 1694.22,554.861 1697.88,564.858 1701.53,571.354 1705.19,574.138 1708.85,573.048 1712.51,567.994 1716.17,558.975 1719.82,546.095 1723.48,529.581 1727.14,509.791 1730.8,487.21 1734.46,462.423 1738.11,436.066 1741.77,408.762 1745.43,381.066 1749.09,353.44 1752.75,326.272 1756.41,299.944 1760.06,274.918 1763.72,251.802 1767.38,231.377 1771.04,214.573 1774.7,202.413 1778.35,195.961 1782.01,196.253 1785.67,204.248 1789.33,220.756 1792.99,246.379 1796.64,281.439 1800.3,325.945 1803.96,379.579 1807.62,441.722 1811.28,511.487 1814.94,587.76 1818.59,669.218 1822.25,754.333 1825.91,841.355 1829.57,928.268 1833.23,1012.74 1836.88,1092.1 1840.54,1163.36 1844.2,1223.37 1847.86,1269.09 1851.52,1297.96 1855.17,1308.32 1858.83,1299.71 1862.49,1273.01 1866.15,1230.42 1869.81,1175.11 1873.47,1110.94 1877.12,1041.96 1880.78,972.037 1884.44,904.506 1888.1,842.01 1891.76,786.412 1895.41,738.824 1899.07,699.711 1902.73,669.026 1906.39,646.353 1910.05,631.033 1913.7,622.279 1917.36,619.249 1921.02,621.11 1924.68,627.06 1928.34,636.351 1932,648.286 1935.65,662.216 1939.31,677.523 1942.97,693.617 1946.63,709.92 1950.29,725.873 1953.94,740.936 1957.6,754.614 1961.26,766.473 1964.92,776.176 1968.58,783.504 1972.23,788.364 1975.89,790.783 1979.55,790.882 1983.21,788.828 1986.87,784.793 1990.53,778.915 1994.18,771.279 1997.84,761.914 2001.5,750.814 2005.16,737.959 2008.82,723.344 2012.47,707.008 2016.13,689.055 2019.79,669.68 2023.45,649.182 2027.11,627.983 2030.76,606.637 2034.42,585.834 2038.08,566.392 2041.74,549.249 2045.4,535.45 2049.06,526.129 2052.71,522.495 2056.37,525.799 2060.03,537.29 2063.69,558.123 2067.35,589.223 2071,631.098 2074.66,683.612 2078.32,745.783 2081.98,815.647 2085.64,890.286 2089.29,966.033 2092.95,1038.85 2096.61,1104.82 2100.27,1160.56 2103.93,1203.55 2107.58,1232.27 2111.24,1246.13 2114.9,1245.35 2118.56,1230.78 2122.22,1203.81 2125.88,1166.24 2129.53,1120.24 2133.19,1068.29 2136.85,1013.04 2140.51,957.151 2144.17,903.142 2147.82,853.196 2151.48,809.056 2155.14,771.981 2158.8,742.745 2162.46,721.695 2166.11,708.816 2169.77,703.79 2173.43,706.05 2177.09,714.809 2180.75,729.081 2184.41,747.708 2188.06,769.408 2191.72,792.836 2195.38,816.674 2199.04,839.719 2202.7,860.942 2206.35,879.527 2210.01,894.852 2213.67,906.461 2217.33,914.018 2220.99,917.288 2224.64,916.117 2228.3,910.43 2231.96,900.238 2235.62,885.641 2239.28,866.839 2242.94,844.153 2246.59,818.04 2250.25,789.121 2253.91,758.199 2257.57,726.265 2261.23,694.507 2264.88,664.299 2268.54,637.179 2272.2,614.822 2275.86,598.999 2279.52,591.528 2283.17,594.2 2286.83,608.678 2290.49,636.327 2294.15,677.982 2297.81,733.664 2301.47,802.289 2305.12,881.505 2308.78,967.74 2312.44,1056.54 2316.1,1143.14 2319.76,1223.17 2323.41,1293.22 2327.07,1351.14 2330.73,1396.15 2334.39,1428.55 2338.05,1449.36 2341.7,1459.95 2345.36,1461.7 2349.02,1455.8 2352.68,1443.08 2356.34,1424.07 2360,1399.03 2363.65,1368.12 2367.31,1331.59 2370.97,1290.01 2374.63,1244.46 2378.29,1196.65 2381.94,1148.94 2385.6,1104.21 2389.26,1065.52 2392.92,1035.74 2396.58,1017.07 2400.23,1010.65 2403.89,1016.33 2407.55,1032.61 2411.21,1056.91 2414.87,1086.01 2418.53,1116.61 2422.18,1145.83 2425.84,1171.54 2429.5,1192.38 2433.16,1207.63 2436.82,1217.04 2440.47,1220.67 2444.13,1218.88 2447.79,1212.24 2451.45,1201.57 2455.11,1187.89 2458.76,1172.26 2462.42,1155.71 2466.08,1139.09 2469.74,1123.04 2473.4,1107.92 2477.06,1093.87 2480.71,1080.84 2484.37,1068.66 2488.03,1057.09 2491.69,1045.89 2495.35,1034.82 2499,1023.67 2502.66,1012.3 2506.32,1000.57 2509.98,988.368 2513.64,975.59 2517.29,962.103 2520.95,947.746 2524.61,932.327 2528.27,915.626 2531.93,897.401 2535.58,877.404 2539.24,855.38 2542.9,831.076 2546.56,804.24 2550.22,774.64 2553.88,742.1 2557.53,706.567 2561.19,668.231 2564.85,627.699 2568.51,586.202 2572.17,545.807 "></polyline>
<polyline clip-path="url(#clip352)" style="stroke:#c271d2; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="285.841,1050.47 289.5,1035.17 293.158,1016.41 296.816,994.912 300.474,971.477 304.132,946.912 307.79,921.987 311.448,897.382 315.106,873.655 318.765,851.216 322.423,830.312 326.081,811.03 329.739,793.31 333.397,776.975 337.055,761.76 340.713,747.36 344.371,733.462 348.029,719.781 351.688,706.085 355.346,692.21 359.004,678.066 362.662,663.642 366.32,649.002 369.978,634.28 373.636,619.685 377.294,605.495 380.953,592.063 384.611,579.824 388.269,569.292 391.927,561.066 395.585,555.817 399.243,554.281 402.901,557.236 406.559,565.466 410.218,579.723 413.876,600.662 417.534,628.78 421.192,664.339 424.85,707.303 428.508,757.277 432.166,813.483 435.824,874.748 439.482,939.542 443.141,1006.03 446.799,1072.19 450.457,1135.89 454.115,1195.07 457.773,1247.86 461.431,1292.69 465.089,1328.41 468.747,1354.26 472.406,1369.88 476.064,1375.28 479.722,1370.72 483.38,1356.69 487.038,1333.91 490.696,1303.32 494.354,1266.15 498.012,1223.9 501.671,1178.37 505.329,1131.55 508.987,1085.54 512.645,1042.38 516.303,1003.94 519.961,971.736 523.619,946.89 527.277,930.028 530.935,921.268 534.594,920.22 538.252,926.016 541.91,937.371 545.568,952.688 549.226,970.201 552.884,988.161 556.542,1005.03 560.2,1019.64 563.859,1031.29 567.517,1039.76 571.175,1045.23 574.833,1048.08 578.491,1048.76 582.149,1047.65 585.807,1044.95 589.465,1040.69 593.123,1034.78 596.782,1027.08 600.44,1017.43 604.098,1005.71 607.756,991.859 611.414,975.82 615.072,957.557 618.73,937.037 622.388,914.245 626.047,889.217 629.705,862.088 633.363,833.14 637.021,802.851 640.679,771.916 644.337,741.249 647.995,711.953 651.653,685.27 655.312,662.511 658.97,644.984 662.628,633.914 666.286,630.369 669.944,635.19 673.602,648.927 677.26,671.783 680.918,703.576 684.576,743.733 688.235,791.304 691.893,845.016 695.551,903.348 699.209,964.616 702.867,1027.07 706.525,1088.97 710.183,1148.68 713.841,1204.72 717.5,1255.86 721.158,1301.12 724.816,1339.88 728.474,1371.84 732.132,1397.01 735.79,1415.72 739.448,1428.48 743.106,1435.94 746.765,1438.8 750.423,1437.69 754.081,1433.17 757.739,1425.66 761.397,1415.45 765.055,1402.74 768.713,1387.65 772.371,1370.34 776.029,1351.07 779.688,1330.24 783.346,1308.45 787.004,1286.44 790.662,1265.08 794.32,1245.15 797.978,1227.26 801.636,1211.67 805.294,1198.23 808.953,1186.39 812.611,1175.28 816.269,1163.92 819.927,1151.35 823.585,1136.8 827.243,1119.81 830.901,1100.23 834.559,1078.24 838.218,1054.25 841.876,1028.82 845.534,1002.6 849.192,976.206 852.85,950.172 856.508,924.88 860.166,900.537 863.824,877.158 867.482,854.592 871.141,832.55 874.799,810.658 878.457,788.503 882.115,765.684 885.773,741.857 889.431,716.771 893.089,690.328 896.747,662.635 900.406,634.057 904.064,605.258 907.722,577.19 911.38,551.026 915.038,528.045 918.696,509.471 922.354,496.32 926.012,489.284 929.67,488.676 933.329,494.438 936.987,506.203 940.645,523.39 944.303,545.309 947.961,571.246 951.619,600.534 955.277,632.587 958.935,666.913 962.594,703.106 966.252,740.83 969.91,779.799 973.568,819.755 977.226,860.454 980.884,901.644 984.542,943.044 988.2,984.328 991.859,1025.09 995.517,1064.84 999.175,1102.95 1002.83,1138.67 1006.49,1171.15 1010.15,1199.43 1013.81,1222.56 1017.47,1239.68 1021.12,1250.09 1024.78,1253.43 1028.44,1249.75 1032.1,1239.55 1035.76,1223.79 1039.41,1203.85 1043.07,1181.36 1046.73,1157.99 1050.39,1135.32 1054.05,1114.57 1057.7,1096.53 1061.36,1081.43 1065.02,1068.99 1068.68,1058.46 1072.34,1048.77 1076,1038.65 1079.65,1026.84 1083.31,1012.17 1086.97,993.749 1090.63,970.96 1094.29,943.534 1097.94,911.514 1101.6,875.219 1105.26,835.181 1108.92,792.094 1112.58,746.753 1116.23,700.015 1119.89,652.761 1123.55,605.862 1127.21,560.153 1130.87,516.395 1134.53,475.24 1138.18,437.202 1141.84,402.634 1145.5,371.719 1149.16,344.49 1152.82,320.854 1156.47,300.63 1160.13,283.594 1163.79,269.514 1167.45,258.19 1171.11,249.491 1174.76,243.392 1178.42,240.006 1182.08,239.6 1185.74,242.601 1189.4,249.568 1193.06,261.164 1196.71,278.093 1200.37,301.035 1204.03,330.578 1207.69,367.151 1211.35,410.964 1215,461.964 1218.66,519.807 1222.32,583.828 1225.98,653.02 1229.64,726.015 1233.29,801.061 1236.95,876.008 1240.61,948.319 1244.27,1015.14 1247.93,1073.45 1251.59,1120.31 1255.24,1153.16 1258.9,1170.19 1262.56,1170.66 1266.22,1155.02 1269.88,1124.95 1273.53,1083.15 1277.19,1033.05 1280.85,978.354 1284.51,922.691 1288.17,869.276 1291.82,820.708 1295.48,778.889 1299.14,745.038 1302.8,719.774 1306.46,703.217 1310.11,695.1 1313.77,694.854 1317.43,701.667 1321.09,714.516 1324.75,732.186 1328.41,753.282 1332.06,776.265 1335.72,799.512 1339.38,821.433 1343.04,840.621 1346.7,856.034 1350.35,867.142 1354.01,874.017 1357.67,877.293 1361.33,878.021 1364.99,877.424 1368.64,876.626 1372.3,876.444 1375.96,877.276 1379.62,879.116 1383.28,881.658 1386.94,884.429 1390.59,886.91 1394.25,888.619 1397.91,889.146 1401.57,888.161 1405.23,885.41 1408.88,880.711 1412.54,873.956 1416.2,865.122 1419.86,854.281 1423.52,841.601 1427.17,827.338 1430.83,811.815 1434.49,795.398 1438.15,778.46 1441.81,761.361 1445.47,744.429 1449.12,727.948 1452.78,712.157 1456.44,697.259 1460.1,683.424 1463.76,670.801 1467.41,659.525 1471.07,649.725 1474.73,641.526 1478.39,635.051 1482.05,630.418 1485.7,627.732 1489.36,627.076 1493.02,628.495 1496.68,631.978 1500.34,637.442 1504,644.711 1507.65,653.501 1511.31,663.416 1514.97,673.947 1518.63,684.494 1522.29,694.397 1525.94,702.996 1529.6,709.688 1533.26,714.013 1536.92,715.712 1540.58,714.785 1544.23,711.5 1547.89,706.34 1551.55,699.904 1555.21,692.734 1558.87,685.141 1562.53,677.062 1566.18,668.023 1569.84,657.252 1573.5,643.891 1577.16,627.228 1580.82,606.814 1584.47,582.429 1588.13,553.975 1591.79,521.424 1595.45,484.93 1599.11,445.071 1602.76,403.118 1606.42,361.21 1610.08,322.407 1613.74,290.636 1617.4,270.588 1621.06,267.536 1624.71,286.991 1628.37,334.057 1632.03,412.377 1635.69,522.755 1639.35,661.937 1643,822.299 1646.66,992.859 1650.32,1161.3 1653.98,1316.17 1657.64,1448.49 1661.29,1552.6 1664.95,1626.19 1668.61,1669.87 1672.27,1686.38 1675.93,1679.73 1679.58,1654.5 1683.24,1615.17 1686.9,1565.79 1690.56,1509.74 1694.22,1449.61 1697.88,1387.3 1701.53,1324.1 1705.19,1260.76 1708.85,1197.7 1712.51,1135.1 1716.17,1072.96 1719.82,1011.31 1723.48,950.222 1727.14,889.946 1730.8,831.037 1734.46,774.451 1738.11,721.632 1741.77,674.54 1745.43,635.593 1749.09,607.486 1752.75,592.904 1756.41,594.154 1760.06,612.793 1763.72,649.321 1767.38,703.025 1771.04,771.982 1774.7,853.224 1778.35,943.007 1782.01,1037.13 1785.67,1131.29 1789.33,1221.34 1792.99,1303.69 1796.64,1375.56 1800.3,1435.18 1803.96,1481.92 1807.62,1516.2 1811.28,1539.23 1814.94,1552.66 1818.59,1558.18 1822.25,1557.24 1825.91,1550.9 1829.57,1539.73 1833.23,1524.02 1836.88,1504 1840.54,1480.11 1844.2,1453.27 1847.86,1424.94 1851.52,1396.92 1855.17,1370.95 1858.83,1348.2 1862.49,1328.92 1866.15,1312.37 1869.81,1297.04 1873.47,1281.09 1877.12,1262.82 1880.78,1240.91 1884.44,1214.64 1888.1,1183.83 1891.76,1148.78 1895.41,1110.11 1899.07,1068.62 1902.73,1025.18 1906.39,980.665 1910.05,935.815 1913.7,891.266 1917.36,847.5 1921.02,804.862 1924.68,763.569 1928.34,723.735 1932,685.399 1935.65,648.549 1939.31,613.147 1942.97,579.146 1946.63,546.502 1950.29,515.185 1953.94,485.178 1957.6,456.48 1961.26,429.103 1964.92,403.08 1968.58,378.467 1972.23,355.354 1975.89,333.885 1979.55,314.263 1983.21,296.759 1986.87,281.708 1990.53,269.499 1994.18,260.547 1997.84,255.277 2001.5,254.088 2005.16,257.339 2008.82,265.324 2012.47,278.265 2016.13,296.303 2019.79,319.496 2023.45,347.824 2027.11,381.189 2030.76,419.421 2034.42,462.283 2038.08,509.464 2041.74,560.582 2045.4,615.165 2049.06,672.633 2052.71,732.264 2056.37,793.162 2060.03,854.207 2063.69,914.032 2067.35,971.015 2071,1023.32 2074.66,1069.01 2078.32,1106.25 2081.98,1133.52 2085.64,1149.92 2089.29,1155.4 2092.95,1150.87 2096.61,1138.17 2100.27,1119.78 2103.93,1098.53 2107.58,1077.05 2111.24,1057.44 2114.9,1040.91 2118.56,1027.74 2122.22,1017.27 2125.88,1008.15 2129.53,998.61 2133.19,986.807 2136.85,971.085 2140.51,950.206 2144.17,923.458 2147.82,890.67 2151.48,852.147 2155.14,808.553 2158.8,760.794 2162.46,709.899 2166.11,656.94 2169.77,602.978 2173.43,549.03 2177.09,496.055 2180.75,444.941 2184.41,396.492 2188.06,351.404 2191.72,310.237 2195.38,273.389 2199.04,241.08 2202.7,213.354 2206.35,190.099 2210.01,171.085 2213.67,156.014 2217.33,144.573 2220.99,136.492 2224.64,131.599 2228.3,129.867 2231.96,131.437 2235.62,136.627 2239.28,145.912 2242.94,159.879 2246.59,179.17 2250.25,204.41 2253.91,236.137 2257.57,274.73 2261.23,320.365 2264.88,372.965 2268.54,432.179 2272.2,497.359 2275.86,567.537 2279.52,641.4 2283.17,717.254 2286.83,792.997 2290.49,866.113 2294.15,933.725 2297.81,992.745 2301.47,1040.14 2305.12,1073.31 2308.78,1090.5 2312.44,1091.17 2316.1,1076.19 2319.76,1047.78 2323.41,1009.26 2327.07,964.574 2330.73,917.793 2334.39,872.653 2338.05,832.238 2341.7,798.818 2345.36,773.808 2349.02,757.827 2352.68,750.778 2356.34,751.944 2360,760.061 2363.65,773.386 2367.31,789.783 2370.97,806.839 2374.63,822.039 2378.29,833.013 2381.94,837.812 2385.6,835.199 2389.26,824.867 2392.92,807.537 2396.58,784.9 2400.23,759.401 2403.89,733.875 2407.55,711.126 2411.21,693.503 2414.87,682.586 2418.53,679.044 2422.18,682.68 2425.84,692.621 2429.5,707.559 2433.16,725.98 2436.82,746.324 2440.47,767.093 2444.13,786.933 2447.79,804.703 2451.45,819.535 2455.11,830.873 2458.76,838.477 2462.42,842.388 2466.08,842.861 2469.74,840.278 2473.4,835.073 2477.06,827.662 2480.71,818.402 2484.37,807.573 2488.03,795.364 2491.69,781.887 2495.35,767.186 2499,751.254 2502.66,734.047 2506.32,715.509 2509.98,695.576 2513.64,674.202 2517.29,651.364 2520.95,627.079 2524.61,601.418 2528.27,574.528 2531.93,546.66 2535.58,518.209 2539.24,489.766 2542.9,462.174 2546.56,436.592 2550.22,414.558 2553.88,398.033 2557.53,389.407 2561.19,391.45 2564.85,407.157 2568.51,439.455 2572.17,490.742 "></polyline>
<polyline clip-path="url(#clip352)" style="stroke:#ac8d18; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="285.841,928.065 289.5,913.656 293.158,898.401 296.816,882.139 300.474,864.752 304.132,846.167 307.79,826.371 311.448,805.426 315.106,783.49 318.765,760.843 322.423,737.886 326.081,715.143 329.739,693.243 333.397,672.883 337.055,654.795 340.713,639.701 344.371,628.269 348.029,621.087 351.688,618.632 355.346,621.253 359.004,629.166 362.662,642.454 366.32,661.07 369.978,684.854 373.636,713.545 377.294,746.798 380.953,784.195 384.611,825.256 388.269,869.441 391.927,916.147 395.585,964.703 399.243,1014.36 402.901,1064.3 406.559,1113.59 410.218,1161.26 413.876,1206.27 417.534,1247.57 421.192,1284.12 424.85,1315 428.508,1339.38 432.166,1356.64 435.824,1366.32 439.482,1368.21 443.141,1362.34 446.799,1349.07 450.457,1329.05 454.115,1303.35 457.773,1273.4 461.431,1240.97 465.089,1208 468.747,1176.45 472.406,1148.07 476.064,1124.17 479.722,1105.49 483.38,1092.09 487.038,1083.38 490.696,1078.22 494.354,1075.03 498.012,1072.08 501.671,1067.65 505.329,1060.24 508.987,1048.75 512.645,1032.56 516.303,1011.52 519.961,985.96 523.619,956.569 527.277,924.323 530.935,890.36 534.594,855.878 538.252,822.027 541.91,789.819 545.568,760.05 549.226,733.241 552.884,709.618 556.542,689.124 560.2,671.47 563.859,656.212 567.517,642.844 571.175,630.868 574.833,619.857 578.491,609.476 582.149,599.486 585.807,589.728 589.465,580.114 593.123,570.611 596.782,561.256 600.44,552.16 604.098,543.537 607.756,535.716 611.414,529.146 615.072,524.401 618.73,522.162 622.388,523.207 626.047,528.376 629.705,538.541 633.363,554.55 637.021,577.163 640.679,606.969 644.337,644.307 647.995,689.186 651.653,741.227 655.312,799.632 658.97,863.189 662.628,930.308 666.286,999.095 669.944,1067.45 673.602,1133.19 677.26,1194.19 680.918,1248.53 684.576,1294.62 688.235,1331.25 691.893,1357.7 695.551,1373.65 699.209,1379.13 702.867,1374.51 706.525,1360.36 710.183,1337.46 713.841,1306.77 717.5,1269.47 721.158,1226.93 724.816,1180.72 728.474,1132.57 732.132,1084.27 735.79,1037.59 739.448,994.141 743.106,955.327 746.765,922.253 750.423,895.699 754.081,876.106 757.739,863.587 761.397,857.944 765.055,858.686 768.713,865.061 772.371,876.082 776.029,890.587 779.688,907.304 783.346,924.953 787.004,942.352 790.662,958.52 794.32,972.753 797.978,984.643 801.636,994.044 805.294,1000.99 808.953,1005.6 812.611,1007.96 816.269,1008.13 819.927,1006.05 823.585,1001.65 827.243,994.806 830.901,985.409 834.559,973.382 838.218,958.672 841.876,941.26 845.534,921.168 849.192,898.475 852.85,873.345 856.508,846.061 860.166,817.055 863.824,786.933 867.482,756.483 871.141,726.672 874.799,698.631 878.457,673.628 882.115,653.033 885.773,638.273 889.431,630.774 893.089,631.886 896.747,642.791 900.406,664.375 904.064,697.094 907.722,740.838 911.38,794.813 915.038,857.504 918.696,926.718 922.354,999.742 926.012,1073.58 929.67,1145.24 933.329,1211.99 936.987,1271.65 940.645,1322.68 944.303,1364.26 947.961,1396.29 951.619,1419.22 955.277,1433.95 958.935,1441.62 962.594,1443.49 966.252,1440.75 969.91,1434.49 973.568,1425.57 977.226,1414.67 980.884,1402.21 984.542,1388.47 988.2,1373.56 991.859,1357.5 995.517,1340.29 999.175,1321.97 1002.83,1302.69 1006.49,1282.72 1010.15,1262.5 1013.81,1242.63 1017.47,1223.74 1021.12,1206.43 1024.78,1191.13 1028.44,1177.99 1032.1,1166.84 1035.76,1157.19 1039.41,1148.37 1043.07,1139.62 1046.73,1130.28 1050.39,1119.87 1054.05,1108.17 1057.7,1095.18 1061.36,1081.07 1065.02,1066.1 1068.68,1050.53 1072.34,1034.59 1076,1018.42 1079.65,1002.05 1083.31,985.49 1086.97,968.683 1090.63,951.566 1094.29,934.067 1097.94,916.109 1101.6,897.602 1105.26,878.433 1108.92,858.478 1112.58,837.619 1116.23,815.785 1119.89,793.01 1123.55,769.503 1127.21,745.718 1130.87,722.409 1134.53,700.657 1138.18,681.838 1141.84,667.532 1145.5,659.368 1149.16,658.835 1152.82,667.084 1156.47,684.778 1160.13,712.008 1163.79,748.299 1167.45,792.692 1171.11,843.863 1174.76,900.258 1178.42,960.212 1182.08,1022.04 1185.74,1084.07 1189.4,1144.75 1193.06,1202.62 1196.71,1256.38 1200.37,1304.96 1204.03,1347.56 1207.69,1383.72 1211.35,1413.27 1215,1436.36 1218.66,1453.33 1222.32,1464.64 1225.98,1470.76 1229.64,1472.07 1233.29,1468.84 1236.95,1461.29 1240.61,1449.64 1244.27,1434.31 1247.93,1415.99 1251.59,1395.68 1255.24,1374.58 1258.9,1353.85 1262.56,1334.29 1266.22,1316.11 1269.88,1298.8 1273.53,1281.32 1277.19,1262.36 1280.85,1240.64 1284.51,1215.21 1288.17,1185.54 1291.82,1151.54 1295.48,1113.52 1299.14,1072.07 1302.8,1027.93 1306.46,981.931 1310.11,934.902 1313.77,887.631 1317.43,840.832 1321.09,795.137 1324.75,751.083 1328.41,709.107 1332.06,669.53 1335.72,632.541 1339.38,598.185 1343.04,566.355 1346.7,536.815 1350.35,509.244 1354.01,483.308 1357.67,458.741 1361.33,435.42 1364.99,413.41 1368.64,392.962 1372.3,374.468 1375.96,358.37 1379.62,345.075 1383.28,334.872 1386.94,327.893 1390.59,324.117 1394.25,323.39 1397.91,325.477 1401.57,330.096 1405.23,336.958 1408.88,345.788 1412.54,356.337 1416.2,368.381 1419.86,381.72 1423.52,396.161 1427.17,411.519 1430.83,427.603 1434.49,444.222 1438.15,461.189 1441.81,478.326 1445.47,495.477 1449.12,512.514 1452.78,529.341 1456.44,545.897 1460.1,562.15 1463.76,578.095 1467.41,593.741 1471.07,609.104 1474.73,624.193 1478.39,638.999 1482.05,653.485 1485.7,667.574 1489.36,681.146 1493.02,694.026 1496.68,705.99 1500.34,716.765 1504,726.041 1507.65,733.478 1511.31,738.726 1514.97,741.437 1518.63,741.28 1522.29,737.947 1525.94,731.156 1529.6,720.642 1533.26,706.149 1536.92,687.423 1540.58,664.219 1544.23,636.328 1547.89,603.617 1551.55,566.101 1555.21,523.998 1558.87,477.779 1562.53,428.18 1566.18,376.189 1569.84,323.033 1573.5,270.21 1577.16,219.574 1580.82,173.478 1584.47,134.884 1588.13,107.375 1591.79,94.9858 1595.45,101.851 1599.11,131.712 1602.76,187.358 1606.42,270.113 1610.08,379.496 1613.74,513.092 1617.4,666.593 1621.06,833.891 1624.71,1007.15 1628.37,1176.98 1632.03,1332.89 1635.69,1464.39 1639.35,1562.61 1643,1621.76 1646.66,1639.93 1650.32,1618.7 1653.98,1562.26 1657.64,1476.65 1661.29,1369.18 1664.95,1248.03 1668.61,1121.57 1672.27,997.575 1675.93,882.413 1679.58,780.562 1683.24,694.434 1686.9,624.558 1690.56,569.991 1694.22,528.839 1697.88,498.767 1701.53,477.423 1705.19,462.75 1708.85,453.183 1712.51,447.755 1716.17,446.127 1719.82,448.581 1723.48,455.97 1727.14,469.613 1730.8,491.152 1734.46,522.325 1738.11,564.666 1741.77,619.139 1745.43,685.765 1749.09,763.305 1752.75,849.12 1756.41,939.271 1760.06,1028.9 1763.72,1112.79 1767.38,1186.06 1771.04,1244.66 1774.7,1285.74 1778.35,1307.72 1782.01,1310.19 1785.67,1293.76 1789.33,1260.03 1792.99,1211.51 1796.64,1151.65 1800.3,1084.74 1803.96,1015.6 1807.62,949.141 1811.28,889.909 1814.94,841.667 1818.59,807.143 1822.25,787.928 1825.91,784.495 1829.57,796.254 1833.23,821.639 1836.88,858.219 1840.54,902.879 1844.2,952.12 1847.86,1002.46 1851.52,1050.89 1855.17,1095.13 1858.83,1133.8 1862.49,1166.2 1866.15,1192.1 1869.81,1211.46 1873.47,1224.34 1877.12,1230.91 1880.78,1231.58 1884.44,1227 1888.1,1218.06 1891.76,1205.82 1895.41,1191.35 1899.07,1175.61 1902.73,1159.35 1906.39,1143.05 1910.05,1126.95 1913.7,1111.08 1917.36,1095.26 1921.02,1079.22 1924.68,1062.64 1928.34,1045.18 1932,1026.58 1935.65,1006.65 1939.31,985.363 1942.97,962.833 1946.63,939.395 1950.29,915.594 1953.94,892.202 1957.6,870.2 1961.26,850.743 1964.92,835.095 1968.58,824.537 1972.23,820.255 1975.89,823.218 1979.55,834.064 1983.21,853.005 1986.87,879.774 1990.53,913.617 1994.18,953.333 1997.84,997.371 2001.5,1043.95 2005.16,1091.18 2008.82,1137.28 2012.47,1180.62 2016.13,1219.9 2019.79,1254.21 2023.45,1283.04 2027.11,1306.29 2030.76,1324.15 2034.42,1337.08 2038.08,1345.64 2041.74,1350.41 2045.4,1351.93 2049.06,1350.57 2052.71,1346.61 2056.37,1340.16 2060.03,1331.29 2063.69,1320.05 2067.35,1306.6 2071,1291.26 2074.66,1274.6 2078.32,1257.35 2081.98,1240.31 2085.64,1224.14 2089.29,1209.17 2092.95,1195.32 2096.61,1182.11 2100.27,1168.8 2103.93,1154.71 2107.58,1139.36 2111.24,1122.58 2114.9,1104.56 2118.56,1085.65 2122.22,1066.29 2125.88,1046.85 2129.53,1027.59 2133.19,1008.61 2136.85,989.911 2140.51,971.458 2144.17,953.197 2147.82,935.077 2151.48,917.042 2155.14,899.007 2158.8,880.839 2162.46,862.366 2166.11,843.405 2169.77,823.812 2173.43,803.562 2177.09,782.823 2180.75,762.043 2184.41,742.004 2188.06,723.842 2191.72,709.005 2195.38,699.133 2199.04,695.882 2202.7,700.698 2206.35,714.613 2210.01,738.081 2213.67,770.92 2217.33,812.342 2220.99,861.061 2224.64,915.439 2228.3,973.644 2231.96,1033.77 2235.62,1093.95 2239.28,1152.43 2242.94,1207.64 2246.59,1258.25 2250.25,1303.25 2253.91,1341.98 2257.57,1374.19 2261.23,1399.94 2264.88,1419.61 2268.54,1433.76 2272.2,1442.99 2275.86,1447.84 2279.52,1448.73 2283.17,1445.91 2286.83,1439.51 2290.49,1429.66 2294.15,1416.61 2297.81,1400.84 2301.47,1383.09 2305.12,1364.3 2308.78,1345.28 2312.44,1326.55 2316.1,1308.04 2319.76,1289.15 2323.41,1268.87 2327.07,1246.11 2330.73,1220.01 2334.39,1190.06 2338.05,1156.25 2341.7,1118.96 2345.36,1078.88 2349.02,1036.89 2352.68,993.953 2356.34,951.012 2360,908.93 2363.65,868.421 2367.31,830.002 2370.97,793.951 2374.63,760.286 2378.29,728.766 2381.94,698.929 2385.6,670.159 2389.26,641.779 2392.92,613.158 2396.58,583.816 2400.23,553.541 2403.89,522.487 2407.55,491.247 2411.21,460.848 2414.87,432.634 2418.53,408.035 2422.18,388.278 2425.84,374.127 2429.5,365.754 2433.16,362.753 2436.82,364.285 2440.47,369.286 2444.13,376.657 2447.79,385.412 2451.45,394.747 2455.11,404.058 2458.76,412.907 2462.42,420.98 2466.08,428.039 2469.74,433.89 2473.4,438.367 2477.06,441.326 2480.71,442.65 2484.37,442.263 2488.03,440.144 2491.69,436.332 2495.35,430.945 2499,424.186 2502.66,416.351 2506.32,407.847 2509.98,399.197 2513.64,391.051 2517.29,384.201 2520.95,379.575 2524.61,378.238 2528.27,381.365 2531.93,390.209 2535.58,406.044 2539.24,430.085 2542.9,463.394 2546.56,506.763 2550.22,560.583 2553.88,624.703 2557.53,698.283 2561.19,779.653 2564.85,866.208 2568.51,954.385 2572.17,1039.76 "></polyline>
<polyline clip-path="url(#clip352)" style="stroke:#00a9ad; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="285.841,732.812 289.5,718.184 293.158,705.552 296.816,695.463 300.474,688.478 304.132,685.159 307.79,686.055 311.448,691.676 315.106,702.467 318.765,718.772 322.423,740.796 326.081,768.563 329.739,801.89 333.397,840.355 337.055,883.302 340.713,929.846 344.371,978.915 348.029,1029.3 351.688,1079.71 355.346,1128.85 359.004,1175.51 362.662,1218.61 366.32,1257.25 369.978,1290.77 373.636,1318.74 377.294,1340.96 380.953,1357.41 384.611,1368.21 388.269,1373.55 391.927,1373.68 395.585,1368.83 399.243,1359.21 402.901,1345.06 406.559,1326.65 410.218,1304.39 413.876,1278.84 417.534,1250.8 421.192,1221.33 424.85,1191.7 428.508,1163.32 432.166,1137.58 435.824,1115.7 439.482,1098.54 443.141,1086.46 446.799,1079.26 450.457,1076.18 454.115,1075.99 457.773,1077.23 461.431,1078.41 465.089,1078.21 468.747,1075.72 472.406,1070.47 476.064,1062.47 479.722,1052.07 483.38,1039.86 487.038,1026.51 490.696,1012.59 494.354,998.5 498.012,984.428 501.671,970.346 505.329,956.072 508.987,941.328 512.645,925.812 516.303,909.237 519.961,891.348 523.619,871.93 527.277,850.804 530.935,827.843 534.594,803 538.252,776.364 541.91,748.215 545.568,719.082 549.226,689.762 552.884,661.31 556.542,634.968 560.2,612.062 563.859,593.874 567.517,581.515 571.175,575.829 574.833,577.329 578.491,586.187 582.149,602.252 585.807,625.106 589.465,654.144 593.123,688.642 596.782,727.838 600.44,770.973 604.098,817.33 607.756,866.234 611.414,917.052 615.072,969.165 618.73,1021.94 622.388,1074.73 626.047,1126.79 629.705,1177.35 633.363,1225.53 637.021,1270.41 640.679,1311.08 644.337,1346.61 647.995,1376.19 651.653,1399.12 655.312,1414.9 658.97,1423.19 662.628,1423.85 666.286,1416.97 669.944,1402.88 673.602,1382.23 677.26,1355.97 680.918,1325.43 684.576,1292.25 688.235,1258.26 691.893,1225.35 695.551,1195.18 699.209,1169.07 702.867,1147.78 706.525,1131.45 710.183,1119.63 713.841,1111.32 717.5,1105.18 721.158,1099.65 724.816,1093.18 728.474,1084.37 732.132,1072.13 735.79,1055.73 739.448,1034.81 743.106,1009.41 746.765,979.868 750.423,946.767 754.081,910.867 757.739,873.032 761.397,834.163 765.055,795.155 768.713,756.848 772.371,719.989 776.029,685.199 779.688,652.941 783.346,623.503 787.004,596.993 790.662,573.355 794.32,552.397 797.978,533.845 801.636,517.381 805.294,502.694 808.953,489.502 812.611,477.573 816.269,466.728 819.927,456.847 823.585,447.881 827.243,439.865 830.901,432.934 834.559,427.342 838.218,423.468 841.876,421.816 845.534,423.003 849.192,427.736 852.85,436.778 856.508,450.904 860.166,470.843 863.824,497.215 867.482,530.472 871.141,570.83 874.799,618.227 878.457,672.278 882.115,732.253 885.773,797.066 889.431,865.273 893.089,935.093 896.747,1004.44 900.406,1071 904.064,1132.34 907.722,1186.04 911.38,1229.9 915.038,1262.11 918.696,1281.39 922.354,1287.14 926.012,1279.44 929.67,1259.05 933.329,1227.39 936.987,1186.4 940.645,1138.4 944.303,1085.95 947.961,1031.66 951.619,977.988 955.277,927.085 958.935,880.705 962.594,840.145 966.252,806.251 969.91,779.453 973.568,759.836 977.226,747.209 980.884,741.163 984.542,741.129 988.2,746.407 991.859,756.188 995.517,769.576 999.175,785.598 1002.83,803.236 1006.49,821.471 1010.15,839.342 1013.81,856.012 1017.47,870.839 1021.12,883.415 1024.78,893.571 1028.44,901.338 1032.1,906.872 1035.76,910.364 1039.41,911.968 1043.07,911.751 1046.73,909.689 1050.39,905.688 1054.05,899.62 1057.7,891.363 1061.36,880.83 1065.02,867.988 1068.68,852.871 1072.34,835.585 1076,816.315 1079.65,795.332 1083.31,772.993 1086.97,749.753 1090.63,726.167 1094.29,702.892 1097.94,680.679 1101.6,660.367 1105.26,642.862 1108.92,629.125 1112.58,620.156 1116.23,616.967 1119.89,620.557 1123.55,631.861 1127.21,651.675 1130.87,680.549 1134.53,718.651 1138.18,765.627 1141.84,820.482 1145.5,881.53 1149.16,946.45 1152.82,1012.45 1156.47,1076.56 1160.13,1135.88 1163.79,1187.92 1167.45,1230.8 1171.11,1263.24 1174.76,1284.62 1178.42,1294.8 1182.08,1294.01 1185.74,1282.75 1189.4,1261.75 1193.06,1231.94 1196.71,1194.55 1200.37,1151.13 1204.03,1103.59 1207.69,1054.15 1211.35,1005.27 1215,959.458 1218.66,919.111 1222.32,886.331 1225.98,862.766 1229.64,849.494 1233.29,846.927 1236.95,854.767 1240.61,872.002 1244.27,896.969 1247.93,927.518 1251.59,961.254 1255.24,995.827 1258.9,1029.2 1262.56,1059.79 1266.22,1086.49 1269.88,1108.58 1273.53,1125.63 1277.19,1137.39 1280.85,1143.82 1284.51,1145.09 1288.17,1141.59 1291.82,1133.87 1295.48,1122.58 1299.14,1108.3 1302.8,1091.54 1306.46,1072.6 1310.11,1051.57 1313.77,1028.38 1317.43,1002.86 1321.09,974.79 1324.75,944.063 1328.41,910.768 1332.06,875.319 1335.72,838.54 1339.38,801.715 1343.04,766.568 1346.7,735.177 1350.35,709.81 1354.01,692.703 1357.67,685.817 1361.33,690.591 1364.99,707.746 1368.64,737.155 1372.3,777.829 1375.96,827.991 1379.62,885.253 1383.28,946.857 1386.94,1009.92 1390.59,1071.69 1394.25,1129.68 1397.91,1181.86 1401.57,1226.68 1405.23,1263.14 1408.88,1290.78 1412.54,1309.62 1416.2,1320.11 1419.86,1323.07 1423.52,1319.53 1427.17,1310.65 1430.83,1297.63 1434.49,1281.62 1438.15,1263.65 1441.81,1244.58 1445.47,1225.13 1449.12,1205.84 1452.78,1187.08 1456.44,1169.11 1460.1,1152.05 1463.76,1135.94 1467.41,1120.74 1471.07,1106.37 1474.73,1092.67 1478.39,1079.5 1482.05,1066.64 1485.7,1053.9 1489.36,1041.06 1493.02,1027.92 1496.68,1014.26 1500.34,999.879 1504,984.6 1507.65,968.244 1511.31,950.645 1514.97,931.645 1518.63,911.092 1522.29,888.836 1525.94,864.73 1529.6,838.642 1533.26,810.457 1536.92,780.109 1540.58,747.605 1544.23,713.08 1547.89,676.869 1551.55,639.613 1555.21,602.399 1558.87,566.92 1562.53,535.633 1566.18,511.834 1569.84,499.593 1573.5,503.437 1577.16,527.754 1580.82,575.968 1584.47,649.614 1588.13,747.585 1591.79,865.77 1595.45,997.268 1599.11,1133.22 1602.76,1264.14 1606.42,1381.41 1610.08,1478.59 1613.74,1551.95 1617.4,1600.17 1621.06,1623.37 1624.71,1622.27 1628.37,1598.03 1632.03,1553.17 1635.69,1492.85 1639.35,1425.44 1643,1361.2 1646.66,1309.38 1650.32,1275.22 1653.98,1258.49 1657.64,1254.31 1661.29,1255.3 1664.95,1254.07 1668.61,1244.99 1672.27,1225 1675.93,1193.56 1679.58,1152.17 1683.24,1103.68 1686.9,1051.61 1690.56,999.576 1694.22,950.866 1697.88,908.184 1701.53,873.556 1705.19,848.348 1708.85,833.356 1712.51,828.904 1716.17,834.926 1719.82,851 1723.48,876.339 1727.14,909.745 1730.8,949.543 1734.46,993.535 1738.11,1039.02 1741.77,1082.9 1745.43,1121.92 1749.09,1153.02 1752.75,1173.76 1756.41,1182.76 1760.06,1179.98 1763.72,1166.88 1767.38,1146.2 1771.04,1121.61 1774.7,1096.94 1778.35,1075.49 1782.01,1059.31 1785.67,1048.85 1789.33,1042.92 1792.99,1038.96 1796.64,1033.65 1800.3,1023.64 1803.96,1006.14 1807.62,979.431 1811.28,943.043 1814.94,897.677 1818.59,844.999 1822.25,787.338 1825.91,727.397 1829.57,667.999 1833.23,611.881 1836.88,561.504 1840.54,518.883 1844.2,485.43 1847.86,461.84 1851.52,448.079 1855.17,443.459 1858.83,446.808 1862.49,456.648 1866.15,471.356 1869.81,489.265 1873.47,508.748 1877.12,528.288 1880.78,546.565 1884.44,562.544 1888.1,575.537 1891.76,585.22 1895.41,591.603 1899.07,594.964 1902.73,595.76 1906.39,594.547 1910.05,591.913 1913.7,588.437 1917.36,584.667 1921.02,581.126 1924.68,578.325 1928.34,576.775 1932,577.009 1935.65,579.589 1939.31,585.105 1942.97,594.162 1946.63,607.348 1950.29,625.184 1953.94,648.064 1957.6,676.171 1961.26,709.402 1964.92,747.293 1968.58,788.976 1972.23,833.17 1975.89,878.228 1979.55,922.238 1983.21,963.157 1986.87,998.987 1990.53,1027.94 1994.18,1048.57 1997.84,1059.9 2001.5,1061.47 2005.16,1053.36 2008.82,1036.18 2012.47,1010.99 2016.13,979.262 2019.79,942.775 2023.45,903.468 2027.11,863.328 2030.76,824.255 2034.42,787.959 2038.08,755.883 2041.74,729.16 2045.4,708.599 2049.06,694.688 2052.71,687.601 2056.37,687.203 2060.03,693.05 2063.69,704.397 2067.35,720.218 2071,739.269 2074.66,760.187 2078.32,781.628 2081.98,802.411 2085.64,821.62 2089.29,838.632 2092.95,853.066 2096.61,864.686 2100.27,873.304 2103.93,878.727 2107.58,880.759 2111.24,879.226 2114.9,874.018 2118.56,865.12 2122.22,852.619 2125.88,836.719 2129.53,817.732 2133.19,796.083 2136.85,772.317 2140.51,747.094 2144.17,721.194 2147.82,695.506 2151.48,671.001 2155.14,648.711 2158.8,629.686 2162.46,614.975 2166.11,605.602 2169.77,602.549 2173.43,606.74 2177.09,619.002 2180.75,639.999 2184.41,670.123 2188.06,709.363 2191.72,757.159 2195.38,812.283 2199.04,872.808 2202.7,936.185 2206.35,999.447 2210.01,1059.51 2213.67,1113.47 2217.33,1158.94 2220.99,1194.12 2224.64,1217.93 2228.3,1229.88 2231.96,1230.03 2235.62,1218.84 2239.28,1197.1 2242.94,1165.99 2246.59,1127 2250.25,1081.98 2253.91,1033.13 2257.57,982.895 2261.23,933.818 2264.88,888.411 2268.54,848.974 2272.2,817.449 2275.86,795.318 2279.52,783.522 2283.17,782.404 2286.83,791.673 2290.49,810.389 2294.15,837.011 2297.81,869.508 2301.47,905.571 2305.12,942.869 2308.78,979.294 2312.44,1013.12 2316.1,1043.04 2319.76,1068.12 2323.41,1087.75 2327.07,1101.56 2330.73,1109.45 2334.39,1111.54 2338.05,1108.15 2341.7,1099.69 2345.36,1086.58 2349.02,1069.15 2352.68,1047.6 2356.34,1022.01 2360,992.411 2363.65,958.891 2367.31,921.714 2370.97,881.459 2374.63,839.114 2378.29,796.134 2381.94,754.431 2385.6,716.309 2389.26,684.337 2392.92,661.182 2396.58,649.403 2400.23,651.215 2403.89,668.218 2407.55,701.122 2411.21,749.487 2414.87,811.554 2418.53,884.256 2422.18,963.446 2425.84,1044.34 2429.5,1122.07 2433.16,1192.27 2436.82,1251.49 2440.47,1297.4 2444.13,1328.9 2447.79,1345.96 2451.45,1349.43 2455.11,1340.8 2458.76,1321.93 2462.42,1294.84 2466.08,1261.58 2469.74,1224.06 2473.4,1183.99 2477.06,1142.91 2480.71,1102.09 2484.37,1062.67 2488.03,1025.6 2491.69,991.73 2495.35,961.839 2499,936.635 2502.66,916.776 2506.32,902.857 2509.98,895.389 2513.64,894.754 2517.29,901.16 2520.95,914.581 2524.61,934.71 2528.27,960.918 2531.93,992.238 2535.58,1027.38 2539.24,1064.79 2542.9,1102.71 2546.56,1139.27 2550.22,1172.64 2553.88,1201.06 2557.53,1223.03 2561.19,1237.35 2564.85,1243.31 2568.51,1240.88 2572.17,1230.92 "></polyline>
</svg>
</div>
</div>
<p>最初の３成分を取り出して，３次元空間にプロットしてみる：<sup>1</sup></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Particles/Files/lorenz96_animation.gif" class="img-fluid figure-img"></p>
<figcaption>Lorenz 96 Model</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled" title="ODE ソルバーの選択">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
ODE ソルバーの選択
</div>
</div>
<div class="callout-body-container callout-body">
<p><code>CoupledODEs</code> のデフォルトのソルバーは</p>
<blockquote class="blockquote">
<p><a href="https://docs.sciml.ai/DiffEqDocs/latest/solvers/ode_solve/">Tsit5 - Tsitouras 5/4 Runge-Kutta method. (free 4th order interpolant).</a></p>
</blockquote>
<p>である <span class="citation" data-cites="Tsitouras2011">(Tsitouras, 2011)</span>．次のようにカスタマイズもできる</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">OrdinaryDiffEq</span>: Vern9 <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># accessing the ODE solvers</span></span>
<span id="cb4-2">diffeq <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (alg <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Vern9</span>(), abstol <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-9</span>, reltol <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-9</span>)</span>
<span id="cb4-3">lorenz96_vern <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ContinuousDynamicalSystem</span>(lorenz96_rule!, u0, p0; diffeq)</span>
<span id="cb4-4"></span>
<span id="cb4-5">Y, t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">trajectory</span>(lorenz96_vern, total_time; Ttr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.2</span>, Δt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sampling_time)</span>
<span id="cb4-6">Y[<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">end</span>]</span></code></pre></div>
</div>
</div>
</section>
<section id="タイムスケール版" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="タイムスケール版"><span class="header-section-number">1.3</span> ２タイムスケール版</h3>
<p><span class="citation" data-cites="Lorenz1995">(Section 4 Lorenz, 1995)</span> では２タイムスケール版の Lorenz 96 モデルが導入されている： <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%20%20%5Cfrac%7Bd%20x_i%7D%7Bd%20t%7D&amp;=-x_%7Bi-1%7D(x_%7Bi-2%7D-x_%7Bi+1%7D)-x_i+F-%5Cleft(%5Cfrac%7Bhc%7D%7Bb%7D%5Cright)%5Csum_%7Bj=1%7D%5E%7BJ-1%7DY_%7Bj,i%7D,%5C%5C%0A%20%20%5Cfrac%7Bd%20y_%7Bj,i%7D%7D%7Bd%20t%7D&amp;=-cbY_%7Bj+1,i%7D(Y_%7Bj+2,i%7D-Y_%7Bj-1,i%7D)-cY_%7Bj,i%7D+%5Cfrac%7Bhc%7D%7Bb%7DX_i.%0A%5Cend%7Balign*%7D"></p>
</section>
</section>
<section id="非圧縮粘性-navier-stokes-方程式" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="非圧縮粘性-navier-stokes-方程式"><span class="header-section-number">2</span> 非圧縮・粘性 Navier-Stokes 方程式</h2>
<section id="モデル定義-1" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="モデル定義-1"><span class="header-section-number">2.1</span> モデル定義</h3>
<p><img src="https://latex.codecogs.com/png.latex?M%5En"> を <img src="https://latex.codecogs.com/png.latex?n">-次元可微分多様体，<img src="https://latex.codecogs.com/png.latex?v:M%5Ctimes%5Cmathbb%7BR%7D_+%5Cto%5Cmathbb%7BR%7D%5En"> を <img src="https://latex.codecogs.com/png.latex?M"> 上のベクトル場とする．<img src="https://latex.codecogs.com/png.latex?v"> に関する非圧縮・粘性 Navier-Stokes 方程式は次のように表せる <span class="citation" data-cites="Temam1995">(Temam, 1995)</span>, <span class="citation" data-cites="Evans2010">(Evans, 2010, p. 6)</span>：</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cpartial_tv-%5Cnu%5Cmathop%7B%7D%5C!%5Cmathbin%5Cbigtriangleup%20v+v%5Ccdot%5Cnabla%20v=f-%5Cnabla%20p,%5Cqquad%5Cnu%3E0,%0A"> <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7Bdiv%7Dv=0,%5Cquad%5Cint_M%20v_j(x,-)%5C,dx=0%5Cquad(j%5Cin%5Bn%5D),%5Cquad%20v(x,0)=:u(x).%0A"> <img src="https://latex.codecogs.com/png.latex?%5Cnu%3E0"> を <strong>粘性</strong> (viscosity) 係数，<img src="https://latex.codecogs.com/png.latex?p:M%5Ctimes%5Cmathbb%7BR%7D_+%5Cto%5Cmathbb%7BR%7D"> を <strong>圧力</strong> (pressure) という．<img src="https://latex.codecogs.com/png.latex?f"> は時間一定の外力である．<sup>2</sup></p>
</section>
<section id="数値解法" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="数値解法"><span class="header-section-number">2.2</span> 数値解法</h3>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="周期的境界条件">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
周期的境界条件
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?M%5En=:%5COmega"> を <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5En"> の領域とし，周期的な境界条件 <img src="https://latex.codecogs.com/png.latex?%0Av(x+Le_i,t)=v(x,t),%5Cqquad(x,t)%5Cin%20M%5En%5Ctimes%5Cmathbb%7BR%7D_+%0A"> を考える．ただし，<img src="https://latex.codecogs.com/png.latex?e_i"> は <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5En"> の標準基底ベクトルである．</p>
<p>この設定の下では数学的に理想的な取り扱いができる．物理的には例えばトーラス上の流体を考えていることに相当する．</p>
</div>
</div>
<p><img src="https://latex.codecogs.com/png.latex?v"> を数値的に得るためには <a href="https://en.wikipedia.org/wiki/Projection_method_(fluid_dynamics)"><strong>射影法</strong></a> (projection method) <span class="citation" data-cites="Chorin1967">(Chorin, 1967)</span>, <span class="citation" data-cites="Chorin1968">(Chorin, 1968)</span> を用いる．</p>
<p>この方法では Helmholtz-Hodge の射影作用素 <img src="https://latex.codecogs.com/png.latex?P"> が用いられる．</p>
<p>これは <span id="eq-projected-navier-stokes"><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7Bd%20v%7D%7Bd%20t%7D+%5Cnu%20Av+B(v,v)=P(f),%5Cqquad%20v(0)=u%0A%5Ctag%7B1%7D"></span> という（無限次元空間 <img src="https://latex.codecogs.com/png.latex?v%5Cin%20V'"> 上の） ODE への帰着を可能にする．ただし， <img src="https://latex.codecogs.com/png.latex?%0AB(v,w):=%5Cfrac%7B1%7D%7B2%7DP(v%5Ccdot%5Cnabla%20w)+%5Cfrac%7B1%7D%7B2%7DP(w%5Ccdot%5Cnabla%20v).%0A"></p>
<p>あとは ODE (1) をソルバーで解くのである．</p>
</section>
<section id="数学的詳細" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="数学的詳細"><span class="header-section-number">2.3</span> 数学的詳細<sup>3</sup></h3>
<p><img src="https://latex.codecogs.com/png.latex?H%5Em(%5COmega)%5Csubset%20L%5E2(%5COmega)"> を <img src="https://latex.codecogs.com/png.latex?m"> 階までの導関数が全て <img src="https://latex.codecogs.com/png.latex?L%5E2(%5COmega)"> に属する関数からなる Sobolev 空間とする．</p>
<p><img src="https://latex.codecogs.com/png.latex?H_p%5Em(%5COmega)"> を <img src="https://latex.codecogs.com/png.latex?H_%5Cmathrm%7Bloc%7D%5Em(%5Cmathbb%7BR%7D%5En)"> の部分空間のうち，<img src="https://latex.codecogs.com/png.latex?%5COmega"> 上で周期的なものとすると，次の表示を持つ： <img src="https://latex.codecogs.com/png.latex?%0AH_p%5Em(%5COmega)=%5Cleft%5C%7Bu=%5Csum_%7Bk%5Cin%5Cmathbb%7BZ%7D%5En%7Dc_ke%5E%7B2i%5Cpi%20k%5Ccdot%20x/L%7D%5C,%5Cmiddle%7C%5C,%5Coverline%7Bc%7D_k=c_%7B-k%7D,%5Csum_%7Bk%5Cin%5Cmathbb%7BZ%7D%5En%7D%5Clvert%20k%5Crvert%5E%7B2m%7D%5Clvert%20c_k%5Crvert%5E2%3C%5Cinfty%5Cright%5C%7D.%0A"> <img src="https://latex.codecogs.com/png.latex?%5Cdot%7BH%7D_p%5Em(%5COmega)"> を <img src="https://latex.codecogs.com/png.latex?H_p%5Em(%5COmega)"> のうち <img src="https://latex.codecogs.com/png.latex?c_0=0"> を満たすものの部分空間とする．上の表示をもとにして，任意の <img src="https://latex.codecogs.com/png.latex?m%5Cin%5Cmathbb%7BR%7D"> について <img src="https://latex.codecogs.com/png.latex?%5Cdot%7BH%7D%5Em_p(%5COmega)"> が定まる．</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AV:=%5Cleft%5C%7Bu%5Cin%20H%5E1_p(%5COmega)%5C,%5Cmiddle%7C%5C,%5Coperatorname%7Bdiv%7Du=0%5C,%5Cmathrm%7Bon%7D%5C;%5Cmathbb%7BR%7D%5En%5Cright%5C%7D,%5Cqquad%20H:=%5Cleft%5C%7Bu%5Cin%20H%5E0_p(%5COmega)%5C,%5Cmiddle%7C%5C,%5Coperatorname%7Bdiv%7Du=0%5C,%5Cmathrm%7Bon%7D%5C;%5Cmathbb%7BR%7D%5En%5Cright%5C%7D%0A"> について <img src="https://latex.codecogs.com/png.latex?V%5Csubset%20H%5Csubset%20V%5E*"> が成り立つ．</p>
<p>以上の設定では，<img src="https://latex.codecogs.com/png.latex?A:V%5Coverset%7B%5Csim%7D%7B%5Cto%7DV%5E*"> は同型，<img src="https://latex.codecogs.com/png.latex?B:V%5Ctimes%20V%5Chookrightarrow%20V%5E*"> は連続な双線型作用素になる．</p>
<p><img src="https://latex.codecogs.com/png.latex?P"> は Helmholtz 射影と呼ばれ，<img src="https://latex.codecogs.com/png.latex?V%5E*"> 上への射影を与える．<sup>4</sup></p>
</section>
<section id="galerkin-近似" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="galerkin-近似"><span class="header-section-number">2.4</span> Galerkin 近似</h3>
<p><img src="https://latex.codecogs.com/png.latex?A"> の固有関数を <img src="https://latex.codecogs.com/png.latex?(w_i)"> とし，最初の <img src="https://latex.codecogs.com/png.latex?m"> 個の固有関数が定める空間上への射影を <img src="https://latex.codecogs.com/png.latex?P_m"> とし， <img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7Bd%20v_m%7D%7Bd%20t%7D+%5Cnu%20Av_m+P_mB(v_m)=P_mf,%5Cqquad%20t%3E0,v_m(0)=P_mv_0.%0A"> を解く．この <img src="https://latex.codecogs.com/png.latex?v_m"> を <img src="https://latex.codecogs.com/png.latex?v"> の <strong>Galerkin 近似</strong> という <span class="citation" data-cites="Temam1995">(Temam, 1995, p. 109)</span>．</p>
<p>こうして得る有限次元空間上の ODE はまだ <a href="https://ja.wikipedia.org/wiki/硬い方程式"><strong>硬い方程式</strong></a> であり，例えば指数的な有限差分を取る <span class="citation" data-cites="Cox-Matthews2002">(Cox and Matthews, 2002)</span> などの処置が必要である．</p>
<p><span class="citation" data-cites="Kantas+2014">(Section 5 Kantas et al., 2014)</span> はデータ同化の文脈でこれを解いている．</p>
</section>
<section id="シミュレーション" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="シミュレーション"><span class="header-section-number">2.5</span> シミュレーション</h3>
<p><code>IncompressibleNavierStokes.jl</code> (<a href="https://github.com/agdestein/IncompressibleNavierStokes.jl">GitHub</a> / <a href="https://agdestein.github.io/IncompressibleNavierStokes.jl/dev/">Docs</a>) パッケージを用いて，非圧縮 Navier-Stokes 方程式を解くことができる．</p>
<p><a href="https://en.wikipedia.org/wiki/Rayleigh%E2%80%93B%C3%A9nard_convection">Rayleigh-Bénard 対流</a> 問題を実行するサンプルコードが提示されている．</p>
<p>Rayleigh-Bénard 対流は二次元空間を下から加熱した際の流体の対流で，<a href="https://ja.wikipedia.org/wiki/%E3%83%99%E3%83%8A%E3%83%BC%E3%83%AB%E3%83%BB%E3%82%BB%E3%83%AB">Bénard 細胞</a> と呼ばれる散逸構造が現れるはずである．</p>
<div id="31ee622a" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">GLMakie</span></span>
<span id="cb5-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">IncompressibleNavierStokes</span></span>
<span id="cb5-3"></span>
<span id="cb5-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Setup</span></span>
<span id="cb5-5">setup <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Setup</span>(</span>
<span id="cb5-6">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">tanh_grid</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.2</span>), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">tanh_grid</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.2</span>)),</span>
<span id="cb5-7">    boundary_conditions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ((<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">DirichletBC</span>(), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">DirichletBC</span>()), (<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">DirichletBC</span>(), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">DirichletBC</span>())),</span>
<span id="cb5-8">    temperature <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">temperature_equation</span>(;</span>
<span id="cb5-9">        Pr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.71</span>,</span>
<span id="cb5-10">        Ra <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e7</span>,</span>
<span id="cb5-11">        Ge <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>,</span>
<span id="cb5-12">        boundary_conditions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb5-13">            (<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">SymmetricBC</span>(), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">SymmetricBC</span>()),</span>
<span id="cb5-14">            (<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">DirichletBC</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">DirichletBC</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>)),</span>
<span id="cb5-15">        ),</span>
<span id="cb5-16">    ),</span>
<span id="cb5-17">)</span>
<span id="cb5-18"></span>
<span id="cb5-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Solve equation</span></span>
<span id="cb5-20"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">solve_unsteady</span>(;</span>
<span id="cb5-21">    setup,</span>
<span id="cb5-22">    ustart <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">velocityfield</span>(setup, (dim, x, y) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">zero</span>(x)),</span>
<span id="cb5-23">    tempstart <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">temperaturefield</span>(setup, (x, y) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sinpi</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>),</span>
<span id="cb5-24">    tlims <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">30.0</span>),</span>
<span id="cb5-25">    Δt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.02</span>,</span>
<span id="cb5-26">    processors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (;</span>
<span id="cb5-27">        anim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">animator</span>(;</span>
<span id="cb5-28">            setup,</span>
<span id="cb5-29">            path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"temperature.mp4"</span>,</span>
<span id="cb5-30">            fieldname <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>temperature,</span>
<span id="cb5-31">            colorrange <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>),</span>
<span id="cb5-32">            size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">900</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>),</span>
<span id="cb5-33">            colormap <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>seaborn_icefire_gradient,</span>
<span id="cb5-34">            nupdate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>,</span>
<span id="cb5-35">        ),</span>
<span id="cb5-36">    ),</span>
<span id="cb5-37">)</span></code></pre></div>
</div>
<p><img src="https://162348.github.io/posts/2024/Particles/Files/temperature.gif" class="img-fluid"></p>
<p><a href="https://agdestein.github.io/IncompressibleNavierStokes.jl/dev/manual/solver#Solvers-2"><code>solve_unsteady()</code></a> 関数は <code>method = RKMethods.RK44(; T = eltype(ustart[1])),</code> がデフォルトである．</p>
<p><code>RK44</code> は 4 次の Runge-Kutta 法である．４次の Runge-Kutta 法は圧力に懸念があることを除いて，速度場の解法としては悪くない性能を示すようである <span class="citation" data-cites="Sanderse-Koren2012">(Sanderse and Koren, 2012)</span>．</p>
<p>例えば非一様な風が障害物に当たる場合のシミュレーション例では，圧力も２次まで計算する <code>RK44P2()</code> を用いている．</p>
<div id="25a733bc" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">IncompressibleNavierStokes</span></span>
<span id="cb6-2"></span>
<span id="cb6-3">n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span></span>
<span id="cb6-4">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">LinRange</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">10.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">LinRange</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb6-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plotgrid</span>(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">...</span>; figure <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (; size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">600</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>)))</span>
<span id="cb6-6"></span>
<span id="cb6-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">inflow</span>(dim, x, y, t) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sinpi</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sinpi</span>(t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb6-8">boundary_conditions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ((<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">DirichletBC</span>(inflow), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">PressureBC</span>()), (<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">PressureBC</span>(), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">PressureBC</span>()))</span>
<span id="cb6-9"></span>
<span id="cb6-10">xc, yc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Disk center</span></span>
<span id="cb6-11">D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>           <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Disk diameter</span></span>
<span id="cb6-12">δ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.11</span>          <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Disk thickness</span></span>
<span id="cb6-13">C <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>           <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Thrust coefficient</span></span>
<span id="cb6-14">c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> C <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> δ)   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Normalize</span></span>
<span id="cb6-15"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">inside</span>(x, y) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">abs</span>(x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> xc) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">≤</span> δ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;&amp;</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">abs</span>(y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> yc) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">≤</span> D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb6-16"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">bodyforce</span>(dim, x, y, t) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">inside</span>(x, y)</span>
<span id="cb6-17"></span>
<span id="cb6-18">setup <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Setup</span>(; x, Re <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">100.0</span>, boundary_conditions, bodyforce, issteadybodyforce <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">true</span>);</span>
<span id="cb6-19"></span>
<span id="cb6-20">ustart <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">velocityfield</span>(setup, (dim, x, y) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">inflow</span>(dim, x, y, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>))</span>
<span id="cb6-21"></span>
<span id="cb6-22">state, outputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">solve_unsteady</span>(;</span>
<span id="cb6-23">    setup,</span>
<span id="cb6-24">    ustart,</span>
<span id="cb6-25">    tlims <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">12.0</span>),</span>
<span id="cb6-26">    method <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RKMethods.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">RK44P2</span>(),</span>
<span id="cb6-27">    Δt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>,</span>
<span id="cb6-28">    processors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb6-29">        anim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">animator</span>(;</span>
<span id="cb6-30">            setup,</span>
<span id="cb6-31">            path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"navier_stokes_animation.mp4"</span>,</span>
<span id="cb6-32">            fieldname <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>vorticity,</span>
<span id="cb6-33">            colorrange <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb6-34">            size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">600</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>),</span>
<span id="cb6-35">            colormap <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>bam,</span>
<span id="cb6-36">            nupdate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>,</span>
<span id="cb6-37">        ),</span>
<span id="cb6-38">        log <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">timelogger</span>(; nupdate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>),</span>
<span id="cb6-39">    ),</span>
<span id="cb6-40">);</span></code></pre></div>
</div>
<p><img src="https://162348.github.io/posts/2024/Particles/Files/navier_stokes_animation.gif" class="img-fluid"></p>
<p>blade の両端で過度が生じていることがわかる．</p>
</section>
</section>



<div id="quarto-appendix" class="default"><section id="文献紹介" class="level2 appendix" data-number="3"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3</span> 文献紹介</h2><div class="quarto-appendix-contents">

<p><span class="citation" data-cites="vanKekem2018">(van/ Kekem, 2018)</span>, <span class="citation" data-cites="Kerin-Engler2022">(Kerin and Engler, 2022)</span> が概観に良い．<span class="citation" data-cites="Balwada+2023">(Balwada and Zanna, 2023)</span> は２タイムスケール版について詳しい．</p>
<p>Navier-Stokes 方程式のデータ同化に関しては <span class="citation" data-cites="Kantas+2014">(Kantas et al., 2014)</span> などで考えられている．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Balwada+2023" class="csl-entry">
Balwada, A., D., and Zanna, L. (2023). <em><a href="https://m2lines.github.io/L96_demo/intro.html"><span class="nocase">Learning Machine Learning with Lorenz-96</span></a></em>. Authorea Preprints.
</div>
<div id="ref-Chorin1967" class="csl-entry">
Chorin, A. J. (1967). <a href="https://projecteuclid.org/journals/bulletin-of-the-american-mathematical-society-new-series/volume-73/issue-6/The-numerical-solution-of-the-Navier-Stokes-equations-for-an/bams/1183529112.full"><span class="nocase">The numerical solution of the Navier-Stokes equations for an incompressible fluid</span></a>. <em>Bulletin of the American Mathematical Society</em>, <em>73</em>(6), 928–931.
</div>
<div id="ref-Chorin1968" class="csl-entry">
Chorin, A. J. (1968). <a href="http://www.jstor.org/stable/2004575">Numerical solution of the navier-stokes equations</a>. <em>Mathematics of Computation</em>, <em>22</em>(104), 745–762.
</div>
<div id="ref-Cox-Matthews2002" class="csl-entry">
Cox, S. M., and Matthews, P. C. (2002). <a href="https://doi.org/10.1006/jcph.2002.6995">Exponential time differencing for stiff systems</a>. <em>Journal of Computational Physics</em>, <em>176</em>(2), 430–455.
</div>
<div id="ref-Evans2010" class="csl-entry">
Evans, L. C. (2010). <em><a href="https://bookstore.ams.org/gsm-19-r">Partial differential equations</a></em>,Vol. 19. American Mathematical Society.
</div>
<div id="ref-Milan2021" class="csl-entry">
K, M. (2021, July). <a href="https://doi.org/10.5281/zenodo.5121430">Milankl/Lorenz96.jl: v0.3.0</a> (Version v0.3.0). Zenodo.
</div>
<div id="ref-Kantas+2014" class="csl-entry">
Kantas, N., Beskos, A., and Jasra, A. (2014). <a href="https://doi.org/10.1137/130930364">Sequential monte carlo methods for high-dimensional inverse problems: A case study for the navier–stokes equations</a>. <em>SIAM/ASA Journal on Uncertainty Quantification</em>, <em>2</em>(1), 464–489.
</div>
<div id="ref-Kerin-Engler2022" class="csl-entry">
Kerin, J., and Engler, H. (2022). <a href="https://doi.org/10.3934/dcdsb.2021064">On the lorenz ’96 model and some generalizations</a>. <em>Discrete and Continuous Dynamical Systems - B</em>.
</div>
<div id="ref-Lorenz1963" class="csl-entry">
Lorenz, E. N. (1963). <a href="https://doi.org/10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2">Deterministic nonperiodic flow</a>. <em>Journal of Atmospheric Sciences</em>, <em>20</em>(2), 130–141.
</div>
<div id="ref-Lorenz1995" class="csl-entry">
Lorenz, E. N. (1995). <a href="https://www.ecmwf.int/en/elibrary/75462-predictability-problem-partly-solved">Predictability: A problem partly solved</a>. In <em>Seminar on predictability, 4-8 september 1995</em>. ECMWF.
</div>
<div id="ref-Sanderse-Koren2012" class="csl-entry">
Sanderse, B., and Koren, B. (2012). <a href="https://doi.org/10.1016/j.jcp.2011.11.028">Accuracy analysis of explicit runge–kutta methods applied to the incompressible navier–stokes equations</a>. <em>Journal of Computational Physics</em>, <em>231</em>(8), 3041–3063.
</div>
<div id="ref-Temam1995" class="csl-entry">
Temam, R. M. (1995). <em><a href="https://doi.org/10.1137/1.9781611970050">Navier–stokes equations and nonlinear functional analysis</a></em>. Society for Industrial; Applied Mathematics.
</div>
<div id="ref-Tsai2018" class="csl-entry">
Tsai, T.-P. (2018). <em><a href="https://doi.org/10.1090/gsm/192">Lectures on navier-stokes equations</a></em>,Vol. 192. American Mathematical Society.
</div>
<div id="ref-Tsitouras2011" class="csl-entry">
Tsitouras, Ch. (2011). <a href="https://doi.org/10.1016/j.camwa.2011.06.002">Runge–kutta pairs of order 5(4) satisfying only the first column simplifying assumption</a>. <em>Computers &amp; Mathematics with Applications</em>, <em>62</em>(2), 770–775.
</div>
<div id="ref-vanKekem2018" class="csl-entry">
van/ Kekem, D. L. (2018). <em>Dynamics of the lorenz-96 model: Bifurcations, symmetries and waves</em> (PhD thesis). University of Groningen. Retrieved from <a href="https://research.rug.nl/en/publications/dynamics-of-the-lorenz-96-model-bifurcations-symmetries-and-waves">https://research.rug.nl/en/publications/dynamics-of-the-lorenz-96-model-bifurcations-symmetries-and-waves</a>
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>コードは<a href="Files/Lorenz96.jl">こちら</a>を参照．↩︎</p></li>
<li id="fn2"><p>上述の方程式は，係数を正規化した場合とも，正規化した関数に関する方程式とも解釈できる．後者の解釈では，<img src="https://latex.codecogs.com/png.latex?%5Cnu%5E%7B-1%7D"> は Reynolds 数に対応する．↩︎</p></li>
<li id="fn3"><p>本小節は <span class="citation" data-cites="Temam1995">(Section 2 Temam, 1995)</span> を参考にしている．↩︎</p></li>
<li id="fn4"><p><span class="citation" data-cites="Tsai2018">(Tsai, 2018, p. 16)</span> も参照．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Nature</category>
  <category>Julia</category>
  <guid>https://162348.github.io/posts/2024/Particles/Lorenz95.html</guid>
  <pubDate>Sat, 05 Oct 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Particles/Files/navier_stokes_animation.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>ベイズデータ解析３</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Survey/Survey3.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="関連記事" class="level2 unnumbered unlisted">
<h2 class="unnumbered unlisted anchored" data-anchor-id="関連記事">関連記事</h2>
<div id="listing-lst-survey" class="listing quarto-float quarto-figure quarto-figure-left quarto-listing quarto-listing-container-grid anchored">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="QmF5ZXNpYW4lMkNTdGF0aXN0aWNz" data-listing-date-sort="1727049600000" data-listing-file-modified-sort="1733137938540" data-listing-date-modified-sort="1727827200000" data-listing-reading-time-sort="3" data-listing-word-count-sort="516">
<a href="../../../posts/2024/Survey/Survey1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Survey/Files/BayesANOVA.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズデータ解析１
</h5>
<div class="card-subtitle listing-subtitle">
分散分析
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-23
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="U3RhdGlzdGljcw==" data-listing-date-sort="1727049600000" data-listing-file-modified-sort="1733137938540" data-listing-date-modified-sort="1727568000000" data-listing-reading-time-sort="3" data-listing-word-count-sort="466">
<a href="../../../posts/2024/Survey/Survey2.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Survey/Files/ATE.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズデータ解析２
</h5>
<div class="card-subtitle listing-subtitle">
平均処置効果の推定とセミパラメトリック法
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-23
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="QmF5ZXNpYW4lMkNTdGF0aXN0aWNz" data-listing-date-sort="1727136000000" data-listing-file-modified-sort="1733137938540" data-listing-date-modified-sort="1727395200000" data-listing-reading-time-sort="2" data-listing-word-count-sort="269">
<a href="../../../posts/2024/Survey/Survey4.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Survey/Files/DataIntegration.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズデータ解析４
</h5>
<div class="card-subtitle listing-subtitle">
アンケートデータとデータ統合
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-24
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>
<section id="有限標本論の概要" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="有限標本論の概要"><span class="header-section-number">1</span> 有限標本論の概要</h2>
<section id="sec-probability-sample" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="sec-probability-sample"><span class="header-section-number">1.1</span> 設定</h3>
<p><img src="https://latex.codecogs.com/png.latex?%5BN%5D"> を母集団とする．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5BN%5D"> の部分集合の全体 <img src="https://latex.codecogs.com/png.latex?P(%5BN%5D)"> 上の確率分布を <strong>抽出計画</strong> (sampling design) といい，ある既知の抽出分布に従って得られる標本 <img src="https://latex.codecogs.com/png.latex?S%5Csubset%5BN%5D"> を <strong>確率標本</strong> (probability sample) という．<a href="https://www.e-stat.go.jp/classifications/terms/90/00/4937">日本語では <strong>無作為抽出標本</strong> などとも呼ばれる</a>．</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="抽出計画の例">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
抽出計画の例
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>抽出計画 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D%5BS%5D"> には，</p>
<ul>
<li>単純無作為抽出 (SRS: Simple Random Sampling)</li>
<li>系統無作為抽出 (Systematic Random Sampling)</li>
<li>層別抽出 (Stratified Sampling)：母集団を層別し，各層の間では独立な抽出を行う．層ごとに抽出計画は異なっても良い．条件付きランダム化 (conditional randomization) ともいう <span class="citation" data-cites="Hernan-Robins2020">(Section 2.2 Hernán and Robins, 2020, p. 17)</span>．</li>
<li>クラスター抽出 (Cluster Random Sampling)：クラスターがまずランダム抽出され，そのクラスター内の全構成員が標本に加わる．クラスターのことを PSU (Primary Sampling Unit) ともいう．クラスター内でもランダム抽出が行われた場合，<strong>２段階クラスターサンプリング</strong> という．</li>
</ul>
<p>などの方法が存在する．</p>
<p>例えば，日本の国勢調査は２段階の層別抽出である．</p>
</div>
</div>
</div>
<p>確率標本 <img src="https://latex.codecogs.com/png.latex?S"> では（１次の）<strong>包含確率</strong> <img src="https://latex.codecogs.com/png.latex?%0A%5Cpi_i:=%5Coperatorname%7BP%7D%5Bi%5Cin%20S%5D=%5Coperatorname%7BP%7D%5BI=1%5D,%5Cqquad%20I:=1_%7Bi%5Cin%20S%7D.%0A"> が定まる．</p>
<div class="callout callout-style-default callout-important no-icon callout-titled" title="狭義の「確率標本」">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
狭義の「確率標本」
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>先ほど，<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BP%7D(%5BN%5D)"> 上の確率変数を確率標本と呼ぶとしたが，正確に <img src="https://latex.codecogs.com/png.latex?S"> が <strong>確率標本</strong> と呼ばれるためには，<img src="https://latex.codecogs.com/png.latex?%5Cpi_i%3E0"> が母集団 <img src="https://latex.codecogs.com/png.latex?i%5Cin%5BN%5D"> の全域で成り立つことが必要である <span class="citation" data-cites="Kim2024">(Kim, 2024, p. 12)</span>．</p>
</div>
</div>
</div>
</section>
<section id="horvitz-thompson-推定量" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="horvitz-thompson-推定量"><span class="header-section-number">1.2</span> Horvitz-Thompson 推定量</h3>
<p>確率標本 <img src="https://latex.codecogs.com/png.latex?S%5Cin%5Cmathcal%7BL%7D(%5COmega;%5Cmathcal%7BP%7D(%5BN%5D))"> に対しては，ある量 <img src="https://latex.codecogs.com/png.latex?y"> についての母集団の総和 <img src="https://latex.codecogs.com/png.latex?%0AY:=%5Csum_%7Bi=1%7D%5ENy_i%0A"> が <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%5Cmathrm%7BHT%7D:=%5Csum_%7Bi%5Cin%20S%7D%5Cfrac%7By_i%7D%7B%5Cpi_i%7D%0A"> により不偏推定できる．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7BY%7D_%5Cmathrm%7BHT%7D"> は <span class="citation" data-cites="Horvitz-Thompson1952">(Horvitz and Thompson, 1952)</span> 推定量と呼ばれる．<sup>1</sup></p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="[@Sen1953]-[@Yates-Grundy1953]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="citation" data-cites="Sen1953">(Sen, 1953)</span>-<span class="citation" data-cites="Yates-Grundy1953">(Yates and Grundy, 1953)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Horvitz-Thompson 推定量の分散は次で与えられる：</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7BV%7D%5B%5Cwidehat%7BY%7D_%5Cmathrm%7BHT%7D%5D=%5Csum_%7Bi,j=1%7D%5EN%5Cbiggr(%5Cpi_%7Bij%7D-%5Cpi_i%5Cpi_j%5Cbiggl)%5Cfrac%7By_iy_j%7D%7B%5Cpi_i%5Cpi_j%7D.%0A"> ただし， <img src="https://latex.codecogs.com/png.latex?%0A%5Cpi_%7Bij%7D:=%5Coperatorname%7BP%7D%5Bi%5Cin%20S,j%5Cin%20S%5D=%5Coperatorname%7BP%7D%5BI=1=J%5D.%0A"> を２次の包含確率という．</p>
</div>
</div>
<p>Horvitz-Thompson 推定量の要点には，「計画した欠損ならば，重みづけによって不偏推定量を得ることができる」という点にある．</p>
<p>そこで抽出計画が不明な場合もこれを推定し，バイアスを補正しようとするアプローチを傾向スコアの方法，または <strong>擬似ランダム化</strong> (pseudo-randomization) の方法という．</p>
</section>
<section id="校正効率の改善に向けて" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="校正効率の改善に向けて"><span class="header-section-number">1.3</span> 「校正」：効率の改善に向けて</h3>
<p>HT 推定量は確率標本 <img src="https://latex.codecogs.com/png.latex?S"> の分布，すなわち抽出計画に依らずに不偏性を持つ．</p>
<p>これを計画不偏性 (design-unbiasedness) というが，この性質を持つ線型な推定量は HT に限られる．</p>
<p>しかし，HT 推定量はいつでも分散が最小というわけではない．</p>
<p>計画不偏性は bias-variance trade-off の観点からは欠点でもあり，それゆえ抽出計画に関する情報を用いて分散を低減することも考えられる．</p>
<p>特に，HT 推定量の荷重 <img src="https://latex.codecogs.com/png.latex?(%5Cpi_i%5E%7B-1%7D)"> を，補助変数 <img src="https://latex.codecogs.com/png.latex?x_i"> に関する <strong>外部一致性</strong> <img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi%5Cin%20S%7Dw_ix_i=%5Coverline%7Bx%7D%0A"> を保ちながら新しいもの <img src="https://latex.codecogs.com/png.latex?(w_i)"> に変更するものが多く考えられた．</p>
<div class="callout callout-style-simple callout-important no-icon callout-titled" title="「外部一致性」の別名">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
「外部一致性」の別名
</div>
</div>
<div class="callout-body-container callout-body">
<p>有限標本論は普遍的な統計推測の基礎であると言える．</p>
<p>実際，この外部一致性の条件は多くの分野で考慮されており，種々の名前が与えられている．</p>
<ul>
<li>有限標本論：校正条件 (calibration condition / benchmarking property) （第 2.3 節）</li>
<li>欠測データ解析：共変量バランシング (covariate balancing) <span class="citation" data-cites="Imai-Ratkovic2014">(Imai and Ratkovic, 2014)</span></li>
<li>機械学習（継続学習）：共変量シフト (covariate shift) <span class="citation" data-cites="Shimodaira2000">(Shimodaira, 2000)</span></li>
</ul>
</div>
</div>
<p>このアプローチを <strong>荷重校正</strong> (calibration weighting) という．</p>
<p>次章にてこれ以降，種々の荷重校正推定量を紹介する．</p>
</section>
</section>
<section id="回帰推定量" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="回帰推定量"><span class="header-section-number">2</span> 回帰推定量</h2>
<section id="はじめに" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="はじめに"><span class="header-section-number">2.1</span> はじめに</h3>
<p>前述の通り，補助変数 <img src="https://latex.codecogs.com/png.latex?x"> が母集団上で知られている場合に，ここから抽出計画に対する追加情報を抽出して推定量に組み込むことで，計画的に欠測させられたデータ（＝確率標本）に対する不偏推定量 <span class="citation" data-cites="Horvitz-Thompson1952">(Horvitz and Thompson, 1952)</span> （以降 HT 推定量という）の効率を改善することを考える．</p>
<p>以降，補助変数 <img src="https://latex.codecogs.com/png.latex?x%5Cin%5Cmathbb%7BR%7D%5Ep"> は母集団上で既知であるとし，その総和を <img src="https://latex.codecogs.com/png.latex?%0AX:=%5Csum_%7Bi%5Cin%5BN%5D%7Dx_i%0A"> で表す．</p>
</section>
<section id="比による校正" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="比による校正"><span class="header-section-number">2.2</span> 比による校正</h3>
<p>補助変数の次元が <img src="https://latex.codecogs.com/png.latex?p=1"> のとき，最も安直には <img src="https://latex.codecogs.com/png.latex?X"> の HT 推定量から，真の値 <img src="https://latex.codecogs.com/png.latex?X"> との「ズレ方」を用いて，<img src="https://latex.codecogs.com/png.latex?Y"> の推定量を「校正」することができる．</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%7B%5Cmathrm%7BR%7D%7D:=%5Cwidehat%7BY%7D_%5Cmathrm%7BHT%7D%5Cfrac%7BX%7D%7B%5Cwidehat%7BX%7D_%5Cmathrm%7BHT%7D%7D%0A"> とできるだろう．</p>
<p>この推定量は ratio estimator などと呼ばれ，性能の代わりにバイアスが生じてしまう．</p>
<p>一般に，<img src="https://latex.codecogs.com/png.latex?X,Y"> が正の相関を持つとき大きな分散低減が得られる <span class="citation" data-cites="Deng-Wu1987">(Deng and Wu, 1987)</span>, <span class="citation" data-cites="Kim2024">(Kim, 2024, p. 92)</span>．</p>
<p><img src="https://latex.codecogs.com/png.latex?x_i=1"> と取った場合を Hajék 推定量ともいう．Hajék 推定量が HT 推定量よりも推奨される状況が <span class="citation" data-cites="Sarndal+1992">(Särndal et al., 1992, p. 182)</span> にリストされている．</p>
<p>この推定量は昔は計算の簡単さから使われていたが，一般の次の回帰推定量の方が MSE が小さいことが知られている <span class="citation" data-cites="Deng-Wu1987">(Deng and Wu, 1987)</span>．</p>
</section>
<section id="sec-regression-estimator" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="sec-regression-estimator"><span class="header-section-number">2.3</span> 回帰推定量</h3>
<p>超母集団模型 <img src="https://latex.codecogs.com/png.latex?%0AY=X%5E%5Ctop%5Cbeta+%5Cepsilon,%5Cqquad%5Cepsilon%5Coverset%7B%5Ctext%7Biid%7D%7D%7B%5Csim%7D(0,%5Csigma%5E2)%0A"> を想定し，得られている標本のみから <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7B%5Cbeta%7D"> を推定する．こうして得られる <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7By%7D_i:=x_i%5E%5Ctop%5Cwidehat%7B%5Cbeta%7D,%5Cqquad%5Cwidehat%7B%5Cbeta%7D:=%5Cleft(%5Csum_%7Bi%5Cin%20S%7D%5Cpi_i%5E%7B-1%7Dx_ix_i%5E%5Ctop%5Cright)%5E%7B-1%7D%5Csum_%7Bi%5Cin%20S%7D%5Cpi_i%5E%7B-1%7Dx_iy_i%0A"> の総和が，<img src="https://latex.codecogs.com/png.latex?Y"> に対する <strong>回帰推定量</strong> (regression estimator) と呼ばれる．<sup>2</sup></p>
<p>これは <img src="https://latex.codecogs.com/png.latex?(y_i)%5Cin%5Cmathbb%7BR%7D%5En"> に関する線型推定量になっている．加えて，外部一致性 <span id="eq-external-consistency"><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi%5Cin%20S%7Dw_ix_i=%5Coverline%7Bx%7D%0A%5Ctag%7B1%7D"></span> を満たす荷重 <img src="https://latex.codecogs.com/png.latex?%0Aw_i:=%5Coverline%7BX%7D%5E%5Ctop%5Cleft(%5Csum_%7Bi%5Cin%20S%7D%5Cpi_i%5E%7B-1%7Dx_ix_i%5E%5Ctop%5Cright)%5E%7B-1%7D%5Cpi_i%5E%7B-1%7Dx_i%0A"> に関して， <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%7B%5Cmathrm%7Breg%7D%7D=%5Csum_%7Bi%5Cin%20S%7Dw_iy_i%0A"> という形の線型推定量になっている．</p>
<p>式 (1) を <strong>外部一致性</strong> (external consistency)，または <strong>校正条件</strong> (calibration / benchmarking property) <span class="citation" data-cites="Deville-Sarndal1992">(Deville and Särndal, 1992)</span> という．</p>
<p>回帰推定量は <img src="https://latex.codecogs.com/png.latex?X,Y"> の関係に依らず一致性を持ち，<img src="https://latex.codecogs.com/png.latex?X,Y"> の間の相関の絶対値が大きいほど分散低減効果が高くなる <span class="citation" data-cites="Kim2024">(Kim, 2024, p. 95)</span>．<sup>3</sup></p>
</section>
<section id="事後層別化" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="事後層別化"><span class="header-section-number">2.4</span> 事後層別化</h3>
<p><strong>事後層別化</strong> (post-stratification / stratification after selection) は標本抽出の結果を見て標本を層別化する手法であるが，回帰推定量の特別な場合と見れる．</p>
<p>母集団が <img src="https://latex.codecogs.com/png.latex?G"> 個の層に分けられるとする：<img src="https://latex.codecogs.com/png.latex?N=N_1+%5Ccdots+N_G">．</p>
<p>このとき，<img src="https://latex.codecogs.com/png.latex?i%5Cin%5BN%5D"> 番目の単位が層 <img src="https://latex.codecogs.com/png.latex?g%5Cin%5BG%5D"> に属するかどうかの指示変数 <img src="https://latex.codecogs.com/png.latex?x_%7Big%7D%5Cin2"> のベクトル <img src="https://latex.codecogs.com/png.latex?x_i:=(x_%7Bi1%7D,%5Ccdots,x_%7BiG%7D)%5E%5Ctop%5Cin2%5EG"> に関する回帰推定量 <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%20%20%5Cwidehat%7BY%7D_%7B%5Cmathrm%7Bpost%7D%7D&amp;:=%5Csum_%7Bi=1%7D%5ENx_i%5E%5Ctop%5Cleft(%5Csum_%7Bi%5Cin%20S%7D%5Cpi_i%5E%7B-1%7Dx_ix_i%5E%5Ctop%5Cright)%5E%7B-1%7D%5Csum_%7Bi%5Cin%20S%7D%5Cpi_i%5E%7B-1%7Dx_iy_i%5C%5C%0A%20%20&amp;=%5Csum_%7Bg=1%7D%5EG%5Csum_%7Bi%5Cin%20S_g%7D%5Cpi_i%5E%7B-1%7D%5Cfrac%7BN_g%7D%7B%5Cwidehat%7BN%7D_g%7Dy_i,%5Cqquad%5Cwidehat%7BN%7D_g:=%5Csum_%7Bi%5Cin%20S%7D%5Cpi_i%5E%7B-1%7Dx_%7Big%7D.%0A%5Cend%7Balign*%7D"> を事後層別化推定量という．</p>
<p>MRP (Multilevel Regression and Post-stratification) <span class="citation" data-cites="Gelman-Little1997">(Gelman and Little, 1997)</span>, <span class="citation" data-cites="Gelman2014">(Gelman, 2014)</span> は事後層別化の階層モデル・縮小推定版である．</p>
</section>
<section id="ランキング法繰り返し比例的フィッティング法" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="ランキング法繰り返し比例的フィッティング法"><span class="header-section-number">2.5</span> ランキング法／繰り返し比例的フィッティング法</h3>
<p><span class="citation" data-cites="Deming-Stephan1940">(Deming and Stephan, 1940)</span> では 1940 年の国勢調査の結果の分析を考えていた．</p>
<p>特に，基本的な情報は全数調査されるが，詳細な情報は標本調査でしか得られない状況下で，母集団の <img src="https://latex.codecogs.com/png.latex?I%5Ctimes%20J"> 分割表の各セル <img src="https://latex.codecogs.com/png.latex?U_%7Bij%7D"> の値 <img src="https://latex.codecogs.com/png.latex?N_%7Bij%7D"> の推定を考えていた．</p>
<p>ただし，周辺和 <img src="https://latex.codecogs.com/png.latex?N_%7Bi-%7D,N_%7B-j%7D"> は全数調査で得られているとする．</p>
<p>このとき，<img src="https://latex.codecogs.com/png.latex?N_%7Bij%7D"> の推定量の候補として <img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7Bn_%7Bij%7D%7D%7Bn_%7Bi-%7D%7DN_i,%5Cquad%5Cfrac%7Bn_%7Bij%7D%7D%7Bn_%7B-j%7D%7DN_%7B-j%7D,%5Cquad%5Cfrac%7Bn_%7Bij%7D%7D%7Bn%7DN%0A"> の３つが考えられる．３番目が良いと考えるかもしれないが，その結果得られる分割表は周辺和を保存しない．</p>
<p>この問題は次のような形でも現れる：指示変数 <img src="https://latex.codecogs.com/png.latex?%0Ax_k=(x_%7B1-k%7D,%5Ccdots,x_%7BI-k%7D,x_%7B-1k%7D,%5Ccdots,x_%7B-Jk%7D),%5Cqquad%20x_%7Bijk%7D:=1_%7BU_%7Bij%7D%7D(k),%0A"> に基づく事後層別化推定量 <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%7B%5Cmathrm%7Bpost%7D%7D=%5Csum_%7Bi%5Cin%20S%7D%5Cpi_i%5E%7B-1%7Dg_i(S)y_i,%5Cqquad%20g_i(S):=%5Cleft(%5Csum_%7Bk=1%7D%5ENx_k%5Cright)%5E%5Ctop%5Cleft(%5Csum_%7Bk%5Cin%20S%7D%5Cpi_k%5E%7B-1%7Dx_kx_k%5E%5Ctop%5Cright)%5E%7B-1%7Dx_i%0A"> を考えたいが，これが <img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7Brank%7D%5Cleft(%5Csum_%7Bk%5Cin%20S%7D%5Cpi_k%5E%7B-1%7Dx_kx_k%5E%5Ctop%5Cright)=I+J-1"> であるため，一意な表示を持たない．</p>
<p><img src="https://latex.codecogs.com/png.latex?g_i(S)"> の候補のうち，次を満たす <img src="https://latex.codecogs.com/png.latex?g_i"> を選ぶことが目標である： <span id="eq-column"><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bk%5Cin%20S%7D%5Cfrac%7Bg_k%7D%7B%5Cpi_k%7Dx_%7Bi-k%7D=%5Csum_%7Bk=1%7D%5ENx_%7Bi-k%7D=N_%7Bi-%7D,%0A%5Ctag%7B2%7D"></span> <span id="eq-row"><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bk%5Cin%20S%7D%5Cfrac%7Bg_k%7D%7B%5Cpi_k%7Dx_%7B-jk%7D=%5Csum_%7Bk=1%7D%5ENx_%7B-jk%7D=N_%7B-j%7D.%0A%5Ctag%7B3%7D"></span></p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="[Iterative Proportional Fitting / Ranking algorithm @Deming-Stephan1940]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="citation" data-cites="Deming-Stephan1940">(Iterative Proportional Fitting / Ranking algorithm Deming and Stephan, 1940)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?g%5E%7B(0)%7D_k%5Cgets1"> と初期化する．</li>
<li><img src="https://latex.codecogs.com/png.latex?x_%7Bi-k%7D=1"> すなわち <img src="https://latex.codecogs.com/png.latex?k%5Cin%20U_%7Bi-%7D"> であるとき， <img src="https://latex.codecogs.com/png.latex?%0A%20%20g%5E%7B(t+1)%7D_k%5Cgets%20g_k%5E%7B(t)%7D%5Cfrac%7B%5Csum_%7Bk=1%7D%5ENx_%7Bi-k%7D%7D%7B%5Csum_%7Bk%5Cin%20S%7D%5Cfrac%7Bg%5E%7B(t)%7D_k%7D%7B%5Cpi_k%7Dx_%7Bi-k%7D%7D.%0A%20%20"> これにより条件 (2) が満たされる．</li>
<li><img src="https://latex.codecogs.com/png.latex?z_%7B-jk%7D=1"> すなわち <img src="https://latex.codecogs.com/png.latex?k%5Cin%20U_%7B-j%7D"> であるとき， <img src="https://latex.codecogs.com/png.latex?%0A%20%20g%5E%7B(t+2)%7D_k%5Cgets%20g_k%5E%7B(t+1)%7D%5Cfrac%7B%5Csum_%7Bk=1%7D%5ENx_%7B-jk%7D%7D%7B%5Csum_%7Bk%5Cin%20S%7D%5Cfrac%7Bg%5E%7B(t+1)%7D_k%7D%7B%5Cpi_k%7Dx_%7B-jk%7D%7D.%0A%20%20"> これにより条件 (3) が満たされる．</li>
<li>収束するまで繰り返す．</li>
</ol>
</div>
</div>
<p>これは特定の目的関数を最小化することに等しい．<span class="citation" data-cites="Deming-Stephan1940">(Deming and Stephan, 1940, p. 428)</span>, <span class="citation" data-cites="Zieschang1990">(Zieschang, 1990)</span>, <span class="citation" data-cites="Deville-Sarndal1993">(Jean-Claude Deville and Sautory, 1993)</span> も参照．</p>
</section>
</section>
<section id="荷重校正推定量" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="荷重校正推定量"><span class="header-section-number">3</span> 荷重校正推定量</h2>
<section id="はじめに-1" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="はじめに-1"><span class="header-section-number">3.1</span> はじめに</h3>
<p>回帰推定量は <img src="https://latex.codecogs.com/png.latex?X"> から <img src="https://latex.codecogs.com/png.latex?Y"> に関する情報を抽出することで，HT 推定量の効率を改善することができる方法である．</p>
<p>しかし，HT のもう一つの魅力的な性質であった <strong>計画一致性</strong> (design consistency) が失われている．</p>
<p>回帰推定量の性質である <strong>外部一致性</strong> (external consistency) を保ちながら，別の解を見つけることで，回帰推定量を一般化する形で計画一致性を持つ効率的な推定量を構成することを考える．</p>
<p>実はこの方法は，モデリングの観点からは <img src="https://latex.codecogs.com/png.latex?X,Y"> の間のモデルを，標本レベルから母集団レベルに一般化することに相当する．こうして考えられる超母集団モデルを <strong>一般化回帰モデル</strong> (GREG: Generalized Regression) という．</p>
<p>このような方法で HT 推定量を改善した計画一致性を持つ推定量を model-assisted estimator，特に特定の制約下最適化問題の解として与えられるものを <strong>校正推定量</strong> (calibrated estimator) という．</p>
<p>校正推定量は計画一致性を持つために，傾向スコアの推定に成功していれば不偏性が保証される．この性質は二重頑健推定量の構成の基礎となる．</p>
</section>
<section id="差分推定量" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="差分推定量"><span class="header-section-number">3.2</span> 差分推定量</h3>
<p>補助的な量 <img src="https://latex.codecogs.com/png.latex?y_i%5E%7B(0)%7D"> が母集団全体で観測されている場合， <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%7B%5Cmathrm%7Bdiff%7D%7D:=%5Csum_%7Bi=1%7D%5ENy_i%5E%7B(0)%7D+%5Csum_%7Bi%5Cin%20S%7D%5Cpi_i%5E%7B-1%7D%5Cleft(y_i-y_i%5E%7B(0)%7D%5Cright)%0A"> は <strong>差分推定量</strong> (difference estimator) と呼ばれる．</p>
<p>HT 推定量同様不偏であるが，分散の値は変化し，特に <img src="https://latex.codecogs.com/png.latex?y_i%5E%7B(0)%7D"> が <img src="https://latex.codecogs.com/png.latex?y_i"> の良い近似であるほど分散が小さくなる <span class="citation" data-cites="Kim2024">(Kim, 2024, p. 99)</span>．</p>
<p>この <img src="https://latex.codecogs.com/png.latex?y_i"> の proxy とも言える量 <img src="https://latex.codecogs.com/png.latex?y_i%5E%7B(0)%7D"> を，他の共変量 <img src="https://latex.codecogs.com/png.latex?x_i"> から回帰により構成することで，回帰推定量（第 2.3 節）よりも複雑な <img src="https://latex.codecogs.com/png.latex?x_i,y_i"> 関係もうまく取り込んだ分散低減が可能になる．</p>
<p>このように（暗黙裡にでも）モデルを用いており，加えて <u>モデルの特定が成功しているかに依らず HT 推定量を改善できる</u> 方法を <strong>model-assisted estimation</strong> といい，校正推定量の基本的な考え方である．</p>
</section>
<section id="sec-projection-estimator" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="sec-projection-estimator"><span class="header-section-number">3.3</span> 一般化回帰モデルと射影推定量</h3>
<p>まず母集団 <img src="https://latex.codecogs.com/png.latex?%5BN%5D"> に応用 <img src="https://latex.codecogs.com/png.latex?Y"> のモデルを当てはめる： <span id="eq-superpopulation-model"><img src="https://latex.codecogs.com/png.latex?%0Ay_i=x_i%5E%5Ctop%5Cbeta+%5Cepsilon_i,%5Cqquad%5Cepsilon_i%5Coverset%7B%5Ctext%7Biid%7D%7D%7B%5Csim%7D(0,c_i(x_i)%5Csigma%5E2).%0A%5Ctag%7B4%7D"></span> このように母集団に置かれるモデルを <strong>超母集団モデル</strong> (superpopulation model) <span class="citation" data-cites="Isaki-Fuller1982">(Isaki and Fuller, 1982)</span> という．</p>
<p>特に式 (4) の Gauss-Markov 型の超母集団モデルを <strong>一般化回帰モデル</strong> (GREG: Generalized Regression) ともいう．</p>
<p>これを解いて得る推定量 <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7By%7D_i=x_i%5E%5Ctop%5Cwidehat%7B%5Cbeta%7D_c"> の総和として得られる推定量 <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%7B%5Cmathrm%7BP%7D%7D:=%5Csum_%7Bi=1%7D%5EN%5Cwidehat%7By%7D_i%0A"> を（モデルベースの） <strong>射影推定量</strong> (projection estimator) という．</p>
<p>射影推定量は計画一致性を持つとは限らない．</p>
<p>仮に GREG モデルで <img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7Bc_i%7D%7B%5Cpi_i%7D%5Cparallel%20x_i%0A"> が成り立つならば，内部バイアス校正 (IBC: Internally Biased Calibration) <span class="citation" data-cites="Firth-Bennett1998">(Firth and Bennett, 1998)</span> 条件 <img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi%5Cin%20S%7D%5Cfrac%7B1%7D%7B%5Cpi_i%7D(y_i-%5Cwidehat%7By%7D_i)=0%0A"> が成り立つ．</p>
<p>この IBC が，射影推定量が抽出計画に依らずに一致性を持つための十分条件である <span class="citation" data-cites="Kim2024">(補題9.1 Kim, 2024, p. 100)</span>．</p>
</section>
<section id="一般化最小二乗法-gls" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="一般化最小二乗法-gls"><span class="header-section-number">3.4</span> 一般化最小二乗法 (GLS)</h3>
<p>当然 GREG モデルが IBC 条件を満たすとは限らない．</p>
<p>そのような場合でも計画一致性を持つような推定量を考えたい．実は， <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%7B%5Cmathrm%7BGREG%7D%7D:=%5Cwidehat%7BY%7D_%5Cmathrm%7BHT%7D+%5Cbiggr(X-%5Cwidehat%7BX%7D_%5Cmathrm%7BHT%7D%5Cbiggl)%5E%5Ctop%5Cwidehat%7B%5Cbeta%7D_c%0A"> は計画一致性を持つ．</p>
<p>これは <strong>一般化回帰推定量</strong> (GREG: Generalized Regression Estimator) または計量経済学において GLS (Generalized Least Squares) <span class="citation" data-cites="Aitken1936">(Aitken, 1936)</span> と呼ばれる．<sup>4</sup></p>
<p>一般化回帰推定量は次の最適化による特徴付けがある： <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%7B%5Cmathrm%7BGREG%7D%7D=%5Csum_%7Bi%5Cin%20S%7D%5Cwidehat%7B%5Comega%7D_iy_i,%5Cqquad%5Cwidehat%7B%5Comega%7D_i:=%5Cpi_i%5E%7B-1%7D+%5Cleft(X-%5Cwidehat%7BX%7D_%5Cmathrm%7BHT%7D%5Cright)%5E%5Ctop%5Cleft(%5Csum_%7Bi%5Cin%20S%7D%5Cfrac%7B1%7D%7Bc_i%7Dx_ix_i%5E%5Ctop%5Cright)%5E%7B-1%7D%5Cfrac%7Bx_i%7D%7Bc_i%7D.%0A"> この荷重 <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7B%5Comega%7D_i"> は，<strong>校正条件</strong> (calibration constraint) （式 (1) との違いに注意）を満たすものの中で <img src="https://latex.codecogs.com/png.latex?%0AQ(%5Comega):=%5Csum_%7Bi%5Cin%20S%7D(%5Comega_i-d_i)%5E2c_i,%5Cqquad%20d_i:=%5Cpi_i%5E%7B-1%7D,%5Cquad%5Coperatorname%7Bsubject%20to%7D%5Csum_%7Bi%5Cin%20S%7D%5Comega_ix_i=%5Csum_%7Bi=1%7D%5ENx_i.%0A"> を最小にするものとも特徴付けられる <span class="citation" data-cites="Kim2024">(Kim, 2024, p. 102)</span>．</p>
<p>特に，<img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7Bw%7D_i%5Cxrightarrow%5Bn%5Cto%5Cinfty%5D%7B%5Cmathrm%7Bp%7D%7Dd_i">．</p>
</section>
<section id="sec-calibration-estimator" class="level3" data-number="3.5">
<h3 data-number="3.5" class="anchored" data-anchor-id="sec-calibration-estimator"><span class="header-section-number">3.5</span> 校正推定量</h3>
<p>一般に，校正条件制約を満たす <img src="https://latex.codecogs.com/png.latex?(%5Comega_i)"> のうち，凸関数 <img src="https://latex.codecogs.com/png.latex?G"> が定める目的関数 <img src="https://latex.codecogs.com/png.latex?%0AQ(%5Comega):=%5Csum_%7Bi%5Cin%20S%7Dd_iG%5Cleft(%5Cfrac%7B%5Comega_i%7D%7Bd_i%7D%5Cright)c_i%0A"> を最小にするものを <strong>校正荷重</strong> (calibration weight)，校正荷重に関する線型推定量を <strong>校正推定量</strong> (calibration estimator) という <span class="citation" data-cites="Deville-Sarndal1992">(Deville and Särndal, 1992)</span>, <span class="citation" data-cites="Kim2024">(Kim, 2024, p. 103)</span>．</p>
<p>ほとんどの校正推定量は漸近的に GREG 推定量に一致する．</p>
<p>一般に，有限母集団に対する確率標本からの一様最小分散不偏推定量 (UMVUE) は存在しない <span class="citation" data-cites="Godambe-Joshi1965">(Godambe and Joshi, 1965)</span> が，GREG 推定量は「期待漸近分散」の下界を達成する <span class="citation" data-cites="Isaki-Fuller1982">(Isaki and Fuller, 1982)</span>．</p>
</section>
<section id="最適校正推定量" class="level3" data-number="3.6">
<h3 data-number="3.6" class="anchored" data-anchor-id="最適校正推定量"><span class="header-section-number">3.6</span> 最適校正推定量</h3>
<p>特に， <img src="https://latex.codecogs.com/png.latex?%0AQ(%5Comega)=%5Csum_%7Bi%5Cin%20S%7D%5Comega_i%5E2c_i%0A"> を最小化するものは <strong>最適校正推定量</strong> (optimal calibrated estimator) と呼ばれる <span class="citation" data-cites="Kim2024">(Kim, 2024, p. 110)</span>．</p>
<p>これはモデルの視点からは <img src="https://latex.codecogs.com/png.latex?x"> を拡張して人工的に IBC 条件を満たすようにした射影推定量（第 3.3 節）とも見れる．</p>
<p>最適校正推定量は超母集団モデル (4) が誤特定されている場合に GREG 推定量より良い性能を示す <span class="citation" data-cites="Kim2024">(Kim, 2024, p. 112)</span>．</p>
<p>GREG モデルより一般的な超母集団モデルに対しての同様の手続きは <strong>モデル校正</strong> (model calibration) <span class="citation" data-cites="Wu-Sitter2001">(Wu and Sitter, 2001)</span> と呼ばれている．この方法では <img src="https://latex.codecogs.com/png.latex?X,Y"> の関係を推定し，<img src="https://latex.codecogs.com/png.latex?Y"> の線型推定量を <img src="https://latex.codecogs.com/png.latex?m(X)"> の形で構成してから，最適構成推定量の議論に還元する．</p>
</section>
<section id="一般化エントロピー法" class="level3" data-number="3.7">
<h3 data-number="3.7" class="anchored" data-anchor-id="一般化エントロピー法"><span class="header-section-number">3.7</span> 一般化エントロピー法</h3>
<p>最適構成推定量の構成に倣い， <img src="https://latex.codecogs.com/png.latex?%0AQ(%5Comega):=%5Csum_%7Bi%5Cin%20S%7DG(%5Comega_i)c_i%5Cqquad%5Coperatorname%7Bsubject%20to%7D%5Csum_%7Bi%5Cin%20S%7D%5Comega_ig(d_i)c_i=%5Csum_%7Bi=1%7D%5ENg(d_i)c_i%0A"> の最小化により校正荷重を構成する方法を <strong>一般化エントロピー法</strong> (generalized entropy method) <span class="citation" data-cites="Kwon+2024">(Kwon et al., 2024)</span> という．</p>
<p>これは目的関数には計画荷重 <img src="https://latex.codecogs.com/png.latex?d_i=%5Cpi_i%5E%7B-1%7D"> が入っていないが，制約条件に入っていることで計画一致性を達成している．</p>
<p>超母集団モデルである GREG モデルが正しく特定されているならば <span class="citation" data-cites="Godambe-Joshi1965">(Godambe and Joshi, 1965)</span> の下界を達成するが，そうでなくとも一致性は保たれる上に，一般の校正推定量（第 3.5 節）よりも分散は小さいである <span class="citation" data-cites="Kwon+2024">(Kwon et al., 2024)</span>．<sup>5</sup></p>
</section>
</section>
<section id="欠測データの扱い" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="欠測データの扱い"><span class="header-section-number">4</span> 欠測データの扱い</h2>
<section id="はじめに-2" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="はじめに-2"><span class="header-section-number">4.1</span> はじめに</h3>
<p>観測単位が欠測している場合 (unit nonresponse)，call-back / follow-up 調査を行うか，それができない場合は次の２つの対処が可能である：</p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="単位欠測の扱い">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
単位欠測の扱い
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>欠測メカニズムを抑える共変量は見えている場合（MAR 条件），傾向スコア推定量が利用可能（第 4.2 節）．これは欠測メカニズムのモデリングに基づく．</li>
<li>一般の校正推定量に対しても，</li>
</ol>
</div>
</div>
<p>単位欠測の場合は，２段階の標本抽出と状況が似ているのである．さらには，非確率標本（調査観察データ，ビッグデータなど）の扱いとも似通う．これについては<a href="../../../posts/2024/Survey/Survey4.html">次稿も参照</a>．</p>
<p>一方で，項目が欠測している場合 (item nonresponse)，<strong>代入法</strong> (imputation) が用いられる．<sup>6</sup></p>
<p>現状は多重代入法（第 5.2 節）が主流であると言える <span class="citation" data-cites="vanBuuren2018">(Buuren, 2018)</span>．</p>
</section>
<section id="sec-propensity-score" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="sec-propensity-score"><span class="header-section-number">4.2</span> 傾向スコア推定量</h3>
<p>標本の観測 <img src="https://latex.codecogs.com/png.latex?Y_i"> は，<img src="https://latex.codecogs.com/png.latex?%5Cdelta_i=0"> のとき欠損しているとする．</p>
<section id="sec-MAR" class="level4" data-number="4.2.1">
<h4 data-number="4.2.1" class="anchored" data-anchor-id="sec-MAR"><span class="header-section-number">4.2.1</span> MAR 条件：欠測のメカニズムを抑える共変量が観測できている</h4>
<p>加えて，標本全体についてある変数 <img src="https://latex.codecogs.com/png.latex?X"> が観測できており，これについて次の条件が成り立つとする：</p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="[MAR condition @Rubin1976]^[最も古典的な形のものであり，母集団上の条件であることから，population MAR とも呼ばれる．母集団上の MAR と抽出計画の無視可能性 [@Sugden-Smith1984] との２条件が成り立つとき，標本の MAR が成り立つ [@Berg+2016]．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="citation" data-cites="Rubin1976">(MAR condition Rubin, 1976)</span><sup>7</sup>
</div>
</div>
<div class="callout-body-container callout-body">
<p>欠測の指示変数 <img src="https://latex.codecogs.com/png.latex?%5Cdelta"> について， <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BP%7D%5B%5Cdelta=1%7CX,Y%5D=%5Coperatorname%7BP%7D%5B%5Cdelta=1%7CX%5D=:p(X)%0A"> が成り立つ．</p>
</div>
</div>
<p>これは条件付き独立性 <img src="https://latex.codecogs.com/png.latex?%5Cdelta%5Cperp%5C!%5C!%5C!%5Cperp%20Y%5Cmid%20X"> よりも弱い条件で，MAR (Missing At Random) の条件と呼ばれる．<sup>8</sup></p>
</section>
<section id="欠測メカニズムの推定" class="level4" data-number="4.2.2">
<h4 data-number="4.2.2" class="anchored" data-anchor-id="欠測メカニズムの推定"><span class="header-section-number">4.2.2</span> 欠測メカニズムの推定</h4>
<p>欠測確率 <img src="https://latex.codecogs.com/png.latex?p(x):=%5Coperatorname%7BP%7D%5B%5Cdelta=1%7CX=x%5D"> にノンパラメトリックなモデル <img src="https://latex.codecogs.com/png.latex?p_%5Cphi(x)"> を課したとする．</p>
<p>このとき，パラメータ <img src="https://latex.codecogs.com/png.latex?%5Cphi"> は擬似最尤推定量 <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7B%5Cphi%7D"> により一致推定をすることができる．</p>
</section>
<section id="傾向スコア推定量" class="level4" data-number="4.2.3">
<h4 data-number="4.2.3" class="anchored" data-anchor-id="傾向スコア推定量"><span class="header-section-number">4.2.3</span> 傾向スコア推定量</h4>
<p>仮に母平均 <img src="https://latex.codecogs.com/png.latex?%0AY:=%5Csum_%7Bi=1%7D%5ENy_i%0A"> が推定対象であったとしよう．</p>
<p>このとき，推定された <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7B%5Cphi%7D"> を元に，次の推定量が構成できる：</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%5Cmathrm%7BPS%7D:=%5Csum_%7Bi%5Cin%5Cdelta%5E%7B-1%7D(1)%7D%5Cfrac%7B1%7D%7B%5Cpi_i%7D%5Cfrac%7By_i%7D%7Bp_%7B%5Cwidehat%7B%5Cphi%7D%7D(x_i)%7D.%0A"></p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題（傾向スコア推定量の一致性）^[[@Kim2024 p.154] 定理12.1も参照．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題（傾向スコア推定量の一致性）<sup>9</sup>
</div>
</div>
<div class="callout-body-container callout-body">
<p>欠測確率 <img src="https://latex.codecogs.com/png.latex?p"> のモデル <img src="https://latex.codecogs.com/png.latex?p_%5Cphi(x)"> の特定に成功しているとき，ある正則性に関する条件が満たされる限り，傾向スコア推定量 <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7BY%7D_%5Cmathrm%7BPS%7D"> は一致推定量に <img src="https://latex.codecogs.com/png.latex?n%5E%7B-1%7D"> のオーダーで漸近する．</p>
</div>
</div>
</section>
</section>
<section id="sec-calibration-estimator-for-missing-data" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="sec-calibration-estimator-for-missing-data"><span class="header-section-number">4.3</span> 校正推定量</h3>
<p>ある校正荷重 <img src="https://latex.codecogs.com/png.latex?(d_i)"> に関して，計画一致性を持つ推定量 <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D=%5Csum_%7Bi%5Cin%20S%7Dd_iy_i%0A"> を考えているが，単位欠測により特定の <img src="https://latex.codecogs.com/png.latex?y_i"> が得られず，計算できないものとする．</p>
<p>この場合でも，応答があった部分標本 <img src="https://latex.codecogs.com/png.latex?%0AS_R:=%5Cdelta%5E%7B-1%7D(1)%0A"> 上の校正推定量 <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%5Comega:=%5Csum_%7Bi%5Cin%20S_R%7D%5Comega_iy_i%0A"> であって，欠測メカニズム <img src="https://latex.codecogs.com/png.latex?p(x)"> の特定か，または超母集団モデル <img src="https://latex.codecogs.com/png.latex?%0Ay_i=x_i%5E%5Ctop%5Cbeta+%5Cepsilon_i,%5Cqquad%5Cepsilon_i%5Coverset%7B%5Ctext%7Biid%7D%7D%7B%5Csim%7D(0,c_i%5Csigma%5E2)%0A"> の特定に成功すれば一致性を持つ，二重頑健なものを構成できる <span class="citation" data-cites="Kim-Haziza2014">(Kim and Haziza, 2014)</span>．</p>
</section>
<section id="代入法とその不偏性条件" class="level3" data-number="4.4">
<h3 data-number="4.4" class="anchored" data-anchor-id="代入法とその不偏性条件"><span class="header-section-number">4.4</span> 代入法とその不偏性条件</h3>
<p>項目非反応がある場合，代入値を <img src="https://latex.codecogs.com/png.latex?y_i%5E*"> として <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%7B%5Cmathrm%7BI%7D%7D:=%5Csum_%7Bi%5Cin%20S%7D%5Cfrac%7B1%7D%7B%5Cpi_i%7D%5Cbiggr(%5Cdelta_iy_i+(1-%5Cdelta_i)y_i%5E*%5Cbiggl)%0A"> による推定が試みられる．</p>
<p>代入 <img src="https://latex.codecogs.com/png.latex?y_i%5E*"> を行うことでリストワイズの削除をするよりも推定の効率を上げることができる．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="[代入推定量の不偏性 @Kim2024 p.162]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="citation" data-cites="Kim2024">(代入推定量の不偏性 Kim, 2024, p. 162)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D%5BY%5E*%7C%5Cdelta=0%5D=%5Coperatorname%7BE%7D%5BY%7C%5Cdelta=1%5D%0A"> が成り立つならば，<img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7BY%7D_%5Cmathrm%7BI%7D"> は不偏推定量である．</p>
</div>
</div>
<p>この条件は，標本内で MAR 条件（第 4.2.1 節）が成り立つとき： <span id="eq-sample-MAR"><img src="https://latex.codecogs.com/png.latex?%0AY%7C(X,%5Cdelta=1)=Y%7C(X,%5Cdelta=0),%0A%5Ctag%7B5%7D"></span> <img src="https://latex.codecogs.com/png.latex?Y%5E*"> を <img src="https://latex.codecogs.com/png.latex?Y%7C(X,%5Cdelta)"> からのサンプリングで代入すれば達成される．</p>
<p>さらに強い条件 <img src="https://latex.codecogs.com/png.latex?%0A%5Cdelta%5Cperp%5C!%5C!%5C!%5Cperp%20Y%5Cmid%20X%0A"> が成り立つとき，標本内の MAR 条件が成り立つ．</p>
<p>換言すれば代入法において，欠測の原因 <img src="https://latex.codecogs.com/png.latex?X"> を突き止め，欠測したグループにおける <img src="https://latex.codecogs.com/png.latex?Y"> の値 <img src="https://latex.codecogs.com/png.latex?Y%7C(X,%5Cdelta=1)"> にモデル (outcome model) を立て，そこからサンプリングをすることを目指す．</p>
</section>
<section id="回帰による代入" class="level3" data-number="4.5">
<h3 data-number="4.5" class="anchored" data-anchor-id="回帰による代入"><span class="header-section-number">4.5</span> 回帰による代入</h3>
<p>仮に共変量 <img src="https://latex.codecogs.com/png.latex?X"> が <img src="https://latex.codecogs.com/png.latex?Y"> と強い相関を持つとする．このように線型回帰模型を背後に想定することが適切な場合は，よく次のような手続きで代入がされる．</p>
<p>まず共変量により母集団を <img src="https://latex.codecogs.com/png.latex?%5BN%5D=N_1+%5Ccdots+N_G"> 個に層別化し，それぞれの層で <span id="eq-semiparametric-model"><img src="https://latex.codecogs.com/png.latex?%0AY_i=X_i%5E%5Ctop%5Cbeta+%5Cepsilon_i,%5Cqquad%5Cepsilon_i%5Coverset%7B%5Ctext%7Biid%7D%7D%7B%5Csim%7D(0,%5Csigma%5E2)%0A%5Ctag%7B6%7D"></span> というセミパラメトリック回帰モデルを考える．</p>
<p>次に推定されたモデルを用いて，<img src="https://latex.codecogs.com/png.latex?%5Cepsilon_i%5E*%5Csim(0,%5Csigma%5E2)"> を残差 <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7B%5Cepsilon%7D_i:=y_i-x_i%5E%5Ctop%5Cwidehat%7B%5Cbeta%7D%0A"> の分布から（リ）サンプリングし， <img src="https://latex.codecogs.com/png.latex?%0Ay_i%5E*%5Cgets%20x_i%5E%5Ctop%5Cwidehat%7B%5Cbeta%7D+%5Cepsilon_i%5E*%0A"> を代入値とする．</p>
<p>以上の手続きは <strong>確率的回帰代入法</strong> (stochastic regression imputation) と呼ばれる．平均を代入する場合は単に回帰代入法または条件付き平均代入法 (conditional mean imputation) という．</p>
<p><img src="https://latex.codecogs.com/png.latex?Y"> と強い相関を持つ補助変数 <img src="https://latex.codecogs.com/png.latex?X"> がいつでも見つかるとは限らない．</p>
<p>その場合は Gauss-Markov モデル (6) を一般の統計モデルに一般化すれば良い．</p>
</section>
<section id="マッチングによる代入" class="level3" data-number="4.6">
<h3 data-number="4.6" class="anchored" data-anchor-id="マッチングによる代入"><span class="header-section-number">4.6</span> マッチングによる代入</h3>
<p>層の中の他のセルをランダムに選んでその値を代入する hot deck imputation や，セルの加重平均を代入する fractional hot deck も同様の考え方に基づく <span class="citation" data-cites="Fuller-Kim2005">(Fuller and Kim, 2005)</span>．</p>
<p>このような手法は <strong>マッチング</strong> と呼ばれ，カーネル法と関連が深い <span class="citation" data-cites="Cheng1994">(Cheng, 1994)</span>．加重平均は対象のセルとの関連度を「距離」によって測り，距離を計算するのに使われる変数は <strong>キー</strong> ともいう <span class="citation" data-cites="高井啓二+2016">(高井啓二 et al., 2016, p. 110)</span>．傾向スコアマッチングでは傾向スコアがキーである．</p>
<p>最も単純には同一データセット内の最も似ている単位を持ち出してその値を代入するのがマッチングであるが，最も洗練された方法としては類似度に依存して関連度を自動的に重みづけて，データセット全体で加重平均をとっても良いわけである．</p>
<p>他の標本の値を参考にする場合は cold deck imputation という．</p>
<p>などの Least squares method も同様の考え方に基づく <span class="citation" data-cites="Little1992">(Little, 1992)</span>．</p>
</section>
<section id="sec-superpopulation-model-imputation" class="level3" data-number="4.7">
<h3 data-number="4.7" class="anchored" data-anchor-id="sec-superpopulation-model-imputation"><span class="header-section-number">4.7</span> 母集団モデルによる代入法</h3>
<p>一方で，母集団上での <img src="https://latex.codecogs.com/png.latex?Y,X"> の関係についてモデルを立てて <img src="https://latex.codecogs.com/png.latex?Y%7CX"> からサンプリングをすることも考えられる．</p>
<div class="callout callout-style-default callout-important no-icon callout-titled" title="注（無情報サンプリング条件）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
注（無情報サンプリング条件）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>母集団の分布と標本の分布が一致するとき，<strong>無情報サンプリング</strong> (noninformative sampling) が実施されたという．そうでない場合は <strong>informative sampling</strong> という．</p>
<p>サンプリングが無情報であるための十分条件には <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BP%7D%5BI=1%7CX,Y%5D=%5Coperatorname%7BP%7D%5BI=1%7CX%5D%0A"> が挙げられる．<span class="citation" data-cites="Sugden-Smith1984">(Sugden and Smith, 1984)</span> はこれを無情報サンプリング条件という．</p>
<p>この下では母集団のモデルと標本のモデルとは一致するが，一般にはこの２つは厳密に峻別しなければ混乱の源である．</p>
</div>
</div>
</div>
<p>標本内の MAR 条件 (5) だけでなく，母集団上で MAR 条件が成り立つ場合は，<img src="https://latex.codecogs.com/png.latex?Y%7CX"> の尤度を <img src="https://latex.codecogs.com/png.latex?f_%5Ctheta(y%7Cx)"> としてモデリングをし，これを <img src="https://latex.codecogs.com/png.latex?%0A%5Cell(%5Ctheta):=%5Csum_%7Bi%5Cin%20S%7Dw_i%5Cdelta_i%5Clog%20f_%5Ctheta(y_i%7Cx_i)%0A"> の最大化によって <img src="https://latex.codecogs.com/png.latex?M">-推定することが考えられる．<sup>10</sup></p>
<p>ただし，<img src="https://latex.codecogs.com/png.latex?w_i"> は <img src="https://latex.codecogs.com/png.latex?Y"> の計画一致性を持つ校正推定量を定める校正荷重であるとする．<img src="https://latex.codecogs.com/png.latex?w_i"> の存在は標本と母集団のズレに起因する．</p>
<p>最終的に学習されたモデル <img src="https://latex.codecogs.com/png.latex?f_%5Ctheta(y%7Cx_i)"> からのサンプリングによって代入値 <img src="https://latex.codecogs.com/png.latex?y_i%5E*"> を生成する．</p>
<p>このモデル <img src="https://latex.codecogs.com/png.latex?f_%5Ctheta(y%7Cx_i)"> を当てはまりの度合いを見ながらベイズ推論によって得る方法もよく取られるようになっている <span class="citation" data-cites="Enders+2020">(C. K. Enders et al., 2020)</span>．</p>
<p>母集団上の MAR 条件が成り立たない場合は <img src="https://latex.codecogs.com/png.latex?Y%7C(X,%5Cdelta=0)"> のモデリングを考える必要がある．</p>
</section>
</section>
<section id="多重代入法" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="多重代入法"><span class="header-section-number">5</span> 多重代入法</h2>
<section id="はじめに-3" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="はじめに-3"><span class="header-section-number">5.1</span> はじめに</h3>
<p>ベイズの観点からは，欠測データとパラメータとは違いがない <span class="citation" data-cites="BDA">(Chapter 18 Gelman et al., 2014, p. 449)</span>．</p>
<p>ベイズ事後分布は欠測データとパラメータの上に同時に定まり，欠測データに関して積分をすることで最終的な推論が実行される．</p>
<p>これを模倣する形で提案されたのが <strong>多重代入法</strong> (MI: Multiple Imputation) <span class="citation" data-cites="Rubin1978MI">(Rubin, 1978)</span>, <span class="citation" data-cites="Rubin1987MI">(Rubin, 1987)</span> である．</p>
<p>多重代入法ではベイズ事後分布から補完値を複数生成し，複数の擬似完全データに関して同じ解析を実行し，最後に結果を平均する．</p>
<p>擬似完全データに対する解析が一貫したベイズ推論であった場合，この一連の手続きによって（近似的な）ベイズ推論が実行されることになる．</p>
<p>しかしデータの補完とその後の擬似完全データ解析は <strong>融和性</strong> (congeniality) を保つ限り別の方法を用いても良いように拡張された <span class="citation" data-cites="Meng1994">(Meng, 1994)</span>．</p>
<p>このことにより多重代入法は広く使われるようになっている．</p>
</section>
<section id="sec-MI" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="sec-MI"><span class="header-section-number">5.2</span> 多重代入法</h3>
<p>多重代入法では，モデルベースの代入法（第 4.7 節）をさらに推し進める．</p>
<p>本来の推定量 <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D=%5Csum_%7Bi%5Cin%20S%7Dw_iy_i%0A"> を代入推定量 <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%5Cmathrm%7BI%7D=%5Csum_%7Bi%5Cin%20S%7Dw_i%5Cbiggr(%5Cdelta_iy_i+(1-%5Cdelta_i)y_i%5E*%5Cbiggl),%5Cqquad%20y_i%5E*%5Csim%20f_%5Ctheta(y_i%7Cx_i)%0A"> で模倣する際，ベイズ事後予測分布で <img src="https://latex.codecogs.com/png.latex?%0Ay_i%5E*%5Csim%20f(y_i%7Cy_%7B%5Ctext%7Bobs%7D%7D)%0A"> によって補間することが理想的である．</p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="[Multiple Imputation @Rubin1978MI]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="citation" data-cites="Rubin1978MI">(Multiple Imputation Rubin, 1978)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>事後予測分布から補間値を <img src="https://latex.codecogs.com/png.latex?M"> 個生成する： <img src="https://latex.codecogs.com/png.latex?%0A%20%20y_i%5E%7B(j)%7D%5Csim%20f(y_i%7Cy_%7B%5Ctext%7Bobs%7D%7D),%5Cqquad%20j%5Cin%5BM%5D.%0A%20%20"></li>
<li>それぞれの補間値について推定量 <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7BY%7D%5E%7B(j)%7D"> を計算し，その平均を最終的な推定値とする： <img src="https://latex.codecogs.com/png.latex?%5Cnewcommand%7B%5CMI%7D%7B%5Cmathrm%7BMI%7D%7D%0A%20%20%5Cwidehat%7BY%7D_%5CMI:=%5Cfrac%7B1%7D%7BM%7D%5Csum_%7Bj=1%7D%5EM%5Cwidehat%7BY%7D%5E%7B(j)%7D.%0A%20%20"></li>
</ol>
</div>
</div>
<p><span class="citation" data-cites="Royston-White2011">(Royston and White, 2011)</span> は <img src="https://latex.codecogs.com/png.latex?M%5Capprox10%5E3"> を推奨している．</p>
</section>
<section id="連鎖方程式による多重代入" class="level3" data-number="5.3">
<h3 data-number="5.3" class="anchored" data-anchor-id="連鎖方程式による多重代入"><span class="header-section-number">5.3</span> 連鎖方程式による多重代入</h3>
<p>多重代入法において事後予測分布から補間値を生成することは，<img src="https://latex.codecogs.com/png.latex?Y"> に関してモデルを立てる必要があるためネックになりがちである．</p>
<p><strong>相互条件付き識別性</strong> (FCS: Fully Conditional Specification) <span class="citation" data-cites="vanBuuren+2006">(Stef Van Buuren and Rubin, 2006)</span> が成り立つモデルについては，モデルの具体的な形に依らない Gibbs サンプラーによるサンプリングが可能になる．</p>
<p>これを <strong>連鎖方程式による多重代入</strong> (MICE: Multiple Imputation by Chained Equations) <span class="citation" data-cites="vanBuuren-Groothuis-Oudshoorn2011">(Buuren and Groothuis-Oudshoorn, 2011)</span> といい，R 言語 <code>mice</code> パッケージで実装されている．</p>
<blockquote class="blockquote">
<p>その実用性も相まってか，近年の Lancet 誌，New England Journal of Medicine 誌のレビューでは，欠測データの取り扱いに最も多く用いられている手法は MICE であるという報告もある<span class="citation" data-cites="Rezvan+2015">(Hayati Rezvan et al., 2015)</span>．<br> <span class="citation" data-cites="野間久史2017">(久史, 2017, p. 75)</span></p>
</blockquote>
</section>
<section id="その他の代入法" class="level3" data-number="5.4">
<h3 data-number="5.4" class="anchored" data-anchor-id="その他の代入法"><span class="header-section-number">5.4</span> その他の代入法</h3>
<p>ランダムな欠損ではなく，計画された大規模な欠損がある場合は，two-phase sampling の考え方を応用することができる <span class="citation" data-cites="Kim2024">(Kim, 2024, p. 173)</span>．</p>
<p>なお，全ての代入法はモデル <img src="https://latex.codecogs.com/png.latex?Y%7C(X,%5Cdelta)"> の特定を間違えると，<img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7BY%7D"> の不偏性が失われることに注意 <span class="citation" data-cites="Rezvan+2015">(Hayati Rezvan et al., 2015)</span>．</p>
</section>
<section id="代入をしない" class="level3" data-number="5.5">
<h3 data-number="5.5" class="anchored" data-anchor-id="代入をしない"><span class="header-section-number">5.5</span> 代入をしない</h3>
<p>代入をせず，欠測しているなら欠測したままで最尤推定を実行することも考えられる．</p>
<p>このアプローチは <strong>完全情報最尤推定</strong> (FIML: Full Information Maximum Likelihood)，より最近では　pairwise likelihood estimation とも呼ばれる．<sup>11</sup></p>
<p>欠測が <img src="https://latex.codecogs.com/png.latex?Y"> に依存しない場合，この「最尤推定量」は MAR の下で一致性と漸近正規性を持つ．<sup>12</sup></p>
<p>ただし，推定されたモデルから，欠測値を代入してから結果を出してももちろん良い．ベイズの観点からは，モデルの平均を取ってから予測することに当たる．<sup>13</sup></p>
<p><span class="citation" data-cites="vanBuuren2018">(1.6節 Buuren, 2018)</span> も参照．</p>
</section>
<section id="欠測値をどう扱うべきか" class="level3" data-number="5.6">
<h3 data-number="5.6" class="anchored" data-anchor-id="欠測値をどう扱うべきか"><span class="header-section-number">5.6</span> 欠測値をどう扱うべきか？</h3>
<p>いつでも多重代入法を使えば良いというものではない．</p>
<p>例えば <img src="https://latex.codecogs.com/png.latex?(X,Y)"> の関数関係が知りたい回帰分析の状況下で被説明変数 <img src="https://latex.codecogs.com/png.latex?Y"> の欠損は，これを無視してリストワイズ消去をした complete-case analysis が代入法と等価になる．</p>
<p>他にも complete-case analysis や代入をしない方がむしろ適切な場合は多い <span class="citation" data-cites="vanBuuren2018">(2.7節 Buuren, 2018)</span>．</p>
</section>
</section>



<div id="quarto-appendix" class="default"><section id="終わりに" class="level2 appendix" data-number="6"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">6</span> 終わりに</h2><div class="quarto-appendix-contents">



</div></section><section id="多重代入法について" class="level3 appendix" data-number="6.1"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">6.1</span> 多重代入法について</h2><div class="quarto-appendix-contents">

<p>パッケージに実装される都合上，多重代入法はパラメトリックな手法であるという言説があるが，必ずしもそうである必要はない．この場合，傾向スコア推定量や校正推定量がセミパラメトリックな手法と呼ばれる．</p>
<p>また多重代入法が代入に使われたのちに，後続の解析は全く違うモデルが使われることもあり，このような場合は <strong>融和性</strong> (congeniality) <span class="citation" data-cites="Meng1994">(Meng, 1994)</span> の議論が必要になる．</p>
<p>特に公的統計においては，後続のタスクが One Number Principle に従うようにするために欠測のあるデータは代入してしまい，擬似完全データを作成することもあり得る <span class="citation" data-cites="Kim2024">(Section 13.1 Kim, 2024, p. 161)</span>．</p>
<p>この観点から見れば，多重代入法とは擬似完全データを複数作ることで後続推定精度営みというようにも思える．</p>
<p>いずれの場合も，多重代入法の「代入法」としての側面が強調されるあまり理論的背景が捨象され，また多重代入法の実際の使われ方が使用可能なパッケージでの実装方式に強く依存され，元来の手法の数理的本体が見失われている状況と言うことができるだろう．</p>
<blockquote class="blockquote">
<p>Bayesian inference draws no distinction between missing data and parameters; both are uncertain, and they have a joint posterior distribution, conditional on observed data. <span class="citation" data-cites="BDA">(Chapter 18 Gelman et al., 2014, p. 449)</span></p>
</blockquote>
</div></section><section id="mar-について" class="level3 appendix" data-number="6.2"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">6.2</span> MAR について</h2><div class="quarto-appendix-contents">

<p>MAR は現行で最も緩い条件である．</p>
<p>そして，MAR が成立しているかは確認したがく，感度分析などが推奨される <span class="citation" data-cites="逸見昌之2014">(逸見昌之, 2014)</span>．</p>
<p>欠測するかどうか <img src="https://latex.codecogs.com/png.latex?%5Cdelta"> が，欠測する所の値 <img src="https://latex.codecogs.com/png.latex?Y"> に依存している場合，これを MNAR という．この場合のセミパラメトリック最適な推定法は <span class="citation" data-cites="Morikawa-Kim2021">(Morikawa and Kim, 2021)</span> などが提案されている．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Aitken1936" class="csl-entry">
Aitken, A. C. (1936). <a href="https://doi.org/10.1017/S0370164600014346">IV.—on least squares and linear combination of observations</a>. <em>Proceedings of the Royal Society of Edinburgh</em>, <em>55</em>, 42–48.
</div>
<div id="ref-Berg+2016" class="csl-entry">
Berg, E., Kim, J.-K., and Skinner, C. (2016). <a href="https://doi.org/10.1093/jssam/smw032"><span>Imputation Under Informative Sampling</span></a>. <em>Journal of Survey Statistics and Methodology</em>, <em>4</em>(4), 436–462.
</div>
<div id="ref-vanBuuren2018" class="csl-entry">
Buuren, S. van. (2018). <em><a href="https://stefvanbuuren.name/fimd/"><span class="nocase">Flexible Imputation of Missing Data</span></a></em>. Boca Raton, FL.: CRC Press.
</div>
<div id="ref-vanBuuren-Groothuis-Oudshoorn2011" class="csl-entry">
Buuren, S. van, and Groothuis-Oudshoorn, K. (2011). <a href="https://doi.org/10.18637/jss.v045.i03">Mice: Multivariate imputation by chained equations in r</a>. <em>Journal of Statistical Software</em>, <em>45</em>(3), 1–67.
</div>
<div id="ref-Cheng1994" class="csl-entry">
Cheng, P. E. (1994). <a href="http://www.jstor.org/stable/2291203">Nonparametric estimation of mean functionals with data missing at random</a>. <em>Journal of the American Statistical Association</em>, <em>89</em>(425), 81–87.
</div>
<div id="ref-Deming-Stephan1940" class="csl-entry">
Deming, W. E., and Stephan, F. F. (1940). <a href="http://www.jstor.org/stable/2235722">On a least squares adjustment of a sampled frequency table when the expected marginal totals are known</a>. <em>The Annals of Mathematical Statistics</em>, <em>11</em>(4), 427–444.
</div>
<div id="ref-Deng-Wu1987" class="csl-entry">
Deng, L.-Y., and Wu, C. F. J. (1987). <a href="http://www.jstor.org/stable/2289466">Estimation of variance of the regression estimator</a>. <em>Journal of the American Statistical Association</em>, <em>82</em>(398), 568–576.
</div>
<div id="ref-Deville-Sarndal1992" class="csl-entry">
Deville, J.-C., and Särndal, C.-E. (1992). <a href="https://doi.org/10.1080/01621459.1992.10475217">Calibration estimators in survey sampling</a>. <em>Journal of the American Statistical Association</em>, <em>87</em>(418), 376–382.
</div>
<div id="ref-Enders+2001" class="csl-entry">
Enders, Craig K., and Bandalos, D. L. (2001). <a href="https://doi.org/10.1207/S15328007SEM0803\_5">The relative performance of full information maximum likelihood estimation for missing data in structural equation models</a>. <em>Structural Equation Modeling: A Multidisciplinary Journal</em>, <em>8</em>(3), 430–457.
</div>
<div id="ref-Enders+2020" class="csl-entry">
Enders, C. K., Du, H., and Keller, B. T. (2020). <a href="https://psycnet.apa.org/doi/10.1037/met0000228"><span class="nocase">A Model-based Imputation Procedure for Multilevel Regression Models with Random Coefficients, Interaction Effects, and Nonlinear Terms</span></a>. <em>Psychological Methods</em>, <em>25</em>(1), 88–112.
</div>
<div id="ref-Firth-Bennett1998" class="csl-entry">
Firth, D., and Bennett, K. E. (1998). <a href="https://doi.org/10.1111/1467-9868.00105">Robust models in probability sampling</a>. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <em>60</em>(1), 3–21.
</div>
<div id="ref-Fuller-Kim2005" class="csl-entry">
Fuller, W. A., and Kim, J.-K. (2005). <a href="https://www150.statcan.gc.ca/n1/pub/12-001-x/2005002/article/9041-eng.pdf">Hot deck imputation for the response model</a>. <em>Survey Methodology</em>, <em>31</em>(2), 139–149.
</div>
<div id="ref-Gelman2014" class="csl-entry">
Gelman, A. (2014). <a href="https://doi.org/10.1214/13-STS458"><span class="nocase">How Bayesian Analysis Cracked the Red-State, Blue-State Problem</span></a>. <em>Statistical Science</em>, <em>29</em>(1), 26–35.
</div>
<div id="ref-BDA" class="csl-entry">
Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., and Rubin, D. B. (2014). <em><a href="http://www.stat.columbia.edu/~gelman/book/">Bayesian data analysis</a></em>. Boca Raton : CRC Press.
</div>
<div id="ref-Gelman-Little1997" class="csl-entry">
Gelman, A., and Little, T. (1997). <a href="https://www150.statcan.gc.ca/n1/en/catalogue/12-001-X19970023616">Poststratification into many categories using hierarchical logistic regression</a>. <em>Survey Methodology</em>, (1997002).
</div>
<div id="ref-Godambe-Joshi1965" class="csl-entry">
Godambe, V. P., and Joshi, V. M. (1965). <a href="http://www.jstor.org/stable/2239112">Admissibility and bayes estimation in sampling finite populations. i</a>. <em>The Annals of Mathematical Statistics</em>, <em>36</em>(6), 1707–1722.
</div>
<div id="ref-Hayashi2000" class="csl-entry">
Hayashi, F. (2000). <em><a href="https://press.princeton.edu/books/ebook/9781400823833/econometrics-1">Econometrics</a></em>. Princeton University Press.
</div>
<div id="ref-Rezvan+2015" class="csl-entry">
Hayati Rezvan, P., Lee, K. J., and Simpson, J. A. (2015). <a href="https://doi.org/10.1186/s12874-015-0022-1">The rise of multiple imputation: A review of the reporting and implementation of the method in medical research</a>. <em>BMC Medical Research Methodology</em>, <em>15</em>(1), 30.
</div>
<div id="ref-Hernan-Robins2020" class="csl-entry">
Hernán, M. A., and Robins, J. M. (2020). <em><a href=""><span>Causal Inference: What If</span></a></em>. Boca Raton: Chapman &amp; Hall/CRC.
</div>
<div id="ref-Horvitz-Thompson1952" class="csl-entry">
Horvitz, D. G., and Thompson, D. J. (1952). <a href="https://doi.org/10.1080/01621459.1952.10483446">A generalization of sampling without replacement from a finite universe</a>. <em>Journal of the American Statistical Association</em>, <em>47</em>(260), 663–685.
</div>
<div id="ref-Imai-Ratkovic2014" class="csl-entry">
Imai, K., and Ratkovic, M. (2014). <a href="http://www.jstor.org/stable/24772753">Covariate balancing propensity score</a>. <em>Journal of the Royal Statistical Society. Series B (Statistical Methodology)</em>, <em>76</em>(1), 243–263.
</div>
<div id="ref-Isaki-Fuller1982" class="csl-entry">
Isaki, C. T., and Fuller, W. A. (1982). <a href="https://doi.org/10.1080/01621459.1982.10477770">Survey design under the regression superpopulation model</a>. <em>Journal of the American Statistical Association</em>, <em>77</em>(377), 89–96.
</div>
<div id="ref-Deville-Sarndal1993" class="csl-entry">
Jean-Claude Deville, C.-E. S., and Sautory, O. (1993). <a href="https://doi.org/10.1080/01621459.1993.10476369">Generalized raking procedures in survey sampling</a>. <em>Journal of the American Statistical Association</em>, <em>88</em>(423), 1013–1020.
</div>
<div id="ref-Kim2024" class="csl-entry">
Kim, J. K. (2024). <a href="https://arxiv.org/abs/2401.07625">Statistics in survey sampling</a>.
</div>
<div id="ref-Kim-Haziza2014" class="csl-entry">
Kim, J. K., and Haziza, D. (2014). <a href="http://www.jstor.org/stable/26432548">DOUBLY ROBUST INFERENCE WITH MISSING DATA IN SURVEY SAMPLING</a>. <em>Statistica Sinica</em>, <em>24</em>(1), 375–394.
</div>
<div id="ref-Kwon+2024" class="csl-entry">
Kwon, Y., Kim, J. K., and Qiu, Y. (2024). <a href="https://arxiv.org/abs/2404.01076">Debiased calibration estimation using generalized entropy in survey sampling</a>.
</div>
<div id="ref-Little1992" class="csl-entry">
Little, R. J. A. (1992). <a href="https://doi.org/10.1080/01621459.1992.10476282">Regression with missing x’s: A review</a>. <em>Journal of the American Statistical Association</em>, <em>87</em>(420), 1227–1237.
</div>
<div id="ref-Meng1994" class="csl-entry">
Meng, X.-L. (1994). <a href="https://doi.org/10.1214/ss/1177010269"><span class="nocase">Multiple-Imputation Inferences with Uncongenial Sources of Input</span></a>. <em>Statistical Science</em>, <em>9</em>(4), 538–558.
</div>
<div id="ref-Morikawa-Kim2021" class="csl-entry">
Morikawa, K., and Kim, J. K. (2021). <a href="https://doi.org/10.1214/21-AOS2070"><span class="nocase">Semiparametric optimal estimation with nonignorable nonresponse data</span></a>. <em>The Annals of Statistics</em>, <em>49</em>(5), 2991–3014.
</div>
<div id="ref-Royston-White2011" class="csl-entry">
Royston, P., and White, I. R. (2011). <a href="https://doi.org/10.18637/jss.v045.i04">Multiple imputation by chained equations (MICE): Implementation in stata</a>. <em>Journal of Statistical Software</em>, <em>45</em>(4), 1–20.
</div>
<div id="ref-Rubin1976" class="csl-entry">
Rubin, D. B. (1976). <a href="http://www.jstor.org/stable/2335739">Inference and missing data</a>. <em>Biometrika</em>, <em>63</em>(3), 581–592.
</div>
<div id="ref-Rubin1978MI" class="csl-entry">
Rubin, D. B. (1978). <a href="http://www.asasrms.org/Proceedings/y1978f.html">Multiple imputations in sample surveys - a phenomenological bayesian approach to nonresponse</a>. <em>Proceedings of the Survey Research Methods Section, ASA</em>, 20–28.
</div>
<div id="ref-Rubin1987MI" class="csl-entry">
Rubin, D. B. (1987). <em><a href="https://doi.org/10.1002/9780470316696"><span class="nocase">Multiple Imputation for Nonresponse in Surveys</span></a></em>. John Wiley &amp; Sons.
</div>
<div id="ref-Sarndal+1992" class="csl-entry">
Särndal, C.-E., Swensson, B., and Wretman, J. (1992). <em><a href="https://link.springer.com/book/9780387406206">Model assisted survey sampling</a></em>. Springer New York.
</div>
<div id="ref-Sen1953" class="csl-entry">
Sen, A. R. (1953). <a href="">On the estimate of the variance in sampling with varying probabilities</a>. <em>Journal of the Indian Society of Agricultural Statistics</em>, <em>5</em>, 119–127.
</div>
<div id="ref-Shimodaira2000" class="csl-entry">
Shimodaira, H. (2000). <a href="https://doi.org/10.1016/S0378-3758(00)00115-4">Improving predictive inference under covariate shift by weighting the log-likelihood function</a>. <em>Journal of Statistical Planning and Inference</em>, <em>90</em>(2), 227–244.
</div>
<div id="ref-vanBuuren+2006" class="csl-entry">
Stef Van Buuren, C. G. M. G.-O., J. P. L. Brand, and Rubin, D. B. (2006). <a href="https://doi.org/10.1080/10629360600810434">Fully conditional specification in multivariate imputation</a>. <em>Journal of Statistical Computation and Simulation</em>, <em>76</em>(12), 1049–1064.
</div>
<div id="ref-Sugden-Smith1984" class="csl-entry">
Sugden, R. A., and Smith, T. M. F. (1984). <a href="https://doi.org/10.1093/biomet/71.3.495"><span class="nocase">Ignorable and informative designs in survey sampling inference</span></a>. <em>Biometrika</em>, <em>71</em>(3), 495–506.
</div>
<div id="ref-Wu-Sitter2001" class="csl-entry">
Wu, C., and Sitter, R. R. (2001). <a href="https://doi.org/10.1198/016214501750333054">A model-calibration approach to using complete auxiliary information from survey data</a>. <em>Journal of the American Statistical Association</em>, <em>96</em>(453), 185–193.
</div>
<div id="ref-Yates-Grundy1953" class="csl-entry">
Yates, F., and Grundy, P. M. (1953). <a href="https://doi.org/10.1111/j.2517-6161.1953.tb00140.x">Selection without replacement from within strata with probability proportional to size</a>. <em>Journal of the Royal Statistical Society: Series B (Methodological)</em>, <em>15</em>(2), 253–261.
</div>
<div id="ref-Zieschang1990" class="csl-entry">
Zieschang, K. D. (1990). <a href="http://www.jstor.org/stable/2289595">Sample weighting methods and estimation of totals in the consumer expenditure survey</a>. <em>Journal of the American Statistical Association</em>, <em>85</em>(412), 986–1001.
</div>
<div id="ref-野間久史2017" class="csl-entry">
久史. (2017). <a href="https://doi.org/10.5023/jappstat.46.67">連鎖方程式による多重代入法</a>. <em>応用統計学</em>, <em>46</em>(2), 67–86.
</div>
<div id="ref-狩野裕2019" class="csl-entry">
狩野裕. (2019). <a href="https://doi.org/10.11329/jjssj.48.199">欠測データ解析のmissとmyth</a>. <em>日本統計学会誌</em>, <em>48</em>(2), 199–214.
</div>
<div id="ref-逸見昌之2014" class="csl-entry">
逸見昌之. (2014). <a href="https://www.ism.ac.jp/editsec/toukei/pdf/62-1-103.pdf">欠測データに対するセミパラメトリックな解析法――その理論的背景について――</a>. <em>統計数理</em>, <em>62</em>(1), 103–122.
</div>
<div id="ref-高井啓二+2016" class="csl-entry">
高井啓二, 星野崇宏, and 野間久史. (2016). <em><a href="https://www.iwanami.co.jp/book/b260306.html">欠測データの統計科学：医学と社会科学への応用</a></em>,Vol. 1. 岩波書店.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Inverse probability weighting estimator ともいう <span class="citation" data-cites="Hernan-Robins2020">(Hernán and Robins, 2020, p. 22)</span>．↩︎</p></li>
<li id="fn2"><p>結果的に，<a href="https://en.wikipedia.org/wiki/Weighted_least_squares">Weighted Least Squares</a> と同じ形になっている．WLS は誤差分散が既知の形 <img src="https://latex.codecogs.com/png.latex?W%5E%7B-1%7D:=%5Cmathrm%7Bdiag%7D(%5Csigma_1%5E2,%5Ccdots,%5Csigma_n%5E2)"> をしている場合の最良線型不偏推定量 (BLUE) である．一般に最小二乗法は広い設定で BLUE を与え続け，一般の既知の分散 <img src="https://latex.codecogs.com/png.latex?V(X)"> を持つ場合は <strong>GLS</strong> (Generalized Least Squares) と呼ばれる．<img src="https://latex.codecogs.com/png.latex?V(X)"> が既知である場合などなく，一般にはこれの推定から始める必要があり，これは Feasible GLS と呼ばれる <span class="citation" data-cites="Hayashi2000">(Hayashi, 2000, p. 59)</span>．↩︎</p></li>
<li id="fn3"><p>この抽出計画に依らない性質を以て，<span class="citation" data-cites="Sarndal+1992">(Särndal et al., 1992)</span> は model-assisted 推定量と呼んでいる．model-dependent 推定量とは対照的である．↩︎</p></li>
<li id="fn4"><p>この２つの類似性は <span class="citation" data-cites="Zieschang1990">(Zieschang, 1990)</span> が指摘している．一般の回帰分析の設定下では <a href="https://en.wikipedia.org/wiki/Generalized_least_squares">“GLS is more efficient than OLS under heteroscedasticity (also spelled heteroskedasticity) or autocorrelation”</a> などと説明される．↩︎</p></li>
<li id="fn5"><p>ただし，余分な項があるために，正しく特定されている下では校正推定量よりもやや分散が大きい．↩︎</p></li>
<li id="fn6"><p>総務省統計局では，Imputation の訳語として「補定」を用いる．↩︎</p></li>
<li id="fn7"><p>最も古典的な形のものであり，母集団上の条件であることから，population MAR とも呼ばれる．母集団上の MAR と抽出計画の無視可能性 <span class="citation" data-cites="Sugden-Smith1984">(Sugden and Smith, 1984)</span> との２条件が成り立つとき，標本の MAR が成り立つ <span class="citation" data-cites="Berg+2016">(Berg et al., 2016)</span>．↩︎</p></li>
<li id="fn8"><p><img src="https://latex.codecogs.com/png.latex?Y%5Cto%20X%5Cto%5Cdelta"> が Markov 連鎖をなす，とも換言できる．↩︎</p></li>
<li id="fn9"><p><span class="citation" data-cites="Kim2024">(Kim, 2024, p. 154)</span> 定理12.1も参照．↩︎</p></li>
<li id="fn10"><p>一方で，重み付き推定方程式の解として定まる <img src="https://latex.codecogs.com/png.latex?Z">-推定量として構成することもできる．<span class="citation" data-cites="高井啓二+2016">(5.2節 高井啓二 et al., 2016, p. 163)</span>．↩︎</p></li>
<li id="fn11"><p>完全情報最尤推定の言葉は初期の構造方程式モデリングプログラム AMOS に組み込まれて有名になっていた <span class="citation" data-cites="Enders+2001">(Craig K. Enders and Bandalos, 2001)</span>．直接尤度 (direct likelihood) または観測尤度 (observed likelihood) の方法ともいう <span class="citation" data-cites="狩野裕2019">(狩野裕, 2019)</span>．<strong>完全尤度</strong> (full likelihood) の用語は <span class="citation" data-cites="高井啓二+2016">(高井啓二 et al., 2016)</span> など．↩︎</p></li>
<li id="fn12"><p><span class="citation" data-cites="狩野裕2019">(狩野裕, 2019)</span> に素晴らしい解説がある．日本語の文献としては <span class="citation" data-cites="高井啓二+2016">(高井啓二 et al., 2016)</span> もあり，第５章で推定方程式の観点から解説されている．↩︎</p></li>
<li id="fn13"><p>そういえば Bayes 的な integral out に関して doubly robust という考え方はないのか？doubly robust の Bayesian counterpart はなんだろう？↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Bayesian</category>
  <category>Statistics</category>
  <guid>https://162348.github.io/posts/2024/Survey/Survey3.html</guid>
  <pubDate>Tue, 24 Sep 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Survey/Files/Horvitz-Thompson.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>ベイズデータ解析４</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Survey/Survey4.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="関連記事" class="level2 unnumbered unlisted">
<h2 class="unnumbered unlisted anchored" data-anchor-id="関連記事">関連記事</h2>
<div id="listing-lst-survey" class="listing quarto-float quarto-figure quarto-figure-left quarto-listing quarto-listing-container-grid anchored">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="QmF5ZXNpYW4lMkNTdGF0aXN0aWNz" data-listing-date-sort="1727049600000" data-listing-file-modified-sort="1733137938540" data-listing-date-modified-sort="1727827200000" data-listing-reading-time-sort="3" data-listing-word-count-sort="516">
<a href="../../../posts/2024/Survey/Survey1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Survey/Files/BayesANOVA.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズデータ解析１
</h5>
<div class="card-subtitle listing-subtitle">
分散分析
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-23
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="U3RhdGlzdGljcw==" data-listing-date-sort="1727049600000" data-listing-file-modified-sort="1733137938540" data-listing-date-modified-sort="1727568000000" data-listing-reading-time-sort="3" data-listing-word-count-sort="466">
<a href="../../../posts/2024/Survey/Survey2.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Survey/Files/ATE.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズデータ解析２
</h5>
<div class="card-subtitle listing-subtitle">
平均処置効果の推定とセミパラメトリック法
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-23
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="QmF5ZXNpYW4lMkNTdGF0aXN0aWNz" data-listing-date-sort="1727136000000" data-listing-file-modified-sort="1733137938540" data-listing-date-modified-sort="1727568000000" data-listing-reading-time-sort="6" data-listing-word-count-sort="1038">
<a href="../../../posts/2024/Survey/Survey3.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Survey/Files/Horvitz-Thompson.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズデータ解析３
</h5>
<div class="card-subtitle listing-subtitle">
標本調査データと欠測データの扱い
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-24
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>
<section id="非確率標本とは何か" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="非確率標本とは何か"><span class="header-section-number">1</span> 非確率標本とは何か？</h2>
<blockquote class="blockquote">
<p>Generally speaking, these designs have not been explored in detail by survey researchers even though they are frequently used in other applied research ﬁelds. <span class="citation" data-cites="Baker+2013">(Baker et al., 2013, p. 91)</span></p>
</blockquote>
<p>母集団 <img src="https://latex.codecogs.com/png.latex?%5BN%5D"> から部分集合 <img src="https://latex.codecogs.com/png.latex?S%5Csubset%5BN%5D"> が標本として抽出されたとする．</p>
<p>この抽出計画 (sampling design / mechanism) が未知である場合，これを <strong>非確率標本</strong> (nonprobability sample) という．</p>
<section id="非確率標本" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="非確率標本"><span class="header-section-number">1.1</span> 非確率標本</h3>
<p><a href="https://www.e-stat.go.jp/classifications/terms/90/00/4937"><strong>確率抽出</strong></a> (probability sampling) とは <img src="https://latex.codecogs.com/png.latex?%5BN%5D"> の部分集合の全体 <img src="https://latex.codecogs.com/png.latex?P(%5BN%5D)"> 上の既知の確率分布に従っているとみなせる標本で，さらに何人も標本に選ばれる確率が零でないもの <img src="https://latex.codecogs.com/png.latex?%0A%5Cpi_i:=%5Coperatorname%7BP%7D%5Bi%5Cin%20S%5D%3E0%0A"> をいう．詳しくは，<a href="../../../posts/2024/Survey/Survey3.html#sec-probability-sample">前稿</a> も参照．</p>
<p>すなわち非確率標本とは，<img src="https://latex.codecogs.com/png.latex?S%5Cin%5Cmathcal%7BL%7D(%5COmega;P(%5BN%5D))"> の従う分布が未知であったり，抽出計画上絶対に標本に入り得ない単位が存在する場合をいう．</p>
</section>
<section id="例" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="例"><span class="header-section-number">1.2</span> 例</h3>
<p>母集団 <img src="https://latex.codecogs.com/png.latex?%5BN%5D"> を国民全体だとした場合，確率抽出は国勢調査規模の営為によってのみしか達成し得ない．</p>
<p>多くの科学分野で実施されるような，特定の学校の学生や特定の地域の構成員を対象としたサンプル　<a href="https://en.wikipedia.org/wiki/Convenience_sampling"><strong>便宜的標本</strong></a> (convenience sample) は全て非確率標本に分類されることになる．</p>
<p>また多くのウェブアンケート代行業者は，事前にアンケートに協力することを約束したユーザーのプールからランダムに抽出して実行する．このような，自主的な応募によって得られたパネルを opt-in panel / panel of volunteers といい，ここからのサンプルもまた便宜的（二段階抽出）標本である．</p>
<p>以上の理由から，多くの「ビッグデータ」と呼ばれるデータは非確率標本である <span class="citation" data-cites="Meng2018">(Meng, 2018)</span>, <span class="citation" data-cites="Kim-Tam2021">(Jae-Kwang Kim and Tam, 2021)</span>．</p>
<p>そのほかの非確率的標本の例については，<span class="citation" data-cites="AAOR2013">(Section 3 AAOR, 2013)</span> を参照．</p>
</section>
<section id="自己選択バイアスの問題" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="自己選択バイアスの問題"><span class="header-section-number">1.3</span> 自己選択バイアスの問題</h3>
<p>このような非確率標本では，特定のクラスの単位を包摂できていない問題 (frame undercoverage) や，自ら進んで応募して標本に入ることで生じる交絡とバイアス (self-selection bias) が問題になる．<sup>1</sup></p>
<p>端的に言えば，<strong>ランダムな欠測</strong> (MAR: Missing At Random) <span class="citation" data-cites="Rubin1976">(Rubin, 1976)</span> の仮定が成り立たず，多くの欠測データ手法はそのままでは適用できないことが問題になる．</p>
</section>
<section id="データ統合" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="データ統合"><span class="header-section-number">1.4</span> データ統合</h3>
<p>非確率標本単体では出来ることが限られているかもしれないが，補助情報と組み合わせてモデルを立てることで統計的推論を試みることができる．</p>
<div class="table-responsive-sm">
<table class="table-hover table-bordered caption-top table">
<caption>典型的なデータの例</caption>
<colgroup>
<col style="width: 10%">
<col style="width: 40%">
<col style="width: 30%">
<col style="width: 10%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Data</th>
<th style="text-align: center;">Design</th>
<th style="text-align: center;">Representative?</th>
<th style="text-align: center;">X</th>
<th style="text-align: center;">Y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">A</td>
<td style="text-align: center;">Probability</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">X</td>
<td style="text-align: center;"><span class="color-unite">missing</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">B</td>
<td style="text-align: center;">Nonprobability</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">X</td>
<td style="text-align: center;">Y</td>
</tr>
</tbody>
</table>
</div>
<p>確率標本 A をビッグデータ B と紐づけられるという状況はかなら理想的であるが，仮にこのような dual frame estimation <span class="citation" data-cites="Hartley1962">(Hartley, 1962)</span>, <span class="citation" data-cites="Skinner-Rao1996">(Skinner and Rao, 1996)</span> の一部として非確率標本を扱えるときは，B を A の補助情報とみることで従来の校正荷重による推定の理論が利用可能になる．<a href="../../../posts/2024/Survey/Survey3.html">校正推定量については前稿も参照</a>．</p>
<p>例えば A を実験データ，B を観察データとしたデータ統合の試みは計量経済学においても進んでいる <span class="citation" data-cites="Athey+2019">(Athey et al., 2019)</span>, <span class="citation" data-cites="Athey+2020">(Athey et al., 2020)</span>, <span class="citation" data-cites="Park-Sasaki2024">(Park and Sasaki, 2024)</span>．B をオルタナティブデータと呼ぶ向きもある．</p>
<p>実はこれから見るように，非確率標本の過小包摂性 (under coverage) は，単純ランダム抽出ではない抽出計画による確率標本のバイアス補正の議論に帰着し，自己選択バイアス (self-selection bias) の補正は欠測データの議論に帰着する <span class="citation" data-cites="Kim-Tam2021">(Jae-Kwang Kim and Tam, 2021)</span>．</p>
</section>
<section id="データ統合の方法" class="level3" data-number="1.5">
<h3 data-number="1.5" class="anchored" data-anchor-id="データ統合の方法"><span class="header-section-number">1.5</span> データ統合の方法</h3>
<p>大きく分けて次の３通りが考えられる <span class="citation" data-cites="Salvatore2024">(Salvatore et al., 2024)</span>：</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<ol type="1">
<li><u>荷重校正による方法</u> <span class="citation" data-cites="Elliot2009">(Elliot, 2009)</span>, <span class="citation" data-cites="Robbins+2020">(Robbins et al., 2020)</span></li>
</ol>
<p>非確率標本はあくまで確率標本の補助情報とし，荷重校正を実施する．</p>
<ol start="2" type="1">
<li><u>擬似ランダム化による方法</u> <span class="citation" data-cites="Elliott-Valliant2017">(Elliott and Valliant, 2017)</span></li>
</ol>
<p>自然によるランダム化が行われたとし，これを推定するステップを追加することで確率標本の議論に帰着させる．</p>
<ol start="3" type="1">
<li><u>大量代入 (mass imputation) による方法</u> <span class="citation" data-cites="Kim+2021">(Jae Kwang Kim et al., 2021)</span></li>
</ol>
</div>
</div>
</div>
</section>
<section id="バイアス低減" class="level3" data-number="1.6">
<h3 data-number="1.6" class="anchored" data-anchor-id="バイアス低減"><span class="header-section-number">1.6</span> バイアス低減</h3>
<p>各単位 <img src="https://latex.codecogs.com/png.latex?i%5Cin%5BN%5D"> が標本に包含される確率 <img src="https://latex.codecogs.com/png.latex?%0A%5Cpi_i:=%5Coperatorname%7BP%7D%5Bi%5Cin%20S%5D,%5Cqquad%20i%5Cin%20%5BN%5D,%0A"> が未知である場合でも，母集団 <img src="https://latex.codecogs.com/png.latex?%5BN%5D"> 上で <img src="https://latex.codecogs.com/png.latex?%0A%5Cpi_i%5E%7B-1%7D%5C,%5Cpropto%5C,x_i%5E%5Ctop%5Clambda,%5Cqquad%20i%5Cin%5BN%5D,%0A"> を満たす補助変数 <img src="https://latex.codecogs.com/png.latex?x_i%5C;(i%5Cin%5BN%5D)"> が利用可能ならば，推定のバイアスを低減することが可能である．</p>
</section>
<section id="傾向スコア" class="level3" data-number="1.7">
<h3 data-number="1.7" class="anchored" data-anchor-id="傾向スコア"><span class="header-section-number">1.7</span> 傾向スコア</h3>
<p>したがって <img src="https://latex.codecogs.com/png.latex?%5Cpi_i"> を推定することが問題になる．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cdelta_i:=1_S(i)"> が <img src="https://latex.codecogs.com/png.latex?%5Cdelta_i=1"> を満たすときのみ <img src="https://latex.codecogs.com/png.latex?y_i"> が観測されるとすると，</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cpi(x):=%5Coperatorname%7BP%7D%5B%5Cdelta=1%7CX=x%5D%0A"> を <strong>包含確率</strong> または <strong>傾向スコア</strong> (propensity score) <span class="citation" data-cites="Rosenbaum-Rubin1983">(Rosenbaum and Rubin, 1983)</span> という．<sup>2</sup></p>
<p>「未知のランダム化メカニズム <img src="https://latex.codecogs.com/png.latex?%5Cpi">」を想定し，これを推定することで確率標本の議論に帰着させるというアプローチは quasi-randomization approach とも呼ばれる <span class="citation" data-cites="Elliott-Valliant2017">(Elliott and Valliant, 2017)</span>, <span class="citation" data-cites="Beresovsky+2024">(Beresovsky et al., 2024)</span>．</p>
</section>
</section>
<section id="校正推定量" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="校正推定量"><span class="header-section-number">2</span> 校正推定量</h2>
<section id="確率標本に対する校正推定量" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="確率標本に対する校正推定量"><span class="header-section-number">2.1</span> 確率標本に対する校正推定量</h3>
<p>GREG モデルと呼ばれる超母集団模型 <span id="eq-super-population-model"><img src="https://latex.codecogs.com/png.latex?%0Ay_i=x_i%5E%5Ctop%5Cbeta+e_i,%5Cqquad%20e_i%5Coverset%7B%5Ctext%7Biid%7D%7D%7B%5Csim%7D(0,c_i(x_i)%5Csigma%5E2),%0A%5Ctag%7B1%7D"></span> を仮定する．校正条件 <span id="eq-calibration-condition"><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi%5Cin%20S%7D%5Comega_ix_i=%5Csum_%7Bi=1%7D%5ENx_i%0A%5Ctag%7B2%7D"></span> を満たす荷重 <img src="https://latex.codecogs.com/png.latex?(%5Comega_i)"> を用いた線型推定量 <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%7B%5Cmathrm%7Bcal%7D%7D:=%5Csum_%7Bi%5Cin%20S%7D%5Comega_iy_i%0A"> を <strong>校正推定量</strong> (calibration estimator) といい，抽出計画が <strong>無視可能</strong> (ignorable) である限り <img src="https://latex.codecogs.com/png.latex?Y"> の不偏推定量になる．</p>
<p>ここまでは <a href="../../../posts/2024/Survey/Survey3.html">前稿</a> で見た通りである．</p>
</section>
<section id="非確率標本に対する校正推定量" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="非確率標本に対する校正推定量"><span class="header-section-number">2.2</span> 非確率標本に対する校正推定量</h3>
<p>こうなると <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bi=1%7D%5ENx_i"> が判明・推定すれば良いので，校正推定量に関しては <a href="../../../posts/2024/Survey/Survey3.html#sec-calibration-estimator-for-missing-data">欠測データに対する対処</a> と同様に，傾向スコアの推定を通じて非確率標本に対応することができる．</p>
<p>これには超母集団模型 (1) に加えて，傾向スコア <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BP%7D%5B%5Cdelta=1%7CX=x%5D=:%5Cpi(x)%0A"> に対してもモデル <img src="https://latex.codecogs.com/png.latex?(%5Cpi_%5Cphi)"> をおく必要がある．</p>
<p>このとき，<img src="https://latex.codecogs.com/png.latex?G%5Cin%20C%5E2(%5Cmathbb%7BR%7D)"> を強凸関数，<img src="https://latex.codecogs.com/png.latex?g:=G'"> として <img src="https://latex.codecogs.com/png.latex?%0AQ(%5Comega):=%5Csum_%7Bi%5Cin%20S%7DG(%5Comega_i)c_i(x_i)%0A"> を，校正条件 (2) と完全情報の下で最尤推定された <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7B%5Cphi%7D"> を用いて推定した傾向スコア <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7B%5Cpi%7D_i:=%5Cpi(%5Cwidehat%7B%5Cphi%7D(x_i))"> に関して <span id="eq-debiasing-constraint"><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi%5Cin%20S%7D%5Comega_ig(%5Cwidehat%7B%5Cpi%7D_i%5E%7B-1%7D)c_i=%5Csum_%7Bi=1%7D%5ENg(%5Cwidehat%7B%5Cpi%7D_i%5E%7B-1%7D)c_i(x_i)%0A%5Ctag%7B3%7D"></span> を満たす中で最小化する荷重 <img src="https://latex.codecogs.com/png.latex?(%5Comega_i)"> を用いた校正推定量は，二重頑健性を持つ．</p>
<p>制約 (3) は選択バイアスを抑える役割を持ち，脱偏倚制約 (de-biasing constraint) とも呼ばれる <span class="citation" data-cites="Kim2024">(Jae Kwang Kim, 2024, p. 198)</span>．</p>
</section>
</section>



<div id="quarto-appendix" class="default"><section id="文献案内" class="level2 appendix" data-number="3"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3</span> 文献案内</h2><div class="quarto-appendix-contents">

<p><span class="citation" data-cites="Kim2024">(Jae Kwang Kim, 2024)</span> を最も参考にした．他によく読んだものは <span class="citation" data-cites="AAOR2013">(AAOR, 2013)</span>, <span class="citation" data-cites="Elliott-Valliant2017">(Elliott and Valliant, 2017)</span>．</p>
<p>セミパラメトリック推定に関する日本語文献は <span class="citation" data-cites="逸見昌之2014">(逸見昌之, 2014)</span>．</p>
<p>非確率標本の確率標本と組み合わせた利用については，計量経済学の文献を除いても <span class="citation" data-cites="Lohr-Raghunathan2017">(Lohr and Raghunathan, 2017)</span>, <span class="citation" data-cites="Meng2018">(Meng, 2018)</span>, <span class="citation" data-cites="Hand2018">(Hand, 2018)</span>, <span class="citation" data-cites="Robbins+2020">(Robbins et al., 2020)</span>, <span class="citation" data-cites="Rao2021">(Rao, 2021)</span>, <span class="citation" data-cites="Beaumont-Rao2021">(Beaumont and Rao, 2021)</span>, <span class="citation" data-cites="Angelopoulos2023">(Angelopoulos et al., 2023)</span>, <span class="citation" data-cites="Golini-Righi2024">(Golini and Righi, 2024)</span>, <span class="citation" data-cites="Salvatore2024">(Salvatore et al., 2024)</span> などがあり，大変盛り上がってきている印象がある．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-AAOR2013" class="csl-entry">
AAOR. (2013). <em>Report of the AAPOR task force on non-probability sampling</em>. American Association for Public Opinion Research.
</div>
<div id="ref-Angelopoulos2023" class="csl-entry">
Angelopoulos, A. N., Bates, S., Fannjiang, C., Jordan, M. I., and Zrnic, T. (2023). <a href="https://doi.org/10.1126/science.adi6000">Prediction-powered inference</a>. <em>Science</em>, <em>382</em>(6671), 669–674.
</div>
<div id="ref-Athey+2020" class="csl-entry">
Athey, S., Chetty, R., and Imbens, G. (2020). <a href="https://arxiv.org/abs/2006.09676">Combining experimental and observational data to estimate treatment effects on long term outcomes</a>.
</div>
<div id="ref-Athey+2019" class="csl-entry">
Athey, S., Chetty, R., Imbens, G. W., and Kang, H. (2019). <em><a href="https://doi.org/10.3386/w26463">The surrogate index: Combining short-term proxies to estimate long-term treatment effects more rapidly and precisely</a></em>. National Bureau of Economic Research.
</div>
<div id="ref-Baker+2013" class="csl-entry">
Baker, R., Brick, J. M., Bates, N. A., Battaglia, M., Couper, M. P., Dever, J. A., … Tourangeau, R. (2013). <a href="https://doi.org/10.1093/jssam/smt008"><span class="nocase">Summary Report of the AAPOR Task Force on Non-probability Sampling</span></a>. <em>Journal of Survey Statistics and Methodology</em>, <em>1</em>(2), 90–143.
</div>
<div id="ref-Beaumont-Rao2021" class="csl-entry">
Beaumont, J.-F., and Rao, J. N. K. (2021). <a href="https://isi-iass.org/home/wp-content/uploads/Survey_Statistician_2021_January_N83_02.pdf"><span class="nocase">Pitfalls of Making Inference from Non-probability Samples: Can Data Integration through Probability Samples Provide Remedies?</span></a> <em>The Survey Statistician</em>, <em>83</em>, 11–22.
</div>
<div id="ref-Beresovsky+2024" class="csl-entry">
Beresovsky, V., Gershunskaya, J., and Savitsky, T. D. (2024). <a href="https://arxiv.org/abs/2312.05383">Review of quasi-randomization approaches for estimation from non-probability samples</a>.
</div>
<div id="ref-Elliot2009" class="csl-entry">
Elliot, M. R. (2009). <a href="https://doi.org/10.29115/SP-2009-0025">Combining <span>Data</span> from <span>Probability</span> and <span>Non</span>- <span>Probability</span> <span>Samples</span> <span>Using</span> <span>Pseudo</span>-<span>Weights</span></a>. <em>Survey Practice</em>, <em>2</em>(6).
</div>
<div id="ref-Elliott-Valliant2017" class="csl-entry">
Elliott, M. R., and Valliant, R. (2017). <a href="http://www.jstor.org/stable/26408228">Inference for nonprobability samples</a>. <em>Statistical Science</em>, <em>32</em>(2), 249–264.
</div>
<div id="ref-Golini-Righi2024" class="csl-entry">
Golini, N., and Righi, P. (2024). <a href="https://doi.org/10.1007/s10260-023-00740-y">Integrating probability and big non-probability samples data to produce official statistics</a>. <em>Statistical Methods &amp; Applications</em>, <em>33</em>(2), 555–580.
</div>
<div id="ref-Hand2018" class="csl-entry">
Hand, D. J. (2018). <a href="https://doi.org/10.1111/rssa.12315"><span class="nocase">Statistical Challenges of Administrative and Transaction Data</span></a>. <em>Journal of the Royal Statistical Society Series A: Statistics in Society</em>, <em>181</em>(3), 555–605.
</div>
<div id="ref-Hartley1962" class="csl-entry">
Hartley, H. O. (1962). <a href="">Multiple frame surveys</a>. In <em>Proceedings of social statistics section</em>, pages 203–206.
</div>
<div id="ref-Kim2024" class="csl-entry">
Kim, Jae Kwang. (2024). <a href="https://arxiv.org/abs/2401.07625">Statistics in survey sampling</a>.
</div>
<div id="ref-Kim+2021" class="csl-entry">
Kim, Jae Kwang, Park, S., Chen, Y., and Wu, C. (2021). <a href="https://doi.org/10.1111/rssa.12696"><span class="nocase">Combining Non-Probability and Probability Survey Samples Through Mass Imputation</span></a>. <em>Journal of the Royal Statistical Society Series A: Statistics in Society</em>, <em>184</em>(3), 941–963.
</div>
<div id="ref-Kim-Tam2021" class="csl-entry">
Kim, Jae-Kwang, and Tam, S.-M. (2021). <a href="https://doi.org/10.1111/insr.12434">Data integration by combining big data and survey sample data for finite population inference</a>. <em>International Statistical Review</em>, <em>89</em>(2), 382–401.
</div>
<div id="ref-Lohr-Raghunathan2017" class="csl-entry">
Lohr, S. L., and Raghunathan, T. E. (2017). <a href="https://doi.org/10.1214/16-STS584"><span class="nocase">Combining Survey Data with Other Data Sources</span></a>. <em>Statistical Science</em>, <em>32</em>(2), 293–312.
</div>
<div id="ref-Meng2018" class="csl-entry">
Meng, X.-L. (2018). <a href="https://doi.org/10.1214/18-AOAS1161SF"><span class="nocase">Statistical paradises and paradoxes in big data (I): Law of large populations, big data paradox, and the 2016 US presidential election</span></a>. <em>The Annals of Applied Statistics</em>, <em>12</em>(2), 685–726.
</div>
<div id="ref-Park-Sasaki2024" class="csl-entry">
Park, Y., and Sasaki, Y. (2024). <a href="https://arxiv.org/abs/2403.16177">The informativeness of combined experimental and observational data under dynamic selection</a>.
</div>
<div id="ref-Rao2021" class="csl-entry">
Rao, J. N. K. (2021). <a href="https://doi.org/10.1007/s13571-020-00227-w">On making valid inferences by integrating data from surveys and other sources</a>. <em>Sankhya B</em>, <em>83</em>(1), 242–272.
</div>
<div id="ref-Robbins+2020" class="csl-entry">
Robbins, M. W., Ghosh-Dastidar, B., and Ramchand, R. (2020). <a href="https://doi.org/10.1093/jssam/smaa037"><span class="nocase">Blending Probability and Nonprobability Samples with Applications to a Survey of Military Caregivers</span></a>. <em>Journal of Survey Statistics and Methodology</em>, <em>9</em>(5), 1114–1145.
</div>
<div id="ref-Rosenbaum-Rubin1983" class="csl-entry">
Rosenbaum, P. R., and Rubin, D. B. (1983). <a href="https://doi.org/10.1093/biomet/70.1.41"><span class="nocase">The Central Role of the Propensity Score in Observational Studies for Causal Effects</span></a>. <em>Biometrika</em>, <em>70</em>(1), 41–55.
</div>
<div id="ref-Rubin1976" class="csl-entry">
Rubin, D. B. (1976). <a href="http://www.jstor.org/stable/2335739">Inference and missing data</a>. <em>Biometrika</em>, <em>63</em>(3), 581–592.
</div>
<div id="ref-Salvatore2024" class="csl-entry">
Salvatore, C., Biffignandi, S., Sakshaug, J. W., Wiśniowski, A., and Struminskaya, B. (2024). <a href="https://doi.org/10.1093/jssam/smad041"><span class="nocase">Bayesian Integration of Probability and Nonprobability Samples for Logistic Regression</span></a>. <em>Journal of Survey Statistics and Methodology</em>, <em>12</em>(2), 458–492.
</div>
<div id="ref-Skinner-Rao1996" class="csl-entry">
Skinner, C. J., and Rao, J. N. K. (1996). <a href="https://doi.org/10.1080/01621459.1996.10476695">Estimation in dual frame surveys with complex designs</a>. <em>Journal of the American Statistical Association</em>, <em>91</em>(433), 349–356.
</div>
<div id="ref-逸見昌之2014" class="csl-entry">
逸見昌之. (2014). <a href="https://www.ism.ac.jp/editsec/toukei/pdf/62-1-103.pdf">欠測データに対するセミパラメトリックな解析法――その理論的背景について――</a>. <em>統計数理</em>, <em>62</em>(1), 103–122.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>すごく大雑把には，収入が高い人ほど収入に関するアンケートに参加しやすい，ウェブに関心のある人ほどウェブアンケートを受けやすい，など．↩︎</p></li>
<li id="fn2"><p>包含確率の用語は標本調査論による．傾向スコアは欠測データ解析による．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Bayesian</category>
  <category>Statistics</category>
  <guid>https://162348.github.io/posts/2024/Survey/Survey4.html</guid>
  <pubDate>Tue, 24 Sep 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Survey/Files/DataIntegration.png" medium="image" type="image/png" height="37" width="144"/>
</item>
<item>
  <title>ベイズデータ解析１</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Survey/Survey1.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="関連記事" class="level2 unnumbered unlisted">
<h2 class="unnumbered unlisted anchored" data-anchor-id="関連記事">関連記事</h2>
<div id="listing-lst-survey" class="listing quarto-float quarto-figure quarto-figure-left quarto-listing quarto-listing-container-grid anchored">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="QmF5ZXNpYW4lMkNNQ01DJTJDUiUyQ1N0YW4lMkNTdGF0aXN0aWNz" data-listing-date-sort="1715472000000" data-listing-file-modified-sort="1733137935992" data-listing-date-modified-sort="1726099200000" data-listing-reading-time-sort="8" data-listing-word-count-sort="1505">
<a href="../../../posts/2024/Computation/brms.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Computation/brms_files/figure-html/unnamed-chunk-4-1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
R によるベイズ混合モデリング入門
</h5>
<div class="card-subtitle listing-subtitle">
brms を用いた混合効果モデリング入門
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-05-12
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="U3RhdGlzdGljcw==" data-listing-date-sort="1727049600000" data-listing-file-modified-sort="1733137938540" data-listing-date-modified-sort="1727568000000" data-listing-reading-time-sort="3" data-listing-word-count-sort="466">
<a href="../../../posts/2024/Survey/Survey2.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Survey/Files/ATE.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズデータ解析２
</h5>
<div class="card-subtitle listing-subtitle">
平均処置効果の推定とセミパラメトリック法
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-23
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="QmF5ZXNpYW4lMkNTdGF0aXN0aWNz" data-listing-date-sort="1727136000000" data-listing-file-modified-sort="1733137938540" data-listing-date-modified-sort="1727568000000" data-listing-reading-time-sort="6" data-listing-word-count-sort="1038">
<a href="../../../posts/2024/Survey/Survey3.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Survey/Files/Horvitz-Thompson.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズデータ解析３
</h5>
<div class="card-subtitle listing-subtitle">
標本調査データと欠測データの扱い
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-24
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>
<section id="分散分析" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="分散分析"><span class="header-section-number">1</span> 分散分析</h2>
<section id="はじめに" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="はじめに"><span class="header-section-number">1.1</span> はじめに</h3>
<p>分散分析 (ANOVA: Analysis of Variance) は標本がある因子 <img src="https://latex.codecogs.com/png.latex?A,B,%5Ccdots"> によって層別されている場合に，層間の平均効果 <img src="https://latex.codecogs.com/png.latex?%5Cmu_i"> に差があるかどうかを検定する手法である： <img src="https://latex.codecogs.com/png.latex?%0AH_0:%5Cmu_1=%5Ccdots=%5Cmu_p%5Cquad%5Ctext%7Bv.s.%7D%5Cquad%20H_1:%5Cexists_%7Bi,j%5Cin%5Bp%5D%7D%5C;%5Cmu_i%5Cne%5Cmu_j.%0A"></p>
<p>因子 <img src="https://latex.codecogs.com/png.latex?A,B,%5Ccdots"> の個数に関して，<img src="https://latex.codecogs.com/png.latex?A"> のみの場合を一元配置分散分析，<img src="https://latex.codecogs.com/png.latex?A,B"> の場合を二元配置分散分析などという．</p>
<p>観測のモデルには <strong>線型 Gauss</strong> の仮定が置かれる．例えば一元配置である場合， <span id="eq-ANOVA"><img src="https://latex.codecogs.com/png.latex?%0AY_%7Bij%7D=%5Cmu_i+%5Cepsilon_%7Bij%7D,%5Cqquad%20i%5Cin%5Bp%5D,j%5Cin%5Bn_i%5D,%5Cepsilon_%7Bij%7D%5Csim%5Cmathrm%7BN%7D(0,%5Csigma%5E2),%0A%5Ctag%7B1%7D"></span> というモデルが仮定されていることに注意．これは変量効果モデルとも呼ばれる形である．</p>
<p>二元配置では <img src="https://latex.codecogs.com/png.latex?%0AY_%7Bij%7D=%5Cmu+%5Calpha_i+%5Cbeta_j+%5Cepsilon_%7Bij%7D%0A"> となり，集団は２つの軸 <img src="https://latex.codecogs.com/png.latex?A,B"> で層別されており（分割表の状態），それぞれの因子からの効果 <img src="https://latex.codecogs.com/png.latex?%5Calpha_i,%5Cbeta_j"> が説明変数に加法的に加えられる．</p>
</section>
<section id="分散分析の抽象的な説明" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="分散分析の抽象的な説明"><span class="header-section-number">1.2</span> 分散分析の抽象的な説明</h3>
<p>分散分析では観測 <img src="https://latex.codecogs.com/png.latex?Y_%7Bij%7D"> の変動のうち，<img src="https://latex.codecogs.com/png.latex?H_0"> の仮定の下で説明されなかった部分（残差） <img src="https://latex.codecogs.com/png.latex?R_1%5E2"> と，そもそも線型 Gauss 模型 (1) では説明しきれない部分 <img src="https://latex.codecogs.com/png.latex?R_0%5E2"> とに関して， <img src="https://latex.codecogs.com/png.latex?%0AF:=%5Cfrac%7B(R%5E2_1-R%5E2_0)/q%7D%7BR%5E2_0/(n-r)%7D%0A"> を考える．ただし，<img src="https://latex.codecogs.com/png.latex?r:=%5Coperatorname%7Brank%7D(X)"> はデータの自由度とした．</p>
<p>この <img src="https://latex.codecogs.com/png.latex?F"> は，各群への所属表すダミー変数を用いた回帰分析の残差 <img src="https://latex.codecogs.com/png.latex?R_0"> と，各群への所属を考慮しない回帰分析による残差 <img src="https://latex.codecogs.com/png.latex?R_1"> とを，自由度を考慮して比を取った形をしている．</p>
<p>この <img src="https://latex.codecogs.com/png.latex?F"> は一般に非心 F-分布に従い，仮定 <img src="https://latex.codecogs.com/png.latex?H_0"> が成り立つときのみ中心 F-分布 <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BF%7D(q,n-r)"> に従う．</p>
<p>これは各群への所属情報に何の情報量もない場合には，<img src="https://latex.codecogs.com/png.latex?F"> が<u>同じ平均を持つ</u>正規確率変数の自乗和の比になるためである．</p>
<p>この <img src="https://latex.codecogs.com/png.latex?F"> を検定統計量として仮設検定を実行するのが (repeated measures) ANOVA である．</p>
</section>
<section id="gauss-markov-の仮定" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="gauss-markov-の仮定"><span class="header-section-number">1.3</span> Gauss-Markov の仮定</h3>
<p>「標本が正規分布に従う母集団からの独立標本である」という帰無仮説を持つ検定に，<span class="citation" data-cites="Shapiro-Wilk1965">(Shapiro and Wilk, 1965)</span> の検定などがある．</p>
<p>探索的な方法には Q-Q plot などがある．<span class="citation" data-cites="vandenBergh+2020">(Don van den Bergh and Wagenmakers, 2020)</span> も参照．</p>
<p>等分散の仮定をチェックする検定には <span class="citation" data-cites="Mauchly1940">(Mauchly, 1940)</span> の検定や <span class="citation" data-cites="Brown-Forsythe1974">(Brown and Forsythe, 1974)</span> の検定などがある．</p>
<p>仮にこれらの仮定が破られた場合は，<span class="citation" data-cites="Kruskal-Wallis1952">(Kruskal and Wallis, 1952)</span> 検定などのランクベースの ANOVA 手法を用いることができる．<sup>1</sup></p>
<p>ただし，検定はデータの一側面しか伝えていない．例えば，データが帰無仮説をどれほど支持しているかの尺度は検定では得られない．</p>
<p>それゆえ，ANOVA などのモデルの仮定を確認するためには，検定だけでなく他の探索的手法と組み合わせることが推奨される．<span class="citation" data-cites="Tijmstra2018">(Tijmstra, 2018)</span> も参照．</p>
</section>
<section id="検定に対する注意喚起" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="検定に対する注意喚起"><span class="header-section-number">1.4</span> 「検定」に対する注意喚起</h3>
<p>一方で ANOVA を含めた検定は一面のみを強調する構造となっており，一連の統計解析の中で自然な位置付けを持つものでない．</p>
<p>特に，<img src="https://latex.codecogs.com/png.latex?p">-値による仮設検定は「データが不十分であることにより判断ができない」ことと，「データと帰無仮説は激しく矛盾する」こととを区別できない．この意味でも限定的な情報量しか持たない．</p>
<p>例えば <img src="https://latex.codecogs.com/png.latex?p">-値が小さく帰無仮説が棄却されたとしても，<img src="https://latex.codecogs.com/png.latex?p">-値はモデルの変化に対して頑健ではないかもしれず，実際はほとんど帰無仮説が成り立つことが真実かもしれない．</p>
<p>このような全貌を探索的に捉えるためには，検定を金科玉条とするのではなく，広くモデル比較・モデル選択の観点からアプローチすることが大切である．同様のことが <span class="citation" data-cites="Rouder+2016">(Rouder et al., 2016)</span> でも論じられている．</p>
<p>ANOVA は，特に大規模なものが，現在でも実験心理学などの分野で広く用いられている．これは心理学では多くの因子 <img src="https://latex.codecogs.com/png.latex?A,B,C,%5Ccdots"> が存在し，それぞれが複雑な関係にあるためである．</p>
<p>しかし推定法も従来の <img src="https://latex.codecogs.com/png.latex?F">-検定を用いたのではその力を十分に発揮できない．解決は丁寧な階層モデリングとベイズによる探索的な解析にある．<sup>2</sup></p>
<blockquote class="blockquote">
<p>”if you have a complicated data structure and are trying to set up a model, it can help to use multilevel modeling”—not just a simple unitswithin-groups structure but a more general approach with crossed factors where appropriate. This is the way that researchers in psychology use ANOVA, but <strong>they are often ill-served by the classical framework of mean squares and F-tests</strong>. We hope that our estimation-oriented approach will allow the powerful tools of Bayesian modeling to be used for the applied goals of inference about large numbers of structured parameters. <span class="citation" data-cites="Gelman2005">(Gelman, 2005, p. 53)</span></p>
</blockquote>
</section>
</section>
<section id="ベイズ分散分析" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="ベイズ分散分析"><span class="header-section-number">2</span> ベイズ分散分析</h2>
<section id="はじめに-1" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="はじめに-1"><span class="header-section-number">2.1</span> はじめに</h3>
<p>ベイズ分散分析 <span class="citation" data-cites="Rouder+2012">(Rouder et al., 2012)</span>, <span class="citation" data-cites="Rouder+2016">(Rouder et al., 2016)</span> では，検定の代わりに Bayes 因子を用いたモデル比較を行う．</p>
<p>特に <span class="citation" data-cites="Rouder+2012">(Rouder et al., 2012)</span> は標準的な事前分布の選択について議論している．</p>
</section>
<section id="考え方" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="考え方"><span class="header-section-number">2.2</span> 考え方</h3>
<p>ベイズ的な仮設検定は <span class="citation" data-cites="Jeffreys1961">(Jeffreys, 1961)</span> に源流を持つ．一般に，位置母数の事前分布に Cauchy 分布を用いることは <span class="citation" data-cites="Jeffreys1961">(5.3節 Jeffreys, 1961)</span> に源流を持つ．このことについては <span class="citation" data-cites="Robert+2009">(Robert et al., 2009)</span> も参照．</p>
<p>同一の人物を繰り返し測定し， <img src="https://latex.codecogs.com/png.latex?%0AY_i%5Coverset%7B%5Ctext%7Biid%7D%7D%7B%5Csim%7D%5Cmathrm%7BN%7D(%5Cmu,%5Csigma%5E2),%5Cqquad%20i%5Cin%5Bn%5D,%0A"> に従って何らかの処置効果 <img src="https://latex.codecogs.com/png.latex?Y_i"> 観測するとし，帰無仮説 <img src="https://latex.codecogs.com/png.latex?%5Cmu=0"> の妥当性を議論したいとする．</p>
<p>この際，まずは効果サイズ (effect size) <span class="citation" data-cites="Cohen1988">(Cohen, 1988)</span> <img src="https://latex.codecogs.com/png.latex?%5Cdelta:=%5Cmu/%5Csigma"> という無次元量にパラメータを変換し，これを Cauchy 分布と比較することを考える： <img src="https://latex.codecogs.com/png.latex?%0AM_0:%5Cdelta=0%5Cquad%5Ctext%7Bv.s.%7D%5Cquad%20M_1:%5Cdelta%5Csim%5Cmathrm%7BC%7D(0,1)%0A"></p>
<p>実際，この Cauchy 分布というのは変換 <img src="https://latex.codecogs.com/png.latex?J(%5Cnu,%5Csigma):=%5Cfrac%7B%5Cmu%5E2%7D%7B%5Csigma%5E2%7D"> を通じて <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D"> 上の Jeffreys 事前分布（この場合は Lebesgue 測度に一致）に（ほとんど）等価になる．</p>
<p>この２つのモデル <img src="https://latex.codecogs.com/png.latex?M_0,M_1"> の残りの仮定は共通の Jeffreys の事前分布 <img src="https://latex.codecogs.com/png.latex?p(%5Csigma%5E2)%5C,%5Cpropto%5C,%5Csigma%5E%7B-2%7D"> で共通とし，Bayes 因子を比較する．</p>
<p>この値を検定統計量のように扱うとき，これを Jeffreys の名前に <span class="citation" data-cites="Zellner-Siow1980">(Zellner and Siow, 1980)</span> を加えて <strong>JZS 因子</strong> <span class="citation" data-cites="Bayarri-Darcia-Donato2007">(Bayarri and García-Donato, 2007)</span> という．</p>
</section>
<section id="p-値との違い" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="p-値との違い"><span class="header-section-number">2.3</span> <img src="https://latex.codecogs.com/png.latex?p">-値との違い</h3>
<p>JZS 因子は <img src="https://latex.codecogs.com/png.latex?p">-値と比較して，サンプルサイズが大きいほど保守的になる傾向がある．<span class="citation" data-cites="Wetzels+2011">(Wetzels et al., 2011)</span> は 2007 年に特定の実験心理学雑誌に投稿された 855 件の t-検定に対して，JZS 因子と <img src="https://latex.codecogs.com/png.latex?p">-値との値を報告してこれを観察している．</p>
<p><span class="citation" data-cites="vandenBergh+2023">(Bergh et al., 2023)</span> は実例を用いて，特に複雑な心理学実験において，２つの解析手法はときに全く違う結論を導くことを例証している．</p>
<p>また JZS 因子は <img src="https://latex.codecogs.com/png.latex?N%5Cto%5Cinfty"> の極限で，<img src="https://latex.codecogs.com/png.latex?%5Cdelta%5Cne0"> であった場合は <img src="https://latex.codecogs.com/png.latex?%5Cinfty"> に発散し，<img src="https://latex.codecogs.com/png.latex?%5Cdelta=0"> であった場合は <img src="https://latex.codecogs.com/png.latex?1"> に収束するという性質を持つ．</p>
</section>
<section id="anova-でのベイズ化" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="anova-でのベイズ化"><span class="header-section-number">2.4</span> ANOVA でのベイズ化</h3>
<p>１元配置 ANOVA のモデルを次のように表す： <span id="eq-Bayesian-ANOVA"><img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BY%7D=%5Cmu%5Cboldsymbol%7B1%7D_n+%5Csigma%5Cboldsymbol%7BX%7D%5Cboldsymbol%7B%5Ctheta%7D+%5Cboldsymbol%7B%5Cepsilon%7D,%5Cqquad%5Cboldsymbol%7B%5Cepsilon%7D%7C%5Csigma%5E2%5Csim%5Cmathrm%7BN%7D(%5Cboldsymbol%7B0%7D,%5Csigma%5E2I_n).%0A%5Ctag%7B2%7D"></span> 各水準 <img src="https://latex.codecogs.com/png.latex?i%5Cin%5Bp%5D"> に属するデータの数を <img src="https://latex.codecogs.com/png.latex?n_i"> とすると <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BX%7D=%5Cbegin%7Bpmatrix%7D%0A%5Cboldsymbol%7B1%7D_%7Bn_1%7D%20&amp;%20%5Cboldsymbol%7B0%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cboldsymbol%7B0%7D%5C%5C%0A%5Cboldsymbol%7B0%7D%20&amp;%20%5Cboldsymbol%7B1%7D_%7Bn_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cboldsymbol%7B0%7D%5C%5C%0A%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%5C%5C%0A%5Cboldsymbol%7B0%7D%20&amp;%20%5Cboldsymbol%7B0%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cboldsymbol%7B1%7D_%7Bn_p%7D%0A%5Cend%7Bpmatrix%7D,%5Cqquad%5Cboldsymbol%7B%5Ctheta%7D=%5Cbegin%7Bpmatrix%7D%0A%5Cmu_1%5C%5C%0A%5Cmu_2%5C%5C%0A%5Cvdots%5C%5C%0A%5Cmu_p%0A%5Cend%7Bpmatrix%7D.%0A"> となる．</p>
<p>すると，<img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Ctheta%7D=0"> の場合のモデルが帰無仮説に対応する．</p>
<p>対立仮説としては，<img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Ctheta%7D"> 上に次の <img src="https://latex.codecogs.com/png.latex?g">-prior を定める： <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7B%5Ctheta%7D%5Csim%5Cmathrm%7BN%7D(%5Cboldsymbol%7B0%7D,G),%5Cqquad%20G=%5Cmathrm%7Bdiag%7D(g_1,%5Ccdots,g_p),%5Cqquad%20g_i%5Coverset%7B%5Ctext%7Biid%7D%7D%7B%5Csim%7D%5Cchi%5E%7B-2%7D(1).%0A"> これは各 <img src="https://latex.codecogs.com/png.latex?%5Cmu_i"> に対して独立な Cauchy 事前分布を仮定している．</p>
<p><span class="citation" data-cites="Zellner-Siow1980">(Zellner and Siow, 1980)</span> の事前分布 <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7B%5Ctheta%7D%7Cg%5Csim%5Cmathrm%7BN%7D(%5Cboldsymbol%7B0%7D,g(%5Cboldsymbol%7BX%7D%5E%5Ctop%5Cboldsymbol%7BX%7D/n)%5E%7B-1%7DI_p)%0A"> や一般の <img src="https://latex.codecogs.com/png.latex?g">-prior との違いとして，スケール因子 <img src="https://latex.codecogs.com/png.latex?(%5Cboldsymbol%7BX%7D%5E%5Ctop%5Cboldsymbol%7BX%7D/n)%5E%7B-1%7D"> がない形であるのは，ANOVA の説明変数 <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BX%7D"> が離散変数であるためである．</p>
</section>
<section id="anova-でのベイズ因子" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="anova-でのベイズ因子"><span class="header-section-number">2.5</span> ANOVA でのベイズ因子</h3>
<p>以上のモデルを，帰無仮説に対立させる「デフォルトモデル」として提案したのが <span class="citation" data-cites="Rouder+2012">(Rouder et al., 2012)</span> である．</p>
<p>特に <img src="https://latex.codecogs.com/png.latex?G=gI_p"> の場合は，結果として得られるベイズ因子は１次元の積分のみを含むため，簡単な数値積分アルゴリズムによって計算可能である．</p>
</section>
<section id="多元配置ベイズ-anova" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="多元配置ベイズ-anova"><span class="header-section-number">2.6</span> 多元配置ベイズ ANOVA</h3>
<p>ひとまず <span class="citation" data-cites="Rouder+2012">(Section 8 Rouder et al., 2012)</span> を参照．</p>
</section>
<section id="ベイズ因子に関する注意喚起" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="ベイズ因子に関する注意喚起"><span class="header-section-number">2.7</span> 「ベイズ因子」に関する注意喚起</h3>
<p>ベイズ因子を含め，周辺尤度 <img src="https://latex.codecogs.com/png.latex?p(%5Ctheta%7Cy)"> （エビデンスともいう）を用いた指標は，モデルの仮定に対して感度が高い <span class="citation" data-cites="Robert2016">(Robert, 2016)</span>, <span class="citation" data-cites="Kamary+2018">(Kamary et al., 2018)</span>．</p>
<p>そのため「モデルのデータへの当てはまりの良さを１つの指標にまとめた値」としては少し心許ない．</p>
<p>加えて，帰無仮説に対立させる仮説を構成して，二項対立の構造に持ち込むことは，自然なデータ解析のワークフローに必ずしも入ってこない．</p>
<p>ベイズ推論の仮定で得られる事後分布から，特定の仮説 <img src="https://latex.codecogs.com/png.latex?H:%5Ctheta=%5Ctheta_0"> がまともかを評価する方法の方が，探索的データ解析の観点からは含意が多いことも多い．</p>
</section>
</section>
<section id="ベイズ推論に基づく方法" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="ベイズ推論に基づく方法"><span class="header-section-number">3</span> ベイズ推論に基づく方法</h2>
<section id="はじめに-2" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="はじめに-2"><span class="header-section-number">3.1</span> はじめに</h3>
<p>ANOVA とベイズ ANOVA の究極的な目標は，平均が一致する <img src="https://latex.codecogs.com/png.latex?%0AH_0:%5Cmu_1=%5Ccdots=%5Cmu_p%0A"> という仮説がデータからどれほど支持されるか／されないかを評価することにある．</p>
<p>最も直接的な方法は，パラメータ空間上に描かれる事後分布を見ることである．信用区間を報告し，帰無仮説がそのどこに位置するかを見ても良いだろう．</p>
</section>
<section id="事後予測によるモデル検証" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="事後予測によるモデル検証"><span class="header-section-number">3.2</span> 事後予測によるモデル検証</h3>
<p>このように，ベイズ事後分布やそのサンプルを通じたモデル検証方法は posterior predictive check <span class="citation" data-cites="Gelman-Shalizi2013">(Gelman and Shalizi, 2013)</span> と呼ばれ，これを多角的に行うことが一つの理想形とされている <span class="citation" data-cites="Gelman+2020">(Gelman et al., 2020)</span>．</p>
<p>同様に <span class="citation" data-cites="Kruschke2015">(Kruschke, 2015)</span> では，モデル (2) の形を一般化線型モデルの特別な場合と見て推定し，ANOVA をモデル比較の観点から適切に実行する方法を論じている．</p>
<p>このように，ANOVA を適切に扱うには，階層モデルとしての取り扱いが欠かせない．同様の議論は <span class="citation" data-cites="Gelman2005">(Gelman, 2005)</span> でも展開されている．</p>
<p>ここでは，以下の節で帰無仮説 <img src="https://latex.codecogs.com/png.latex?H_0"> の妥当性を詳細に評価するための方法を見ていく．</p>
</section>
<section id="ベイズ事後-p-値" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="ベイズ事後-p-値"><span class="header-section-number">3.3</span> ベイズ事後 <img src="https://latex.codecogs.com/png.latex?p">-値</h3>
<p>Bayes 因子の他に，検定統計量に対するベイズ事後予測分布を導出し，その裾確率を評価して <img src="https://latex.codecogs.com/png.latex?p">-値の代替とする方法もある．</p>
<p>これは <strong>事後予測 <img src="https://latex.codecogs.com/png.latex?p">-値</strong> (posterior predictive <img src="https://latex.codecogs.com/png.latex?p">-value) <span class="citation" data-cites="BDA">(Gelman et al., 2014, p. 146)</span> と呼ばれる．</p>
</section>
<section id="rope-region-of-practical-equivalence" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="rope-region-of-practical-equivalence"><span class="header-section-number">3.4</span> ROPE (Region of Practical Equivalence)</h3>
<p>ROPE は帰無仮説 <img src="https://latex.codecogs.com/png.latex?H_0"> と区別がつかないとする区間である．</p>
<p>帰無仮説が <img src="https://latex.codecogs.com/png.latex?H_0:%5Ctheta=%5Ctheta_0"> という形をしていた場合，ほとんどの場合 <img src="https://latex.codecogs.com/png.latex?%5Ctheta=%5Ctheta_0+0.1"> でも事実上変化はない．</p>
<p>このように，帰無仮説と同一視してしまう範囲を <strong>ROPE</strong> <span class="citation" data-cites="Kruschke2015">(Kruschke, 2015, p. 336)</span> という．</p>
<section id="hdr-の使用" class="level4" data-number="3.4.1">
<h4 data-number="3.4.1" class="anchored" data-anchor-id="hdr-の使用"><span class="header-section-number">3.4.1</span> HDR の使用</h4>
<p>この ROPE が 95% <a href="https://ja.wikipedia.org/wiki/信用区間"><strong>最高密度信用領域</strong></a> (HDR: Highest Density Region) と互いに素になるときに，「棄却」されたとする．</p>
<p>ただし，最高密度信用領域とは 95% 信用区間＝95% の事後確率を持つ領域のうち，面積が最も小さいもののことを言う．</p>
<p>この方法では，逆に HDR が ROPE を完全に含む場合，帰無仮説を「採択」するという積極的な意思決定も可能である．</p>
<p>ROPE と同様の考え方は，ベイズによる実験計画法でも range of equivalence <span class="citation" data-cites="Freedman+1984">(Freedman et al., 1984)</span>, <span class="citation" data-cites="Spiegelhalter+1994">(Spiegelhalter et al., 1994)</span> の名前で用いられてきた歴史がある．</p>
</section>
<section id="rope-の確率" class="level4" data-number="3.4.2">
<h4 data-number="3.4.2" class="anchored" data-anchor-id="rope-の確率"><span class="header-section-number">3.4.2</span> ROPE の確率</h4>
<p>または，事後確率分布が ROPE 内にどれほどの確率を与えるかを見ることもできる <span class="citation" data-cites="Kruschke2018">(Kruschke, 2018)</span>．</p>
<p>ROPE の応用と実装は <span class="citation" data-cites="Kelter2022">(Kelter, 2022)</span> も参照．</p>
</section>
</section>
<section id="混合モデリングによる方法" class="level3" data-number="3.5">
<h3 data-number="3.5" class="anchored" data-anchor-id="混合モデリングによる方法"><span class="header-section-number">3.5</span> 混合モデリングによる方法</h3>
<p>ベイズの方法の特徴は，検定・モデル比較と推論とに区別がないことである．</p>
<p>加えて純粋に検定・モデル比較のための手続きを作るより（ベイズ因子など），推定の一種として扱った方がより多くの情報を引き出せるため，ワークフローとしては好ましい <span class="citation" data-cites="Kruschke2011">(Kruschke, 2011)</span>．</p>
<p><span class="citation" data-cites="Robert2016">(Robert, 2016)</span>, <span class="citation" data-cites="Kamary+2018">(Kamary et al., 2018)</span> では検定の対象となっているモデル <img src="https://latex.codecogs.com/png.latex?%0AM_1:x%5Csim%20f_1(x%7C%5Ctheta_1)%5Cquad%5Ctext%7Bv.s.%7D%5Cquad%20M_2:x%5Csim%20f_2(x%7C%5Ctheta_2)%0A"> を，混合モデル <img src="https://latex.codecogs.com/png.latex?%0AM_%5Calpha:x%5Csim%5Calpha%20f_1(x%7C%5Ctheta_1)+(1-%5Calpha)f_2(x%7C%5Ctheta_2)%0A"> の成分の１つとみなし，その荷重 <img src="https://latex.codecogs.com/png.latex?%5Calpha"> の事後分布を推定し，これを検定に用いるという方法が提案されている．</p>
</section>
<section id="ハイパーモデル上の推論による解決" class="level3" data-number="3.6">
<h3 data-number="3.6" class="anchored" data-anchor-id="ハイパーモデル上の推論による解決"><span class="header-section-number">3.6</span> ハイパーモデル上の推論による解決</h3>
<p>同様の発想により，ベイズ因子の計算と推論によるモデル比較とを，より大きなハイパーモデルを立てることで同時に実行することもできる．</p>
<p><span class="citation" data-cites="Kruschke2011">(Kruschke, 2011, p. 308)</span> や <span class="citation" data-cites="ONeill-Kypraios2016">(O’Neill and Kypraios, 2016)</span> などで考えられている．</p>
</section>
</section>
<section id="ベイズ統計解析に関する文献案内" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="ベイズ統計解析に関する文献案内"><span class="header-section-number">4</span> ベイズ統計解析に関する文献案内</h2>
<p>応用分野の研究者に対する「なぜベイズを使うのか？」に対する端的な回答として，「統計的有意性」などの「わかりやすい」指標に飛びついた結果，真のデータの声を聞かずに自分の見たいものを見始めてしまうと言うことが少なく，「自己欺瞞に陥りにくい」という美点があることは，<a href="../../../posts/2024/AI/BAI.html">ベイズ機械学習の稿</a> でも触れた．</p>
<p><img src="https://latex.codecogs.com/png.latex?p">-値はそのような欺瞞を生む代用例であり，使用を禁止すべきとの声 <span class="citation" data-cites="McShane+2019">(Blakeley B. McShane and Tackett, 2019)</span> もある．その論拠は大まかに次のとおりである．</p>
<p>そもそも <img src="https://latex.codecogs.com/png.latex?p">-値とは，「帰無仮説を採用したモデルはデータへの当てはまりの度合いが悪い」ということを言っているだけであり，<img src="https://latex.codecogs.com/png.latex?p">-値が十分に低ければそれ以上の情報は引き出せない．</p>
<p>当然 <img src="https://latex.codecogs.com/png.latex?p">-値が <img src="https://latex.codecogs.com/png.latex?0.01"> であることと <img src="https://latex.codecogs.com/png.latex?0.00001"> であることは質的に全く変わらない <span class="citation" data-cites="BDA">(Gelman et al., 2014, p. 150)</span>．</p>
<p>そのことに加え <img src="https://latex.codecogs.com/png.latex?p">-値は必ずしも頑健な指標ではなく，帰無仮説を少し摂動させただけで <img src="https://latex.codecogs.com/png.latex?p"> 値が大きくなってしまうかもしれない．そのような場合は結局ほとんど帰無的であり，「統計的有意性」はほとんど無意味になってしまう．同様の議論が <span class="citation" data-cites="Gelman-Stern2006">(Gelman and Stern, 2006)</span> で展開されている．</p>
<p>このような現状への対処として，応用分野の研究者にもベイズ統計学は根本的な解決法として広く推奨される <span class="citation" data-cites="Dienes-Mclatchie2018">(Dienes and Mclatchie, 2018)</span>．<span class="citation" data-cites="Wagenmakers+2016">(Wagenmakers et al., 2016)</span> はその旨を２つの実例を通じて簡潔に実証しており，同時にベイズ統計学の考え方に対する洗練された導入を行なっている．</p>
<p><span class="citation" data-cites="vandenBergh+2020">(Don van den Bergh and Wagenmakers, 2020)</span> は分散分析をベイズの方法によって実行する手引きを，特に JASP を用いて実演している．</p>
<p>JASP のベイズ ANOVA のエンジンは R パッケージ <code>BayesFactor</code> (<a href="https://cran.r-project.org/web/packages/BayesFactor/index.html">CRAN</a> / <a href="https://github.com/richarddmorey/BayesFactor">GitHub</a>) を用いている．<code>BayesFactor</code> では大規模な <img src="https://latex.codecogs.com/png.latex?M">-元配置 ANOVA モデルにおいても Bayes 因子を用いたモデル比較を行うことができる．</p>
<p>ベイズ ANOVA の R パッケージとしては <code>bayesanova</code> (<a href="https://cran.r-project.org/web/packages/bayesanova/index.html">CRAN</a> / <a href="https://github.com/cran/bayesanova">GitHub</a>) <span class="citation" data-cites="Kelter2022">(Kelter, 2022)</span> もある．これは検定に似た行為を根本的に排除して Gauss 混合モデルとして Gibbs サンプラーによるベイズ推定を実行し，ROPE (Region of Practical Equivalence) <span class="citation" data-cites="Kruschke2015">(Kruschke, 2015, p. 336)</span> <span class="citation" data-cites="Kruschke2018">(Kruschke, 2018)</span> を用いたモデル比較を行う．</p>
<p>もちろんこのような完全なモデリングを行うことが理想かもしれないが，従来の ANOVA になれきっている研究者にとっては，Bayesian ANOVA に手を伸ばしてみることが次のステップとして大変良いだろう．</p>
<p>また別の角度からの「ベイズを使うべき理由」としての説得的な議論としては，ベイズ階層モデリングは ANOVA の正統進化という理解 <span class="citation" data-cites="Gelman2005">(Gelman, 2005)</span> ができるという向きもある．</p>
<p>以上の立場は <span class="citation" data-cites="BDA">(Gelman et al., 2014)</span> や <span class="citation" data-cites="Kruschke2015">(Kruschke, 2015)</span> などの標準的なベイズデータ解析の教科書でも一貫している．</p>
</section>



<div id="quarto-appendix" class="default"><section id="その他の文献案内" class="level2 appendix" data-number="5"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">5</span> その他の文献案内</h2><div class="quarto-appendix-contents">

<p>F-検定については <span class="citation" data-cites="吉田朋広2006-数理統計">(吉田朋広, 2006)</span> を参考にした．</p>
<p>ANOVA の歴史については <span class="citation" data-cites="Tweney2014">(Tweney, 2014)</span> を参照．(repeated measures) ANOVA は多重線型回帰のうち説明変数が離散変数である場合に相当するという理解は，一般化線型モデルの発展と普及に伴って理解が広がった．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Bayarri-Darcia-Donato2007" class="csl-entry">
Bayarri, M. J., and García-Donato, G. (2007). <a href="https://doi.org/10.1093/biomet/asm014"><span class="nocase">Extending conventional priors for testing general hypotheses in linear models</span></a>. <em>Biometrika</em>, <em>94</em>(1), 135–152.
</div>
<div id="ref-vandenBergh+2023" class="csl-entry">
Bergh, D. van den, Wagenmakers, E.-J., and Aust, F. (2023). <a href="https://doi.org/10.1177/25152459231168024">Bayesian repeated-measures analysis of variance: An updated methodology implemented in JASP</a>. <em>Advances in Methods and Practices in Psychological Science</em>, <em>6</em>(2), 25152459231168024.
</div>
<div id="ref-McShane+2019" class="csl-entry">
Blakeley B. McShane, A. G., David Gal, and Tackett, J. L. (2019). <a href="https://doi.org/10.1080/00031305.2018.1527253">Abandon statistical significance</a>. <em>The American Statistician</em>, <em>73</em>(sup1), 235–245.
</div>
<div id="ref-Brown-Forsythe1974" class="csl-entry">
Brown, M. B., and Forsythe, A. B. (1974). <a href="https://doi.org/10.1080/01621459.1974.10482955">Robust tests for the equality of variances</a>. <em>Journal of the American Statistical Association</em>, <em>69</em>(346), 364–367.
</div>
<div id="ref-Cohen1988" class="csl-entry">
Cohen, J. (1988). <em><a href="https://doi.org/10.4324/9780203771587">Statistical power analysis for the behavioral sciences</a></em>. Routledge.
</div>
<div id="ref-Dienes-Mclatchie2018" class="csl-entry">
Dienes, Z., and Mclatchie, N. (2018). <a href="https://doi.org/10.3758/s13423-017-1266-z">Four reasons to prefer bayesian analyses over significance testing</a>. <em>Psychonomic Bulletin &amp; Review</em>, <em>25</em>(1), 207–218.
</div>
<div id="ref-vandenBergh+2020" class="csl-entry">
Don van den Bergh, M. M., Johnny van Doorn, and Wagenmakers, E.-J. (2020). <a href="https://doi.org/10.3917/anpsy1.201.0073"><span class="nocase">A Tutorial on Conducting and Interpreting a Bayesian ANOVA in JASP</span></a>. <em>L’Année Psychologique</em>, <em>120</em>, 73–96.
</div>
<div id="ref-Freedman+1984" class="csl-entry">
Freedman, L. S., Lowe, D., and Macaskill, P. (1984). <a href="http://www.jstor.org/stable/2530902">Stopping rules for clinical trials incorporating clinical opinion</a>. <em>Biometrics</em>, <em>40</em>(3), 575–586.
</div>
<div id="ref-Gelman2005" class="csl-entry">
Gelman, A. (2005). <a href="https://doi.org/10.1214/009053604000001048"><span class="nocase">Analysis of variance—why it is more important than ever</span></a>. <em>The Annals of Statistics</em>, <em>33</em>(1), 1–53.
</div>
<div id="ref-BDA" class="csl-entry">
Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., and Rubin, D. B. (2014). <em><a href="http://www.stat.columbia.edu/~gelman/book/">Bayesian data analysis</a></em>. Boca Raton : CRC Press.
</div>
<div id="ref-Gelman-Shalizi2013" class="csl-entry">
Gelman, A., and Shalizi, C. R. (2013). <a href="https://doi.org/10.1111/j.2044-8317.2011.02037.x">Philosophy and the practice of bayesian statistics</a>. <em>British Journal of Mathematical and Statistical Psychology</em>, <em>66</em>(1), 8–38.
</div>
<div id="ref-Gelman-Stern2006" class="csl-entry">
Gelman, A., and Stern, H. (2006). <a href="https://doi.org/10.1198/000313006X152649">The difference between <span>“significant”</span> and <span>“not significant”</span> is not itself statistically significant</a>. <em>The American Statistician</em>, <em>60</em>(4), 328–331.
</div>
<div id="ref-Gelman+2020" class="csl-entry">
Gelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., … Modrák, M. (2020). <a href="https://arxiv.org/abs/2011.01808">Bayesian workflow</a>.
</div>
<div id="ref-Jeffreys1961" class="csl-entry">
Jeffreys, H. (1961). <em><a href="https://doi.org/10.1093/oso/9780198503682.001.0001">Theory of probability</a></em>. Oxford University Press.
</div>
<div id="ref-Kamary+2018" class="csl-entry">
Kamary, K., Mengersen, K., Robert, C. P., and Rousseau, J. (2018). <a href="https://arxiv.org/abs/1412.2044">Testing hypotheses via a mixture estimation model</a>.
</div>
<div id="ref-Kelter2022" class="csl-entry">
Kelter, R. (2022). Bayesanova: An r package for bayesian inference in the analysis of variance via markov chain monte carlo in gaussian mixture models. <em>The R Journal</em>, <em>14</em>, 54–78.
</div>
<div id="ref-Kruschke2011" class="csl-entry">
Kruschke, J. K. (2011). <a href="https://doi.org/10.1177/1745691611406925">Bayesian assessment of null values via parameter estimation and model comparison</a>. <em>Perspectives on Psychological Science</em>, <em>6</em>(3), 299–312.
</div>
<div id="ref-Kruschke2015" class="csl-entry">
Kruschke, J. K. (2015). <em><a href="https://www.sciencedirect.com/book/9780124058880/doing-bayesian-data-analysis">Doing bayesian data analysis: A tutorial with r, JAGS, and stan</a></em>. London ; Tokyo : Academic Press.
</div>
<div id="ref-Kruschke2018" class="csl-entry">
Kruschke, J. K. (2018). <a href="https://doi.org/10.1177/2515245918771304">Rejecting or accepting parameter values in bayesian estimation</a>. <em>Advances in Methods and Practices in Psychological Science</em>, <em>1</em>(2), 270–280.
</div>
<div id="ref-Kruskal-Wallis1952" class="csl-entry">
Kruskal, W. H., and Wallis, W. A. (1952). <a href="https://doi.org/10.1080/01621459.1952.10483441">Use of ranks in one-criterion variance analysis</a>. <em>Journal of the American Statistical Association</em>, <em>47</em>(260), 583–621.
</div>
<div id="ref-Mauchly1940" class="csl-entry">
Mauchly, J. W. (1940). <a href="http://www.jstor.org/stable/2235878">Significance test for sphericity of a normal n-variate distribution</a>. <em>The Annals of Mathematical Statistics</em>, <em>11</em>(2), 204–209.
</div>
<div id="ref-ONeill-Kypraios2016" class="csl-entry">
O’Neill, P. D., and Kypraios, T. (2016). <a href="https://arxiv.org/abs/1411.7888">Bayesian model choice via mixture distributions with application to epidemics and population process models</a>.
</div>
<div id="ref-Robert2016" class="csl-entry">
Robert, C. P. (2016). <a href="https://doi.org/10.1016/j.jmp.2015.08.002">The expected demise of the bayes factor</a>. <em>Journal of Mathematical Psychology</em>, <em>72</em>, 33–37.
</div>
<div id="ref-Robert+2009" class="csl-entry">
Robert, C. P., Chopin, N., and Rousseau, J. (2009). <a href="https://doi.org/10.1214/09-STS284"><span class="nocase">Harold Jeffreys’s Theory of Probability Revisited</span></a>. <em>Statistical Science</em>, <em>24</em>(2), 141–172.
</div>
<div id="ref-Rouder+2016" class="csl-entry">
Rouder, J. N., Engelhardt, C. R., McCabe, S., and Morey, R. D. (2016). <a href="https://doi.org/10.3758/s13423-016-1026-5">Model comparison in ANOVA</a>. <em>Psychonomic Bulletin &amp; Review</em>, <em>23</em>(6), 1779–1786.
</div>
<div id="ref-Rouder+2012" class="csl-entry">
Rouder, J. N., Morey, R. D., Speckman, P. L., and Province, J. M. (2012). <a href="https://doi.org/10.1016/j.jmp.2012.08.001">Default bayes factors for ANOVA designs</a>. <em>Journal of Mathematical Psychology</em>, <em>56</em>(5), 356–374.
</div>
<div id="ref-Shapiro-Wilk1965" class="csl-entry">
Shapiro, S. S., and Wilk, M. B. (1965). <a href="https://doi.org/10.1093/biomet/52.3-4.591"><span class="nocase">An analysis of variance test for normality (complete samples)†</span></a>. <em>Biometrika</em>, <em>52</em>(3-4), 591–611.
</div>
<div id="ref-Spiegelhalter+1994" class="csl-entry">
Spiegelhalter, D. J., Freedman, L. S., and Parmar, M. K. B. (1994). <a href="https://doi.org/10.2307/2983527">Bayesian approaches to randomized trials</a>. <em>Journal of the Royal Statistical Society: Series A (Statistics in Society)</em>, <em>157</em>(3), 357–387.
</div>
<div id="ref-Tijmstra2018" class="csl-entry">
Tijmstra, J. (2018). <a href="https://doi.org/10.3758/s13423-018-1447-4">Why checking model assumptions using null hypothesis significance tests does not suffice: A plea for plausibility</a>. <em>Psychonomic Bulletin &amp; Review</em>, <em>25</em>(2), 548–559.
</div>
<div id="ref-Tweney2014" class="csl-entry">
Tweney, R. D. (2014). <a href="https://doi.org/10.1002/9781118445112.stat06304">History of analysis of variance</a>. In <em>Wiley StatsRef: Statistics reference online</em>. John Wiley &amp; Sons, Ltd.
</div>
<div id="ref-Wagenmakers+2016" class="csl-entry">
Wagenmakers, E.-J., Morey, R. D., and Lee, M. D. (2016). <a href="https://doi.org/10.1177/0963721416643289">Bayesian benefits for the pragmatic researcher</a>. <em>Current Directions in Psychological Science</em>, <em>25</em>(3), 169–176.
</div>
<div id="ref-Wetzels+2011" class="csl-entry">
Wetzels, R., Matzke, D., Lee, M. D., Rouder, J. N., Iverson, G. J., and Wagenmakers, E.-J. (2011). <a href="https://doi.org/10.1177/1745691611406923">Statistical evidence in experimental psychology: An empirical comparison using 855 t tests</a>. <em>Perspectives on Psychological Science</em>, <em>6</em>(3), 291–298.
</div>
<div id="ref-Zellner-Siow1980" class="csl-entry">
Zellner, A., and Siow, A. (1980). <a href="https://doi.org/10.1007/BF02888369">Posterior odds ratios for selected regression hypotheses</a>. <em>Trabajos de Estadistica Y de Investigacion Operativa</em>, <em>31</em>(1), 585–603.
</div>
<div id="ref-吉田朋広2006-数理統計" class="csl-entry">
吉田朋広. (2006). <em>数理統計学</em>,Vol. 21. 朝倉書店.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>もちろん，Stan などの確率的プログラミング言語を用いた完全なベイズモデリングはいつでも実行可能である．↩︎</p></li>
<li id="fn2"><p>そして因子分析を通じて，記述統計学の正統進化であるということもできる！？ ANOVA の歴史については <span class="citation" data-cites="Tweney2014">(Tweney, 2014)</span> も参照．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Bayesian</category>
  <category>Statistics</category>
  <guid>https://162348.github.io/posts/2024/Survey/Survey1.html</guid>
  <pubDate>Mon, 23 Sep 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Survey/Files/BayesANOVA.png" medium="image" type="image/png" height="139" width="144"/>
</item>
<item>
  <title>ベイズデータ解析２</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Survey/Survey2.html</link>
  <description><![CDATA[ 





<section id="関連記事" class="level2 unnumbered unlisted">
<h2 class="unnumbered unlisted anchored" data-anchor-id="関連記事">関連記事</h2>
<div id="listing-lst-survey" class="listing quarto-float quarto-figure quarto-figure-left quarto-listing quarto-listing-container-grid anchored">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="QmF5ZXNpYW4lMkNTdGF0aXN0aWNz" data-listing-date-sort="1727049600000" data-listing-file-modified-sort="1733137938540" data-listing-date-modified-sort="1727827200000" data-listing-reading-time-sort="3" data-listing-word-count-sort="516">
<a href="../../../posts/2024/Survey/Survey1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Survey/Files/BayesANOVA.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズデータ解析１
</h5>
<div class="card-subtitle listing-subtitle">
分散分析
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-23
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="QmF5ZXNpYW4lMkNTdGF0aXN0aWNz" data-listing-date-sort="1727136000000" data-listing-file-modified-sort="1733137938540" data-listing-date-modified-sort="1727568000000" data-listing-reading-time-sort="6" data-listing-word-count-sort="1038">
<a href="../../../posts/2024/Survey/Survey3.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Survey/Files/Horvitz-Thompson.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズデータ解析３
</h5>
<div class="card-subtitle listing-subtitle">
標本調査データと欠測データの扱い
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-24
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="QmF5ZXNpYW4lMkNTdGF0aXN0aWNz" data-listing-date-sort="1727136000000" data-listing-file-modified-sort="1733137938540" data-listing-date-modified-sort="1727395200000" data-listing-reading-time-sort="2" data-listing-word-count-sort="269">
<a href="../../../posts/2024/Survey/Survey4.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Survey/Files/DataIntegration.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズデータ解析４
</h5>
<div class="card-subtitle listing-subtitle">
アンケートデータとデータ統合
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-24
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
</section>
<section id="はじめに" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="はじめに"><span class="header-section-number">1</span> はじめに</h2>
<section id="概観" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="概観"><span class="header-section-number">1.1</span> 概観</h3>
<p>現代の因果推論は平均処置効果 (ATE) <img src="https://latex.codecogs.com/png.latex?%0A%5Ctau:=%5Coperatorname%7BE%7D%5BY_i%5E1%5D-%5Coperatorname%7BE%7D%5BY_i%5E0%5D%0A"> と関連する推定対象 (estimand / target parameter) に集中している．</p>
<section id="潜在結果モデル" class="level4" data-number="1.1.1">
<h4 data-number="1.1.1" class="anchored" data-anchor-id="潜在結果モデル"><span class="header-section-number">1.1.1</span> 潜在結果モデル</h4>
<p>このように <strong>因果効果</strong> と呼ばれる推定対象を設定し，良い実験計画を構築してこれを推定するという枠組みは <span class="citation" data-cites="Neyman-23">(Neyman et al., 1990)</span> から始まるもので，<span class="citation" data-cites="Rubin1974-Causal">(Rubin, 1974)</span> の因果モデルや <strong>潜在結果モデル</strong> (potential outcome model)，または <strong>反実仮想モデル</strong> (counterfactual model) とも呼ばれる．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="潜在結果モデルを用いた因果推論">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
潜在結果モデルを用いた因果推論
</div>
</div>
<div class="callout-body-container callout-body">
<p>潜在結果モデルは特定の介入の因果効果を推定する枠組みであり，十分に考慮された実験計画が必要であるが，それにより不必要なモデリングの議論を避けることができる．</p>
<p>このために，極めて多くの人間を対象とする科学分野で潜在結果モデルが用いられている．</p>
<ul>
<li>計量経済学</li>
<li>医学・疫学・生物統計学</li>
<li>社会学 <span class="citation" data-cites="Morgan-Winship2014">(Morgan and Winship, 2014)</span></li>
</ul>
</div>
</div>
<p>この方法では，ランダム化された実験，あるいは欠測メカニズムが推定しやすいように工夫された「擬似実験」を行なうことで，ほとんどモデリングの議論を表に出さずとも ATE やその他の実験科学者が設定する量を不偏推定可能にする，というアプローチをとる．<sup>1</sup></p>
<p>最終的に ATE の推定においては，各個体 <img src="https://latex.codecogs.com/png.latex?i%5Cin%5Bn%5D"> に対して処置を行った場合の結果 <img src="https://latex.codecogs.com/png.latex?Y_i%5E1"> と行わなかった場合の結果 <img src="https://latex.codecogs.com/png.latex?Y_i%5E0"> とのいずれかは必ず欠測するということである．<sup>2</sup></p>
<p>端的に言えば，統計学のサンプリング論と科学の実験計画論との邂逅である <span class="citation" data-cites="Ding2024">(Ding, 2024)</span>．</p>
</section>
<section id="構造的因果モデル" class="level4" data-number="1.1.2">
<h4 data-number="1.1.2" class="anchored" data-anchor-id="構造的因果モデル"><span class="header-section-number">1.1.2</span> 構造的因果モデル</h4>
<p>しかし他の多くの科学では実験的介入が難しかったり，実験計画だけでは背後の交絡要因が統制しきれない状況がある．</p>
<p>またはそもそも，科学的な興味の対象が「因果効果」だけでなくデータの背後にある「モデル」にもある場合も多い．</p>
<p>このような場合には，変数同士の関係を丁寧にモデリングし，加えて識別可能性を確保するなどの理論的な配慮が欠かせない．</p>
<p>これを可能にするのが <strong>構造的因果モデル</strong> (SCM: Structural Causal Model) またはノンパラメトリック構造方程式モデルの枠組みである <span class="citation" data-cites="Bongers+2021">(Bongers et al., 2021)</span>．</p>
<p>多くはグラフィカルモデルと計算機的な方法を組み合わせることで，推定可能な高次元モデルを構築する．このモデルに対する「変換」として，介入操作と因果効果を定義する．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="構造的因果モデルを用いた因果推論">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
構造的因果モデルを用いた因果推論
</div>
</div>
<div class="callout-body-container callout-body">
<p>自然を対象にする科学分野を中心として，介入できない状況下での因果推論が構造的因果モデルの枠組みで行われる．</p>
<ul>
<li>地球科学 <span class="citation" data-cites="Runge2023">(Runge et al., 2023)</span></li>
<li>機械学習：エキスパートシステム <span class="citation" data-cites="Pearl88-IntelligentSystem">(Pearl, 1988)</span>，継続学習 <span class="citation" data-cites="Cui-Athey2022">(Cui and Athey, 2022)</span>，反実仮想機械学習 <span class="citation" data-cites="Huber2023">(M. Huber, 2023)</span></li>
<li>医学・疫学・生物統計学：標的学習 (targeted learning) <span class="citation" data-cites="vanderLaan-Rose11-TargetedLearning">(Laan and Rose, 2011)</span></li>
</ul>
<p>モデリングが必要不可欠であるため，計算的にも困難な問題となる．それゆえ計算機科学や機械学習の分野で盛んに研究されている．</p>
</div>
</div>
</section>
<section id="まとめ" class="level4" data-number="1.1.3">
<h4 data-number="1.1.3" class="anchored" data-anchor-id="まとめ"><span class="header-section-number">1.1.3</span> まとめ</h4>
<div class="callout callout-style-simple callout-important no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li><u>潜在結果アプローチ</u>：実験を行うことでモデリングを回避する．</li>
<li><u>構造的因果モデル</u>：モデリングを行い，モデルの変換として因果効果を定義する．特定の条件下 <span class="citation" data-cites="Rubin1980">(Rubin, 1980)</span> で離散変数に実験処置介入を行った場合として，潜在結果アプローチを含むとも見れる．<sup>3</sup></li>
</ul>
</div>
</div>
</div>
<p>歴史的には，どちらかというと構造的因果モデル → 潜在結果モデルという順に注目された．</p>
<p>この現象は特に経済学で顕著に起こった．Cowles 委員会のイニシアティブの下で，初めは構造的なアプローチを取っていた経済学が，実験事実との乖離が激しいことの自覚から，実験と統計的推論を取り入れるように生まれ変わった現象は <strong>信頼性革命</strong> と呼ばれている．</p>
<p>本章では以降，各分野における因果推論の歴史を議論する．</p>
</section>
</section>
<section id="経済学における因果推論の歴史" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="経済学における因果推論の歴史"><span class="header-section-number">1.2</span> 経済学における因果推論の歴史</h3>
<p>経済学において，<span class="citation" data-cites="Haavelmo1943">(Haavelmo, 1943)</span> は「構造推定」の枠組みで政策介入の因果効果を推定しようとした．<sup>4</sup></p>
<p>構造推定では「同時方程式」により統計モデルを定義するが，その際には識別可能性が問題になる．</p>
<p>当時の計算資源では十分な推定を実行することができず，加えて，マクロなモデルに対する「介入」の定義を正しく与えていなかった <span class="citation" data-cites="Lucas1976">(Lucas, 1976)</span>．<sup>5</sup></p>
<p>時代が下ると，このアプローチでの経済学は大きな批判に晒され，より実験的なアプローチを採用するように変化を余儀なくされた．これが信頼性革命である．</p>
</section>
<section id="計量経済学における信頼性革命" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="計量経済学における信頼性革命"><span class="header-section-number">1.3</span> 計量経済学における信頼性革命</h3>
<p><span class="citation" data-cites="Leamer1983">(Leamer, 1983)</span> は計量経済学の手法と古典的な実験科学とを比較し，計量経済学の信頼性は感度解析とロバストを取り入れることによって（のみ）回復されるだろうと論じた．</p>
<p><span class="citation" data-cites="LaLonde1986">(LaLonde, 1986)</span> は職業訓練の効果に関する観察研究と実験研究の結果が大きく異なることを示し，当時の計量経済学が抱えていた体質に抜本的改革を迫った．</p>
<p><span class="citation" data-cites="Leamer1983">(Leamer, 1983)</span> が「よく計画された実験を超える統計的手法など出てこないかもしれない」と論じていた通り，その後の信頼性革命は主に実験計画を改善することと擬似ランダム化の適切な取り扱いによって達成された <span class="citation" data-cites="Angrist-Pischke2010">(Angrist and Pischke, 2010)</span>．</p>
<p>そのキーワードは「自然実験」や「擬似実験」と呼ばれており，サーベイ手法での「擬似ランダム化」アプローチに相当する．<a href="../../../posts/2024/Survey/Survey3.html">擬似ランダム化については次稿も参照</a>．</p>
</section>
<section id="媒介分析" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="媒介分析"><span class="header-section-number">1.4</span> 媒介分析</h3>
<p><strong>媒介分析</strong> (mediation analysis) <span class="citation" data-cites="Robins-Greenland1992">(J. M. Robins and Greenland, 1992)</span> においては，因果の流れが複数あり得る場合に，媒介因子 <img src="https://latex.codecogs.com/png.latex?Z"> を経由した <strong>間接効果</strong> の量を総合効果の中から識別することを目標とする．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Survey/Files/Mediation.svg" class="img-fluid figure-img"></p>
<figcaption>媒介変数 <img src="https://latex.codecogs.com/png.latex?Z"> を表す図式</figcaption>
</figure>
</div>
<p>一方でモデリングに基づいた方法も可能である <span class="citation" data-cites="Pearl2012">(Pearl, 2012)</span>, <span class="citation" data-cites="Nguyen+2021">(Nguyen et al., 2021)</span>．<sup>6</sup></p>
<p>はじめ社会学や社会心理学においてはモデルによる媒介分析が試みられていた <span class="citation" data-cites="Alwin-Hauser1975">(Alwin and Hauser, 1975)</span>, <span class="citation" data-cites="Baron-Kenny1986">(Baron and Kenny, 1986)</span>．</p>
</section>
</section>
<section id="交絡調整法" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="交絡調整法"><span class="header-section-number">2</span> 交絡調整法</h2>
<section id="はじめに-1" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="はじめに-1"><span class="header-section-number">2.1</span> はじめに</h3>
<p>因果推論において，実験計画による工夫に限界がある際は，条件 <span id="eq-unconfoundedness"><img src="https://latex.codecogs.com/png.latex?%0A(Y%5E0_i,Y%5E1_i)%5Cperp%5C!%5C!%5C!%5Cperp%20A_i%7CX_i%0A%5Ctag%7B1%7D"></span> を満たす共変量 <img src="https://latex.codecogs.com/png.latex?X_i"> の特定を目指す．</p>
<p>この <img src="https://latex.codecogs.com/png.latex?X_i"> を <strong>交絡因子</strong> (cofounders) といい，条件 (1) を <strong>非交絡性</strong> (unconfoundedness) または <strong>無視可能性</strong> (ignorability) という．</p>
</section>
<section id="操作変数法" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="操作変数法"><span class="header-section-number">2.2</span> 操作変数法</h3>
<p><strong>操作変数</strong> (instrumental variable) とは，処置変数（または説明変数）をよく予測するような補助変数であり，補助変数と処置変数の間の関係を推定することで擬似的に層別サンプリングが行われたとみなせるようなものである．<sup>7</sup></p>
<p>未観測の交絡因子が予期される場合でも，操作変数が利用可能である場合はこれを調整することができる．</p>
<div class="callout callout-style-default callout-important no-icon callout-titled" title="計量経済学的な説明^[[Section 12.5 @Hansen2022 p.335] も参照．]">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
計量経済学的な説明<sup>8</sup>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>回帰モデル <img src="https://latex.codecogs.com/png.latex?%0AY=X_1%5E%5Ctop%5Cbeta_1+X_2%5E%5Ctop%5Cbeta_2+%5Cepsilon%0A"> において，<img src="https://latex.codecogs.com/png.latex?X_1"> は外生性を持つが，<img src="https://latex.codecogs.com/png.latex?X_2"> は内生性を持ってしまうとする： <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D%5BX_1%5Cepsilon%5D=0,%5Cquad%5Coperatorname%7BE%7D%5BX_2%5Cepsilon%5D%5Cne0.%0A"> このとき，次の３条件を満たす <img src="https://latex.codecogs.com/png.latex?X"> と同次元の <img src="https://latex.codecogs.com/png.latex?Z"> を操作変数という：</p>
<ol type="1">
<li>外生性：<img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7BE%7D%5BZ%5Cepsilon%5D=0">．</li>
<li>多重線型性の非存在：<img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7Brank%7D%5Coperatorname%7BE%7D%5BZZ%5E%5Ctop%5D%3E0">．</li>
<li>関連性：<img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7Brank%7D%5Coperatorname%7BE%7D%5BZX%5E%5Ctop%5D=%5Coperatorname%7Brank%7D%5Coperatorname%7BE%7D%5BX%5D">．</li>
</ol>
<p>操作変数 <img src="https://latex.codecogs.com/png.latex?Z_2"> を <img src="https://latex.codecogs.com/png.latex?X_2"> の代わりに説明変数に用いることで内生性の問題が除去される．このため <img src="https://latex.codecogs.com/png.latex?Z_2"> は <strong>排除されていた外生変数</strong> (excluded exogenous variable) ともいう．</p>
</div>
</div>
</div>
<p>操作変数が存在するとき，遵守者の平均処置効果，すなわち <strong>局所平均処置効果</strong> (LATE: Local Average Treatment Effect) が識別可能になる <span class="citation" data-cites="Imbens-Angrist94-LATE">(Imbens and Angrist, 1994)</span>．</p>
</section>
<section id="回帰非連続デザイン" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="回帰非連続デザイン"><span class="header-section-number">2.3</span> 回帰非連続デザイン</h3>
<p><a href="https://ja.wikipedia.org/wiki/回帰不連続デザイン"><strong>回帰不連続デザイン</strong></a> (RDD: Regression Discontinuity Design) では，割り当ての閾値の近傍では擬似ランダム化が行われていると仮定できる状況において，閾値の近傍に位置した部分標本を用いて，その部分標本での処置効果を推定する．</p>
</section>
<section id="差の差法" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="差の差法"><span class="header-section-number">2.4</span> 差の差法</h3>
<p><a href="https://ja.wikipedia.org/wiki/差分の差分法"><strong>差分の差法</strong></a> (DID: Difference-in-Differences) は，被曝群と比較群それぞれの処置前後の差分に現れる差分を，処置効果の近似とみなす方法である．</p>
<p>被曝群と比較群をマッチングすることで共変量を統制することが期待されるが，処置の有無と関係を持つ未統制の共変量の調整が問題となる <span class="citation" data-cites="Bertrand+2004">(Bertrand et al., 2004)</span>．</p>
</section>
<section id="周辺構造モデル" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="周辺構造モデル"><span class="header-section-number">2.5</span> 周辺構造モデル</h3>
<p>周辺構造モデルは平均処置効果をパラメータに持つモデルであり <span class="citation" data-cites="Robins2000">(J. M. Robins, 2000)</span>，潜在結果変数の（周辺）平均構造をモデリングする： <img src="https://latex.codecogs.com/png.latex?%0Ag(%5Coperatorname%7BE%7D%5BY%5Ea_i%7CL_i%5D)=%5Cpsi_0+%5Cpsi_1a+%5Cpsi_2L_i+%5Cpsi_3L_ia.%0A"></p>
<p>統計ソフトの充実によりよく使われるようになったが，後述の構造的ネストモデルと <img src="https://latex.codecogs.com/png.latex?G">-推定の方が一般的であり，より効率的である <span class="citation" data-cites="Vamsteelandt-Joffe2014">(Vansteelandt and Joffe, 2014)</span>．</p>
</section>
<section id="g-推定" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="g-推定"><span class="header-section-number">2.6</span> <img src="https://latex.codecogs.com/png.latex?G">-推定</h3>
<p><img src="https://latex.codecogs.com/png.latex?G">-推定 <span class="citation" data-cites="Robins+2000">(J. M. Robins et al., 2000)</span> は不服従など処置変数 <img src="https://latex.codecogs.com/png.latex?D"> に依存した交絡を調整するために，構造的平均モデル，パラメトリック <img src="https://latex.codecogs.com/png.latex?G">-公式 <span class="citation" data-cites="Robins1986">(J. Robins, 1986)</span>，構造的ネストモデル (structural nested model) <span class="citation" data-cites="Robins+1992">(J. M. Robins et al., 1992)</span> と同時に提案された．</p>
<p><strong>構造的平均モデル</strong> (SMM: Structural Mean Model) では，リンク関数 <img src="https://latex.codecogs.com/png.latex?g"> の自由度を残して <img src="https://latex.codecogs.com/png.latex?%0Ag(%5Coperatorname%7BE%7D%5BY%5Ea%7CL=l,A=a%5D)-g(%5Coperatorname%7BE%7D%5BY%5E0%7CL=l,A=a%5D)=%5Cgamma%5E*(l,a;%5Cpsi%5E*)%0A"> により処置 <img src="https://latex.codecogs.com/png.latex?A=a"> の平均因果効果にパラメトリックな仮定をおく．</p>
</section>
</section>
<section id="モデルフリー推定手法" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="モデルフリー推定手法"><span class="header-section-number">3</span> モデルフリー推定手法</h2>
<section id="はじめに-2" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="はじめに-2"><span class="header-section-number">3.1</span> はじめに</h3>
<p>疫学では一般化推定方程式，計量経済学では一般化モーメント法など，モデルを全面に押し出さずに推定目標を定義し，これを推定する手法が用いられる．</p>
<p>このように関心のある母数以外の <strong>局外母数</strong> (nuisance parameter) にはモデルを明示的に想定しない手法を <strong>セミパラメトリック法</strong> (semi-parametric method) という．</p>
<p>このような手法では，興味のあるパラメータがはっきりしているため，それ以外のモデルの仮定にはひとまず興味がなく，誤特定の下でも効率的な推論ができるロバスト性が重視される．<sup>9</sup></p>
</section>
<section id="共通の枠組み" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="共通の枠組み"><span class="header-section-number">3.2</span> 共通の枠組み</h3>
<p>ある関数 <img src="https://latex.codecogs.com/png.latex?g"> に関して， <span id="eq-GMM"><img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D%5Bg(%5Cbeta,X,Y)%5D=0%0A%5Ctag%7B2%7D"></span> によって推定対象 <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> を特徴付ける場面は多い．<sup>10</sup></p>
<p>条件 (2) によって推定対象 <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> が定義されているとき，標本上の対応する方程式 <span id="eq-EstimatingEquation"><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi=1%7D%5Eng(%5Cbeta,X_i,Y_i)=0%0A%5Ctag%7B3%7D"></span> の解として推定量を構成することが自然な発想になる．</p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="名前一覧">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
名前一覧
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>数理統計学・頑健統計では極値点として定義される <img src="https://latex.codecogs.com/png.latex?M">-推定量（第 3.3 節）と区別して <strong><img src="https://latex.codecogs.com/png.latex?Z">-推定量</strong> とも呼ばれる <span class="citation" data-cites="vanderVaart1998">(van&nbsp;der&nbsp;Vaart, 1998)</span>．</li>
<li>疫学では <img src="https://latex.codecogs.com/png.latex?g"> を <strong>推定関数</strong> <span class="citation" data-cites="Godambe1997">(Godambe, 1997)</span>，式 (2) を推定関数の <strong>不偏性</strong>，式 (3) を <strong>推定方程式</strong> という．</li>
<li>計量経済学では <strong>一般化モーメント法</strong> (GMM: Generalized Method of Moments) <span class="citation" data-cites="Hansen82-GMM">(L. P. Hansen, 1982)</span> として知られる．式 (3) を <strong>モーメント方程式</strong> という．主に構造方程式モデルの推定に用いられた．</li>
</ul>
</div>
</div>
<p>特に一般化モーメント法は，モデルの議論を伴わないリサーチクエスチョンに応えるために格好の枠組みである．</p>
<p>例えば線型回帰係数に対する OLS 推定量は <img src="https://latex.codecogs.com/png.latex?g(%5Cbeta,X)=X(Y-X%5E%5Ctop%5Cbeta)"> によって定まる一般化モーメント推定量である．</p>
<p>操作変数推定量は <img src="https://latex.codecogs.com/png.latex?g(%5Cbeta,X,Y,Z)=Z(Y-X%5E%5Ctop%5Cbeta)"> によって定まる一般化モーメント推定量である．</p>
<p>このような推定量はモデルに依存しない方法を与える上に，漸近論の観点で好ましい性質を持つ <span class="citation" data-cites="Hansen82-GMM">(L. P. Hansen, 1982)</span>．</p>
</section>
<section id="sec-M-estimator" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="sec-M-estimator"><span class="header-section-number">3.3</span> <img src="https://latex.codecogs.com/png.latex?M">-推定量</h3>
<p>最尤推定量のように，特定の目的関数 <img src="https://latex.codecogs.com/png.latex?%0AM_n(%5Ctheta):=%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi=1%7D%5Enm_%5Ctheta(X_i)%0A"> を最大化する点として定義される推定量 <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7B%5Ctheta%7D"> は <strong><img src="https://latex.codecogs.com/png.latex?M">-推定量</strong> と呼ばれる．</p>
<p>同時に最尤推定量は，スコア関数の零点としても特徴付けられる <span class="citation" data-cites="Cramer1946">(Carmer, 1946)</span>．</p>
<p>大変大雑把に言えば，モーメント法 → 最尤推定量 → <img src="https://latex.codecogs.com/png.latex?Z">-推定量という歴史的な流れがある <span class="citation" data-cites="LeCam1952">(Le&nbsp;Cam, 1952)</span>．</p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="名前一覧">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
名前一覧
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>頑健統計において <img src="https://latex.codecogs.com/png.latex?M">-推定量 <span class="citation" data-cites="Huber1964">(P. J. Huber, 1964)</span> と呼ばれる．<sup>11</sup></li>
<li>数理統計において最小コントラスト推定量 <span class="citation" data-cites="Pfanzagl1969">(Pfanzagl, 1969)</span> と呼ばれる．</li>
</ul>
</div>
</div>
<p>頑健統計に起源を持つように，<img src="https://latex.codecogs.com/png.latex?M">-推定量，一般に <img src="https://latex.codecogs.com/png.latex?Z">-推定量は極めて安定して一致性と漸近正規性をもつ．</p>
<p>推定方程式 (3) を近似的に解いても大丈夫だし，推定関数の不偏性 (2) が漸近的にしか成り立たなくてもほとんど問題がない．</p>
</section>
<section id="一般化推定方程式" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="一般化推定方程式"><span class="header-section-number">3.4</span> 一般化推定方程式</h3>
<p>一般化推定方程式は，一般化線型モデル <span class="citation" data-cites="Nelder-Wedderburn72-GLM">(Nelder and Wedderburn, 1972)</span> における，擬似スコア <img src="https://latex.codecogs.com/png.latex?%0AU(Y_j,%5Cbeta%7CX_j)=(%5Cpartial_%5Cbeta%5Cmu(X_j%5E%5Ctop%5Cbeta))%5E%5Ctop%20V_i%5E%7B-1%7D(Y_i-%5Cmu(X_i%5E%5Ctop%5Cbeta))%0A"> を推定関数に用いた一般化モーメント法である．</p>
<p><img src="https://latex.codecogs.com/png.latex?U"> を擬似スコアと呼んだのは，誤差の分散 <img src="https://latex.codecogs.com/png.latex?V_i"> はモデルの仮定により定まるわけではなく，主に推定効率のために「作業仮設として」設定されたものであるためである．</p>
<p>実際，正規化した <img src="https://latex.codecogs.com/png.latex?V_i"> は作業相関係数⾏列ともいう．<img src="https://latex.codecogs.com/png.latex?V_i"> を代入した尤度を <strong>擬似尤度</strong> (quasi-likelihood) <span class="citation" data-cites="Wedderburn1974">(Wedderburn, 1974)</span> という．</p>
<p>この方法では，真の誤差分布が相関を持つようなものであった場合でも，平均構造 <img src="https://latex.codecogs.com/png.latex?%5Cmu"> の特定にさえ成功すれば，<img src="https://latex.codecogs.com/png.latex?%5Cbeta"> に関して不偏推定を可能にする．ある種の最尤推定の迂回路である．</p>
<p><img src="https://latex.codecogs.com/png.latex?V_i"> の特定に成功した場合は，セミパラメトリック最適な推定量を与える．</p>
<p>二次のモーメントに関しても関心がある場合は，混合効果モデルなどを通じたモデル化が必要になる．詳しくは <a href="../../../posts/2024/Computation/brms.html">この稿</a> を参照．</p>
</section>
<section id="経験尤度法" class="level3" data-number="3.5">
<h3 data-number="3.5" class="anchored" data-anchor-id="経験尤度法"><span class="header-section-number">3.5</span> 経験尤度法</h3>
<p>データ <img src="https://latex.codecogs.com/png.latex?%5C%7Bx_i%5C%7D_%7Bi=1%7D%5En%5Csubset%5Cmathbb%7BR%7D%5Ed"> に関する <strong>経験尤度</strong> (empirical likelihood) <span class="citation" data-cites="Owen1988">(Owen, 1988)</span> とは，分布関数の汎函数 <img src="https://latex.codecogs.com/png.latex?%0AL(F):=%5Cprod_%7Bi=1%7D%5EnF(X_i)-F(X_i-)=%5Cprod_%7Bi=1%7D%5En%5Coperatorname%7BP%7D%5BX=x_i%5D%0A"> をいう．</p>
<p>この観点から，経験分布関数 <img src="https://latex.codecogs.com/png.latex?F_n"> は経験尤度を最大にするノンパラメトリック推定量である．</p>
<p>最尤法はモデルの全ての母数を特定化しない限り実行できないが，経験尤度の最大化ならば可能である．<sup>12</sup></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi=1%7D%5Enp_ig(x_i,%5Ctheta)=0%0A"> を満たす中で経験尤度を最大化する <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> を <strong>最大経験尤度推定量</strong> (MELE: maximum empirical likelihood estimator) <span class="citation" data-cites="Qin-Lawless1994">(Qin and Lawless, 1994)</span> という．</p>
</section>
</section>



<div id="quarto-appendix" class="default"><section id="文献案内" class="level2 appendix" data-number="4"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">4</span> 文献案内</h2><div class="quarto-appendix-contents">






</div></section><section id="ベイズ推定" class="level3 appendix" data-number="4.1"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">4.1</span> ベイズ推定</h2><div class="quarto-appendix-contents">

<p>平均処置効果のベイズ推定は初めから <span class="citation" data-cites="Rubin1978">(Rubin, 1978)</span> により考えられていた．</p>
<p>近年のレビューには <span class="citation" data-cites="Li+2023-BayesianCausalInference">(Li et al., 2023)</span> がある．</p>
<blockquote class="blockquote">
<p>First and most importantly, by enabling imputation of all missing potential outcomes, the Bayesian paradigm provides a unified inferential framework for any causal estimand. <span class="citation" data-cites="Li+2023-BayesianCausalInference">(Li et al., 2023, p. 18)</span></p>
</blockquote>
<p>頻度論的な因果推論手法は特にモデルフリーな感覚があり，応用分野に浸透しきっている．モデリングの必要性を感じにくいこともあり，ベイズ的な方法が出遅れたままの感がある．</p>
<p>ベイズ手法の成功事例には <span class="citation" data-cites="Dorie+2019">(Dorie et al., 2019)</span> がある．ここでは，2016 年の Atlantic Causal Inference Conference のデータ解析コンペティションで，BART (Bayesian Additive Regression Trees) に基づく手法が優勝したことが考察されている．</p>
<blockquote class="blockquote">
<p>In general, Bayesian nonparametrics offers both the flexibility of modern machine learning algorithms and the statistically-principled uncertainty quantification of Bayesian inference. <span class="citation" data-cites="Linero-Antonelli2023">(Linero and Antonelli, 2023)</span></p>
</blockquote>
</div></section><section id="計量経済学" class="level3 appendix" data-number="4.2"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">4.2</span> 計量経済学</h2><div class="quarto-appendix-contents">

<p><span class="citation" data-cites="川口-澤田2024">(川口康平 and 澤田真行, 2024)</span> は日本語の文献であるが，最新の手法も含めた潜在結果モデルの因果推論手法を，計量経済学の構造推定の文脈から切り離して紹介しており，計量経済学に限らず広い聴衆にリーチすべき内容になっている．<a href="https://github.com/keisemi/EconometriciansGuide_CausalInference">GitHub サポートページはこちら</a>．</p>
</div></section><section id="生物統計学" class="level3 appendix" data-number="4.3"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">4.3</span> 生物統計学</h2><div class="quarto-appendix-contents">

<p><span class="citation" data-cites="Hernan-Robins2020">(Hernán and Robins, 2020)</span> は 2024 年 reviesed 版も <a href="https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/">無料で公開されている</a>．</p>
</div></section><section id="社会科学" class="level3 appendix" data-number="4.4"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">4.4</span> 社会科学</h2><div class="quarto-appendix-contents">

<p><span class="citation" data-cites="Morgan-Winship2014">(Morgan and Winship, 2014)</span> は社会学の本である．４章で媒介解析を扱うと同時に，第５章では Rubin の周辺構造モデルも扱っている．</p>
<p><span class="citation" data-cites="Brand+2023">(Brand et al., 2023)</span> は社会学に力点が置かれているが，因果推論手法一般について極めて良い概観を与える読みやすいレビューである．</p>
</div></section><section id="統計学" class="level3 appendix" data-number="4.5"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">4.5</span> 統計学</h2><div class="quarto-appendix-contents">

<p><span class="citation" data-cites="Rosenbaum2023">(Rosenbaum, 2023)</span> は統計学の本である．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Alwin-Hauser1975" class="csl-entry">
Alwin, D. F., and Hauser, R. M. (1975). <a href="http://www.jstor.org/stable/2094445">The decomposition of effects in path analysis</a>. <em>American Sociological Review</em>, <em>40</em>(1), 37–47.
</div>
<div id="ref-Angrist-Pischke2010" class="csl-entry">
Angrist, J. D., and Pischke, J.-S. (2010). <a href="http://www.jstor.org/stable/25703496">The credibility revolution in empirical economics: How better research design is taking the con out of econometrics</a>. <em>The Journal of Economic Perspectives</em>, <em>24</em>(2), 3–30.
</div>
<div id="ref-Baron-Kenny1986" class="csl-entry">
Baron, R. M., and Kenny, D. A. (1986). <a href="https://doi.org/10.1037/0022-3514.51.6.1173">The moderator–mediator variable distinction in social psychological research: Conceptual, strategic, and statistical considerations</a>. <em>Journal of Personality and Social Psychology</em>, <em>51</em>(6), 1173–1182.
</div>
<div id="ref-Bertrand+2004" class="csl-entry">
Bertrand, M., Duflo, E., and Mullainathan, S. (2004). <a href="https://doi.org/10.1162/003355304772839588"><span>How Much Should We Trust Differences-In-Differences Estimates?*</span></a>. <em>The Quarterly Journal of Economics</em>, <em>119</em>(1), 249–275.
</div>
<div id="ref-Bongers+2021" class="csl-entry">
Bongers, S., Forré, P., Peters, J., and Mooij, J. M. (2021). <a href="https://doi.org/10.1214/21-AOS2064">Foundations of structural causal models with cycles and latent variables</a>. <em>The Annals of Statistics</em>, <em>49</em>(5), 2885–2915.
</div>
<div id="ref-Brand+2023" class="csl-entry">
Brand, J. E., Zhou, X., and Xie, Y. (2023). <a href="https://doi.org/10.1146/annurev-soc-030420-015345">Recent developments in causal inference and machine learning</a>. <em>Annual Review of Sociology</em>, <em>49</em>(Volume 49, 2023), 81–110. Journal Article.
</div>
<div id="ref-Cramer1946" class="csl-entry">
Carmer, H. (1946). <em>Mathematical methods of statistics</em>. Princeton University Press.
</div>
<div id="ref-Cui-Athey2022" class="csl-entry">
Cui, P., and Athey, S. (2022). <a href="https://doi.org/10.1038/s42256-022-00445-z">Stable learning establishes some common ground between causal inference and machine learning</a>. <em>Nature Machine Intelligence</em>, <em>4</em>(2), 110–115.
</div>
<div id="ref-Ding2024" class="csl-entry">
Ding, P. (2024). <em><a href="https://doi.org/10.1201/9781003484080"><span class="nocase">A First Course in Causal Inference</span></a></em>. Chapman; Hall/CRC.
</div>
<div id="ref-Dorie+2019" class="csl-entry">
Dorie, V., Hill, J., Shalit, U., Scott, M., and Cervone, D. (2019). <a href="https://www.jstor.org/stable/26771031">Automated versus do-it-yourself methods for causal inference: Lessons learned from a data analysis competition</a>. <em>Statistical Science</em>, <em>34</em>(1), pp. 43–68.
</div>
<div id="ref-Godambe1997" class="csl-entry">
Godambe, V. P. (1997). <a href="http://www.jstor.org/stable/4356005">Estimating functions: A synthesis of least squares and maximum likelihood methods</a>. <em>Lecture Notes-Monograph Series</em>, <em>32</em>, 5–15.
</div>
<div id="ref-Haavelmo1943" class="csl-entry">
Haavelmo, T. (1943). <a href="http://www.jstor.org/stable/1905714">The statistical implications of a system of simultaneous equations</a>. <em>Econometrica</em>, <em>11</em>(1), 1–12.
</div>
<div id="ref-Hansen2022" class="csl-entry">
Hansen, B. E. (2022). <em>Econometrics</em>. Princeton University Press.
</div>
<div id="ref-Hansen82-GMM" class="csl-entry">
Hansen, L. P. (1982). Large sample properties of generalized method of moments estimators. <em>Econometrica</em>, <em>50</em>(4), 1029–1054.
</div>
<div id="ref-Heckman2010" class="csl-entry">
Heckman, J. J. (2010). <a href="http://www.jstor.org/stable/20778729">Building bridges between structural and program evaluation approaches to evaluating policy</a>. <em>Journal of Economic Literature</em>, <em>48</em>(2), 356–398.
</div>
<div id="ref-Hernan-Robins2020" class="csl-entry">
Hernán, M. A., and Robins, J. M. (2020). <em><a href=""><span>Causal Inference: What If</span></a></em>. Boca Raton: Chapman &amp; Hall/CRC.
</div>
<div id="ref-Holland86-Review" class="csl-entry">
Holland, P. W. (1986). Statistics and causal inference. <em>Journal of the American Statistical Association</em>, <em>81</em>(396), 945–960.
</div>
<div id="ref-Huber2023" class="csl-entry">
Huber, M. (2023). <em><a href="https://mitpress.mit.edu/9780262545914/causal-analysis/"><span class="nocase">Causal Analysis: Impact Evaluation and Causal Machine Learning with Applications in R</span></a></em>. MIT Press.
</div>
<div id="ref-Huber1964" class="csl-entry">
Huber, P. J. (1964). <a href="https://doi.org/10.1214/aoms/1177703732"><span class="nocase">Robust Estimation of a Location Parameter</span></a>. <em>The Annals of Mathematical Statistics</em>, <em>35</em>(1), 73–101.
</div>
<div id="ref-Huber1981" class="csl-entry">
Huber, P. J. (1981). <em><a href="https://onlinelibrary.wiley.com/doi/book/10.1002/0471725250">Robust statistics</a></em>. John Wiley &amp; Sons.
</div>
<div id="ref-Imbens-Angrist94-LATE" class="csl-entry">
Imbens, G. W., and Angrist, J. D. (1994). Identification and estimation of local average treatment effects. <em>Econometrica</em>, <em>62</em>(2), 467–475.
</div>
<div id="ref-vanderLaan-Rose11-TargetedLearning" class="csl-entry">
Laan, M. J. van der, and Rose, S. (2011). <em><a href="https://doi.org/10.1007/978-1-4419-9782-1"><span class="nocase">Targeted Learning: Causal Inference for Observational and Experimental Data</span></a></em>. Springer New York.
</div>
<div id="ref-LaLonde1986" class="csl-entry">
LaLonde, R. J. (1986). <a href="http://www.jstor.org/stable/1806062">Evaluating the econometric evaluations of training programs with experimental data</a>. <em>The American Economic Review</em>, <em>76</em>(4), 604–620.
</div>
<div id="ref-LeCam1952" class="csl-entry">
Le&nbsp;Cam, L. M. (1952). <em>On some asymptotic properties of maximum likelihood estimates and related bayes’ estimates</em> (PhD thesis). UC Berkeley. Retrieved from <a href="https://math.berkeley.edu/publications/some-asymptotic-properties-maximum-likelihood-estimates-and-related-bayes-estimates">https://math.berkeley.edu/publications/some-asymptotic-properties-maximum-likelihood-estimates-and-related-bayes-estimates</a>
</div>
<div id="ref-Leamer1983" class="csl-entry">
Leamer, E. E. (1983). <a href="http://www.jstor.org/stable/1803924">Let’s take the con out of econometrics</a>. <em>The American Economic Review</em>, <em>73</em>(1), 31–43.
</div>
<div id="ref-Li+2023-BayesianCausalInference" class="csl-entry">
Li, F., Ding, P., and Mealli, F. (2023). <a href="https://doi.org/10.1098/rsta.2022.0153">Bayesian causal inference: A critical review</a>. <em>Philosophical Transactions of the Royal Society A: Mathematical Physical and Engineering Sciences</em>, <em>381</em>(2247).
</div>
<div id="ref-Linero-Antonelli2023" class="csl-entry">
Linero, A. R., and Antonelli, J. L. (2023). <a href="https://wires.onlinelibrary.wiley.com/doi/full/10.1002/wics.1583">The how and why of bayesian nonparametric causal inference</a>. <em>WIREs Computational Statistics</em>, <em>15</em>(1), e1583.
</div>
<div id="ref-Lucas1976" class="csl-entry">
Lucas, R. E. (1976). <a href="https://doi.org/10.1016/S0167-2231(76)80003-6">Econometric policy evaluation: A critique</a>. <em>Carnegie-Rochester Conference Series on Public Policy</em>, <em>1</em>, 19–46.
</div>
<div id="ref-Morgan-Winship2014" class="csl-entry">
Morgan, S. L., and Winship, C. (2014). <em><a href=""><span class="nocase">Counterfactuals and Causal Inference</span></a></em>. Cambridge University Press.
</div>
<div id="ref-Nelder-Wedderburn72-GLM" class="csl-entry">
Nelder, J. A., and Wedderburn, R. W. M. (1972). Generalized linear models. <em>Journal of the Royal Statistical Society, Series A (General)</em>, <em>135</em>(3), 370–384.
</div>
<div id="ref-Neyman-23" class="csl-entry">
Neyman, J., Dabrowska, D. M., and Speed, T. P. (1990). <a href="https://doi.org/10.1214/ss/1177012031"><span class="nocase">On the Application of Probability Theory to Agricultural Experiments. Essay on Principles. Section 9</span></a>. <em>Statistical Science</em>, <em>5</em>(4), 465–472.
</div>
<div id="ref-Nguyen+2021" class="csl-entry">
Nguyen, T. Q., Schmid, I., and Stuart, E. A. (2021). <a href="https://doi.org/10.1037/met0000299">Clarifying causal mediation analysis for the applied researcher: Defining effects based on what we want to learn</a>. <em>Psychological Methods</em>, <em>26</em>(2), 255–271.
</div>
<div id="ref-Owen1988" class="csl-entry">
Owen, A. B. (1988). <a href="https://doi.org/10.1093/biomet/75.2.237"><span class="nocase">Empirical likelihood ratio confidence intervals for a single functional</span></a>. <em>Biometrika</em>, <em>75</em>(2), 237–249.
</div>
<div id="ref-Pearl88-IntelligentSystem" class="csl-entry">
Pearl, J. (1988). <em>Probabilistic reasoning in intelligent systems</em>. Morgan Kaufmann.
</div>
<div id="ref-Pearl2012" class="csl-entry">
Pearl, J. (2012). <a href="https://doi.org/10.1002/9781119945710.ch12">The mediation formula: A guide to the assessment of causal pathways in nonlinear models</a>. In <em>Causality</em>, pages 151–179. John Wiley &amp; Sons, Ltd.
</div>
<div id="ref-Pearl2015" class="csl-entry">
Pearl, J. (2015). <a href="https://doi.org/10.1017/S0266466614000231">TRYGVE HAAVELMO AND THE EMERGENCE OF CAUSAL CALCULUS</a>. <em>Econometric Theory</em>, <em>31</em>(1), 152–179.
</div>
<div id="ref-Pfanzagl1969" class="csl-entry">
Pfanzagl, J. (1969). <a href="https://doi.org/10.1007/BF02613654">On the measurability and consistency of minimum contrast estimates</a>. <em>Metrika</em>, <em>14</em>(1), 249–272.
</div>
<div id="ref-Qin-Lawless1994" class="csl-entry">
Qin, J., and Lawless, J. (1994). <a href="https://doi.org/10.1214/aos/1176325370"><span class="nocase">Empirical Likelihood and General Estimating Equations</span></a>. <em>The Annals of Statistics</em>, <em>22</em>(1), 300–325.
</div>
<div id="ref-Robins1986" class="csl-entry">
Robins, J. (1986). <a href="https://doi.org/10.1016/0270-0255(86)90088-6">A new approach to causal inference in mortality studies with a sustained exposure period—application to control of the healthy worker survivor effect</a>. <em>Mathematical Modelling</em>, <em>7</em>(9), 1393–1512.
</div>
<div id="ref-Robins2000" class="csl-entry">
Robins, J. M. (2000). Marginal structural models versus structural nested models as tools for causal inference. In M. E. Halloran and D. Berry, editors, <em>Statistical models in epidemiology, the environment, and clinical trials</em>, pages 95–133. New York, NY: Springer New York.
</div>
<div id="ref-Robins-Greenland1992" class="csl-entry">
Robins, J. M., and Greenland, S. (1992). <a href="https://journals.lww.com/epidem/fulltext/1992/03000/identifiability_and_exchangeability_for_direct_and.13.aspx">Identifiability and exchangeability for direct and indirect effects</a>. <em>Epidemiology</em>, <em>3</em>(2).
</div>
<div id="ref-Robins+2000" class="csl-entry">
Robins, J. M., Hernán, M. Á., and Brumback, B. (2000). <a href="https://journals.lww.com/epidem/fulltext/2000/09000/marginal_structural_models_and_causal_inference_in.11.aspx">Marginal structural models and causal inference in epidemiology</a>. <em>Epidemiology</em>, <em>11</em>(5).
</div>
<div id="ref-Robins+1992" class="csl-entry">
Robins, J. M., Mark, S. D., and Newey, W. K. (1992). <a href="http://www.jstor.org/stable/2532304">Estimating exposure effects by modelling the expectation of exposure conditional on confounders</a>. <em>Biometrics</em>, <em>48</em>(2), 479–495.
</div>
<div id="ref-Rosenbaum2023" class="csl-entry">
Rosenbaum, P. R. (2023). <em><a href="">Causal inference</a></em>. MIT Press.
</div>
<div id="ref-Rubin1974-Causal" class="csl-entry">
Rubin, D. B. (1974). <a href="https://psycnet.apa.org/doi/10.1037/h0037350">Estimating causal effects of treatments in randomized and nonrandomized studies</a>. <em>Journal of Educational Psychology</em>, <em>66</em>(5), 688–701.
</div>
<div id="ref-Rubin1978" class="csl-entry">
Rubin, D. B. (1978). <a href="http://www.jstor.org/stable/2958688">Bayesian inference for causal effects: The role of randomization</a>. <em>The Annals of Statistics</em>, <em>6</em>(1), 34–58.
</div>
<div id="ref-Rubin1980" class="csl-entry">
Rubin, D. B. (1980). <a href="http://www.jstor.org/stable/2287653">Randomization analysis of experimental data: The fisher randomization test comment</a>. <em>Journal of the American Statistical Association</em>, <em>75</em>(371), 591–593.
</div>
<div id="ref-Runge2023" class="csl-entry">
Runge, J., Gerhardus, A., Varando, G., Eyring, V., and Camps-Valls, G. (2023). <a href="https://doi.org/10.1038/s43017-023-00431-y">Causal inference for time series</a>. <em>Nature Reviews Earth &amp; Environment</em>, <em>4</em>(7), 487–505.
</div>
<div id="ref-Fujii+2022" class="csl-entry">
Ryosuke Fujii, Y. T., Shuntaro Sato, and Suzuki, K. (2022). <a href="https://doi.org/10.1080/15592294.2021.1959736">DNA methylation as a mediator of associations between the environment and chronic diseases: A scoping review on application of mediation analysis</a>. <em>Epigenetics</em>, <em>17</em>(7), 759–785.
</div>
<div id="ref-vanderVaart1998" class="csl-entry">
van&nbsp;der&nbsp;Vaart, A. (1998). <em><a href="https://doi.org/10.1017/CBO9780511802256">Asymptotic statistics</a></em>. Cambridge University Press.
</div>
<div id="ref-Vamsteelandt-Joffe2014" class="csl-entry">
Vansteelandt, S., and Joffe, M. (2014). <a href="https://doi.org/10.1214/14-STS493"><span class="nocase">Structural Nested Models and G-estimation: The Partially Realized Promise</span></a>. <em>Statistical Science</em>, <em>29</em>(4), 707–731.
</div>
<div id="ref-Wedderburn1974" class="csl-entry">
Wedderburn, R. W. M. (1974). <a href="http://www.jstor.org/stable/2334725">Quasi-likelihood functions, generalized linear models, and the gauss-newton method</a>. <em>Biometrika</em>, <em>61</em>(3), 439–447.
</div>
<div id="ref-黒木学2016" class="csl-entry">
学. (2016). <a href="https://doi.org/10.20742/pbsj.44.0_124">R-6-2 構造的因果モデルから潜在反応モデルへ</a>. <em>日本行動計量学会大会抄録集</em>, <em>44</em>, 124–125.
</div>
<div id="ref-川口-澤田2024" class="csl-entry">
川口康平, and 澤田真行. (2024). <em><a href="">因果推論の計量経済学</a></em>. 日本評論社.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>科学的な興味の対象は多くの場合モデル全体ではなく，特定の１つのパラメータであり，そのような場合は実験計画を工夫することでモデルに関係なく推定可能になるという発想は <span class="citation" data-cites="Heckman2010">(Heckman, 2010)</span> により “Marschak’s Maxim” と呼ばれる．詳しくは <span class="citation" data-cites="vanderLaan-Rose11-TargetedLearning">(Laan and Rose, 2011)</span> のPearl による foreword も参照．↩︎</p></li>
<li id="fn2"><p>因果推論の根本問題 <span class="citation" data-cites="Holland86-Review">(Holland, 1986)</span> とも呼ばれる．↩︎</p></li>
<li id="fn3"><p><span class="citation" data-cites="黒木学2016">(学, 2016)</span> も参照．↩︎</p></li>
<li id="fn4"><p><span class="citation" data-cites="川口-澤田2024">(川口康平 and 澤田真行, 2024)</span>, <span class="citation" data-cites="Pearl2015">(Pearl, 2015)</span> も参照．↩︎</p></li>
<li id="fn5"><p>詳しくは <a href="https://ja.wikipedia.org/wiki/ルーカス批判">ルーカス批判 (Wikipedia)</a> も参照．↩︎</p></li>
<li id="fn6"><p><span class="citation" data-cites="vanderLaan-Rose11-TargetedLearning">(Laan and Rose, 2011)</span> の Pearl による Foreword も参照．<span class="citation" data-cites="Fujii+2022">(Ryosuke Fujii and Suzuki, 2022)</span> の <a href="https://shuntaros.github.io/mediation-analysis-DNA-methylation/method.html">オンラインページ</a>も参照．↩︎</p></li>
<li id="fn7"><p>ただし当然結果に依存してはいけない．<span class="citation" data-cites="Imbens-Angrist94-LATE">(Section 2 Imbens and Angrist, 1994, p. 468)</span> や <span class="citation" data-cites="Hernan-Robins2020">(Section 3.1 Hernán and Robins, 2020, p. 28)</span> も参照．↩︎</p></li>
<li id="fn8"><p><span class="citation" data-cites="Hansen2022">(Section 12.5 B. E. Hansen, 2022, p. 335)</span> も参照．↩︎</p></li>
<li id="fn9"><p>それゆえ最尤法やベイズ法のように，一旦はモデルの想定が必要な手法が忌避されるところがある．↩︎</p></li>
<li id="fn10"><p><img src="https://latex.codecogs.com/png.latex?X,Y"> を任意の定数とした際に，<img src="https://latex.codecogs.com/png.latex?%5Cbeta"> に関して一意な解を持つとき，モーメント条件は <strong>識別可能</strong> であるという．↩︎</p></li>
<li id="fn11"><p>他には <img src="https://latex.codecogs.com/png.latex?L">-, <img src="https://latex.codecogs.com/png.latex?R">-推定量があった <span class="citation" data-cites="Huber1981">(Section 3.2 P. J. Huber, 1981, p. 43)</span>．↩︎</p></li>
<li id="fn12"><p>一般化推定方程式のように，作業的な値を代入して得る尤度は <strong>擬似尤度</strong> (quasi-likelihood) という．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Statistics</category>
  <guid>https://162348.github.io/posts/2024/Survey/Survey2.html</guid>
  <pubDate>Mon, 23 Sep 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Survey/Files/ATE.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>R 上の Stan インターフェイス</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/R/Stan2.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<div id="listing-lst-stan" class="listing quarto-float quarto-figure quarto-figure-left quarto-listing quarto-listing-container-grid anchored">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="UHJvY2VzcyUyQ01DTUMlMkNSJTJDU3RhbiUyQ1lVSU1BJTJDQmF5ZXNpYW4=" data-listing-date-sort="1715472000000" data-listing-file-modified-sort="1733137937540" data-listing-date-modified-sort="1726790400000" data-listing-reading-time-sort="5" data-listing-word-count-sort="952">
<a href="../../../posts/2024/R/adastan.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/R/Files/adastan1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
SDE のベイズ推定入門
</h5>
<div class="card-subtitle listing-subtitle">
YUIMA と Stan を用いた確率過程のベイズ推定入門
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-05-12
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="QmF5ZXNpYW4lMkNDb21wdXRhdGlvbiUyQ1N0YW4=" data-listing-date-sort="1715904000000" data-listing-file-modified-sort="1733137937492" data-listing-date-modified-sort="1726531200000" data-listing-reading-time-sort="3" data-listing-word-count-sort="554">
<a href="../../../posts/2024/R/Stan1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/R/Files/Stan.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Stan 入門
</h5>
<div class="card-subtitle listing-subtitle">
rstan による Stan の利用
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-05-17
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="U3RhbiUyQ1IlMkNZVUlNQSUyQ1Byb2Nlc3M=" data-listing-date-sort="1715904000000" data-listing-file-modified-sort="1733137937524" data-listing-date-modified-sort="1726531200000" data-listing-reading-time-sort="5" data-listing-word-count-sort="859">
<a href="../../../posts/2024/R/YUIMA.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<!-- img(9CEB782EFEE6)[progressive=false, height=150px]:lst-stan:posts/2024/R/YUIMA.html -->
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
YUIMA 入門
</h5>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-05-17
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
<section id="概観" class="level2 unlisted unnumbered">
<h2 class="unlisted unnumbered anchored" data-anchor-id="概観">概観</h2>
<p><code>RStan</code> は <code>Rcpp</code> や <code>inline</code> といったパッケージにより C++ を R から呼び出すことで，Stan とのインターフェイスを実現している．</p>
<p>一方で <code>CmdStanR</code> は <code>CmdStan</code> という Stan のコマンドラインインターフェイスを R から呼び出すことで，Stan とのインターフェイスを実現している．</p>
</section>
<section id="rstan-パッケージ" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="rstan-パッケージ"><span class="header-section-number">1</span> <code>RStan</code> パッケージ</h2>
<section id="はじめるために" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="はじめるために"><span class="header-section-number">1.1</span> はじめるために</h3>
<p><a href="https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started">RStan Getting Started</a> に従って実行します．</p>
<section id="インストール" class="level4" data-number="1.1.1">
<h4 data-number="1.1.1" class="anchored" data-anchor-id="インストール"><span class="header-section-number">1.1.1</span> インストール</h4>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="すでにインストールされており，再インストールしたい場合">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
すでにインストールされており，再インストールしたい場合
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">packageVersion</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rstan"</span>)</span></code></pre></div>
<p>を実行してすでに存在する場合は，次を実行します</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">remove.packages</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rstan"</span>)</span>
<span id="cb2-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.exists</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".RData"</span>)) <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.remove</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".RData"</span>)</span></code></pre></div>
</div>
</div>
</div>
<p>ほとんどの場合，次の１行でインストールできます：</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">install.packages</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rstan"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">repos =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://cloud.r-project.org/"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">dependencies =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>)</span></code></pre></div>
</section>
<section id="rstan-の利用のためにはc-コンパイラが必要" class="level4" data-number="1.1.2">
<h4 data-number="1.1.2" class="anchored" data-anchor-id="rstan-の利用のためにはc-コンパイラが必要"><span class="header-section-number">1.1.2</span> <code>RStan</code> の利用のためには，<code>c++</code> コンパイラが必要</h4>
<p>XCode コマンドラインツールをインストールすることにより，<code>/Library/Developer/CommandLineTools/usr/bin</code> に <code>clang++</code> がインストールされます．</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb4-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">clang</span>++ <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-v</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-E</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-x</span> c++ /dev/null</span></code></pre></div>
<p>現在では，<a href="https://mac.thecoatlessprofessor.com/macrtools/"><code>macrtools</code></a> を通じて <code>C++</code> コンパイラを R 内でインストールすることもできます．</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="コンパイラ最適化 (MacOS)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
コンパイラ最適化 (MacOS)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><a href="https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started">RStan Getting Started</a> の <a href="https://github.com/stan-dev/rstan/wiki/Configuring-C---Toolchain-for-Mac">Configuring C Toolchain for Mac</a> では，次のようなコンパイラの最適化が推奨されています：</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1">dotR <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.path</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Sys.getenv</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HOME"</span>), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".R"</span>)</span>
<span id="cb5-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.exists</span>(dotR)) <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dir.create</span>(dotR)</span>
<span id="cb5-3">M <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.path</span>(dotR, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Makevars"</span>)</span>
<span id="cb5-4"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.exists</span>(M)) <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.create</span>(M)</span>
<span id="cb5-5">arch <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ifelse</span>(R.version<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>arch <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"aarch64"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"arm64"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"x86_64"</span>)</span>
<span id="cb5-6"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cat</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">paste</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">CXX17FLAGS += -O3 -mtune=native -arch"</span>, arch, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"-ftemplate-depth-256"</span>),</span>
<span id="cb5-7">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">file =</span> M, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sep =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">append =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span></code></pre></div>
<p>これにより <code>~/.R/Makevars</code> に次のような行が追加されます：</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb6-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">CXX17FLAGS</span> += <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-O3</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-mtune</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>native <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-arch</span> arm64 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-ftemplate-depth-256</span></span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="検証" class="level4" data-number="1.1.3">
<h4 data-number="1.1.3" class="anchored" data-anchor-id="検証"><span class="header-section-number">1.1.3</span> 検証</h4>
<p>次のコードが実行されれば，インストールは成功しています．</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">example</span>(stan_model, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">package =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rstan"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">run.dontrun =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>)</span></code></pre></div>
</section>
</section>
<section id="stan-関数" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="stan-関数"><span class="header-section-number">1.2</span> <code>stan</code> 関数</h3>
<p>RStan パッケージの本体は <code>stan</code> 関数である：</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">stan</span>(file, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">model_name =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"anon_model"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">model_code =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fit =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span>,</span>
<span id="cb8-2">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pars =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span>,</span>
<span id="cb8-3">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">chains =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">iter =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2000</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">warmup =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">floor</span>(iter<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">thin =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,</span>
<span id="cb8-4">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">init =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"random"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">seed =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sample.int</span>(.Machine<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>integer.max, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),</span>
<span id="cb8-5">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">algorithm =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"NUTS"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HMC"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Fixed_param"</span>),</span>
<span id="cb8-6">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">control =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sample_file =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">diagnostic_file =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>,</span>
<span id="cb8-7">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">save_dso =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">verbose =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">include =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>,</span>
<span id="cb8-8">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">cores =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">getOption</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mc.cores"</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>L),</span>
<span id="cb8-9">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">open_progress =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">interactive</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;&amp;</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">isatty</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">stdout</span>()) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;&amp;</span></span>
<span id="cb8-10">                  <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">identical</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Sys.getenv</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RSTUDIO"</span>), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1"</span>),</span>
<span id="cb8-11">  ...,</span>
<span id="cb8-12">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">boost_lib =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">eigen_lib =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span></span>
<span id="cb8-13">  )</span></code></pre></div>
<section id="モデルの受け渡し" class="level4" data-number="1.2.1">
<h4 data-number="1.2.1" class="anchored" data-anchor-id="モデルの受け渡し"><span class="header-section-number">1.2.1</span> モデルの受け渡し</h4>
<p><code>model_code=""</code> が Stan モデルを定義するコードを，文字列として直接受け渡すための引数である．</p>
<p>返り値はフィット済みの <code>stanfit</code> オブジェクトである．</p>
<p>他の方法は次のとおり：</p>
<ul>
<li><code>file</code> としてファイルへのパスを渡す</li>
<li>フィット済みの <code>stanfit</code> オブジェクトを <code>fit</code> 引数として渡す</li>
</ul>
</section>
<section id="重要な引数" class="level4" data-number="1.2.2">
<h4 data-number="1.2.2" class="anchored" data-anchor-id="重要な引数"><span class="header-section-number">1.2.2</span> 重要な引数</h4>
<ul>
<li><code>data</code>：データを与える．<code>list</code> 型．</li>
<li><code>iter</code>：繰り返し回数．デフォルトは <code>2000</code>．</li>
<li><code>chains</code>：チェイン数．デフォルトは <code>4</code>．</li>
</ul>
</section>
<section id="stanfit-オブジェクト" class="level4" data-number="1.2.3">
<h4 data-number="1.2.3" class="anchored" data-anchor-id="stanfit-オブジェクト"><span class="header-section-number">1.2.3</span> <code>stanfit</code> オブジェクト</h4>
<p><code>stan</code> 関数は Stan モデルを C++ に変換して実行し，結果を <code>stanfit</code> オブジェクトとして返す．</p>
<p>これに対して <code>print</code>, <code>summary</code>, <code>plot</code> などのメソッドが利用可能である．</p>
<p>さらに，次の様にして MCMC サンプルを取り出すことができる：</p>
<ul>
<li><code>as.array</code> メソッドを用いて MCMC サンプルを <code>array</code> 型で取り出す</li>
<li><code>extract</code> メソッドを用いて MCMC サンプルを <code>list</code> 型で取り出す</li>
<li><code>posterior</code> ライブラリの <code>as_draws_df</code> メソッドを用いて MCMC サンプルを <code>df</code> 型で取り出す．種々のデータ型 <code>&lt;format&gt;</code> に対して <code>as_draws_&lt;format&gt;</code> が存在する．</li>
</ul>
<p>取り出した MCMC サンプルは <code>bayesplot</code> パッケージの <code>mcmc_trace</code>, <code>mcmc_dens</code> などの関数を用いて可視化することができる．</p>
</section>
<section id="例１軌道と事後分布の可視化" class="level4" data-number="1.2.4">
<h4 data-number="1.2.4" class="anchored" data-anchor-id="例１軌道と事後分布の可視化"><span class="header-section-number">1.2.4</span> 例１：軌道と事後分布の可視化</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1">scode <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb9-2"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">parameters {</span></span>
<span id="cb9-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  array[2] real y;</span></span>
<span id="cb9-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb9-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">model {</span></span>
<span id="cb9-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  y[1] ~ normal(0, 1);</span></span>
<span id="cb9-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  y[2] ~ double_exponential(0, 2);</span></span>
<span id="cb9-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb9-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb9-10">fit <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">stan</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">model_code =</span> scode, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">iter =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">chains =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">verbose =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(bayesplot)</span>
<span id="cb10-2"></span>
<span id="cb10-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mcmc_trace</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.array</span>(fit), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pars =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y[1]"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y[2]"</span>))</span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/R/Stan2_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption>軌道のプロット</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mcmc_dens</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.array</span>(fit), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pars =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y[1]"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y[2]"</span>))</span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/R/Stan2_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption>密度のプロット</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="例２確率過程の統計推測" class="level4" data-number="1.2.5">
<h4 data-number="1.2.5" class="anchored" data-anchor-id="例２確率過程の統計推測"><span class="header-section-number">1.2.5</span> 例２：確率過程の統計推測</h4>
<p>OU 過程</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AdX_t=%5Ctheta(%5Cmu-X_t)%5C,dt+%5Csigma%5C,dW_t%0A"></p>
<p>に対して，<code>stan</code> 関数でベイズ推定を実行してみます．</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(yuima)</span>
<span id="cb12-2">model <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">setModel</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">drift =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"theta*(mu-X)"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">diffusion =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sigma"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">state.variable =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"X"</span>)</span></code></pre></div>
</div>
<p>パラメータは <span id="eq-sde-param"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bpmatrix%7D%5Ctheta%5C%5C%5Cmu%5C%5C%5Csigma%5Cend%7Bpmatrix%7D%0A=%0A%5Cbegin%7Bpmatrix%7D1%5C%5C0%5C%5C0.5%5Cend%7Bpmatrix%7D%0A%5Ctag%7B1%7D"></span> として YUIMA を用いてシミュレーションをし，そのデータを与えてパラメータが復元できるかをみます．</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(rstan)</span>
<span id="cb13-2">excode <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"data {</span></span>
<span id="cb13-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            int N;</span></span>
<span id="cb13-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            real x[N+1];</span></span>
<span id="cb13-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            real h;</span></span>
<span id="cb13-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          }</span></span>
<span id="cb13-7"></span>
<span id="cb13-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          parameters {</span></span>
<span id="cb13-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            real theta;</span></span>
<span id="cb13-10"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            real mu;</span></span>
<span id="cb13-11"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            real&lt;lower=0&gt; sigma;</span></span>
<span id="cb13-12"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          }</span></span>
<span id="cb13-13"></span>
<span id="cb13-14"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          model {</span></span>
<span id="cb13-15"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            x[1] ~ normal(0,1);</span></span>
<span id="cb13-16"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            for(n in 2:(N+1)){</span></span>
<span id="cb13-17"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">              x[n] ~ normal(x[n-1] + theta * (mu - x[n-1]) * h,  sqrt(h) * sigma);</span></span>
<span id="cb13-18"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            }</span></span>
<span id="cb13-19"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          }"</span></span>
<span id="cb13-20"></span>
<span id="cb13-21">sampling <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">setSampling</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">Initial =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">Terminal =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">n =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span>
<span id="cb13-22">yuima <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">setYuima</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">model =</span> model, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sampling =</span> sampling)</span>
<span id="cb13-23">simulation <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">simulate</span>(yuima, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">true.parameter =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">theta =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mu =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sigma =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xinit =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rnorm</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb13-24">sde_dat <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">N =</span>  yuima<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>sampling<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>n,</span>
<span id="cb13-25">                  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.numeric</span>(simulation<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>data<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>original.data),</span>
<span id="cb13-26">                  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">h=</span>yuima<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>sampling<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>Terminal<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>yuima<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>sampling<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>n)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># シミュレーション結果</span></span>
<span id="cb14-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(simulation)</span></code></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/R/Stan2_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ベイズ推定</span></span>
<span id="cb15-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rstan_options</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">auto_write =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>)</span>
<span id="cb15-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">options</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mc.cores =</span> parallel<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">detectCores</span>())</span>
<span id="cb15-4"></span>
<span id="cb15-5">fit <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">stan</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">model_code=</span>excode, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> sde_dat, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">iter =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">chains =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">print</span>(fit)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Inference for Stan model: anon_model.
4 chains, each with iter=1000; warmup=500; thin=1; 
post-warmup draws per chain=500, total post-warmup draws=2000.

         mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat
theta    0.89    0.25 1.01   -0.44    0.07    0.59    1.70    3.27    17 1.14
mu       0.02    0.27 3.59   -5.90   -0.15    0.12    0.42    7.23   178 1.02
sigma    0.50    0.00 0.01    0.48    0.49    0.50    0.51    0.52   108 1.07
lp__  3105.37    0.14 1.23 3102.48 3104.76 3105.46 3106.29 3107.15    80 1.06

Samples were drawn using NUTS(diag_e) at Thu Sep 19 16:46:14 2024.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).</code></pre>
</div>
</div>
<p>パラメータ (1) がよく推定できていることがわかる．特に <img src="https://latex.codecogs.com/png.latex?%5Csigma"> が安定して推定できている：</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(fit)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>ci_level: 0.8 (80% intervals)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>outer_level: 0.95 (95% intervals)</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/R/Stan2_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bayesplot"</span>)</span>
<span id="cb21-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rstanarm"</span>)</span>
<span id="cb21-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ggplot2"</span>)</span>
<span id="cb21-4"></span>
<span id="cb21-5">posterior <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.matrix</span>(fit)</span>
<span id="cb21-6">plot_title <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggtitle</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Posterior distributions"</span>,</span>
<span id="cb21-7">                      <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"with medians and 80% intervals"</span>)</span>
<span id="cb21-8"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mcmc_areas</span>(posterior,</span>
<span id="cb21-9">           <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pars =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"theta"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mu"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sigma"</span>),</span>
<span id="cb21-10">           <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">prob =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> plot_title</span></code></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/R/Stan2_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="トラブルシューティング" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="トラブルシューティング"><span class="header-section-number">1.3</span> トラブルシューティング</h3>
<section id="cmath-が見つからない" class="level4" data-number="1.3.1">
<h4 data-number="1.3.1" class="anchored" data-anchor-id="cmath-が見つからない"><span class="header-section-number">1.3.1</span> <code>cmath</code> が見つからない</h4>
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1">Quitting from lines <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">329-343</span> (adastan.qmd) </span>
<span id="cb22-2"></span>
<span id="cb22-3"> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">compileCode</span>(f, code, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">language =</span> language, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">verbose =</span> verbose) でエラー<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> </span>
<span id="cb22-4">  using C<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">++</span> compiler<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> ‘Apple clang version <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>.<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span> (clang<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">-1600</span>.<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>.<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">26.3</span>)’using C<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">++</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">17</span>using SDK<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> ‘MacOSX15.<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span>sdk’In file included from <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span>built<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>In file included from <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Library<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Frameworks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>R.framework<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Versions<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.3</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>arm64<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Resources<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>library<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>StanHeaders<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>include<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>stan<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>math<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>prim<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>fun<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Eigen.hpp<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">22</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>In file included from <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Library<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Frameworks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>R.framework<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Versions<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.3</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>arm64<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Resources<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>library<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>RcppEigen<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>include<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Eigen<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Dense<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>In file included from <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Library<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Frameworks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>R.framework<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Versions<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.3</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>arm64<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Resources<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>library<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>RcppEigen<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>include<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Eigen<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Core<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">19</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">/</span>Library<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Frameworks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>R.framework<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Versions<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.3</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>arm64<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Resources<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>library<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>RcppEigen<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>include<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Eigen<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>src<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Core<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>util<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Macros.h<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">679</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> fatal error<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cmath'</span> file not found  <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">679</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#include &lt;cmath&gt;      |          ^~~~~~~1 error generated.make: *** [file2546221168fc.o] Error 1</span></span>
<span id="cb22-5"> 呼び出し<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>  .main ... cxxfunctionplus <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">&lt;</span>Anonymous<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">-&gt;</span> cxxfunction <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">-&gt;</span> compileCode</span>
<span id="cb22-6"> 追加情報<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>  警告メッセージ<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> </span>
<span id="cb22-7"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>  パッケージ <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'rstan'</span> はバージョン <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>.<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3.1</span> の R の下で造られました  </span>
<span id="cb22-8"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>  パッケージ <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bayesplot'</span> はバージョン <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>.<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3.1</span> の R の下で造られました  </span>
<span id="cb22-9"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>  パッケージ <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'rstanarm'</span> はバージョン <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>.<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3.1</span> の R の下で造られました  </span>
<span id="cb22-10"></span>
<span id="cb22-11"></span>
<span id="cb22-12">Quitting from lines <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">329-343</span> (adastan.qmd) </span>
<span id="cb22-13"> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sink</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">type =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"output"</span>) でエラー<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>  コネクションが不正です </span>
<span id="cb22-14"> 呼び出し<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>  .main ... eval <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">-&gt;</span> stan <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">-&gt;</span> stan_model <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">-&gt;</span> cxxfunctionplus <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">-&gt;</span> sink</span>
<span id="cb22-15"> 実行が停止されました </span></code></pre></div>
<p>大変長く書いてあるが，要は <code>fatal error: 'cmath' file not found</code> である．</p>
<p>筆者の場合は純粋な <code>clang++</code> の問題であった：</p>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb23-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">❯</span> echo <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#include &lt;cmath&gt;</span></span>
<span id="cb23-2"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">#include &lt;iostream&gt;</span></span>
<span id="cb23-3"></span>
<span id="cb23-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">int main() {</span></span>
<span id="cb23-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    double result = std::sqrt(16.0);</span></span>
<span id="cb23-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    std::cout &lt;&lt; "The square root of 16 is " &lt;&lt; result &lt;&lt; std::endl;</span></span>
<span id="cb23-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    return 0;</span></span>
<span id="cb23-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">}'</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> test.cpp</span>
<span id="cb23-9"></span>
<span id="cb23-10"></span>
<span id="cb23-11"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">~</span></span>
<span id="cb23-12"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">❯</span> clang++ <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-std</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>c++17 test.cpp <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-o</span> test</span>
<span id="cb23-13"></span>
<span id="cb23-14"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">test.cpp:1:10:</span> fatal error: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cmath'</span> file not found</span>
<span id="cb23-15">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">1</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">|</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#include &lt;cmath&gt;</span></span>
<span id="cb23-16">      <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">|</span>          <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">^~~~~~~</span></span>
<span id="cb23-17"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">1</span> error generated.</span></code></pre></div>
<p>このような場合は，まず Xcode の再インストールをすると良い．</p>
<div class="sourceCode" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb24-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">softwareupdate</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--list</span></span></code></pre></div>
<p>の出力を用いて，次のようにする：</p>
<div class="sourceCode" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb25-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">softwareupdate</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-i</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Command Line Tools (macOS High Sierra version 10.13) for Xcode-10.1"</span></span></code></pre></div>
<p>または次のようにする：</p>
<div class="sourceCode" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb26-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> rm <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-rf</span> /Library/Developer/CommandLineTools</span>
<span id="cb26-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">xcode-select</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--install</span></span></code></pre></div>
</section>
</section>
</section>
<section id="cmdstanr-パッケージ" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="cmdstanr-パッケージ"><span class="header-section-number">2</span> <code>CmdStanR</code> パッケージ</h2>
<p><code>CmdStanPy</code>, <code>CmdStanR</code> はいずれも Stan のインターフェースである．</p>
<p><code>CmdStanR</code> は <code>R6</code> オブジェクトを用いており，大変現代的な実装を持っている．</p>
<section id="はじめるために-1" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="はじめるために-1"><span class="header-section-number">2.1</span> はじめるために</h3>
<p><a href="https://mc-stan.org/cmdstanr/articles/cmdstanr.html">Getting Started with CmdStanR</a> に従って実行します．</p>
<section id="インストール-1" class="level4" data-number="2.1.1">
<h4 data-number="2.1.1" class="anchored" data-anchor-id="インストール-1"><span class="header-section-number">2.1.1</span> インストール</h4>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">install.packages</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cmdstanr"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">repos =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'https://stan-dev.r-universe.dev'</span>, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">getOption</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"repos"</span>)))</span></code></pre></div>
</section>
<section id="cmdstanr-の利用のためにはcmdstan-が必要" class="level4" data-number="2.1.2">
<h4 data-number="2.1.2" class="anchored" data-anchor-id="cmdstanr-の利用のためにはcmdstan-が必要"><span class="header-section-number">2.1.2</span> <code>CmdStanR</code> の利用のためには，<code>CmdStan</code> が必要</h4>
<p><code>CmdStanR</code> を<a href="../../../posts/2024/R/Stan1.html#sec-installing-cmdstan">直接インストールすることもできます</a>が，<code>CmdStanR</code> 内部からインストールすることもできます．</p>
<div class="sourceCode" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">install_cmdstan</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">cores =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span></code></pre></div>
<div class="cell">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cmdstan_version</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "2.35.0"</code></pre>
</div>
</div>
<p>多くの場合，自動で <code>CMDSTAN</code> 環境変数にパスが設定されます．次のいずれかの方法で確認できます：</p>
<div class="sourceCode" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Sys.getenv</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CMDSTAN"</span>)</span>
<span id="cb31-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cmdstan_path</span>()</span></code></pre></div>
<p><code>CmdStanR</code> の美点の一つは，<code>install_cmdstan()</code> により <code>CmdStan</code> をアップデートすることで最新の Stan を R から簡単に利用できることである．</p>
<p>一方で <code>RStan</code> はパッケージ自体のアップデートを待つ必要がある．</p>
</section>
</section>
<section id="モデル定義" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="モデル定義"><span class="header-section-number">2.2</span> モデル定義</h3>
<p><code>cmdstan_model()</code> 関数は，Stan 言語による記述されたモデル定義を，C++ コードにコンパイルし，その結果を <code>R6</code> オブジェクトとして返す．<sup>1</sup></p>
<div class="sourceCode" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cmdstan_model</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">stan_file =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">exe_file =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">compile =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>, ...)</span></code></pre></div>
<p>返り値は <code>CmdStanModel</code> オブジェクトである．ただし <code>R6</code> オブジェクトでもあり，<code>R6</code> 流のメソッドの呼び方 <code>$</code> が使える．</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1">file <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.path</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cmdstan_path</span>(), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"examples"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bernoulli"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bernoulli.stan"</span>)</span>
<span id="cb33-2">mod <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cmdstan_model</span>(file)</span></code></pre></div>
</div>
<p>Stan 言語による定義は次のようにして確認できる：</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1">mod<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">print</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>data {
  int&lt;lower=0&gt; N;
  array[N] int&lt;lower=0, upper=1&gt; y;
}
parameters {
  real&lt;lower=0, upper=1&gt; theta;
}
model {
  theta ~ beta(1, 1); // uniform prior on interval 0,1
  y ~ bernoulli(theta);
}</code></pre>
</div>
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">names</span>(mod<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">variables</span>())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "parameters"             "included_files"         "data"                  
[4] "transformed_parameters" "generated_quantities"  </code></pre>
</div>
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">names</span>(mod<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">variables</span>()<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>transformed_parameters)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>character(0)</code></pre>
</div>
</div>
<p>元となったファイルのパスも <code>stan_file()</code>, <code>exe_file()</code> で確認できる．</p>
</section>
<section id="stan-コードの操作" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="stan-コードの操作"><span class="header-section-number">2.3</span> Stan コードの操作</h3>
<p><code>write_stan_file()</code> 関数は Stan コードをファイルに書き出すことができる：</p>
<div class="sourceCode" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">write_stan_file</span>(</span>
<span id="cb40-2">  code,</span>
<span id="cb40-3">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">dir =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">getOption</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cmdstanr_write_stan_file_dir"</span>, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">tempdir</span>()),</span>
<span id="cb40-4">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">basename =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>,</span>
<span id="cb40-5">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">force_overwrite =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>,</span>
<span id="cb40-6">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">hash_salt =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span></span>
<span id="cb40-7">)</span></code></pre></div>
<p>グローバル環境変数が設定されていない限り，<code>tempdir()</code> で一時ファイルが作成される．これは R セッションの終了とともに削除される．</p>
<div class="sourceCode" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1">stan_file_variables <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">write_stan_file</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb41-2"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">data {</span></span>
<span id="cb41-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  int&lt;lower=1&gt; J;</span></span>
<span id="cb41-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  vector&lt;lower=0&gt;[J] sigma;</span></span>
<span id="cb41-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  vector[J] y;</span></span>
<span id="cb41-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb41-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">parameters {</span></span>
<span id="cb41-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  real mu;</span></span>
<span id="cb41-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  real&lt;lower=0&gt; tau;</span></span>
<span id="cb41-10"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  vector[J] theta_raw;</span></span>
<span id="cb41-11"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb41-12"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">transformed parameters {</span></span>
<span id="cb41-13"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  vector[J] theta = mu + tau * theta_raw;</span></span>
<span id="cb41-14"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb41-15"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">model {</span></span>
<span id="cb41-16"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  target += normal_lpdf(tau | 0, 10);</span></span>
<span id="cb41-17"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  target += normal_lpdf(mu | 0, 10);</span></span>
<span id="cb41-18"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  target += normal_lpdf(theta_raw | 0, 1);</span></span>
<span id="cb41-19"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  target += normal_lpdf(y | theta, sigma);</span></span>
<span id="cb41-20"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb41-21"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb41-22">mod_v <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cmdstan_model</span>(stan_file_variables)</span>
<span id="cb41-23">variables <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> mod_v<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">variables</span>()</span></code></pre></div>
</section>
<section id="サンプリング" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="サンプリング"><span class="header-section-number">2.4</span> サンプリング</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1">data_list <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">N =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb42-2"></span>
<span id="cb42-3">fit <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> mod<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sample</span>(</span>
<span id="cb42-4">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> data_list,</span>
<span id="cb42-5">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">seed =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">123</span>,</span>
<span id="cb42-6">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">chains =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,</span>
<span id="cb42-7">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">parallel_chains =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,</span>
<span id="cb42-8">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">refresh =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># print update every 1000 iters</span></span>
<span id="cb42-9">)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running MCMC with 4 parallel chains...

Chain 1 Iteration:    1 / 2000 [  0%]  (Warmup) 
Chain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) 
Chain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) 
Chain 1 Iteration: 2000 / 2000 [100%]  (Sampling) 
Chain 2 Iteration:    1 / 2000 [  0%]  (Warmup) 
Chain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) 
Chain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) 
Chain 2 Iteration: 2000 / 2000 [100%]  (Sampling) 
Chain 3 Iteration:    1 / 2000 [  0%]  (Warmup) 
Chain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) 
Chain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) 
Chain 3 Iteration: 2000 / 2000 [100%]  (Sampling) 
Chain 4 Iteration:    1 / 2000 [  0%]  (Warmup) 
Chain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) 
Chain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) 
Chain 4 Iteration: 2000 / 2000 [100%]  (Sampling) 
Chain 1 finished in 0.0 seconds.
Chain 2 finished in 0.0 seconds.
Chain 3 finished in 0.0 seconds.
Chain 4 finished in 0.0 seconds.

All 4 chains finished successfully.
Mean chain execution time: 0.0 seconds.
Total execution time: 0.2 seconds.</code></pre>
</div>
</div>
<p>返り値 <code>fit</code> は <code>CmdStanMCMC</code> オブジェクトであり，<code>summary()</code> などのメソッドが使用可能である．</p>
<p><code>summary()</code> メソッドは，<code>posterior</code> パッケージのメソッド <code>summarise_draws()</code> を自動で使うようになっている．</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1">fit<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summary</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 10
  variable   mean median    sd   mad      q5    q95  rhat ess_bulk ess_tail
  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
1 lp__     -7.30  -7.00  0.797 0.345 -8.86   -6.75   1.00    1923.    2017.
2 theta     0.257  0.241 0.124 0.127  0.0800  0.485  1.00    1232.    1477.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1">fit<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summary</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">variables =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"theta"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lp__"</span>), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mean"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sd"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 3
  variable   mean    sd
  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;
1 theta     0.257 0.124
2 lp__     -7.30  0.797</code></pre>
</div>
</div>
<p>同様にして <code>draws()</code> メソッドで <code>bayesplot</code> パッケージが呼び出される．</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mcmc_hist</span>(fit<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">draws</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"theta"</span>))</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/R/Stan2_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
</section>
</section>



<div id="quarto-appendix" class="default"><section id="文献紹介" class="level2 appendix" data-number="3"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3</span> 文献紹介</h2><div class="quarto-appendix-contents">




</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>実際には，最初に <code>CmdStanModel</code> オブジェクトを生成し，<code>compile()</code> メソッドを呼び出している．これが <code>compile = TRUE</code> フラッグの存在意義である．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Bayesian</category>
  <category>Computation</category>
  <category>Stan</category>
  <category>R</category>
  <guid>https://162348.github.io/posts/2024/R/Stan2.html</guid>
  <pubDate>Thu, 19 Sep 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/R/Files/adastan.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>ベイズ生存時間解析</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/TransDimensionalModels/SurvivalAnalysis.html</link>
  <description><![CDATA[ 





<section id="次稿" class="level2 unlisted unnumbered">
<h2 class="unlisted unnumbered anchored" data-anchor-id="次稿">次稿</h2>
<div id="listing-lst-listing1" class="listing quarto-float quarto-figure quarto-figure-left quarto-listing quarto-listing-container-grid anchored">
<div class="list grid quarto-listing-cols-1">
<div class="g-col-1" data-index="0" data-categories="QmF5ZXNpYW4lMkNNQ01DJTJDU3RhdGlzdGljcw==" data-listing-date-sort="1726099200000" data-listing-file-modified-sort="1733137938564" data-listing-date-modified-sort="1731369600000" data-listing-reading-time-sort="2" data-listing-word-count-sort="266">
<a href="../../../posts/2024/TransDimensionalModels/SurvivalAnalysis1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-center">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/TransDimensionalModels/Images/Polyhazard.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズ階層多ハザードモデル
</h5>
<div class="card-subtitle listing-subtitle">
Zig-Zag サンプラーによるモデル平均法
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
</section>
<section id="生存時間と競合リスクの解析" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="生存時間と競合リスクの解析"><span class="header-section-number">1</span> 生存時間と競合リスクの解析</h2>
<section id="sec-HTA" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="sec-HTA"><span class="header-section-number">1.1</span> はじめに</h3>
<p><a href="https://ja.wikipedia.org/wiki/医療経済学">医療経済学</a> などにおける <a href="https://ja.wikipedia.org/wiki/医療技術評価"><strong>医療技術評価</strong></a> (HTA: Health Technology Assessment) とは，新たな医療技術を臨床試験で評価し，リスクやコストを勘案して新技術の既存法との効果や安全性を評価・比較する <strong>決定理論的な枠組み</strong> である．</p>
<p>この枠組みでは非負確率変数 <img src="https://latex.codecogs.com/png.latex?Y"> に対して，例えば次のような平均の計算が必要になる： <span id="eq-HTA"><img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D%5BY%5D=%5Cint%5E%5Cinfty_0S_Y(y)%5C,dy,%5Cqquad%20S_Y(y):=%5Coperatorname%7BP%7D%5BY%5Cge%20y%5D.%0A%5Ctag%7B1%7D"></span></p>
<p>医療技術評価の文脈において <img src="https://latex.codecogs.com/png.latex?Y"> は被験者のイベントまでの時間 (time-to-event) を表す確率変数で，<img src="https://latex.codecogs.com/png.latex?S_Y"> は <img src="https://latex.codecogs.com/png.latex?Y"> の <strong>生存（割合）関数</strong> といい，<img src="https://latex.codecogs.com/png.latex?Y"> の分布関数 <img src="https://latex.codecogs.com/png.latex?F_Y"> と次の関係を持つ： <img src="https://latex.codecogs.com/png.latex?%0AS_Y(y)=1-F_Y(y).%0A"></p>
<p>平均 (1) を計算するためには，観測の打ち切りを乗り越えて <img src="https://latex.codecogs.com/png.latex?S_Y"> を <img src="https://latex.codecogs.com/png.latex?%5B0,%5Cinfty)"> 全域で推定する必要があり，そのためにはベイズ手法が有望視されている（第 1.5 節）．</p>
</section>
<section id="sec-survival-analysis-introduction" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="sec-survival-analysis-introduction"><span class="header-section-number">1.2</span> 生存時間解析とは</h3>
<p>イベントまでの時間 <img src="https://latex.codecogs.com/png.latex?Y"> の生存関数 <img src="https://latex.codecogs.com/png.latex?S_Y"> を推定する問題は <strong>生存時間解析</strong> (survival analysis) または信頼性解析として知られ，ほとんど統計学の起源と同時に始まる長い歴史を持つ．<sup>1</sup></p>
<p>共変量 <img src="https://latex.codecogs.com/png.latex?X"> の生存時間 <img src="https://latex.codecogs.com/png.latex?Y"> への影響を調べる際には，生存関数 <img src="https://latex.codecogs.com/png.latex?S_Y"> の代わりに <strong>ハザード関数</strong> （または瞬間故障率，死亡率） <img src="https://latex.codecogs.com/png.latex?%0Ah(y):=%5Cfrac%7Bf(y)%7D%7BS(t)%7D=-%5Cfrac%7Bd%20%5Clog%20S(y)%7D%7Bd%20t%7D,%5Cqquad%20f(y)=F'(y)=-S'(y),%0A"> もモデリングの対象になる．ただし <img src="https://latex.codecogs.com/png.latex?f"> は <img src="https://latex.codecogs.com/png.latex?Y"> の確率密度関数とした．</p>
<p>ハザード関数 <img src="https://latex.codecogs.com/png.latex?h"> は，被験者の生存割合が <img src="https://latex.codecogs.com/png.latex?S(y)"> である段階での，次の単位時間でのイベント発生率を表す．ハザード関数が判れば，生存関数は <img src="https://latex.codecogs.com/png.latex?%0AS(y)=%5Cexp%5Cleft(-%5Cint%5Ey_0h(t)%5C,dt%5Cright)%0A"> によって復元される．</p>
<p>さらに究極の目標として，生存時間 <img src="https://latex.codecogs.com/png.latex?Y"> に影響を与える共変量 <img src="https://latex.codecogs.com/png.latex?X"> の成分を特定することがある．この際に用いるモデルを <strong>競合リスクモデル</strong> という（第 1.7 節）．</p>
<p>競合する <img src="https://latex.codecogs.com/png.latex?K"> 個のリスク要因がそれぞれハザード <img src="https://latex.codecogs.com/png.latex?h_1,%5Ccdots,h_K"> を持つとき，イベント発生時刻 <img src="https://latex.codecogs.com/png.latex?Y"> のハザードは和 <img src="https://latex.codecogs.com/png.latex?%0Ah_Y(y)=%5Csum_%7Bj=1%7D%5EKh_j(y)%0A"> で与えられる．これを <strong>多ハザード模型 (Polyhazard model)</strong>（第 1.6 節），<img src="https://latex.codecogs.com/png.latex?h_i"> を <strong>原因別ハザード</strong> という．</p>
</section>
<section id="生存関数推定" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="生存関数推定"><span class="header-section-number">1.3</span> 生存関数推定</h3>
<section id="欠測の問題" class="level4" data-number="1.3.1">
<h4 data-number="1.3.1" class="anchored" data-anchor-id="欠測の問題"><span class="header-section-number">1.3.1</span> 欠測の問題</h4>
<p>生存時間解析における最大の問題は観測の <strong>打ち切り</strong> (censoring) である．</p>
<p>換言すれば，ほとんどの生存時間データでは種々の理由で被験者が脱落し，追跡終了時点以降はイベントの発生を確認できないのである．</p>
<p>そこで，５割生存時間 (MST: Median Survival Time) を代わりに推定対象としたり，ある打ち切り時刻 <img src="https://latex.codecogs.com/png.latex?T%3E0"> までの区間のみに限って <img src="https://latex.codecogs.com/png.latex?S:%5B0,T%5D%5Cto%5B0,1%5D"> を推定することが考えられた．</p>
</section>
<section id="sec-parametrics" class="level4" data-number="1.3.2">
<h4 data-number="1.3.2" class="anchored" data-anchor-id="sec-parametrics"><span class="header-section-number">1.3.2</span> パラメトリックモデル</h4>
<p><img src="https://latex.codecogs.com/png.latex?S_Y"> をパラメトリックな分布族の中から推定することが考えられる．</p>
<p>この場合，形状母数 <img src="https://latex.codecogs.com/png.latex?%5Cnu%3E0"> によってハザード関数の増加・減少を柔軟にモデリングできる <a href="https://ja.wikipedia.org/wiki/ワイブル分布">Weibull 分布</a> <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BW%7D(%5Cnu,%5Calpha)"> または <span class="citation" data-cites="Rosin-Rammler1933">(Rosin and Rammler, 1933)</span> の分布 <img src="https://latex.codecogs.com/png.latex?%0Af(x;%5Cnu,%5Calpha)=%5Cfrac%7B%5Cnu%7D%7B%5Calpha%7D%5Cleft(%5Cfrac%7Bx%7D%7B%5Calpha%7D%5Cright)%5E%7B%5Cnu-1%7D%5Cexp%5Cleft(-%5Cleft(%5Cfrac%7Bx%7D%7B%5Calpha%7D%5Cright)%5E%5Cnu%5Cright)1_%7B%5Cleft%5C%7Bx%3E0%5Cright%5C%7D%7D,%5Cqquad%5Calpha%3E0,%5Cnu%3E0,%0A"> <img src="https://latex.codecogs.com/png.latex?%0Ah(t)=%5Cfrac%7B%5Cnu%7D%7B%5Calpha%7D%5Cleft(%5Cfrac%7Bt%7D%7B%5Calpha%7D%5Cright)%5E%7B%5Cnu-1%7D1_%7B%5Cleft%5C%7Bt%3E0%5Cright%5C%7D%7D%0A"> をはじめとして，Gamma 分布，対数正規分布，対数ロジスティック分布分布，パレート分布など，極値分布の指数変換様の分布族が用いられる．</p>
</section>
<section id="ノンパラメトリックモデル" class="level4" data-number="1.3.3">
<h4 data-number="1.3.3" class="anchored" data-anchor-id="ノンパラメトリックモデル"><span class="header-section-number">1.3.3</span> ノンパラメトリックモデル</h4>
<p>これには <span class="citation" data-cites="Kaplan-Meier1958">(Kaplan and Meier, 1958)</span> や <span class="citation" data-cites="Cutler-Ederer1958">(Cutler and Ederer, 1958)</span> の方法が古来より有名である．</p>
</section>
</section>
<section id="回帰" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="回帰"><span class="header-section-number">1.4</span> 回帰</h3>
<section id="ハザードの回帰" class="level4" data-number="1.4.1">
<h4 data-number="1.4.1" class="anchored" data-anchor-id="ハザードの回帰"><span class="header-section-number">1.4.1</span> ハザードの回帰</h4>
<p>生存時間解析の主な目的は，生存曲線の正確な描画というより，生存時間を決定する要因の特定にある．</p>
<p><span class="citation" data-cites="Cox72-RegressionModelsLifeTables">(Cox, 1972)</span> はベースとなる生存関数 <img src="https://latex.codecogs.com/png.latex?S_0"> (baseline survival curve) を局外母数として，<img src="https://latex.codecogs.com/png.latex?S"> と <img src="https://latex.codecogs.com/png.latex?S_0"> の関係をパラメトリックにモデリングする．</p>
<p>より正確には，ハザード関数 <img src="https://latex.codecogs.com/png.latex?h"> のベース <img src="https://latex.codecogs.com/png.latex?h_0"> からの比の対数を，線型な予測子 <img src="https://latex.codecogs.com/png.latex?%0A%5Clog%20%5Cfrac%7Bh(y)%7D%7Bh_0(y)%7D=X%5E%5Ctop%5Cbeta+%5Cepsilon%0A"> によってモデリングする．</p>
<p>一般にハザードの比を <img src="https://latex.codecogs.com/png.latex?%0Ah(y%7Cx)=h_0(y)c(X%5E%5Ctop%5Cbeta)%0A"> とモデリングするものを <strong>乗法的ハザードモデル</strong> といい，特に <img src="https://latex.codecogs.com/png.latex?c=%5Cexp"> と取った場合を Cox の <strong>比例ハザードモデル</strong> (Cox’s proportional hazard model) とも呼ばれる．</p>
<p>この方法は，打ち切りデータへの対処が簡便になることが美点である．</p>
</section>
<section id="生存時間の回帰" class="level4" data-number="1.4.2">
<h4 data-number="1.4.2" class="anchored" data-anchor-id="生存時間の回帰"><span class="header-section-number">1.4.2</span> 生存時間の回帰</h4>
<p>生存時間 <img src="https://latex.codecogs.com/png.latex?Y"> の対数を直接 <img src="https://latex.codecogs.com/png.latex?%0A%5Clog%20Y=%5Cmu+%5Cbeta%5E%5Ctop%20X+%5Cepsilon%0A"> によってモデリングする方法は <strong>加速故障時間モデル</strong> (AFT: Accelerated Failure Time Model) <span class="citation" data-cites="Wei1992">(Wei, 1992)</span> と呼ばれる．</p>
<p>このモデルはハザード関数に，<img src="https://latex.codecogs.com/png.latex?h_0"> を <img src="https://latex.codecogs.com/png.latex?x=0"> の場合のハザード関数として <img src="https://latex.codecogs.com/png.latex?%0Ah(y%7Cx)=e%5E%7B-%5Cbeta%5E%5Ctop%20x%7Dh_0(ye%5E%7B-%5Cbeta%5E%5Ctop%20x%7D),%0A"> という乗法的な仮定をおいていることに相当する．</p>
</section>
</section>
<section id="sec-modern-survival-analysis" class="level3" data-number="1.5">
<h3 data-number="1.5" class="anchored" data-anchor-id="sec-modern-survival-analysis"><span class="header-section-number">1.5</span> 生存関数推定再論</h3>
<p>一方で医療行為の社会的な影響も考える HTA の目標を達成するためには，式 (1) のような量を計算する必要がある．</p>
<p>そのためには，生存曲線の推定と同時に打ち切り時点以降の外挿もできるようなモデルを考える必要があるが，Kaplan-Meier 法などのノンパラメトリック法は（現状）この用途には用いることができない．</p>
<p>表現力が高いパラメトリックモデルをベイズ推定することが，非常に魅力的な解決策として考えられ，実際 NICE のガイドラインでも推奨されている <span class="citation" data-cites="Latimer2011">(Latimer, 2011)</span>．</p>
<p>その際の魅力的なモデルに polyhazard model <span class="citation" data-cites="Berger-Sun1993">(Berger and Sun, 1993)</span>, <span class="citation" data-cites="Louzada-Neto1999">(Louzada-Neto, 1999)</span> がある．</p>
<p><span class="citation" data-cites="Latimer2013">(Latimer, 2013)</span> では現状の HTA 分析では，生存時間モデルに対してモデル検証・モデル選択が不十分であることに警鐘が鳴らされている．</p>
<p>polyhazard model のような階層モデルを効率的にベイズ推定・モデル平均化ができるような MCMC 法が開発されることは，このモデル検証の手続きを自動化したり，より手軽にするために非常に重要である．</p>
</section>
<section id="sec-polyhazard-model" class="level3" data-number="1.6">
<h3 data-number="1.6" class="anchored" data-anchor-id="sec-polyhazard-model"><span class="header-section-number">1.6</span> 多ハザードモデルの表現力</h3>
<p>Polyhazard model もハザード関数をモデリングするが， <img src="https://latex.codecogs.com/png.latex?%0Ah_Y(y)=%5Csum_%7Bj=1%7D%5EKh_j(y)%0A"> という形でモデリングし，個々の <img src="https://latex.codecogs.com/png.latex?h_j"> にパラメトリックな仮定をおく．</p>
<p>仮に <img src="https://latex.codecogs.com/png.latex?h_j"> として，形状母数 <img src="https://latex.codecogs.com/png.latex?%5Cnu%3E0"> と位置母数 <img src="https://latex.codecogs.com/png.latex?%5Cmu:=%5Calpha%5E%7B-%5Cnu%7D%3E0"> を持つ Weibull 分布 <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BW%7D(%5Cnu,%5Cmu)"> のハザード関数<sup>2</sup> <img src="https://latex.codecogs.com/png.latex?%0Ah_%7B%5Cmathrm%7BW%7D%7D(y):=%5Cmu%5Cnu%20y%5E%7B%5Cnu-1%7D%0A"> と対数ロジスティック分布 <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BLL%7D(%5Cnu,%5Cmu)"> のハザード関数 <img src="https://latex.codecogs.com/png.latex?%0Ah_%7B%5Cmathrm%7BLL%7D%7D(y):=%5Cfrac%7B%5Cleft(%5Cfrac%7B%5Cnu%7D%7B%5Cmu%7D%5Cright)%5Cleft(%5Cfrac%7By%7D%7B%5Cmu%7D%5Cright)%5E%7B%5Cnu-1%7D%7D%7B1+%5Cleft(%5Cfrac%7By%7D%7B%5Cmu%7D%5Cright)%5E%5Cnu%7D%0A"> の２つのみを考えたとしても，複数のパラメトリックモデルを足し合わせることで驚異的な表現力を達成することができる．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/TransDimensionalModels/Images/Polyhazard.png" class="img-fluid figure-img"></p>
<figcaption><span class="citation" data-cites="Hardcastle+2024">(Hardcastle et al., 2024, p. 5)</span> より．</figcaption>
</figure>
</div>
</section>
<section id="sec-competing-risk-analysis" class="level3" data-number="1.7">
<h3 data-number="1.7" class="anchored" data-anchor-id="sec-competing-risk-analysis"><span class="header-section-number">1.7</span> 競合リスク解析</h3>
<section id="モデルの解釈" class="level4" data-number="1.7.1">
<h4 data-number="1.7.1" class="anchored" data-anchor-id="モデルの解釈"><span class="header-section-number">1.7.1</span> モデルの解釈</h4>
<p>polyhazard モデルでは各 <img src="https://latex.codecogs.com/png.latex?h_k"> の前に係数がついていない点には注意が必要である．</p>
<p>各 <img src="https://latex.codecogs.com/png.latex?h_k"> は実在の原因のハザードを表しており，各被験者は同時に <img src="https://latex.codecogs.com/png.latex?K"> 個のリスクに晒されているというモデルである（第 1.2 節）．</p>
<p>このようなモデルを <strong>競合リスクモデル</strong> (competing risk model) ともいう．</p>
<p>例えば，心臓の移植後のハザード曲線はバスタブ曲線の形を持ち，少なくとも２つの別々の競合するリスク要因が存在することが窺える <span class="citation" data-cites="Demiris+2015">(Demiris et al., 2015)</span>．</p>
</section>
<section id="競合リスクモデリング" class="level4" data-number="1.7.2">
<h4 data-number="1.7.2" class="anchored" data-anchor-id="競合リスクモデリング"><span class="header-section-number">1.7.2</span> 競合リスクモデリング</h4>
<p>しかし，リスク因子はほとんどの場合観測できず，潜在変数となる．<img src="https://latex.codecogs.com/png.latex?K"> の数も不確実である．</p>
<p>このような識別不可能なモデルは，階層モデルとしてベイズ推論を実行することが向いていると言えるかも知れない．</p>
<p>さらに発展的なモデルにはマルチステートモデルもある <span class="citation" data-cites="齋藤-室谷2023">(齋藤哲雄 and 室谷健太, 2023)</span>, <span class="citation" data-cites="齋藤-室谷2024">(Saito and Murotani, 2024)</span>．</p>
</section>
</section>
<section id="ベイズ階層多ハザードモデル" class="level3" data-number="1.8">
<h3 data-number="1.8" class="anchored" data-anchor-id="ベイズ階層多ハザードモデル"><span class="header-section-number">1.8</span> ベイズ階層多ハザードモデル</h3>
<p><span class="citation" data-cites="Hardcastle+2024">(Hardcastle et al., 2024)</span> では HTA への応用を念頭に，完全なベイズ階層多ハザードモデルの推定を試みている．ここではそのモデルの詳細を紹介する．</p>
<section id="第１階層" class="level4" data-number="1.8.1">
<h4 data-number="1.8.1" class="anchored" data-anchor-id="第１階層"><span class="header-section-number">1.8.1</span> 第１階層</h4>
<p>各個別要因 <img src="https://latex.codecogs.com/png.latex?k%5Cin%5BK%5D"> の形状母数 <img src="https://latex.codecogs.com/png.latex?%5Cnu_k"> と位置母数 <img src="https://latex.codecogs.com/png.latex?%5Cmu_k"> に階層構造 <span id="eq-nu"><img src="https://latex.codecogs.com/png.latex?%0A%5Clog(%5Cnu_k)=%5Calpha_k%5Csim%5Cmathrm%7BN%7D(0,%5Csigma_%5Calpha%5E2)%0A%5Ctag%7B2%7D"></span> <span id="eq-mu"><img src="https://latex.codecogs.com/png.latex?%0A%5Clog(%5Cmu_k)=%5Cbeta_%7Bk,0%7D+%5Csum_%7Bj%5Cin%5Cleft%5C%7Bj%5Cin%5Bp%5D%5Cmid%5Cgamma_%7Bkj%7D=1%5Cright%5C%7D%7Dx_j%5Cbeta_%7Bk,j%7D,%5Cqquad%5Cbeta_%7Bk,0%7D%5Csim%5Cmathrm%7BN%7D(0,%5Csigma_%7B%5Cbeta_0%7D%5E2)%0A%5Ctag%7B3%7D"></span> を考える．ただし，<img src="https://latex.codecogs.com/png.latex?%5Cgamma_%7Bk,j%7D%5Cin2"> は共変量 <img src="https://latex.codecogs.com/png.latex?x_j"> が <img src="https://latex.codecogs.com/png.latex?k%5Cin%5BK%5D"> 番目の部分モデルに参加するかどうかを決める指示変数とする．</p>
<p>残っているパラメータ <img src="https://latex.codecogs.com/png.latex?%5Cbeta_%7Bk,j%7D%5C;(j%5Cin%5Bp%5D)"> には <img src="https://latex.codecogs.com/png.latex?%0A%5Cbeta_%7Bk,j%7D%5Csim(1-%5Comega)%5Cdelta_0+%5Comega%5Coperatorname%7BN%7D(0,%5Csigma_%5Cbeta%5E2)%0A"> と spike-and-slab 事前分布 <span class="citation" data-cites="Mitchell-Beauchamp1988">(Mitchell and Beauchamp, 1988)</span> を仮定し，変数選択を促進する．</p>
<p>以降，<img src="https://latex.codecogs.com/png.latex?%5Ctheta_k=(%5Cnu_k,%5Cmu_k)"> とし，<img src="https://latex.codecogs.com/png.latex?(K,%5Cgamma,%5Ctheta)"> を本モデルのパラメータとする．</p>
</section>
<section id="第二階層" class="level4" data-number="1.8.2">
<h4 data-number="1.8.2" class="anchored" data-anchor-id="第二階層"><span class="header-section-number">1.8.2</span> 第二階層</h4>
<p><img src="https://latex.codecogs.com/png.latex?%5Csigma_%5Calpha%5E2=2,%5Csigma_%7B%5Cbeta_0%7D%5E2=5"> は固定してしまうと，<img src="https://latex.codecogs.com/png.latex?%5Cphi:=(%5Comega,%5Csigma_%5Cbeta)"> がハイパーパラメータとして残っている．これには <img src="https://latex.codecogs.com/png.latex?%0A%5Comega%5Csim%5Coperatorname%7BBeta%7D(a,b)%0A"> <img src="https://latex.codecogs.com/png.latex?%0A%5Csigma_%5Cbeta%5Csim%5Coperatorname%7BHalfCauchy%7D(0,1)%0A"> という事前分布をおく．</p>
<p>前者はモデルのサイズについて Beta-二項分布を仮定することに等価である <span class="citation" data-cites="Ley-Steel2009">(3.1 節 Ley and Steel, 2009)</span>．後者は <span class="citation" data-cites="Gelman2006">(Gelman, 2006)</span>, <span class="citation" data-cites="Polson-Scott2012">(Polson and Scott, 2012)</span> の推奨の通りである．</p>
</section>
<section id="sec-prior-of-PX" class="level4" data-number="1.8.3">
<h4 data-number="1.8.3" class="anchored" data-anchor-id="sec-prior-of-PX"><span class="header-section-number">1.8.3</span> <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BP%7D(E)"> 上の事前分布</h4>
<p>実はまだ第一階層のパラメータが残っている．ハザードの数 <img src="https://latex.codecogs.com/png.latex?K"> と <img src="https://latex.codecogs.com/png.latex?h_k"> の関数形をどうするかである．</p>
<p>ここでは Weibull 分布 <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BW%7D(%5Cnu,%5Cmu)"> と対数ロジスティック分布 <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BLL%7D(%5Cnu,%5Cmu)"> の２つ <img src="https://latex.codecogs.com/png.latex?%0AD=%5C%7B%5Cmathrm%7BW%7D(%5Cnu,%5Cmu),%5Cmathrm%7BLL%7D(%5Cnu,%5Cmu)%5C%7D%0A"> から等確率で <img src="https://latex.codecogs.com/png.latex?%0AK%5Csim%5Cmathrm%7BPois%7D_%7B%3E0%7D(%5Cxi)%0A"> 個選ぶこととする．</p>
<p>ハイパーパラメータ <img src="https://latex.codecogs.com/png.latex?%5Cxi"> については，<span class="citation" data-cites="Hardcastle+2024">(Hardcastle et al., 2024)</span> では <img src="https://latex.codecogs.com/png.latex?%5Cxi=2"> としている．この根拠は <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BP%7D%5BK%3E4%5D%5Capprox0.061%0A"> であることとしている．</p>
</section>
<section id="部分的な階層モデル" class="level4" data-number="1.8.4">
<h4 data-number="1.8.4" class="anchored" data-anchor-id="部分的な階層モデル"><span class="header-section-number">1.8.4</span> 部分的な階層モデル</h4>
<p>元々部分的に階層化された多ハザードモデルは広く考えられていた．</p>
<p><span class="citation" data-cites="Demiris+2015">(Demiris et al., 2015)</span> は <img src="https://latex.codecogs.com/png.latex?K%5Cin%5C%7B1,2,3,4%5C%7D"> の poly-Weibull モデルを推定し，その適合具合を比較した．</p>
<p><span class="citation" data-cites="Benaglia+2015">(Benaglia et al., 2015)</span> では <img src="https://latex.codecogs.com/png.latex?K=2"> に限ったが，bi-Weibull モデルと bi-Gompertz モデルを推定し，視覚化手法によりモデルの適合具合を比較した．</p>
<p>このように個別のモデルを推定してベストのものを選び出す方法は，モデルの仮定を緩和して多くの変数を動かすようにすればするほど難しくなっていく．</p>
<p>例えば分布族も種々のものを考え，<img src="https://latex.codecogs.com/png.latex?K%5Cin%5C%7B1,2,3,4%5C%7D"> のいずれも考えるとなると，推定すべき個別のモデルは乗法的に増加していく．</p>
<p>そこで <span class="citation" data-cites="Negrin+2017">(Negrín et al., 2017)</span> は，モデルを「比較」して「選択」するよりもむしろ，ベイズモデル平均 (BMA: Bayesian Model Averaging) を用いることでモデルの不確実性を考慮しつつ最終的なモデルを得ることを提案した．</p>
<p>しかし，そのモデルは <img src="https://latex.codecogs.com/png.latex?K=2"> の Weibull 分布族にのみ限っていた．</p>
</section>
</section>
</section>
<section id="pdmp-によるベイズ競合リスク分析" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="pdmp-によるベイズ競合リスク分析"><span class="header-section-number">2</span> PDMP によるベイズ競合リスク分析</h2>
<p><span class="citation" data-cites="Hardcastle+2024">(Hardcastle et al., 2024)</span> では完全なベイズ階層 polyhazard モデルに対するサンプラーを Zig-Zag サンプラーに基づいて構成している．ここではこれを紹介する．</p>
<section id="課題" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="課題"><span class="header-section-number">2.1</span> 課題</h3>
<p>完全なベイズ階層多ハザードモデルが考えられていなかったことは，次の３つの問題によると考えられる：</p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="Zig-Zag サンプラーが挑む課題">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Zig-Zag サンプラーが挑む課題
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><u>次元の変化 (trans-dimensionality)</u></li>
</ol>
<p>ラベル <img src="https://latex.codecogs.com/png.latex?k%5Cin%5BK%5D"> が変わる毎に共変量の数が違い，従って <img src="https://latex.codecogs.com/png.latex?%5Cbeta_k"> の次元が変わる．従ってサンプラーは，次元の異なる空間の間を往復する必要がある．</p>
<ol start="2" type="1">
<li><u>尤度の変化</u></li>
</ol>
<p>加えて関数空間上にも事前分布をおいているため，<img src="https://latex.codecogs.com/png.latex?h_k"> の関数形も途中で変わる（第 1.8.3 節）．これに伴い，サンプリングするべき尤度の形も変わってしまう．</p>
<ol start="3" type="1">
<li><u>識別不可能性</u></li>
</ol>
<p>このモデルは潜在的な <img src="https://latex.codecogs.com/png.latex?K"> 個のリスクを仮定しており，全てに同等な同等な仮定をおいているため当然識別不可能である．その上事後分布が <img src="https://latex.codecogs.com/png.latex?K!"> 個の峰を持つ対称性を持ってしまう．このことは MCMC の収束を遅くする上に，最終的に得られる推定量を変に平均化してしまう恐れがある．</p>
</div>
</div>
<p>そこで局外母数 <img src="https://latex.codecogs.com/png.latex?(K,D,%5Cgamma,%5Cphi)"> と推定対象 <img src="https://latex.codecogs.com/png.latex?%5Ctheta%5Cin%5Cmathbb%7BR%7D%5E%7B2K+%5Clvert%5Cgamma%5Crvert_1%7D"> のサンプリングに，多峰性分布につよい Zig-Zag サンプラーを用いる．</p>
</section>
<section id="theta-の-zig-zag-サンプリング" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="theta-の-zig-zag-サンプリング"><span class="header-section-number">2.2</span> <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> の Zig-Zag サンプリング</h3>
<p>Zig-Zag サンプラーについては次の記事も参照：</p>
<div id="listing-lst-zigzag" class="listing quarto-float quarto-figure quarto-figure-left quarto-listing quarto-listing-container-grid anchored">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="UHJvY2VzcyUyQ1NhbXBsaW5nJTJDSnVsaWElMkNNQ01D" data-listing-date-sort="1719964800000" data-listing-file-modified-sort="1733137937480" data-listing-date-modified-sort="1721260800000" data-listing-reading-time-sort="13" data-listing-word-count-sort="2593">
<a href="../../../posts/2024/Process/ZigZag.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<!-- img(9CEB782EFEE6)[progressive=false, height=150px]:lst-zigzag:posts/2024/Process/ZigZag.html -->
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Zig-Zag 過程によるサンプリング
</h5>
<div class="card-subtitle listing-subtitle">
ジャンプと確定的な動きによる新たな MCMC 手法
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-07-03
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="TUNNQyUyQ0NvbXB1dGF0aW9uJTJDSnVsaWElMkNTYW1wbGluZw==" data-listing-date-sort="1721260800000" data-listing-file-modified-sort="1733137938516" data-listing-date-modified-sort="1724889600000" data-listing-reading-time-sort="14" data-listing-word-count-sort="2629">
<a href="../../../posts/2024/Stat/ZigZagSubsampling.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Stat/MeanOfGaussian.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Zig-Zag サンプラーのサブサンプリングによるスケーラビリティ
</h5>
<div class="card-subtitle listing-subtitle">
大規模モデル・大規模データに対する MCMC を目指して
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-07-18
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="UHJvY2VzcyUyQ1NhbXBsaW5nJTJDUg==" data-listing-date-sort="1706659200000" data-listing-file-modified-sort="1733137937476" data-listing-date-modified-sort="1719878400000" data-listing-reading-time-sort="7" data-listing-word-count-sort="1230">
<a href="../../../posts/2024/Process/PureJump.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Process/PureJump_files/figure-html/unnamed-chunk-1-1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
純粋跳躍過程の生成作用素と区分的確定的 Markov 過程
</h5>
<div class="card-subtitle listing-subtitle">
ジャンプと確定的な動きによる新たな MCMC 手法
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-01-31
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
<p>モデルが複雑であることに加えて尤度が変動することもあり，Poisson 点過程に対する解析的に上界が見つかるはずもないため，Automatic Zig-Zag <span class="citation" data-cites="Corbella+2022">(Corbella et al., 2022)</span> を Concave-Convex PDMP <span class="citation" data-cites="Sutton-Fearnhead2023">(Sutton and Fearnhead, 2023)</span> で修正して用いる．</p>
<p>続きは次稿参照：</p>
<div id="listing-lst-listing" class="listing quarto-float quarto-figure quarto-figure-left quarto-listing quarto-listing-container-grid anchored">
<div class="list grid quarto-listing-cols-1">
<div class="g-col-1" data-index="0" data-categories="QmF5ZXNpYW4lMkNNQ01DJTJDU3RhdGlzdGljcw==" data-listing-date-sort="1726099200000" data-listing-file-modified-sort="1733137938564" data-listing-date-modified-sort="1731369600000" data-listing-reading-time-sort="2" data-listing-word-count-sort="266">
<a href="../../../posts/2024/TransDimensionalModels/SurvivalAnalysis1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-center">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/TransDimensionalModels/Images/Polyhazard.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズ階層多ハザードモデル
</h5>
<div class="card-subtitle listing-subtitle">
Zig-Zag サンプラーによるモデル平均法
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>
</section>



<div id="quarto-appendix" class="default"><section id="文献紹介" class="level2 appendix" data-number="3"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3</span> 文献紹介</h2><div class="quarto-appendix-contents">

<p>生存時間解析について <span class="citation" data-cites="武冨-山本2023">(武冨奈菜美 and 山本和嬉, 2023)</span> は網羅的で入門的な日本語文献である．</p>
<p><span class="citation" data-cites="西川正子2008">(西川正子, 2008)</span> は競合リスクモデルに焦点を当てた日本語文献である．<span class="citation" data-cites="齋藤-室谷2023">(齋藤哲雄 and 室谷健太, 2023)</span>, <span class="citation" data-cites="齋藤-室谷2024">(Saito and Murotani, 2024)</span> はマルチステートモデルも扱っている．<span class="citation" data-cites="森満2016">(森満, 2016)</span> は医学者による説明が与えられている．</p>
<p>本項は <span class="citation" data-cites="Hardcastle+2024">(Hardcastle et al., 2024)</span> を大きく参考にした．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Benaglia+2015" class="csl-entry">
Benaglia, T., Jackson, C. H., and Sharples, L. D. (2015). <a href="https://doi.org/10.1002/sim.6375">Survival extrapolation in the presence of cause specific hazards</a>. <em>Statistics in Medicine</em>, <em>34</em>(5), 796–811.
</div>
<div id="ref-Berger-Sun1993" class="csl-entry">
Berger, J. O., and Sun, D. (1993). <a href="https://doi.org/10.1080/01621459.1993.10476426">Bayesian analysis for the poly-weibull distribution</a>. <em>Journal of the American Statistical Association</em>, <em>88</em>(424), 1412–1418.
</div>
<div id="ref-Corbella+2022" class="csl-entry">
Corbella, A., Spencer, S. E. F., and Roberts, G. O. (2022). <a href="https://doi.org/10.1007/s11222-022-10142-x"><span class="nocase">Automatic Zig-Zag Sampling in Practice</span></a>. <em>Statistics and Computing</em>, <em>32</em>(6), 107.
</div>
<div id="ref-Cox72-RegressionModelsLifeTables" class="csl-entry">
Cox, D. R. (1972). <a href="https://doi.org/10.1111/j.2517-6161.1972.tb00899.x">Regression models and life-tables</a>. <em>Journal of the Royal Statistical Society. Series B (Methodological)</em>, <em>34</em>(2), 187–220.
</div>
<div id="ref-Cutler-Ederer1958" class="csl-entry">
Cutler, S. J., and Ederer, F. (1958). <a href="https://doi.org/10.1016/0021-9681(58)90126-7">Maximum utilization of the life table method in analyzing survival</a>. <em>Journal of Chronic Diseases</em>, <em>8</em>(6), 699–712.
</div>
<div id="ref-Demiris+2015" class="csl-entry">
Demiris, N., Lunn, D., and Sharples, L. D. (2015). <a href="https://doi.org/10.1177/0962280211419645">Survival extrapolation using the poly-weibull model</a>. <em>Statistical Methods in Medical Research</em>, <em>24</em>(2), 287–301.
</div>
<div id="ref-Gelman2006" class="csl-entry">
Gelman, A. (2006). <a href="https://doi.org/10.1214/06-BA117A"><span class="nocase">Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper)</span></a>. <em>Bayesian Analysis</em>, <em>1</em>(3), 515–534.
</div>
<div id="ref-Hardcastle+2024" class="csl-entry">
Hardcastle, L., Livingstone, S., and Baio, G. (2024). <a href="https://arxiv.org/abs/2406.14182">Averaging polyhazard models using piecewise deterministic monte carlo with applications to data with long-term survivors</a>.
</div>
<div id="ref-Kaplan-Meier1958" class="csl-entry">
Kaplan, E. L., and Meier, P. (1958). <a href="http://www.jstor.org/stable/2281868">Nonparametric estimation from incomplete observations</a>. <em>Journal of the American Statistical Association</em>, <em>53</em>(282), 457–481.
</div>
<div id="ref-Latimer2011" class="csl-entry">
Latimer, N. R. (2011). <em>NICE DSU technical support document 14: Undertaking survival analysis for economic evaluations alongside clinical trials–estrapolation with patient-level data</em>. National Institute for Health; Care Excellence. Retrieved from <a href="https://www.sheffield.ac.uk/nice-dsu/tsds/survival-analysis">https://www.sheffield.ac.uk/nice-dsu/tsds/survival-analysis</a>
</div>
<div id="ref-Latimer2013" class="csl-entry">
Latimer, N. R. (2013). <a href="https://doi.org/10.1177/0272989X12472398">Survival analysis for economic evaluations alongside clinical trials—extrapolation with patient-level data: Inconsistencies, limitations, and a practical guide</a>. <em>Medical Decision Making</em>, <em>33</em>(6), 743–754.
</div>
<div id="ref-Ley-Steel2009" class="csl-entry">
Ley, E., and Steel, M. F. J. (2009). <a href="https://doi.org/10.1002/jae.1057">On the effect of prior assumptions in bayesian model averaging with applications to growth regression</a>. <em>Journal of Applied Econometrics</em>, <em>24</em>(4), 651–674.
</div>
<div id="ref-Louzada-Neto1999" class="csl-entry">
Louzada-Neto, F. (1999). <a href="http://www.jstor.org/stable/2533756">Polyhazard models for lifetime data</a>. <em>Biometrics</em>, <em>55</em>(4), 1281–1285.
</div>
<div id="ref-Mitchell-Beauchamp1988" class="csl-entry">
Mitchell, T. J., and Beauchamp, J. J. (1988). <a href="http://www.jstor.org/stable/2290129">Bayesian variable selection in linear regression</a>. <em>Journal of the American Statistical Association</em>, <em>83</em>(404), 1023–1032.
</div>
<div id="ref-Negrin+2017" class="csl-entry">
Negrín, M. A., Nam, J., and Briggs, A. H. (2017). <a href="https://doi.org/10.1177/0272989X16650669">Bayesian solutions for handling uncertainty in survival extrapolation</a>. <em>Medical Decision Making</em>, <em>37</em>(4), 367–376.
</div>
<div id="ref-Polson-Scott2012" class="csl-entry">
Polson, N. G., and Scott, J. G. (2012). <a href="https://doi.org/10.1214/12-BA730"><span class="nocase">On the Half-Cauchy Prior for a Global Scale Parameter</span></a>. <em>Bayesian Analysis</em>, <em>7</em>(4), 887–902.
</div>
<div id="ref-Rosin-Rammler1933" class="csl-entry">
Rosin, P., and Rammler, E. (1933). <a href="">The law governing the fineness of powdered coal</a>. <em>Journal of the Institute of Fuel</em>, <em>7</em>, 29–36.
</div>
<div id="ref-齋藤-室谷2024" class="csl-entry">
Saito, T., and Murotani, K. (2024). <a href="https://doi.org/10.5691/jjb.45.37">Competing risks and multistate modelsin oncology clinical trials</a>. <em>Japanese Journal of Biometrics</em>, <em>45</em>(1), 37–65.
</div>
<div id="ref-Sutton-Fearnhead2023" class="csl-entry">
Sutton, M., and Fearnhead, P. (2023). <a href="https://doi.org/10.1080/10618600.2023.2203735"><span class="nocase">Concave-Convex PDMP-based Sampling</span></a>. <em>Journal of Computational and Graphical Statistics</em>, <em>32</em>(4), 1425–1435.
</div>
<div id="ref-Wei1992" class="csl-entry">
Wei, L. J. (1992). <a href="https://doi.org/10.1002/sim.4780111409">The accelerated failure time model: A useful alternative to the cox regression model in survival analysis</a>. <em>Statistics in Medicine</em>, <em>11</em>(14-15), 1871–1879.
</div>
<div id="ref-森満2016" class="csl-entry">
森満. (2016). <a href="https://doi.org/10.3950/jibiinkoka.119.989">専門医に必要な統計の知識と研究デザイン</a>. <em>日本耳鼻咽喉科学会会報</em>, <em>119</em>(7), 989–992.
</div>
<div id="ref-武冨-山本2023" class="csl-entry">
武冨奈菜美, and 山本和嬉. (2023). <a href="https://doi.org/10.11329/jjssj.52.69">生存時間解析・信頼性解析のための統計モデル</a>. <em>日本統計学会誌</em>, <em>52</em>(2), 69–112.
</div>
<div id="ref-西川正子2008" class="csl-entry">
西川正子. (2008). <a href="https://doi.org/10.5691/jjb.29.141">生存時間解析における競合リスクモデル</a>. <em>計量生物学</em>, <em>29</em>(2), 141–170.
</div>
<div id="ref-齋藤-室谷2023" class="csl-entry">
齋藤哲雄, and 室谷健太. (2023). <a href="https://doi.org/10.11329/jjssj.52.221">マルチステートモデルの理論とがん臨床研究への応用</a>. <em>日本統計学会誌</em>, <em>52</em>(2), 221–267.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><span class="citation" data-cites="武冨-山本2023">(武冨奈菜美 and 山本和嬉, 2023)</span> は Halley の生命表や Daniel Bernoulli の競合リスク解析の例を挙げている．生命表については <a href="../../../posts/2023/Surveys/BayesianComp.html#sec-Graunt">ベイズ計算の稿</a> も参照．↩︎</p></li>
<li id="fn2"><p>位置母数 <img src="https://latex.codecogs.com/png.latex?%5Cmu:=%5Calpha%5E%7B-%5Cnu%7D%3E0"> の変換により第 1.3.2 節のハザード関数と見た目が異なることに注意．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Bayesian</category>
  <category>MCMC</category>
  <category>Statistics</category>
  <guid>https://162348.github.io/posts/2024/TransDimensionalModels/SurvivalAnalysis.html</guid>
  <pubDate>Thu, 12 Sep 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/TransDimensionalModels/Images/Polyhazard.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>最適輸送とは何か？</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/PX/OT.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="最適輸送に関する記事" class="level2 unnumbered unlisted">
<h2 class="unnumbered unlisted anchored" data-anchor-id="最適輸送に関する記事">最適輸送に関する記事</h2>
<div id="listing-lst-listing" class="listing quarto-float quarto-figure quarto-figure-left quarto-listing quarto-listing-container-grid anchored">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Q29tcHV0YXRpb24lMkNQKFgpJTJDUHl0aG9u" data-listing-date-sort="1710288000000" data-listing-file-modified-sort="1733137936300" data-listing-date-modified-sort="1728604800000" data-listing-reading-time-sort="26" data-listing-word-count-sort="5125">
<a href="../../../posts/2024/PX/OT1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<!-- img(9CEB782EFEE6)[progressive=false, height=150px]:lst-listing:posts/2024/PX/OT1.html -->
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
最適輸送とそのエントロピー緩和
</h5>
<div class="card-subtitle listing-subtitle">
Iterative Proportional Fitting / Sinkhorn-Knopp Algorithm
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-03-13
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>
<section id="はじめに" class="level2 unnumbered unlisted">
<h2 class="unnumbered unlisted anchored" data-anchor-id="はじめに">はじめに</h2>
<p>最適輸送問題は，変分法の黎明期に提案された，変分問題の１つである．</p>
<p>しかし，Lagrange と Hamilton による解析力学の変分原理や，Plateau 問題から続く極小曲面の理論と違い，最適輸送問題は変分法の黎明期に提案されたにも拘らず，その発展は大きく遅れた．</p>
<p>実際，<span class="citation" data-cites="Monge1781">(Monge, 1781)</span> の問題が解かれたのは <span class="citation" data-cites="Brenier1987">(Brenier, 1987)</span>，<span class="citation" data-cites="Kantorovich1942">(Kantorovich, 1942)</span> が拡張した形が厳密に解かれたのは独立な結果 <span class="citation" data-cites="Evans-Gangbo1999">(Evans and Gangbo, 1999)</span>, <span class="citation" data-cites="Ambrosio2003">(Ambrosio, 2003)</span> まで待つ必要がある．</p>
<p>そこで，本章では変分法の歴史（第 1 節）を見ることから始め，続いて <span class="citation" data-cites="Kantorovich1942">(Kantorovich, 1942)</span> の定式化と双対性理論を見る（第 2 節）．</p>
<p>Kantorovich の問題は離散空間上に限っていたが，一般の Polish 空間上の理論を第 3 節でみる．最後にまとめる（第 4 節）．</p>
</section>
<section id="sec-variational-calculus" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="sec-variational-calculus"><span class="header-section-number">1</span> 変分法の始まり</h2>
<p><a href="https://ja.wikipedia.org/wiki/変分法">変分法</a> (calculus of variations) とは，関数空間上の関数（汎函数という）の最適化問題をいう．</p>
<section id="fermat-の原理" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="fermat-の原理"><span class="header-section-number">1.1</span> Fermat の原理</h3>
<p>歴史上，最初に解析的な解答が与えられた変分法の問題は <a href="https://ja.wikipedia.org/wiki/フェルマーの原理"><strong>Fermat の原理</strong></a> <span class="citation" data-cites="Fermat1657">(Fermat, 1657)</span> である <span class="citation" data-cites="Goldstine1980">(Goldstine, 1980)</span>．</p>
<p>これは <u>光の経路は，進むのにかかる時間が停留するような曲線として実現される</u> というものであり，この原理から光の直進性や反射・屈折の法則が導かれる．</p>
<p>実は約 200 年後の <a href="https://ja.wikipedia.org/wiki/ウィリアム・ローワン・ハミルトン">Hamilton</a> は，自身の名前も冠されている Hamilton 力学の研究の前に光学の研究を行なっている．</p>
<p>そこで光の反射・屈折などの法則から Fermat の原理を逆に導き，２つの定式化が等価であることを導いた <span class="citation" data-cites="中根美知代2000">(中根美知代, 2000)</span>．その際に用いた表現が「特性関数」と呼んだ汎函数 <img src="https://latex.codecogs.com/png.latex?I"> に関する変分原理 <img src="https://latex.codecogs.com/png.latex?%0A%5Cdelta%20I=%5Cdelta%5Cint%5Cnu(x,y,z)%5C,d%5Crho=0%0A"> である．ただし <img src="https://latex.codecogs.com/png.latex?%5Cnu"> は屈折率，<img src="https://latex.codecogs.com/png.latex?%5Crho"> は線分要素であり，<img src="https://latex.codecogs.com/png.latex?%5Cdelta"> は Lagrange の変分作用素である．</p>
<p>Hamiltonian はこの定式化を光学から力学に拡張し，Hamilton 形式の力学となった．現代では Hamiltonian と呼べる量は <span class="citation" data-cites="Hamilton1834">(Hamilton, 1834)</span> で最初に出現し，「主関数」と呼ばれている <span class="citation" data-cites="中根美知代2000">(中根美知代, 2000)</span>．主関数 <img src="https://latex.codecogs.com/png.latex?I"> に対して <img src="https://latex.codecogs.com/png.latex?%5Cdelta%20I=0"> が成り立つことと，Euler-Lagrange 方程式が成り立つことが同値になる．<sup>1</sup></p>
</section>
<section id="最急降下問題" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="最急降下問題"><span class="header-section-number">1.2</span> 最急降下問題</h3>
<p>続いて <span class="citation" data-cites="Bernoulli1969">(Bernoulli, 1696)</span> にて John Bernoulli が <a href="https://ja.wikipedia.org/wiki/最速降下曲線">最急降下曲線</a> (Brachistochrone problem) <sup>2</sup> を自身の著書で取り上げた．</p>
<p>「誰も答えられなかった場合は自分の回答を発表する」というスタイルが挑戦的で，Leibniz, Newton など多くの数学者がこれに取り組んだ．John 自身は「最速の粒子の軌道は光と同じ原理で進むはずだ」との仮定から，Fermat の原理の繰り返しと見ることで幾何学的にこの問題を解いた <span class="citation" data-cites="Levi2014">(Levi, 2014)</span>．</p>
<p>同時に関連する複数の「変分問題」を発表した．これを <span class="citation" data-cites="Euler1744">(Euler, 1744)</span> が組織的に取り上げるとともに，<strong>変分法</strong> の名前をつけた．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題（最急降下曲線）">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題（最急降下曲線）
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?%0A%5COmega:=%5Cleft%5C%7B%5Cgamma:%5Bt_0,t_1%5D%5Cto%5Cmathbb%7BR%7D%5E2%5C;%5Cmiddle%7C%5C;%5Cbegin%7Barray%7D%7Bl%7D%0A%20%20%20%20%5Cgamma(t_0)=(0,0),%5Cgamma(t_1)=(a,b).%5C%5C%0A%20%20%20%20C%5E1%5Ctext%7B%E7%B4%9A%E3%81%AE%E9%99%B0%E9%96%A2%E6%95%B0%E8%A1%A8%E7%A4%BA%7Dy:%5Ba,b%5D%5Cto%5Cmathbb%7BR%7D_+%5Ctext%7B%E3%82%92%E6%8C%81%E3%81%A4%7D%5C%5C%0A%20%20%20%20%5Cgamma'(t_0)=(0,0).%0A%5Cend%7Barray%7D%5Cright%5C%7D%0A"> 上で，一様重力下で原点からより低い位置にある点 <img src="https://latex.codecogs.com/png.latex?(a,b)%5C;(a%3C0,b%3E0)"> に最も速く移動する曲線は，次の cycloid が与える： <img src="https://latex.codecogs.com/png.latex?%0A%5Cgamma(t)=C%5Cbegin%7Bpmatrix%7Dt-%5Cfrac%7B%5Csin%202t%7D%7B2%7D%5C%5C%5Cfrac%7B1%7D%7B2%7D-%5Cfrac%7B%5Ccos%202t%7D%7B2%7D%5Cend%7Bpmatrix%7D,%5Cqquad%20C%3E0,t%5Cin%5B0,t_1%5D,Ct_1-%5Cfrac%7B%5Csin%202t_1%7D%7B2%7D=a.%0A"></p>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled" title="証明">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
証明
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>まず，所要時間を表す汎関数 <img src="https://latex.codecogs.com/png.latex?S:%5COmega%5Cto%5Cmathbb%7BR%7D"> を求める．</p>
<p>位置 <img src="https://latex.codecogs.com/png.latex?x"> での速さを <img src="https://latex.codecogs.com/png.latex?v(x)"> とすると，初期条件 <img src="https://latex.codecogs.com/png.latex?v(0)=0"> より，エネルギー保存則から <img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B1%7D%7B2%7Dmv(x)%5E2=mgy(x)%20%5Cquad%5CLeftrightarrow%5Cquad%20v(x)=%5Csqrt%7B2gy(x)%7D.%0A"> 位置 <img src="https://latex.codecogs.com/png.latex?x"> までの運動の軌跡の長さ <img src="https://latex.codecogs.com/png.latex?l(x)"> は <img src="https://latex.codecogs.com/png.latex?%0Al(x)=%5Cint%5Ex_0%5Csqrt%7B1+y'(x)%5E2%7Ddx%0A"> である．以上から， <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%20%20%20%20S(%5Cgamma)%20&amp;=%20%5Cint%5E%7Bl(a)%7D_0%5Cfrac%7Bdl%7D%7Bv(x)%7D%20%5C%5C%0A%20%20%20%20&amp;=%20%5Cint%5Ea_0%5Cfrac%7B%5Csqrt%7B1+y'(x)%5E2%7D%7D%7Bv(x)%7Ddx%20=%20%5Cint%5Ea_0%5Csqrt%7B%5Cfrac%7B1+y'(x)%5E2%7D%7B2gy(x)%7D%7Ddx.%0A%5Cend%7Balign*%7D"> 改めて，<img src="https://latex.codecogs.com/png.latex?S(%5Cgamma)"> の <img src="https://latex.codecogs.com/png.latex?%5Csqrt%7B2g%7D"> 倍を <img src="https://latex.codecogs.com/png.latex?S(%5Cgamma)"> として取り直しても，極値点は変わらない． 特に，Lagrangian は <img src="https://latex.codecogs.com/png.latex?%0AL(y,y'):=%5Csqrt%7B%5Cfrac%7B1+y'%5E2%7D%7By%7D%7D%0A"> で与えられる．</p>
<p>計算すると， <img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20y%7D=%5Cfrac%7B1%7D%7B2%7D%5Cleft(%5Cfrac%7B1+y'%5E2%7D%7By%7D%5Cright)%5E%7B-%5Cfrac%7B1%7D%7B2%7D%7D%5Cleft(-%5Cfrac%7B1+y'%5E2%7D%7By%5E2%7D%5Cright)=-%5Cfrac%7B1%7D%7B2%7D%5Cfrac%7B(1+y'%5E2)%5E%7B%5Cfrac%7B1%7D%7B2%7D%7D%7D%7By%5E%7B%5Cfrac%7B3%7D%7B2%7D%7D%7D%0A"> <img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20y'%7D=%5Cfrac%7B1%7D%7B2%7D%5Cleft(%5Cfrac%7B1+y'%5E2%7D%7By%7D%5Cright)%5E%7B-%5Cfrac%7B1%7D%7B2%7D%7D2%5Cfrac%7By'%7D%7By%7D=%5Cfrac%7By'%7D%7B%5Csqrt%7By(1+y'%5E2)%7D%7D%0A"> から，Euler-Lagrange 方程式は <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%20%20%20%20-%5Cfrac%7B1%7D%7B2%7D%5Cfrac%7B(1+y'%5E2)%5E%7B%5Cfrac%7B1%7D%7B2%7D%7D%7D%7By%5E%7B%5Cfrac%7B3%7D%7B2%7D%7D%7D%20&amp;=%20%5Cfrac%7Bd%20%7D%7Bd%20x%7D%5Cfrac%7By'%7D%7B%5Csqrt%7By(1+y'%5E2)%7D%7D%20%5C%5C%0A%20%20%20%20&amp;=%20%5Cfrac%7By''%7D%7B%5Csqrt%7By(1+y'%5E2)%7D%7D+%5Cleft(-%5Cfrac%7B1%7D%7B2%7D%5Cright)%5Cfrac%7By'%7D%7B%5Cbiggr(y(1+y'%5E2)%5Cbiggl)%5E%7B%5Cfrac%7B3%7D%7B2%7D%7D%7D%5Cbiggr((1+y'%5E2)+2yy'y''%5Cbiggl)%20%5C%5C%0A%20%20%20%20&amp;=%20%5Cfrac%7By''%7D%7B%5Csqrt%7By(1+y'%5E2)%7D%7D-%5Cfrac%7B1%7D%7B2%7D%5Cfrac%7By'%7D%7B%5Csqrt%7By%5E3(1+y'%5E2)%7D%7D-%5Cfrac%7By'%5E2y''%7D%7B%5Csqrt%7By(1+y'%5E2)%5E3%7D%7D.%0A%5Cend%7Balign*%7D"> となる．両辺に <img src="https://latex.codecogs.com/png.latex?%5Csqrt%7By(1+y'%5E2)%7D"> を乗じることで <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%20%20%20%20-%5Cfrac%7B1%7D%7B2%7D%5Cfrac%7B1+y'%5E2%7D%7By%7D%20&amp;=%20y''-%5Cfrac%7B1%7D%7B2%7D%5Cfrac%7By'%7D%7By%7D-%5Cfrac%7By'%5E2y''%7D%7B1+y'%5E2%7D%20%5C%5C%0A%20%20%20%20&amp;=%20%5Cfrac%7By''%7D%7B1+y'%5E2%7D-%5Cfrac%7B1%7D%7B2%7D%5Cfrac%7By'%7D%7By%7D%0A%5Cend%7Balign*%7D"> より， <img src="https://latex.codecogs.com/png.latex?%0A-%5Cfrac%7B1%7D%7B2y%7D=%5Cfrac%7By''%7D%7B1+y'%5E2%7D%20%5Cquad%5CLeftrightarrow%20y'%5E2+2yy''+1=0%0A"> の形に同値変形出来る．同値性は因子 <img src="https://latex.codecogs.com/png.latex?y(1+y'%5E2)"> が <img src="https://latex.codecogs.com/png.latex?x=0"> の場合を除いて零にならないことによる．</p>
<p>この常備分方程式には積分因子 <img src="https://latex.codecogs.com/png.latex?y'"> が見つかり，これを両辺に乗じることで <img src="https://latex.codecogs.com/png.latex?%0Ay'+2yy'y''+y'%5E3=(y+yy'%5E2)'=0%0A"></p>
<p>を得る．よって，この第一積分を <img src="https://latex.codecogs.com/png.latex?y+yy'%5E2=C%3E0"> とおいて解を求める．なお，<img src="https://latex.codecogs.com/png.latex?y%5Cge%200"> として良いから <img src="https://latex.codecogs.com/png.latex?C%5Cge0"> が必要で，<img src="https://latex.codecogs.com/png.latex?C=0"> のとき <img src="https://latex.codecogs.com/png.latex?y=0"> より <img src="https://latex.codecogs.com/png.latex?%5COmega"> の元ではない．この条件は正規形の常微分方程式 <img src="https://latex.codecogs.com/png.latex?%0Ay'=%5Csqrt%7B%5Cfrac%7BC-y%7D%7By%7D%7D%0A"> に帰着するが，これは変数分離型であることに注目すれば， <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%20%20%20%20x%20&amp;=%20%5Cint%5Csqrt%7B%5Cfrac%7By%7D%7BC-y%7D%7Ddy+C'%20%5Cqquad%20C'%5Cin%5Cmathbb%7BR%7D%5C%5C%0A%20%20%20%20&amp;=%20%5Cint%5Cfrac%7B%5Csin%20t%7D%7B%5Ccos%20t%7D2C%5Csin%20t%5Ccos%20tdt+C'%20%5Cqquad%20y=:C%5Csin%5E2t%20%5C%5C%0A%20%20%20%20&amp;=%20C%5Cint(1-%5Ccos%202t)dt+C'%20%5C%5C%0A%20%20%20%20&amp;=%20C%5Cleft(t-%5Cfrac%7B%5Csin%202t%7D%7Bt%7D%5Cright)+C'.%0A%5Cend%7Balign*%7D"> と積分出来る．<img src="https://latex.codecogs.com/png.latex?y=0"> のとき <img src="https://latex.codecogs.com/png.latex?t=0"> で，このとき <img src="https://latex.codecogs.com/png.latex?x=0"> が必要だから，<img src="https://latex.codecogs.com/png.latex?C'=0"> を得る． 総じて， <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bcases%7D%0A%20%20%20%20x=Ct-%5Cfrac%7BC%7D%7B2%7D%5Csin%202t,%20%5C%5C%0A%20%20%20%20y=C%5Csin%5E2t=%5Cfrac%7BC%7D%7B2%7D-%5Cfrac%7BC%7D%7B2%7D%5Ccos%202t.%0A%5Cend%7Bcases%7D%20%5Cqquad%20C%3E0.%0A"></p>
</div>
</div>
</div>
</section>
<section id="euler-の直接法" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="euler-の直接法"><span class="header-section-number">1.3</span> Euler の直接法</h3>
<p><span class="citation" data-cites="Euler1744">(Euler, 1744)</span> は曲線全体の集合 <img src="https://latex.codecogs.com/png.latex?%0A%5COmega(x_0,x_1):=%5Cleft%5C%7B%5Cgamma%5Cin%20C%5E%5Cinfty(%5Bt_0,t_1%5D)%5C,%5Cmiddle%7C%5C,%5Cgamma(t_0)=x_0,%5Cgamma(t_1)=x_1%5Cright%5C%7D%0A"> 上の汎函数 <img src="https://latex.codecogs.com/png.latex?%0AS(%5Cgamma):=%5Cint%5E%7Bt_1%7D_%7Bt_0%7DL%5Ccirc%5Cgamma%5C,dt%0A"> の極値を求める一般的な方法（のちに Euler-Lagrange 方程式として知られる）を示し，それを 100 以上の具体的な問題で検証した <span class="citation" data-cites="Goldstine1980">(Goldstine, 1980)</span>．</p>
<p>しかし <span class="citation" data-cites="Euler1744">(Euler, 1744)</span> は専ら幾何学的な手法を用いており，「幾何学的でない方法の開発が望まれる」という但し書きが p.52 に付けられているという．</p>
<p>これに対して当時 19 才であった Lagrange が Euler に自身のアイデアを手紙に綴り，すぐさま非凡なアイデアを感得した Euler は Lagrange を呼び出した．</p>
<p>Lagrange の方法は，変分作用素 <img src="https://latex.codecogs.com/png.latex?%5Cdelta"> を用いた完全に代数的なもので，実際 <span class="citation" data-cites="Lagrange1788">(Lagrange, 1788)</span> は一才の図表や幾何学的な議論がなく，Newton 力学が完全に代数・解析化されている．</p>
<p>Euler ものちに Lagrange の方法が優れていることを認め，自身のスタイルを完全に Lagrange の方法に移した．</p>
<p>一方で近年，Euler の方法は具体的な構成を与えることと，数値解法との相性が良いことから，<a href="https://ja.wikipedia.org/wiki/変分法における直接解法"><strong>直接法</strong></a> (direct method) として復活を見ている <span class="citation" data-cites="Hanc2017">(Hanc, 2017)</span>．</p>
</section>
<section id="plateau-問題" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="plateau-問題"><span class="header-section-number">1.4</span> Plateau 問題</h3>
<p>Lagrange は 1760 年に，与えられた境界条件を満たす曲面の中で面積が最小になるものを決定するという，現代でいう <a href="https://en.wikipedia.org/wiki/Plateau%27s_problem"><strong>プラトー問題</strong></a> を定式化した．</p>
<p>これは現在でも変分法の中心問題の一つである．特に，一般の <img src="https://latex.codecogs.com/png.latex?n"> 次元 Euclid 空間内の <img src="https://latex.codecogs.com/png.latex?k"> 次元曲面に関するプラトー問題は，<img src="https://latex.codecogs.com/png.latex?k%5Cle%20n-2"> の場合や <img src="https://latex.codecogs.com/png.latex?n%5Cge8"> の超曲面の場合に解が滑らかでないことがある．</p>
</section>
<section id="sec-Monge" class="level3" data-number="1.5">
<h3 data-number="1.5" class="anchored" data-anchor-id="sec-Monge"><span class="header-section-number">1.5</span> 最適輸送問題</h3>
<p>最適輸送の問題はフランス革命の最中に <span class="citation" data-cites="Monge1781">(Monge, 1781)</span> によって考えられた．</p>
<p>論文のタイトルにある déblai とは掘削現場の残土のことであり，remblai は建築時の盛り土を指す．</p>
<p>掘削現場と建築現場が分離している際に，どの地点からどの地点に土をどれほど運べば，最もコストが低く済むかを考えることが Monge の問題である．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/PX/Images/Monge.png" class="img-fluid figure-img"></p>
<figcaption><span class="citation" data-cites="Villani2009">(Villani, 2009, p. 30)</span></figcaption>
</figure>
</div>
<p>現代的には <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E3"> 上のコスト <img src="https://latex.codecogs.com/png.latex?%0Ac(x,y):=%5Clvert%20x-y%5Crvert%0A"> に関する最適輸送問題である．</p>
<p>しかし <span class="citation" data-cites="Monge1781">(Monge, 1781)</span> では決定論的な解，すなわち「１箇所の掘削現場の土は全て同一の現場に輸送し，複数箇所に分割して輸送することはない」という状況に限って考察していた．</p>
</section>
<section id="最適輸送問題の特殊性" class="level3" data-number="1.6">
<h3 data-number="1.6" class="anchored" data-anchor-id="最適輸送問題の特殊性"><span class="header-section-number">1.6</span> 最適輸送問題の特殊性</h3>
<p>しかし，曲線や力学の変分問題や Plateau 問題とは異なり，<span class="citation" data-cites="Kantorovich1942">(Kantorovich, 1942)</span> が独立に定式化するまで，ほとんど目ぼしい発展はなかったのである！</p>
<p>これは他の問題と比べて確率論が重要な位置をしめるため，特に定式化が難しかったためだろうと考えられる <span class="citation" data-cites="Ambrosio2024">(Ambrosio and Quarteroni, 2024)</span>．実際，公理的な確率論の展開は <span class="citation" data-cites="Kolmogorov1933">(Kolmogorov, 1933)</span> まで待つ必要があった．</p>
<p>実際，Monge の問題が厳密に解かれたのは独立な結果 <span class="citation" data-cites="Evans-Gangbo1999">(Evans and Gangbo, 1999)</span>, <span class="citation" data-cites="Ambrosio2003">(Ambrosio, 2003)</span> まで待つ必要がある．</p>
<p>なお，のちに <span class="citation" data-cites="Kantorovich1948">(Kantorovich, 1948)</span> にて Monge の問題と関連づけているが，Kantorovich ははじめは Monge の議論がすでに存在することを知らなかったという <span class="citation" data-cites="Vershik2013">(Vershik, 2013)</span>．</p>
<!-- #### 変分法と物理学 -->
</section>
</section>
<section id="sec-Kantorovich" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="sec-Kantorovich"><span class="header-section-number">2</span> Kantorovich の定式化と最適化</h2>
<section id="はじめに-1" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="はじめに-1"><span class="header-section-number">2.1</span> はじめに</h3>
<p>最適輸送は数学，特に偏微分方程式論，非線型解析の分野で重要な道具になりつつあるが，その遥かに前から最適化，経済学の分野で活躍を始めた．</p>
<p>特に，<a href="https://en.wikipedia.org/wiki/Leonid_Kantorovich">Leonid Kantorovich</a> は線型計画法による解決から，ノーベル経済学賞を与えられている．</p>
<p>この章では Kantorovich のオリジナルの理論を離散の場合に見て，次章 3 で一般の確率測度に対して一般化する．</p>
</section>
<section id="kantorovich-の問題" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="kantorovich-の問題"><span class="header-section-number">2.2</span> Kantorovich の問題</h3>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5Ed"> 上の２つの点群 <img src="https://latex.codecogs.com/png.latex?%5C%7Bx_i%5C%7D_%7Bi=1%7D%5En,%5C%7By_j%5C%7D_%7Bj=1%7D%5Em%5Csubset%5Cmathbb%7BR%7D%5Ed"> が重み <img src="https://latex.codecogs.com/png.latex?a%5Cin%5Cmathbb%7BR%7D%5En,b%5Cin%5Cmathbb%7BR%7D%5Em"> 付きで与えられているとする： <img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi=1%7D%5Ena_i=%5Csum_%7Bj=1%7D%5Emb_j=1.%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?(x,a)"> と付値された資源を <img src="https://latex.codecogs.com/png.latex?(y,b)"> の状態に運ぶ計画の全体は，<img src="https://latex.codecogs.com/png.latex?a,b"> を周辺分布にもつ結合分布の全体として <img src="https://latex.codecogs.com/png.latex?%0AU(a,b):=%5Cleft%5C%7BP%5Cin%20M_%7Bn,m%7D(%5Cmathbb%7BR%7D)%5C,%5Cmiddle%7C%5C,P%5Cge%200,%5Csum_%7Bj=1%7D%5EmP_%7Bij%7D=a_i,%5Csum_%7Bi=1%7D%5EnP_%7Bij%7D=b_j%5Cright%5C%7D%0A"> と表せる．<sup>3</sup></p>
<p>この輸送計画のうち，コスト <img src="https://latex.codecogs.com/png.latex?C=(c(x_i,x_j))%5Cin%20M_%7Bn,m%7D(%5Cmathbb%7BR%7D)"> に関する輸送コストを最小にする計画を見つける問題を <strong><span class="citation" data-cites="Kantorovich1942">(Kantorovich, 1942)</span> の問題</strong> という： <img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_%7BP%5Cin%20U(a,b)%7D(C%7CP)_%5Cmathrm%7BHS%7D=%5Cmin_%7BP%5Cin%20U(a,b)%7D%5Csum_%7Bi=1%7D%5En%5Csum_%7Bj=1%7D%5EmC_%7Bij%7DP_%7Bij%7D.%0A"></p>
<p>実はこの問題は，凸制約 <img src="https://latex.codecogs.com/png.latex?P%5Cge0"> の下での，線型目的関数 <img src="https://latex.codecogs.com/png.latex?(C%7CP)_%5Cmathrm%7BHS%7D"> の最小化問題になっている．</p>
<p>従って，simplex 法などの線型計画法により解くことができる．</p>
</section>
<section id="機械学習への応用" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="機械学習への応用"><span class="header-section-number">2.3</span> 機械学習への応用</h3>
<p>特に <img src="https://latex.codecogs.com/png.latex?c(x,y)=d(x,y)%5Ep"> と取った場合，最適輸送コスト <img src="https://latex.codecogs.com/png.latex?%0AW_c(a,b)%20=%20%5Cmin_%7BP%20%5Cin%20U(a,b)%7D(C%7CP)%0A"> は点群の間の距離を定める．</p>
<p>このような構成は <img src="https://latex.codecogs.com/png.latex?E"> の距離 <img src="https://latex.codecogs.com/png.latex?d"> の構造のみに由来するため，Euclid 空間に限らず実行可能である．</p>
<p>すなわち最適輸送の考え方は，コスト <img src="https://latex.codecogs.com/png.latex?c"> または損失 <img src="https://latex.codecogs.com/png.latex?l"> さえ定義可能であれば，極めて一般の空間上に距離を定義することに使える．</p>
<p>特に距離 <img src="https://latex.codecogs.com/png.latex?d"> の性質を考慮した最適輸送距離は，機械学習において自然な損失関数を与える <span class="citation" data-cites="Figalli-Glaudo2023">(5.6節 Figalli and Glaudo, 2023)</span>, <span class="citation" data-cites="佐藤竜馬2023">(佐藤竜馬, 2023)</span>, <span class="citation" data-cites="Figalli-Ambrosio2024">(Figalli and Ambrosio, 2024)</span>．</p>
</section>
<section id="双対問題" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="双対問題"><span class="header-section-number">2.4</span> 双対問題</h3>
</section>
</section>
<section id="sec-OT-problem" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="sec-OT-problem"><span class="header-section-number">3</span> 一般の最適輸送問題</h2>
<section id="はじめに-2" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="はじめに-2"><span class="header-section-number">3.1</span> はじめに</h3>
<p>前節では離散空間の場合を扱った．</p>
<p>一般的には最適輸送問題の解は <a href="../../../posts/2024/Probability/Coupling.html"><strong>カップリング</strong></a> によって与えられる．</p>
<p>カップリングとは確率論的な概念であり，「輸送計画」を数学的に表現する格好の概念である．</p>
<p>逆に言えば解の表現に確率論的な発想が必要であった点が，力学や Plateau 問題における曲線や曲面が解となる変分問題とは違い，変分問題の中でも異色なものであると言える．</p>
<p>そこでまずカップリングの概念を定義し，一般の空間上での最適輸送問題を定式化する．</p>
</section>
<section id="カップリング" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="カップリング"><span class="header-section-number">3.2</span> カップリング</h3>
<p>可測空間 <img src="https://latex.codecogs.com/png.latex?E"> 上の２つの確率分布 <img src="https://latex.codecogs.com/png.latex?%5Cmu,%5Cnu%5Cin%5Cmathcal%7BP%7D(E)"> の <a href="https://en.wikipedia.org/wiki/Coupling_(probability)"><strong>カップリング</strong></a> または <strong>輸送計画</strong> とは，<img src="https://latex.codecogs.com/png.latex?%5Cmu,%5Cnu"> を２つの周辺分布にもつ <img src="https://latex.codecogs.com/png.latex?E%5E2"> 上の Radon 確率測度 <img src="https://latex.codecogs.com/png.latex?%5Cpi%5Cin%20P(E%5E2)"> をいう．</p>
<p>カップリングの全体を <img src="https://latex.codecogs.com/png.latex?%0AC(%5Cmu,%5Cnu):=%5Cleft%5C%7B%5Cpi%5Cin%20P(E%5E2)%5C:%5Cmiddle%7C%5C:%5Csubstack%7B(%5Cmathrm%7Bpr%7D_1)_*%5Cpi=%5Cmu,%5C%5C(%5Cmathrm%7Bpr%7D_2)_*%5Cpi=%5Cnu.%7D%5Cright%5C%7D%0A"> で表す．<sup>4</sup></p>
<p>この名前の由来は，次の分解を与える <a href="../../../posts/2024/Probability/Kernel.html">確率核</a> <img src="https://latex.codecogs.com/png.latex?P"> を考えるとわかる： <img src="https://latex.codecogs.com/png.latex?%0A%5Cpi(dxdy)=%5Cmu(dx)P(x,dy)%0A"></p>
<div class="callout callout-style-simple callout-caution no-icon callout-titled" title="独立カップリング">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
独立カップリング
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?%5Cpi:=%5Cmu%5Cotimes%5Cnu"> を <strong>独立カップリング</strong> (trivial coupling) という．この場合， <img src="https://latex.codecogs.com/png.latex?%0AP(x,dy)=%5Cnu(dy),%5Cqquad%20x%5Cin%20E,%0A"> が成り立つ．</p>
<p>独立カップリング <img src="https://latex.codecogs.com/png.latex?(X,Y)%5Csim%5Cpi"> について，<img src="https://latex.codecogs.com/png.latex?X"> を <img src="https://latex.codecogs.com/png.latex?Y"> で条件付けても分布は変わらない．</p>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon callout-titled" title="確定カップリング / Monge カップリング">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
確定カップリング / Monge カップリング
</div>
</div>
<div class="callout-body-container callout-body">
<p>一方で，ある関数 <img src="https://latex.codecogs.com/png.latex?T:E%5Cto%20E"> が存在して， <img src="https://latex.codecogs.com/png.latex?%0AP(x,dy)=%5Cdelta_%7BT(x)%7D(dy)%0A"> を満たすカップリングを <strong>確定カップリング</strong> (deterministic coupling) または Monge カップリングという．</p>
<p>このとき <img src="https://latex.codecogs.com/png.latex?T_*%5Cmu=%5Cnu"> の関係があり，<img src="https://latex.codecogs.com/png.latex?T"> は変数変換としても働く．この <img src="https://latex.codecogs.com/png.latex?T"> を <strong>輸送写像</strong> (transport map) または Monge 輸送計画という．<sup>5</sup></p>
</div>
</div>
</section>
<section id="最適輸送問題" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="最適輸送問題"><span class="header-section-number">3.3</span> 最適輸送問題</h3>
<p>最適輸送問題は２地点間の輸送コストを表す関数 <img src="https://latex.codecogs.com/png.latex?%0Ac:E%5Ctimes%20E%5Cto%5Cmathbb%7BR%7D_+%0A"> と，開始・終了時点での資源の密度分布 <img src="https://latex.codecogs.com/png.latex?%5Cmu,%5Cnu%5Cin%5Cmathcal%7BP%7D(E)"> に関して定まるもので，輸送にかかる総コストの最小化を図る．</p>
<p>輸送計画はカップリング <img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Cin%20C(%5Cmu,%5Cnu)"> として定式化でき，このことを用いると <strong>Kantorovich の最適輸送問題</strong> は <img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_%7B%5Ckappa%5Cin%20C(%5Cmu,%5Cnu)%7D%5Cint_%7BE%5Ctimes%20E%7Dc(x,y)%5Ckappa(dxdy)%0A"> と定式化できる．</p>
</section>
<section id="monge-の輸送計画" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="monge-の輸送計画"><span class="header-section-number">3.4</span> Monge の輸送計画</h3>
<p>一方で <strong>Monge の最適輸送問題</strong> は，この解を Monge カップリングの中で探す（第 1.5 節）．<sup>6</sup></p>
<p>この制約は極めて強く，一般に解が存在するとは限らない．実際 Monge の問題では，一箇所の資源を分割しそれぞれを別の目的地に運ぶことが許されないから，Delta 測度は Delta 測度以外に輸送することが出来ないことになる．<sup>7</sup></p>
<p>Kantorovich の最適輸送問題は，極めて一般的な設定で最適カップリング <img src="https://latex.codecogs.com/png.latex?%5Cpi%5Cin%20C(%5Cmu,%5Cnu)"> の存在が保証される．</p>
<p>さらに，<img src="https://latex.codecogs.com/png.latex?c"> が <img src="https://latex.codecogs.com/png.latex?E"> 上の距離様の関数である場合，最適輸送コストも距離様の性質を満たすため，確率分布の間の距離を構成することができる．</p>
</section>
<section id="最適輸送計画" class="level3" data-number="3.5">
<h3 data-number="3.5" class="anchored" data-anchor-id="最適輸送計画"><span class="header-section-number">3.5</span> 最適輸送計画</h3>
<p><img src="https://latex.codecogs.com/png.latex?d:E%5Ctimes%20E%5Cto%5Cmathbb%7BR%7D_+"> は距離公理のうち三角不等式のみ満たさない可測関数とする．これを <strong>半距離</strong> とここでは呼ぶ．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義 (coupling / optimal cost distance)^[[@Kulik2018 p.122], [@Villani2009 p.10] も参照．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定義 (coupling / optimal cost distance)<sup>8</sup>
</div>
</div>
<div class="callout-body-container callout-body">
<p>半距離 <img src="https://latex.codecogs.com/png.latex?d"> が <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BP%7D(E)"> 上に定める <strong>カップリング距離</strong> または <strong>最適輸送距離</strong> とは，<strong>Monge-Kantorovich 最小化問題</strong> の解 <img src="https://latex.codecogs.com/png.latex?%0Ad(%5Cmu,%5Cnu):=%5Cinf_%7B%5Ckappa%5Cin%20C(%5Cmu,%5Cnu)%7D%5Cint_%7BE%5E2%7Dd(x,y)%5Ckappa(dxdy)%0A"> をいう．</p>
<p>下界を達成するカップリング <img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Cin%20C(%5Cmu,%5Cnu)"> を <strong><img src="https://latex.codecogs.com/png.latex?d">-最適カップリング</strong> または <strong>最適輸送計画</strong> といい，その全体を <img src="https://latex.codecogs.com/png.latex?C_%5Cmathrm%7Bopt%7D(%5Cmu,%5Cnu)"> と表す．</p>
</div>
</div>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="最適輸送計画の存在^[[@Kulik2018 p.124] 命題4.3.3，[@Villani2009 p.10] も参照．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
最適輸送計画の存在<sup>9</sup>
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?E"> が Polish 空間，半距離 <img src="https://latex.codecogs.com/png.latex?d"> が下半連続であるとする： <img src="https://latex.codecogs.com/png.latex?%0Ad(x,y)%5Cle%5Climinf_%7Bn%5Cto%5Cinfty%7Dd(x_n,y_n).%0A"> このとき，最適輸送計画が存在する：<img src="https://latex.codecogs.com/png.latex?C_%5Cmathrm%7Bopt%7D(%5Cmu,%5Cnu)%5Cne%5Cemptyset">．</p>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled" title="証明">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
証明
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><u><img src="https://latex.codecogs.com/png.latex?C(%5Cmu,%5Cnu)%5Csubset%5Cmathcal%7BP%7D(E%5E2)"> は一様に緊密である</u></p>
<p>実際， <img src="https://latex.codecogs.com/png.latex?%5Cmu,%5Cnu%5Cin%5Cmathcal%7BP%7D(E)"> は緊密であるから，任意の <img src="https://latex.codecogs.com/png.latex?%5Cepsilon%3E0"> に対して，ある <img src="https://latex.codecogs.com/png.latex?K_1,K_2%5Coverset%7B%5Ctextrm%7Bcpt%7D%7D%7B%5Csubset%7DE"> が存在して，</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmu(K_1)%5Cge1-%5Cfrac%7B%5Cepsilon%7D%7B2%7D,%5Cqquad%5Cnu(K_2)%5Cge1-%5Cfrac%7B%5Cepsilon%7D%7B2%7D.%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?K:=K_1%5Ctimes%20K_2"> と定めると，任意の <img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Cin%20C(%5Cmu,%5Cnu)"> に対して，Bonferroniの不等式から次が成り立つ：</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ckappa(K)=%5Ckappa%5Cbiggr((K_1%5Ctimes%20K)%5Ccap(K%5Ctimes%20K_2)%5Cbiggl)%5Cge1-%5Cepsilon.%0A"></p>
<p><u>構成</u></p>
<p>任意の <img src="https://latex.codecogs.com/png.latex?n%5Cin%5Cmathbb%7BN%7D%5E+"> に対して，ある <img src="https://latex.codecogs.com/png.latex?(%5Cxi_n,%5Ceta_n)%5Cin%20C(%5Cmu,%5Cnu)"> が存在して，</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D%5Bd(%5Cxi_n,%5Ceta_n)%5D%5Cle%20d(%5Cmu,%5Cnu)+%5Cfrac%7B1%7D%7Bn%7D.%0A"></p>
<p>このとき <img src="https://latex.codecogs.com/png.latex?%5Clim_%7Bn%5Cto%5Cinfty%7D%5Coperatorname%7BE%7D%5Bd(%5Cxi_n,%5Ceta_n)%5D=d(%5Cmu,%5Cnu)"> であることに注意． <img src="https://latex.codecogs.com/png.latex?C(%5Cmu,%5Cnu)"> は一様に緊密であったから，Prohorovの定理より，ある部分列 <img src="https://latex.codecogs.com/png.latex?%5C%7B(%5Cxi_%7Bn_k%7D,%5Ceta_%7Bn_k%7D)%5C%7D"> が存在して， ある極限 <img src="https://latex.codecogs.com/png.latex?(%5Cxi,%5Ceta)"> に収束する．このとき，射影 <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Bpr%7D_i:E%5E2%5Cto%20E"> は連続であることより，各成分も弱収束するから，やはり <img src="https://latex.codecogs.com/png.latex?(%5Cxi,%5Ceta)%5Cin%20C(%5Cmu,%5Cnu)"> ． Skorohodの定理から，ある確率変数列 <img src="https://latex.codecogs.com/png.latex?%5C%7B(%5Cwidetilde%7B%5Cxi%7D_k,%5Cwidetilde%7B%5Ceta%7D_k)%5C%7D"> と <img src="https://latex.codecogs.com/png.latex?(%5Cwidetilde%7B%5Cxi%7D,%5Cwidetilde%7B%5Ceta%7D)"> が存在して， <img src="https://latex.codecogs.com/png.latex?(%5Cwidetilde%7B%5Cxi%7D_k,%5Cwidetilde%7B%5Ceta%7D_k)%5Cxrightarrow%7B%5C;%5Ctext%7Ba.s.%7D%7D(%5Cwidetilde%7B%5Cxi%7D,%5Cwidetilde%7B%5Ceta%7D)"> ．</p>
<p><u>証明の完了</u></p>
<p>すると <img src="https://latex.codecogs.com/png.latex?d"> の下半連続性から，</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ad(%5Cwidetilde%7B%5Cxi%7D,%5Cwidetilde%7B%5Ceta%7D)%5Cle%5Climinf_%7Bk%5Cto%5Cinfty%7Dd(%5Cwidetilde%7B%5Cxi%7D_k,%5Cwidetilde%7B%5Ceta%7D_k).%0A"></p>
<p>この不等式を，Fatouの補題と併せると，</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D%5Bd(%5Cwidetilde%7B%5Cxi%7D,%5Cwidetilde%7B%5Ceta%7D)%5D%5Cle%5Coperatorname%7BE%7D%5Cleft%5B%5Climinf_%7Bk%5Cto%5Cinfty%7D%20d(%5Cwidetilde%7B%5Cxi%7D_k,%5Cwidetilde%7B%5Ceta%7D_k)%5Cright%5D%5Cle%5Climinf_%7Bk%5Cto%5Cinfty%7D%5Coperatorname%7BE%7D%5Bd(%5Cwidetilde%7B%5Cxi%7D_k,%5Cwidetilde%7B%5Ceta%7D_k)%5D=%5Climinf_%7Bk%5Cto%5Cinfty%7D%5Coperatorname%7BE%7D%5Bd(%5Cxi_k,%5Ceta_k)%5D=d(%5Cmu,%5Cnu).%0A"></p>
</div>
</div>
</div>
</section>
<section id="双対問題-1" class="level3" data-number="3.6">
<h3 data-number="3.6" class="anchored" data-anchor-id="双対問題-1"><span class="header-section-number">3.6</span> 双対問題</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題 [@Kantorovich1940]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題 <span class="citation" data-cites="Kantorovich1940">(Kantorovich, 1940)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p>次の等式が，両辺が有限である限り成り立つ： <img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_%7B%5Ckappa%5Cin%20C(%5Cmu,%5Cnu)%7D%5Cint_%7BE%5E2%7Dd(x,y)%5Ckappa(dxdy)=%5Cmax_%7B%5Cvarphi(x)+%5Cpsi(y)+c(x,y)%5Cge0%7D%5Cint_E-%5Cphi%5C,d%5Cmu+%5Cint_Y-%5Cpsi%5C,d%5Cnu.%0A"></p>
</div>
</div>
</section>
</section>
<section id="sec-OT-math" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="sec-OT-math"><span class="header-section-number">4</span> 最適輸送と数学</h2>
<section id="はじめに-3" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="はじめに-3"><span class="header-section-number">4.1</span> はじめに</h3>
<p>連続体力学における連続方程式，多孔質媒体方程式をはじめとして，種々の方程式は密度 <img src="https://latex.codecogs.com/png.latex?%5Crho_t"> に関する微分方程式になっている．</p>
<p>だが，密度とは本質的に確率測度として理解できる．物理的には点群であるような対象は，むしろ確率測度と見た方が直接的である．</p>
<p>１つの方程式を関数方程式と測度方程式の両面で解釈することができるとき，前者を Euler 流，後者を Lagrange 流の解釈ともいう <span class="citation" data-cites="Villani2009">(Villani, 2009, p. 14)</span>．</p>
<p>最適輸送理論の大きな貢献の１つに，従来 Euler 流に解釈されていたものを，Lagrange 流に解釈し直す方法を与えることが挙げられる <span class="citation" data-cites="Ambrosio2024">(Ambrosio and Quarteroni, 2024)</span>．</p>
</section>
<section id="連続方程式" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="連続方程式"><span class="header-section-number">4.2</span> 連続方程式</h3>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="連続方程式 / 質量保存の法則^[[@Ambrosio+2008 p.183] 定理8.3.1 は [@Villani2009 p.14] にも取り上げられている．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
連続方程式 / 質量保存の法則<sup>10</sup>
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?M"> を <img src="https://latex.codecogs.com/png.latex?C%5E1">-Riemann 多様体，<img src="https://latex.codecogs.com/png.latex?F:%5B0,T)%5Ctimes%20M%5Cto%20TM"> を可測なベクトル場とする．<img src="https://latex.codecogs.com/png.latex?(%5Cmu_t)_%7Bt%5Cin%5B0,T%5D%7D%5Csubset%5Cmathcal%7BP%7D(M)"> を弱連続な曲線で次を満たすとする： <img src="https://latex.codecogs.com/png.latex?%0A%5Cint%5ET_0%5Cint_M%5Clvert%20F_t(x)%5Crvert%5Cmu_t(dx)%5C,dt%3C%5Cinfty.%0A"></p>
<p>このとき，次の２条件は同値：</p>
<ol type="1">
<li><p><img src="https://latex.codecogs.com/png.latex?(%5Cmu_t)"> は <img src="https://latex.codecogs.com/png.latex?%0AF_t(%5Cphi_t(x))=%5Cfrac%7Bd%20%5Cphi_t%7D%7Bd%20t%7D(x)%0A"> を満たす確率的フロー <img src="https://latex.codecogs.com/png.latex?(%5Cphi_t)"> の分布である．</p></li>
<li><p><img src="https://latex.codecogs.com/png.latex?(%5Cmu_t)"> は次の連続方程式の弱解である： <img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%5Cpartial%20%5Cmu_t%7D%7B%5Cpartial%20t%7D+%5Coperatorname%7Bdiv%7D_x(F_t%5Cmu_t)=0.%0A"></p></li>
</ol>
<p>さらにベクトル場 <img src="https://latex.codecogs.com/png.latex?F_t"> が局所 Lipschitz 連続であるとき，<img src="https://latex.codecogs.com/png.latex?(%5Cphi_t)"> はフローを定め， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmu_t=(%5Cphi_t)_*%5Cmu_0%0A"> が成り立つ．</p>
</div>
</div>
<p>これは <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BP%7D(M)"> 上の PDE に対する特性曲線法と見ることもできる．<sup>11</sup></p>
</section>
<section id="schrödinger-橋問題" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="schrödinger-橋問題"><span class="header-section-number">4.3</span> Schrödinger 橋問題</h3>
<p>Schrödinger 橋問題 <span class="citation" data-cites="Schrodinger1931">(Schrödinger, 1931)</span>, <span class="citation" data-cites="Schrodinger1932">(Schrödinger, 1932)</span> は，確率過程の分布の空間 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BP%7D(C(%5B0,1%5D;%5Cmathbb%7BR%7D%5Ed))"> 上の次の変分問題である：</p>
</section>
</section>



<div id="quarto-appendix" class="default"><section id="文献紹介" class="level2 appendix" data-number="5"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">5</span> 文献紹介</h2><div class="quarto-appendix-contents">

<p><a href="https://springermathpodcast.buzzsprout.com/">Springer Math Podcast</a> では 2023 年に最適輸送に関連する Podcast を３つ発表しており，<span class="citation" data-cites="Ambrosio2024">(Ambrosio and Quarteroni, 2024)</span>, <span class="citation" data-cites="Figalli-Ambrosio2024">(Figalli and Ambrosio, 2024)</span>, <span class="citation" data-cites="Gigli-DeLellis2024">(Gigli and De Lellis, 2024)</span> はその記事化である．最適輸送について深入りする前に，数学的な背景を知ったり，モチベーションを上げるために格好である．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Ambrosio2003" class="csl-entry">
Ambrosio, L. (2003). <a href="https://doi.org/10.1007/978-3-540-39189-0_1">Lecture notes on optimal transport problems</a>. In <em>Mathematical aspects of evolving interfaces: Lectures given at the c.i.m.-c.i.m.e. Joint euro-summer school held in madeira, funchal, portugal, july 3-9, 2000</em>, pages 1–52. Berlin, Heidelberg: Springer Berlin Heidelberg.
</div>
<div id="ref-Ambrosio+2008" class="csl-entry">
Ambrosio, L., Gigli, N., and Savaré, G. (2008). <em><a href="https://link.springer.com/book/10.1007/978-3-7643-8722-8"><span class="nocase">Gradient Flows: In Metric Spaces and in the Space of Probability Measures</span></a></em>. Birkhäuser Basel.
</div>
<div id="ref-Ambrosio2024" class="csl-entry">
Ambrosio, L., and Quarteroni, A. (2024). <a href="https://doi.org/10.1007/978-3-031-51685-6_1">Talking about optimal transport</a>. In L. Ambrosio and A. Quarteroni, editors, <em>Conversations on optimal transport</em>, pages 1–19. Cham: Springer Nature Switzerland.
</div>
<div id="ref-Bernoulli1969" class="csl-entry">
Bernoulli, J. (1696). <a href="">Poblema novum ad cujus solution em mathematici invitantur</a>. <em>Acta Eruditorum</em>, <em>1</em>, 269.
</div>
<div id="ref-Brenier1987" class="csl-entry">
Brenier, Y. (1987). <a href="https://gallica.bnf.fr/ark:/12148/bpt6k57465590/f13.item">Decomposition polaire et réarrangement monotone des champs de vecteurs</a>. <em>Comptes Rendus de l’Académie Des Sciences - Series I - Mathematics</em>, <em>305</em>(19), 805–808.
</div>
<div id="ref-Euler1744" class="csl-entry">
Euler, L. (1744). <em><a href="">Ethodus inveniendi lineas curvas maximi minimive proprietate gaudentes sive solutio problematis isoperimetrici latissimo sensu accepti</a></em>. Lausannæ ; Genevæ : Apud Marcum-Michaelem Bousquet &amp; Socios.
</div>
<div id="ref-Evans-Gangbo1999" class="csl-entry">
Evans, L. C., and Gangbo, W. (1999). <em><a href="">Differential equations methods for the monge-kantorovich mass transfer problem</a></em>,Vol. 137. American Mathematical Society.
</div>
<div id="ref-Fermat1657" class="csl-entry">
Fermat, P. de. (1657). <a href="">Marin cureau de la chambre, la lumière (chez iacqves d’allin, paris, 1657)</a>. <em>Personal Correspondence</em>.
</div>
<div id="ref-Figalli2023" class="csl-entry">
Figalli, A. (2023). <em><a href="">An introduction to optimal transport and wasserstein gradient flows</a></em>.
</div>
<div id="ref-Figalli-Ambrosio2024" class="csl-entry">
Figalli, A., and Ambrosio, L. (2024). <a href="https://doi.org/10.1007/978-3-031-51685-6_2">Optimal transport, fields medals and beyond</a>. In L. Ambrosio and A. Quarteroni, editors, <em>Conversations on optimal transport</em>, pages 21–38. Cham: Springer Nature Switzerland.
</div>
<div id="ref-Figalli-Glaudo2023" class="csl-entry">
Figalli, A., and Glaudo, F. (2023). <em><a href="https://doi.org/10.4171/ETB/25"><span class="nocase">An Invitation to Optimal Transport, Wasserstein Distances, and Gradient Flows</span></a></em>. European Mathematical Society.
</div>
<div id="ref-Gigli-DeLellis2024" class="csl-entry">
Gigli, N., and De Lellis, C. (2024). <a href="https://doi.org/10.1007/978-3-031-51685-6_3">From moving masses to bending spaces: An excursion in metric geometry</a>. In L. Ambrosio and A. Quarteroni, editors, <em>Conversations on optimal transport</em>, pages 39–58. Cham: Springer Nature Switzerland.
</div>
<div id="ref-Goldstine1980" class="csl-entry">
Goldstine, H. H. (1980). <em><a href="https://doi.org/10.1007/978-1-4613-8106-8">A history of the calculus of variations from the 17th through the 19th century</a></em>,Vol. 5. Springer New York.
</div>
<div id="ref-Hamilton1834" class="csl-entry">
Hamilton, W. R. (1834). <a href="">On a general method in dynamics; by which the study of the motions of all free systems of attracting or repelling points is reduced to the search and differentiation of one central relation, or characteristic function.</a> <em>Philosophical Transactions of the Royal Society</em>, <em>124</em>, 247–308.
</div>
<div id="ref-Hanc2017" class="csl-entry">
Hanc, J. (2017). <em><a href="">The original euler’s calculus-of-variations method: Key to lagrangian mechanics for beginners</a></em>.
</div>
<div id="ref-Kantorovich1940" class="csl-entry">
Kantorovich, L. V. (1940). On an effective method of solving certain classes of extremal problems. <em>Doklady Akademii Nauk SSSR</em>, <em>28</em>, 212–215.
</div>
<div id="ref-Kantorovich1942" class="csl-entry">
Kantorovich, L. V. (1942). <a href="https://link.springer.com/article/10.1007/s10958-006-0049-2">On the translocation of masses</a>. <em>Doklady Akademii Nauk SSSR</em>, <em>37</em>(7-8), 227–229.
</div>
<div id="ref-Kantorovich1948" class="csl-entry">
Kantorovich, L. V. (1948). <a href="https://doi.org/10.1007/s10958-006-0050-9">On a problem of monge</a>. <em>Uspekhi Matematicheskikh Nauk</em>, <em>3</em>(2), 225–226.
</div>
<div id="ref-Kolmogorov1933" class="csl-entry">
Kolmogorov, A. N. (1933). <em><a href="https://link.springer.com/book/10.1007/978-3-642-49888-6">Grundegriffe der wahrscheinlichkeitsrechnung</a></em>,Vol. 2. Springer Berlin, Heidelberg.
</div>
<div id="ref-Kulik2018" class="csl-entry">
Kulik, A. (2018). <em><a href="https://doi.org/10.1515/9783110458930">Ergodic behavior of markov processes: With applications to limit theorems</a></em>,Vol. 67. De Gruyter: Berlin, Boston.
</div>
<div id="ref-Lagrange1788" class="csl-entry">
Lagrange, J.-L. (1788). <em><a href="">Mécanique analytique</a></em>.
</div>
<div id="ref-Levi2014" class="csl-entry">
Levi, M. (2014). Quick! Find a solution to the brachistochrone problem. In <em>SIAM news</em>. SIAM.
</div>
<div id="ref-Monge1781" class="csl-entry">
Monge, G. (1781). <em><a href="">Mémoire sur la théorie des déblais et des remblais</a></em>. Imprimerie Royale.
</div>
<div id="ref-Schrodinger1931" class="csl-entry">
Schrödinger, E. (1931). <a href="">Über die umkehrung der naturgesetze</a>. <em>Sitzungsberichte Der Preussischen Akademie Der Wissenschaften, Physikalische Mathematische Klasse</em>, <em>8</em>(9), 144–153.
</div>
<div id="ref-Schrodinger1932" class="csl-entry">
Schrödinger, E. (1932). <a href="http://eudml.org/doc/78968">Sur la théorie relativiste de l’électron et l’interprétation de la mécanique quantique</a>. <em>Annales de l’institut Henri Poincaré</em>, <em>2</em>(4), 269–310.
</div>
<div id="ref-Vershik2013" class="csl-entry">
Vershik, A. M. (2013). <a href="https://doi.org/10.1007/s00283-013-9380-x">Long history of the monge-kantorovich transportation problem</a>. <em>The Mathematical Intelligencer</em>, <em>35</em>(4), 1–9.
</div>
<div id="ref-Villani2009" class="csl-entry">
Villani, C. (2009). <em><a href="https://doi.org/10.1007/978-3-540-71050-9"><span class="nocase">Optimal Transport: Old and New</span></a></em>,Vol. 338. Springer Berlin, Heidelberg.
</div>
<div id="ref-中根美知代2000" class="csl-entry">
中根美知代. (2000). <a href="">物理学から数学へ : Hamilton-jacobi 理論の誕生 (数学史の研究)</a>. In <em>数理解析研究所講究録</em>,Vol. 1130, pages 58–71.
</div>
<div id="ref-佐藤竜馬2023" class="csl-entry">
佐藤竜馬. (2023). <em><a href="">最適輸送の理論とアルゴリズム</a></em>. 講談社サイエンティフィック.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>ホロノミック拘束系などでは．↩︎</p></li>
<li id="fn2"><p>3blue1brown の <a href="https://www.youtube.com/watch?v=Cld0p3a43fU">YouTube 動画</a> も参照．↩︎</p></li>
<li id="fn3"><p>輸送多面体 (transportation polytope) という．コスト行列 <img src="https://latex.codecogs.com/png.latex?C"> との衝突を防ぐため，ここでは <img src="https://latex.codecogs.com/png.latex?U(a,b)"> と表した．↩︎</p></li>
<li id="fn4"><p><a href="../../../static/Notations.html#subsec-distributions">Notation</a> の稿も参照．↩︎</p></li>
<li id="fn5"><p><span class="citation" data-cites="Villani2009">(Villani, 2009, p. 6)</span>, <span class="citation" data-cites="Figalli-Glaudo2023">(Def. 1.4.1 Figalli and Glaudo, 2023)</span> も参照．↩︎</p></li>
<li id="fn6"><p><span class="citation" data-cites="Figalli2023">(Figalli, 2023, p. 3)</span>, <span class="citation" data-cites="Figalli-Glaudo2023">(Figalli and Glaudo, 2023)</span> に従った．↩︎</p></li>
<li id="fn7"><p>しかし，任意の連続分布の間には輸送写像が存在する． <span class="citation" data-cites="Figalli-Glaudo2023">(Figalli and Glaudo, 2023, p. 9)</span>．↩︎</p></li>
<li id="fn8"><p><span class="citation" data-cites="Kulik2018">(Kulik, 2018, p. 122)</span>, <span class="citation" data-cites="Villani2009">(Villani, 2009, p. 10)</span> も参照．↩︎</p></li>
<li id="fn9"><p><span class="citation" data-cites="Kulik2018">(Kulik, 2018, p. 124)</span> 命題4.3.3，<span class="citation" data-cites="Villani2009">(Villani, 2009, p. 10)</span> も参照．↩︎</p></li>
<li id="fn10"><p><span class="citation" data-cites="Ambrosio+2008">(Ambrosio et al., 2008, p. 183)</span> 定理8.3.1 は <span class="citation" data-cites="Villani2009">(Villani, 2009, p. 14)</span> にも取り上げられている．↩︎</p></li>
<li id="fn11"><p><span class="citation" data-cites="Villani2009">(Villani, 2009, p. 19)</span> Bibliographical notes も参照．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>P(X)</category>
  <category>Survey</category>
  <guid>https://162348.github.io/posts/2024/PX/OT.html</guid>
  <pubDate>Tue, 03 Sep 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/PX/Images/OT.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>雑音除去過程</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Samplers/DD1.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="命題" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="命題"><span class="header-section-number">1</span> 命題</h2>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="[命題 @Haussmann-Pardoux1986]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="citation" data-cites="Haussmann-Pardoux1986">(命題 Haussmann and Pardoux, 1986)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Brown 運動 <img src="https://latex.codecogs.com/png.latex?%5C%7BB_t%5C%7D%5Csubset%5Cmathcal%7BL%7D(%5COmega;%5Cmathbb%7BR%7D%5Ed)"> と可測関数 <img src="https://latex.codecogs.com/png.latex?b:%5B0,1%5D%5Ctimes%5Cmathbb%7BR%7D%5Ed%5Cto%5Cmathbb%7BR%7D%5Ed,%5Csigma:%5B0,1%5D%5Ctimes%5Cmathbb%7BR%7D%5Ed%5Cto%20M_d(%5Cmathbb%7BR%7D)"> に関して， <img src="https://latex.codecogs.com/png.latex?%0AdX_t=b_t(X_t)%5C,dt+%5Csigma_t(X_t)%5C,dB_t,%5Cqquad%20t%5Cin%5B0,1%5D,%0A"> を Markov 過程とする．さらに次の３条件を仮定する：</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?b_t,%5Csigma_t"> は <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5Ed"> 上局所 Lipschitz 連続で，線型増大条件を満たす： <img src="https://latex.codecogs.com/png.latex?%0A%20%20%5Clvert%20b_t(x)%5Crvert+%5Clvert%5Csigma_t(x)%5Crvert%5Cle%20K(1+%5Clvert%20x%5Crvert),%5Cqquad%20x%5Cin%5Cmathbb%7BR%7D%5Ed,K%3E0.%0A%20%20"></li>
<li><img src="https://latex.codecogs.com/png.latex?X_0"> は密度 <img src="https://latex.codecogs.com/png.latex?p_0"> をもち，ある <img src="https://latex.codecogs.com/png.latex?%5Clambda%3C0"> について次を満たす： <img src="https://latex.codecogs.com/png.latex?%0A%20%20p_0%5Cin%20L%5E2((1+%5Clvert%20x%5Crvert%5E2)%5E%5Clambda%5C,dx).%0A%20%20"></li>
<li><img src="https://latex.codecogs.com/png.latex?a:=%5Csigma%5Csigma%5E%5Ctop"> は一様に正定値である <img src="https://latex.codecogs.com/png.latex?%0A%20%20a_t(x)%5Cge%5Calpha%20I_d%0A%20%20"> であるか，<img src="https://latex.codecogs.com/png.latex?%5Calpha%5E%7Bij%7D_%7Bx_ix_j%7D%5Cin%20L%5E%5Cinfty((0,1)%5Ctimes%5Cmathbb%7BR%7D%5Ed)"> である．</li>
</ul>
<p>このとき，時間反転 <img src="https://latex.codecogs.com/png.latex?%5Coverline%7BX%7D_t:=X_%7B1-t%7D"> の分布は次の SDE の解である： <img src="https://latex.codecogs.com/png.latex?%0Ad%5Coverline%7BX%7D_t=%5Coverline%7Bb%7D_t(%5Coverline%7BX%7D_t)%5C,dt+%5Coverline%7B%5Csigma%7D_t(%5Coverline%7BX%7D_t)%5C,d%5Coverline%7BB%7D_t,%5Cqquad%20t%5Cin%5B0,1%5D.%0A"> ただし，<img src="https://latex.codecogs.com/png.latex?(B_t)"> も Brown 運動で， <img src="https://latex.codecogs.com/png.latex?%0A%5Coverline%7Bb%7D%5Ei_t(x)=-b_%7B1-t%7D%5Ei(x)+%5Csum_%7Bj=1%7D%5Ed%5Cfrac%7B%5Cbiggr(a%5E%7Bij%7D_%7B1-t%7D(x)p_%7B1-t%7D(x)%5Cbiggl)_%7Bx_j%7D%7D%7Bp_%7B1-t%7D(x)%7D,%0A"> <img src="https://latex.codecogs.com/png.latex?%0A%5Coverline%7Ba%7D%5E%7Bij%7D_t(x)=a%5E%7Bij%7D_%7B1-t%7D(x),%5Cqquad%5Coverline%7B%5Csigma%7D%5E%7Bij%7D_t(x)=%5Csigma%5E%7Bij%7D_%7B1-t%7D(x).%0A"></p>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="系">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
系
</div>
</div>
<div class="callout-body-container callout-body">
<p>前の命題の３条件を満たす，ドリフト係数 <img src="https://latex.codecogs.com/png.latex?%5Csigma"> が <img src="https://latex.codecogs.com/png.latex?x%5Cin%5Cmathbb%7BR%7D%5Ed"> に依らない SDE <img src="https://latex.codecogs.com/png.latex?%0AdX_t=b_t(X_t)%5C,dt+%5Csigma_t%5C,dB_t,%5Cqquad%20t%5Cin%5B0,1%5D,%0A"> を考える．この <img src="https://latex.codecogs.com/png.latex?(X)_%7Bt%5Cin%5B0,1%5D%7D"> の時間反転は，<img src="https://latex.codecogs.com/png.latex?a_t:=%5Csigma_t%5Csigma%5E%5Ctop_t"> に関して <img src="https://latex.codecogs.com/png.latex?%0Ad%5Coverline%7BX%7D_t=%5Cbiggr(-b_%7B1-t%7D(%5Coverline%7BX%7D_t)+a_%7B1-t%7D%5Cnabla_x%5Clog%20p_%7B1-t%7D(%5Coverline%7BX%7D_t)%5Cbiggl)%5C,dt+%5Csigma_%7B1-t%7D%5C,d%5Coverline%7BB%7D_t,%5Cqquad%5Coverline%7BX%7D_0=X_1,%0A"> と分布同等になる．</p>
</div>
</div>
<p>SGM <span class="citation" data-cites="Song-Ermon2019">(Song and Ermon, 2019)</span>, <span class="citation" data-cites="Song+2021ICLR">(Song et al., 2021)</span> は， <span id="eq-OU"><img src="https://latex.codecogs.com/png.latex?%0Ab_t(x)=-x,%5Cqquad%5Csigma_t=%5Csqrt%7B2%7D,%0A%5Ctag%7B1%7D"></span> と設定し，<img src="https://latex.codecogs.com/png.latex?(X_t)"> を OU 過程とした．これは <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BN%7D_d(0,I_d)"> に全変動距離・Wasserstein 距離・<img src="https://latex.codecogs.com/png.latex?%5Cchi%5E2">-距離で<a href="../../../posts/2024/Process/Langevin.html">指数収束する</a>．</p>
<p>従って，この時間反転を <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BN%7D_d(0,I_d)"> からスタートさせることで，データ分布 <img src="https://latex.codecogs.com/png.latex?p_0"> からのサンプリングが可能になる．</p>
<p>しかしこのアイデアを実行するためには，スコア <img src="https://latex.codecogs.com/png.latex?%5Cnabla_x%5Clog%20p_%7B1-t%7D(X_t)"> の項を何らかの方法で推定する方法が必要である．</p>
</section>
<section id="スコアマッチングへの応用" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="スコアマッチングへの応用"><span class="header-section-number">2</span> スコアマッチングへの応用</h2>
<section id="はじめに" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="はじめに"><span class="header-section-number">2.1</span> はじめに</h3>
<p><a href="../../../posts/2024/Samplers/EBM.html#sec-DSM">Denoising Score Matching</a> <span class="citation" data-cites="Vincent2011">(Vincent, 2011)</span> を初めとして，<a href="../../../posts/2024/Samplers/NF3.html#sec-GFM">Generalized Flow Matching</a> <span class="citation" data-cites="Isobe+2024">(Isobe et al., 2024)</span> や Functional Flow Matching <span class="citation" data-cites="Kerrigan+2024">(Kerrigan et al., 2024)</span> は，次のような目的関数を持っている： <span id="eq-DSM-loss"><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D(%5Ctheta)=%5Coperatorname%7BE%7D%5Cbiggl%5B%5Cbiggl%7Cs_%5Ctheta(%5Cwidetilde%7BX%7D)-%5Cfrac%7BX-%5Cwidetilde%7BX%7D%7D%7B%5Csigma%5E2%7D%5Cbiggr%7C%5E2%5Cbiggr%5D,%5Cqquad%20X%5Csim%20p_0,%5Cwidetilde%7BX%7D%5Csim%20p_0*%5Cmathrm%7BN%7D(0,%5Csigma%5E2I_d).%0A%5Ctag%7B2%7D"></span></p>
<p>これはデータ <img src="https://latex.codecogs.com/png.latex?X%5Csim%20p_0"> と，それに独立な Gauss ノイズを印加したもの <img src="https://latex.codecogs.com/png.latex?%5Cwidetilde%7BX%7D"> との差分を目標としてスコアネットワーク <img src="https://latex.codecogs.com/png.latex?s_%5Ctheta"> を学習している．</p>
</section>
<section id="デノイジング過程としての見方" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="デノイジング過程としての見方"><span class="header-section-number">2.2</span> デノイジング過程としての見方</h3>
<p>データにノイズを印加する過程は，<img src="https://latex.codecogs.com/png.latex?b_t=0,%5Csigma_t=I_d"> とした SDE <img src="https://latex.codecogs.com/png.latex?%0AdX_t=dB_t,%5Cqquad%20t%5Cin%5B0,1%5D,X_0%5Csim%20p_0,%0A"> で <img src="https://latex.codecogs.com/png.latex?t=0"> から <img src="https://latex.codecogs.com/png.latex?t=%5Csigma%5E2"> まで輸送することにあたる： <img src="https://latex.codecogs.com/png.latex?%0AX_%5Csigma%5E2=X_0+(B_%7B%5Csigma%5E2%7D-B_0)%5Coverset%7B%5Ctext%7Bd%7D%7D%7B=%7D%5Cwidetilde%7BX%7D.%0A"> この時間反転は <img src="https://latex.codecogs.com/png.latex?%0Ad%5Coverline%7BX%7D_t=%5Cnabla_x%5Clog%20p_%7B1-t%7D(%5Coverline%7BX%7D_t)%5C,dt+d%5Coverline%7BB%7D_t,%5Cqquad%5Coverline%7BX%7D_0=X_1,%0A"> と分布同等になる．</p>
<p>この時間反転過程 <img src="https://latex.codecogs.com/png.latex?(%5Coverline%7BX%7D_t)"> は <img src="https://latex.codecogs.com/png.latex?%5Coverline%7BX%7D_%7B1-%5Csigma%5E2%7D=%5Cwidetilde%7BX%7D"> を <img src="https://latex.codecogs.com/png.latex?%5Coverline%7BX%7D_1=X"> まで運ぶが，この際に <img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cll1"> ならば次の関係を示唆する： <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%20%20%20%20X&amp;%5Coverset%7B%5Ctext%7Bd%7D%7D%7B=%7D%5Cwidetilde%7BX%7D+%5Cint%5E1_%7B1-%5Csigma%5E2%7D%5Cnabla_x%5Clog%20p_%7B1-t%7D(%5Coverline%7BX%7D_t)%5C,dt+%5Cepsilon%5C%5C%0A%20%20%20%20&amp;%5Capprox%5Cwidetilde%7BX%7D+%5Csigma%5E2%5Cnabla_x%5Clog%20p_0(X)+%5Cepsilon,%5Cqquad%5Cepsilon%5Csim%5Cmathrm%7BN%7D(0,%5Csigma%5E2I_d).%0A%5Cend%7Balign*%7D"> <img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cto0"> の極限で次の等号が成り立つ： <img src="https://latex.codecogs.com/png.latex?%0A%5Clim_%7B%5Csigma%5Cto0%7D%5Cfrac%7BX-%5Cwidetilde%7BX%7D%7D%7B%5Csigma%5E2%7D%5Coverset%7B%5Ctext%7Bd%7D%7D%7B=%7D%5Cnabla_x%5Clog%20p_0(X).%0A"></p>
</section>
<section id="sec-Tweedie-formula" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="sec-Tweedie-formula"><span class="header-section-number">2.3</span> Tweedie の式</h3>
<p>実は同様の式は，<img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cto0"> の極限で漸近的にではなく正の <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2%3E0"> に関しても，次の意味で成り立つ：</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?X%5Csim%20p_0,%5Cwidetilde%7BX%7D%5Csim%20p_0*%5Cmathrm%7BN%7D(0,%5Csigma%5E2I_d)=:%5Cwidetilde%7Bp%7D_0"> とする．このとき，次が成り立つ： <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D%5BX%7C%5Cwidetilde%7BX%7D=%5Cwidetilde%7Bx%7D%5D=%5Cwidetilde%7Bx%7D+%5Csigma%5E2%5Cnabla_%7B%5Cwidetilde%7Bx%7D%7D%5Clog%20%5Cwidetilde%7Bp%7D_0(%5Cwidetilde%7Bx%7D).%0A"></p>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled" title="証明">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
証明
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>一般に，<img src="https://latex.codecogs.com/png.latex?%5Cphi_%5Csigma"> を <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BN%7D_d(0,%5Csigma%5E2I_d)"> の密度関数とすると， <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D%5BX%7C%5Cwidetilde%7BX%7D=%5Cwidetilde%7Bx%7D%5D=%5Cint_%7B%5Cmathbb%7BR%7D%5Ed%7Dxp_0(x)%5Cphi_%5Csigma(%5Cwidetilde%7Bx%7D-x)%5C,dx%0A"> より， <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D%5BX%7C%5Cwidetilde%7BX%7D=%5Cwidetilde%7Bx%7D%5D-%5Cwidetilde%7Bx%7D=%5Cint_%7B%5Cmathbb%7BR%7D%5Ed%7D(x-%5Cwidetilde%7Bx%7D)p_0(x)%5Cphi_%5Csigma(%5Cwidetilde%7Bx%7D-x)%5C,dx.%0A"></p>
<p>一方で， <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%20%20%20%20&amp;%5Cqquad%5Cnabla_%7B%5Cwidetilde%7Bx%7D%7D%5Clog%5Cleft(%5Cint_%7B%5Cmathbb%7BR%7D%5Ed%7Dp_0(x)%5Cphi_%5Csigma(%5Cwidetilde%7Bx%7D-x)%5C,dx%5Cright)%5C%5C%0A%20%20%20%20&amp;=%5Cfrac%7B%5Cint_%7B%5Cmathbb%7BR%7D%5Ed%7Dp_0(x)%5Cnabla_%7B%5Cwidetilde%7Bx%7D%7D%5Cphi_%5Csigma(%5Cwidetilde%7Bx%7D-x)%5C,dx%7D%7B%5Cint_%7B%5Cmathbb%7BR%7D%5Ed%7Dp_0(x)%5Cphi_%5Csigma(%5Cwidetilde%7Bx%7D-x)%5C,dx%7D%5C%5C%0A%20%20%20%20&amp;=%5Cint_%7B%5Cmathbb%7BR%7D%5Ed%7Dp_0(x)%5Cphi_%5Csigma(%5Cwidetilde%7Bx%7D-x)%5Cfrac%7Bx-%5Cwidetilde%7Bx%7D%7D%7B%5Csigma%5E2%7D%5C,dx%5C%5C%0A%20%20%20%20&amp;=%5Cfrac%7B%5Coperatorname%7BE%7D%5BX%7C%5Cwidetilde%7BX%7D=%5Cwidetilde%7Bx%7D%5D-%5Cwidetilde%7Bx%7D%7D%7B%5Csigma%5E2%7D.%0A%5Cend%7Balign*%7D"></p>
</div>
</div>
</div>
<p>すなわち，<img src="https://latex.codecogs.com/png.latex?%5Cwidetilde%7BX%7D"> から <img src="https://latex.codecogs.com/png.latex?X"> を不偏推定しようとすることで，スコア <img src="https://latex.codecogs.com/png.latex?%5Cnabla_%7B%5Cwidetilde%7Bx%7D%7D%5Clog%5Cwidetilde%7Bp%7D(%5Cwidetilde%7Bx%7D)"> を学習することができるのである．</p>
<p>ただし，学習されるスコアは，データ分布 <img src="https://latex.codecogs.com/png.latex?p_0"> のものではなく，ノイズ分布 <img src="https://latex.codecogs.com/png.latex?%5Cwidetilde%7Bp%7D_0"> のものであることに注意．</p>
<p>これが，デノイジングスコアマッチングの目的関数 (2) の背後にある動機付けである．</p>
</section>
</section>
<section id="確率的局所化" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="確率的局所化"><span class="header-section-number">3</span> 確率的局所化</h2>
<section id="ou-過程による-sgm" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="ou-過程による-sgm"><span class="header-section-number">3.1</span> OU 過程による SGM</h3>
<p>OU 過程の例 (1) に戻ろう．OU 過程 <img src="https://latex.codecogs.com/png.latex?%0AdX_t=-X_t%5C,dt+%5Csqrt%7B2%7D%5C,dB_t%0A"> の時間反転は次と分布同等である： <span id="eq-OU-reverse"><img src="https://latex.codecogs.com/png.latex?%0Ad%5Coverline%7BX%7D_t=%5Cbiggr(%5Coverline%7BX%7D_t+2%5Cnabla_x%5Clog%20p_%7B1-t%7D(%5Coverline%7BX%7D_t)%5Cbiggl)%5C,dt+%5Csqrt%7B2%7D%5C,d%5Coverline%7BB%7D_t,%5Cqquad%5Coverline%7BX%7D_0=X_1.%0A%5Ctag%7B3%7D"></span></p>
<p>OU 過程 <img src="https://latex.codecogs.com/png.latex?(X_t)"> は <img src="https://latex.codecogs.com/png.latex?%0AX_t%5Coverset%7B%5Ctext%7Bd%7D%7D%7B=%7De%5E%7B-t%7DX_0+%5Csqrt%7B1-e%5E%7B-2t%7D%7D%5Cepsilon,%5Cqquad%20X_0%5Csim%20p_0,%5Cepsilon%5Csim%5Cmathrm%7BN%7D_d(0,I_d)%0A"> という遷移半群を持っているため，<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D%5BX_t%5D=%5Cmathcal%7BL%7D%5Be%5E%7B-t%7DX_0%5D*%5Cmathrm%7BN%7D_d(0,1-e%5E%7B-2t%7D)"> であることから，Tweedie の式 2.3 より <img src="https://latex.codecogs.com/png.latex?%0A%5Cnabla_x%5Clog%20p_t(x_t)=%5Cfrac%7B%5Coperatorname%7BE%7D%5Be%5E%7B-t%7DX_0%7CX_t=x_t%5D-x_t%7D%7B1-e%5E%7B-2t%7D%7D%0A"> を得る．従ってこのスコアを式 (3) に代入し， <img src="https://latex.codecogs.com/png.latex?%0Am_t(x_t):=%5Coperatorname%7BE%7D%5BX_0%7CtX_0+%5Csqrt%7Bt%7D%5Cepsilon=x_t%5D,%5Cqquad%20X_0%5Csim%20p_0,%5Cepsilon%5Csim%5Cmathrm%7BN%7D_d(0,I_d),%0A"> とおき， <img src="https://latex.codecogs.com/png.latex?%0A%5Ctau(t)=%5Cfrac%7B1%7D%7Be%5E%7B2t%7D-1%7D%0A"> の変数変換を施すと OU 過程の時間反転 (3) は次のように書き直せる： <span id="eq-OU-reverse-2"><img src="https://latex.codecogs.com/png.latex?%0Ad%5Coverline%7BY%7D_%5Ctau=%5Cbiggr(-%5Cfrac%7B1+%5Ctau%7D%7B%5Ctau(1+%5Ctau)%7D%5Coverline%7BY%7D_%5Ctau+%5Cfrac%7B1%7D%7B%5Csqrt%7B%5Ctau(1+%5Ctau)%7D%7Dm_%5Ctau%5Cleft(%5Csqrt%7B%5Ctau(1+%5Ctau)%7D%5Coverline%7BY%7D_%5Ctau%5Cright)%5Cbiggl)%5C,d%5Ctau+%5Cfrac%7B1%7D%7B%5Csqrt%7B%5Ctau(1+%5Ctau)%7D%7D%5C,d%5Coverline%7BB%7D_%5Ctau.%0A%5Ctag%7B4%7D"></span></p>
<p>これが <a href="../../../posts/2024/Bridges/SB1.html">denoising diffusion</a> である．</p>
</section>
<section id="もう一つのサンプリング法" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="もう一つのサンプリング法"><span class="header-section-number">3.2</span> もう一つのサンプリング法</h3>
<p><strong>確率的局所化</strong> (stochastic localization) は初め，<span class="citation" data-cites="Eldan2013">(Eldan, 2013)</span> が高次元空間内の等方的な凸体上での等周不等式を示すために構成した半マルチンゲールが基になっている．</p>
<p>確率的局所化においては，<img src="https://latex.codecogs.com/png.latex?p_0"> からのあるサンプル <img src="https://latex.codecogs.com/png.latex?x_0"> に対して，その <strong>観測過程</strong> <img src="https://latex.codecogs.com/png.latex?(Y_t)"> と呼ばれる <img src="https://latex.codecogs.com/png.latex?x_0"> のノイズ付きの観測を考える．ただし，<img src="https://latex.codecogs.com/png.latex?Y_t"> は時間が進むごとに <img src="https://latex.codecogs.com/png.latex?x_0"> に関する情報量が増えるとする．<sup>1</sup></p>
<p>例えば <img src="https://latex.codecogs.com/png.latex?%0AY_t=tx_0+B_t,%5Cqquad%20t%5Cin%5Cmathbb%7BR%7D_+,%0A"> という場合である．<img src="https://latex.codecogs.com/png.latex?B_t"> というノイズは印加されているが，<img src="https://latex.codecogs.com/png.latex?x_0"> というメッセージの内容がどんどん大きくなるため，Signal-to-noise 比は増大していく．</p>
<p>この場合については，<img src="https://latex.codecogs.com/png.latex?p_0"> が有限な二次の積率を持つならば， <img src="https://latex.codecogs.com/png.latex?%0AdY_%5Ctau=m_%5Ctau(Y_%5Ctau)%5C,d%5Ctau+dB'_%5Ctau%0A"> という SDE の解と分布同等である <span class="citation" data-cites="Liptser-Shiryaev2001-Statistics">(Liptser and Shiryaev, 2001)</span>．</p>
<p>これは式 (4) で与えた OU 過程の時間反転 <img src="https://latex.codecogs.com/png.latex?(%5Coverline%7BY%7D_%5Ctau)"> に関して，<img src="https://latex.codecogs.com/png.latex?Y_%5Ctau=%5Csqrt%7B%5Ctau(1+%5Ctau)%7D%5Coverline%7BY%7D_%5Ctau"> の関係を持つ．</p>
</section>
<section id="確率的局所化-1" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="確率的局所化-1"><span class="header-section-number">3.3</span> 確率的局所化</h3>
<p>実は <img src="https://latex.codecogs.com/png.latex?(Y_t)"> は， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmu_t:=%5Cmathcal%7BL%7D%5BX_0%7CY_t%5D%0A"> として定まる <img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7BP%7D(%5Cmathbb%7BR%7D%5Ed)">-値の確率過程 <img src="https://latex.codecogs.com/png.latex?%5C%7B%5Cmu_t%5C%7D%5Csubset%5Cmathcal%7BL%7D(%5COmega;%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed))"> について，次の性質を持つ： <img src="https://latex.codecogs.com/png.latex?%0A%5Cmu_0=%5Cmathcal%7BL%7D%5BX_0%5D=p_0%5C,d%5Cell_d,%5Cqquad%5Cmu_t%5CRightarrow%5Cdelta_%7Bx_0%7D%5Cqquad%20t%5Cto%5Cinfty,%0A"></p>
<p>実は上述のサンプリング法は，このような <img src="https://latex.codecogs.com/png.latex?p_0%5C,d%5Cell_d"> から <img src="https://latex.codecogs.com/png.latex?%5Cdelta_%7BX_0%7D%5C;(X_0%5Csim%20p_0)"> への確率過程が与えられるごとに構成できる．</p>
<p>実際，最も簡単には，重心 <img src="https://latex.codecogs.com/png.latex?%0AM_t:=%5Cint_%7B%5Cmathbb%7BR%7D%5Ed%7Dx%5C,%5Cmu_t(dx)%0A"> を計算すれば，<img src="https://latex.codecogs.com/png.latex?M_t"> は <img src="https://latex.codecogs.com/png.latex?t%5Cto%5Cinfty"> の極限で <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D%5BX_0%5D"> に収束する．</p>
<p>これが <strong>確率的局所化</strong> である．</p>
<p>確率的局所化に基づいたサンプラーは <span class="citation" data-cites="Alaoui+2022">(Alaoui et al., 2022)</span> により <a href="../../../posts/2024/Nature/StatisticalMechanics1.html#sec-SK-model">Sherrington-Kirkpatrick 模型</a> の Gibbs 分布からのサンプリングに適用され，<span class="citation" data-cites="Montanari-Wu2024">(Montanari and Wu, 2023)</span> でさらにベイズ統計への応用のために拡張されている．</p>
<p>また，最良の雑音除去拡散モデルの収束証明は確率的局所化に基づいた証明によって与えられている <span class="citation" data-cites="Benton+2024">(Benton et al., 2024)</span>．</p>
</section>
</section>
<section id="関連ページ" class="level2 unnumbered unlisted">
<h2 class="unnumbered unlisted anchored" data-anchor-id="関連ページ">関連ページ</h2>
<div id="listing-lst-listing" class="listing quarto-float quarto-figure quarto-figure-left quarto-listing quarto-listing-container-grid anchored">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="RGVlcCUyQ1Byb2Nlc3MlMkNTYW1wbGluZw==" data-listing-date-sort="1707868800000" data-listing-file-modified-sort="1733137937708" data-listing-date-modified-sort="1724371200000" data-listing-reading-time-sort="5" data-listing-word-count-sort="826">
<a href="../../../posts/2024/Samplers/Diffusion.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Samplers/Files/DDPM_outputs.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
拡散模型
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル６
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="RGVlcCUyQ05hdHVyZSUyQ1NhbXBsaW5n" data-listing-date-sort="1711756800000" data-listing-file-modified-sort="1733137937708" data-listing-date-modified-sort="1722470400000" data-listing-reading-time-sort="5" data-listing-word-count-sort="880">
<a href="../../../posts/2024/Samplers/EBM.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Samplers/Files/NCL/thumb_checkerboard.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
エネルギーベースモデル
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル５
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-03-30
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>



<div id="quarto-appendix" class="default"><section id="文献紹介" class="level2 appendix" data-number="4"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">4</span> 文献紹介</h2><div class="quarto-appendix-contents">

<p><span class="citation" data-cites="Anderson1982">(Anderson, 1982)</span> では Fokker-Planck 方程式の解に対する条件の言葉で時間反転命題を与えている．また，時間反転も，元の Brown 運動 <img src="https://latex.codecogs.com/png.latex?B_t"> と独立な Brown 運動 <img src="https://latex.codecogs.com/png.latex?%5Coverline%7BB%7D_t"> に関する SDE ではなく，その時間反転 <img src="https://latex.codecogs.com/png.latex?%5Cwidetilde%7BB%7D_t:=B_%7B1-t%7D"> に関する SDE で与えている．</p>
<p><a href="https://alexxthiery.github.io/posts/reverse_and_tweedie/reverse_and_tweedie.html#ref-efron2011tweedie">Aleandre Thiéry のブログ記事</a> や <a href="https://drive.google.com/file/d/1ipWPVNBpFy5GlQqXtSbbhB0gAJUld-yd/view">鈴木大慈氏のスライド</a>，<a href="https://metaphor.ethz.ch/x/2024/fs/401-4634-24L/">Montanari の講義資料</a> を参照した．</p>
<p>Tweedie の式は <span class="citation" data-cites="Robbins1956">(Robbins, 1956)</span> によって命名されている．<span class="citation" data-cites="Efron2011">(Efron, 2011)</span> では選択バイアスが存在する状況における経験ベイズ法に応用している．</p>
<p>確率的局所化については <span class="citation" data-cites="Montanari2023">(Montanari, 2023)</span> を参考にした．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Alaoui+2022" class="csl-entry">
Alaoui, A. E., Montanari, A., and Sellke, M. (2022). <a href="https://doi.org/10.1109/FOCS54457.2022.00038">Sampling from the sherrington-kirkpatrick gibbs measure via algorithmic stochastic localization</a>. In <em>2022 IEEE 63rd annual symposium on foundations of computer science (FOCS)</em>, pages 323–334.
</div>
<div id="ref-Anderson1982" class="csl-entry">
Anderson, B. D. O. (1982). <a href="https://doi.org/10.1016/0304-4149(82)90051-5">Reverse-time diffusion equation models</a>. <em>Stochastic Processes and Their Applications</em>, <em>12</em>(3), 313–326.
</div>
<div id="ref-Benton+2024" class="csl-entry">
Benton, J., Bortoli, V. D., Doucet, A., and Deligiannidis, G. (2024). <a href="https://arxiv.org/abs/2308.03686">Nearly <img src="https://latex.codecogs.com/png.latex?d">-linear convergence bounds for diffusion models via stochastic localization</a>.
</div>
<div id="ref-Efron2011" class="csl-entry">
Efron, B. (2011). <a href="http://www.jstor.org/stable/23239562">Tweedie’s formula and selection bias</a>. <em>Journal of the American Statistical Association</em>, <em>106</em>(496), 1602–1614.
</div>
<div id="ref-Eldan2013" class="csl-entry">
Eldan, R. (2013). <a href="https://doi.org/10.1007/s00039-013-0214-y"><span class="nocase">Thin Shell Implies Spectral Gap Up to Polylog via a Stochastic Localization Scheme</span></a>. <em>Geometric and Functional Analysis</em>, <em>23</em>(2), 532–569.
</div>
<div id="ref-Haussmann-Pardoux1986" class="csl-entry">
Haussmann, U. G., and Pardoux, E. (1986). <a href="https://doi.org/10.1214/aop/1176992362"><span class="nocase">Time Reversal of Diffusions</span></a>. <em>The Annals of Probability</em>, <em>14</em>(4), 1188–1205.
</div>
<div id="ref-Isobe+2024" class="csl-entry">
Isobe, N., Koyama, M., Zhang, J., Hayashi, K., and Fukumizu, K. (2024). <a href="https://arxiv.org/abs/2402.18839">Extended flow matching: A method of conditional generation with generalized continuity equation</a>.
</div>
<div id="ref-Kerrigan+2024" class="csl-entry">
Kerrigan, G., Migliorini, G., and Smyth, P. (2024). <a href="https://proceedings.mlr.press/v238/kerrigan24a.html">Functional flow matching</a>. In S. Dasgupta, S. Mandt, and Y. Li, editors, <em>Proceedings of the 27th international conference on artificial intelligence and statistics</em>,Vol. 238, pages 3934–3942. PMLR.
</div>
<div id="ref-Liptser-Shiryaev2001-Statistics" class="csl-entry">
Liptser, R. S., and Shiryaev, A. N. (2001). <em>Statistics of random processes i: General theory</em>. Original Russian edition published by Nauka, Moscow, 1974; Springer Berlin, Heidelberg.
</div>
<div id="ref-Montanari2023" class="csl-entry">
Montanari, A. (2023). <a href="https://arxiv.org/abs/2305.10690">Sampling, diffusions, and stochastic localization</a>.
</div>
<div id="ref-Montanari-Wu2024" class="csl-entry">
Montanari, A., and Wu, Y. (2023). <a href="https://arxiv.org/abs/2304.11449">Posterior sampling from the spiked models via diffusion processes</a>.
</div>
<div id="ref-Robbins1956" class="csl-entry">
Robbins, H. (1956). <a href="https://projecteuclid.org/ebooks/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-Third-Berkeley-Symposium-on-Mathematical-Statistics-and-Probability/chapter/An-Empirical-Bayes-Approach-to-Statistics/bsmsp/1200512992"><span class="nocase">An Empirical Bayes Approach to Statistics</span></a>. In <em>Proceedings of the third berkeley symposium on mathematical statistics and probability</em>,Vol. 1, pages 157–163.
</div>
<div id="ref-Song-Ermon2019" class="csl-entry">
Song, Y., and Ermon, S. (2019). <a href="https://proceedings.neurips.cc/paper_files/paper/2019/file/3001ef257407d5a371a96dcd947c7d93-Paper.pdf"><span class="nocase">Generative Modeling by Estimating Gradients of the Data Distribution</span></a>. In H. Wallach, H. Larochelle, A. Beygelzimer, F. dAlché-Buc, E. Fox, and R. Garnett, editors, <em>Advances in neural information processing systems</em>,Vol. 32. Curran Associates, Inc.
</div>
<div id="ref-Song+2021ICLR" class="csl-entry">
Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B. (2021). <a href="https://openreview.net/forum?id=PxTIG12RRHS"><span class="nocase">Score-Based Generative Modeling through Stochastic Differential Equations</span></a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Vincent2011" class="csl-entry">
Vincent, P. (2011). <a href="https://direct.mit.edu/neco/article/23/7/1661/7677/A-Connection-Between-Score-Matching-and-Denoising">A connection between score matching and denoising autoencoders</a>. <em>Neural Computation</em>, <em>23</em>(7), 1661–1674.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>例えば，<img src="https://latex.codecogs.com/png.latex?x_*,Y_%7Bt_2%7D,Y_%7Bt_1%7D"> が長さ３の Markov 連鎖をなす，などの意味で．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Process</category>
  <category>Sampling</category>
  <guid>https://162348.github.io/posts/2024/Samplers/DD1.html</guid>
  <pubDate>Mon, 26 Aug 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Samplers/Files/DSM.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>Skilling-Hutchinson の跡推定量</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Probability/Trace.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="命題" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="命題"><span class="header-section-number">1</span> 命題</h2>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="[@Skilling1989]-[@Hutchinson1990]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="citation" data-cites="Skilling1989">(Skilling, 1989)</span>-<span class="citation" data-cites="Hutchinson1990">(Hutchinson, 1990)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p>任意の正方行列 <img src="https://latex.codecogs.com/png.latex?A%5Cin%20M_n(%5Cmathbb%7BR%7D)"> と，<img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BV%7D%5BX%5D=I_n"> を満たす確率ベクトル <img src="https://latex.codecogs.com/png.latex?X%5Cin%5Cmathcal%7BL%7D(%5COmega;%5Cmathbb%7BR%7D%5En)"> について，</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BTr%7D(A)=%5Coperatorname%7BE%7D%5BX%5E%5Ctop%20AX%5D.%0A"></p>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled" title="証明">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
証明
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?%0AX%5E%5Ctop%20AX=%5Coperatorname%7BTr%7D(AXX%5E%5Ctop)%0A"> に注意する．これは，一般に <img src="https://latex.codecogs.com/png.latex?x,y%5Cin%5Cmathbb%7BR%7D%5En"> に対して <img src="https://latex.codecogs.com/png.latex?%0Ayx%5E%5Ctop=%5Cbegin%7Bpmatrix%7Dy_1%5C%5C%5Cvdots%5C%5Cy_n%5Cend%7Bpmatrix%7D(x_1%5C;%5Ccdots%5C;x_n)=%5Cbegin%7Bpmatrix%7Dy_1x_1&amp;%5Ccdots&amp;y_1x_n%5C%5C%5Cvdots&amp;%5Cddots&amp;%5Cvdots%5C%5Cy_nx_1&amp;%5Ccdots&amp;y_nx_n%5Cend%7Bpmatrix%7D%0A"> <img src="https://latex.codecogs.com/png.latex?%0A%5Ctherefore%5Cqquad%5Coperatorname%7BTr%7D(yx%5E%5Ctop)=x%5E%5Ctop%20y%0A"> が成り立つためである．</p>
<p>よって，次のように計算できる：</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%20%20%20%20%5Coperatorname%7BE%7D%5BX%5E%5Ctop%20AX%5D&amp;=%5Coperatorname%7BE%7D%5B%5Coperatorname%7BTr%7D(AXX%5E%5Ctop)%5D%5C%5C%0A%20%20%20%20&amp;=%5Coperatorname%7BTr%7D(%5Coperatorname%7BE%7D%5BAXX%5E%5Ctop%5D)%5C%5C%0A%20%20%20%20&amp;=%5Coperatorname%7BTr%7D(A%5Coperatorname%7BE%7D%5BXX%5E%5Ctop%5D)=%5Coperatorname%7BTr%7D(A).%0A%5Cend%7Balign*%7D"></p>
</div>
</div>
</div>
<p><span class="citation" data-cites="Hutchinson1990">(Hutchinson, 1990)</span> では <img src="https://latex.codecogs.com/png.latex?A"> を対称行列に，<img src="https://latex.codecogs.com/png.latex?X"> を中心化された確率変数に限って示されている．</p>
<p><span class="citation" data-cites="Skilling1989">(Skilling, 1989)</span> では <span class="citation" data-cites="Hutchinson1990">(Hutchinson, 1990)</span> のように命題の形では提示していないが，同様の推定量を提案しており，これと一般化跡 (generalized trace) と Chebyshev 多項式の議論を通じて，<img src="https://latex.codecogs.com/png.latex?A"> のスペクトルのベイズ推定を議論している．</p>
</section>
<section id="推定量の性質" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="推定量の性質"><span class="header-section-number">2</span> 推定量の性質</h2>
<p>実用上，<img src="https://latex.codecogs.com/png.latex?X"> の分布は標準 Gauss や Rademacher 分布などが用いられる．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題（推定量の分散）">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題（推定量の分散）
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?A%5Cin%20S_n(%5Cmathbb%7BR%7D)"> を対称行列とする．</p>
<ol type="1">
<li><p><img src="https://latex.codecogs.com/png.latex?X%5Csim%5Cmathrm%7BN%7D(0,I_n)"> のとき， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7BV%7D%5BX%5E%5Ctop%20AX%5D=2%5Coperatorname%7BTr%7D(A%5E2)=2%5C%7CA%5C%7C%5E2_%5Cmathrm%7BHS%7D.%0A"></p></li>
<li><p><img src="https://latex.codecogs.com/png.latex?X%5Csim%5Cmathrm%7BRad%7D%5E%7B%5Cotimes%20n%7D"> のとき， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7BV%7D%5BX%5E%5Ctop%20AX%5D=2%5Csum_%7Bi%5Cne%20j%7Da_%7Bij%7D%5E2.%0A"></p></li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled" title="証明^[[@Hutchinson1990 p.437], [@Avron-Toledo2011 補題9], [@Adams+2018 命題4.2] も参照．]">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
証明<sup>1</sup>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?A%5Cin%20S_n(%5Cmathbb%7BR%7D)"> が正定値対称であるとき，ある直交行列 <img src="https://latex.codecogs.com/png.latex?U%5Cin%20O_n(%5Cmathbb%7BR%7D)"> と対角行列 <img src="https://latex.codecogs.com/png.latex?%5CLambda=%5Cmathrm%7Bdiag%7D(%5Clambda_1,%5Cdots,%5Clambda_n)"> が存在して， <img src="https://latex.codecogs.com/png.latex?%0AA=U%5CLambda%20U%5E%5Ctop.%0A"> <img src="https://latex.codecogs.com/png.latex?Y:=U%5E%5Ctop%20X"> と定めるとやはり <img src="https://latex.codecogs.com/png.latex?Y%5Csim%5Cmathrm%7BN%7D(0,I_n)"> であり， <img src="https://latex.codecogs.com/png.latex?%0AX%5E%5Ctop%20AX=X%5E%5Ctop%20U%5CLambda%20U%5E%5Ctop%20X=Y%5E%5Ctop%5CLambda%20Y,%0A"> <img src="https://latex.codecogs.com/png.latex?%0A%5Ctherefore%5Cqquad%5Cmathrm%7BV%7D%5BX%5E%5Ctop%20AX%5D=2%5Csum_%7Bi=1%7D%5En%5Clambda_i%5E2=2%5Coperatorname%7BTr%7D(%5CLambda%5E2)=2%5Coperatorname%7BTr%7D(A%5E2).%0A"></li>
<li>一般の <img src="https://latex.codecogs.com/png.latex?X%5Cin%5Cmathcal%7BL%7D(%5COmega;%5Cmathbb%7BR%7D%5En)"> に関して， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7BV%7D%5BX%5E%5Ctop%20AX%5D=%5Csum_%7Bi,j,k,l=1%7D%5Ena_%7Bij%7Da_%7Bkl%7D%5Cbiggr(%5Coperatorname%7BE%7D%5BX_iX_jX_kX_l%5D-%5Coperatorname%7BE%7D%5BX_iX_j%5D%5Coperatorname%7BE%7D%5BX_kX_l%5D%5Cbiggl).%0A"></li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="系">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
系
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?A"> が対称行列で <img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7BE%7D%5BX%5D=0"> であるとき，<img src="https://latex.codecogs.com/png.latex?X"> は Rademacher とした場合が最小分散不偏推定量を定める <span class="citation" data-cites="Hutchinson1990">(Hutchinson, 1990, p. 命題1)</span>．</p>
</div>
</div>
</section>
<section id="応用" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="応用"><span class="header-section-number">3</span> 応用</h2>
<div id="listing-lst-listing" class="listing quarto-float quarto-figure quarto-figure-left quarto-listing quarto-listing-container-grid anchored">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="RGVlcCUyQ1NhbXBsaW5n" data-listing-date-sort="1707868800000" data-listing-file-modified-sort="1733137937892" data-listing-date-modified-sort="1724025600000" data-listing-reading-time-sort="3" data-listing-word-count-sort="450">
<a href="../../../posts/2024/Samplers/NF.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_result.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
正規化流
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル４
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="RGVlcCUyQ1NhbXBsaW5nJTJDUChYKQ==" data-listing-date-sort="1707868800000" data-listing-file-modified-sort="1733137937892" data-listing-date-modified-sort="1724803200000" data-listing-reading-time-sort="4" data-listing-word-count-sort="794">
<a href="../../../posts/2024/Samplers/NF1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Samplers/Files/linear/output.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ニューラル常微分方程式
</h5>
<div class="card-subtitle listing-subtitle">
シミュレーションなしの拡散モデルとしての連続正規化流
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="RGVlcCUyQ05hdHVyZSUyQ1NhbXBsaW5n" data-listing-date-sort="1711756800000" data-listing-file-modified-sort="1733137937708" data-listing-date-modified-sort="1722470400000" data-listing-reading-time-sort="5" data-listing-word-count-sort="880">
<a href="../../../posts/2024/Samplers/EBM.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Samplers/Files/NCL/thumb_checkerboard.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
エネルギーベースモデル
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル５
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-03-30
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
<ul>
<li><a href="../../../posts/2024/Samplers/NF.html#sec-Hutchinson">残差フロー (residual flow)</a> では Jacobian の推定が焦点になる．これに Skilling-Hutchinson の跡推定量を用いることができる．</li>
<li><a href="../../../posts/2024/Samplers/NF1.html">Neural ODE</a> において，Jacobian の跡 <img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7BTr%7D(J_%7BF_t%7D(x_t))"> の計算は Skilling-Hutchinson の跡推定量を用いれば <img src="https://latex.codecogs.com/png.latex?O(d)"> で済む <span class="citation" data-cites="Grathwohl+2019">(Grathwohl et al., 2019)</span>．</li>
<li><a href="../../../posts/2024/Samplers/EBM.html#sec-SSM">Sliced Score Matching</a> の目的関数は，Skilling-Hutchinson の跡推定量により Jacobian <img src="https://latex.codecogs.com/png.latex?Ds_%5Ctheta"> を推定したスコアマッチングと解釈できる．</li>
</ul>
</section>



<div id="quarto-appendix" class="default"><section id="文献紹介" class="level2 appendix" data-number="4"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">4</span> 文献紹介</h2><div class="quarto-appendix-contents">

<!-- [@Grathwohl+2019] も参考にした． -->
<p><span class="citation" data-cites="Adams+2018">(Adams et al., 2018)</span> では <span class="citation" data-cites="Skilling1989">(Skilling, 1989)</span> の研究を踏襲し，大規模行列のスペクトル（密度）推定に向けて，Skilling-Hutchinson の跡推定量の拡張が議論されている．</p>
<p><span class="citation" data-cites="Meyer+2021">(Meyer et al., n.d.)</span> では Skilling-Hutchinson の跡推定量を改良したアルゴリズムが提案されている．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Adams+2018" class="csl-entry">
Adams, R. P., Pennington, J., Johnson, M. J., Smith, J., Ovadia, Y., Patton, B., and Saunderson, J. (2018). <a href="https://arxiv.org/abs/1802.03451">Estimating the spectral density of large implicit matrices</a>.
</div>
<div id="ref-Avron-Toledo2011" class="csl-entry">
Avron, H., and Toledo, S. (2011). <a href="https://doi.org/10.1145/1944345.1944349">Randomized algorithms for estimating the trace of an implicit symmetric positive semi-definite matrix</a>. <em>J. ACM</em>, <em>58</em>(2).
</div>
<div id="ref-Grathwohl+2019" class="csl-entry">
Grathwohl, W., Chen, R. T. Q., Bettencourt, J., and Duvenaud, D. (2019). <a href="https://openreview.net/forum?id=rJxgknCcK7"><span class="nocase">Scalable Reversible Generative Models with Free-form Continuous Dynamics</span></a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Hutchinson1990" class="csl-entry">
Hutchinson, M. F. (1990). <a href="https://doi.org/10.1080/03610919008812866"><span class="nocase">A Stochastic Estimator of the Trace of the Influence Matrix for Laplacian Smoothing Splines</span></a>. <em>Communications in Statistics - Simulation and Computation</em>, <em>19</em>(2), 433–450. doi: 10.1080/03610919008812866.
</div>
<div id="ref-Meyer+2021" class="csl-entry">
Meyer, R. A., Musco, C., Musco, C., and Woodruff, D. P. (n.d.). <a href="https://doi.org/10.1137/1.9781611976496.16">Hutch++: Optimal stochastic trace estimation</a>. In <em>2021 symposium on simplicity in algorithms (SOSA)</em>, pages 142–155.
</div>
<div id="ref-Skilling1989" class="csl-entry">
Skilling, J. (1989). <a href="https://doi.org/10.1007/978-94-015-7860-8_48">The eigenvalues of mega-dimensional matrices</a>. In J. Skilling, editor, <em>Maximum entropy and bayesian methods: Cambridge, england, 1988</em>, pages 455–466. Dordrecht: Springer Netherlands.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><span class="citation" data-cites="Hutchinson1990">(Hutchinson, 1990, p. 437)</span>, <span class="citation" data-cites="Avron-Toledo2011">(Avron and Toledo, 2011, p. 補題9)</span>, <span class="citation" data-cites="Adams+2018">(Adams et al., 2018, p. 命題4.2)</span> も参照．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Probability</category>
  <category>Functional Analysis</category>
  <guid>https://162348.github.io/posts/2024/Probability/Trace.html</guid>
  <pubDate>Tue, 20 Aug 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Probability/Images/Skilling-Hutchinson.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>ニューラル常微分方程式</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Samplers/NF4.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="関連ページ" class="level3 unnumbered unlisted">
<h3 class="unnumbered unlisted anchored" data-anchor-id="関連ページ">関連ページ</h3>
<div id="listing-flow-listing" class="quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="RGVlcCUyQ1NhbXBsaW5n" data-listing-date-sort="1707868800000" data-listing-file-modified-sort="1733137937892" data-listing-date-modified-sort="1724025600000" data-listing-reading-time-sort="3" data-listing-word-count-sort="450">
<a href="../../../posts/2024/Samplers/NF.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_result.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
正規化流
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル４
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="RGVlcCUyQ1NhbXBsaW5nJTJDUChYKQ==" data-listing-date-sort="1707868800000" data-listing-file-modified-sort="1733137937892" data-listing-date-modified-sort="1724803200000" data-listing-reading-time-sort="4" data-listing-word-count-sort="794">
<a href="../../../posts/2024/Samplers/NF1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Samplers/Files/linear/output.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ニューラル常微分方程式
</h5>
<div class="card-subtitle listing-subtitle">
シミュレーションなしの拡散モデルとしての連続正規化流
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="RGVlcCUyQ1NhbXBsaW5nJTJDUHl0aG9u" data-listing-date-sort="1722643200000" data-listing-file-modified-sort="1733137937892" data-listing-date-modified-sort="1724025600000" data-listing-reading-time-sort="10" data-listing-word-count-sort="1863">
<a href="../../../posts/2024/Samplers/NF2.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Samplers/Files/NF/Glow_output.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
正規化流
</h5>
<div class="card-subtitle listing-subtitle">
<code>normflows</code> によるハンズオン
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-03
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>
<section id="事前準備" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="事前準備"><span class="header-section-number">1</span> 事前準備</h2>
<div id="3960ed9a" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> math</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> IPython.display <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> clear_output</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm_notebook <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> tqdm</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> mpl</span>
<span id="cb1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-8"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>matplotlib inline</span>
<span id="cb1-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-10">sns.color_palette(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bright"</span>)</span>
<span id="cb1-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> mpl</span>
<span id="cb1-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.cm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> cm</span>
<span id="cb1-13"></span>
<span id="cb1-14"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-15"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Tensor</span>
<span id="cb1-16"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> nn</span>
<span id="cb1-17"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.nn  <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> functional <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> F</span>
<span id="cb1-18"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.autograd <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Variable</span>
<span id="cb1-19"></span>
<span id="cb1-20">use_cuda <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cuda.is_available()</span></code></pre></div>
</details>
</div>
<p>まずは ODE ソルバーを用意する．これはどのようなものでも NODE のサブルーチンとして使うことができる．</p>
<div id="9c14e270" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> ode_solve(z0, t0, t1, f):</span>
<span id="cb2-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Simplest Euler ODE initial value solver</span></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb2-5">    h_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span></span>
<span id="cb2-6">    n_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> math.ceil((<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>(t1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> t0)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>h_max).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>().item())</span>
<span id="cb2-7"></span>
<span id="cb2-8">    h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (t1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> t0)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>n_steps</span>
<span id="cb2-9">    t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t0</span>
<span id="cb2-10">    z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z0</span>
<span id="cb2-11"></span>
<span id="cb2-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i_step <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n_steps):</span>
<span id="cb2-13">        z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> f(z, t)</span>
<span id="cb2-14">        t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> h</span>
<span id="cb2-15">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> z</span></code></pre></div>
</div>
<p>NODE では，<img src="https://latex.codecogs.com/png.latex?D_%7Bx%7DL_t"> と <img src="https://latex.codecogs.com/png.latex?D_%5Ctheta%20L_t"> とは随伴状態 <img src="https://latex.codecogs.com/png.latex?a(t)"> に関する ODE で得られる．</p>
<p>この ODE の係数を事前に自動微分を通じて計算しておくための親クラスを定義する：</p>
<div id="b003fdd6" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> ODEF(nn.Module):</span>
<span id="cb3-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> forward_with_grad(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, z, t, grad_outputs):</span>
<span id="cb3-3">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Compute f and a df/dz, a df/dp, a df/dt"""</span></span>
<span id="cb3-4">        batch_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb3-5"></span>
<span id="cb3-6">        out <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.forward(z, t)</span>
<span id="cb3-7"></span>
<span id="cb3-8">        a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> grad_outputs</span>
<span id="cb3-9">        adfdz, adfdt, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>adfdp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.autograd.grad(</span>
<span id="cb3-10">            (out,), (z, t) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.parameters()), grad_outputs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(a),</span>
<span id="cb3-11">            allow_unused<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, retain_graph<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb3-12">        )</span>
<span id="cb3-13">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># grad method automatically sums gradients for batch items, we have to expand them back</span></span>
<span id="cb3-14">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> adfdp <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb3-15">            adfdp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([p_grad.flatten() <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> p_grad <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> adfdp]).unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb3-16">            adfdp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfdp.expand(batch_size, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> batch_size</span>
<span id="cb3-17">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> adfdt <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb3-18">            adfdt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfdt.expand(batch_size, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> batch_size</span>
<span id="cb3-19">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> out, adfdz, adfdt, adfdp</span>
<span id="cb3-20"></span>
<span id="cb3-21">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> flatten_parameters(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb3-22">        p_shapes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb3-23">        flat_parameters <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb3-24">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> p <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.parameters():</span>
<span id="cb3-25">            p_shapes.append(p.size())</span>
<span id="cb3-26">            flat_parameters.append(p.flatten())</span>
<span id="cb3-27">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> torch.cat(flat_parameters)</span></code></pre></div>
</div>
</section>
<section id="neural-ode-の実装" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="neural-ode-の実装"><span class="header-section-number">2</span> Neural ODE の実装</h2>
<p>Neural ODE では誤差逆伝播の代わりに随伴感度法を用いる．</p>
<p>これは <code>torch.nn.Module</code> を継承したクラスとしては定義できないため，<code>torch.autograd.Function</code> を継承したクラスとして定義する：</p>
<div id="02ec01a1" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> ODEAdjoint(torch.autograd.Function):</span>
<span id="cb4-2">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@staticmethod</span></span>
<span id="cb4-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> forward(ctx, z0, t, flat_parameters, func):</span>
<span id="cb4-4">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(func, ODEF)</span>
<span id="cb4-5">        bs, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>z_shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z0.size()</span>
<span id="cb4-6">        time_len <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t.size(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb4-7"></span>
<span id="cb4-8">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb4-9">            z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(time_len, bs, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>z_shape).to(z0)</span>
<span id="cb4-10">            z[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z0</span>
<span id="cb4-11">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i_t <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(time_len <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>):</span>
<span id="cb4-12">                z0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ode_solve(z0, t[i_t], t[i_t<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], func)</span>
<span id="cb4-13">                z[i_t<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z0</span>
<span id="cb4-14"></span>
<span id="cb4-15">        ctx.func <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> func</span>
<span id="cb4-16">        ctx.save_for_backward(t, z.clone(), flat_parameters)</span>
<span id="cb4-17">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> z</span>
<span id="cb4-18"></span>
<span id="cb4-19">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@staticmethod</span></span>
<span id="cb4-20">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> backward(ctx, dLdz):</span>
<span id="cb4-21">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb4-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        dLdz shape: time_len, batch_size, *z_shape</span></span>
<span id="cb4-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb4-24">        func <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ctx.func</span>
<span id="cb4-25">        t, z, flat_parameters <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ctx.saved_tensors</span>
<span id="cb4-26">        time_len, bs, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>z_shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z.size()</span>
<span id="cb4-27">        n_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.prod(z_shape)</span>
<span id="cb4-28">        n_params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> flat_parameters.size(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb4-29"></span>
<span id="cb4-30">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Dynamics of augmented system to be calculated backwards in time</span></span>
<span id="cb4-31">        <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> augmented_dynamics(aug_z_i, t_i):</span>
<span id="cb4-32">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb4-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            tensors here are temporal slices</span></span>
<span id="cb4-34"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            t_i - is tensor with size: bs, 1</span></span>
<span id="cb4-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            aug_z_i - is tensor with size: bs, n_dim*2 + n_params + 1</span></span>
<span id="cb4-36"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            """</span></span>
<span id="cb4-37">            z_i, a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> aug_z_i[:, :n_dim], aug_z_i[:, n_dim:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>n_dim]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ignore parameters and time</span></span>
<span id="cb4-38"></span>
<span id="cb4-39">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Unflatten z and a</span></span>
<span id="cb4-40">            z_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z_i.view(bs, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>z_shape)</span>
<span id="cb4-41">            a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a.view(bs, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>z_shape)</span>
<span id="cb4-42">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.set_grad_enabled(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>):</span>
<span id="cb4-43">                t_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t_i.detach().requires_grad_(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb4-44">                z_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z_i.detach().requires_grad_(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb4-45">                func_eval, adfdz, adfdt, adfdp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> func.forward_with_grad(z_i, t_i, grad_outputs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>a)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># bs, *z_shape</span></span>
<span id="cb4-46">                adfdz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfdz.to(z_i) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> adfdz <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> torch.zeros(bs, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>z_shape).to(z_i)</span>
<span id="cb4-47">                adfdp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfdp.to(z_i) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> adfdp <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> torch.zeros(bs, n_params).to(z_i)</span>
<span id="cb4-48">                adfdt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfdt.to(z_i) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> adfdt <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> torch.zeros(bs, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).to(z_i)</span>
<span id="cb4-49"></span>
<span id="cb4-50">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Flatten f and adfdz</span></span>
<span id="cb4-51">            func_eval <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> func_eval.view(bs, n_dim)</span>
<span id="cb4-52">            adfdz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfdz.view(bs, n_dim)</span>
<span id="cb4-53">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> torch.cat((func_eval, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>adfdz, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>adfdp, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>adfdt), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-54"></span>
<span id="cb4-55">        dLdz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dLdz.view(time_len, bs, n_dim)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># flatten dLdz for convenience</span></span>
<span id="cb4-56">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb4-57">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## Create placeholders for output gradients</span></span>
<span id="cb4-58">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prev computed backwards adjoints to be adjusted by direct gradients</span></span>
<span id="cb4-59">            adj_z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(bs, n_dim).to(dLdz)</span>
<span id="cb4-60">            adj_p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(bs, n_params).to(dLdz)</span>
<span id="cb4-61">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># In contrast to z and p we need to return gradients for all times</span></span>
<span id="cb4-62">            adj_t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(time_len, bs, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).to(dLdz)</span>
<span id="cb4-63"></span>
<span id="cb4-64">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i_t <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(time_len<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>):</span>
<span id="cb4-65">                z_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z[i_t]</span>
<span id="cb4-66">                t_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t[i_t]</span>
<span id="cb4-67">                f_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> func(z_i, t_i).view(bs, n_dim)</span>
<span id="cb4-68"></span>
<span id="cb4-69">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute direct gradients</span></span>
<span id="cb4-70">                dLdz_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dLdz[i_t]</span>
<span id="cb4-71">                dLdt_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.bmm(torch.transpose(dLdz_i.unsqueeze(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), f_i.unsqueeze(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb4-72"></span>
<span id="cb4-73">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adjusting adjoints with direct gradients</span></span>
<span id="cb4-74">                adj_z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> dLdz_i</span>
<span id="cb4-75">                adj_t[i_t] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adj_t[i_t] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> dLdt_i</span>
<span id="cb4-76"></span>
<span id="cb4-77">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pack augmented variable</span></span>
<span id="cb4-78">                aug_z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat((z_i.view(bs, n_dim), adj_z, torch.zeros(bs, n_params).to(z), adj_t[i_t]), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-79"></span>
<span id="cb4-80">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Solve augmented system backwards</span></span>
<span id="cb4-81">                aug_ans <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ode_solve(aug_z, t_i, t[i_t<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], augmented_dynamics)</span>
<span id="cb4-82"></span>
<span id="cb4-83">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Unpack solved backwards augmented system</span></span>
<span id="cb4-84">                adj_z[:] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> aug_ans[:, n_dim:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>n_dim]</span>
<span id="cb4-85">                adj_p[:] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> aug_ans[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>n_dim:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>n_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> n_params]</span>
<span id="cb4-86">                adj_t[i_t<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> aug_ans[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>n_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> n_params:]</span>
<span id="cb4-87"></span>
<span id="cb4-88">                <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">del</span> aug_z, aug_ans</span>
<span id="cb4-89"></span>
<span id="cb4-90">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## Adjust 0 time adjoint with direct gradients</span></span>
<span id="cb4-91">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute direct gradients</span></span>
<span id="cb4-92">            dLdz_0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dLdz[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb4-93">            dLdt_0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.bmm(torch.transpose(dLdz_0.unsqueeze(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), f_i.unsqueeze(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb4-94"></span>
<span id="cb4-95">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adjust adjoints</span></span>
<span id="cb4-96">            adj_z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> dLdz_0</span>
<span id="cb4-97">            adj_t[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adj_t[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> dLdt_0</span>
<span id="cb4-98">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> adj_z.view(bs, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>z_shape), adj_t, adj_p, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span></code></pre></div>
</div>
<p>これを <code>nn.Module</code> クラスとしてラップすることで，準備完了である：</p>
<div id="b47f65c3" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> NeuralODE(nn.Module):</span>
<span id="cb5-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, func):</span>
<span id="cb5-3">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(NeuralODE, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb5-4">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(func, ODEF)</span>
<span id="cb5-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.func <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> func</span>
<span id="cb5-6"></span>
<span id="cb5-7">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, z0, t<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Tensor([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span>]), return_whole_sequence<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>):</span>
<span id="cb5-8">        t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t.to(z0)</span>
<span id="cb5-9">        z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ODEAdjoint.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(z0, t, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.func.flatten_parameters(), <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.func)</span>
<span id="cb5-10">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> return_whole_sequence:</span>
<span id="cb5-11">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> z</span>
<span id="cb5-12">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb5-13">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> z[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
</div>
</section>
<section id="ダイナミクスの再現" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="ダイナミクスの再現"><span class="header-section-number">3</span> ダイナミクスの再現</h2>
<section id="線型ダイナミクス" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="線型ダイナミクス"><span class="header-section-number">3.1</span> 線型ダイナミクス</h3>
<p>簡単な線型ダイナミクスを，線型なダイナミクスで学習する．</p>
<div id="5ff41c1d" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> LinearODEF(ODEF):</span>
<span id="cb6-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, W):</span>
<span id="cb6-3">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(LinearODEF, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb6-4">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, bias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb6-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin.weight <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Parameter(W)</span>
<span id="cb6-6"></span>
<span id="cb6-7">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x, t):</span>
<span id="cb6-8">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin(x)</span>
<span id="cb6-9"></span>
<span id="cb6-10"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> SpiralFunctionExample(LinearODEF):</span>
<span id="cb6-11">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb6-12">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(SpiralFunctionExample, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(Tensor([[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span>], [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>]]))</span>
<span id="cb6-13"></span>
<span id="cb6-14"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> RandomLinearODEF(LinearODEF):</span>
<span id="cb6-15">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb6-16">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># super(RandomLinearODEF, self).__init__(torch.randn(2, 2)/2.)</span></span>
<span id="cb6-17">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(RandomLinearODEF, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(Tensor([[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>], [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>]]))</span>
<span id="cb6-18"></span>
<span id="cb6-19"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> to_np(x):</span>
<span id="cb6-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> x.detach().cpu().numpy()</span></code></pre></div>
</div>
<div id="9c7f3f65" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> plot_trajectories(obs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, times<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, trajs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, save<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>)):</span>
<span id="cb7-2">    plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>figsize)</span>
<span id="cb7-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> obs <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb7-4">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> times <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb7-5">            times <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(obs)</span>
<span id="cb7-6">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> o, t <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span>(obs, times):</span>
<span id="cb7-7">            o, t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> to_np(o), to_np(t)</span>
<span id="cb7-8">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> b_i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(o.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]):</span>
<span id="cb7-9">                plt.scatter(o[:, b_i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], o[:, b_i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>t[:, b_i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cm.plasma)</span>
<span id="cb7-10"></span>
<span id="cb7-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> trajs <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb7-12">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> z <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> trajs:</span>
<span id="cb7-13">            z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> to_np(z)</span>
<span id="cb7-14">            plt.plot(z[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], z[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], lw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>)</span>
<span id="cb7-15">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> save <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb7-16">            plt.savefig(save)</span>
<span id="cb7-17">    plt.show()</span>
<span id="cb7-18"></span>
<span id="cb7-19"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> conduct_experiment(ode_true, ode_trained, n_steps, name, plot_freq<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>):</span>
<span id="cb7-20">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create data</span></span>
<span id="cb7-21">    z0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Variable(torch.Tensor([[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>]]))</span>
<span id="cb7-22"></span>
<span id="cb7-23">    t_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">6.29</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span></span>
<span id="cb7-24">    n_points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span></span>
<span id="cb7-25"></span>
<span id="cb7-26">    index_np <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, n_points, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.int64)</span>
<span id="cb7-27">    index_np <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.hstack([index_np[:, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]])</span>
<span id="cb7-28">    times_np <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, t_max, num<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_points)</span>
<span id="cb7-29">    times_np <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.hstack([times_np[:, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]])</span>
<span id="cb7-30"></span>
<span id="cb7-31">    times <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.from_numpy(times_np[:, :, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]).to(z0)</span>
<span id="cb7-32">    obs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ode_true(z0, times, return_whole_sequence<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>).detach()</span>
<span id="cb7-33">    obs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> obs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> torch.randn_like(obs) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span></span>
<span id="cb7-34"></span>
<span id="cb7-35">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get trajectory of random timespan</span></span>
<span id="cb7-36">    min_delta_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb7-37">    max_delta_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.0</span></span>
<span id="cb7-38">    max_points_num <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span></span>
<span id="cb7-39">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> create_batch():</span>
<span id="cb7-40">        t0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.uniform(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, t_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> max_delta_time)</span>
<span id="cb7-41">        t1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.random.uniform(min_delta_time, max_delta_time)</span>
<span id="cb7-42"></span>
<span id="cb7-43">        idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sorted</span>(np.random.permutation(index_np[(times_np <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> t0) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> (times_np <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> t1)])[:max_points_num])</span>
<span id="cb7-44"></span>
<span id="cb7-45">        obs_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> obs[idx]</span>
<span id="cb7-46">        ts_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> times[idx]</span>
<span id="cb7-47">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> obs_, ts_</span>
<span id="cb7-48"></span>
<span id="cb7-49">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Train Neural ODE</span></span>
<span id="cb7-50">    optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.optim.Adam(ode_trained.parameters(), lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>lr)</span>
<span id="cb7-51">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n_steps):</span>
<span id="cb7-52">        obs_, ts_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> create_batch()</span>
<span id="cb7-53"></span>
<span id="cb7-54">        z_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ode_trained(obs_[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], ts_, return_whole_sequence<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb7-55">        loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> F.mse_loss(z_, obs_.detach())</span>
<span id="cb7-56"></span>
<span id="cb7-57">        optimizer.zero_grad()</span>
<span id="cb7-58">        loss.backward(retain_graph<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb7-59">        optimizer.step()</span>
<span id="cb7-60"></span>
<span id="cb7-61">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> plot_freq <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb7-62">            z_p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ode_trained(z0, times, return_whole_sequence<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb7-63"></span>
<span id="cb7-64">            plot_trajectories(obs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[obs], times<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[times], trajs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[z_p], save<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Files/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span>plot_freq<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.png"</span>)</span>
<span id="cb7-65">            clear_output(wait<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div>
</div>
<div id="ec1bf5c6" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">ode_true <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> NeuralODE(SpiralFunctionExample())</span>
<span id="cb8-2">ode_trained <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> NeuralODE(RandomLinearODEF())</span>
<span id="cb8-3">conduct_experiment(ode_true, ode_trained, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"linear"</span>)</span></code></pre></div>
</div>
<p>ImageMagick により git 生成した結果は次の通り：</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb9-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">convert</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-delay</span> 10 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-loop</span> 0 <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$(</span><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">{</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">..</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">49</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">}</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">;</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">do</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">echo</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$i</span>.png<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">;</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">done</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">)</span> output.gif</span></code></pre></div>
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/linear/output.gif" class="img-fluid"></p>
</section>
<section id="非線型ダイナミクス" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="非線型ダイナミクス"><span class="header-section-number">3.2</span> 非線型ダイナミクス</h3>
<p>今回は非線型のダイナミクスを，<a href="https://pytorch.org/docs/stable/generated/torch.nn.ELU.html">ELU</a> を備えた一層のニューラルネットワークで学習する：</p>
<div id="ea8e3b83" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> TestODEF(ODEF):</span>
<span id="cb10-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, A, B, x0):</span>
<span id="cb10-3">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(TestODEF, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb10-4">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.A <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, bias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb10-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.A.weight <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Parameter(A)</span>
<span id="cb10-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.B <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, bias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb10-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.B.weight <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Parameter(B)</span>
<span id="cb10-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.x0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Parameter(x0)</span>
<span id="cb10-9"></span>
<span id="cb10-10">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x, t):</span>
<span id="cb10-11">        xTx0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.x0, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb10-12">        dxdt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.sigmoid(xTx0) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.A(x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.x0) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> torch.sigmoid(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>xTx0) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.B(x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.x0)</span>
<span id="cb10-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> dxdt</span>
<span id="cb10-14"></span>
<span id="cb10-15"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> NNODEF(ODEF):</span>
<span id="cb10-16">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, in_dim, hid_dim, time_invariant<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>):</span>
<span id="cb10-17">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(NNODEF, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb10-18">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.time_invariant <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time_invariant</span>
<span id="cb10-19"></span>
<span id="cb10-20">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> time_invariant:</span>
<span id="cb10-21">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(in_dim, hid_dim)</span>
<span id="cb10-22">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb10-23">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(in_dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, hid_dim)</span>
<span id="cb10-24">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(hid_dim, hid_dim)</span>
<span id="cb10-25">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(hid_dim, in_dim)</span>
<span id="cb10-26">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.elu <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.ELU(inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-27"></span>
<span id="cb10-28">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x, t):</span>
<span id="cb10-29">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.time_invariant:</span>
<span id="cb10-30">            x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat((x, t), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb10-31"></span>
<span id="cb10-32">        h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.elu(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin1(x))</span>
<span id="cb10-33">        h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.elu(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin2(h))</span>
<span id="cb10-34">        out <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin3(h)</span>
<span id="cb10-35">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> out</span></code></pre></div>
</div>
<div id="d8b02904" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">func <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> TestODEF(Tensor([[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>], [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>]]), Tensor([[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span>], [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>]]), Tensor([[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span>]]))</span>
<span id="cb11-2">ode_true <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> NeuralODE(func)</span>
<span id="cb11-3"></span>
<span id="cb11-4">func <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> NNODEF(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>, time_invariant<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb11-5">ode_trained <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> NeuralODE(func)</span>
<span id="cb11-6"></span>
<span id="cb11-7">conduct_experiment(ode_true, ode_trained, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3000</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"nonlinear"</span>, plot_freq<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>, lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.001</span>)</span></code></pre></div>
</div>
<p>逡巡を繰り返して学習する様子がよく伺える．学習率を <code>lr=0.001</code> としているが，<code>lr=0.01</code> でも <code>lr=0.005</code> でも，学習が非常に良い線まで行ってもすぐに初期値よりもカオスなダイナミクスに戻ってしまう挙動がよく見られた．</p>
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/nonlinear/output.gif" class="img-fluid"></p>
</section>
</section>


<div id="quarto-appendix" class="default"><section id="文献紹介" class="level2 appendix" data-number="4"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">4</span> 文献紹介</h2><div class="quarto-appendix-contents">

<p><a href="https://msurtsukov.github.io/Neural-ODE/">Mikhail Surtsukov 氏</a>によるチュートリアルが，<a href="https://github.com/msurtsukov/neural-ode?tab=readme-ov-file">このレポジトリ</a>で公開されている．</p>
<p>FFJORD <span class="citation" data-cites="Grathwohl+2019">(Grathwohl et al., 2019)</span> の実装は，<a href="https://github.com/rtqichen/ffjord">このレポジトリ</a>で公開されている．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Grathwohl+2019" class="csl-entry">
Grathwohl, W., Chen, R. T. Q., Bettencourt, J., and Duvenaud, D. (2019). <a href="https://openreview.net/forum?id=rJxgknCcK7"><span class="nocase">Scalable Reversible Generative Models with Free-form Continuous Dynamics</span></a>. In <em>International conference on learning representations</em>.
</div>
</div></section></div> ]]></description>
  <category>Deep</category>
  <category>Sampling</category>
  <category>Python</category>
  <guid>https://162348.github.io/posts/2024/Samplers/NF4.html</guid>
  <pubDate>Tue, 20 Aug 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Samplers/Files/nonlinear/output.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>特異値分解</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/FunctionalAnalysis/SVD.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="特異値分解" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="特異値分解"><span class="header-section-number">1</span> 特異値分解</h2>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題（特異値分解）^[[@Eckart-Young1936 p.213 Theorem 1], [@Strang16 p.372] など．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題（特異値分解）<sup>1</sup>
</div>
</div>
<div class="callout-body-container callout-body">
<p>任意の行列 <img src="https://latex.codecogs.com/png.latex?A%5Cin%20M_%7Bn,p%7D(%5Cmathbb%7BR%7D),r:=%5Coperatorname%7Brank%7D(A)"> について，直交行列 <img src="https://latex.codecogs.com/png.latex?U%5Cin%20O_n(%5Cmathbb%7BR%7D),V%5Cin%20O_p(%5Cmathbb%7BR%7D)"> と非負実数 <img src="https://latex.codecogs.com/png.latex?%5Csigma_1%5Cge%5Ccdots%5Cge%5Csigma_r%3E0"> が存在して，次が成り立つ： <img src="https://latex.codecogs.com/png.latex?%0AA=U%5CSigma%20V%5E%5Ctop,%5Cqquad%5CSigma:=%5Cbegin%7Bbmatrix%7DD&amp;O_%7Br,p-r%7D%5C%5CO_%7Bn-r,r%7D&amp;O_%7Bn-r,p-r%7D%5Cend%7Bbmatrix%7D,%5Cquad%20D:=%5Cmathrm%7Bdiag%7D(%5Csigma_1,%5Ccdots,%5Csigma_r).%0A"> <img src="https://latex.codecogs.com/png.latex?D"> を <strong>特異値行列</strong>，の対角要素を <strong>特異値</strong> と呼ぶ．<sup>2</sup></p>
</div>
</div>
<p><span class="citation" data-cites="Sylvester1889">(Sylvester, 1889)</span> は特異値を正準乗数 (canonical multipliers) と呼んでいた．Sylvester は特異値分解を独立に再発見した一人で，歴史上最初の特異値分解は <span class="citation" data-cites="Beltrami1873">(Beltrami, 1873)</span> が与えたものだとされている．より詳しい歴史については <span class="citation" data-cites="Stewart1993">(Stewart, 1993)</span> 参照．</p>
<div class="callout callout-style-default callout-note no-icon callout-titled" title="証明">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
証明
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p>まず <img src="https://latex.codecogs.com/png.latex?v_1,%5Ccdots,v_r%5Cin%5Cmathbb%7BR%7D%5En"> を，<img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop%20A"> の固有ベクトルからなる正規直交系として取る． このとき <img src="https://latex.codecogs.com/png.latex?v_1,%5Ccdots,v_r"> は <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BIm%7D%5C,(A%5E%5Ctop)"> の像の基底である． <img src="https://latex.codecogs.com/png.latex?v_1,%5Ccdots,v_r"> が <img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop%20A"> の固有ベクトルであることが必要であることは， <img src="https://latex.codecogs.com/png.latex?%0AA%5E%5Ctop%20A=(U%5CSigma%20V%5E%5Ctop)%5E%5Ctop(U%5CSigma%20V%5E%5Ctop)=V%5CSigma%5E%5Ctop%20U%5E%5Ctop%20U%5CSigma%20V%5E%5Ctop=V(%5CSigma%5E%5Ctop%5CSigma)V%0A"> となることからわかり，<img src="https://latex.codecogs.com/png.latex?%5Csigma_1%5E2,%5Ccdots,%5Csigma_r%5E2"> が <img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop%20A"> の固有値である． （従って <img src="https://latex.codecogs.com/png.latex?AA%5E%5Ctop"> の固有値でもある）．</p></li>
<li><p>続いて，条件 <img src="https://latex.codecogs.com/png.latex?Av_i=%5Csigma_iu_i%5C;(i%5Cin%5Br%5D)"> によって，<img src="https://latex.codecogs.com/png.latex?u_1,%5Ccdots,u_r"> を定める．するとこれらは直交し， <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BIm%7D%5C,(A)"> の基底をなす．さらに，<img src="https://latex.codecogs.com/png.latex?AA%5E%5Ctop"> の固有ベクトルでもある．</p>
<p>このことは次のように示せる：</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0Au_i%5E%5Ctop%20u_j&amp;=%5Cleft(%5Cfrac%7BAv_i%7D%7B%5Csigma_i%7D%5Cright)%5E%5Ctop%5Cleft(%5Cfrac%7BAv_j%7D%7B%5Csigma_j%7D%5Cright)=%5Cfrac%7Bv_i%5E%5Ctop%20A%5E%5Ctop%20Av_j%7D%7B%5Csigma_i%5Csigma_j%7D=%5Cfrac%7B%5Csigma_j%5E2%7D%7B%5Csigma_i%5Csigma_j%7Dv_i%5E%5Ctop%20v_j=0,%5Cqquad%20i%5Cne%20j.%0A%5Cend%7Balign*%7D"></p>
<p><img src="https://latex.codecogs.com/png.latex?%5Clangle%20u_1,%5Ccdots,u_r%5Crangle%5Csubset%5Cmathrm%7BIm%7D%5C,(A)"> であることと，正規直交することから線型独立でもあり，これらが <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BIm%7D%5C,(A)"> の基底であることがわかる． さらに，任意の <img src="https://latex.codecogs.com/png.latex?i%5Cin%5Br%5D"> について， <img src="https://latex.codecogs.com/png.latex?%0AAA%5E%5Ctop%20u_i=%5Cfrac%7BAA%5E%5Ctop%20Au_i%7D%7B%5Csigma_i%7D=%5Csigma_iAv_i=%5Csigma_i%5E2u_i,%5Cqquad%20i%5Cin%5Br%5D.%0A"> なお，<img src="https://latex.codecogs.com/png.latex?Av_i=%5Csigma_iu_i"> が必要であることは，<img src="https://latex.codecogs.com/png.latex?v_1,%5Ccdots,v_r"> の正規直交性から， <img src="https://latex.codecogs.com/png.latex?%0AAv_i=%5Cbiggr(u_1%5Csigma_1v_1%5E%5Ctop+%5Ccdots+u_r%5Csigma_rv_r%5E%5Ctop%5Cbiggl)v_i=u_i%5Csigma_i%0A"> からわかる．</p></li>
<li><p><img src="https://latex.codecogs.com/png.latex?v_1,%5Ccdots,v_r"> の正規直交な延長であって，<img src="https://latex.codecogs.com/png.latex?v_%7Br+1%7D,%5Ccdots,v_n"> が <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BKer%7D%5C;(A)"> の基底になるもの，<img src="https://latex.codecogs.com/png.latex?u_1,%5Ccdots,u_r"> の正規直交な延長であって，<img src="https://latex.codecogs.com/png.latex?u_%7Br+1%7D,%5Ccdots,u_m"> が <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BKer%7D%5C;(A%5E%5Ctop)"> の基底になるものが取れる． これは，核と余像，像と余核が直交するためである． これについて，<img src="https://latex.codecogs.com/png.latex?A=U%5CSigma%20V%5E%5Ctop"> が成り立つ．</p></li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-default callout-warning no-icon callout-titled" title="系">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
系
</div>
</div>
<div class="callout-body-container callout-body">
<p>以上の証明から，次のこともわかる：</p>
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?A"> の特異値は，<img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop%20A"> の固有値の正の平方根に等しい．</li>
<li><img src="https://latex.codecogs.com/png.latex?V"> の列ベクトルは <img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop%20A"> の固有ベクトルであり，<img src="https://latex.codecogs.com/png.latex?U"> の列ベクトルは <img src="https://latex.codecogs.com/png.latex?AA%5E%5Ctop"> の固有ベクトルになる．</li>
</ol>
</div>
</div>
</section>
<section id="低階数近似" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="低階数近似"><span class="header-section-number">2</span> 低階数近似</h2>
<p><img src="https://latex.codecogs.com/png.latex?(n,p)">-行列の全体 <img src="https://latex.codecogs.com/png.latex?M_%7Bn,p%7D(%5Cmathbb%7BC%7D)"> は <a href="../../../static/Notations.html#subsec-linear-space">Hilbert-Schmidt 内積</a> <img src="https://latex.codecogs.com/png.latex?%0A(B%20%5C,%7C%5C,A)_%5Cmathrm%7BHS%7D:=%5Coperatorname%7BTr%7D(A%5E*B)=%5Csum_%7Bi=1%7D%5Em%5Csum_%7Bj=1%7D%5Ena_%7Bij%7Db_%7Bij%7D%0A"> に関して Hilbert 空間をなす．<img src="https://latex.codecogs.com/png.latex?M_%7Bn,p%7D(%5Cmathbb%7BR%7D)"> はこの閉部分空間をなす．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題 [@Eckart-Young1936]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題 <span class="citation" data-cites="Eckart-Young1936">(Eckart and Young, 1936)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?A%5Cin%20M_%7Bn,p%7D(%5Cmathbb%7BR%7D)"> を行列，<img src="https://latex.codecogs.com/png.latex?0%5Cle%20r%5Cle%20n%5Clor%20p"> を自然数とする．ランク <img src="https://latex.codecogs.com/png.latex?r"> の行列 <img src="https://latex.codecogs.com/png.latex?%5Cwidetilde%7BA%7D%5Cin%20M_%7Bn,p%7D(%5Cmathbb%7BR%7D)"> のうち，<img src="https://latex.codecogs.com/png.latex?A"> に最も近いものは <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidetilde%7BA%7D:=U%5CSigma_%7B1:r%7DV%5E%5Ctop=%5Coperatorname*%7Bargmin%7D_%7B%5Coperatorname%7Brank%7D(%5Cwidetilde%7BA%7D)=r%7D%5C%7CA-%5Cwidetilde%7BA%7D%5C%7C_%5Cmathrm%7BHS%7D%0A"> が与える．ただし，<img src="https://latex.codecogs.com/png.latex?%5CSigma_%7B1:r%7D=%5Cmathrm%7Bdiag%7D(%5Csigma_1,%5Ccdots,%5Csigma_r,0,%5Ccdots,0)"> とした．</p>
</div>
</div>
<p>またこのときの残差は，残った特異値のうち最大のもの <img src="https://latex.codecogs.com/png.latex?%0A%5C%7CA-%5Cwidetilde%7BA%7D%5C%7C_%5Cmathrm%7BHS%7D=%5Csigma_%7Br+1%7D%0A"> が与える．<sup>3</sup></p>
</section>
<section id="一般化逆行列" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="一般化逆行列"><span class="header-section-number">3</span> 一般化逆行列</h2>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題 [@Moore1920]-[@Penrose1955]^[[@柳井-竹内-一般逆行列] も参照．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題 <span class="citation" data-cites="Moore1920">(Moore, 1920)</span>-<span class="citation" data-cites="Penrose1955">(Penrose, 1955)</span><sup>4</sup>
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?A%5Cin%20M_%7Bmn%7D(%5Cmathbb%7BR%7D)"> について，次の３条件を満たす行列 <img src="https://latex.codecogs.com/png.latex?A%5E+%5Cin%20M_%7Bnm%7D(%5Cmathbb%7BR%7D)"> は一意的に定まる：</p>
<ol type="a">
<li>反射型一般可逆行列：<img src="https://latex.codecogs.com/png.latex?AA%5E+A=A,A%5E+AA%5E+=A%5E+"></li>
<li>最小ノルム型：<img src="https://latex.codecogs.com/png.latex?A%5E+A"> は自己共役である：<img src="https://latex.codecogs.com/png.latex?(A%5E+A)%5E%5Ctop=A%5E+A"></li>
<li>最小誤差型：<img src="https://latex.codecogs.com/png.latex?AA%5E+"> も自己共役である：<img src="https://latex.codecogs.com/png.latex?(AA%5E+)%5E%5Ctop=AA%5E+"></li>
</ol>
<p>これを <strong>Moore-Penrose の一般化逆行列</strong> という．</p>
</div>
</div>
<p>任意の行列 <img src="https://latex.codecogs.com/png.latex?A%5Cin%20M_%7Bn,p%7D(%5Cmathbb%7BR%7D)"> の一般化逆行列は，直交行列 <img src="https://latex.codecogs.com/png.latex?V,U"> で座標変換を施したところで逆行列を取り，これを再び <img src="https://latex.codecogs.com/png.latex?V,U"> で変換し直したものに等しい：</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題（一般化逆の特徴付け）^[[@柳井-竹内-一般逆行列 定理5.6], [@Strang16 p.395] も参照．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題（一般化逆の特徴付け）<sup>5</sup>
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?A%5Cin%20M_%7Bn,p%7D(%5Cmathbb%7BR%7D)"> の一般化逆行列は次のように表せる： <img src="https://latex.codecogs.com/png.latex?%0AA%5E+=V%5CSigma%5E%7B-1%7DU%5E%5Ctop,%5Cqquad%20%5CSigma%5E%7B-1%7D=%5Cbegin%7Bbmatrix%7DD%5E%7B-1%7D&amp;O_%7Br,p-r%7D%5C%5CO_%7Bn-r,r%7D&amp;O_%7Bn-r,p-r%7D%5Cend%7Bbmatrix%7D.%0A"></p>
</div>
</div>
</section>



<div id="quarto-appendix" class="default"><section id="関連ページ" class="level2 unnumbered unlisted appendix"><h2 class="anchored quarto-appendix-heading">関連ページ</h2><div class="quarto-appendix-contents">

<div id="listing-related-articles-listing" class="quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="U3RhdGlzdGljcyUyQ0tlcm5lbCUyQ1Byb2JhYmlsaXR5JTJDQmF5ZXNpYW4=" data-listing-date-sort="1723420800000" data-listing-file-modified-sort="1733137936200" data-listing-date-modified-sort="1723593600000" data-listing-reading-time-sort="6" data-listing-word-count-sort="1072">
<a href="../../../posts/2024/Kernels/HierarchicalModel.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Kernels/Images/MM.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
階層モデル再論
</h5>
<div class="card-subtitle listing-subtitle">
多変量解析から機械学習へ
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-12
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="RGVlcCUyQ05hdHVyZSUyQ1N0YXRpc3RpY3MlMkNHZW9tZXRyeQ==" data-listing-date-sort="1722297600000" data-listing-file-modified-sort="1733137936220" data-listing-date-modified-sort="1723680000000" data-listing-reading-time-sort="3" data-listing-word-count-sort="597">
<a href="../../../posts/2024/Kernels/Manifold.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Kernels/Images/UMAPvSNE.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
非線型な次元縮約法の概観
</h5>
<div class="card-subtitle listing-subtitle">
最古にして最難のタスクと多様体学習
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-07-30
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="S2VybmVs" data-listing-date-sort="1723248000000" data-listing-file-modified-sort="1733137936220" data-listing-date-modified-sort="1723334400000" data-listing-reading-time-sort="3" data-listing-word-count-sort="581">
<a href="../../../posts/2024/Kernels/Kernel.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Kernels/Images/Gibbs.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
カーネル法の概観
</h5>
<div class="card-subtitle listing-subtitle">
半正定値カーネルから距離学習まで
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-10
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Beltrami1873" class="csl-entry">
Beltrami, E. (1873). <a href="https://gallica.bnf.fr/ark:/12148/bpt6k99434d/f442">Sulle funzioni bilineari</a>. <em>Giornale Di Matematiche Ad Uso Degli Studenti Delle Universita</em>, <em>11</em>, 98–106.
</div>
<div id="ref-Eckart-Young1936" class="csl-entry">
Eckart, C., and Young, G. (1936). <a href="https://doi.org/10.1007/BF02288367">The approximation of one matrix by another of lower rank</a>. <em>Psychometrika</em>, <em>1</em>(3), 211–218.
</div>
<div id="ref-Moore1920" class="csl-entry">
Moore, E. H. (1920). <a href="https://doi.org/10.1090%2FS0002-9904-1920-03322-7">On the reciprocal of the general algebraic matrix</a>. <em>Bulletin of the American Mathematical Society</em>, <em>26</em>(9), 394–395.
</div>
<div id="ref-Penrose1955" class="csl-entry">
Penrose, R. (1955). <a href="https://doi.org/10.1017/S0305004100030401">A generalized inverse for matrices</a>. <em>Mathematical Proceedings of the Cambridge Philosophical Society</em>, <em>51</em>(3), 406–413.
</div>
<div id="ref-Stewart1993" class="csl-entry">
Stewart, G. W. (1993). <a href="https://doi.org/10.1137/1035134">On the early history of the singular value decomposition</a>. <em>SIAM Review</em>, <em>35</em>(4), 551–566.
</div>
<div id="ref-Strang16" class="csl-entry">
Strang, G. (2016). <em>Introduction to linear algebra</em>. Wellesley-Cambridge Press.
</div>
<div id="ref-Sylvester1889" class="csl-entry">
Sylvester, J. J. (1889). <a href="https://books.google.co.jp/books?id=cxRKAQAAMAAJ&amp;pg=PA1&amp;hl=ja&amp;source=gbs_toc_r&amp;cad=2#v=onepage&amp;q&amp;f=false">On the reduction of a bilinear quantic of the <img src="https://latex.codecogs.com/png.latex?n">-th order to the form of a sum of <img src="https://latex.codecogs.com/png.latex?n"> products by a double orthogonal substitution</a>. <em>The Messenger of Mathematics</em>, <em>18</em>, 42–46.
</div>
<div id="ref-柳井-竹内-一般逆行列" class="csl-entry">
柳井晴夫，竹内啓. (1983). <em>射影行列・一般逆行列・特異値分解</em>,Vol. 10. 2018年に新装版が出版されている; 東京大学出版会.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><span class="citation" data-cites="Eckart-Young1936">(Eckart and Young, 1936, p. 213 Theorem 1)</span>, <span class="citation" data-cites="Strang16">(Strang, 2016, p. 372)</span> など．↩︎</p></li>
<li id="fn2"><p><span class="citation" data-cites="Eckart-Young1936">(Eckart and Young, 1936, p. 214)</span> によると，以前はにより正準乗数 (canonical multipliers) と呼ばれていた．↩︎</p></li>
<li id="fn3"><p><img src="https://latex.codecogs.com/png.latex?r%5Cge%5Coperatorname%7Brank%7D(A)"> であるとき，<img src="https://latex.codecogs.com/png.latex?%5Csigma_%7Br+1%7D=0"> とする．<span class="citation" data-cites="Strang16">(Strang, 2016, p. 394)</span> も参照．↩︎</p></li>
<li id="fn4"><p><span class="citation" data-cites="柳井-竹内-一般逆行列">(柳井晴夫，竹内啓, 1983)</span> も参照．↩︎</p></li>
<li id="fn5"><p><span class="citation" data-cites="柳井-竹内-一般逆行列">(柳井晴夫，竹内啓, 1983, p. 定理5.6)</span>, <span class="citation" data-cites="Strang16">(Strang, 2016, p. 395)</span> も参照．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Functional Analysis</category>
  <guid>https://162348.github.io/posts/2024/FunctionalAnalysis/SVD.html</guid>
  <pubDate>Mon, 12 Aug 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/FunctionalAnalysis/Images/SVD.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>階層モデル再論</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Kernels/HierarchicalModel.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="はじめに" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="はじめに">はじめに</h2>
<p>潜在変数模型とはどうやらとんでもなく広い射程を持った対象であるようである．</p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="潜在変数モデルとは……">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
潜在変数モデルとは……
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>心理学，経済学をはじめとして多くの分野で中心的に扱われてきたモデルである（<a href="https://ja.wikipedia.org/wiki/共分散構造分析">構造方程式モデル</a>，因子分析，項目応答モデル，同時方程式モデルなど）．</li>
<li>ベイズ統計学では <strong>階層モデル</strong> (hierarchical model) として極めて重要な役割を果たす．</li>
<li>生成モデリング（<a href="../../../posts/2024/Kernels/Deep4.html">VAE</a>, <a href="../../../posts/2024/Samplers/EBM.html">EBM</a>, <a href="../../../posts/2024/Samplers/Diffusion.html">Diffusion</a>, <a href="../../../posts/2024/Kernels/Deep3.html">GAN</a>, <a href="../../../posts/2024/Computation/PGM1.html">Probabilistic Graphical Model</a>）も，観測変数上の周辺分布がデータ分布に近づくように潜在変数模型を学習する方法である．</li>
<li>認知科学において，脳も潜在変数模型に基いてメンタルモデルを構成しているという仮説もある（<a href="../../../posts/2024/Kernels/NCL.html#sec-InfoMax">InfoMax に関する稿</a>も参照）．表現学習や独立成分分析の指導原理になっている側面がある．</li>
<li>情報理論において，通信路の組み合わせは潜在変数模型としてモデリングできる．さらには，潜在変数模型は数学的には確率空間の圏上の図式であるとして研究されている <span class="citation" data-cites="Perrone2024">(Perrone, 2024)</span>．</li>
</ol>
</div>
</div>
<p>このように種々の文脈で登場する潜在変数模型であるが，<u><strong>それぞれの文脈において「潜在変数」の果たす役割は全く違う</strong></u>．</p>
<p>しかし，数学的には全く同じ枠組みで記述できる．従って，そのように扱うことは一定の価値を持つだろう．</p>
<p>実際，近年になり，これから本稿で解説するように，潜在変数モデルの観点から心理学，経済学，環境科学，遺伝学，信号処理，逆問題，社会学，政治科学，マーケティング分野で独自に発展した手法が，特定の手法の特別な場合と見れるという理解が進み，手法の交流と知見の交換が進んでいる．</p>
</section>
<section id="本稿の目的" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="本稿の目的">本稿の目的</h2>
<p>本稿では主成分分析，因子分析，構造方程式モデリング，混合モデル，独立成分分析を，<u>潜在変数モデルとして解釈し，図式で理解する</u>．</p>
<p>確率変数を丸つきの大文字で表し，<img src="https://latex.codecogs.com/png.latex?X%5Ei,Y%5Ei"> は観測変数，<img src="https://latex.codecogs.com/png.latex?Z%5Ei"> は潜在変数を表す．矢印は <a href="../../../posts/2024/Probability/Kernel.html">確率核</a> を表す．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/MM.svg" class="img-fluid figure-img"></p>
<figcaption>混合モデル（第 4 節）</figcaption>
</figure>
</div>
<p>種々の <strong>多変量解析法</strong> を（ベイズ）階層モデルとして統一的に理解すると同時に，それぞれの文脈での「使い方の違い」に注目することを目指す．</p>
</section>
<section id="sec-PCA" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="sec-PCA"><span class="header-section-number">1</span> 主成分分析 (PCA)</h2>
<section id="はじめに-1" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="はじめに-1"><span class="header-section-number">1.1</span> はじめに</h3>
<p>主成分分析では，<img src="https://latex.codecogs.com/png.latex?p"> 次元のデータ <img src="https://latex.codecogs.com/png.latex?%5C%7Bx_i%5C%7D_%7Bi=1%7D%5En%5Csubset%5Cmathbb%7BR%7D%5Ep"> の各成分を，より少数の潜在変数を持った１層の線型 Gauss 模型</p>
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/PCA.svg" class="img-fluid"></p>
<p>で説明しようとする．<sup>1</sup></p>
<p>歴史的に主成分分析は，おろした垂線の足の二乗距離和の意味でコストが最小になるような線型射影を求める問題 <span class="citation" data-cites="Pearson01-PCA">(Pearson, 1901)</span> として最初に登場し，値の分散が最大となるような線型射影を求める問題 <span class="citation" data-cites="Hotelling33-PCA">(Hotelling, 1933)</span> として PCA の名前がつき，心理学分野，特に psychometrika で取り上げられて大きく発展した．</p>
<p>このような潜在変数モデルとしての見方は probabilistic PCA <span class="citation" data-cites="Tipping-Bishop1999">(Tipping and Bishop, 1999)</span> / SPCA (Sensible PCA) <span class="citation" data-cites="Roweis1997">(Roweis, 1997)</span> として，因子分析から逆輸入する形で初めて自覚された見方である（第 2.3.1 節も参照）．</p>
<p>確率的な見地から見れば，正規性を仮定した変数 <img src="https://latex.codecogs.com/png.latex?Z%5E1,%5Ccdots,Z%5Er"> の事前分布が互いに独立なデルタ分布に縮退している場合が古典的な PCA である <span class="citation" data-cites="Roweis1997">(Roweis, 1997)</span>．</p>
<p>いずれの場合も追加の過程なくしてモデルは識別可能性がなく，後続タスクに応じて種々の制約を追加することで所望の解を得る，という動的な使い方がなされる．</p>
<p>以降，<img src="https://latex.codecogs.com/png.latex?X%5Cin%5Cmathcal%7BL%7D(%5COmega;%5Cmathbb%7BR%7D%5Ep),Z%5Cin%5Cmathcal%7BL%7D(%5COmega;%5Cmathbb%7BR%7D%5Er)"> を確率変数， <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BX%7D=(x_i%5Ej)%5Cin%20M_%7Bn,p%7D(%5Cmathbb%7BR%7D),%5Cboldsymbol%7BZ%7D=(z_i%5Ej)%5Cin%20M_%7Bn,r%7D(%5Cmathbb%7BR%7D)%0A"> を行列することに注意．</p>
</section>
<section id="概要" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="概要"><span class="header-section-number">1.2</span> 概要</h3>
<p>PCA ではデータ行列を <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BX%7D:=%5Cbegin%7Bpmatrix%7Dx_1%5E%5Ctop%5C%5C%5Cvdots%5C%5Cx_n%5E%5Ctop%5Cend%7Bpmatrix%7D%5Cin%20M_%7Bn,p%7D(%5Cmathbb%7BR%7D)%0A"> で定めたとき，データ次元 <img src="https://latex.codecogs.com/png.latex?p"> より小さい数の成分 <img src="https://latex.codecogs.com/png.latex?r"> で説明しようとする： <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BX%7D%5Capprox%5Cboldsymbol%7BZ%7DC%5E%5Ctop,%5Cqquad%5Cboldsymbol%7BZ%7D:=%5Cbegin%7Bpmatrix%7Dz_1%5E%5Ctop%5C%5C%5Cvdots%5C%5Cz_n%5E%5Ctop%5Cend%7Bpmatrix%7D%5Cin%20M_%7Bn,r%7D(%5Cmathbb%7BR%7D),C%5Cin%20M_%7Bp,r%7D(%5Cmathbb%7BR%7D).%0A"></p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li>古典的には，<img src="https://latex.codecogs.com/png.latex?z_%7Bij%7D"> を（主成分）<strong>得点</strong> (score)，<img src="https://latex.codecogs.com/png.latex?Z%5Ei"> を <strong>合成変量</strong>，<img src="https://latex.codecogs.com/png.latex?c_%7Bij%7D"> を <strong>負荷量</strong> (loading) ともいう <span class="citation" data-cites="足立-山本2024">(足立浩平 and 山本倫生, 2024)</span>．</li>
<li>機械学習では <img src="https://latex.codecogs.com/png.latex?Z%5E1,%5Ccdots,Z%5Er"> を <strong>潜在因子</strong>，<img src="https://latex.codecogs.com/png.latex?W%5Cin%20M_%7Bpr%7D(%5Cmathbb%7BR%7D)"> を <strong>荷重</strong> (weight) ともいう <span class="citation" data-cites="Murphy2022">(Murphy, 2022)</span>．</li>
</ul>
</div>
</div>
</div>
<p>この問題は <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BX%7D"> の <a href="../../../posts/2024/FunctionalAnalysis/SVD.html">特異値分解</a> (SVD) <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BX%7D=U%5CSigma%20V%5E%5Ctop"> により解ける： <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BZ%7D=U%5CSigma_%7B1:r%7D%5E%5Calpha%20A=%5Cboldsymbol%7BX%7D(%5Cunderbrace%7BV%5CSigma%5E%7B%5Calpha-1%7D_%7B1:r%7DA%7D_%7B=:W%7D),%5Cqquad%20C:=V%5CSigma_%7B1:r%7D%5E%7B1-%5Calpha%7D(A%5E%7B-1%7D)%5E%5Ctop.%0A"> ただし，<img src="https://latex.codecogs.com/png.latex?%5Calpha%5Cin%5Cmathbb%7BR%7D,A%5Cin%5Cmathrm%7BGL%7D_p(%5Cmathbb%7BR%7D)"> は任意である．この解は，特異値分解の性質により，残差を Hilbert-Schmidt ノルムの意味で最小にする： <span id="eq-PCA-objective"><img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_C%5C%7C%5Cboldsymbol%7BX%7D-%5Cboldsymbol%7BZ%7DC%5E%5Ctop%5C%7C_%5Cmathrm%7BHS%7D=%5Cmin_C%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi=1%7D%5En%5Clvert%20x_i-Cz_i%5Crvert%5E2=%5Csigma_%7Br+1%7D%0A%5Ctag%7B1%7D"></span> この目的関数は復元誤差とも理解できる．ただし，<img src="https://latex.codecogs.com/png.latex?%5Csigma_%7Br+1%7D"> は行列 <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BZ%7DC"> の第 <img src="https://latex.codecogs.com/png.latex?r+1"> 特異値である．</p>
</section>
<section id="主成分分散最大化" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="主成分分散最大化"><span class="header-section-number">1.3</span> 主成分分散最大化</h3>
<p>荷重行列 <img src="https://latex.codecogs.com/png.latex?W"> が <img src="https://latex.codecogs.com/png.latex?W%5E%5Ctop%20W=I_r"> を満たすという制約条件を追加すると，目的関数 (1) は潜在変数の分散を最大にすることと等価になる： <span id="eq-PCA-objective2"><img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname*%7Bargmin%7D_%7BW%7D%5C%7C%5Cboldsymbol%7BX%7D-%5Cboldsymbol%7BZ%7DW%5C%7C_%5Cmathrm%7BHS%7D=%5Coperatorname*%7Bargmin%7D_W%5Coperatorname%7BTr%7D((%5Cboldsymbol%7BX%7DW)%5E%5Ctop%5Cboldsymbol%7BX%7DW).%0A%5Ctag%7B2%7D"></span></p>
<p>すなわち，<img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BZ%7D=%5Cboldsymbol%7BX%7DW"> の変動が差大になるようにすれば良い．</p>
<p>そのためには，確率変数 <img src="https://latex.codecogs.com/png.latex?X"> のデータ行列 <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BX%7D"> から計算した経験共分散行列 <img src="https://latex.codecogs.com/png.latex?S%5Cin%20M_%7Bp%7D(%5Cmathbb%7BR%7D)_+"> の固有ベクトルのうち，対応する固有値が大きいものから <img src="https://latex.codecogs.com/png.latex?w_1,%5Ccdots,w_r"> として荷重行列とすれば良い： <img src="https://latex.codecogs.com/png.latex?%0AW:=(w_1%5C;%5Ccdots%5C;w_r).%0A"></p>
<p>実はこれは解の１つに過ぎず，<img src="https://latex.codecogs.com/png.latex?W"> に右から直交行列を乗じて「回転」させたものは全て解になる．上の解は追加の条件 <img src="https://latex.codecogs.com/png.latex?Z%5E%5Ctop%20Z=I_r"> を課すことで特定される．</p>
</section>
<section id="計算上の注意" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="計算上の注意"><span class="header-section-number">1.4</span> 計算上の注意</h3>
<p>各次元に関する長さのスケールを揃えるために，PCA を始める前にデータを正規化しておくか，または共分散行列 <img src="https://latex.codecogs.com/png.latex?S"> の代わりに，相関行列を用いるべきである．</p>
<p>また，実際に最適化や相関行列の固有値分解をすることはなく，基本的に SVD の方が <img src="https://latex.codecogs.com/png.latex?O(np%5E2)+O(p%5E3)"> と高速である <span class="citation" data-cites="Unkel-Trendafilov2010">(Unkel and Trendafilov, 2010)</span>．</p>
<p>さらに次元 <img src="https://latex.codecogs.com/png.latex?p"> が高い場合は，<strong>確率的 SVD</strong> <span class="citation" data-cites="Halko+2011">(Halko et al., 2011)</span>, <span class="citation" data-cites="Drineas+2016">(Drineas and Mahoney, 2016)</span> を用いてさらに <img src="https://latex.codecogs.com/png.latex?O(nr%5E2)+(r%5E3)"> まで削減できる．このような手法は確率的数値解析と呼ばれる <span class="citation" data-cites="Murray+2023">(Murray et al., 2023)</span>．</p>
</section>
<section id="sec-dimension-reduction" class="level3" data-number="1.5">
<h3 data-number="1.5" class="anchored" data-anchor-id="sec-dimension-reduction"><span class="header-section-number">1.5</span> 線型射影による次元縮約</h3>
<p><img src="https://latex.codecogs.com/png.latex?W%5E%5Ctop%20W=I_r"> の仮定の下で，PCA の目的関数 (1) は，潜在変数の分散最大化 (2) と見れるのだった．</p>
<p>これは同じ仮定の下で，データ変数 <img src="https://latex.codecogs.com/png.latex?X"> の最小誤差の線型射影を求める問題とも見れる： <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname*%7Bargmin%7D_W%5C%7C%5Cboldsymbol%7BX%7D-%5Cboldsymbol%7BZ%7DW%5C%7C_%5Cmathrm%7BHS%7D=%5Coperatorname*%7Bargmin%7D_W%5C%7C%5Cboldsymbol%7BX%7D-%5Cboldsymbol%7BX%7DWW%5E%5Ctop%5C%7C_%5Cmathrm%7BHS%7D.%0A"></p>
<p>なお，一般の行列 <img src="https://latex.codecogs.com/png.latex?A"> について <img src="https://latex.codecogs.com/png.latex?P_A=A(A%5E%7B-1%7DA)%5E+A%5E%5Ctop"> は <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BIm%7D%5C,A"> 上の直交射影になる．<img src="https://latex.codecogs.com/png.latex?A"> が直交行列であるとき，<img src="https://latex.codecogs.com/png.latex?P_A=AA%5E%5Ctop"> が成り立つ．</p>
</section>
<section id="因子分析志向の主成分分析" class="level3" data-number="1.6">
<h3 data-number="1.6" class="anchored" data-anchor-id="因子分析志向の主成分分析"><span class="header-section-number">1.6</span> 因子分析志向の主成分分析</h3>
<p>因子分析では，<img src="https://latex.codecogs.com/png.latex?Z%5E1,%5Ccdots,Z%5Er"> を対等な因子と見て，それぞれのデータへの影響を調べたい．このような場合は， <img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B1%7D%7Bn%7D%5Cboldsymbol%7BZ%7D%5E%5Ctop%5Cboldsymbol%7BZ%7D=I_r%0A"> が自然な制約になる．この際の解は，直交行列 <img src="https://latex.codecogs.com/png.latex?T%5Cin%20O_r(%5Cmathbb%7BR%7D)"> の違いを除いて， <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BZ%7D=%5Csqrt%7Bn%7DUT,%5Cqquad%20C=%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%7D%7DV%5CSigma_%7B1:r%7DT,%5Cqquad%20W=%5Csqrt%7Bn%7DV%5CSigma_%7B1:r%7D%5E%7B-1%7DT,%0A"> まで確定する．</p>
<p>しばしば，追加の仮定 <img src="https://latex.codecogs.com/png.latex?%0AC%5E%5Ctop%20C=%5Cmathrm%7Bdiag%7D(%5Crho_%7B1:r%7D),%5Cqquad%20%5Crho_1%5Cge%5Ccdots%5Cge%5Crho_r%5Cge0%0A"> を課して得られる一意な解 <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BZ%7D=%5Csqrt%7Bn%7DU,%5Cqquad%20C=%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%7D%7DV%5CSigma_%7B1:r%7D,%5Cqquad%20W=%5Csqrt%7Bn%7DV%5CSigma_%7B1:r%7D%5E%7B-1%7D,%0A"> を <strong>初期解</strong> と呼び，これを「回転」させることで他の解が探索され，所望の分解を探す．</p>
<p>因子分析では <span class="citation" data-cites="Thurstone1947">(Thurstone, 1947)</span> 以来，種々の回転法とアルゴリズムが蓄積している <span class="citation" data-cites="足立-山本2024">(足立浩平 and 山本倫生, 2024)</span>．一般にこの文脈では，<span class="citation" data-cites="Thurstone1947">(Thurstone, 1947)</span> にいう「単純構造」を達成した，解釈が容易な因子をドメイン知識に基づいて構成することを目指す．この「単純構造」とは，現代でいう一種の disentangled factor と理解できる．</p>
</section>
</section>
<section id="sec-FA" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="sec-FA"><span class="header-section-number">2</span> 因子分析 (FA)</h2>
<section id="はじめに-2" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="はじめに-2"><span class="header-section-number">2.1</span> はじめに</h3>
<p>主成分分析が「低階数近似」ならば，因子分析は「高階数近似」というべきである <span class="citation" data-cites="足立浩平2023">(足立浩平, 2023)</span>．</p>
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/FA.svg" class="img-fluid"></p>
<p>より正確には，因子分析は，観測の各次元 <img src="https://latex.codecogs.com/png.latex?X%5E1,%5Ccdots,X%5Ep"> ごとに「独自因子」<img src="https://latex.codecogs.com/png.latex?Z%5E1,%5Ccdots,Z%5Ep"> を想定しつつ，全観測に共通する「共通因子」<img src="https://latex.codecogs.com/png.latex?F%5E1,%5Ccdots,F%5Er"> をどのように抽出できるかを考える，という志向性を持つ：</p>
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/FA2.svg" class="img-fluid"></p>
<p>この意味では，FA は独自因子 <img src="https://latex.codecogs.com/png.latex?U%5E1,%5Ccdots,U%5Ep"> を追加した PCA とも理解できる．</p>
<p>歴史的には <span class="citation" data-cites="Spearman1904">(Spearman, 1904)</span> が古典テスト理論の文脈で <img src="https://latex.codecogs.com/png.latex?r=1"> の因子分析を，<span class="citation" data-cites="Thurstone1947">(Thurstone, 1947)</span> が一般の <img src="https://latex.codecogs.com/png.latex?1%5Cle%20r%3Cp"> の場合の因子分析を「回転」の手法と共に導入した．</p>
<p>さらに興味深いことに，FA では PCA をはじめとした多くの多変量分析手法と違い，<span class="citation" data-cites="Lawley1942">(Lawley, 1942)</span>, <span class="citation" data-cites="Anderson-Rubin1956">(Anderson and Rubin, 1956)</span> らにより，初期から確率的な扱いが発展した手法である <span class="citation" data-cites="足立-山本2024">(足立浩平 and 山本倫生, 2024)</span>．</p>
<p>FA に倣う形で，PCA にも確率論的なアプローチが導入された <span class="citation" data-cites="Tipping-Bishop1999">(Tipping and Bishop, 1999)</span>, <span class="citation" data-cites="Roweis1997">(Roweis, 1997)</span>．</p>
</section>
<section id="概要-1" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="概要-1"><span class="header-section-number">2.2</span> 概要</h3>
<p>FA では <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BZ%7D=(%5Cboldsymbol%7BF%7D%5C;%5Cboldsymbol%7BU%7D)%5Cin%20M_%7Bn,r+p%7D(%5Cmathbb%7BR%7D)"> の分解に基づき， <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BX%7D%5Capprox%5Cboldsymbol%7BF%7DA%5E%5Ctop+%5Cboldsymbol%7BU%7D%5CPsi%5E%7B1/2%7D,%5Cqquad%20A%5Cin%20M_%7Br,p%7D(%5Cmathbb%7BR%7D),%5CPsi=%5Cmathrm%7Bdiag%7D(%5Cpsi_1,%5Ccdots,%5Cpsi_p)%5Cin%20M_p(%5Cmathbb%7BR%7D),%0A"> によってデータ行列 <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BX%7D%5Cin%20M_%7Bn,p%7D(%5Cmathbb%7BR%7D)"> を説明しようとする．<sup>2</sup></p>
<p>PCA よりさらに識別可能性は絶望的であるが，FA では潜在変数の解釈可能性担保のため，次の仮定を課す： <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7B1%7D_n%5E%5Ctop%5Cboldsymbol%7BF%7D=%5Cboldsymbol%7B0%7D_r,%5Cqquad%20%5Cboldsymbol%7B1%7D_n%5E%5Ctop%5Cboldsymbol%7BU%7D=%5Cboldsymbol%7B0%7D_p,%0A"> <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BF%7D%5E%5Ctop%5Cboldsymbol%7BF%7D=n%5Cboldsymbol%7BI%7D_r,%5Cqquad%20%5Cboldsymbol%7BU%7D%5E%5Ctop%5Cboldsymbol%7BU%7D=n%5Cboldsymbol%7BI%7D_p,%5Cqquad%5Cboldsymbol%7BF%7D%5E%5Ctop%5Cboldsymbol%7BU%7D=O.%0A"> すなわち，推定される確率変数 <img src="https://latex.codecogs.com/png.latex?F,U"> が標準化されていて互いに無相関であるように誘導する．</p>
<p>また，<img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BU%7D"> の経験分散が <img src="https://latex.codecogs.com/png.latex?%5CPsi"> になることに注意．</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li>古典的には，<img src="https://latex.codecogs.com/png.latex?f_%7Bij%7D"> を共通因子，<img src="https://latex.codecogs.com/png.latex?%5Cpsi_j"> を独自因子の <strong>得点</strong> (score)，<img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> を <strong>負荷量</strong> (loading) ともいう <span class="citation" data-cites="足立-山本2024">(足立浩平 and 山本倫生, 2024)</span>．</li>
<li>機械学習では <img src="https://latex.codecogs.com/png.latex?Z%5E1,%5Ccdots,Z%5Er"> を <strong>潜在因子</strong>，<img src="https://latex.codecogs.com/png.latex?W%5Cin%20M_%7Bpr%7D(%5Cmathbb%7BR%7D)"> を <strong>荷重</strong> (weight) ともいう <span class="citation" data-cites="Murphy2022">(Murphy, 2022)</span>．</li>
</ul>
</div>
</div>
</div>
<p>この問題は，<img src="https://latex.codecogs.com/png.latex?C:=(A%5C;%5CPsi%5E%7B1/2%7D)"> と定めると，PCA と同じ問題 (1) に帰着される： <img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_C%5C%7C%5Cboldsymbol%7BX%7D-%5Cboldsymbol%7BZ%7DC%5E%5Ctop%5C%7C_%5Cmathrm%7BHS%7D.%0A"></p>
<p>これはやはり特異値分解により解くことができる <span class="citation" data-cites="DeLeeuw04-SimultaneousEstimationOfEFA">(De Leeuw, 2004)</span>．</p>
<p>解は直交行列による回転を除いても，やはり一意に定まらないようである．</p>
</section>
<section id="確率的アプローチ" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="確率的アプローチ"><span class="header-section-number">2.3</span> 確率的アプローチ</h3>
<p>ここで， <img src="https://latex.codecogs.com/png.latex?%0AU:=%5Cbegin%7Bpmatrix%7DU%5E1%5C%5C%5Cvdots%5C%5CU%5Ep%5Cend%7Bpmatrix%7D%5Cin%5Cmathcal%7BL%7D(%5COmega;%5Cmathbb%7BR%7D%5Ep),%5Cqquad%20F:=%5Cbegin%7Bpmatrix%7DF%5E1%5C%5C%5Cvdots%5C%5CF%5Er%5Cend%7Bpmatrix%7D%5Cin%5Cmathcal%7BL%7D(%5COmega;%5Cmathbb%7BR%7D%5Er),%0A"> を確率変数とすると， <span id="eq-probabilistic-FA"><img src="https://latex.codecogs.com/png.latex?%0AX%5Capprox%20AF+%5CPsi%5E%7B1/2%7DU%0A%5Ctag%7B3%7D"></span> によって <img src="https://latex.codecogs.com/png.latex?X"> に確率モデルが誘導されることになる．</p>
<section id="sec-PPCA" class="level4" data-number="2.3.1">
<h4 data-number="2.3.1" class="anchored" data-anchor-id="sec-PPCA"><span class="header-section-number">2.3.1</span> 正規性の仮定</h4>
<p><img src="https://latex.codecogs.com/png.latex?U,F"> に正規性の仮定をおけば，このモデルは EM アルゴリズムなどを用いて最尤推定できる <span class="citation" data-cites="Rubin-Thayer1982">(Rubin and Thayer, 1982)</span>, <span class="citation" data-cites="Ghahramani-Hinton1996">(Ghahramani and Hinton, 1996)</span>．このような最尤推定のアプローチは <span class="citation" data-cites="Lawley1942">(Lawley, 1942)</span> から考えられていた．</p>
<p>この見方が PCA にも応用された．追加の仮定 <img src="https://latex.codecogs.com/png.latex?%0AA%5E%5Ctop%20A=I_%7Br%7D,%5Cqquad%20%5CPsi=%5Csigma%5E2I_p,%0A"> の下での FA への確率論的アプローチを probabilistic PCA <span class="citation" data-cites="Tipping-Bishop1999">(Tipping and Bishop, 1999)</span> / SPCA (Sensible PCA) <span class="citation" data-cites="Roweis1997">(Roweis, 1997)</span> という．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cto0"> の極限で古典的 PCA が回復される．</p>
</section>
<section id="共分散構造分析" class="level4" data-number="2.3.2">
<h4 data-number="2.3.2" class="anchored" data-anchor-id="共分散構造分析"><span class="header-section-number">2.3.2</span> 共分散構造分析</h4>
<p>一方で，分布の仮定は課さず，<img src="https://latex.codecogs.com/png.latex?X"> の経験分散 <img src="https://latex.codecogs.com/png.latex?S"> を，式 (3) の右辺の共分散 <img src="https://latex.codecogs.com/png.latex?%0A%5CSigma:=AA%5E%5Ctop+%5CPsi%0A"> となるべく近づけるように学習する方法もある．</p>
<p>例えば <span class="citation" data-cites="Harman-Jones1966">(Harman and Jones, 1966)</span>, <span class="citation" data-cites="Harman-Fukuda1966">(Harman and Fukuda, 1966)</span> では，Hilbert-Schmidt ノルム <img src="https://latex.codecogs.com/png.latex?%5C%7CS-%5CSigma%5C%7C_%5Cmathrm%7BHS%7D"> の最小化することで解を探索する方法が考慮された．</p>
<p>このように，データの共分散行列を低階数近似するアプローチは <strong>共分散構造分析</strong> <span class="citation" data-cites="Bock-Bargmann1966">(Bock and Bargmann, 1966)</span> ともいう．</p>
<p>さらに，確率論的なアプローチは一般の構造方程式モデル (SEM, 次節 3 参照) へと発展 <span class="citation" data-cites="Joreskog70">(Karl Gustav Jöreskog, 1970)</span>, <span class="citation" data-cites="Sorbom1974">(Sörbom, 1974)</span>, <span class="citation" data-cites="Joreskog1978">(Karl G. Jöreskog, 1978)</span> し，現状，共分散構造分析は SEM の特別な場合と解される．<sup>3</sup></p>
</section>
</section>
<section id="スパース推定" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="スパース推定"><span class="header-section-number">2.4</span> スパース推定</h3>
<p>FA のモデルは識別可能とは程遠く，解釈可能性が重要である．<span class="citation" data-cites="Thurstone1947">(Thurstone, 1947)</span> は因子付加行列が「単純構造」を持つことを一つの指標としたが，現代的にはスパース推定の言葉で与えられた <strong>完全単純構造</strong> <span class="citation" data-cites="Bernaards-Jennrich2003">(Bernaards and Jennrich, 2003)</span> を仮定することが増えてきた．</p>
<p><strong>スパース PCA</strong> <span class="citation" data-cites="Zou+2006">(Zou et al., 2006)</span>, <span class="citation" data-cites="Jolliffe+2003">(Ian T Jolliffe and Uddin, 2003)</span> では，従来の SVD + 回転ではなく，LASSO 様の <img src="https://latex.codecogs.com/png.latex?L%5E1">-正則化項によって，解釈可能な因子付加行列を得ようとする．最終的に得られる目的関数は elastic net <span class="citation" data-cites="Zou-Hastie2005">(Zou and Hastie, 2005)</span> 様になる．</p>
<p>等価だが，自動関連度決定 (ARD) を用いた <strong>Bayesian PCA</strong> <span class="citation" data-cites="Bishop1998">(Bishop, 1998)</span>, <span class="citation" data-cites="Archambeau-Bach2008">(Archambeau and Bach, 2008)</span> や spike-and-slab <span class="citation" data-cites="Rattray+2009">(Rattray et al., 2009)</span> など，スパース性を促す事前分布を用いることもできる．</p>
</section>
<section id="sec-other-priors-FA" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="sec-other-priors-FA"><span class="header-section-number">2.5</span> その他の事前分布</h3>
<p>非正規な事前分布（特に Laplace 分布やロジスティック分布などの裾の重いもの）を用いることで，モデルが識別可能性を回復することがある．</p>
<p>このように，<a href="../../../posts/2024/Kernels/NCL.html#sec-identifiability">一般の設定で潜在変数モデルが識別可能になるための条件が，非線型独立分析の分野で提案されている</a> <span class="citation" data-cites="Khemakhem+2020">(Khemakhem et al., 2020)</span>．</p>
<section id="gamma-分布" class="level4" data-number="2.5.1">
<h4 data-number="2.5.1" class="anchored" data-anchor-id="gamma-分布"><span class="header-section-number">2.5.1</span> Gamma 分布</h4>
<p>また，Gamma 事前分布は非負かつスパースな表現を促進し，カウントデータとよく用いられる <span class="citation" data-cites="Canny2004">(Canny, 2004)</span>．</p>
<p>これは環境科学分野の Positive Matrix Factorization <span class="citation" data-cites="Paatero-Tapper1994">(Paatero and Tapper, 1994)</span> や信号処理分野の Nonnegative Matrix Factorization (NMF) <span class="citation" data-cites="Lee-Seung1999">(Lee and Seung, 1999)</span> の，確率論的な一般化と見れる <span class="citation" data-cites="Buntine-Jakulin2006">(Buntine and Jakulin, 2006)</span>．</p>
</section>
<section id="dirichlet-分布" class="level4" data-number="2.5.2">
<h4 data-number="2.5.2" class="anchored" data-anchor-id="dirichlet-分布"><span class="header-section-number">2.5.2</span> Dirichlet 分布</h4>
<p>また，Dirichlet 事前分布を用いることで，潜在変数 <img src="https://latex.codecogs.com/png.latex?Z%5Cin%5Cmathcal%7BL%7D(%5COmega;%5Cmathbb%7BR%7D%5Er)"> に <img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi=1%7D%5ErZ%5Ei=1%0A"> が課されるため，「各次元への依存度」のような意味づけが可能になる．これは政治学における空間分析において，「どの立場への傾倒が強いか」を推定することにも用いられる <span class="citation" data-cites="Buntine-Jakulin2006">(Buntine and Jakulin, 2006)</span>．</p>
<p>このモデルは multinomial PCA <span class="citation" data-cites="Buntine-Jakulin2006">(Buntine and Jakulin, 2006)</span> の他に，遺伝学で admixture <span class="citation" data-cites="Pritchard+2000">(Pritchard et al., 2000)</span>，simplex factor analysis <span class="citation" data-cites="Bhattacharya-Dunson2012">(Bhattacharya and Dunson, 2012)</span>, 科学出版で mixed-membership model <span class="citation" data-cites="Erosheva+2004">(Erosheva et al., 2004)</span>，マーケティングで user rating profile model <span class="citation" data-cites="Marlin2003">(Marlin, 2003)</span> など，種々の分野で独立に提案されている．</p>
</section>
</section>
<section id="非線型化" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="非線型化"><span class="header-section-number">2.6</span> 非線型化</h3>
<p>FA の一般化の方向性として，正規性の緩和の他に，線型性の緩和があり得る．</p>
<p>MCMC による推論 <span class="citation" data-cites="Hoffman2017">(Hoffman, 2017)</span> をすることも，または指数型分布 <span class="citation" data-cites="Collins+2001">(Collins et al., 2001)</span> への拡張や，VAE による非線型化を通じて変分推論をすることも考えられる．</p>
<p><a href="../../../posts/2024/Kernels/Deep4.html#sec-AE">自己符号化器</a> は，まさに非線型な潜在変数モデルに対する最尤推定を行っており，４層以上のニューラルネットワークを用いることで PCA を非線型化して一般化することができる．<sup>4</sup></p>
<p>また，カーネル法と Gauss 過程により非線型化することもできる <span class="citation" data-cites="Lawrence2005">(Lawrence, 2005)</span>．</p>
</section>
<section id="sec-MixFA" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="sec-MixFA"><span class="header-section-number">2.7</span> 混合モデリング</h3>
<p>複数の線型 Gauss 因子分析モデルの重ね合わせとみなす <strong>mixture of factor analysers</strong> <span class="citation" data-cites="Ghahramani-Hinton1996">(Ghahramani and Hinton, 1996)</span> も単純ながら表現が高く，EM アルゴリズムや SGD <span class="citation" data-cites="Ricahrdson-Weiss2018">(Richardson and Weiss, 2018)</span>, <span class="citation" data-cites="Zong+2018">(Zong et al., 2018)</span> によって推定できる．</p>
<p><span class="citation" data-cites="Ricahrdson-Weiss2018">(Richardson and Weiss, 2018)</span> では生成モデルとしての性能も GAN と劣らないこと，VAE や GAN などの生成モデルよりも分布へのフィッティングが良いことを報告している．</p>
<p>さらにこのアプローチはノンパラメトリックベイズ法につながる．この方法では，例えば <span class="citation" data-cites="Paisley-Carin2009">(Paisley and Carin, 2009)</span> では Beta 過程事前分布をおき，Gibbs サンプラーで推論することで，混合数 <img src="https://latex.codecogs.com/png.latex?K"> も同時に自動で決定できる．</p>
</section>
</section>
<section id="sec-SEM" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="sec-SEM"><span class="header-section-number">3</span> 構造方程式モデリング (SEM)</h2>
<section id="はじめに-3" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="はじめに-3"><span class="header-section-number">3.1</span> はじめに</h3>
<p><span class="citation" data-cites="Joreskog1969">(K. G. Jöreskog, 1969)</span> は因子分析モデルを潜在変数モデルとして，事前情報を取り入れるなど柔軟に用いた．</p>
<p>特に，データを（現代でいう）訓練データと検証データに分けて，因子分析により推定された潜在変数間の関数関係を検定するための方法を提案し <span class="citation" data-cites="Joreskog-Lawley1968">(K. G. Jöreskog and Lawley, 1968)</span>，これを <strong>検証的因子分析</strong> (Confirmatory FA) と呼び，それ以前の手法に <strong>探索的因子分析</strong> というレトロニムを与えた．<sup>5</sup></p>
<p>最終的に，潜在変数同士により一般的な関数関係も考慮したものなど多くの潜在変数モデルが，共分散構造に基づいた非線型数値最適化を推論エンジンとして統一的に推定できることに辿り着いた．<sup>6</sup></p>
<p>このことに加えて，潜在変数間の関数関係に適切な仮定をおくことで，因果推論・高次の因子分析・分散分析など従来考慮されなかった新たなタスクにも適用可能であることも了解された <span class="citation" data-cites="Joreskog1978">(Karl G. Jöreskog, 1978)</span>, <span class="citation" data-cites="Bentler1980">(Bentler, 1980)</span>．<sup>7</sup></p>
<p>現代では特徴抽出，生成，表現学習にも用いられていると思うと感慨である．</p>
<p>これを <strong>共分散構造分析</strong> または <strong>構造方程式モデリング</strong> (SEM: Structural Equation Modeling) という．<sup>8</sup> 心理学の文脈では，潜在変数のことを <strong>構成概念</strong> (construct) と呼び，潜在変数間は無関係とした従来の因果分析モデルを <strong>測定方程式</strong> と呼ぶ．<sup>9</sup></p>
</section>
<section id="sec-PLS" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="sec-PLS"><span class="header-section-number">3.2</span> 部分最小自乗モデル (PLS)</h3>
<p>PLS (Partial Least Square) モデル <span class="citation" data-cites="Joreskog-Wold1982">(K. G. Jöreskog and Wold, 1982)</span>, <span class="citation" data-cites="Gustafsson2001">(Gustafsson, 2001)</span> では，次のような潜在変数モデルを用いて，２つの構成概念間の因果関係を評価しようとする <span class="citation" data-cites="豊田秀樹1991">(豊田秀樹, 1991)</span>：</p>
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/PLS.svg" class="img-fluid"></p>
<p>なお，パス図において，潜在変数から観測変数に矢印が伸びている場合，これは影響的指標と呼ばれ，観測のモデルと解され，誤差が入ることが想定される <span class="citation" data-cites="豊田秀樹1991">(豊田秀樹, 1991)</span>．<sup>10</sup> 逆の矢印は形成的指標という．</p>
<p>すなわち，PLS では，<img src="https://latex.codecogs.com/png.latex?X%5E1,X%5E2,X%5E3,%5Ccdots"> には，<img src="https://latex.codecogs.com/png.latex?Z%5E1,Z%5E2,%5Ccdots"> とは独立な独自因子が作用していると仮定されている．</p>
<p>このような仮定は，<img src="https://latex.codecogs.com/png.latex?Y%5E1,Y%5E2,%5Ccdots"> を被説明変数として，教師あり PCA <span class="citation" data-cites="Yu+2006">(Yu et al., 2006)</span> に有用である．</p>
<p>というのも，被説明変数のうち必ずしも <img src="https://latex.codecogs.com/png.latex?Y%5E1,Y%5E2,%5Ccdots"> に関係する要素が全てとは限らないために，<img src="https://latex.codecogs.com/png.latex?Z%5E1,Z%5E2"> の間で間接的に回帰分析を行いたい場合に自然な設定である <span class="citation" data-cites="Nounou+2002">(Nounou et al., 2002)</span>．</p>
</section>
<section id="構造方程式モデリングの発展" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="構造方程式モデリングの発展"><span class="header-section-number">3.3</span> 構造方程式モデリングの発展</h3>
<p>PLS において，潜在変数から構成概念への矢印が全て影響的であった場合，これは潜在因子の間に関係が仮定されていることを除いて，（探索的）因子分析と等価になる．</p>
<p>一般に，SEM は，潜在変数同士の関数関係も考慮した因子分析モデルだと理解できる．</p>
<p>このようなモデルは，社会学において <strong>多重指標分析</strong> と呼ばれていたモデルに相当し <span class="citation" data-cites="白倉幸男1984">(白倉幸男, 1984)</span> <span class="citation" data-cites="清水和秋1989">(清水和秋, 1989)</span>，経済学において <strong>同時方程式モデル</strong> と呼ばれていたモデルに相当する <span class="citation" data-cites="Bentler1980">(Bentler, 1980)</span>．<sup>11</sup></p>
<p>加えて，心理学・行動計量学においても，多くの既存の多変量解析法（因子分析，パス解析，二段階抽出モデル，潜在構造分析，項目反応モデルなど）はいずれも SEM の特殊な形だと解釈できることが自覚された <span class="citation" data-cites="McArdle1984">(McArdle, 1984)</span>, <span class="citation" data-cites="Muthen2002">(Muthén, 2002)</span>．<sup>12</sup></p>
<p>こうして SEM の名と LISREL プログラムの下で，多くの社会科学分野で使われていたモデルが，形式的にはほとんど等価であるという了解が形成されていった．</p>
<p>このことから，SEM は第二世代の多変量解析 <span class="citation" data-cites="Fornell1985">(Fornell, 1985)</span> とも評される．<sup>13</sup></p>
</section>
<section id="計算統計学という要素" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="計算統計学という要素"><span class="header-section-number">3.4</span> 計算統計学という要素</h3>
<p>構造方程式モデリングが普及した理由の一つとして，計算機統計学の発展とうまく合流した点が見逃せない．</p>
<p>そもそも Jöreskog は，因子分析を研究していた時期 <span class="citation" data-cites="Joreskog1966">(Karl G. Jöreskog, 1966)</span> <span class="citation" data-cites="Joreskog1967a">(K. G. Jöreskog, 1967)</span> から，数値的な解法とコンピュータプログラムの開発にも重点を置いていた．特に，因子分析モデルを，<a href="https://ja.wikipedia.org/wiki/DFP法">DFP 法</a> に基づいて数値的に最尤推定する方法を提案した <span class="citation" data-cites="Joreskog1967a">(K. G. Jöreskog, 1967)</span>．</p>
<p>SEM も，コンピュータプログラム LISREL (LInear Structural RELationships) <span class="citation" data-cites="Joreskog-vanThillo1972">(Jőreskog and Thiilo, 1972)</span> の存在が，広い分野の人口に膾炙した要因として大きい <span class="citation" data-cites="清水和秋1989">(清水和秋, 1989)</span>, <span class="citation" data-cites="Grimm-Yarnold2016">(Grimm and Yarnold, 2016)</span>．</p>
<p>構造方程式モデルがどのように因子分析，因果分析，共分散構造分析を統合し，LISREL プログラムと共に発展していたかは，<span class="citation" data-cites="清水和秋1994">(清水和秋, 1994)</span> に大変わかりやすくまとまっている</p>
</section>
<section id="sec-CCA" class="level3" data-number="3.5">
<h3 data-number="3.5" class="anchored" data-anchor-id="sec-CCA"><span class="header-section-number">3.5</span> 正準相関分析 (CCA)</h3>
<p>正準相関分析 <span class="citation" data-cites="Hotelling36">(Hotelling, 1936)</span> においては，２つの構成概念の間は相関関係で結び，すべての観測は形成的な影響を及ぼすとする（観測誤差は想定しない） <span class="citation" data-cites="豊田秀樹1991">(豊田秀樹, 1991)</span>：</p>
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/CCA.svg" class="img-fluid"></p>
<p>このモデルでは <img src="https://latex.codecogs.com/png.latex?X%5E1,X%5E2,X%5E3"> とその潜在要因 <img src="https://latex.codecogs.com/png.latex?Z%5E1">，<img src="https://latex.codecogs.com/png.latex?X%5E4,X%5E5"> とその潜在要因 <img src="https://latex.codecogs.com/png.latex?Z%5E2"> とを完全に対等に扱い，その間の関係を理解しようとする．</p>
<p>例えばマルチモーダル学習において，<img src="https://latex.codecogs.com/png.latex?X,Y"> が類似したタスクに関するデータという場合に応用がある <span class="citation" data-cites="岩瀬-中山2016">(岩瀬智亮 and 中山英樹, 2016)</span>．また，PLS と共に特徴抽出にも用いられる <span class="citation" data-cites="Sun+2009">(Sun et al., 2009)</span>．</p>
<p>複数の標本に対して同時に実行する主成分分析ともみなせるが，別々に PCA を実行した場合と違い「共通要因」を抽出することに志向がある <span class="citation" data-cites="赤穂昭太郎2013">(赤穂昭太郎, 2013)</span>．</p>
<p>なお，正準相関分析が，このような確率論的解釈ができることは <span class="citation" data-cites="Bach-Jordan2005">(Bach and Jordan, 2005)</span> で自覚されたことである．</p>
<p>この潜在変数モデルとしての観点から，<img src="https://latex.codecogs.com/png.latex?Z%5E3,Z%5E4,%5Ccdots"> がある GCCA (Generalized CCA) <span class="citation" data-cites="Horst1961">(Horst, 1961)</span>，指数分布族の場合 <span class="citation" data-cites="Klami+2010">(Klami et al., 2010)</span>，ニューラルネットワークにより非線型にした DCCA <span class="citation" data-cites="Andrew+2013">(Andrew et al., 2013)</span>，さらに変分推論する場合 <span class="citation" data-cites="Wang+2017">(Wang et al., 2017)</span>, <span class="citation" data-cites="Suzuki+2017">(Suzuki et al., 2017)</span> に拡張されている．</p>
<p>質的データをダミーベクトルに変換して（一般化）正準相関分析を行う，質的データの解析法を <strong>対応分析</strong> (correspondence analysis) または <strong>数量化第III類</strong> ともいう．<sup>14</sup></p>
</section>
</section>
<section id="sec-MM" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="sec-MM"><span class="header-section-number">4</span> 混合モデル (MM)</h2>
<section id="はじめに-4" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="はじめに-4"><span class="header-section-number">4.1</span> はじめに</h3>
<p>混合モデルは，次のようなたいへん基本的な設定であるが，第 2.7 節で見たように，例えば因子分析モデルと組み合わせることで極めて豊かな表現力を持つ．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/MM.svg" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>混合モデルは SEM の別の選択肢としても使える．また，ランダム効果要因を明示的にモデルに組み込む意味で，一般線型モデルの確率論的な拡張と考えることもできる <span class="citation" data-cites="狩野裕2002">(狩野裕, 2002)</span>．<sup>15</sup></p>
</section>
<section id="正規混合モデル-gmm" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="正規混合モデル-gmm"><span class="header-section-number">4.2</span> 正規混合モデル (GMM)</h3>
<p><img src="https://latex.codecogs.com/png.latex?Z%5Cin%5Cmathcal%7BL%7D(%5COmega;%5BK%5D)"> は <img src="https://latex.codecogs.com/png.latex?%0A%5BK%5D=%5C%7B1,%5Ccdots,K%5C%7D%0A"> に値を取る離散確率変数で，確率核 <img src="https://latex.codecogs.com/png.latex?Z%5Cto%20X"> が <img src="https://latex.codecogs.com/png.latex?%0Ap(x%7Cz=k)%5C,dx=%5Cmathrm%7BN%7D_p(%5Cmu_k,%5CSigma_k)%0A"> と表せる場合，<img src="https://latex.codecogs.com/png.latex?X"> に課される仮定を <strong>正規混合モデル</strong> (GMM: Gaussian Mixture Model) という．</p>
<p><img src="https://latex.codecogs.com/png.latex?Z%5Csim%5Cmathrm%7BU%7D(%5BK%5D),%5CSigma_k=I"> の場合，これは <a href="../../../posts/2024/Computation/VI2.html#sec-EM-and-K-means"><img src="https://latex.codecogs.com/png.latex?K">-平均クラスタリングに等価</a> なモデルとなる．</p>
<p>これは SGD により訓練をすることで，生成のタスクにおいても GAN に匹敵する性能も持つ <span class="citation" data-cites="Ricahrdson-Weiss2018">(Richardson and Weiss, 2018)</span>．</p>
<p>また，デノイジングや deblurring, inpainting, super-resolution などの画像逆問題は，巨大な GMM の潜在変数の推定として理解できる <span class="citation" data-cites="Zoran-Weiss2011">(Zoran and Weiss, 2011)</span>, <span class="citation" data-cites="Papyam-Elad2016">(Papyan and Elad, 2016)</span>．</p>
</section>
<section id="正規スケール混合モデル-gsm" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="正規スケール混合モデル-gsm"><span class="header-section-number">4.3</span> 正規スケール混合モデル (GSM)</h3>
<p>Gaussian scale mixture モデルとは， <img src="https://latex.codecogs.com/png.latex?%0Ap(x%7Cz)%5C,dx=%5Cmathrm%7BN%7D_p(0,%5Csigma_0%5E2z)%0A"> で定まる階層モデルである．</p>
<p>このモデルは，<img src="https://latex.codecogs.com/png.latex?Z"> の分布により，種々の（特に裾の重い）分布を表せる：</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?Z%5Csim%5Cmathrm%7BBer%7D(%5Cpi)"> のときを spike and slab 分布という： <img src="https://latex.codecogs.com/png.latex?%0Ap(x)%5C,dx=%5Cpi%5Cmathrm%7BN%7D(0,%5Csigma_0%5E2)+(1-%5Cpi)%5Cdelta_0.%0A"></li>
<li><img src="https://latex.codecogs.com/png.latex?Z%5Csim%5Cmathrm%7BC%7D(1)_+"> のとき，<strong>馬蹄分布</strong> <span class="citation" data-cites="Carvalho+2010">(Carvalho et al., 2010)</span> という．<sup>16</sup></li>
</ol>
</div>
</div>
</div>
</section>
<section id="潜在-dirichlet-配分-lda" class="level3" data-number="4.4">
<h3 data-number="4.4" class="anchored" data-anchor-id="潜在-dirichlet-配分-lda"><span class="header-section-number">4.4</span> 潜在 Dirichlet 配分 (LDA)</h3>
<section id="はじめに-5" class="level4" data-number="4.4.1">
<h4 data-number="4.4.1" class="anchored" data-anchor-id="はじめに-5"><span class="header-section-number">4.4.1</span> はじめに</h4>
<p>文書の埋め込み・数値表現を得るために，単語 <img src="https://latex.codecogs.com/png.latex?i%5Cin%5BM%5D"> が文書 <img src="https://latex.codecogs.com/png.latex?j%5Cin%5BN%5D"> に現れた回数をカウントした行列 <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BC%7D%5Cin%20M_%7BMN%7D(%5Cmathbb%7BN%7D)"> を通じた主成分分析が用いることも考えられる．</p>
<p>これを <strong>潜在意味索引</strong> (LSI: Latent Semantic Indexing) <span class="citation" data-cites="Deerwester+1990">(Deerwester et al., 1990)</span> と呼ぶ．得られた低次元埋め込みを文書検索 (document retrieval) などに用いることもできる．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BC%7D"> の列も単語とし，帯幅 <img src="https://latex.codecogs.com/png.latex?h%3E0"> を決めて，<img src="https://latex.codecogs.com/png.latex?h"> 文字以内に単語 <img src="https://latex.codecogs.com/png.latex?i,j%5Cin%5BM%5D"> が共起した回数を <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D"> とすると，全く同様の手続きが，単語の埋め込みに応用できる．これを <a href="https://ja.wikipedia.org/wiki/潜在意味解析"><strong>潜在意味解析</strong></a> (LSA: Latent Semantic Analysis) <span class="citation" data-cites="Deerwester+1990">(Deerwester et al., 1990)</span> と呼ぶ．</p>
</section>
<section id="sec-PLSI" class="level4" data-number="4.4.2">
<h4 data-number="4.4.2" class="anchored" data-anchor-id="sec-PLSI"><span class="header-section-number">4.4.2</span> 確率的潜在意味索引 (PLSI)</h4>
<p><span class="citation" data-cites="Hofmann1999">(Hofmann, 1999)</span> による pLSI または aspect model は LSI を確率モデル，特に混合モデルとして解釈し直したものである．</p>
<p>単語数よりも少ない数の <strong>トピック</strong> <img src="https://latex.codecogs.com/png.latex?Z"> というものがあり，これが単語を決めている，というモデルを想定した．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/PLSI.svg" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>このモデルを通じて，トピック <img src="https://latex.codecogs.com/png.latex?Z"> の分布（あるいは，現代的には <img src="https://latex.codecogs.com/png.latex?%5CTheta"> の値）を「文書」の特徴量とする，というアイデアである．</p>
</section>
<section id="sec-LDA" class="level4" data-number="4.4.3">
<h4 data-number="4.4.3" class="anchored" data-anchor-id="sec-LDA"><span class="header-section-number">4.4.3</span> Dirichlet 事前分布の追加</h4>
<p>変数 <img src="https://latex.codecogs.com/png.latex?%5CTheta"> に Dirichlet 事前分布を追加し，完全なベイズの見方を提示したのが Latent Dirichlet Allocation <span class="citation" data-cites="Blei+2003">(Blei et al., 2003)</span> である．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5CTheta"> を文書，<img src="https://latex.codecogs.com/png.latex?Z"> トピック，<img src="https://latex.codecogs.com/png.latex?W"> をトピックごとの語彙デッキとする．</p>
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/LDA.svg" class="img-fluid"></p>
<p>最終的に，トピック <img src="https://latex.codecogs.com/png.latex?Z"> とその人の語彙 <img src="https://latex.codecogs.com/png.latex?W"> が合わさって，単語 <img src="https://latex.codecogs.com/png.latex?X"> が観測されるというモデルが考えられている．</p>
</section>
<section id="確率的トピックモデル" class="level4" data-number="4.4.4">
<h4 data-number="4.4.4" class="anchored" data-anchor-id="確率的トピックモデル"><span class="header-section-number">4.4.4</span> 確率的トピックモデル</h4>
<p>自然言語処理において，単語分布のモデリングの潜在変数は <strong>トピック</strong> と呼ばれて，これを確率的にモデリングする手法は PTM (Probabilistic Topic Model) <span class="citation" data-cites="Blei2012">(Blei, 2012)</span> と呼ばれている．</p>
<p>「トピック」は短い文章の中でも激しく移り変わることが知られている <span class="citation" data-cites="Church-Gale1991">(Church and Gale, 1991)</span>．</p>
<p>そのため，LDA では，<img src="https://latex.codecogs.com/png.latex?%5CTheta"> の事前分布と <img src="https://latex.codecogs.com/png.latex?W"> の事前分布は， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7BDirichlet%7D(%5Calpha%5Cboldsymbol%7B1%7D),%5Cqquad%5Calpha%3E0,%0A"> という形で，極めて小さい <img src="https://latex.codecogs.com/png.latex?%5Calpha%3E0"> を設定し，特定のトピックがどの文書に現れるかは極めてスパースになるようにモデリングをする．</p>
</section>
<section id="推論" class="level4" data-number="4.4.5">
<h4 data-number="4.4.5" class="anchored" data-anchor-id="推論"><span class="header-section-number">4.4.5</span> 推論</h4>
<p>LDA の推論手法には変分推論 <span class="citation" data-cites="Blei+2003">(Blei et al., 2003)</span> や Gibbs サンプリング <span class="citation" data-cites="Griffith-Steyvers2004">(T. L. Griffiths and Steyvers, 2004)</span>，そしてスペクトルに基づく方法 <span class="citation" data-cites="Arova+2013">(Arora et al., 2013)</span> がある．</p>
<p>トピック数の決定には，尤度を <a href="../../../posts/Surveys/SMCSamplers.html#sec-AIS">焼なまし重点サンプリング</a> で計算する方法 <span class="citation" data-cites="Wallach+2009">(Wallach et al., 2009)</span> の他，ノンパラメトリックベイズ法も用いられる <span class="citation" data-cites="Teh+2006">(Yee Whye Teh and Blei, 2006)</span>．</p>
</section>
<section id="時系列化" class="level4" data-number="4.4.6">
<h4 data-number="4.4.6" class="anchored" data-anchor-id="時系列化"><span class="header-section-number">4.4.6</span> 時系列化</h4>
<p>単語の並びは明らかな方向性があり，対照的なモデリングはこの消息を取り逃がしていると考えられる．</p>
<p>そこで，トピックの移り変わりを捉えるモデルとして dynamic topic model <span class="citation" data-cites="Blei+2006">(Blei and Lafferty, 2006)</span> がある．これは Kalman 平滑化と変分推論を組み合わせている様である．</p>
<p>また単語の時系列構造を捉えるために，LDA に隠れ Markov モデルを組み合わせた LDA-HMM <span class="citation" data-cites="Griffiths+2004">(T. Griffiths et al., 2004)</span> が提案された．TopicRNN <span class="citation" data-cites="Dieng+2017">(Dieng et al., 2017)</span> ではより長距離の相関を捉えるために，<a href="../../../posts/2024/Kernels/Deep.html#sec-RNN2">RNN</a> と組み合わせている．</p>
</section>
</section>
<section id="sec-SSM" class="level3" data-number="4.5">
<h3 data-number="4.5" class="anchored" data-anchor-id="sec-SSM"><span class="header-section-number">4.5</span> 状態空間モデル (SSM)</h3>
<section id="概要-2" class="level4" data-number="4.5.1">
<h4 data-number="4.5.1" class="anchored" data-anchor-id="概要-2"><span class="header-section-number">4.5.1</span> 概要</h4>
<p>状態空間モデル (State Space Model) は，混合モデルの時系列化と捉えられる：</p>
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/SSM.svg" class="img-fluid"></p>
<p>潜在変数 <img src="https://latex.codecogs.com/png.latex?X_t"> が離散的である場合は特に <strong>隠れ Markov モデル</strong> (HMM: Hidden Markov Model) <span class="citation" data-cites="Baum-Petrie1966">(Baum and Petrie, 1966)</span> と呼ばれる．</p>
<p>HMM に関しては早くから EM 様の推定手法 <strong>Baum-Welch アルゴリズム</strong> <span class="citation" data-cites="Baum-Eagon1967">(Baum and Eagon, 1967)</span>, <span class="citation" data-cites="Baum+1970">(Baum et al., 1970)</span> が提案されているが，データサイズが大きい場合は SGD が用いられる．Blocked Gibbs サンプラー <span class="citation" data-cites="Scott2002">(Scott, 2002)</span> や，潜在変数を消去して，周辺尤度に関してスペクトル法／テンソル分解 <span class="citation" data-cites="Hsu+2012">(Hsu et al., 2012)</span>, <span class="citation" data-cites="Anandkumar+2012">(Animashree Anandkumar et al., 2012)</span>, <span class="citation" data-cites="Anandkumar+2015">(Anima Anandkumar et al., 2015)</span>, <span class="citation" data-cites="Obermeyer+2019">(Obermeyer et al., 2019)</span> を実行するなどの代替手法がある．</p>
</section>
<section id="sec-S4" class="level4" data-number="4.5.2">
<h4 data-number="4.5.2" class="anchored" data-anchor-id="sec-S4"><span class="header-section-number">4.5.2</span> 構造的状態系列モデル (S4)</h4>
<p>S4 (Structured State Space Sequence) <span class="citation" data-cites="Gu+2022">(Gu et al., 2022)</span>, <span class="citation" data-cites="Gu+2020">(Gu et al., 2020)</span>, <span class="citation" data-cites="Goel+2022">(Goel et al., 2022)</span> とは，時系列を深層ニューラルネットワークの力でモデリングするために，線型 Gauss で単純な SMM を上下にスタックし深層にしたものである．各層は LSSL (Linear State Space Layer) と呼ばれる．</p>
<p>さらに長距離の依存性に耐えるために，S5 <span class="citation" data-cites="Smith+2023">(Smith et al., 2023)</span> や Mamba <span class="citation" data-cites="Gu-Dao2024">(Gu and Dao, 2024)</span> が提案されている．後者では，選択的に記憶を忘却できるような「選択」機構 (S6: Selective SSM) を導入している．</p>
</section>
</section>
</section>
<section id="sec-ICA" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="sec-ICA"><span class="header-section-number">5</span> 独立成分分析 (ICA)</h2>
<section id="はじめに-6" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="はじめに-6"><span class="header-section-number">5.1</span> はじめに</h3>
<p>（線型）独立成分分析で用いるモデルは，PCA や FA のそれと全く変わらず，線型変換 <img src="https://latex.codecogs.com/png.latex?x_n=Az_n"> でデータを説明しようとする：</p>
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/ICA.svg" class="img-fluid"></p>
<p>ただし，潜在変数 <img src="https://latex.codecogs.com/png.latex?Z%5E1,%5Ccdots,Z%5Er"> は互いに <strong>独立</strong> であるという「真の構造」が強く想定される場合に使われる．</p>
<p>加えて，モデルの <strong>識別可能性</strong> を重視する．このために，（独立）因子分析（第 2.5 節）で考えたように，正規分布より裾の重い事前分布を導入することで，モデルの識別可能性を確約する．<sup>17</sup></p>
<p>この意味で，確率モデルとしては PCA / FA に等価であるが，典型的な ICA の文脈では <img src="https://latex.codecogs.com/png.latex?Z%5E1,%5Ccdots,Z%5Er"> は非正規確率変数であり，<img src="https://latex.codecogs.com/png.latex?A"> を生成荷重や混合行列，<img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> を <strong>認識荷重</strong> (recognition weight) などという．</p>
</section>
<section id="推定手法" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="推定手法"><span class="header-section-number">5.2</span> 推定手法</h3>
<p>最初に <a href="https://ja.wikipedia.org/wiki/ブラインド信号源分離">音源分離</a> について適用された <span class="citation" data-cites="Bell-Sejnowski1995">(Bell and Sejnowski, 1995)</span> では，<img src="https://latex.codecogs.com/png.latex?X"> と <img src="https://latex.codecogs.com/png.latex?Z"> の相互情報量の最大化が目指された．</p>
<p>最尤推定は EM アルゴリズムの他に近似 Newton 法で実行されることもあり，fast ICA <span class="citation" data-cites="Hyvarinen-Oja2000">(Hyvärinen and Oja, 2000)</span> と呼ばれる．</p>
<p>また古典的には，探索的データ解析で考案された <strong>射影追跡</strong> (PP: Projection Pursuit) <span class="citation" data-cites="Friedman-Tukey1974">(Friedman and Tukey, 1974)</span> みたく，学習される <img src="https://latex.codecogs.com/png.latex?Z"> の分布が Gauss からなるべく遠いように学習することも考えられた．</p>
<p>disentangled な表現を学習したい場面では，<img src="https://latex.codecogs.com/png.latex?Z"> の成分同士の相関が最小になるように学習される； <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BKL%7D%5Cleft(%5Coperatorname%7BP%7D%5EZ,%5Cbigotimes_%7Bj=1%7D%5Er%5Coperatorname%7BP%7D%5E%7BZ_j%7D%5Cright).%0A"></p>
<p>最小情報コピュラに基づく方法も提案されている <span class="citation" data-cites="Bedford+2016">(Bedford et al., 2016)</span>, <span class="citation" data-cites="Sei-Yano2024">(Sei and Yano, 2024)</span>．</p>
<p>他にも表現学習や認知科学の文脈を踏襲して，<a href="../../../posts/2024/Kernels/NCL.html#sec-InfoMax">InfoMax</a> やスパース符号化などの原則がある．</p>
</section>
<section id="非線型化-1" class="level3" data-number="5.3">
<h3 data-number="5.3" class="anchored" data-anchor-id="非線型化-1"><span class="header-section-number">5.3</span> 非線型化</h3>
<p><a href="../../../posts/2024/Kernels/NCL.html">非線型独立成分分析は，表現学習の文脈でも研究されている</a>．</p>
</section>
</section>
<section id="おわりに" class="level2 unnumbered unlisted">
<h2 class="unnumbered unlisted anchored" data-anchor-id="おわりに">おわりに</h2>
<p>現代の深層生成モデルは，いずれも非線型な潜在変数モデルであると理解できる．</p>
<p>その意味で，次の記事は全て，本稿の続きであり，本稿は現代の機械学習の壮大な序章としても理解できる．</p>
<div id="listing-kernel-listing" class="quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="RGVlcA==" data-listing-date-sort="1722211200000" data-listing-file-modified-sort="1733137936220" data-listing-date-modified-sort="1723420800000" data-listing-reading-time-sort="2" data-listing-word-count-sort="385">
<a href="../../../posts/2024/Kernels/NCL.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Kernels/Images/contrastive_repr4.jpeg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
表現学習と非線型独立成分分析
</h5>
<div class="card-subtitle listing-subtitle">
「データ理解」に向けた深層潜在変数モデル
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-07-29
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="RGVlcCUyQ05hdHVyZSUyQ1N0YXRpc3RpY3MlMkNHZW9tZXRyeQ==" data-listing-date-sort="1722297600000" data-listing-file-modified-sort="1733137936220" data-listing-date-modified-sort="1723680000000" data-listing-reading-time-sort="3" data-listing-word-count-sort="597">
<a href="../../../posts/2024/Kernels/Manifold.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Kernels/Images/UMAPvSNE.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
非線型な次元縮約法の概観
</h5>
<div class="card-subtitle listing-subtitle">
最古にして最難のタスクと多様体学習
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-07-30
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="RGVlcCUyQ1N1cnZleQ==" data-listing-date-sort="1707609600000" data-listing-file-modified-sort="1733137936196" data-listing-date-modified-sort="1722211200000" data-listing-reading-time-sort="5" data-listing-word-count-sort="883">
<a href="../../../posts/2024/Kernels/Deep.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Kernels/Images/AE.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
数学者のための深層学習概観
</h5>
<div class="card-subtitle listing-subtitle">
歴史と導入
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-11
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
<p>非線形性の他に本稿で扱わなかったものは深層モデルである．</p>
<p>だがそもそも，現代のニューラルネットワークが深層化したのは，単純で可微分なモジュール性を保ちながら表現力を高めるためのトリックであり，確率論的には本稿で扱ったモデルと等価であるはずである．</p>
<p>ニューラルネットワークの他にも，計算のために深層化したモデルを考える場面は多い．例えばアニーリングを用いた <a href="../../../posts/Surveys/SMCSamplers.html">SMC サンプラー</a> は，グラフカルモデル <img src="https://latex.codecogs.com/png.latex?Z%5Cto%20X"> の潜在変数 <img src="https://latex.codecogs.com/png.latex?Z"> の推定を，人工的に時系列構造を見出して状態空間モデル 4.5 にあてはめてサンプリングしやすくする方法と言える．</p>
<p>しかし，<a href="../../../posts/2024/Probability/Kernel.html">確率核は射をなす</a>のだから，全てのモデルは本質的には一層であるとみなすこともできるのである．</p>
<p>この見方をとった方が計算効率が上がるという例もある．例えば <span class="citation" data-cites="Chen+2024">(Chen et al., 2024)</span> では，トランスフォーマーの注意機構をランダム Fourier 特徴写像で近似し，<a href="../../../posts/2024/Kernels/Kernel.html#sec-RFF">Monte Carlo 法によって元のモデルと等価な計算を安価に行っている</a>．</p>
<p><a href="https://puniupa.github.io/posts/2024/AI/BAI.html">ベイズ機械学習</a> や <a href="https://puniupa.github.io/posts/2024/AI/TDL.html">位相的機械学習</a> をはじめとした，丁寧なモデルへの理解が，これからも手法への統一した視点からの理解と，応用分野を横断した相互理解を促進してくれるのではないかと，筆者は意気込んでいる．</p>
</section>




<div id="quarto-appendix" class="default"><section id="扱ったモデル一覧" class="level2 appendix unnumbered"><h2 class="anchored quarto-appendix-heading">扱ったモデル一覧</h2><div class="quarto-appendix-contents">

<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row quarto-layout-valign-bottom">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/PCA.svg" class="img-fluid figure-img"></p>
<figcaption>PCA</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/FA.svg" class="img-fluid figure-img"></p>
<figcaption>FA</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-bottom">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/PLS.svg" class="img-fluid figure-img"></p>
<figcaption>PLS</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/CCA.svg" class="img-fluid figure-img"></p>
<figcaption>CCA</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-bottom">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/PLSI.svg" class="img-fluid figure-img"></p>
<figcaption>PLSI</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/LDA.svg" class="img-fluid figure-img"></p>
<figcaption>LDA</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-bottom">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/SSM.svg" class="img-fluid figure-img"></p>
<figcaption>SSM</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/ICA.svg" class="img-fluid figure-img"></p>
<figcaption>ICA</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/HierarchicalModels.png" class="img-fluid figure-img"></p>
<figcaption><span class="citation" data-cites="Murphy2023">(Murphy, 2023, p. 920)</span> より，本稿で扱ったモデルのいくつかを含んだ，数式による一覧表．すでに図式による解説を受けた後だと，より見やすいだろう．<img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7BCat%7D(c%7C%5Cboldsymbol%7B%5Cpi%7D)"> は確率ベクトル <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Cpi%7D"> が定める質量関数を表す．</figcaption>
</figure>
</div>
</div></section><section id="付録" class="level2 unnumbered appendix"><h2 class="anchored quarto-appendix-heading">付録</h2><div class="quarto-appendix-contents">

<p>ここでは，歴史を感じる引用をいくつか紹介したい．</p>
<blockquote class="blockquote">
<p>心理測定学 (psychometrics) における因子分析，計量経済学 (econometrics) における同時方程式モデル (simultaneous equation models), そして生物測定学 (biometrics) におけるパス解析 (path analysis) を，共分散構造分析の下に統一化することが可能となった契機は，潜在変数 (latent variables) の概念である <span class="citation" data-cites="Bentler1980">(Bentler, 1980)</span>．<span class="citation" data-cites="清水和秋1989">(清水和秋, 1989)</span></p>
</blockquote>
<p>そして，異分野横断の知見交流が進んだ契機の一つは，LISREL プログラムの存在であった．<span class="citation" data-cites="清水和秋1994">(清水和秋, 1994)</span> では，ETS での安定した研究環境が LISREL の継続的な保守を可能にして最終的には WINDOWS 上でも安定して提供され，これを用いることを通じて異分野を巻き込みながら構造方程式モデリングが発展していった様子が詳細に解説されている．LISREL はバージョン VI まである．</p>
<blockquote class="blockquote">
<p>紹介した文献からもわかるように，この分野は最近になってやっと日本では注目されてようになってきた。 このように日本へのこの方法論の導入が遅れた理由の一つはソフト流通の問題にあると筆者は考えている。青木 (1988) や土田 (1988) が述べているように， LISREL は大型計算機の場合， アメリカ産のコンビュータでしかサポートしてくれないとのことである。<span class="citation" data-cites="清水和秋1989">(清水和秋, 1989)</span></p>
</blockquote>
<p>そして現代はというと，計算機統計学と機械学習が先行し（過ぎ）ていると思える．</p>
<p>もしその通りならば，種々の科学への応用とそれぞれ固有の課題への特殊化が，これからの未来を彩ってくれるのかもしれない．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Anandkumar+2015" class="csl-entry">
Anandkumar, Anima, Ge, R., Hsu, D., Kakade, S. M., and Telgarsky, M. (2015). Tensor decompositions for learning latent variable models (a survey for ALT). In K. Chaudhuri, C. GENTILE, and S. Zilles, editors, <em>Algorithmic learning theory</em>, pages 19–38. Cham: Springer International Publishing.
</div>
<div id="ref-Anandkumar+2012" class="csl-entry">
Anandkumar, Animashree, Hsu, D., and Kakade, S. M. (2012). <a href="https://proceedings.mlr.press/v23/anandkumar12.html">A method of moments for mixture models and hidden markov models</a>. In S. Mannor, N. Srebro, and R. C. Williamson, editors, <em>Proceedings of the 25th annual conference on learning theory</em>,Vol. 23, pages 33.1–33.34. Edinburgh, Scotland: PMLR.
</div>
<div id="ref-Anderson-Rubin1956" class="csl-entry">
Anderson, T. W., and Rubin, H. (1956). <a href="https://projecteuclid.org/proceedings/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-Third-Berkeley-Symposium-on-Mathematical-Statistics-and/Chapter/Statistical-Inference-in-Factor-Analysis/bsmsp/1200511860">Statistical inference in factor analysis</a>. In <em>Proceedings of the thrid berkeley symposium on mathematical statistics and probability</em>,Vol. 5, pages 111–150.
</div>
<div id="ref-Andrew+2013" class="csl-entry">
Andrew, G., Arora, R., Bilmes, J., and Livescu, K. (2013). <a href="https://proceedings.mlr.press/v28/andrew13.html">Deep canonical correlation analysis</a>. In S. Dasgupta and D. McAllester, editors, <em>Proceedings of the 30th international conference on machine learning</em>,Vol. 28, pages 1247–1255. Atlanta, Georgia, USA: PMLR.
</div>
<div id="ref-Archambeau-Bach2008" class="csl-entry">
Archambeau, C., and Bach, F. (2008). <a href="https://proceedings.neurips.cc/paper_files/paper/2008/file/d93ed5b6db83be78efb0d05ae420158e-Paper.pdf">Sparse probabilistic projections</a>. In D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, <em>Advances in neural information processing systems</em>,Vol. 21. Curran Associates, Inc.
</div>
<div id="ref-Arova+2013" class="csl-entry">
Arora, S., Ge, R., Halpern, Y., Mimno, D., Moitra, A., Sontag, D., … Zhu, M. (2013). <a href="https://proceedings.mlr.press/v28/arora13.html">A practical algorithm for topic modeling with provable guarantees</a>. In S. Dasgupta and D. McAllester, editors, <em>Proceedings of the 30th international conference on machine learning</em>,Vol. 28, pages 280–288. Atlanta, Georgia, USA: PMLR.
</div>
<div id="ref-Asher83-Causal" class="csl-entry">
Asher, H. B. (1983). <em>Causal modelling</em>,Vol. 3. 和訳は心理学者広瀬弘忠による『因果分析法』（朝倉書店，1980）; SAGE Publications, Inc.
</div>
<div id="ref-Bach-Jordan2005" class="csl-entry">
Bach, F. R., and Jordan, M. I. (2005). <em>A probabilistic interpretation of canonical correlation analysis</em>. University of California, Berkeley. Retrieved from <a href="https://statistics.berkeley.edu/tech-reports/688">https://statistics.berkeley.edu/tech-reports/688</a>
</div>
<div id="ref-Baum-Eagon1967" class="csl-entry">
Baum, L. E., and Eagon, J. A. (1967). An inequality with applications to statistical estimation for probabilistic functions of markov processes and to a model for ecology. <em>Bulletin of the American Mathematical Society</em>, <em>73</em>(3), 360–363.
</div>
<div id="ref-Baum-Petrie1966" class="csl-entry">
Baum, L. E., and Petrie, T. (1966). Statistical inference for probabilistic functions of finite state markov chains. <em>The Annals of Mathematical Statistics</em>, <em>37</em>(6), 1554–1563.
</div>
<div id="ref-Baum+1970" class="csl-entry">
Baum, L. E., Petrie, T., Soules, G., and Weiss, N. (1970). <a href="http://www.jstor.org/stable/2239727">A maximization technique occurring in the statistical analysis of probabilistic functions of markov chains</a>. <em>The Annals of Mathematical Statistics</em>, <em>41</em>(1), 164–171.
</div>
<div id="ref-Bedford+2016" class="csl-entry">
Bedford, T., Daneshkhah, A., and Wilson, K. J. (2016). <a href="https://doi.org/10.1111/risa.12471">Approximate uncertainty modeling in risk analysis with vine copulas</a>. <em>Risk Analysis</em>, <em>36</em>(4), 792–815.
</div>
<div id="ref-Bell-Sejnowski1995" class="csl-entry">
Bell, A. J., and Sejnowski, T. J. (1995). <a href="https://doi.org/10.1162/neco.1995.7.6.1129"><span class="nocase">An Information-Maximization Approach to Blind Separation and Blind Deconvolution</span></a>. <em>Neural Computation</em>, <em>7</em>(6), 1129–1159.
</div>
<div id="ref-Bentler1980" class="csl-entry">
Bentler, P. M. (1980). <a href="https://doi.org/10.1146/annurev.ps.31.020180.002223">Multivariate analysis with latent variables: Causal modeling</a>. <em>Annual Review of Psychology</em>, <em>31</em>(Volume 31, 1980), 419–456. Journal Article.
</div>
<div id="ref-Bernaards-Jennrich2003" class="csl-entry">
Bernaards, C. A., and Jennrich, R. I. (2003). <a href="https://doi.org/10.1007/BF02295613">Orthomax rotation and perfect simple structure</a>. <em>Psychometrika</em>, <em>68</em>(4), 585–588.
</div>
<div id="ref-Bhattacharya-Dunson2012" class="csl-entry">
Bhattacharya, A., and Dunson, D. B. (2012). <a href="https://doi.org/10.1080/01621459.2011.646934">Simplex factor models for multivariate unordered categorical data</a>. <em>Journal of the American Statistical Association</em>, <em>107</em>(497), 362–377.
</div>
<div id="ref-Bishop1998" class="csl-entry">
Bishop, C. (1998). <a href="https://proceedings.neurips.cc/paper_files/paper/1998/file/c88d8d0a6097754525e02c2246d8d27f-Paper.pdf">Bayesian PCA</a>. In M. Kearns, S. Solla, and D. Cohn, editors, <em>Advances in neural information processing systems</em>,Vol. 11. MIT Press.
</div>
<div id="ref-Blei2012" class="csl-entry">
Blei, D. M. (2012). <a href="https://doi.org/10.1145/2133806.2133826">Probabilistic topic models</a>. <em>Commun. ACM</em>, <em>55</em>(4), 77–84.
</div>
<div id="ref-Blei+2006" class="csl-entry">
Blei, D. M., and Lafferty, J. D. (2006). <a href="https://doi.org/10.1145/1143844.1143859">Dynamic topic models</a>. In <em>Proceedings of the 23rd international conference on machine learning</em>, pages 113–120. New York, NY, USA: Association for Computing Machinery.
</div>
<div id="ref-Blei+2003" class="csl-entry">
Blei, D. M., Ng, A. Y., and Jordan, M. I. (2003). <a href="https://www.jmlr.org/papers/v3/blei03a.html"><span>Latent Dirichlet Allocation</span></a>. <em>Journal of Machine Learning Research</em>, <em>3</em>, 993–1022.
</div>
<div id="ref-Bock-Bargmann1966" class="csl-entry">
Bock, R. D., and Bargmann, R. E. (1966). <a href="https://doi.org/10.1007/BF02289521">Analysis of covariance structures</a>. <em>Psychometrika</em>, <em>31</em>(4), 507–534.
</div>
<div id="ref-Buntine-Jakulin2006" class="csl-entry">
Buntine, W., and Jakulin, A. (2006). Discrete component analysis. In C. Saunders, M. Grobelnik, S. Gunn, and J. Shawe-Taylor, editors, <em>Subspace, latent structure and feature selection</em>, pages 1–33. Berlin, Heidelberg: Springer Berlin Heidelberg.
</div>
<div id="ref-Canny2004" class="csl-entry">
Canny, J. (2004). <a href="https://doi.org/10.1145/1008992.1009016">GaP: A factor model for discrete data</a>. In <em>Proceedings of the 27th annual international ACM SIGIR conference on research and development in information retrieval</em>, pages 122–129. New York, NY, USA: Association for Computing Machinery.
</div>
<div id="ref-Carvalho+2010" class="csl-entry">
Carvalho, C. M., Polson, N. G., and Scott, J. G. (2010). <a href="https://doi.org/10.1093/biomet/asq017"><span class="nocase">The horseshoe estimator for sparse signals</span></a>. <em>Biometrika</em>, <em>97</em>(2), 465–480.
</div>
<div id="ref-Chen+2024" class="csl-entry">
Chen, H., Liu, Z., Wang, X., Tian, Y., and Wang, Y. (2024). <a href="https://arxiv.org/abs/2403.19928">DiJiang: Efficient large language models through compact kernelization</a>.
</div>
<div id="ref-Church-Gale1991" class="csl-entry">
Church, K. W., and Gale, W. A. (1991). <a href="https://doi.org/10.1007/BF01889984">Probability scoring for spelling correction</a>. <em>Statistics and Computing</em>, <em>1</em>(2), 93–103.
</div>
<div id="ref-Collins+2001" class="csl-entry">
Collins, M., Dasgupta, S., and Schapire, R. E. (2001). <a href="https://proceedings.neurips.cc/paper_files/paper/2001/file/f410588e48dc83f2822a880a68f78923-Paper.pdf">A generalization of principal components analysis to the exponential family</a>. In T. Dietterich, S. Becker, and Z. Ghahramani, editors, <em>Advances in neural information processing systems</em>,Vol. 14. MIT Press.
</div>
<div id="ref-DeLeeuw04-SimultaneousEstimationOfEFA" class="csl-entry">
De Leeuw, J. (2004). <a href="https://doi.org/10.1007/978-1-4020-1958-6_7">Least squares optimal scaling of partially observed linear systems</a>. In <em>Recent developments on structural equation models</em>. Springer Dordrecht.
</div>
<div id="ref-Deerwester+1990" class="csl-entry">
Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., and Harshman, R. (1990). <a href="https://doi.org/10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9">Indexing by latent semantic analysis</a>. <em>Journal of the American Society for Information Science</em>, <em>41</em>(6), 391–407.
</div>
<div id="ref-Dieng+2017" class="csl-entry">
Dieng, A. B., Wang, C., Gao, J., and Paisley, J. (2017). <a href="https://openreview.net/forum?id=rJbbOLcex">Topic<span>RNN</span>: A recurrent neural network with long-range semantic dependency</a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Drineas+2016" class="csl-entry">
Drineas, P., and Mahoney, M. W. (2016). <a href="https://doi.org/10.1145/2842602">RandNLA: Randomized numerical linear algebra</a>. <em>Commun. ACM</em>, <em>59</em>(6), 80–90.
</div>
<div id="ref-Erosheva+2004" class="csl-entry">
Erosheva, E., Fienberg, S., and Lafferty, J. (2004). <a href="https://doi.org/10.1073/pnas.0307760101">Mixed-membership models of scientific publications</a>. <em>Proceedings of the National Academy of Sciences</em>, <em>101</em>(suppl_1), 5220–5227.
</div>
<div id="ref-Fornell1985" class="csl-entry">
Fornell, C. (1985). <em>A second generation of multivariate analysis: Classification of methods and implications for marketing research</em>. Business, Stephen M. Ross School, University of Michigan. Retrieved from <a href="https://hdl.handle.net/2027.42/35621">https://hdl.handle.net/2027.42/35621</a>
</div>
<div id="ref-Friedman-Tukey1974" class="csl-entry">
Friedman, J. H., and Tukey, J. W. (1974). <a href="https://doi.org/10.1109/T-C.1974.224051">A projection pursuit algorithm for exploratory data analysis</a>. <em>IEEE Transactions on Computers</em>, <em>C-23</em>(9), 881–890.
</div>
<div id="ref-Ghahramani-Hinton1996" class="csl-entry">
Ghahramani, Z., and Hinton, G. E. (1996). <em>The EM algorithm for mixtures of factor analyzers</em>. Department of Computer Science, University of Toronto. Retrieved from <a href="https://www.cs.toronto.edu/~hinton/absps/tr96-1.html">https://www.cs.toronto.edu/~hinton/absps/tr96-1.html</a>
</div>
<div id="ref-Ghojogh+2022" class="csl-entry">
Ghojogh, B., Ghodsi, A., Karray, F., and Crowley, M. (2022). <a href="https://arxiv.org/abs/2101.00734">Factor analysis, probabilistic principal component analysis, variational inference, and variational autoencoder: Tutorial and survey</a>.
</div>
<div id="ref-Goel+2022" class="csl-entry">
Goel, K., Gu, A., Donahue, C., and Re, C. (2022). <a href="https://proceedings.mlr.press/v162/goel22a.html">It’s raw! <span>A</span>udio generation with state-space models</a>. In K. Chaudhuri, S. Jegelka, L. Song, C. Szepesvari, G. Niu, and S. Sabato, editors, <em>Proceedings of the 39th international conference on machine learning</em>,Vol. 162, pages 7616–7633. PMLR.
</div>
<div id="ref-Griffith-Steyvers2004" class="csl-entry">
Griffiths, T. L., and Steyvers, M. (2004). <a href="https://doi.org/10.1073/pnas.0307752101">Finding scientific topics</a>. <em>Proceedings of the National Academy of Sciences</em>, <em>101</em>(suppl_1), 5228–5235.
</div>
<div id="ref-Griffiths+2004" class="csl-entry">
Griffiths, T., Steyvers, M., Blei, D., and Tenenbaum, J. (2004). <a href="https://proceedings.neurips.cc/paper_files/paper/2004/file/ef0917ea498b1665ad6c701057155abe-Paper.pdf">Integrating topics and syntax</a>. In L. Saul, Y. Weiss, and L. Bottou, editors, <em>Advances in neural information processing systems</em>,Vol. 17. MIT Press.
</div>
<div id="ref-Grimm-Yarnold2016" class="csl-entry">
Grimm, L. G., and Yarnold, P. R. (2016). <em>研究論文を読み解くための多変量解析入門 応用篇</em>. Reading and Understanding MORE Multivariate Statistics (2020) の翻訳書; 北大路書房.
</div>
<div id="ref-Gu-Dao2024" class="csl-entry">
Gu, A., and Dao, T. (2024). <a href="https://arxiv.org/abs/2312.00752">Mamba: Linear-time sequence modeling with selective state spaces</a>.
</div>
<div id="ref-Gu+2020" class="csl-entry">
Gu, A., Dao, T., Ermon, S., Rudra, A., and Ré, C. (2020). <a href="https://proceedings.neurips.cc/paper_files/paper/2020/file/102f0bb6efb3a6128a3c750dd16729be-Paper.pdf">HiPPO: Recurrent memory with optimal polynomial projections</a>. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, <em>Advances in neural information processing systems</em>,Vol. 33, pages 1474–1487. Curran Associates, Inc.
</div>
<div id="ref-Gu+2022" class="csl-entry">
Gu, A., Goel, K., and Re, C. (2022). <a href="https://openreview.net/forum?id=uYLFoz1vlAC">Efficiently modeling long sequences with structured state spaces</a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Gustafsson2001" class="csl-entry">
Gustafsson, M. G. (2001). <a href="https://doi.org/10.1021/ci0003909">A probabilistic derivation of the partial least-squares algorithm</a>. <em>Journal of Chemical Information and Computer Sciences</em>, <em>41</em>(2), 288–294. doi: 10.1021/ci0003909.
</div>
<div id="ref-Halko+2011" class="csl-entry">
Halko, N., Martinsson, P. G., and Tropp, J. A. (2011). <a href="https://doi.org/10.1137/090771806">Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions</a>. <em>SIAM Review</em>, <em>53</em>(2), 217–288.
</div>
<div id="ref-Harman-Fukuda1966" class="csl-entry">
Harman, H. H., and Fukuda, Y. (1966). <a href="https://doi.org/10.1007/BF02289525">Resolution of the heywood case in the minres solution</a>. <em>Psychometrika</em>, <em>31</em>(4), 563–571.
</div>
<div id="ref-Harman-Jones1966" class="csl-entry">
Harman, H. H., and Jones, W. H. (1966). <a href="https://doi.org/10.1007/BF02289468">Factor analysis by minimizing residuals (minres)</a>. <em>Psychometrika</em>, <em>31</em>(3), 351–368.
</div>
<div id="ref-Hoffman2017" class="csl-entry">
Hoffman, M. D. (2017). <a href="https://proceedings.mlr.press/v70/hoffman17a.html">Learning deep latent <span>G</span>aussian models with <span>M</span>arkov chain <span>M</span>onte <span>C</span>arlo</a>. In D. Precup and Y. W. Teh, editors, <em>Proceedings of the 34th international conference on machine learning</em>,Vol. 70, pages 1510–1519. PMLR.
</div>
<div id="ref-Hofmann1999" class="csl-entry">
Hofmann, T. (1999). <a href="https://doi.org/10.1145/312624.312649">Probabilistic latent semantic indexing</a>. In <em>Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval</em>, pages 50–57. New York, NY, USA: Association for Computing Machinery.
</div>
<div id="ref-Horst1961" class="csl-entry">
Horst, P. (1961). <a href="https://doi.org/10.1002/1097-4679(196110)17:4<331::AID-JCLP2270170402>3.0.CO;2-D">Generalized canonical correlations and their applications to experimental data</a>. <em>Journal of Clinical Psychology</em>, <em>17</em>(4), 331–347.
</div>
<div id="ref-Hotelling33-PCA" class="csl-entry">
Hotelling, H. (1933). <a href="https://psycnet.apa.org/doi/10.1037/h0071325">Analysis of a complex of statistical variables into principal components</a>. <em>Journal of Educational Psychology</em>, <em>24</em>(6), 417–441.
</div>
<div id="ref-Hotelling36" class="csl-entry">
Hotelling, H. (1936). <a href="https://www.jstor.org/stable/2333955">Relations between two sets of variates</a>. <em>Biometrika</em>, <em>27</em>(3/4), 321–377.
</div>
<div id="ref-Hsu+2012" class="csl-entry">
Hsu, D., Kakade, S. M., and Zhang, T. (2012). <a href="https://doi.org/10.1016/j.jcss.2011.12.025">A spectral algorithm for learning hidden markov models</a>. <em>Journal of Computer and System Sciences</em>, <em>78</em>(5), 1460–1480.
</div>
<div id="ref-Hyvarinen-Oja2000" class="csl-entry">
Hyvärinen, A., and Oja, E. (2000). <a href="https://doi.org/10.1016/S0893-6080(00)00026-5">Independent component analysis: Algorithms and applications</a>. <em>Neural Networks</em>, <em>13</em>(4), 411–430.
</div>
<div id="ref-Jolliffe+2003" class="csl-entry">
Ian T Jolliffe, N. T. T., and Uddin, M. (2003). <a href="https://doi.org/10.1198/1061860032148">A modified principal component technique based on the LASSO</a>. <em>Journal of Computational and Graphical Statistics</em>, <em>12</em>(3), 531–547.
</div>
<div id="ref-Joreskog1966" class="csl-entry">
Jöreskog, Karl G. (1966). <em>UMLFA: A computer program for unrestricted maximum likelihood factor analysis</em>. ETS. Retrieved from <a href="https://www.ets.org/research/policy_research_reports/publications/report/1966/iazh.html">https://www.ets.org/research/policy_research_reports/publications/report/1966/iazh.html</a>
</div>
<div id="ref-Joreskog1967a" class="csl-entry">
Jöreskog, K. G. (1967). <a href="https://doi.org/10.1007/BF02289658">Some contributions to maximum likelihood factor analysis</a>. <em>Psychometrika</em>, <em>32</em>(4), 443–482.
</div>
<div id="ref-Joreskog1969" class="csl-entry">
Jöreskog, K. G. (1969). <a href="https://doi.org/10.1007/BF02289343">A general approach to confirmatory maximum likelihood factor analysis</a>. <em>Psychometrika</em>, <em>34</em>(2), 183–202.
</div>
<div id="ref-Joreskog70" class="csl-entry">
Jöreskog, Karl Gustav. (1970). <a href="https://www.jstor.org/stable/2334833">A general method for analysis of covariance structures</a>. <em>Biometrika</em>, <em>57</em>(2), 239–251.
</div>
<div id="ref-Joreskog1978" class="csl-entry">
Jöreskog, Karl G. (1978). <a href="https://doi.org/10.1007/BF02293808">Structural analysis of covariance and correlation matrices</a>. <em>Psychometrika</em>, <em>43</em>(4), 443–477.
</div>
<div id="ref-Joreskog-Lawley1968" class="csl-entry">
Jöreskog, K. G., and Lawley, D. N. (1968). <a href="https://doi.org/10.1111/j.2044-8317.1968.tb00399.x">New methods in maximum likelihood factor analysis</a>. <em>British Journal of Mathematical and Statistical Psychology</em>, <em>21</em>(1), 85–96.
</div>
<div id="ref-Joreskog-Wold1982" class="csl-entry">
Jöreskog, K. G., and Wold, H. (1982). Systems under indirect observation: Causality, structure, prediction. In, pages 263–270. North-Holland.
</div>
<div id="ref-Joreskog-vanThillo1972" class="csl-entry">
Jőreskog, K. G., and Thiilo, M. van. (1972). <a href="https://doi.org/10.1002/j.2333-8504.1972.tb00827.x"><span class="nocase">LISREL: A General Computer Program for Estimating a Linear Structural Equation System Involving Multiple Indicators of Unmeasured Variables</span></a>. <em>ETS Research Bulletin Series</em>, <em>1972</em>(2), i–71.
</div>
<div id="ref-Khemakhem+2020" class="csl-entry">
Khemakhem, I., Kingma, D., Monti, R., and Hyvarinen, A. (2020). <a href="https://proceedings.mlr.press/v108/khemakhem20a.html">Variational autoencoders and nonlinear ICA: A unifying framework</a>. In S. Chiappa and R. Calandra, editors, <em>Proceedings of the twenty third international conference on artificial intelligence and statistics</em>,Vol. 108, pages 2207–2217. PMLR.
</div>
<div id="ref-Klami+2010" class="csl-entry">
Klami, A., Virtanen, S., and Kaski, S. (2010). Bayesian exponential family projections for coupled data sources. In <em>Proceedings of the twenty-sixth conference on uncertainty in artificial intelligence</em>, pages 286–293. Arlington, Virginia, USA: AUAI Press.
</div>
<div id="ref-Lawley1942" class="csl-entry">
Lawley, D. N. (1942). <a href="https://doi.org/10.1017/S0080454100006178">XIV.—further investigations in factor estimation</a>. <em>Proceedings of the Royal Society of Edinburgh. Section A. Mathematical and Physical Sciences</em>, <em>61</em>(2), 176–185.
</div>
<div id="ref-Lawrence2005" class="csl-entry">
Lawrence, N. (2005). <a href="http://jmlr.org/papers/v6/lawrence05a.html">Probabilistic non-linear principal component analysis with gaussian process latent variable models</a>. <em>Journal of Machine Learning Research</em>, <em>6</em>(60), 1783–1816.
</div>
<div id="ref-Lee-Seung1999" class="csl-entry">
Lee, D. D., and Seung, H. S. (1999). <a href="https://doi.org/10.1038/44565">Learning the parts of objects by non-negative matrix factorization</a>. <em>Nature</em>, <em>401</em>(6755), 788–791.
</div>
<div id="ref-Marlin2003" class="csl-entry">
Marlin, B. M. (2003). <a href="https://proceedings.neurips.cc/paper_files/paper/2003/file/269d837afada308dd4aeab28ca2d57e4-Paper.pdf">Modeling user rating profiles for collaborative filtering</a>. In S. Thrun, L. Saul, and B. Schölkopf, editors, <em>Advances in neural information processing systems</em>,Vol. 16. MIT Press.
</div>
<div id="ref-McArdle1984" class="csl-entry">
McArdle, J. J. (1984). <a href="https://doi.org/10.1080/00273171.1984.9676927">On the madness in his method: R. B. Cattell’s contributions to structural equation modeling</a>. <em>Multivariate Behavioral Research</em>, <em>19</em>(2-3), 245–267.
</div>
<div id="ref-Murphy2022" class="csl-entry">
Murphy, K. P. (2022). <em><a href="https://probml.github.io/pml-book/book1.html">Probabilistic machine learning: An introduction</a></em>. MIT Press.
</div>
<div id="ref-Murphy2023" class="csl-entry">
Murphy, K. P. (2023). <em><a href="http://probml.github.io/book2">Probabilistic machine learning: Advanced topics</a></em>. MIT Press.
</div>
<div id="ref-Murray+2023" class="csl-entry">
Murray, R., Demmel, J., Mahoney, M. W., Erichson, N. B., Melnichenko, M., Malik, O. A., … Dongarra, J. (2023). <em>Randomized numerical linear algebra: A perspective on the field with an eye to software</em> (No. UCB/EECS-2023-19). Retrieved from <a href="http://www2.eecs.berkeley.edu/Pubs/TechRpts/2023/EECS-2023-19.html">http://www2.eecs.berkeley.edu/Pubs/TechRpts/2023/EECS-2023-19.html</a>
</div>
<div id="ref-Muthen2002" class="csl-entry">
Muthén, B. O. (2002). <a href="https://doi.org/10.2333/bhmk.29.81"><span>Beyond SEM: General Latent Variable Modeling</span></a>. <em>Behaviormetrika</em>, <em>29</em>(1), 81–117.
</div>
<div id="ref-Nounou+2002" class="csl-entry">
Nounou, M. N., Bakshi, B. R., Goel, P. K., and Shen, X. (2002). <a href="https://doi.org/10.1002/aic.690480818">Process modeling by bayesian latent variable regression</a>. <em>AIChE Journal</em>, <em>48</em>(8), 1775–1793.
</div>
<div id="ref-Obermeyer+2019" class="csl-entry">
Obermeyer, F., Bingham, E., Jankowiak, M., Pradhan, N., Chiu, J., Rush, A., and Goodman, N. (2019). <a href="https://proceedings.mlr.press/v97/obermeyer19a.html">Tensor variable elimination for plated factor graphs</a>. In K. Chaudhuri and R. Salakhutdinov, editors, <em>Proceedings of the 36th international conference on machine learning</em>,Vol. 97, pages 4871–4880. PMLR.
</div>
<div id="ref-Paatero-Tapper1994" class="csl-entry">
Paatero, P., and Tapper, U. (1994). <a href="https://doi.org/10.1002/env.3170050203">Positive matrix factorization: A non-negative factor model with optimal utilization of error estimates of data values</a>. <em>Environmetrics</em>, <em>5</em>(2), 111–126.
</div>
<div id="ref-Paisley-Carin2009" class="csl-entry">
Paisley, J., and Carin, L. (2009). <a href="https://doi.org/10.1145/1553374.1553474">Nonparametric factor analysis with beta process priors</a>. In <em>Proceedings of the 26th annual international conference on machine learning</em>, pages 777–784. New York, NY, USA: Association for Computing Machinery.
</div>
<div id="ref-Papyam-Elad2016" class="csl-entry">
Papyan, V., and Elad, M. (2016). <a href="https://doi.org/10.1109/TIP.2015.2499698">Multi-scale patch-based image restoration</a>. <em>IEEE Transactions on Image Processing</em>, <em>25</em>(1), 249–261.
</div>
<div id="ref-Pearson01-PCA" class="csl-entry">
Pearson, K. (1901). <a href="https://www.tandfonline.com/doi/abs/10.1080/14786440109462720">On lines and planes of closest fit to systems of points in space</a>. <em>Philosophical Magazine</em>, <em>2</em>(11), 559–572.
</div>
<div id="ref-Perrone2024" class="csl-entry">
Perrone, P. (2024). <a href="https://doi.org/10.1109/TIT.2023.3328825"><span class="nocase">Markov Categories and Entropy</span></a>. <em>IEEE Transactions on Information Theory</em>, <em>70</em>(3), 1671–1692.
</div>
<div id="ref-Pritchard+2000" class="csl-entry">
Pritchard, J. K., Stephens, M., and Donnelly, P. (2000). <a href="https://doi.org/10.1093/genetics/155.2.945"><span class="nocase">Inference of Population Structure Using Multilocus Genotype Data</span></a>. <em>Genetics</em>, <em>155</em>(2), 945–959.
</div>
<div id="ref-Rattray+2009" class="csl-entry">
Rattray, M., Stegle, O., Sharp, K., and Winn, J. (2009). <a href="https://doi.org/10.1088/1742-6596/197/1/012002">Inference algorithms and learning theory for bayesian sparse factor analysis</a>. <em>Journal of Physics: Conference Series</em>, <em>197</em>(1), 012002.
</div>
<div id="ref-Ricahrdson-Weiss2018" class="csl-entry">
Richardson, E., and Weiss, Y. (2018). <a href="https://proceedings.neurips.cc/paper_files/paper/2018/file/0172d289da48c48de8c5ebf3de9f7ee1-Paper.pdf">On GANs and GMMs</a>. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, <em>Advances in neural information processing systems</em>,Vol. 31. Curran Associates, Inc.
</div>
<div id="ref-Roweis1997" class="csl-entry">
Roweis, S. (1997). <a href="https://proceedings.neurips.cc/paper_files/paper/1997/file/d9731321ef4e063ebbee79298fa36f56-Paper.pdf">EM algorithms for PCA and SPCA</a>. In M. Jordan, M. Kearns, and S. Solla, editors, <em>Advances in neural information processing systems</em>,Vol. 10. MIT Press.
</div>
<div id="ref-Rubin-Thayer1982" class="csl-entry">
Rubin, D. B., and Thayer, D. T. (1982). <a href="https://doi.org/10.1007/BF02293851">EM algorithms for ML factor analysis</a>. <em>Psychometrika</em>, <em>47</em>(1), 69–76.
</div>
<div id="ref-Scott2002" class="csl-entry">
Scott, S. L. (2002). <a href="https://doi.org/10.1198/016214502753479464">Bayesian methods for hidden markov models</a>. <em>Journal of the American Statistical Association</em>, <em>97</em>(457), 337–351.
</div>
<div id="ref-Sei-Yano2024" class="csl-entry">
Sei, T., and Yano, K. (2024). <a href="https://doi.org/10.3150/23-BEJ1687"><span class="nocase">Minimum information dependence modeling</span></a>. <em>Bernoulli</em>, <em>30</em>(4), 2623–2643.
</div>
<div id="ref-Herbert-Simon57-ModelsOfMan" class="csl-entry">
Simon, H. (1957). <em>Models of man; social and rational.</em> Wiley.
</div>
<div id="ref-Smith+2023" class="csl-entry">
Smith, J. T. H., Warrington, A., and Linderman, S. (2023). <a href="https://openreview.net/forum?id=Ai8Hw3AXqks">Simplified state space layers for sequence modeling</a>. In <em>The eleventh international conference on learning representations</em>.
</div>
<div id="ref-Socan2003" class="csl-entry">
Socan, G. (2003). <em>The incremental value of rank factor analysis</em> (PhD thesis). Rijksuniversiteit Groningen.
</div>
<div id="ref-Sorbom1974" class="csl-entry">
Sörbom, D. (1974). <a href="https://doi.org/10.1111/j.2044-8317.1974.tb00543.x"><span class="nocase">A General Method for Studying Differences in Factor Means and Factor Structure between Groups</span></a>. <em>British Journal of Mathematical and Statistical Psychology</em>, <em>27</em>(2), 229–239.
</div>
<div id="ref-Spearman1904" class="csl-entry">
Spearman, C. (1904). <a href="https://psycnet.apa.org/doi/10.2307/1412107">’General intelligence,’ objectively determined and measured</a>. <em>The American Journal of Psychology</em>, <em>15</em>(2), 201–293.
</div>
<div id="ref-Sun+2009" class="csl-entry">
Sun, L., Ji, S., Yu, S., and Ye, J. (2009). On the equivalence between canonical correlation analysis and orthonormalized partial least squares. In <em>Proceedings of the 21st international joint conference on artificial intelligence</em>, pages 1230–1235. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc.
</div>
<div id="ref-Suzuki+2017" class="csl-entry">
Suzuki, M., Nakayama, K., and Matsuo, Y. (2017). <a href="https://openreview.net/forum?id=Hk8rlUqge">Joint multimodal learning with deep generative models</a>.
</div>
<div id="ref-Thurstone1947" class="csl-entry">
Thurstone, L. L. (1947). <em><a href="">Multiple factor analysis</a></em>. University of Chicago Press.
</div>
<div id="ref-Tipping-Bishop1999" class="csl-entry">
Tipping, M. E., and Bishop, C. M. (1999). <a href="https://www.jstor.org/stable/2680726">Probabilistic principle component analysis</a>. <em>Journal of the Royal Statistical Society. Series B (Statistical Methodology)</em>, <em>61</em>(3), 611–622.
</div>
<div id="ref-Unkel-Trendafilov2010" class="csl-entry">
Unkel, S., and Trendafilov, N. T. (2010). <a href="https://doi.org/10.1111/j.1751-5823.2010.00120.x">Simultaneous parameter estimation in exploratory factor analysis: An expository review</a>. <em>International Statistical Review</em>, <em>78</em>(3), 363–382.
</div>
<div id="ref-Wallach+2009" class="csl-entry">
Wallach, H. M., Murray, I., Salakhutdinov, R., and Mimno, D. (2009). <a href="https://doi.org/10.1145/1553374.1553515">Evaluation methods for topic models</a>. In <em>Proceedings of the 26th annual international conference on machine learning</em>, pages 1105–1112. New York, NY, USA: Association for Computing Machinery.
</div>
<div id="ref-Wang+2017" class="csl-entry">
Wang, W., Yan, X., Lee, H., and Livescu, K. (2017). <a href="https://openreview.net/forum?id=H1Heentlx">Deep variational canonical correlation analysis</a>.
</div>
<div id="ref-Wright1918" class="csl-entry">
Wright, S. (1918). <a href="https://academic.oup.com/genetics/article/3/4/367/5934526">On the nature of size factors</a>. <em>Genetics</em>, <em>3</em>(4), 367.
</div>
<div id="ref-Wright1921" class="csl-entry">
Wright, S. (1921). Correlation and causation. <em>Journal of Agricultural Reserach</em>, <em>20</em>, 557–585.
</div>
<div id="ref-Teh+2006" class="csl-entry">
Yee Whye Teh, M. J. B., Michael I Jordan, and Blei, D. M. (2006). <a href="https://doi.org/10.1198/016214506000000302">Hierarchical dirichlet processes</a>. <em>Journal of the American Statistical Association</em>, <em>101</em>(476), 1566–1581.
</div>
<div id="ref-Yu+2006" class="csl-entry">
Yu, S., Yu, K., Tresp, V., Kriegel, H.-P., and Wu, M. (2006). <a href="https://doi.org/10.1145/1150402.1150454">Supervised probabilistic principal component analysis</a>. In <em>Proceedings of the 12th ACM SIGKDD international conference on knowledge discovery and data mining</em>, pages 464–473. New York, NY, USA: Association for Computing Machinery.
</div>
<div id="ref-Zong+2018" class="csl-entry">
Zong, B., Song, Q., Min, M. R., Cheng, W., Lumezanu, C., Cho, D., and Chen, H. (2018). <a href="https://openreview.net/forum?id=BJJLHbb0-">Deep autoencoding gaussian mixture model for unsupervised anomaly detection</a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Zoran-Weiss2011" class="csl-entry">
Zoran, D., and Weiss, Y. (2011). <a href="https://doi.org/10.1109/ICCV.2011.6126278">From learning models of natural image patches to whole image restoration</a>. In <em>2011 international conference on computer vision</em>, pages 479–486.
</div>
<div id="ref-Zou-Hastie2005" class="csl-entry">
Zou, H., and Hastie, T. (2005). <a href="https://doi.org/10.1111/j.1467-9868.2005.00503.x"><span class="nocase">Regularization and Variable Selection Via the Elastic Net</span></a>. <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em>, <em>67</em>(2), 301–320.
</div>
<div id="ref-Zou+2006" class="csl-entry">
Zou, H., Hastie, T., and Tibshirani, R. (2006). <a href="http://www.jstor.org/stable/27594179">Sparse principal component analysis</a>. <em>Journal of Computational and Graphical Statistics</em>, <em>15</em>(2), 265–286.
</div>
<div id="ref-岩瀬-中山2016" class="csl-entry">
岩瀬智亮, and 中山英樹. (2016). <a href="http://id.nii.ac.jp/1001/00162588/">深層一般化正準相関分析</a>. <em>情報処理学会第78回全国大会講演論文集</em>, <em>2016</em>(1), 183–184.
</div>
<div id="ref-星野崇宏+2005" class="csl-entry">
星野崇宏, 岡田謙介, and 前田忠彦. (2005). <a href="https://doi.org/10.2333/jbhmk.32.209">構造方程式モデリングにおける適合度指標とモデル改善について : 展望とシミュレーション研究による新たな知見</a>. <em>行動計量学</em>, <em>32</em>(2), 209–235.
</div>
<div id="ref-江口真透1999" class="csl-entry">
江口真透. (1999). <a href="http://hdl.handle.net/10787/295">概パラメトリック推測 － 柔らかなモデルの構築 －</a>. <em>統計数理</em>, <em>47</em>(1), 29–48.
</div>
<div id="ref-清水和秋1989" class="csl-entry">
清水和秋. (1989). <a href="http://hdl.handle.net/10112/13348">検証的因子分析，LISRELそしてRAMの概要</a>. <em>関西大学社会学部紀要</em>, <em>20</em>(2), 61–86.
</div>
<div id="ref-清水和秋1994" class="csl-entry">
清水和秋. (1994). <a href="http://hdl.handle.net/10112/13345">JöreskogとSörbomによるコンピュータ・プログラムと構造方程式モデル</a>. <em>関西大学社会学部紀要</em>, <em>25</em>(3), 1–41.
</div>
<div id="ref-狩野裕2002" class="csl-entry">
狩野裕. (2002). <a href="https://doi.org/10.2333/jbhmk.29.138">構造方程式モデリングは，因子分析，分散分析，パス解析の すべてにとって代わるのか？</a>. <em>行動計量学</em>, <em>29</em>(2), 138–159.
</div>
<div id="ref-統計科学のフロンティア5" class="csl-entry">
甘利俊一，狩野裕，佐藤俊哉，松山裕，竹内啓，石黒真木夫. (2002). <em><a href="https://www.iwanami.co.jp/book/b260371.html">多変量解析の展開：隠れた構造と因果を推理する</a></em>,Vol. 5. 岩波書店.
</div>
<div id="ref-白倉幸男1984" class="csl-entry">
白倉幸男. (1984). <a href="https://doi.org/10.18910/4301">多重指標線形構造モデルとその応用 : 研究ノート</a>. <em>大阪大学人間科学部紀要</em>, <em>10</em>, 25–45.
</div>
<div id="ref-豊田秀樹1991" class="csl-entry">
豊田秀樹. (1991). <a href="https://doi.org/10.5926/jjep1953.39.4_467">共分散構造分析の下位モデルとその適用例</a>. <em>教育心理学研究</em>, <em>39</em>(4), 467–478.
</div>
<div id="ref-豊田秀樹1992" class="csl-entry">
豊田秀樹. (1992). <em><a href="https://www.utp.or.jp/book/b302422.html">SASによる共分散構造分析</a></em>,Vol. 3. 東京大学出版会.
</div>
<div id="ref-豊田秀樹2007" class="csl-entry">
豊田秀樹. (2007). <em>共分散構造分析［理論編］</em>. 朝倉書店.
</div>
<div id="ref-赤穂昭太郎2013" class="csl-entry">
赤穂昭太郎. (2013). <a href="https://doi.org/10.3902/jnns.20.62">正準相関分析入門</a>. <em>日本神経回路学会誌</em>, <em>20</em>(2), 62–72.
</div>
<div id="ref-足立浩平2023" class="csl-entry">
足立浩平. (2023). 50歳を超えてから始めた因子分析. <em>日本行動計量学会報</em>, <em>177</em>.
</div>
<div id="ref-足立浩平+2019" class="csl-entry">
足立浩平, 伊藤真道, and 宇野光平. (2019). <a href="https://doi.org/10.20551/jscswabun.32.1_61">行列分解に基づく因子分析とその新展開</a>. <em>計算機統計学</em>, <em>32</em>(1), 61–77.
</div>
<div id="ref-足立-山本2024" class="csl-entry">
足立浩平, and 山本倫生. (2024). <em><a href="https://www.kyoritsu-pub.co.jp/book/b10085699.html">主成分分析と因子分析―特異値分解を出発点として―</a></em>. 共立出版.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>図を見やすくするために，<img src="https://latex.codecogs.com/png.latex?X%5E1%5Cto%20X%5E%7Bp-1%7D"> や <img src="https://latex.codecogs.com/png.latex?X%5E2%5Cto%20X%5Ep"> などは省略している．↩︎</p></li>
<li id="fn2"><p><span class="citation" data-cites="足立-山本2024">(足立浩平 and 山本倫生, 2024)</span>, <span class="citation" data-cites="足立浩平2023">(足立浩平, 2023)</span> によると，この行列分解による定式化は Henk A. K. Kiers によるもので，初出は同大学からの博士論文 <span class="citation" data-cites="Socan2003">(Socan, 2003)</span> が最初ではないか，とのこと．この見方を MDFA (Matrix Decomposition Factor Analysis) と呼ぶ．<span class="citation" data-cites="足立浩平+2019">(足立浩平 et al., 2019)</span> も参照．↩︎</p></li>
<li id="fn3"><p>ただし，<span class="citation" data-cites="星野崇宏+2005">(星野崇宏 et al., 2005)</span> は SEM をより一般的とし，共分散構造分析とは観測変数が連続な場合の下位モデルである，と解している．↩︎</p></li>
<li id="fn4"><p><span class="citation" data-cites="江口真透1999">(江口真透, 1999)</span> 第３節に，PCA をニューラルネットワークにより近似的に実行する方法が紹介されている．<span class="citation" data-cites="Ghojogh+2022">(Ghojogh et al., 2022)</span> はサーベイを与えている．↩︎</p></li>
<li id="fn5"><p><span class="citation" data-cites="豊田秀樹1992">(豊田秀樹, 1992)</span> では CFA を確認的因子分析と呼んでいる．<span class="citation" data-cites="豊田秀樹1991">(豊田秀樹, 1991)</span> では，古典テスト理論を確認的因子分析の下位モデルとして紹介している．また，このような因果関係の確認的方法は，社会学における <span class="citation" data-cites="Herbert-Simon57-ModelsOfMan">(Simon, 1957)</span> の基準などが知られていた．↩︎</p></li>
<li id="fn6"><p><span class="citation" data-cites="Joreskog70">(Karl Gustav Jöreskog, 1970)</span> は具体的なモデルを例に取り，彼の検証的因果分析が，パス解析 <span class="citation" data-cites="Wright1918">(Wright, 1918)</span>, <span class="citation" data-cites="Wright1921">(Wright, 1921)</span> のように因果分析に応用できることを示した結果だと言える <span class="citation" data-cites="Asher83-Causal">(Asher, 1983)</span>．この観点から，パス解析は「検証的因果推論」と表現することもできる <span class="citation" data-cites="統計科学のフロンティア5">(甘利俊一，狩野裕，佐藤俊哉，松山裕，竹内啓，石黒真木夫, 2002, p. 73)</span>．↩︎</p></li>
<li id="fn7"><p><span class="citation" data-cites="狩野裕2002">(狩野裕, 2002)</span> は SEM の射程と得意・不得意を分析している．↩︎</p></li>
<li id="fn8"><p>現代ではコンピュータの力により，新たに「生成」「表現学習」というタスクが加わったと思うと，感慨深い．↩︎</p></li>
<li id="fn9"><p><span class="citation" data-cites="清水和秋1989">(清水和秋, 1989)</span>, <span class="citation" data-cites="豊田秀樹1992">(豊田秀樹, 1992)</span>, <span class="citation" data-cites="統計科学のフロンティア5">(甘利俊一，狩野裕，佐藤俊哉，松山裕，竹内啓，石黒真木夫, 2002, p. 82)</span> も参照．↩︎</p></li>
<li id="fn10"><p>また，パス図では観測変数は四角で囲むべきであるが，ここでは省略した．↩︎</p></li>
<li id="fn11"><p>同時方程式は潜在変数を持たない模型で，経済学におけるパス解析の継承と見れる <span class="citation" data-cites="豊田秀樹2007">(豊田秀樹, 2007)</span>．特に Keynes 経済学におけるマクロな経済計画の発想で，<a href="https://ja.wikipedia.org/wiki/コウルズ財団">Cowles 委員会</a> により 1940 年代から 1950 年代にかけて盛んに研究された．↩︎</p></li>
<li id="fn12"><p>「従来から存在するがやや標準的でない分析方法がSEMの枠組みで実行できることも指摘しておきたい．たとえば，三相データの分析モデルである PARAFAC，行動遺伝学における ACE モデル，イプサティブデータの分析，潜在曲線モデル，潜在構造分析などの離散潜在変数のモデル，項目反応モデルなどである．加えて，SEM で実行できる新しいモデル，たとえば，多変量二段抽出モデル，平均に特色をもたせる三相データの分析モデルや因子分析と分散分析の統合モデルなどがある．」<span class="citation" data-cites="狩野裕2002">(狩野裕, 2002, p. 139)</span>．↩︎</p></li>
<li id="fn13"><p>多変量解析の高級言語とか形容することもあるという．構造方程式モデリングについては，<span class="citation" data-cites="豊田秀樹1991">(豊田秀樹, 1991)</span>, <span class="citation" data-cites="狩野裕2002">(狩野裕, 2002)</span> も参照．↩︎</p></li>
<li id="fn14"><p>オランダ学派を中心に等質性分析とも呼ぶ．↩︎</p></li>
<li id="fn15"><p>ただし，SEM は共分散構造，混合モデルは平均構造に分析の焦点がある，という志向の違いもある．<span class="citation" data-cites="狩野裕2002">(狩野裕, 2002)</span> も参照．↩︎</p></li>
<li id="fn16"><p><img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BC%7D(%5Csigma)_+"> は Cauchy 分布 <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BC%7D(0,%5Csigma)"> を <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D_+"> 上に制限したものである．truncated Cauchy または half-Cauchy という．↩︎</p></li>
<li id="fn17"><p><span class="citation" data-cites="Hyvarinen-Oja2000">(Hyvärinen and Oja, 2000)</span> では，<span class="citation" data-cites="Bell-Sejnowski1995">(Bell and Sejnowski, 1995)</span> のように測定誤差を考えない場合を ICA といい，誤差も入る一般の場合を IFA (Independent Factor Analysis) と呼び分けている．<span class="citation" data-cites="統計科学のフロンティア5">(甘利俊一，狩野裕，佐藤俊哉，松山裕，竹内啓，石黒真木夫, 2002, p. 110)</span> も参照．「これを回転の不定性という．因子分析はさまざまな考察によって，この不定性を解消しようとする．独立成分分析は，非正規性を仮定すれば，この不定性が消えることを示したものとも言える」<span class="citation" data-cites="統計科学のフロンティア5">(甘利俊一，狩野裕，佐藤俊哉，松山裕，竹内啓，石黒真木夫, 2002, p. 13)</span>．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Statistics</category>
  <category>Kernel</category>
  <category>Probability</category>
  <category>Bayesian</category>
  <guid>https://162348.github.io/posts/2024/Kernels/HierarchicalModel.html</guid>
  <pubDate>Mon, 12 Aug 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Kernels/Images/MM.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>フローベース模型による条件付き生成</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Samplers/NF3.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="関連ページ" class="level3 unnumbered unlisted">
<h3 class="unnumbered unlisted anchored" data-anchor-id="関連ページ">関連ページ</h3>
<div id="listing-diffusion-listing" class="quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="RGVlcCUyQ1Byb2Nlc3MlMkNTYW1wbGluZw==" data-listing-date-sort="1707868800000" data-listing-file-modified-sort="1733137937708" data-listing-date-modified-sort="1724371200000" data-listing-reading-time-sort="5" data-listing-word-count-sort="826">
<a href="../../../posts/2024/Samplers/Diffusion.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Samplers/Files/DDPM_outputs.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
拡散模型
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル６
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="RGVlcCUyQ1NhbXBsaW5nJTJDUChYKQ==" data-listing-date-sort="1707868800000" data-listing-file-modified-sort="1733137937892" data-listing-date-modified-sort="1724803200000" data-listing-reading-time-sort="4" data-listing-word-count-sort="794">
<a href="../../../posts/2024/Samplers/NF1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Samplers/Files/linear/output.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ニューラル常微分方程式
</h5>
<div class="card-subtitle listing-subtitle">
シミュレーションなしの拡散モデルとしての連続正規化流
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="RGVlcCUyQ05hdHVyZSUyQ1NhbXBsaW5n" data-listing-date-sort="1711756800000" data-listing-file-modified-sort="1733137937708" data-listing-date-modified-sort="1722470400000" data-listing-reading-time-sort="5" data-listing-word-count-sort="880">
<a href="../../../posts/2024/Samplers/EBM.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Samplers/Files/NCL/thumb_checkerboard.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
エネルギーベースモデル
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル５
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-03-30
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>
<section id="誘導" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="誘導"><span class="header-section-number">1</span> 誘導</h2>
<p>拡散模型の美点には，条件付けが可能で拡張性に優れているという点もある．</p>
<p>実際，拡散模型の出現後，Conditional VAE <span class="citation" data-cites="Kingma+2014">(Kingma et al., 2014)</span> などの従来手法を凌駕する条件付き生成が可能であることが直ちに理解された．</p>
<p><img src="https://latex.codecogs.com/png.latex?C"> がクラスラベルなどの離散変数である場合，「誘導」による条件付き生成が初めに考えられた．</p>
<section id="はじめに" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="はじめに"><span class="header-section-number">1.1</span> はじめに</h3>
<p>「誘導」ではまず，DDPM <span class="citation" data-cites="Ho+2020">(Ho et al., 2020)</span> でタイムステップ <img src="https://latex.codecogs.com/png.latex?t"> を positional encoding したようにして，プロンプト <img src="https://latex.codecogs.com/png.latex?c"> をデータに埋め込む．<sup>1</sup></p>
<p>そしてデータ <img src="https://latex.codecogs.com/png.latex?X"> とそのラベル <img src="https://latex.codecogs.com/png.latex?C"> に対して，条件付き分布 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D%5BX%7CC%5D"> をモデリングする．</p>
<p>しかしこのアプローチの問題は，ラベル <img src="https://latex.codecogs.com/png.latex?C"> が不確実な場合などは，この情報を無視して普通の <img src="https://latex.codecogs.com/png.latex?X"> が生成されてしまいがちであることである．</p>
<p>そこで目的関数に，条件付き分布 <img src="https://latex.codecogs.com/png.latex?X%7CC"> の正確性を期すような追加のデザインをする．これが「誘導」である．</p>
</section>
<section id="条件付きスコア場" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="条件付きスコア場"><span class="header-section-number">1.2</span> 条件付きスコア場</h3>
<p>条件付き分布 <img src="https://latex.codecogs.com/png.latex?p(x%7Cc)"> を学習することを考える．</p>
<p>このとき <img src="https://latex.codecogs.com/png.latex?p(x%7Cc)"> のスコアは，Bayes の定理から次のように表せる： <img src="https://latex.codecogs.com/png.latex?%0A%5Clog%20p(x%7Cc)=%5Clog%20p(c%7Cx)+%5Clog%20p(x)-%5Clog%20p(c),%0A"> <span id="eq-conditioned-score"><img src="https://latex.codecogs.com/png.latex?%0A%5Ctherefore%5Cqquad%5Cnabla_x%5Clog%20p(x%7Cc)=%5Cnabla_x%5Clog%20p(x)+%5Cnabla_x%5Clog%20p(c%7Cx).%0A%5Ctag%7B1%7D"></span></p>
<p>すなわち，条件付き確率 <img src="https://latex.codecogs.com/png.latex?p(x%7Cc)"> のスコア場は，条件なしのスコア場 <img src="https://latex.codecogs.com/png.latex?%5Cnabla_x%5Clog%20p(x)"> と，分類器のスコア場 <img src="https://latex.codecogs.com/png.latex?%5Cnabla_x%5Clog%20p(c%7Cx)"> の重ね合わせになる．</p>
</section>
<section id="sec-CG" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="sec-CG"><span class="header-section-number">1.3</span> 分類器による誘導 (CG)</h3>
<p>式 (1) から，<img src="https://latex.codecogs.com/png.latex?%5Cnabla_x%5Clog%20p(x%7Cc)"> が計算できる分類器 <img src="https://latex.codecogs.com/png.latex?p(c%7Cx)"> を新たに訓練すれば，既存のモデル <img src="https://latex.codecogs.com/png.latex?%5Cnabla_x%5Clog%20p(x)"> から，サンプリング方法を変えるだけで条件付き生成ができる．</p>
<p>これを <strong>CG: Classifier Guidance</strong> <span class="citation" data-cites="Dhariwal-Nichol2021">(Dhariwal and Nichol, 2021)</span> といい，サンプリング中に各ステップで少しずつ <img src="https://latex.codecogs.com/png.latex?x_t"> が <img src="https://latex.codecogs.com/png.latex?p(x_t%7Cc)"> に近づくように「誘導」されていく．</p>
<p>さらに，<img src="https://latex.codecogs.com/png.latex?c"> が無視されがちな場合も見越して，誘導スケール (guidance scale) という新たなハイパーパラメータ <img src="https://latex.codecogs.com/png.latex?%5Clambda%5Cge0"> を導入し，次のスコア <span id="eq-CG-score"><img src="https://latex.codecogs.com/png.latex?%0A%5Cnabla_x%5Clog%20p(x)+%5Clambda%5Cnabla_x%5Clog%20p(c%7Cx).%0A%5Ctag%7B2%7D"></span> からサンプリングすることも考えられる．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Clambda%3E1"> としどんどん大きくしていくと，クラスラベル <img src="https://latex.codecogs.com/png.latex?c"> に「典型的な」サンプルが生成される傾向にある．</p>
</section>
<section id="分類器なしの誘導" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="分類器なしの誘導"><span class="header-section-number">1.4</span> 分類器なしの誘導</h3>
<p>CG はいわばアドホックな方法であり，外部の分類器 <img src="https://latex.codecogs.com/png.latex?p(c%7Cx)"> に頼らない方法を考えたい．</p>
<p>そのためには，式 (2) から <img src="https://latex.codecogs.com/png.latex?p(c%7Cx)"> を消去して <span id="eq-CFG-score"><img src="https://latex.codecogs.com/png.latex?%0A%5Clambda%5Cnabla_x%5Clog%20p(x%7Cc)+(1-%5Clambda)%5Cnabla_x%5Clog%20p(x)%0A%5Ctag%7B3%7D"></span> とみて，<img src="https://latex.codecogs.com/png.latex?p(x%7Cc),p(x)"> のいずれもデータから学ぶ．</p>
<p>このアプローチを <strong>Classifier-Free Diffusion Guidance</strong> <span class="citation" data-cites="Ho-Salimans2021">(Ho and Salimans, 2021)</span> という．</p>
<p>その際は，新たなクラスラベル <img src="https://latex.codecogs.com/png.latex?%5Cemptyset"> を導入して <img src="https://latex.codecogs.com/png.latex?%0Ap(x)=p(x%7C%5Cemptyset)%0A"> とみなすことで，<img src="https://latex.codecogs.com/png.latex?p(x%7Cc),p(x)"> を同一の <a href="../../../posts/2024/Samplers/Diffusion.html#sec-score-network">スコアネットワーク</a> でモデリングする．</p>
<p>データセット内にランダムに1から2割の画像をクラスラベル <img src="https://latex.codecogs.com/png.latex?%5Cemptyset"> と設定することで，これを実現する．</p>
<p>同様の方法を，スコアマッチングではなくフローマッチングを行うことを <span class="citation" data-cites="Dao+2023">(Dao et al., 2023)</span>, <span class="citation" data-cites="Zheng+2023GuidedFlow">(Q. Zheng et al., 2023)</span> が提案している．</p>
<p>この方法は，追加の分類器の訓練が必要ないだけでなく，サンプリングのクオリティも向上する <span class="citation" data-cites="Nichol+2022">(Nichol et al., 2022)</span>, <span class="citation" data-cites="Saharia+2022SIGGRAPH">(Saharia, Chan, Chang, et al., 2022)</span>．これは分類タスクで訓練されたスコア <img src="https://latex.codecogs.com/png.latex?%5Clog%20p(c%7Cx)"> はどう訓練してもスコアネットワークで学習したスコア (3) に匹敵する「良い」勾配が得られないためである．</p>
</section>
<section id="高解像度画像生成への応用" class="level3" data-number="1.5">
<h3 data-number="1.5" class="anchored" data-anchor-id="高解像度画像生成への応用"><span class="header-section-number">1.5</span> 高解像度画像生成への応用</h3>
<section id="sec-CascadedGeneration" class="level4" data-number="1.5.1">
<h4 data-number="1.5.1" class="anchored" data-anchor-id="sec-CascadedGeneration"><span class="header-section-number">1.5.1</span> Cascaded Generation</h4>
<p>条件付き生成の技術はそのままで，最終的なクオリティを向上させるためには，Cascading <span class="citation" data-cites="Ho+2022">(Ho et al., 2022)</span> が使用可能である．</p>
<p>これは，画像生成は <img src="https://latex.codecogs.com/png.latex?x"> の解像度が低い状態で行い，この低解像度画像を次の条件付き拡散モデルの条件付け <img src="https://latex.codecogs.com/png.latex?c"> として，条件付き生成を <strong>高解像度化</strong> (super-resolution) に用いるものである <span class="citation" data-cites="Saharia+2023">(Saharia et al., 2023)</span>．</p>
<p>この方法の美点は，条件付き生成器をたくさんスタックしたのちに，拡散模型間の段階でも Gauss ノイズや blur を印加することで，さらに最終的なクオリティが上げられるという <span class="citation" data-cites="Ho+2022">(Ho et al., 2022)</span>．これを <strong>conditioning augmentation</strong> と呼んでいる．</p>
<p>この方法は最初から高解像度での生成を目指して大規模な単一の拡散模型を設計するよりも大きく計算コストを削減できる．</p>
<p>Google も <a href="https://imagen.research.google/">Imagen</a> <span class="citation" data-cites="Saharia+2022">(Saharia, Chan, Saxena, et al., 2022)</span> でこのアーキテクチャを用いている．</p>
</section>
<section id="self-conditioning-chen2023analogbits" class="level4" data-number="1.5.2">
<h4 data-number="1.5.2" class="anchored" data-anchor-id="self-conditioning-chen2023analogbits"><span class="header-section-number">1.5.2</span> Self-Conditioning <span class="citation" data-cites="Chen+2023AnalogBits">(T. Chen et al., 2023)</span></h4>
<p>拡散モデルを自己再帰的に用い，自身の前回の出力を今回の入力として逐次的にサンプリングを繰り返すことで，サンプリングのクオリティをさらに向上する自己条件づけが <span class="citation" data-cites="Chen+2023AnalogBits">(T. Chen et al., 2023)</span> で提案された．</p>
<p>この方法は RoseTTAFold Diffusion <span class="citation" data-cites="Watson+2023">(Watson et al., 2023)</span> によるたんぱく質構造生成でも用いられている：</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/RFDiff.gif" class="img-fluid figure-img"></p>
<figcaption>RFdiffusion generating a novel protein that binds to the insulin receptor. Taken from <a href="https://www.bakerlab.org/2023/07/11/diffusion-model-for-protein-design/">Baker Lab HP</a></figcaption>
</figure>
</div>
</section>
</section>
<section id="逆問題への応用" class="level3" data-number="1.6">
<h3 data-number="1.6" class="anchored" data-anchor-id="逆問題への応用"><span class="header-section-number">1.6</span> 逆問題への応用</h3>
<p>一方で単一の <img src="https://latex.codecogs.com/png.latex?Y=y"> を想定した状況では，非償却的な方法を採用することでさらに精度を上げることが考えられる．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Clog%20p_t(x_t%7Cy)"> を一緒くたに <img src="https://latex.codecogs.com/png.latex?s%5E%5Ctheta_%7Bt%7D(x_t,y)"> に取り替えてしまうのではなく，まず第一項 <img src="https://latex.codecogs.com/png.latex?%5Cnabla_x%5Clog%20p_t(x_t%7Cy)"> を <img src="https://latex.codecogs.com/png.latex?s_t%5E%5Ctheta(x_t)"> により統一的にモデリングする．</p>
<p>そして <img src="https://latex.codecogs.com/png.latex?%5Cnabla_x%5Clog%20p_t(y%7Cx_t)"> の項は <a href="../../../posts/2024/Samplers/DD1.html#sec-Tweedie-formula">Tweedie の推定量</a> <span id="eq-Tweedie-estimator"><img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7Bx%7D_0:=%5Coperatorname%7BE%7D%5Bx_0%7Cx_t%5D=%5Cfrac%7B1%7D%7B%5Csqrt%7B%5Coverline%7B%5Calpha%7D_t%7D%7D%5Cbiggr(x_t+(1-%5Coverline%7B%5Calpha%7D_t)%5Cnabla_%7Bx_t%7D%5Clog%20p_t(x_t)%5Cbiggl)%0A%5Ctag%7B4%7D"></span> を通じて <img src="https://latex.codecogs.com/png.latex?%0Ap(y%7Cx_t)%5Capprox%20p(y%7C%5Cwidehat%7Bx%7D_0)%0A"> によって近似する．式 (4) の <img src="https://latex.codecogs.com/png.latex?%5Cnabla_%7Bx_t%7D%5Clog%20p_t(x_t)"> に事前に訓練したスコアネットワーク <img src="https://latex.codecogs.com/png.latex?s_t%5E%5Ctheta(x_t)"> を用いる．</p>
<p><span class="citation" data-cites="Chung+2023">(Chung et al., 2023)</span> はこの方法を Computer Vision における非線型逆問題に適用している．</p>
<p><span class="citation" data-cites="Song+2023">(Song et al., 2023)</span> では Monte Carlo 法が用いられている．</p>
<p>拡散模型の一般の事後分布サンプリングのための応用については次稿も参照：</p>
<div id="listing-lst-embedding" class="listing quarto-float quarto-figure quarto-figure-left quarto-listing quarto-listing-container-grid anchored">
<div class="list grid quarto-listing-cols-1">
<div class="g-col-1" data-index="0" data-categories="UHJvY2VzcyUyQ1NhbXBsaW5nJTJDUChYKQ==" data-listing-date-sort="1722643200000" data-listing-file-modified-sort="1733137935916" data-listing-date-modified-sort="1728691200000" data-listing-reading-time-sort="2" data-listing-word-count-sort="300">
<a href="../../../posts/2024/Bridges/SB0.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-center">
<!-- img(9CEB782EFEE6)[progressive=false, height=150px]:lst-embedding:posts/2024/Bridges/SB0.html -->
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
拡散モデルによる事後分布サンプリング
</h5>
<div class="card-subtitle listing-subtitle">
Langevin 拡散の時間反転を用いたシミュレーションベースのサンプリング法
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-03
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>
</section>
<section id="sec-2" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="sec-2"><span class="header-section-number">2</span> フローマッチングによる連続な条件付け</h2>
<section id="sec-CCG" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="sec-CCG"><span class="header-section-number">2.1</span> 連続な条件付き生成</h3>
<p>連続な変数に対する条件付き確率からの生成は CcGAN <span class="citation" data-cites="Ding+2021">(Ding et al., 2021)</span> などでも試みられていた．</p>
<p>AlphaFold 3 <span class="citation" data-cites="Abramson+2024">(Abramson et al., 2024)</span> や RoseTTAFold Diffusion <span class="citation" data-cites="Watson+2023">(Watson et al., 2023)</span>, <span class="citation" data-cites="Krishna+2024">(Krishna et al., 2024)</span> など，たんぱく質構造生成模型において拡散モデルが用いられている理由も，高精度な条件付き生成が可能であることが大きいという．</p>
<p>このことに加えて連続な変数に対する条件付けを可能にすることは，拡散モデルの拡張性をさらに高めることになる．</p>
<p>そもそも拡散モデルは <a href="../../../posts/2024/Samplers/NF1.html#sec-FM">連続時間正規化流</a> (CNF) と合流し，フローマッチング（第 2.2 節）によりノイズ分布 <img src="https://latex.codecogs.com/png.latex?P_0"> をデータ分布 <img src="https://latex.codecogs.com/png.latex?P_1"> に変換する曲線 <img src="https://latex.codecogs.com/png.latex?%5C%7BP_t%5C%7D_%7Bt%5Cin%5B0,1%5D%7D%5Csubset%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)"> を直接学習するように発展した．</p>
<p>この方法では，新たな条件付け変数 <img src="https://latex.codecogs.com/png.latex?c%5Cin%5B0,1%5D%5Ek"> に対して，連続写像 <img src="https://latex.codecogs.com/png.latex?%0AP_%7Bt,c%7D:%5B0,1%5D%5Ctimes%5B0,1%5D%5Ek%5Cto%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)%0A"> を学習するようにフローマッチングを拡張できれば，連続な条件付き生成が可能になることになる．</p>
<p>これを行列値ベクトル場の理論を通じて達成するのが <strong>拡張フローマッチング</strong> (EFM: Extended Flow Matching) <span class="citation" data-cites="Isobe+2024">(Isobe et al., 2024)</span> である．</p>
<p>このようなフローマッチングの拡張は <span class="citation" data-cites="Chen-Lipman2024">(R. T. Q. Chen and Lipman, 2024)</span> でも考えられている．</p>
</section>
<section id="sec-FM" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="sec-FM"><span class="header-section-number">2.2</span> フローマッチング (FM)</h3>
<p>２つの確率分布 <img src="https://latex.codecogs.com/png.latex?P_0,P_1%5Cin%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)"> を結ぶ曲線を <img src="https://latex.codecogs.com/png.latex?%0A(P_t)=((%5Cphi_t)_*P_0)_%7Bt%5Cin%5B0,1%5D%7D%5Cin%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5B0,1%5D%7D%0A"> の形で学習することを考える．</p>
<p>そのための１つのアプローチとして，<a href="https://ja.wikipedia.org/wiki/連続の方程式">連続方程式</a> というPDE <span id="eq-CE"><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%5Cpartial%20p_t%7D%7B%5Cpartial%20t%7D+%5Coperatorname%7Bdiv%7D(F_tp_t)=0.%0A%5Ctag%7B5%7D"></span> を満たすベクトル場 <img src="https://latex.codecogs.com/png.latex?F_t"> を学習し，これが定めるフローを <img src="https://latex.codecogs.com/png.latex?(%5Cphi_t)"> とすることがある：</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%5Cpartial%20%5Cphi_t(x)%7D%7B%5Cpartial%20t%7D=F_t(%5Cphi_t(x)).%0A"></p>
<p>このような <img src="https://latex.codecogs.com/png.latex?F_t"> が１つ既知であり，<img src="https://latex.codecogs.com/png.latex?p_t"> から自由にサンプリングできる場合は， <span id="eq-FM-objective"><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D_%7B%5Cmathrm%7BFM%7D%7D(%5Ctheta)=%5Coperatorname%7BE%7D%5Cbiggl%5B%5Cbiggl%7CF_%5Ctheta(X_T,T)-F_T(X_T)%5Cbiggr%7C%5E2%5Cbiggr%5D,%5Cqquad%20T%5Csim%5Cmathrm%7BU%7D(%5B0,1%5D),X_T%5Csim%20p_T,%0A%5Ctag%7B6%7D"></span> の最小化によってベクトル場 <img src="https://latex.codecogs.com/png.latex?F_t"> が学習できる．これを <strong>フローマッチング</strong> (FM: Flow Matching) の目的関数という．</p>
</section>
<section id="条件付きフローマッチング-cfm" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="条件付きフローマッチング-cfm"><span class="header-section-number">2.3</span> 条件付きフローマッチング (CFM)</h3>
<p>仮に <img src="https://latex.codecogs.com/png.latex?p_t"> が <img src="https://latex.codecogs.com/png.latex?%0Ap_t(x)=%5Cint_%5COmega%20p_t(x%7Cc)q(c)%5C,dc,%5Cqquad%5COmega%5Csubset%5Cmathbb%7BR%7D%5Ek,%0A"> という <img src="https://latex.codecogs.com/png.latex?p_%7Bt,c%7D(x):=p_t(x%7Cc)"> の <img src="https://latex.codecogs.com/png.latex?q">-混合としての展開を通じて得られているとする．</p>
<p>この場合，<img src="https://latex.codecogs.com/png.latex?(p_%7Bt,c%7D)"> を生成するベクトル場 <img src="https://latex.codecogs.com/png.latex?F_t(x%7Cc)"> が特定できれば， <span id="eq-marginal-VF"><img src="https://latex.codecogs.com/png.latex?%0AF_t(x):=%5Coperatorname%7BE%7D%5Cleft%5B%5Cfrac%7BF_t(x%7CU)p_t(x%7CU)%7D%7Bp_t(x)%7D%5Cright%5D%0A%5Ctag%7B7%7D"></span> が <img src="https://latex.codecogs.com/png.latex?(p_t)"> を生成する <span class="citation" data-cites="Lipman+2023">(定理1 Lipman et al., 2023)</span>, <span class="citation" data-cites="Tong+2024">(定理3.1 Tong et al., 2024)</span>．</p>
<p>従って，<img src="https://latex.codecogs.com/png.latex?F_t"> を学習するには FM 目的関数 (6) の代わりに <span id="eq-CFM-objective"><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D_%7B%5Cmathrm%7BCFM%7D%7D(%5Ctheta)=%5Coperatorname%7BE%7D%5Cbiggl%5B%5Cbiggl%7CF_%5Ctheta(X_T,T)-F_T(X%7CC)%5Cbiggr%7C%5E2%5Cbiggr%5D,%5Cqquad%20C%5Csim%20q,%0A%5Ctag%7B8%7D"></span> の最小化によっても <img src="https://latex.codecogs.com/png.latex?F_t(x%7Cc)"> が学習できる．これを <strong>条件付きフローマッチング</strong> (CFM: Conditional Flow Matching) の目的関数という．</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="$P_0$ が Gauss 分布である場合 [@Lipman+2023]">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<img src="https://latex.codecogs.com/png.latex?P_0"> が Gauss 分布である場合 <span class="citation" data-cites="Lipman+2023">(Lipman et al., 2023)</span>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?P_0=%5Cmathrm%7BN%7D_d(0,I_d)"> をノイズ分布，<img src="https://latex.codecogs.com/png.latex?P_1"> を一般のデータ分布とする．</p>
<p>ただし，誤差を許して，<img src="https://latex.codecogs.com/png.latex?P_1*%5Cmathrm%7BN%7D_d(0,%5Csigma%5E2I_d)"> を改めて真のデータ分布とする．</p>
<p>このように定式化することで，各データ点 <img src="https://latex.codecogs.com/png.latex?c%5Cin%5C%7Bx_i%5C%7D_%7Bi=1%7D%5En"> で条件づければ， <img src="https://latex.codecogs.com/png.latex?%0AP_%7B0,c%7D:=P_0(-%7Cc)=%5Cmathrm%7BN%7D_d(0,I_d),%5Cqquad%20P_%7B1,c%7D:=P_1(-%7Cc)=%5Cmathrm%7BN%7D_d(0,%5Csigma%5E2I_d),%0A"> の間を結ぶ曲線 <img src="https://latex.codecogs.com/png.latex?(P_%7Bt,c%7D)_%7Bt%5Cin%5B0,1%5D,c%5Cin%5C%7Bx_i%5C%7D_%7Bi=1%7D%5En%7D"> を学習する問題となる．</p>
<p>実は <img src="https://latex.codecogs.com/png.latex?P_%7B0,c%7D,P_%7B1,c%7D"> が Gauss 分布であることにより，この問題はすでに <span class="citation" data-cites="McCann1997">(McCann, 1997, p. 159)</span> によって解かれており，最適輸送は <img src="https://latex.codecogs.com/png.latex?%0AP_%7Bt,c%7D=%5Cmathrm%7BN%7D_d%5Cbiggr(tc,(t%5Csigma-t+1)%5E2I_d%5Cbiggl),%5Cqquad%20F_t(x%7Cc)=%5Cfrac%7Bc-(1-%5Csigma)x%7D%7B1-(1-%5Csigma)t%7D,%0A"> によって与えられる．</p>
</div>
</div>
</div>
<p>しかし，各 <img src="https://latex.codecogs.com/png.latex?(P_%7Bt,c%7D)_%7Bt%5Cin%5B0,1%5D%7D"> が最適輸送になっていても，式 (7) で定まる <img src="https://latex.codecogs.com/png.latex?(P_t)_%7Bt%5Cin%5B0,1%5D%7D"> が最適輸送になるとは限らない．</p>
</section>
<section id="最適輸送-cfm-ot-cfm" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="最適輸送-cfm-ot-cfm"><span class="header-section-number">2.4</span> 最適輸送 CFM (OT-CFM)</h3>
<p>ここで形式的に，条件付ける変数 <img src="https://latex.codecogs.com/png.latex?c"> は <a href="../../../posts/2024/Probability/Coupling.html">カップリング</a> <img src="https://latex.codecogs.com/png.latex?%5Cpi%5Cin%20C(P_0,P_1)"> に従う <img src="https://latex.codecogs.com/png.latex?C%5Csim%5Cpi"> とする： <img src="https://latex.codecogs.com/png.latex?%0AC(P_0,P_1):=%5Cleft%5C%7B%5Cpi%5Cin%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed%5Ctimes%5Cmathbb%7BR%7D%5Ed)%5C:%5Cmiddle%7C%5C:%5Cbegin%7Barray%7D%7Bl%7D(%5Cmathrm%7Bpr%7D_1)_*%5Cpi=P_0,%5C%5C(%5Cmathrm%7Bpr%7D_2)_*%5Cpi=P_1%5Cend%7Barray%7D%5Cright%5C%7D.%0A"></p>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="$P_0$ も一般の分布である場合 [I-CFM @Tong+2024]">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<img src="https://latex.codecogs.com/png.latex?P_0"> も一般の分布である場合 <span class="citation" data-cites="Tong+2024">(I-CFM Tong et al., 2024)</span>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?Q_0,Q_1"> は未知のデータ分布で， <img src="https://latex.codecogs.com/png.latex?%0AP_1=Q_1*%5Cmathrm%7BN%7D_d(0,%5Csigma%5E2I_d),%5Cqquad%20P_0=Q_0*%5Cmathrm%7BN%7D_d(0,%5Csigma%5E2I_d),%0A"> の間を架橋したいとする．このとき， <img src="https://latex.codecogs.com/png.latex?%0A%5Cpi:=Q_0%5Cotimes%20Q_1%0A"> と定めると， <img src="https://latex.codecogs.com/png.latex?%0AP_%7Bt,c%7D=%5Cmathrm%7BN%7D_d%5Cbiggr(tc_1+(1-t)c_0,%5Csigma%5E2I_d%5Cbiggl),%5Cqquad%20F_t(x%7Cc)=c_1-c_0,%0A"> が <img src="https://latex.codecogs.com/png.latex?P_0,P_1"> の間の輸送を定める <span class="citation" data-cites="Tong+2024">(命題3.3 Tong et al., 2024)</span>．</p>
<p>加えて，<img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cto0"> の極限において，学習される輸送 <img src="https://latex.codecogs.com/png.latex?(P_t)"> は <img src="https://latex.codecogs.com/png.latex?Q_0,Q_1"> の間の輸送になる．</p>
<p>これは <span class="citation" data-cites="Lipman+2023">(Lipman et al., 2023)</span> の例の，<img src="https://latex.codecogs.com/png.latex?P_0,P_1"> を対称に扱った拡張と見れる．</p>
<p>また，<img src="https://latex.codecogs.com/png.latex?P_%7Bt,c%7D"> が <img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cto0"> とした Delta 測度である場合が Rectified Flow <span class="citation" data-cites="Liu+2023-Flow">(Liu et al., 2023)</span> に当たる．</p>
<p>この方法を拡張し，例えば平均を線型関数 <img src="https://latex.codecogs.com/png.latex?m(t)=tc_1+(1-t)c_0"> の代わりに <img src="https://latex.codecogs.com/png.latex?%0Am(t)=%5Ccos%5Cleft(%5Cfrac%7B%5Cpi%20t%7D%7B2%7D%5Cright)c_0+%5Csin%5Cleft(%5Cfrac%7B%5Cpi%20t%7D%7B2%7D%5Cright)c_1%0A"> とした場合が Stochastic Interpolant <span class="citation" data-cites="Albergo-Vanden-Eijnden2023">(Albergo and Vanden-Eijnden, 2023)</span> に当たる．</p>
</div>
</div>
</div>
<p>その中でも特に，<img src="https://latex.codecogs.com/png.latex?%5Cpi"> を 2-Wasserstein 距離に関する最適輸送計画 <img src="https://latex.codecogs.com/png.latex?%0A%5Cpi:=%5Coperatorname*%7Bargmin%7D_%7B%5Cpi%5Cin%20C(P_0,P_1)%7D%5Coperatorname%7BE%7D%5B%5Clvert%20X-Y%5Crvert%5E2%5D%0A"> であるとする．</p>
<p>このとき， <img src="https://latex.codecogs.com/png.latex?%0AP_%7Bt,c%7D=%5Cmathrm%7BN%7D_d%5Cbiggr(tc_1+(1-t)c_0,%5Csigma%5E2I_d%5Cbiggl),%5Cqquad%20F_t(x%7Cc)=c_1-c_0,%0A"> を <img src="https://latex.codecogs.com/png.latex?C%5Csim%5Cpi"> に関して周辺化した輸送 <img src="https://latex.codecogs.com/png.latex?(P_t)%5Cin%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5B0,1%5D%7D"> は，<img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cto0"> の極限で（動的な）最適輸送になる <span class="citation" data-cites="Tong+2024">(命題3.4 Tong et al., 2024)</span>．</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="Schrödinger Bridge のシミュレーション [SB-CFM @Tong+2024]">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Schrödinger Bridge のシミュレーション <span class="citation" data-cites="Tong+2024">(SB-CFM Tong et al., 2024)</span>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cpi_%7B2%5Csigma%5E2%7D:=%5Coperatorname*%7Bargmin%7D_%7B%5Cpi%5Cin%20C(P_0,P_1)%7D%5Cbiggr(%5Coperatorname%7BE%7D%5B%5Clvert%20X-Y%5Crvert%5E2%5D+2%5Csigma%5E2H(%5Cpi)%5Cbiggl)%0A"> を，エントロピー正則化項 <img src="https://latex.codecogs.com/png.latex?2%5Csigma%5E2"> を持ったエントロピー最適輸送計画とする．</p>
<p>このとき，各点を結んだ Broanian bridge <img src="https://latex.codecogs.com/png.latex?%0AP_%7Bt,c%7D:=%5Cmathrm%7BN%7D%5Cbiggr(tc_1+(1-t)c_0,t(1-t)%5Csigma%5E2I_d%5Cbiggl),%0A"> <img src="https://latex.codecogs.com/png.latex?%0AF_t(x%7Cc):=%5Cfrac%7B1-2t%7D%7B2t(1-t)%7D%5Cbiggr(x-(tc_1+(1-t)c_0)%5Cbiggl)+(c_1-c_0),%0A"> の周辺化 <img src="https://latex.codecogs.com/png.latex?(P_t)%5Cin%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5B0,1%5D%7D"> は，標準 Brown 運動を <img src="https://latex.codecogs.com/png.latex?%5Csigma"> だけスケールした分布 <img src="https://latex.codecogs.com/png.latex?W"> に対する Schrödinger bridge <img src="https://latex.codecogs.com/png.latex?%0A%5Cpi%5E*:=%5Coperatorname*%7Bargmin%7D_%7B%5Csubstack%7B%5Cmu_0=P_0%5C%5C%5Cmu_1=P_1%7D%7D%5Coperatorname%7BKL%7D(%5Cmu,W)%0A"> と分布同等になる <span class="citation" data-cites="Tong+2024">(定理3.5 Tong et al., 2024)</span>．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cto0"> の極限が OT-CFM であり，<img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cto%5Cinfty"> の極限が I-CFM である．</p>
</div>
</div>
</div>
<p>訓練時は，CFM の目的関数 (8) を計算するために <img src="https://latex.codecogs.com/png.latex?(X_0,X_1)%5Csim%5Cpi"> というサンプリングが必要になる．データサイズが大きい場合には，これにミニバッチ最適輸送 <span class="citation" data-cites="Fatras+2021">(Fatras et al., 2021)</span> を用いることができる．</p>
<p>このように，２つの分布 <img src="https://latex.codecogs.com/png.latex?P_0,P_1"> を単に独立カップリングと見るのではなく，依存関係があった場合にはそれも考慮してなるべくダイナミクスが直線になるように誘導する方法 Multisample Flow Matching として <span class="citation" data-cites="Pooladian+2023">(Pooladian et al., 2023)</span> も考えている．</p>
</section>
<section id="sec-OT-CFM-in-GFM-perspective" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="sec-OT-CFM-in-GFM-perspective"><span class="header-section-number">2.5</span> <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5B0,1%5D%7D"> 上の最適化としての見方</h3>
<p>実は OT-CFM は，２つの確率密度 <img src="https://latex.codecogs.com/png.latex?p_0,p_1"> を結ぶ曲線 <img src="https://latex.codecogs.com/png.latex?(p_t)%5Cin%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5B0,1%5D%7D"> の中で，<strong>Dirichlet エネルギー</strong> <img src="https://latex.codecogs.com/png.latex?%0AD(p):=%5Cinf_%7B(p,F)%7D%5Cfrac%7B1%7D%7B2%7D%5Cint_%7B%5B0,1%5D%5Ctimes%5Cmathbb%7BR%7D%5Ed%7D%5Clvert%20F_t(x)%5Crvert%5E2p_t(x)%5C,dxdt%0A"> を最小化する曲線 <img src="https://latex.codecogs.com/png.latex?(p_t)"> を学習していると見れる <span class="citation" data-cites="Isobe+2024">(Isobe et al., 2024)</span>．ただし，<img src="https://latex.codecogs.com/png.latex?(p,F)"> は連続方程式 (5) を満たす密度とベクトル場の組とした．</p>
<p>条件付きフローマッチングでは，このような曲線 <img src="https://latex.codecogs.com/png.latex?(p_t)"> を次の方法で構成していた．</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<ol type="1">
<li>ある決定論的なダイナミクス <img src="https://latex.codecogs.com/png.latex?%5Cpsi_c:%5B0,1%5D%5Cto%5Cmathbb%7BR%7D%5Ed"> を定める．<sup>2</sup></li>
<li><img src="https://latex.codecogs.com/png.latex?Q%5Cin%5Cmathcal%7BP%7D(C%5E1(%5B0,1%5D;%5Cmathbb%7BR%7D%5Ed))"> を確率測度とする．</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cpsi,Q"> から， <img src="https://latex.codecogs.com/png.latex?%0AP%5EQ:=%5Coperatorname%7BE%7D_%7B%5Cpsi%5Csim%20Q%7D%5B%5Cdelta_%5Cpsi%5D%0A"> によって確率測度の曲線 <img src="https://latex.codecogs.com/png.latex?(P%5EQ_t)%5Cin%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5B0,1%5D%7D"> を定める．</li>
</ol>
</div>
</div>
</div>
<p>実は Dirichlet 汎函数 <img src="https://latex.codecogs.com/png.latex?D:%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5B0,1%5D%7D%5Cto%5Cmathbb%7BR%7D_+"> が凸であるために，このように構成される <img src="https://latex.codecogs.com/png.latex?(p_t)"> の中での最適解は，<img src="https://latex.codecogs.com/png.latex?Q%5Cin%5Cmathcal%7BP%7D(C%5E1(%5B0,1%5D;%5Cmathbb%7BR%7D%5Ed))"> の全体で探す必要はなく，線型なダイナミクス <img src="https://latex.codecogs.com/png.latex?%0A%5Cpsi_c(t)=tc_1+(1-t)c_0,%5Cqquad%20c=(c_0,c_1)%5Cin%5Cmathbb%7BR%7D%5Ed%5Ctimes%5Cmathbb%7BR%7D%5Ed,%0A"> の重ね合わせの形でのみ探せば良い <span class="citation" data-cites="Brenier2003">(Brenier, 2003)</span>．</p>
<p>従って，<img src="https://latex.codecogs.com/png.latex?(X_0,X_1)"> の分布の全体 <img src="https://latex.codecogs.com/png.latex?C(P_0,P_1)"> のみについてパラメータづけをして探せば良い．さらにこの場合， <img src="https://latex.codecogs.com/png.latex?%0AF_t(x%7Cc)=%5Cfrac%7B%5Cpartial%20%5Cpsi_c(t)%7D%7B%5Cpartial%20t%7D=c_1-c_0%0A"> であるから，<img src="https://latex.codecogs.com/png.latex?D(P)=2W_2(P_0,P_1)%5E2"> の最小化は <img src="https://latex.codecogs.com/png.latex?P_0,P_1"> の 2-Wasserstein 最適な輸送計画 <img src="https://latex.codecogs.com/png.latex?%5Cpi%5E*"> の探索に等価になる．</p>
<p>これが OT-CFM の <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5B0,1%5D%7D"> 上の最適化としての解釈である．同時に，条件付きフローマッチングの目的関数 (8) の他に，<a href="../../../posts/2024/Samplers/EBM.html#sec-DSM">DSM</a> 様の目的関数 <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D%5Cbiggl%5B%5Cbiggl%7CF_T(%5Cpsi(T))-%5Cpartial_t%5Cpsi_C(T)%5Cbiggr%7C%5E2%5Cbiggr%5D,%5Cqquad%20T%5Csim%5Cmathrm%7BU%7D(%5B0,1%5D),C%5Csim%5Cpi%5E*,%0A"> の最小化点としてもベクトル場 <img src="https://latex.codecogs.com/png.latex?F_t"> が学習できる．</p>
</section>
<section id="sec-GFM" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="sec-GFM"><span class="header-section-number">2.6</span> 拡張フローマッチング (GFM)</h3>
<p>前節での観察は次のように要約できる：</p>
<div class="callout callout-style-simple callout-important no-icon callout-titled" title="OT-CFM の Dirichlet 汎函数最小化としての特徴付け">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
OT-CFM の Dirichlet 汎函数最小化としての特徴付け
</div>
</div>
<div class="callout-body-container callout-body">
<p>OT-CFM は，条件付きフローマッチングに対して，Dirichlet エネルギーの言葉で帰納バイアスを導入することで，最適輸送を学習するための方法論である．</p>
</div>
</div>
<p>こう考えると，Dirichlet エネルギーの言葉で他の帰納バイアスを導入することが考えられる．</p>
<p>ここで条件付けの議論（第 2.1 節）に戻ってくる．最適輸送のための <img src="https://latex.codecogs.com/png.latex?c=(c_0,c_1)%5Cin%5Cmathbb%7BR%7D%5E%7B2d%7D"> に限らず，一般の <img src="https://latex.codecogs.com/png.latex?c%5Cin%5Cmathbb%7BR%7D%5Ek"> に対して連続に条件付けされるように拡張したい．</p>
<p>これは，<img src="https://latex.codecogs.com/png.latex?(F_t),(p_t)"> の添字を <img src="https://latex.codecogs.com/png.latex?t%5Cin%5B0,1%5D"> から <img src="https://latex.codecogs.com/png.latex?%5Cxi%5Cin%5B0,1%5D%5Ctimes%5Cmathbb%7BR%7D%5Ek"> に拡張することで達成される．</p>
<p>これは新たな <img src="https://latex.codecogs.com/png.latex?(F_%5Cxi),(p_%5Cxi)"> を <img src="https://latex.codecogs.com/png.latex?M_%7Bdk%7D(%5Cmathbb%7BR%7D)">-値の行列値ベクトル場 <img src="https://latex.codecogs.com/png.latex?(F_t)"> とベクトル値密度 <img src="https://latex.codecogs.com/png.latex?(p_t)"> と見ることに等価である．すると，<strong>一般化連続方程式</strong> <span class="citation" data-cites="Brenier2003">(Brenier, 2003)</span>, <span class="citation" data-cites="Lavenant2019">(Lavenant, 2019)</span> <img src="https://latex.codecogs.com/png.latex?%0A%5Cnabla_%5Cxi%20p_%5Cxi(x)+%5Coperatorname%7Bdiv%7D_x(p_%5Cxi%20u_%5Cxi)=0%0A"> の理論を用いれば，全く同様の枠組みで可能になる <span class="citation" data-cites="Isobe+2024">(命題1 Isobe et al., 2024)</span>．</p>
<p>これが <strong>拡張フローマッチング</strong> (EFM: Extended Flow Matching) <span class="citation" data-cites="Isobe+2024">(Isobe et al., 2024)</span> である．</p>
</section>
<section id="gfm-の無限次元最適化" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="gfm-の無限次元最適化"><span class="header-section-number">2.7</span> GFM の無限次元最適化</h3>
<p>ただし，拡張 Dirichlet エネルギー <span class="citation" data-cites="Lavenant2019">(Lavenant, 2019)</span> <img src="https://latex.codecogs.com/png.latex?%0AD(P):=%5Cinf_%7B(p,F)%7D%5Cfrac%7B1%7D%7B2%7D%5Cint_%7B%5B0,1%5D%5Ctimes%5Cmathbb%7BR%7D%5Ek%5Ctimes%5Cmathbb%7BR%7D%5Ed%7D%5Clvert%20F_%5Cxi(x)%5Crvert%5E2p_%5Cxi(x)%5C,dxd%5Cxi%0A"> の第 2.5 節の形での最小化点は，もはや線型なダイナミクスの重ね合わせとは限らない．</p>
<p>すると無限次元最適化になってしまうため，適切な <a href="../../../posts/2023/KernelMethods/KernelMethods4Mathematicians.html">RKHS</a> <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BF%7D%5Csubset%5Cmathrm%7BMap%7D(%5B0,1%5D%5Ctimes%5Cmathbb%7BR%7D%5Ek;%5Cmathbb%7BR%7D%5Ed)"> 内で探すことが必要である： <img src="https://latex.codecogs.com/png.latex?%0A%5Cpsi=%5Cphi_%7Bx_%7B%5Cpartial%5CXi%7D%7D%5Cin%5Coperatorname*%7Bargmin%7D_%7Bf%5Cin%5Cmathcal%7BF%7D%7D%5Csum_%7B%5Cxi%5Cin%5Cpartial%5CXi%7D%5Clvert%20f(%5Cxi)-x_%5Cxi%5Crvert%5E2.%0A"> ただし，<img src="https://latex.codecogs.com/png.latex?%5Cpartial%5CXi%5Coverset%7B%5Ctext%7Bfinite%7D%7D%7B%5Csubset%7D%5B0,1%5D%5Ctimes%5Cmathbb%7BR%7D%5Ek"> は境界条件が与えられる点の有限集合で，<img src="https://latex.codecogs.com/png.latex?x_%5Cxi%5Cin%5Cmathbb%7BR%7D%5Ed"> はその点での値である．</p>
<p><img src="https://latex.codecogs.com/png.latex?(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5Clvert%5Cpartial%5CXi%5Crvert%7D"> 上での結合分布 <img src="https://latex.codecogs.com/png.latex?%5Cpi"> が与えられたならば， <img src="https://latex.codecogs.com/png.latex?%0A%5Cinf_%7BQ%5Cin%5Cmathcal%7BP%7D(C%5E1(%5B0,1%5D%5Ctimes%5Cmathbb%7BR%7D%5Ek;%5Cmathbb%7BR%7D%5Ed))%7DD(P%5EQ)%5Cle%5Cinf_%5Cpi%5Cint_%7B(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5Clvert%5Cpartial%5CXi%5Crvert%7D%7D%5Clvert%5Cnabla_%5Cxi%5Cphi_%7Bx_%7B%5Cpartial%5CXi%7D%7D%5Crvert%5E2%5Cpi(dx_%5Cxi)%0A"> という評価が得られるが，この右辺は最適輸送の形になっており，最小値が適切な周辺分布とコスト関数 <img src="https://latex.codecogs.com/png.latex?%0Ac(x_%7B%5Cpartial%5CXi%7D):=%5Cint_%7B%5B0,1%5D%5Ctimes%5Cmathbb%7BR%7D%5Ek%7D%5Clvert%5Cnabla_%5Cxi%5Cphi_%7Bx_%7B%5Cpartial%5CXi%7D%7D(%5Cxi)%5Crvert%5E2%5C,d%5Cxi%0A"> が定める輸送計画問題になっている．</p>
<p>この解 <img src="https://latex.codecogs.com/png.latex?%5Cpi%5E*"> をミニバッチ最適輸送で解きながら，目的関数 <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D%5Cbiggl%5B%5Cbiggl%7CF_T(%5Cpsi(T))-%5Cnabla_%5Cxi%5Cphi_%7Bx_%7B%5Cpartial%5CXi%7D%7D%5Cbiggr%7C%5E2%5Cbiggr%5D,%5Cqquad%20T%5Csim%5Cmathrm%7BU%7D(%5B0,1%5D),x_%7B%5Cpartial%5CXi%7D%5Csim%5Cpi%5E*,%0A"> の最小化点としてベクトル場 <img src="https://latex.codecogs.com/png.latex?F_t"> を学習することができる <span class="citation" data-cites="Isobe+2024">(定理4 Isobe et al., 2024)</span>．</p>
<p>これを <span class="citation" data-cites="Isobe+2024">(Isobe et al., 2024)</span> は MMOT-EFM と呼んでいる．</p>
</section>
</section>



<div id="quarto-appendix" class="default"><section id="文献紹介" class="level2 appendix" data-number="3"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3</span> 文献紹介</h2><div class="quarto-appendix-contents">

<p>本記事の後半第 2 節は，<span class="citation" data-cites="Tong+2024">(Tong et al., 2024)</span>, <span class="citation" data-cites="Isobe+2024">(Isobe et al., 2024)</span> の解説である．</p>
<p>前半の内容に関して，メンダコ氏によるブログ記事 <a href="https://horomary.hatenablog.com/entry/2024/06/30/211033">AlphaFold の進化史</a> は AlphaFold3 が丁寧に解説されている．</p>
<p>当該ブログは丁寧に書かれており，大変おすすめできる．</p>
<blockquote class="blockquote">
<p>Alphafold3とは長大な条件付けネットワークを備えた全原子拡散生成モデルであると前述したとおり、Alphafold3では必須入力としてタンパク質配列を、任意入力として核酸配列、SMILES形式で表現された低分子リガンド、金属イオンなどを長大な条件付けネットワークに入力することで、拡散モデルへの条件付けベクトルを作成します。</p>
</blockquote>
<blockquote class="blockquote">
<p>DeepLearningで大規模分子の構造分布を予測するなんて数年前には考えられませんでしたが、拡散モデルによってすでに現実になりつつあります。一例として Distributional GraphormerというMicrosoft Researchの研究 <span class="citation" data-cites="Zheng+2024">(S. Zheng et al., 2024)</span> を紹介します。</p>
</blockquote>
<p>続きはぜひ，<a href="https://horomary.hatenablog.com/entry/2024/06/30/211033#AlphaFold3-2024">メンダコ氏のブログ</a>でお読みください．</p>
<p><span class="citation" data-cites="Dao+2023">(Dao et al., 2023)</span> のプロジェクトページは <a href="https://vinairesearch.github.io/LFM/">こちら</a>．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Abramson+2024" class="csl-entry">
Abramson, J., Adler, J., Dunger, J., Evans, R., Green, T., Pritzel, A., … Jumper, J. M. (2024). <a href="https://doi.org/10.1038/s41586-024-07487-w">Accurate structure prediction of biomolecular interactions with AlphaFold 3</a>. <em>Nature</em>, <em>630</em>(8016), 493–500.
</div>
<div id="ref-Albergo-Vanden-Eijnden2023" class="csl-entry">
Albergo, M. S., and Vanden-Eijnden, E. (2023). <a href="https://openreview.net/forum?id=li7qeBbCR1t"><span class="nocase">Building Normalizing Flows with Stochastic Interpolants</span></a>. In <em>The eleventh international conference on learning representations</em>.
</div>
<div id="ref-Brenier2003" class="csl-entry">
Brenier, Y. (2003). <a href="https://doi.org/10.1007/978-3-540-44857-0_4">Extended monge-kantorovich theory</a>. In <em>Optimal transportation and applications: Lectures given at the c.i.m.e. Summer school, held in martina franca, italy, september 2-8, 2001</em>, pages 91–121. Berlin, Heidelberg: Springer Berlin Heidelberg.
</div>
<div id="ref-Chen-Lipman2024" class="csl-entry">
Chen, R. T. Q., and Lipman, Y. (2024). <a href="https://openreview.net/forum?id=g7ohDlTITL">Flow matching on general geometries</a>. In <em>The twelfth international conference on learning representations</em>.
</div>
<div id="ref-Chen+2023AnalogBits" class="csl-entry">
Chen, T., ZHANG, R., and Hinton, G. (2023). <a href="https://openreview.net/forum?id=3itjR9QxFw">Analog bits: Generating discrete data using diffusion models with self-conditioning</a>. In <em>The eleventh international conference on learning representations</em>.
</div>
<div id="ref-Chung+2023" class="csl-entry">
Chung, H., Kim, J., Mccann, M. T., Klasky, M. L., and Ye, J. C. (2023). <a href="https://openreview.net/forum?id=OnD9zGAGT0k">Diffusion posterior sampling for general noisy inverse problems</a>. In <em>The eleventh international conference on learning representations</em>.
</div>
<div id="ref-Dao+2023" class="csl-entry">
Dao, Q., Phung, H., Nguyen, B., and Tran, A. (2023). <a href="https://arxiv.org/abs/2307.08698">Flow matching in latent space</a>.
</div>
<div id="ref-Dhariwal-Nichol2021" class="csl-entry">
Dhariwal, P., and Nichol, A. Q. (2021). <a href="https://openreview.net/forum?id=AAWuCvzaVt">Diffusion models beat <span>GAN</span>s on image synthesis</a>. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan, editors, <em>Advances in neural information processing systems</em>.
</div>
<div id="ref-Ding+2021" class="csl-entry">
Ding, X., Wang, Y., Xu, Z., Welch, W. J., and Wang, Z. J. (2021). <a href="https://openreview.net/forum?id=PrzjugOsDeE">Cc<span>{</span>GAN<span>}</span>: Continuous conditional generative adversarial networks for image generation</a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Fatras+2021" class="csl-entry">
Fatras, K., Zine, Y., Majewski, S., Flamary, R., Gribonval, R., and Courty, N. (2021). <a href="https://arxiv.org/abs/2101.01792">Minibatch optimal transport distances; analysis and applications</a>.
</div>
<div id="ref-Ho+2020" class="csl-entry">
Ho, J., Jain, A., and Abbeel, P. (2020). <a href="https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html"><span>Denoising Diffusion Probabilistic Models</span></a>. In <em>Advances in neural information processing systems</em>,Vol. 33.
</div>
<div id="ref-Ho+2022" class="csl-entry">
Ho, J., Saharia, C., Chan, W., Fleet, D. J., Norouzi, M., and Salimans, T. (2022). <a href="http://jmlr.org/papers/v23/21-0635.html">Cascaded diffusion models for high fidelity image generation</a>. <em>Journal of Machine Learning Research</em>, <em>23</em>(47), 1–33.
</div>
<div id="ref-Ho-Salimans2021" class="csl-entry">
Ho, J., and Salimans, T. (2021). <a href="https://openreview.net/forum?id=qw8AKxfYbI">Classifier-free diffusion guidance</a>. In <em>NeurIPS 2021 workshop on deep generative models and downstream applications</em>.
</div>
<div id="ref-Isobe+2024" class="csl-entry">
Isobe, N., Koyama, M., Zhang, J., Hayashi, K., and Fukumizu, K. (2024). <a href="https://arxiv.org/abs/2402.18839">Extended flow matching: A method of conditional generation with generalized continuity equation</a>.
</div>
<div id="ref-Kingma+2014" class="csl-entry">
Kingma, D. P., Mohamed, S., Jimenez Rezende, D., and Welling, M. (2014). <a href="https://proceedings.neurips.cc/paper_files/paper/2014/file/d523773c6b194f37b938d340d5d02232-Paper.pdf"><span class="nocase">Semi-supervised Learning with Deep Generative Models</span></a>. In Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K. Q. Weinberger, editors, <em>Advances in neural information processing systems</em>,Vol. 27. Curran Associates, Inc.
</div>
<div id="ref-Krishna+2024" class="csl-entry">
Krishna, R., Wang, J., Ahern, W., Sturmfels, P., Venkatesh, P., Kalvet, I., … Baker, D. (2024). <a href="https://doi.org/10.1126/science.adl2528">Generalized biomolecular modeling and design with RoseTTAFold all-atom</a>. <em>Science</em>, <em>384</em>(6693), eadl2528.
</div>
<div id="ref-Lavenant2019" class="csl-entry">
Lavenant, H. (2019). <a href="https://doi.org/10.1016/j.jfa.2019.05.003">Harmonic mappings valued in the wasserstein space</a>. <em>Journal of Functional Analysis</em>, <em>277</em>(3), 688–785.
</div>
<div id="ref-Lipman+2023" class="csl-entry">
Lipman, Y., Chen, R. T. Q., Ben-Hamu, H., Nickel, M., and Le, M. (2023). <a href="https://openreview.net/forum?id=PqvMRDCJT9t">Flow matching for generative modeling</a>. In <em>The eleventh international conference on learning representations</em>.
</div>
<div id="ref-Liu+2023-Flow" class="csl-entry">
Liu, X., Gong, C., and liu, qiang. (2023). <a href="https://openreview.net/forum?id=XVjTT1nw5z">Flow straight and fast: Learning to generate and transfer data with rectified flow</a>. In <em>The eleventh international conference on learning representations</em>.
</div>
<div id="ref-McCann1997" class="csl-entry">
McCann, R. J. (1997). <a href="https://doi.org/10.1006/aima.1997.1634">A convexity principle for interacting gases</a>. <em>Advances in Mathematics</em>, <em>128</em>(1), 153–179.
</div>
<div id="ref-Nichol+2022" class="csl-entry">
Nichol, A. Q., Dhariwal, P., Ramesh, A., Shyam, P., Mishkin, P., Mcgrew, B., … Chen, M. (2022). <a href="https://proceedings.mlr.press/v162/nichol22a.html"><span>GLIDE</span>: Towards photorealistic image generation and editing with text-guided diffusion models</a>. In K. Chaudhuri, S. Jegelka, L. Song, C. Szepesvari, G. Niu, and S. Sabato, editors, <em>Proceedings of the 39th international conference on machine learning</em>,Vol. 162, pages 16784–16804. PMLR.
</div>
<div id="ref-Pooladian+2023" class="csl-entry">
Pooladian, A.-A., Ben-Hamu, H., Domingo-Enrich, C., Amos, B., Lipman, Y., and Chen, R. T. Q. (2023). <a href="https://proceedings.mlr.press/v202/pooladian23a.html">Multisample flow matching: Straightening flows with minibatch couplings</a>. In A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett, editors, <em>Proceedings of the 40th international conference on machine learning</em>,Vol. 202, pages 28100–28127. PMLR.
</div>
<div id="ref-Saharia+2022SIGGRAPH" class="csl-entry">
Saharia, C., Chan, W., Chang, H., Lee, C. A., Ho, J., Salimans, T., … Norouzi, M. (2022). <a href="https://openreview.net/forum?id=FPGs276lUeq"><span class="nocase">Palette: Image-to-Image Diffusion Models</span></a>.
</div>
<div id="ref-Saharia+2022" class="csl-entry">
Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E., … Norouzi, M. (2022). <a href="https://openreview.net/forum?id=08Yk-n5l2Al">Photorealistic text-to-image diffusion models with deep language understanding</a>. In A. H. Oh, A. Agarwal, D. Belgrave, and K. Cho, editors, <em>Advances in neural information processing systems</em>.
</div>
<div id="ref-Saharia+2023" class="csl-entry">
Saharia, C., Ho, J., Chan, W., Salimans, T., Fleet, D. J., and Norouzi, M. (2023). <a href="https://doi.org/10.1109/TPAMI.2022.3204461">Image super-resolution via iterative refinement</a>. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, <em>45</em>(4), 4713–4726.
</div>
<div id="ref-Song+2023" class="csl-entry">
Song, J., Zhang, Q., Yin, H., Mardani, M., Liu, M.-Y., Kautz, J., … Vahdat, A. (2023). <a href="https://proceedings.mlr.press/v202/song23k.html">Loss-guided diffusion models for plug-and-play controllable generation</a>. In A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett, editors, <em>Proceedings of the 40th international conference on machine learning</em>,Vol. 202, pages 32483–32498. PMLR.
</div>
<div id="ref-Tong+2024" class="csl-entry">
Tong, A., FATRAS, K., Malkin, N., Huguet, G., Zhang, Y., Rector-Brooks, J., … Bengio, Y. (2024). <a href="https://openreview.net/forum?id=CD9Snc73AW"><span class="nocase">Improving and Generalizing Flow-Based Generative Models with Minibatch Optimal Transport</span></a>. <em>Transactions on Machine Learning Research</em>.
</div>
<div id="ref-Watson+2023" class="csl-entry">
Watson, J. L., Juergens, D., Bennett, N. R., Trippe, B. L., Yim, J., Eisenach, H. E., … Baker, D. (2023). <a href="https://doi.org/10.1038/s41586-023-06415-8">De novo design of protein structure and function with RFdiffusion</a>. <em>Nature</em>, <em>620</em>(7976), 1089–1100.
</div>
<div id="ref-Zheng+2023GuidedFlow" class="csl-entry">
Zheng, Q., Le, M., Shaul, N., Lipman, Y., Grover, A., and Chen, R. T. Q. (2023). <a href="https://arxiv.org/abs/2311.13443">Guided flows for generative modeling and decision making</a>.
</div>
<div id="ref-Zheng+2024" class="csl-entry">
Zheng, S., He, J., Liu, C., Shi, Y., Lu, Z., Feng, W., … Liu, T.-Y. (2024). <a href="https://doi.org/10.1038/s42256-024-00837-3">Predicting equilibrium distributions for molecular systems with deep learning</a>. <em>Nature Machine Intelligence</em>, <em>6</em>(5), 558–567.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><img src="https://latex.codecogs.com/png.latex?c"> が <img src="https://latex.codecogs.com/png.latex?x_t"> と同じ画像である場合は，<span class="citation" data-cites="Ho+2022">(Ho et al., 2022)</span> のように <img src="https://latex.codecogs.com/png.latex?x_t"> にそのまま連結することも考えられる．↩︎</p></li>
<li id="fn2"><p>すべての <img src="https://latex.codecogs.com/png.latex?(P_%7Bt,c%7D)_%7Bt%5Cin%5B0,1%5D%7D"> は <img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cto0"> の極限で決定論的なダイナミクスを定めていた．これを <img src="https://latex.codecogs.com/png.latex?%5Cpsi_c(t)"> と表すこととする．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Deep</category>
  <category>Sampling</category>
  <category>P(X)</category>
  <guid>https://162348.github.io/posts/2024/Samplers/NF3.html</guid>
  <pubDate>Sat, 10 Aug 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Samplers/Files/RFDiff.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>カーネル法の概観</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Kernels/Kernel.html</link>
  <description><![CDATA[ 





<section id="関連ページ" class="level2 unnumbered unlisted">
<h2 class="unnumbered unlisted anchored" data-anchor-id="関連ページ">関連ページ</h2>
<div id="listing-kernel-listing" class="quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="QmF5ZXNpYW4lMkNLZXJuZWwlMkNQeXRob24=" data-listing-date-sort="1707609600000" data-listing-file-modified-sort="1733137936200" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="3" data-listing-word-count-sort="592">
<a href="../../../posts/2024/Kernels/GP.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/docs/posts/2024/Kernels/GP_files/figure-html/cell-10-output-1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Gauss 過程を用いた統計解析
</h5>
<div class="card-subtitle listing-subtitle">
実践編（回帰と分類）
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-11
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="QmF5ZXNpYW4lMkNLZXJuZWwlMkNQcm9jZXNz" data-listing-date-sort="1707609600000" data-listing-file-modified-sort="1733137936200" data-listing-date-modified-sort="1723075200000" data-listing-reading-time-sort="2" data-listing-word-count-sort="216">
<a href="../../../posts/2024/Kernels/GP2.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Kernels/Images/Gibbs.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Gauss 過程を用いたベイズ推論
</h5>
<div class="card-subtitle listing-subtitle">
理論編
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-11
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="S2VybmVs" data-listing-date-sort="1699315200000" data-listing-file-modified-sort="1733137935612" data-listing-date-modified-sort="1710374400000" data-listing-reading-time-sort="2" data-listing-word-count-sort="256">
<a href="../../../posts/2023/KernelMethods/KernelMethods4Mathematicians.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2023/KernelMethods/KernelMethods.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
数学者のためのカーネル法概観
</h5>
<div class="card-subtitle listing-subtitle">
カーネル PCA と SVM を例として
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2023-11-07
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="3" data-categories="S2VybmVs" data-listing-date-sort="1710374400000" data-listing-file-modified-sort="1733137936220" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="1" data-listing-word-count-sort="48">
<a href="../../../posts/2024/Kernels/Kernel1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<!-- img(9CEB782EFEE6)[progressive=false, height=150px]:kernel-listing:posts/2024/Kernels/Kernel1.html -->
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
カーネル法１
</h5>
<div class="card-subtitle listing-subtitle">
カーネル平均埋め込み
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-03-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="4" data-categories="RGVlcCUyQ05hdHVyZSUyQ1N0YXRpc3RpY3MlMkNHZW9tZXRyeQ==" data-listing-date-sort="1722297600000" data-listing-file-modified-sort="1733137936220" data-listing-date-modified-sort="1723680000000" data-listing-reading-time-sort="3" data-listing-word-count-sort="597">
<a href="../../../posts/2024/Kernels/Manifold.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Kernels/Images/UMAPvSNE.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
非線型な次元縮約法の概観
</h5>
<div class="card-subtitle listing-subtitle">
最古にして最難のタスクと多様体学習
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-07-30
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="5" data-categories="RGVlcA==" data-listing-date-sort="1722211200000" data-listing-file-modified-sort="1733137936220" data-listing-date-modified-sort="1723420800000" data-listing-reading-time-sort="2" data-listing-word-count-sort="385">
<a href="../../../posts/2024/Kernels/NCL.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Kernels/Images/contrastive_repr4.jpeg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
表現学習と非線型独立成分分析
</h5>
<div class="card-subtitle listing-subtitle">
「データ理解」に向けた深層潜在変数モデル
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-07-29
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
</section>
<section id="半正定値カーネル" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> 半正定値カーネル</h1>
<section id="はじめに" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="はじめに"><span class="header-section-number">1.1</span> はじめに</h2>
<p>カーネル法は，カーネルの選択と構成が第一歩になる．</p>
<p>例えば <a href="../../../posts/2024/Kernels/GP2.html">Gauss 過程</a> は，平均関数と共分散関数＝正定値カーネルを定めるごとに定まる．従って Gauss 過程回帰などを実行する前には，適切な事前 Gauss 過程を定める半正定値カーネルを選ぶ必要がある．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義（正定値核関数）^[[@Murphy2022 p.565] 17.1節は，半正定値核のことを Mercer 核とも呼んでいる．]">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定義（正定値核関数）<sup>1</sup>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>一般に <strong>核</strong> とは，可測関数 <img src="https://latex.codecogs.com/png.latex?E,F"> の間の写像 <img src="https://latex.codecogs.com/png.latex?K:E%5Cto%5Cmathcal%7BS%7D(F)"> をいう．ただし，<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BS%7D(F)"> は <img src="https://latex.codecogs.com/png.latex?F"> 上の符号付き測度全体の集合とする．</p>
<p>特に <img src="https://latex.codecogs.com/png.latex?F"> 上の確率測度の全体 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BP%7D(F)"> に値を取る核を <a href="../../../posts/2024/Probability/Kernel.html"><strong>確率核</strong></a> という．</p>
<p><strong>核（関数）</strong> とは，<img src="https://latex.codecogs.com/png.latex?F"> 上に自然な <img src="https://latex.codecogs.com/png.latex?%5Csigma">-有限測度 <img src="https://latex.codecogs.com/png.latex?%5Cnu%5Cin%5Cmathcal%7BS%7D(F)"> がある際に，次を満たす積分核 <img src="https://latex.codecogs.com/png.latex?k:E%5Ctimes%20F%5Cto%5Cmathbb%7BR%7D"> をいう： <img src="https://latex.codecogs.com/png.latex?%0AK(x,A)=%5Cint_A%20k(x,y)%5C,d%5Cnu(y).%0A"></p>
<p><strong>正定値核</strong> とは，この積分核 <img src="https://latex.codecogs.com/png.latex?k"> であって，さらに半正定値関数でもあるものをいう．</p>
<p>以降，本稿でカーネルと言った場合，積分核となる関数 <img src="https://latex.codecogs.com/png.latex?k:E%5Ctimes%20F%5Cto%5Cmathbb%7BR%7D"> を指す．一般のカーネルについては，<a href="../../../posts/2024/Probability/Kernel.html">確率核の稿</a>を参照．</p>
</div>
</div>
</div>
</section>
<section id="定常カーネル" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="定常カーネル"><span class="header-section-number">1.2</span> 定常カーネル</h2>
<p>距離空間 <img src="https://latex.codecogs.com/png.latex?(T,d)"> 上の Gauss 過程 <img src="https://latex.codecogs.com/png.latex?(X_t)"> が定常的である場合，共分散関数 <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7BC%7D(s,t):=%5Coperatorname%7BE%7D%5Cbiggl%5B(X_s-%5Coperatorname%7BE%7D%5BX_s%5D)(X_t-%5Coperatorname%7BE%7D%5BX_t%5D)%5Cbiggr%5D,%5Cqquad%20s,t%5Cin%20T%0A"> は距離 <img src="https://latex.codecogs.com/png.latex?d(s,t)"> のみの関数になる．</p>
<p>このような半正定値関数 <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BC%7D"> の例を <img src="https://latex.codecogs.com/png.latex?T=%5Cmathbb%7BR%7D%5Ed"> として挙げる．</p>
<section id="poisson-核" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="poisson-核"><span class="header-section-number">1.2.1</span> Poisson 核</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義 (Poisson kernel)">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定義 (Poisson kernel)
</div>
</div>
<div class="callout-body-container callout-body">
<p>（<img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5Ed"> 上の）Poisson 核とは，Cauchy 分布 <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BC%7D(0,%5Cell%5E%7B-1%7D)"> の特性関数 <img src="https://latex.codecogs.com/png.latex?%0AK(x,y;%5Cell)=%5Cexp%5Cleft(-%5Cfrac%7B%5C%7Cx-y%5C%7C_1%7D%7B%5Cell%7D%5Cright)%0A"> をいう．</p>
</div>
</div>
</section>
<section id="sec-Gauss-kernel" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="sec-Gauss-kernel"><span class="header-section-number">1.2.2</span> Gauss 核</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義 (Gaussian Radial Basis Function kernel / Squared Exponential kernel)^[RBF は [@持橋-大羽2019 p.68]，SE は [@Rasmussen-Williams2006 p.14] の用語．[@Murphy2023] では両方が併記されている．Gaussian kernel とも呼ばれる．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定義 (Gaussian Radial Basis Function kernel / Squared Exponential kernel)<sup>2</sup>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Gauss 核（動径基底関数カーネルともいう）とは，Gauss 分布 <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BN%7D(0,%5Cell%5E%7B-2%7D)"> の特性関数 <img src="https://latex.codecogs.com/png.latex?%0AK(x,y;%5Cell):=%5Cexp%5Cleft(-%5Cfrac%7B%5Clvert%20x-y%5Crvert%5E2%7D%7B2%5Cell%5E2%7D%5Cright)%0A"> をいう．<sup>3</sup></p>
</div>
</div>
<p><a href="https://en.wikipedia.org/wiki/Radial_basis_function">Radial Basis Function</a> とは動径 <img src="https://latex.codecogs.com/png.latex?r=%5Clvert%20x%5Crvert"> の関数であることをいう．RBF カーネルと言ったとき特に Gauss 核を指すことが多いが，これは混乱を招く．<span class="citation" data-cites="Murphy2023">(Murphy, 2023)</span> では Squared Exponential kernel の語が使われているが，ここでは Gauss 核と呼ぶ．</p>
</section>
<section id="sec-ARD-kernel" class="level3" data-number="1.2.3">
<h3 data-number="1.2.3" class="anchored" data-anchor-id="sec-ARD-kernel"><span class="header-section-number">1.2.3</span> 関連度自動決定核 (ARD)</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義 (ARD: Autonatic Relevance Determination)^[[@MacKay1994], [@Neal1996 p.16] なども参照．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定義 (ARD: Autonatic Relevance Determination)<sup>4</sup>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Gauss カーネルの Euclid ノルムを Mahalanobis ノルムに変更したもの <img src="https://latex.codecogs.com/png.latex?%0AK(r;%5CSigma,%5Csigma%5E2)=%5Csigma%5E2%5Cexp%5Cleft(-%5Cfrac%7Br%5E%5Ctop%5CSigma%5E%7B-1%7Dr%7D%7B2%7D%5Cright)%0A"> を関連度自動決定カーネルともいう．</p>
</div>
</div>
<p>そもそも関連度自動決定 <span class="citation" data-cites="MacKay1994">(MacKay, 1994)</span>, <span class="citation" data-cites="Neal1996">(Neal, 1996, p. 16)</span> またはスパースベイズ学習 <span class="citation" data-cites="Tipping2001">(Tipping, 2001)</span> とは，ニューラルネットワークの最初のレイヤーの荷重をスパースにするために分散不定の正規分布を事前分布として導入する，という技法である <span class="citation" data-cites="Loeliger+2016">(Loeliger et al., 2016)</span>．</p>
<p>一般に出力をスパースにするためのフレームワークとしても活用され，ARD 核はその最たる例である．</p>
</section>
<section id="matérn-核" class="level3" data-number="1.2.4">
<h3 data-number="1.2.4" class="anchored" data-anchor-id="matérn-核"><span class="header-section-number">1.2.4</span> Matérn 核</h3>
<p>ARD 核は軟化性能を持つため，見本道は無限回微分可能になってしまう．</p>
<p>これが不適な状況下では，<a href="https://en.wikipedia.org/wiki/Mat%C3%A9rn_covariance_function">Matérn 核</a> <img src="https://latex.codecogs.com/png.latex?%0AK(r;%5Cnu,%5Cell)=%5Cfrac%7B2%5E%7B1-%5Cnu%7D%7D%7B%5CGamma(%5Cnu)%7D%5Cleft(%5Cfrac%7B%5Csqrt%7B2%5Cnu%7Dr%7D%7B%5Cell%7D%5Cright)%5E%5Cnu%20K_%5Cnu%5Cleft(%5Cfrac%7B%5Csqrt%7B2%5Cnu%7Dr%7D%7B%5Cell%7D%5Cright)%0A"> などが用いられることがある．ただし，<img src="https://latex.codecogs.com/png.latex?K_%5Cnu"> は修正 Bessel 関数とする．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cnu"> は滑らか度を決定し，見本道は <img src="https://latex.codecogs.com/png.latex?%5Clfloor%5Cnu%5Crfloor"> 階 <img src="https://latex.codecogs.com/png.latex?L%5E2">-微分可能になる．<img src="https://latex.codecogs.com/png.latex?%5Cnu%5Cto%5Cinfty"> の極限で Gauss 核に収束する．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cnu=1/2"> の場合 <img src="https://latex.codecogs.com/png.latex?%0AK(r;1/2,%5Cell)=%5Cexp%5Cleft(-%5Cfrac%7Br%7D%7B%5Cell%7D%5Cright)%0A"> であり，対応する Gauss 過程は <a href="../../../posts/2024/Process/OU1.html">Ornstein-Uhlenbeck 過程</a> である．</p>
</section>
<section id="定常スペクトル核" class="level3" data-number="1.2.5">
<h3 data-number="1.2.5" class="anchored" data-anchor-id="定常スペクトル核"><span class="header-section-number">1.2.5</span> 定常スペクトル核</h3>
<p>任意の（定常な）正定値関数は，ある関数 <img src="https://latex.codecogs.com/png.latex?p"> に関して <span id="eq-spectral-decomposition"><img src="https://latex.codecogs.com/png.latex?%0AK(r)=%5Cint_%7B%5Cmathbb%7BR%7D%5Ed%7Dp(%5Comega)e%5E%7Bi%5Comega%5E%5Ctop%20r%7D%5C,d%5Comega%0A%5Ctag%7B1%7D"></span> と表せる．この <img src="https://latex.codecogs.com/png.latex?p"> は <strong>スペクトル密度</strong> という．</p>
<p><img src="https://latex.codecogs.com/png.latex?K"> が RBF 核であるとき，<img src="https://latex.codecogs.com/png.latex?p"> もそうなる： <img src="https://latex.codecogs.com/png.latex?%0Ap(%5Comega)=%5Csqrt%7B2%5Cpi%5Cell%5E2%7D%5Cexp%5Cbiggr(-2%5Cpi%5E2%5Comega%5E2%5Cell%5E2%5Cbiggl).%0A"></p>
<p>この対応を用いて，スペクトル密度 <img src="https://latex.codecogs.com/png.latex?p"> をデザインすることで，様々な正定値カーネルを得ることが出来る．</p>
<p>例えば spectral mixture kernel <span class="citation" data-cites="Wilson-Adams2013">(Wilson and Adams, 2013)</span> では，スケール母数と位置母数とについて RBF 核の混合を考えることで，新たな正定値カーネルを構成する．</p>
</section>
</section>
<section id="非定常カーネル" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="非定常カーネル"><span class="header-section-number">1.3</span> 非定常カーネル</h2>
<p>環境統計学などにおいて，空間相関の仕方が時間的に変化していくという設定がよくある．</p>
<p>このような場合は，一般の２変数の半正定値カーネル関数を考えることが有用である．</p>
<section id="多項式核" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="多項式核"><span class="header-section-number">1.3.1</span> 多項式核</h3>
<p><img src="https://latex.codecogs.com/png.latex?%0AK(x,y)=(x%5E%5Ctop%20y+c)%5EM%0A"> は非斉次項 <img src="https://latex.codecogs.com/png.latex?c"> を持つ，<img src="https://latex.codecogs.com/png.latex?M"> 次の多項式核と呼ばれる．</p>
</section>
<section id="gibbs-核" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="gibbs-核"><span class="header-section-number">1.3.2</span> Gibbs 核</h3>
<p>Gibbs 核 <span class="citation" data-cites="Gibbs1997">(Gibbs, 1997)</span> は，ハイパーパラメータ <img src="https://latex.codecogs.com/png.latex?%5Csigma,%5Cell"> を入力に依存するようにした RBF 核である： <img src="https://latex.codecogs.com/png.latex?%0AK(x,y)=%5Csigma(x)%5Csigma(y)%5Csqrt%7B%5Cfrac%7B2%5Cell(x)%5Cell(y)%7D%7B%5Cell(x)%5E2+%5Cell(y)%5E2%7D%7D%5Cexp%5Cleft(-%5Cfrac%7B%5Clvert%20x-y%5Crvert%5E2%7D%7B%5Cell(x)%5E2+%5Cell(y)%5E2%7D%5Cright).%0A"></p>
<p>このようにすることで，<img src="https://latex.codecogs.com/png.latex?%5Csigma,%5Cell"> を別の Gauss 過程でモデリングし，階層モデルを考えることもできる <span class="citation" data-cites="Heinonen+2016">(Heinonen et al., 2016)</span>．</p>
</section>
<section id="スペクトル核-remes2017" class="level3" data-number="1.3.3">
<h3 data-number="1.3.3" class="anchored" data-anchor-id="スペクトル核-remes2017"><span class="header-section-number">1.3.3</span> スペクトル核 <span class="citation" data-cites="Remes+2017">(Remes et al., 2017)</span></h3>
<p>正定値核は Fourier 変換を通じて，スペクトル密度によって指定することもできる（Bochner の定理）．</p>
<p>この手法は，非定常核に対しても <span class="citation" data-cites="Remes+2017">(Remes et al., 2017)</span> が拡張している．</p>
</section>
</section>
<section id="位相空間上の核" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="位相空間上の核"><span class="header-section-number">1.4</span> 位相空間上の核</h2>
<p>文章上の string kernel <span class="citation" data-cites="Lodhi+2002">(Lodhi et al., 2002)</span> やグラフ上の graph kernel <span class="citation" data-cites="Kriege+2020">(Kriege et al., 2020)</span> も考えられている．</p>
<section id="乱歩核" class="level3" data-number="1.4.1">
<h3 data-number="1.4.1" class="anchored" data-anchor-id="乱歩核"><span class="header-section-number">1.4.1</span> 乱歩核</h3>
<p><span class="citation" data-cites="Borgwardt+2006">(Borgwardt et al., 2006)</span> は random walk kernel を提案しており，<img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5Ed"> へ埋め込まれるようなものの計算量は <img src="https://latex.codecogs.com/png.latex?O(n%5E3d)"> である．</p>
</section>
</section>
<section id="weisfeiler-lehman-核" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="weisfeiler-lehman-核"><span class="header-section-number">1.5</span> Weisfeiler-Lehman 核</h2>
<p>さらに効率の良いカーネルとして Weisfeiler-Lehman カーネル <span class="citation" data-cites="Shervashidze+2011">(Shervashidze et al., 2011)</span> もある．</p>
</section>
<section id="核の構成" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="核の構成"><span class="header-section-number">1.6</span> 核の構成</h2>
<section id="半正定値核のなす正錐" class="level3" data-number="1.6.1">
<h3 data-number="1.6.1" class="anchored" data-anchor-id="半正定値核のなす正錐"><span class="header-section-number">1.6.1</span> 半正定値核のなす正錐</h3>
<p>半正定値核は <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BMap%7D(T%5E2,%5Cmathbb%7BR%7D)"> 上で閉凸錐をなす．すなわち， <img src="https://latex.codecogs.com/png.latex?%0Ac_1K_1+c_2K_2,%5Cqquad%20c_1,c_2%5Cge0,%0A"> とその各点収束極限は再び半正定値核である．</p>
</section>
<section id="sec-KDE" class="level3" data-number="1.6.2">
<h3 data-number="1.6.2" class="anchored" data-anchor-id="sec-KDE"><span class="header-section-number">1.6.2</span> カーネル密度推定量 (KDE)</h3>
<p>データ <img src="https://latex.codecogs.com/png.latex?%5C%7Bx_n%5C%7D%5Csubset%5Cmathcal%7BX%7D"> と半正定値核 <img src="https://latex.codecogs.com/png.latex?K"> に対して， <img src="https://latex.codecogs.com/png.latex?%0Ap(x%7C%5C%7Bx_n%5C%7D)=%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bn=1%7D%5ENK_%5Cell(x,x_n)%0A"> は再び半正定値核である．これを <strong>Parzen 窓推定量</strong> または <strong>カーネル密度推定量</strong> という．</p>
<p>これはデータの経験分布と確率核 <img src="https://latex.codecogs.com/png.latex?K"> との畳み込みになっている．<img src="https://latex.codecogs.com/png.latex?K"> として Gauss 核を用いると，これはデータ分布の軟化として使え，<a href="../../../posts/2024/Samplers/EBM.html#sec-RSM">デノイジングスコアマッチング</a>などに応用を持つ．</p>
<p>ただし，<img src="https://latex.codecogs.com/png.latex?%5Cell"> は <strong>幅</strong> (bandwidth) とよばれるハイパーパラメータである．例えば <img src="https://latex.codecogs.com/png.latex?K"> が動径 <img src="https://latex.codecogs.com/png.latex?r"> の関数であるとき， <img src="https://latex.codecogs.com/png.latex?%0AK_%5Cell(r):=%5Cfrac%7B1%7D%7B%5Cell%7DK%5Cleft(%5Cfrac%7Br%7D%7B%5Cell%7D%5Cright)%0A"> などと導入できる．</p>
</section>
<section id="カーネル回帰" class="level3" data-number="1.6.3">
<h3 data-number="1.6.3" class="anchored" data-anchor-id="カーネル回帰"><span class="header-section-number">1.6.3</span> カーネル回帰</h3>
<p>データが <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D=%5C%7B(x_i,y_i)%5C%7D_%7Bi=1%7D%5En"> という形で与えられ，平均 <img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7BE%7D%5BY%7CX,%5Cmathcal%7BD%7D%5D"> を推定することを考える．</p>
<p>この際，まず結合密度を次の形で推定する： <img src="https://latex.codecogs.com/png.latex?%0Ap(y,x%7C%5Cmathcal%7BD%7D)=%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi=1%7D%5EnK_%5Cell(x,x_i)K_%5Cell(y,y_i)%0A"> これを用いると，次のように平均が推定できる： <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D%5BY%7CX,%5Cmathcal%7BD%7D%5D=%5Cint_%7B%5Cmathcal%7BY%7D%7D%20yp(y%7CX,%5Cmathcal%7BD%7D)%5C,dy=%5Csum_%7Bi=1%7D%5Eny_iw_i(x),%5Cqquad%20w_i(x):=%5Cfrac%7BK_%5Cell(x,x_i)%7D%7B%5Csum_%7Bj=1%7D%5EnK_%5Cell(x,x_j)%7D.%0A"></p>
<p>この手続きを，<strong>カーネル回帰</strong> / カーネル平滑化，または回帰関数に関する <span class="citation" data-cites="Nadaraya1964">(Nadaraya, 1964)</span>-<span class="citation" data-cites="Watson1964">(Watson, 1964)</span> 推定量という．</p>
</section>
<section id="局所線型回帰-llr" class="level3" data-number="1.6.4">
<h3 data-number="1.6.4" class="anchored" data-anchor-id="局所線型回帰-llr"><span class="header-section-number">1.6.4</span> 局所線型回帰 (LLR)</h3>
<p>カーネル回帰では <img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7BE%7D%5BY%7CX,%5Cmathcal%7BD%7D%5D"> を，<img src="https://latex.codecogs.com/png.latex?%5C%7By_i%5C%7D"> の適切な線型和として予測していた．実は <img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi=1%7D%5Eny_iw_i(x)=%5Cmin_%5Cbeta%5Csum_%7Bi=1%7D%5En(y_i-%5Cbeta)%5E2K_%5Cell(x,x_i)%0A"> の解として特徴付けられる．</p>
<p>代わりに， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmu(x):=%5Cmin_%7B%5Cbeta%7D%5Csum_%7Bi=1%7D%5En%5Cbiggr(y_i-%5Cbeta%5E%5Ctop%5Cphi(x_i)%5Cbiggl)%5E2K_%5Cell(x,x_i)%0A"> によって <img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7BE%7D%5BY%7CX,%5Cmathcal%7BD%7D%5D"> を予測することを，局所線型回帰 (locally linear regression) または <a href="https://en.wikipedia.org/wiki/Local_regression">LOWESS (Locally Weighted Scatterplot Smoothing)</a> <span class="citation" data-cites="Cleveland1979">(Cleveland, 1979)</span>, <span class="citation" data-cites="Cleveland-Devlin1988">(Cleveland and Devlin, 1988)</span>，または <a href="https://en.wikipedia.org/wiki/Savitzky%E2%80%93Golay_filter">Savitsky-Golay フィルター</a> <span class="citation" data-cites="Savitzky-Golay1964">(Savitzky and Golay, 1964)</span> という．</p>
</section>
<section id="半正定値構成" class="level3" data-number="1.6.5">
<h3 data-number="1.6.5" class="anchored" data-anchor-id="半正定値構成"><span class="header-section-number">1.6.5</span> 半正定値構成</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?K:T%5E2%5Cto%5Cmathbb%7BC%7D"> を半正定値，<img src="https://latex.codecogs.com/png.latex?f:%5Cmathcal%7BX%7D%5Cto%5Cmathbb%7BC%7D"> を関数とする． <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidetilde%7BK%7D(x,y):=f(x)K(x,y)%5Coverline%7Bf(y)%7D%0A"> は再び半正定値である．</p>
</div>
</div>
</section>
<section id="核の押し出し" class="level3" data-number="1.6.6">
<h3 data-number="1.6.6" class="anchored" data-anchor-id="核の押し出し"><span class="header-section-number">1.6.6</span> 核の押し出し</h3>
<p><img src="https://latex.codecogs.com/png.latex?S%5E1%5Csimeq%5B0,2%5Cpi)"> 上の確率分布は，方向データとして，海洋学における波の方向，気象学における風向のモデリングに応用を持つ．</p>
<p>全射 <img src="https://latex.codecogs.com/png.latex?%5Cpi:%5Cmathbb%7BR%7D%5Ctwoheadrightarrow%20S%5E1"> に従って，<img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D">-値の Gauss 過程を，方向データ値の Gauss 過程に押し出すことが出来る <span class="citation" data-cites="Jona-Lasinio+2012">(Jona-Lasinio et al., 2012)</span>．</p>
<p>これに伴い，<img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D">-値の核 <img src="https://latex.codecogs.com/png.latex?K:%5Cmathbb%7BR%7D%5Cto%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D)"> を <img src="https://latex.codecogs.com/png.latex?S%5E1">-値に押し出すこともできる： <img src="https://latex.codecogs.com/png.latex?%0A%5Cpi_*K:%5Cmathbb%7BR%7D%5Cto%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D)%5Cxrightarrow%7B%5Cpi_*%7D%5Cmathcal%7BP%7D(S%5E1).%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cpi"> による Gauss 分布の押し出し <img src="https://latex.codecogs.com/png.latex?%5Cpi_*%5Cmathrm%7BN%7D_1(%5Cmu,%5Csigma%5E2)"> は <a href="https://en.wikipedia.org/wiki/Wrapped_normal_distribution">wrapped normal distribution</a> と呼ばれている．これに対応し，この Gauss 過程は wrapped Gaussian process と呼ばれている <span class="citation" data-cites="Jona-Lasinio+2012">(Jona-Lasinio et al., 2012)</span>．</p>
</section>
</section>
<section id="sec-RFF" class="level2" data-number="1.7">
<h2 data-number="1.7" class="anchored" data-anchor-id="sec-RFF"><span class="header-section-number">1.7</span> 核の Monte Carlo 近似</h2>
<section id="カーネルの近似" class="level3" data-number="1.7.1">
<h3 data-number="1.7.1" class="anchored" data-anchor-id="カーネルの近似"><span class="header-section-number">1.7.1</span> カーネルの近似</h3>
<p>以上，種々のカーネル関数を紹介してきたが，これらはデータに関して効率的に計算される必要がある．</p>
<p>特に潜在空間上での Gram 行列の逆行列または Cholesky 分解を計算する <img src="https://latex.codecogs.com/png.latex?O(n%5E3)"> の複雑性が難点である <span class="citation" data-cites="Liu+2020">(Liu et al., 2020)</span>．</p>
<p>このデータ数 <img src="https://latex.codecogs.com/png.latex?n"> に関してスケールしない点が従来カーネル法の難点とされてきたが，これはランダムなカーネル関数を用いた Monte Carlo 近似によって高速化できる．<img src="https://latex.codecogs.com/png.latex?m"> 個のランダムに選択された基底関数を用いれば，Monte Carlo 誤差を許して計算量は <img src="https://latex.codecogs.com/png.latex?O(nm+m%5E3)"> にまで圧縮できる．</p>
</section>
<section id="random-fourier-features" class="level3" data-number="1.7.2">
<h3 data-number="1.7.2" class="anchored" data-anchor-id="random-fourier-features"><span class="header-section-number">1.7.2</span> Random Fourier Features</h3>
<p>正定値核のスペクトル表現 (1) を通じて，核の値 <img src="https://latex.codecogs.com/png.latex?K(x,y)"> を Monte Carlo 近似をすることが出来る．</p>
<p>例えば <img src="https://latex.codecogs.com/png.latex?K"> が RBF 核であるとき，<img src="https://latex.codecogs.com/png.latex?p"> は正規密度になるから，Gauss 確率変数からのサンプリングを通じてこれを実現できる： <img src="https://latex.codecogs.com/png.latex?%0AK(x,y)%5Capprox%5Cphi(x)%5E%5Ctop%5Cphi(y),%5Cqquad%20%5Cphi(x):=%5Csqrt%7B%5Cfrac%7B1%7D%7BD%7D%7D%5Cbegin%7Bpmatrix%7D%5Csin(Z%5E%5Ctop%20x)%5C%5C%5Ccos(Z%5E%5Ctop%20x)%5Cend%7Bpmatrix%7D,Z=(z_%7Bij%7D),z_%7Bij%7D%5Coverset%7B%5Ctext%7Biid%7D%7D%7B%5Csim%7D%5Cmathrm%7BN%7D(0,%5Csigma%5E%7B-2%7D).%0A"></p>
<p>これは核の値 <img src="https://latex.codecogs.com/png.latex?K(x,y)"> を，逆に（ランダムに定まる）特徴ベクトル <img src="https://latex.codecogs.com/png.latex?%5Cphi(x),%5Cphi(y)"> の値を通じて計算しているため，Random Fourier Features <span class="citation" data-cites="Rahimi-Recht2007">(Rahimi and Recht, 2007)</span>, <span class="citation" data-cites="Sutherland-Schneider2015">(Sutherland and Schneider, 2015)</span>，または Random Kitchen Sinks <span class="citation" data-cites="Rahimi-Recht2008">(Rahimi and Recht, 2008)</span> と呼ばれる．</p>
<p><img src="https://latex.codecogs.com/png.latex?Z"> の行を互いに直交するように取ることで，Monte Carlo 推定の精度が上がる．これを orthogonal random features <span class="citation" data-cites="Yu+2016">(Yu et al., 2016)</span> と呼ぶ．</p>
</section>
</section>
</section>
<section id="sec-metric-learning" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> 距離学習</h1>
<section id="はじめに-1" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="はじめに-1"><span class="header-section-number">2.1</span> はじめに</h2>
<p>２つのデータ点 <img src="https://latex.codecogs.com/png.latex?x_1,x_2%5Cin%5Cmathcal%7BX%7D"> に対して，その意味論的な距離 <img src="https://latex.codecogs.com/png.latex?d(x_1,x_2)"> を学習することを考える．</p>
<p>これはある種の表現学習として，分類，クラスタリング，<a href="../../../posts/2024/Kernels/Manifold.html">次元縮約</a> などの事前タスクとしても重要である．顔認識など，computer vision への応用が大きい．</p>
<p>古典的には，<img src="https://latex.codecogs.com/png.latex?K">-近傍分類器と対置させ，これが最大の精度を発揮するような距離を学習することが考えられる</p>
<p>また，ニューラルネットワークにより埋め込み <img src="https://latex.codecogs.com/png.latex?f:%5Cmathcal%7BX%7D%5Chookrightarrow%5Cmathbb%7BR%7D%5Ed"> を構成し，その後 <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5Ed"> 上の Euclid 距離を <img src="https://latex.codecogs.com/png.latex?d"> として用いるとき，これを <strong>深層距離学習</strong> (deep metric learning) という．</p>
<p>深層距離学習では距離学習自体が下流タスクとなっており，その性能が深層埋め込み <img src="https://latex.codecogs.com/png.latex?f"> に依存している．実際，深層距離学習の性能は芳しいと言えないことが知られている <span class="citation" data-cites="Musgrave+2020">(Musgrave et al., 2020)</span>．</p>
</section>
<section id="k-近傍分類" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="k-近傍分類"><span class="header-section-number">2.2</span> <img src="https://latex.codecogs.com/png.latex?K">-近傍分類</h2>
<p>ラベル付きデータ <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D=%5C%7B(x_i,y_i)%5C%7D%5Csubset%5Cmathcal%7BX%7D%5Ctimes%5BC%5D"> が与えられているとする．</p>
<p><img src="https://latex.codecogs.com/png.latex?K">-近傍分類法は，「<img src="https://latex.codecogs.com/png.latex?x"> の近傍上位 <img src="https://latex.codecogs.com/png.latex?K"> 個のデータに訊いてみる」という方法であり，こうして得る事後確率 <img src="https://latex.codecogs.com/png.latex?%0Ap(y=c%7Cx,%5Cmathcal%7BD%7D)=%5Cfrac%7B1%7D%7BK%7D%5Csum_%7Bi%5Cin%5Cmathcal%7BD%7D_K(x)%7D1_%7B%5Cleft%5C%7By_i=c%5Cright%5C%7D%7D%0A"> から <img src="https://latex.codecogs.com/png.latex?x"> のラベルを予測する．</p>
<p>この事後分布をさらにクラスタリングに用いたものが <a href="../../../posts/2024/Computation/VI.html"><img src="https://latex.codecogs.com/png.latex?K">-平均法</a> <span class="citation" data-cites="MacQueen1967">(MacQueen, 1967)</span>, <span class="citation" data-cites="Lloyd1982">(Lloyd, 1982)</span> である</p>
<p><a href="https://ja.wikipedia.org/wiki/K近傍法"><img src="https://latex.codecogs.com/png.latex?K">-近傍法</a>はそのシンプルな発想に拘らず一致性と，良い収束レートを持つ <span class="citation" data-cites="Chaudhuri-DasGupta2014">(Chaudhuri and Dasgupta, 2014)</span>．</p>
<p>一様カーネル <img src="https://latex.codecogs.com/png.latex?%0AK(r;%5Cell):=%5Cfrac%7B1%7D%7B2%5Cell%7D1_%7B%5B0,%5Cell%5D%7D(r)%0A"> が定める密度推定量を，どの</p>
</section>
<section id="mahalanobis-距離の学習" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="mahalanobis-距離の学習"><span class="header-section-number">2.3</span> Mahalanobis 距離の学習</h2>
<p><img src="https://latex.codecogs.com/png.latex?%0Ad(x_1,x_2;M):=%5Csqrt%7B(x_1-x_2)%5E%5Ctop%20M(x_1-x_2)%7D%0A"> というパラメトリックモデルを過程し，<img src="https://latex.codecogs.com/png.latex?M"> を学習することを考える．</p>
<section id="大マージン最近傍-lmnn-weinberger2005" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="大マージン最近傍-lmnn-weinberger2005"><span class="header-section-number">2.3.1</span> 大マージン最近傍 <span class="citation" data-cites="Weinberger+2005">(LMNN, Kilian Q. Weinberger et al., 2005)</span></h3>
<p>Large margin nearest neighbor (LMNN) <span class="citation" data-cites="Weinberger+2005">(Kilian Q. Weinberger et al., 2005)</span>, <span class="citation" data-cites="Weinberger-Saul2009">(Kilian Q. Weinberger and Saul, 2009)</span> は，<img src="https://latex.codecogs.com/png.latex?K">-近傍分類器による後続タスクが最も精度が良くなるように <img src="https://latex.codecogs.com/png.latex?M"> を学習する方法をいう．</p>
<p>各データ番号 <img src="https://latex.codecogs.com/png.latex?i%5Cin%5Bn%5D"> に対して，これと似ているデータ番号の集合 <img src="https://latex.codecogs.com/png.latex?N_i%5Csubset%5Bn%5D"> が与えられているとする（ラベルが同一であるデータ点など）．これに対して，<img src="https://latex.codecogs.com/png.latex?%5Clambda%5Cin(0,1),m%5Cge0"> をハイパーパラメータとして， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D(M):=(1-%5Clambda)%5Cmathcal%7BL%7D%5E-(M)+%5Clambda%5Cmathcal%7BL%7D%5E+(M),%5Cqquad%5Clambda%5Cin(0,1),%0A"> <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D%5E-(M):=%5Csum_%7Bi=1%7D%5En%5Csum_%7Bj%5Cin%20N_i%7Dd(x_i,x_j;M)%5E2,%5Cquad%5Cmathcal%7BL%7D%5E+(M):=%5Csum_%7Bi=1%7D%5En%5Csum_%7Bj%5Cin%20N_i%7D%5Csum_%7Bk=1%7D%5EN%5Cdelta_%7Bik%7D%5Cbiggr(m+d(x_i,x_j;M)%5E2-d(x_i,x_k;M)%5E2%5Cbiggl)%5E2,%0A"> を最小化するように <img src="https://latex.codecogs.com/png.latex?M"> を学習する．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D"> は凸関数であるため，半正定値計画法が適用できる．また，<img src="https://latex.codecogs.com/png.latex?M:=W%5E%5Ctop%20W"> によりパラメータ変換をして，<img src="https://latex.codecogs.com/png.latex?W"> に関して解くことで，問題の凸性を失う代わりに次元数を削減できる．</p>
</section>
<section id="sec-NCA" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="sec-NCA"><span class="header-section-number">2.3.2</span> 近傍成分分析 <span class="citation" data-cites="Goldberger+2004">(NCA, Goldberger et al., 2004)</span></h3>
<p>近傍成分分析 (NCA: Neighborhood Component Analysis) <span class="citation" data-cites="Goldberger+2004">(Goldberger et al., 2004)</span> では <img src="https://latex.codecogs.com/png.latex?W"> を学習する．</p>
<p>類似度行列 <img src="https://latex.codecogs.com/png.latex?W"> に関して，<a href="../../../posts/2024/Kernels/Manifold.html#sec-SNE">確率的近傍埋め込み</a> でも使うモデル <img src="https://latex.codecogs.com/png.latex?%0Ap_%7Bij%7D%5EW:=%5Cfrac%7B%5Cexp%5Cleft(-%5Clvert%20Wx_i-Wx_j%5Crvert%5E2%5Cright)%7D%7B%5Csum_%7Bk%5Cneq%20i%7D%5Cexp%5Cleft(-%5Clvert%20Wx_i-Wx_k%5Crvert%5E2%5Cright)%7D%0A"> を考える．各 <img src="https://latex.codecogs.com/png.latex?i%5Cin%5Bn%5D"> について，<img src="https://latex.codecogs.com/png.latex?x_i"> 以外のデータから <img src="https://latex.codecogs.com/png.latex?x_j"> のラベルを <img src="https://latex.codecogs.com/png.latex?1">-近傍分類器で正しく予測する確率が最大になるように， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D(W):=1-%5Cfrac%7B1%7D%7BN%7DJ(W),%5Cquad%20J(W):=%5Csum_%7Bi=1%7D%5En%5Csum_%7B(i,j)%5Cin%20E%7Dp_%7Bij%7D%5EW%0A"> を最小化するように学習する．ただし，辺の集合 <img src="https://latex.codecogs.com/png.latex?E"> は，ラベルの同じデータを結ぶとした．</p>
</section>
</section>
<section id="sec-deep-metric-learning" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="sec-deep-metric-learning"><span class="header-section-number">2.4</span> 深層距離学習</h2>
<section id="分類に基づく目的関数" class="level3" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="分類に基づく目的関数"><span class="header-section-number">2.4.1</span> 分類に基づく目的関数</h3>
<p>深層距離学習では目的関数の設定が重要である．</p>
<p>最も初等的には，自己符号化器などで分類問題を解き，その内部表現（よく最後から２層目を用いる）での Euclid 距離を距離関数に用いる方法がある．</p>
<p>しかし，距離の情報を学習するために，分類タスクは弱すぎるようである．</p>
</section>
<section id="者比較に基づく目的関数" class="level3" data-number="2.4.2">
<h3 data-number="2.4.2" class="anchored" data-anchor-id="者比較に基づく目的関数"><span class="header-section-number">2.4.2</span> ２者比較に基づく目的関数</h3>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D(%5Ctheta;x_i,x_j):=%5Cdelta_%7By_i,y_j%7Dd(z_i,z_j)%5E2+(1-%5Cdelta_%7By_i,y_j%7D)%5Cbiggr(m-d(z_i,z_j)%5E2%5Cbiggl)_+,%5Cqquad%20z_i=f_%5Ctheta(x_i)%0A"> という損失関数は <strong>対照的損失</strong> (contrastive loss) <span class="citation" data-cites="Chopra+2005">(Chopra et al., 2005)</span> と呼ばれる．</p>
<p>この損失はラベル <img src="https://latex.codecogs.com/png.latex?y_i,y_j"> が同一のデータ <img src="https://latex.codecogs.com/png.latex?x_i,x_j"> の潜在表現の距離を近づけ，ラベルが異なるデータは <img src="https://latex.codecogs.com/png.latex?m"> 以上は話すように埋め込み <img src="https://latex.codecogs.com/png.latex?f_%5Ctheta"> を学習する．</p>
<p>この際に用いるニューラルネットワークは，同時に２つの入力 <img src="https://latex.codecogs.com/png.latex?x_i,x_j"> をとって学習することから，<strong>双子ネットワーク</strong> (Siamese network) とも呼ばれる．</p>
</section>
<section id="sec-triplet-loss" class="level3" data-number="2.4.3">
<h3 data-number="2.4.3" class="anchored" data-anchor-id="sec-triplet-loss"><span class="header-section-number">2.4.3</span> ３者比較に基づく目的関数</h3>
<p>この方法は直ちに三子損失 (triplet loss) <span class="citation" data-cites="Schroff+2015">(Schroff et al., 2015)</span>，<img src="https://latex.codecogs.com/png.latex?n">-ペア損失 (<img src="https://latex.codecogs.com/png.latex?n">-pair loss) <span class="citation" data-cites="Sohn2016">(Sohn, 2016)</span>, <span class="citation" data-cites="Oord+2018">(Oord et al., 2018)</span> に拡張された．</p>
<p>このことにより，<img src="https://latex.codecogs.com/png.latex?x_i,x_j"> の「近さ」のスケールと「遠さ」のスケールが一致し，安定した結果が得られる．</p>
<p>三子損失は，各データ <img src="https://latex.codecogs.com/png.latex?x_i"> に対して，「似ている」ペア <img src="https://latex.codecogs.com/png.latex?x_i%5E+"> と「似ていない」ペア <img src="https://latex.codecogs.com/png.latex?x_i%5E-"> を事前に選び， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D(%5Ctheta;x_i,x_i%5E+,x_i%5E-):=%5Cbiggr(d_%5Ctheta(x_i,x_i%5E+)%5E2-d_%5Ctheta(x_i,x_i%5E-)%5E2+m%5Cbiggl)_+,%5Cqquad%20m%5Cin%5Cmathbb%7BR%7D%0A"> と定められる．このとき，<img src="https://latex.codecogs.com/png.latex?x_i"> は参照点 (anchor) と呼ばれる．</p>
<p>この方法は <img src="https://latex.codecogs.com/png.latex?x_i%5E+,x_i%5E-"> を選ばなければいけないが，その分拡張性に優れる．<a href="../../../posts/2024/Kernels/NCL.html">ノイズ対照学習</a> の稿も参照．</p>
<p><img src="https://latex.codecogs.com/png.latex?n">-ペア損失では，負のデータ <img src="https://latex.codecogs.com/png.latex?x_i%5E-"> をさらに増やす．これは <span class="citation" data-cites="Oord+2019">(Oord et al., 2019 Contrastive Predictive Coding)</span> にて，<a href="../../../posts/2024/Kernels/NCL.html#sec-CPC">InfoMax の観点から表現学習に用いられたもの</a>と一致する．</p>
</section>
<section id="者比較の加速" class="level3" data-number="2.4.4">
<h3 data-number="2.4.4" class="anchored" data-anchor-id="者比較の加速"><span class="header-section-number">2.4.4</span> ３者比較の加速</h3>
<p>負の例 <img src="https://latex.codecogs.com/png.latex?x_i%5E-"> を特に情報量が高いもの <span class="citation" data-cites="Faghri+2018">(hard negatives, Faghri et al., 2018)</span> を選ぶことで，学習を加速させることができる．</p>
<p>これは，３者損失を提案した Google の <a href="https://en.wikipedia.org/wiki/FaceNet">FaceNet</a> <span class="citation" data-cites="Schroff+2015">(Schroff et al., 2015)</span> で考えられた戦略である．</p>
<p>クラスラベルが得られる場合，各クラスから代表的なデータを選んでおくことで <img src="https://latex.codecogs.com/png.latex?O(n)"> にまで加速できる <span class="citation" data-cites="Movshovitz-Attias+2017">(Movshovitz-Attias et al., 2017)</span>．この代表点は固定して１つに定める必要はなく，ソフトな形で選べる <span class="citation" data-cites="Qian+2019">(Qian et al., 2019)</span>．</p>
</section>
</section>
</section>



<div id="quarto-appendix" class="default"><section id="終わりに" class="level1 appendix" data-number="3"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3</span> 終わりに</h2><div class="quarto-appendix-contents">

<p>ここで扱った深層距離学習は，現代的には<a href="../../../posts/2024/Kernels/NCL.html">表現学習</a>として更なる発展を見ている．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Borgwardt+2006" class="csl-entry">
Borgwardt, K., Schraudolph, N., and Vishwanathan, S. v. n. (2006). <a href="https://proceedings.neurips.cc/paper_files/paper/2006/file/e37b08dd3015330dcbb5d6663667b8b8-Paper.pdf">Fast computation of graph kernels</a>. In B. Schölkopf, J. Platt, and T. Hoffman, editors, <em>Advances in neural information processing systems</em>,Vol. 19. MIT Press.
</div>
<div id="ref-Chaudhuri-DasGupta2014" class="csl-entry">
Chaudhuri, K., and Dasgupta, S. (2014). <a href="https://proceedings.neurips.cc/paper_files/paper/2014/file/db957c626a8cd7a27231adfbf51e20eb-Paper.pdf">Rates of convergence for nearest neighbor classification</a>. In Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K. Q. Weinberger, editors, <em>Advances in neural information processing systems</em>,Vol. 27. Curran Associates, Inc.
</div>
<div id="ref-Chopra+2005" class="csl-entry">
Chopra, S., Hadsell, R., and LeCun, Y. (2005). <a href="https://doi.org/10.1109/CVPR.2005.202">Learning a similarity metric discriminatively, with application to face verification</a>. <em>2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05)</em>, <em>1</em>, 539–546.
</div>
<div id="ref-Cleveland1979" class="csl-entry">
Cleveland, W. S. (1979). <a href="https://doi.org/10.1080/01621459.1979.10481038">Robust locally weighted regression and smoothing scatterplots</a>. <em>Journal of the American Statistical Association</em>, <em>74</em>(368), 829–836.
</div>
<div id="ref-Cleveland-Devlin1988" class="csl-entry">
Cleveland, W. S., and Devlin, S. J. (1988). <a href="https://doi.org/10.1080/01621459.1988.10478639">Locally weighted regression: An approach to regression analysis by local fitting</a>. <em>Journal of the American Statistical Association</em>, <em>83</em>(403), 596–610.
</div>
<div id="ref-Faghri+2018" class="csl-entry">
Faghri, F., Fleet, D. J., Kiros, J. R., and Fidler, S. (2018). <a href="https://arxiv.org/abs/1707.05612">VSE++: Improving visual-semantic embeddings with hard negatives</a>.
</div>
<div id="ref-Gibbs1997" class="csl-entry">
Gibbs, M. N. (1997). <em>Bayesian gaussian process regression and classification</em> (PhD thesis). Cambridge University. Retrieved from <a href="https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=b5a0c62c8d7cf51137bfb079947b8393c00ed169">https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=b5a0c62c8d7cf51137bfb079947b8393c00ed169</a>
</div>
<div id="ref-Goldberger+2004" class="csl-entry">
Goldberger, J., Hinton, G. E., Roweis, S., and Salakhutdinov, R. R. (2004). <a href="https://proceedings.neurips.cc/paper_files/paper/2004/file/42fe880812925e520249e808937738d2-Paper.pdf">Neighbourhood components analysis</a>. In L. Saul, Y. Weiss, and L. Bottou, editors, <em>Advances in neural information processing systems</em>,Vol. 17. MIT Press.
</div>
<div id="ref-Heinonen+2016" class="csl-entry">
Heinonen, M., Mannerström, H., Rousu, J., Kaski, S., and Lähdesmäki, H. (2016). <a href="https://proceedings.mlr.press/v51/heinonen16.html">Non-stationary gaussian process regression with hamiltonian monte carlo</a>. In A. Gretton and C. C. Robert, editors, <em>Proceedings of the 19th international conference on artificial intelligence and statistics</em>,Vol. 51, pages 732–740. Cadiz, Spain: PMLR.
</div>
<div id="ref-Jona-Lasinio+2012" class="csl-entry">
Jona-Lasinio, G., Gelfand, A., and Jona-Lasinio, M. (2012). <a href="http://www.jstor.org/stable/41713483">SPATIAL ANALYSIS OF WAVE DIRECTION DATA USING WRAPPED GAUSSIAN PROCESSES</a>. <em>The Annals of Applied Statistics</em>, <em>6</em>(4), 1478–1498.
</div>
<div id="ref-Kriege+2020" class="csl-entry">
Kriege, N. M., Johansson, F. D., and Morris, C. (2020). <a href="https://doi.org/10.1007/s41109-019-0195-3">A survey on graph kernels</a>. <em>Applied Network Science</em>, <em>5</em>(1), 6.
</div>
<div id="ref-Liu+2020" class="csl-entry">
Liu, H., Ong, Y.-S., Shen, X., and Cai, J. (2020). <a href="https://doi.org/10.1109/TNNLS.2019.2957109">When gaussian process meets big data: A review of scalable GPs</a>. <em>IEEE Transactions on Neural Networks and Learning Systems</em>, <em>31</em>(11), 4405–4423.
</div>
<div id="ref-Lloyd1982" class="csl-entry">
Lloyd, S. (1982). <a href="https://ieeexplore.ieee.org/document/1056489">Least squares quantization in PCM</a>. <em>IEEE Transactions on Information Theory</em>, <em>28</em>(2), 129–137.
</div>
<div id="ref-Lodhi+2002" class="csl-entry">
Lodhi, H., Saunders, C., Shawe-Taylor, J., Cristianini, N., and Watkins, C. (2002). <a href="https://www.jmlr.org/papers/v2/lodhi02a.html">Text classification using string kernels</a>. <em>Journal of Machine Learning Research</em>, <em>2</em>, 419–444.
</div>
<div id="ref-Loeliger+2016" class="csl-entry">
Loeliger, H.-A., Bruderer, L., Malmberg, H., Wadehn, F., and Zalmai, N. (2016). <a href="https://doi.org/10.1109/ITA.2016.7888168">On sparsity by NUV-EM, gaussian message passing, and kalman smoothing</a>. In <em>2016 information theory and applications workshop (ITA)</em>, pages 1–10.
</div>
<div id="ref-MacKay1994" class="csl-entry">
MacKay, D. J. C. (1994). <em>Bayesian nonlinear modeling for the prediction competition</em> (No. 2),Vol. 100. American Society of Heating, Refrigerating,; Air Conditioning Engineers (ASHRAE). Retrieved from <a href="https://www.osti.gov/biblio/33309">https://www.osti.gov/biblio/33309</a>
</div>
<div id="ref-MacQueen1967" class="csl-entry">
MacQueen, J. (1967). <a href="https://projecteuclid.org/ebooks/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-Fifth-Berkeley-Symposium-on-Mathematical-Statistics-and/chapter/Some-methods-for-classification-and-analysis-of-multivariate-observations/bsmsp/1200512992">Some methods for classification and analysis of multivariate observations</a>. In <em>Proceedings of the fifth berkeley symposium on mathematical statistics and probability</em>,Vol. 1, pages 281–297.
</div>
<div id="ref-Movshovitz-Attias+2017" class="csl-entry">
Movshovitz-Attias, Y., Toshev, A., Leung, T. K., Ioffe, S., and Singh, S. (2017). <a href="https://doi.org/10.1109/ICCV.2017.47">No fuss distance metric learning using proxies</a>. In <em>2017 IEEE international conference on computer vision (ICCV)</em>, pages 360–368. Los Alamitos, CA, USA: IEEE Computer Society.
</div>
<div id="ref-Murphy2022" class="csl-entry">
Murphy, K. P. (2022). <em><a href="https://probml.github.io/pml-book/book1.html">Probabilistic machine learning: An introduction</a></em>. MIT Press.
</div>
<div id="ref-Murphy2023" class="csl-entry">
Murphy, K. P. (2023). <em><a href="http://probml.github.io/book2">Probabilistic machine learning: Advanced topics</a></em>. MIT Press.
</div>
<div id="ref-Musgrave+2020" class="csl-entry">
Musgrave, K., Belongie, S., and Lim, S.-N. (2020). A metric learning reality check. In A. Vedaldi, H. Bischof, T. Brox, and J.-M. Frahm, editors, <em>Computer vision – ECCV 2020</em>, pages 681–699. Cham: Springer International Publishing.
</div>
<div id="ref-Nadaraya1964" class="csl-entry">
Nadaraya, E. A. (1964). <a href="https://doi.org/10.1137/1109020">On estimating regression</a>. <em>Theory of Probability &amp; Its Applications</em>, <em>9</em>(1), 141–142.
</div>
<div id="ref-Neal1996" class="csl-entry">
Neal, R. M. (1996). <em><a href="https://link.springer.com/book/10.1007/978-1-4612-0745-0">Bayesian learning for neural networks</a></em>,Vol. 118. Springer New York.
</div>
<div id="ref-Oord+2018" class="csl-entry">
Oord, A. van den, Li, Y., Babuschkin, I., Simonyan, K., Vinyals, O., Kavukcuoglu, K., … Hassabis, D. (2018). <a href="https://proceedings.mlr.press/v80/oord18a.html">Parallel <span>W</span>ave<span>N</span>et: Fast high-fidelity speech synthesis</a>. In J. Dy and A. Krause, editors, <em>Proceedings of the 35th international conference on machine learning</em>,Vol. 80, pages 3918–3926. PMLR.
</div>
<div id="ref-Oord+2019" class="csl-entry">
Oord, A. van den, Li, Y., and Vinyals, O. (2019). <a href="https://arxiv.org/abs/1807.03748">Representation learning with contrastive predictive coding</a>.
</div>
<div id="ref-Qian+2019" class="csl-entry">
Qian, Q., Shang, L., Sun, B., Hu, J., Li, H., and Jin, R. (2019). <a href="https://openaccess.thecvf.com/content_ICCV_2019/html/Qian_SoftTriple_Loss_Deep_Metric_Learning_Without_Triplet_Sampling_ICCV_2019_paper.html">SoftTriple loss: Deep metric learning without triplet sampling</a>. In <em>Proceedings of the IEEE/CVF international conference on computer vision (ICCV)</em>.
</div>
<div id="ref-Rahimi-Recht2007" class="csl-entry">
Rahimi, A., and Recht, B. (2007). <a href="https://proceedings.neurips.cc/paper_files/paper/2007/file/013a006f03dbc5392effeb8f18fda755-Paper.pdf">Random features for large-scale kernel machines</a>. In J. Platt, D. Koller, Y. Singer, and S. Roweis, editors, <em>Advances in neural information processing systems</em>,Vol. 20. Curran Associates, Inc.
</div>
<div id="ref-Rahimi-Recht2008" class="csl-entry">
Rahimi, A., and Recht, B. (2008). <a href="https://proceedings.neurips.cc/paper_files/paper/2008/file/0efe32849d230d7f53049ddc4a4b0c60-Paper.pdf">Weighted sums of random kitchen sinks: Replacing minimization with randomization in learning</a>. In D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, <em>Advances in neural information processing systems</em>,Vol. 21. Curran Associates, Inc.
</div>
<div id="ref-Rasmussen-Williams2006" class="csl-entry">
Rasmussen, C. E., and Williams, C. K. I. (2006). <em><a href="https://direct.mit.edu/books/book/2320/Gaussian-Processes-for-Machine-Learning">Gaussian processes for machine learning</a></em>. The MIT Press.
</div>
<div id="ref-Remes+2017" class="csl-entry">
Remes, S., Heinonen, M., and Kaski, S. (2017). <a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/c65d7bd70fe3e5e3a2f3de681edc193d-Paper.pdf">Non-stationary spectral kernels</a>. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, <em>Advances in neural information processing systems</em>,Vol. 30. Curran Associates, Inc.
</div>
<div id="ref-Savitzky-Golay1964" class="csl-entry">
Savitzky, Abraham., and Golay, M. J. E. (1964). <a href="https://doi.org/10.1021/ac60214a047">Smoothing and differentiation of data by simplified least squares procedures.</a> <em>Analytical Chemistry</em>, <em>36</em>(8), 1627–1639. doi: 10.1021/ac60214a047.
</div>
<div id="ref-Schroff+2015" class="csl-entry">
Schroff, F., Kalenichenko, D., and Philbin, J. (2015). <a href="https://openaccess.thecvf.com/content_cvpr_2015/html/Schroff_FaceNet_A_Unified_2015_CVPR_paper.html">FaceNet: A unified embedding for face recognition and clustering</a>. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR)</em>.
</div>
<div id="ref-Shervashidze+2011" class="csl-entry">
Shervashidze, N., Schweitzer, P., Leeuwen, E. J. van, Mehlhorn, K., and Borgwardt, K. M. (2011). <a href="http://jmlr.org/papers/v12/shervashidze11a.html">Weisfeiler-lehman graph kernels</a>. <em>Journal of Machine Learning Research</em>, <em>12</em>(77), 2539–2561.
</div>
<div id="ref-Sohn2016" class="csl-entry">
Sohn, K. (2016). <a href="https://proceedings.neurips.cc/paper_files/paper/2016/file/6b180037abbebea991d8b1232f8a8ca9-Paper.pdf">Improved deep metric learning with multi-class n-pair loss objective</a>. In D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett, editors, <em>Advances in neural information processing systems</em>,Vol. 29. Curran Associates, Inc.
</div>
<div id="ref-Sutherland-Schneider2015" class="csl-entry">
Sutherland, D. J., and Schneider, J. (2015). On the error of random fourier features. In <em>Proceedings of the thirty-first conference on uncertainty in artificial intelligence</em>, pages 862–871. Arlington, Virginia, USA: AUAI Press.
</div>
<div id="ref-Tipping2001" class="csl-entry">
Tipping, M. E. (2001). <a href="https://www.jmlr.org/papers/v1/tipping01a.html">Sparse bayesian learning and the relevance vector machine</a>. <em>Journal of Machine Learning Research</em>, <em>1</em>, 211–244.
</div>
<div id="ref-Watson1964" class="csl-entry">
Watson, G. S. (1964). <a href="http://www.jstor.org/stable/25049340">Smooth regression analysis</a>. <em>Sankhyā: The Indian Journal of Statistics, Series A (1961-2002)</em>, <em>26</em>(4), 359–372.
</div>
<div id="ref-Weinberger+2005" class="csl-entry">
Weinberger, Kilian Q., Blitzer, J., and Saul, L. (2005). <a href="https://proceedings.neurips.cc/paper_files/paper/2005/file/a7f592cef8b130a6967a90617db5681b-Paper.pdf">Distance metric learning for large margin nearest neighbor classification</a>. In Y. Weiss, B. Schölkopf, and J. Platt, editors, <em>Advances in neural information processing systems</em>,Vol. 18. MIT Press.
</div>
<div id="ref-Weinberger-Saul2009" class="csl-entry">
Weinberger, Kilian Q., and Saul, L. K. (2009). <a href="http://jmlr.org/papers/v10/weinberger09a.html">Distance metric learning for large margin nearest neighbor classification</a>. <em>Journal of Machine Learning Research</em>, <em>10</em>(9), 207–244.
</div>
<div id="ref-Wilson-Adams2013" class="csl-entry">
Wilson, A., and Adams, R. (2013). <a href="https://proceedings.mlr.press/v28/wilson13.html">Gaussian process kernels for pattern discovery and extrapolation</a>. In S. Dasgupta and D. McAllester, editors, <em>Proceedings of the 30th international conference on machine learning</em>,Vol. 28, pages 1067–1075. Atlanta, Georgia, USA: PMLR.
</div>
<div id="ref-Yu+2016" class="csl-entry">
Yu, F. X. X., Suresh, A. T., Choromanski, K. M., Holtmann-Rice, D. N., and Kumar, S. (2016). <a href="https://proceedings.neurips.cc/paper_files/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf">Orthogonal random features</a>. In D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett, editors, <em>Advances in neural information processing systems</em>,Vol. 29. Curran Associates, Inc.
</div>
<div id="ref-持橋-大羽2019" class="csl-entry">
持橋大地, and 大羽成征. (2019). <em><a href="https://www.kspub.co.jp/book/detail/1529267.html">ガウス過程と機械学習</a></em>. 講談社.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><span class="citation" data-cites="Murphy2022">(Murphy, 2022, p. 565)</span> 17.1節は，半正定値核のことを Mercer 核とも呼んでいる．↩︎</p></li>
<li id="fn2"><p>RBF は <span class="citation" data-cites="持橋-大羽2019">(持橋大地 and 大羽成征, 2019, p. 68)</span>，SE は <span class="citation" data-cites="Rasmussen-Williams2006">(Rasmussen and Williams, 2006, p. 14)</span> の用語．<span class="citation" data-cites="Murphy2023">(Murphy, 2023)</span> では両方が併記されている．Gaussian kernel とも呼ばれる．↩︎</p></li>
<li id="fn3"><p>他のパラメータの入れ方もある．例えば <a href="https://gpy.readthedocs.io/en/deploy/GPy.kern.src.html#GPy.kern.src.rbf.RBF"><code>GPy</code> での実装</a> は <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2%5Cexp%5Cleft(-%5Cfrac%7Br%5E2%7D%7B2%7D%5Cright)"> を採用している．Fourier 変換や偏微分方程式論の文脈では <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B1%7D%7B(4%5Cpi%20t)%5E%7Bd/2%7D%7D%5Cexp%5Cleft(-%5Cfrac%7Br%5E2%7D%7B4%7D%5Cright)"> も良く用いられる．これは熱方程式の基本解になるためである．↩︎</p></li>
<li id="fn4"><p><span class="citation" data-cites="MacKay1994">(MacKay, 1994)</span>, <span class="citation" data-cites="Neal1996">(Neal, 1996, p. 16)</span> なども参照．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Kernel</category>
  <guid>https://162348.github.io/posts/2024/Kernels/Kernel.html</guid>
  <pubDate>Sat, 10 Aug 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Kernels/Images/Gibbs.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>離散空間上のフローベース模型</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Samplers/DiscreteDiffusion.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<div id="listing-diffusion-listing" class="quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="RGVlcCUyQ1NhbXBsaW5nJTJDUChYKQ==" data-listing-date-sort="1707868800000" data-listing-file-modified-sort="1733137937892" data-listing-date-modified-sort="1724803200000" data-listing-reading-time-sort="4" data-listing-word-count-sort="794">
<a href="../../../posts/2024/Samplers/NF1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Samplers/Files/linear/output.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ニューラル常微分方程式
</h5>
<div class="card-subtitle listing-subtitle">
シミュレーションなしの拡散モデルとしての連続正規化流
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="RGVlcCUyQ1NhbXBsaW5nJTJDUChYKQ==" data-listing-date-sort="1723248000000" data-listing-file-modified-sort="1733137937892" data-listing-date-modified-sort="1728691200000" data-listing-reading-time-sort="4" data-listing-word-count-sort="618">
<a href="../../../posts/2024/Samplers/NF3.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Samplers/Files/RFDiff.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
フローベース模型による条件付き生成
</h5>
<div class="card-subtitle listing-subtitle">
誘導からフローマッチングへ
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-10
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="RGVlcCUyQ1NhbXBsaW5nJTJDUHl0aG9u" data-listing-date-sort="1722556800000" data-listing-file-modified-sort="1733137937708" data-listing-date-modified-sort="1722816000000" data-listing-reading-time-sort="15" data-listing-word-count-sort="2810">
<a href="../../../posts/2024/Samplers/DDPM.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<!-- img(9CEB782EFEE6)[progressive=false, height=150px]:diffusion-listing:posts/2024/Samplers/DDPM.html -->
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
拡散模型の実装
</h5>
<div class="card-subtitle listing-subtitle">
<code>PyTorch</code>によるハンズオン
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-02
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="3" data-categories="RGVlcCUyQ1Byb2Nlc3MlMkNTYW1wbGluZw==" data-listing-date-sort="1707868800000" data-listing-file-modified-sort="1733137937708" data-listing-date-modified-sort="1724371200000" data-listing-reading-time-sort="5" data-listing-word-count-sort="826">
<a href="../../../posts/2024/Samplers/Diffusion.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Samplers/Files/DDPM_outputs.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
拡散模型
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル６
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
<section id="sec-D3PM" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="sec-D3PM"><span class="header-section-number">1</span> 離散雑音除去拡散模型 (D3PM) <span class="citation" data-cites="Austin+2021">(Austin et al., 2021)</span></h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://github.com/cloneofsimo/d3pm/blob/main/contents/best.gif"><img src="https://162348.github.io/posts/2024/Samplers/Files/best.gif" class="img-fluid figure-img" alt="Minimal Implementation of a D3PM by Simo Ryu (Ryu, 2024) (Tap to image to visit his repository)"></a></p>
<figcaption>Minimal Implementation of a D3PM by Simo Ryu <span class="citation" data-cites="Simo2024">(Ryu, 2024)</span> (Tap to image to visit his repository)</figcaption>
</figure>
</div>
<section id="はじめに" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="はじめに"><span class="header-section-number">1.1</span> はじめに</h3>
<p>離散データ上のフローベースのサンプリング法として，Argmax Flows と Multinomial Diffusion が <span class="citation" data-cites="Hoogeboom+2021">(Hoogeboom et al., 2021)</span> により提案された．</p>
<p>D3PM <span class="citation" data-cites="Austin+2021">(Austin et al., 2021)</span> はこの拡張として提案されたものである．</p>
<p>その結果，D3PM は BERT <span class="citation" data-cites="Lewis+2020-BART">(Lewis et al., 2020)</span> などのマスク付き言語モデルと等価になる．</p>
</section>
<section id="ノイズ過程" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="ノイズ過程"><span class="header-section-number">1.2</span> ノイズ過程</h3>
<section id="設計意図" class="level4" data-number="1.2.1">
<h4 data-number="1.2.1" class="anchored" data-anchor-id="設計意図"><span class="header-section-number">1.2.1</span> 設計意図</h4>
<p>効率的な訓練のために，</p>
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?q(x_t%7Cx_0)"> からシミュレーション可能</li>
<li><img src="https://latex.codecogs.com/png.latex?q(x_%7Bt-1%7D%7Cx_t,x_0)"> が評価可能</li>
</ol>
<p>であるとする．これにより， <img src="https://latex.codecogs.com/png.latex?%0AL_%7Bt-1%7D(x_0):=%5Cint_%5Cmathcal%7BX%7D%5Coperatorname%7BKL%7D%5Cbiggr(q(x_%7Bt-1%7D%7Cx_t,x_0),p_%5Ctheta(x_%7Bt-1%7D%7Cx_t)%5Cbiggl)%5C,q(x_t%7Cx_0)%5C,dx_t%0A"><br>
の Monte Carlo 近似が可能になる．</p>
<p><img src="https://latex.codecogs.com/png.latex?p(x_T)=q(x_T%7Cx_0)"> を一様分布など，簡単にシミュレーション可能な分布とする．</p>
</section>
<section id="実装" class="level4" data-number="1.2.2">
<h4 data-number="1.2.2" class="anchored" data-anchor-id="実装"><span class="header-section-number">1.2.2</span> 実装</h4>
<p><img src="https://latex.codecogs.com/png.latex?x_0%5Cin%5Cmathcal%7BX%7D"> は，<img src="https://latex.codecogs.com/png.latex?%5BK%5D">-値の離散ベクトル <img src="https://latex.codecogs.com/png.latex?x_0%5E%7B(i)%7D"> が <img src="https://latex.codecogs.com/png.latex?D"> 個集まったものとする．ただし，<img src="https://latex.codecogs.com/png.latex?x_0%5E%7B(i)%7D"> は one-hot encoding による横ベクトルとする．</p>
<p>すると，ある確率行列 <img src="https://latex.codecogs.com/png.latex?Q_t"> に関して， <img src="https://latex.codecogs.com/png.latex?%0AQ(-%7Cx_%7Bt-1%7D)=x_%7Bt-1%7DQ_t=%5Ccdots=x_0Q_1%5Ccdots%20Q_t%0A"> と表せる．右辺の第 <img src="https://latex.codecogs.com/png.latex?i"> 行は，次 <img src="https://latex.codecogs.com/png.latex?k%5Cin%5BK%5D"> の状態に至る確率を表す確率ベクトルとなっている．</p>
<p>するとこの逆は，ベイズの定理より <img src="https://latex.codecogs.com/png.latex?%0Aq(x_%7Bt-1%7D%7Cx_t,x_0)=%5Cfrac%7Bq(x_t%7Cx_%7Bt-1%7D,x_0)q(x_%7Bt-1%7D%7Cx_0)%7D%7Bq(x_t%7Cx_0)%7D%0A"> <img src="https://latex.codecogs.com/png.latex?%0AQ(-%7Cx_t,x_0)=%0A"></p>
</section>
<section id="核-q-の取り方" class="level4" data-number="1.2.3">
<h4 data-number="1.2.3" class="anchored" data-anchor-id="核-q-の取り方"><span class="header-section-number">1.2.3</span> 核 <img src="https://latex.codecogs.com/png.latex?Q"> の取り方</h4>
<p><img src="https://latex.codecogs.com/png.latex?%0AQ_t:=(1-%5Cbeta_t)I_K+%5Cfrac%7B%5Cbeta_t%7D%7BK%7D%0A"> と取った場合を一様核という．</p>
<p>または，<img src="https://latex.codecogs.com/png.latex?Q_t"> として <strong>脱落核</strong> を取ることもできる．これは１つの点 <img src="https://latex.codecogs.com/png.latex?m%5Cin%5BK%5D"> を吸収点とする方法である： <img src="https://latex.codecogs.com/png.latex?%0A(Q_t)_%7Bij%7D:=%5Cbegin%7Bcases%7D1&amp;i=j=m,%5C%5C%0A1-%5Cbeta_t&amp;i=j%5Cin%5BK%5D%5Csetminus%5C%7Bm%5C%7D%5C%5C%0A%5Cbeta_t&amp;%5Cmathrm%7Botherwise%7D%0A%5Cend%7Bcases%7D%0A"></p>
</section>
</section>
<section id="除去過程" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="除去過程"><span class="header-section-number">1.3</span> 除去過程</h3>
<p><img src="https://latex.codecogs.com/png.latex?p_%5Ctheta(x_%7Bt-1%7D%7Cx_t)"> をモデリングするのではなく，<img src="https://latex.codecogs.com/png.latex?%5Cwidetilde%7Bp%7D_%5Ctheta(x_0%7Cx_t)"> をモデリングし， <img src="https://latex.codecogs.com/png.latex?%0Ap_%5Ctheta(x_%7Bt-1%7D%7Cx_t)%5C,%5Cpropto%5C,%5Csum_%7B%5Cwidetilde%7Bx%7D_0%5Cin%5BK%5D%7Dq(x_%7Bt-1%7D%7Cx_t,%5Cwidetilde%7Bx%7D_0)%5Cwidetilde%7Bp%7D_%5Ctheta(%5Cwidetilde%7Bx%7D_0%7Cx_t)%0A"> は間接的にモデリングする．</p>
<p>これにより，ステップ数を小さく取った場合でも，<img src="https://latex.codecogs.com/png.latex?k"> ステップをまとめて <img src="https://latex.codecogs.com/png.latex?p_%5Ctheta(x_%7Bt-k%7D%7Cx_t)"> をいきなりサンプリングするということも十分に可能になるためである．</p>
</section>
<section id="bert-devlin2019-との対応" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="bert-devlin2019-との対応"><span class="header-section-number">1.4</span> BERT <span class="citation" data-cites="Devlin+2019">(Devlin et al., 2019)</span> との対応</h3>
<p><img src="https://latex.codecogs.com/png.latex?Q_t"> として，一様核と脱落核を重ね合わせたとする．</p>
<p>すなわち，各トークンを各ステップで <img src="https://latex.codecogs.com/png.latex?%5Calpha=10%5C%25"> でマスクし，<img src="https://latex.codecogs.com/png.latex?%5Cbeta=5%5C%25"> で一様にリサンプリングし，これを元に戻す逆過程を学習する．</p>
<p>これは BERT <span class="citation" data-cites="Devlin+2019">(Devlin et al., 2019)</span> と全く同じ目的関数を定める．</p>
<p>MaskGIT (Masked Generative Image Transformer) <span class="citation" data-cites="Chang+2022">(Chang et al., 2022)</span> も，画像をベクトル量子化した後に，全く同様の要領でマスク・リサンプリングをし，これを回復しようとする．これはトランスフォーマーなどの自己回帰的モデルを用いて逐次的に生成するより，サンプリングがはるかに速くなるという．</p>
</section>
</section>


<div id="quarto-appendix" class="default"><section id="参考文献" class="level2 appendix" data-number="2"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">2</span> 参考文献</h2><div class="quarto-appendix-contents">

<p><span class="citation" data-cites="Simo2024">(Ryu, 2024)</span> に素晴らしい教育的リポジトリがある．D3PM の 425 行での PyTorch での実装を提供している．</p>
<p><span class="citation" data-cites="Campbell+2024">(Campbell et al., 2024)</span> は最新の論文の一つである．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Austin+2021" class="csl-entry">
Austin, J., Johnson, D. D., Ho, J., Tarlow, D., and Berg, R. van den. (2021). <a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/958c530554f78bcd8e97125b70e6973d-Paper.pdf">Structured denoising diffusion models in discrete state-spaces</a>. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P. S. Liang, and J. W. Vaughan, editors, <em>Advances in neural information processing systems</em>,Vol. 34, pages 17981–17993. Curran Associates, Inc.
</div>
<div id="ref-Campbell+2024" class="csl-entry">
Campbell, A., Yim, J., Barzilay, R., Rainforth, T., and Jaakkola, T. (2024). <a href="https://arxiv.org/abs/2402.04997">Generative flows on discrete state-spaces: Enabling multimodal flows with applications to protein co-design</a>.
</div>
<div id="ref-Chang+2022" class="csl-entry">
Chang, H., Zhang, H., Jiang, L., Liu, C., and Freeman, W. T. (2022). MaskGIT: Masked generative image transformer. In <em>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR)</em>, pages 11315–11325.
</div>
<div id="ref-Devlin+2019" class="csl-entry">
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2019). <a href="https://aclanthology.org/N19-1423/">BERT: Pre-training of deep bidirectional transformers for language understanding</a>. In <em>Proceedings of the 2019 conference of the north american chapter of the association for computational linguistics: Human language technologies</em>,Vol. 1, pages 4171–4186.
</div>
<div id="ref-Hoogeboom+2021" class="csl-entry">
Hoogeboom, E., Nielsen, D., Jaini, P., Forré, P., and Welling, M. (2021). <a href="https://openreview.net/forum?id=6nbpPqUCIi7">Argmax flows and multinomial diffusion: Learning categorical distributions</a>. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan, editors, <em>Advances in neural information processing systems</em>.
</div>
<div id="ref-Lewis+2020-BART" class="csl-entry">
Lewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., … Zettlemoyer, L. (2020). <a href="https://doi.org/10.18653/v1/2020.acl-main.703"><span>BART</span>: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</a>. In D. Jurafsky, J. Chai, N. Schluter, and J. Tetreault, editors, <em>Proceedings of the 58th annual meeting of the association for computational linguistics</em>, pages 7871–7880. Online: Association for Computational Linguistics.
</div>
<div id="ref-Simo2024" class="csl-entry">
Ryu, S. (2024). <a href="https://github.com/cloneofsimo/d3pm">Minimal implementation of a D3PM (structured denoising diffusion models in discrete state-spaces), in pytorch</a>.
</div>
</div></section></div> ]]></description>
  <category>Deep</category>
  <category>Sampling</category>
  <category>Nature</category>
  <guid>https://162348.github.io/posts/2024/Samplers/DiscreteDiffusion.html</guid>
  <pubDate>Fri, 09 Aug 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Samplers/Files/best.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Neural Network 訓練の加速</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Samplers/DDPM1.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/docs/posts/2024/Samplers/DDPM_files/figure-html/fig-encoding-output-1.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption><a href="../../../posts/2024/Samplers/DDPM.html">前稿：拡散模型の実装――PyTorch によるハンズオン</a></figcaption>
</figure>
</div>
<section id="問題点と改善したいこと" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="問題点と改善したいこと"><span class="header-section-number">1</span> 問題点と改善したいこと</h2>
<p>データセットの読み込みの段階において，次のコードがある：</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">kwargs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'num_workers'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pin_memory'</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'prefetch_factor'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>}</span>
<span id="cb1-2">train_loader <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataLoader(dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_dataset, batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_batch_size, shuffle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs)</span>
<span id="cb1-3">test_loader  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataLoader(dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>test_dataset,  batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>inference_batch_size, shuffle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs)</span></code></pre></div>
<p>これはデータセット（今回は<code>MNIST</code>）を読み込み，iterable 型としての仕様を可能にするためのコードである．</p>
<p>上述の通りのコードだとエポック 18 で <code>RuntimeError: Shared memory manager connection has timed out</code> を得たが，<code>num_workers=0</code> とするとエラーが発生しなかった．</p>
<p>しかし，<code>num_workers=0</code> （デフォルト設定）とすると，デフォルトの単一プロセス処理が実行されるため，並列による高速化の恩恵を受けられない．その結果，１エポック 12 分以上なので，40 時間以上をかける必要が出てきた（寝てる間もディスプレイをオフにするだけでスリープさせず，回し続ける）．</p>
<div class="callout callout-style-simple callout-important no-icon callout-titled" title="今回の目標">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
今回の目標
</div>
</div>
<div class="callout-body-container callout-body">
<p>うまく並列処理をするようなコードに書き直すことで，ローカル環境でも１日以内で実行できるようにしたい．</p>
</div>
</div>
</section>
<section id="dataloader-の引数について" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="dataloader-の引数について"><span class="header-section-number">2</span> <code>DataLoader</code> の引数について</h2>
<p><a href="https://pytorch.org/docs/stable/data.html"><code>DataLoader</code> メソッドのドキュメント</a> を参照すると，</p>
<section id="num_workers" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="num_workers"><span class="header-section-number">2.1</span> <code>num_workers</code></h3>
<p>は正整数に設定されると，その数だけ並列に動く ‘worker’ が起動され，マルチプロセス処理が実行される．</p>
<p>しかし，子プロセスも同等のメモリを占めるため，値が大きすぎるとランタイムエラーが発生する（<a href="https://github.com/pytorch/pytorch/issues/13246#issuecomment-905703662">issue #13246</a> 参照）．</p>
<p>さらに，この際の並列処理は Python の <code>multiprocessing</code> パッケージによるもので，Windows と MacOS では（Unix 系のような <code>fork()</code> ではなく） <code>spawn()</code> が呼ばれる．これは別のインタープリターを開始するため，コードの大部分を <code>if __name__ == "__main__":</code> で囲まない限り，同じコードを何回も実行することとなり，ランタイムエラーが出現することとなる．</p>
</section>
<section id="pin_memeory" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="pin_memeory"><span class="header-section-number">2.2</span> <code>pin_memeory</code></h3>
<p>しかし，CUDA 上のテンソルオブジェクトを並列処理で共有することは非推奨であり，その際は自動メモリ固定 (automatic memory pinning) を行う必要がある．</p>
<p>pinned memory とは page-locked メモリとも呼ばれ，通常の pageable メモリより転送速度が速いという．</p>
<p>さて，paging とはなんだろうか？（一旦後回し）</p>
</section>
<section id="prefetch_factor" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="prefetch_factor"><span class="header-section-number">2.3</span> <code>prefetch_factor</code></h3>
<p>は各 <code>worker</code> が取ってきてストックしておくバッチの数である．</p>
<p>すなわち，<code>num_workers * prefetch_factor</code> だけデータをメモリに読み込んでおくことになる．</p>
</section>
</section>
<section id="高速化法" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="高速化法"><span class="header-section-number">3</span> 高速化法</h2>
<section id="google-colab-の利用" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="google-colab-の利用"><span class="header-section-number">3.1</span> Google Colab の利用</h3>
<p>結局この方法でトレーニングをし，<a href="../../../posts/2024/Samplers/DDPM.html">前稿</a> を完成させたのであった．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/A100.png" class="img-fluid figure-img"></p>
<figcaption>A100（8/6/2024 時点）</figcaption>
</figure>
</div>
<p>A100 が税込 1,494,000 円であったが，これを利用すると１エポック 22 秒で実行できた．</p>
</section>
<section id="torch.nn.dataparallel-の使用" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="torch.nn.dataparallel-の使用"><span class="header-section-number">3.2</span> <code>torch.nn.DataParallel</code> の使用</h3>
<p>自分のローカルマシンは CUDA がないため利用できないが，ある場合は <code>PyTorch</code> のモジュールで並列処理が可能である．<sup>1</sup></p>
</section>
</section>
<section id="mps-で本当に高速になっているのか" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="mps-で本当に高速になっているのか"><span class="header-section-number">4</span> <code>mps</code> で本当に高速になっているのか？</h2>
<p>アップルは <a href="https://developer.apple.com/jp/metal/">Metal</a> という計算 API を提供しており，これが Apple Silicon で利用できる．</p>
<div id="42adf36d" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb2-2">DEVICE <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.device(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mps"</span>)</span>
<span id="cb2-3">train_batch_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span></span>
<span id="cb2-4">epochs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div>
</div>
<p>とし，１エポックにかかる時間を比較する．その他の設定は前節と同様．</p>
<div id="46f74797" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Start training DDPMs..."</span>)</span>
<span id="cb3-2">model.train()</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> time</span>
<span id="cb3-5"></span>
<span id="cb3-6">start_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time()</span>
<span id="cb3-7"></span>
<span id="cb3-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> epoch <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(epochs):</span>
<span id="cb3-9">    noise_prediction_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb3-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> batch_idx, (x, _) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> tqdm(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(train_loader), total<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train_loader)):</span>
<span id="cb3-11">        optimizer.zero_grad()</span>
<span id="cb3-12"></span>
<span id="cb3-13">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.to(DEVICE)</span>
<span id="cb3-14">        </span>
<span id="cb3-15">        noisy_input, epsilon, pred_epsilon <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> diffusion(x)</span>
<span id="cb3-16">        loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> denoising_loss(pred_epsilon, epsilon)</span>
<span id="cb3-17">        </span>
<span id="cb3-18">        noise_prediction_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> loss.item()</span>
<span id="cb3-19">        </span>
<span id="cb3-20">        loss.backward()</span>
<span id="cb3-21">        optimizer.step()</span>
<span id="cb3-22">        </span>
<span id="cb3-23">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\t</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Epoch"</span>, epoch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"complete!"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\t</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Denoising Loss: "</span>, noise_prediction_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> batch_idx)</span>
<span id="cb3-24">    </span>
<span id="cb3-25">total_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> start_time</span>
<span id="cb3-26"></span>
<span id="cb3-27"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Finish!! Total time: "</span>, total_time)</span></code></pre></div>
</div>
<p>12:58 であった．一方で，CPU でも訓練してみる．</p>
<div id="a0cce554" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">DEVICE <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.device(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cpu"</span>)</span>
<span id="cb4-2">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Denoiser(image_resolution<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>img_size,</span>
<span id="cb4-3">                    hidden_dims<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>hidden_dims, </span>
<span id="cb4-4">                    diffusion_time_embedding_dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>timestep_embedding_dim, </span>
<span id="cb4-5">                    n_times<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_timesteps).to(DEVICE)</span>
<span id="cb4-6">diffusion <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Diffusion(model, image_resolution<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>img_size, n_times<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_timesteps, beta_minmax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>beta_minmax, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>DEVICE).to(DEVICE)</span>
<span id="cb4-7"></span>
<span id="cb4-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Start training DDPMs..."</span>)</span>
<span id="cb4-9">model.train()</span>
<span id="cb4-10"></span>
<span id="cb4-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> time</span>
<span id="cb4-12"></span>
<span id="cb4-13">start_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time()</span>
<span id="cb4-14"></span>
<span id="cb4-15"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> epoch <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(epochs):</span>
<span id="cb4-16">    noise_prediction_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb4-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> batch_idx, (x, _) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> tqdm(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(train_loader), total<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train_loader)):</span>
<span id="cb4-18">        optimizer.zero_grad()</span>
<span id="cb4-19"></span>
<span id="cb4-20">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.to(DEVICE)</span>
<span id="cb4-21">        </span>
<span id="cb4-22">        noisy_input, epsilon, pred_epsilon <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> diffusion(x)</span>
<span id="cb4-23">        loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> denoising_loss(pred_epsilon, epsilon)</span>
<span id="cb4-24">        </span>
<span id="cb4-25">        noise_prediction_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> loss.item()</span>
<span id="cb4-26">        </span>
<span id="cb4-27">        loss.backward()</span>
<span id="cb4-28">        optimizer.step()</span>
<span id="cb4-29">        </span>
<span id="cb4-30">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\t</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Epoch"</span>, epoch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"complete!"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\t</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Denoising Loss: "</span>, noise_prediction_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> batch_idx)</span>
<span id="cb4-31">    </span>
<span id="cb4-32">total_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> start_time</span>
<span id="cb4-33"></span>
<span id="cb4-34"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Finish!! Total time: "</span>, total_time)</span></code></pre></div>
</div>
<p>１時間越え！</p>
</section>



<div id="quarto-appendix" class="default"><section id="終わりに" class="level2 appendix" data-number="5"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">5</span> 終わりに</h2><div class="quarto-appendix-contents">

<p>あまりに時間がかかるので，本記事は <code>eval: false</code> としておく．</p>


</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><a href="https://qiita.com/m__k/items/87b3b1da15f35321ecf5">PyTorchでGPUを並列で使えるようにするtorch.nn.DataParallelのメモ</a> などを参照した．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Deep</category>
  <category>Python</category>
  <guid>https://162348.github.io/posts/2024/Samplers/DDPM1.html</guid>
  <pubDate>Tue, 06 Aug 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Samplers/Files/fig-generation3-output-1.png" medium="image" type="image/png" height="142" width="144"/>
</item>
<item>
  <title>正規化流</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Samplers/NF2.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="関連ページ" class="level3 unnumbered unlisted">
<h3 class="unnumbered unlisted anchored" data-anchor-id="関連ページ">関連ページ</h3>
<div id="listing-flow-listing" class="quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="RGVlcCUyQ1NhbXBsaW5n" data-listing-date-sort="1707868800000" data-listing-file-modified-sort="1733137937892" data-listing-date-modified-sort="1724025600000" data-listing-reading-time-sort="3" data-listing-word-count-sort="450">
<a href="../../../posts/2024/Samplers/NF.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_result.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
正規化流
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル４
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="RGVlcCUyQ1NhbXBsaW5nJTJDUChYKQ==" data-listing-date-sort="1707868800000" data-listing-file-modified-sort="1733137937892" data-listing-date-modified-sort="1724803200000" data-listing-reading-time-sort="4" data-listing-word-count-sort="794">
<a href="../../../posts/2024/Samplers/NF1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Samplers/Files/linear/output.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ニューラル常微分方程式
</h5>
<div class="card-subtitle listing-subtitle">
シミュレーションなしの拡散モデルとしての連続正規化流
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="RGVlcCUyQ1Byb2Nlc3MlMkNTYW1wbGluZw==" data-listing-date-sort="1707868800000" data-listing-file-modified-sort="1733137937708" data-listing-date-modified-sort="1724371200000" data-listing-reading-time-sort="5" data-listing-word-count-sort="826">
<a href="../../../posts/2024/Samplers/Diffusion.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://162348.github.io/posts/2024/Samplers/Files/DDPM_outputs.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
拡散模型
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル６
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>
<section id="real-nvp-dinh2017" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="real-nvp-dinh2017"><span class="header-section-number">1</span> Real NVP <span class="citation" data-cites="Dinh+2017">(Dinh et al., 2017)</span></h2>
<div id="a6e8370b" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import required packages</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> tv</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> normflows <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> nf</span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> matplotlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mpl_toolkits.mplot3d <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Axes3D</span>
<span id="cb1-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> matplotlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> cm</span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span></code></pre></div>
</div>
<div id="38109043" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set up model</span></span>
<span id="cb2-2"></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define 2D Gaussian base distribution</span></span>
<span id="cb2-4">base <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nf.distributions.base.DiagGaussian(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb2-5"></span>
<span id="cb2-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define list of flows</span></span>
<span id="cb2-7">num_layers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span></span>
<span id="cb2-8">flows <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb2-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(num_layers):</span>
<span id="cb2-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Neural network with two hidden layers having 64 units each</span></span>
<span id="cb2-11">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Last layer is initialized by zeros making training more stable</span></span>
<span id="cb2-12">    param_map <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nf.nets.MLP([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>], init_zeros<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb2-13">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add flow layer</span></span>
<span id="cb2-14">    flows.append(nf.flows.AffineCouplingBlock(param_map))</span>
<span id="cb2-15">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Swap dimensions</span></span>
<span id="cb2-16">    flows.append(nf.flows.Permute(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, mode<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'swap'</span>))</span>
<span id="cb2-17">    </span>
<span id="cb2-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct flow model</span></span>
<span id="cb2-19">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nf.NormalizingFlow(base, flows)</span>
<span id="cb2-20">device <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.device(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mps"</span>)</span>
<span id="cb2-21">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.to(device)</span></code></pre></div>
</div>
<div id="9430f9d1" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define target distribution</span></span>
<span id="cb3-2">target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nf.distributions.TwoMoons()</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot target distribution</span></span>
<span id="cb3-5">grid_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span></span>
<span id="cb3-6">xx, yy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.meshgrid(torch.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, grid_size), torch.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, grid_size))</span>
<span id="cb3-7">zz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([xx.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), yy.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb3-8">zz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> zz.to(device)</span>
<span id="cb3-9"></span>
<span id="cb3-10">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target.log_prob(zz).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb3-11">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb3-12">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb3-13"></span>
<span id="cb3-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plt.figure(figsize=(15, 15))</span></span>
<span id="cb3-15">plt.pcolormesh(xx, yy, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb3-16">plt.gca().set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb3-17">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/NF2_files/figure-html/cell-4-output-1.png" width="347" height="341" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="22c827ea" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot initial flow distribution</span></span>
<span id="cb4-2">model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="cb4-3">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.log_prob(zz).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb4-4">model.train()</span>
<span id="cb4-5">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb4-6">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb4-7"></span>
<span id="cb4-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plt.figure(figsize=(15, 15))</span></span>
<span id="cb4-9">plt.pcolormesh(xx, yy, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb4-10">plt.gca().set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb4-11">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/NF2_files/figure-html/cell-5-output-1.png" width="347" height="341" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Train model</span></span>
<span id="cb5-2">max_iter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4000</span></span>
<span id="cb5-3">num_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span></span>
<span id="cb5-4">show_iter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span></span>
<span id="cb5-5"></span>
<span id="cb5-6"></span>
<span id="cb5-7">loss_hist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([])</span>
<span id="cb5-8"></span>
<span id="cb5-9">optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.optim.Adam(model.parameters(), lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5e-4</span>, weight_decay<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-5</span>)</span>
<span id="cb5-10"></span>
<span id="cb5-11"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> it <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> tqdm(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(max_iter)<span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#, disable=True</span></span>
<span id="cb5-12">):</span>
<span id="cb5-13">    optimizer.zero_grad()</span>
<span id="cb5-14">    </span>
<span id="cb5-15">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get training samples</span></span>
<span id="cb5-16">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target.sample(num_samples).to(device)</span>
<span id="cb5-17">    </span>
<span id="cb5-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute loss</span></span>
<span id="cb5-19">    loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.forward_kld(x)</span>
<span id="cb5-20">    </span>
<span id="cb5-21">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Do backprop and optimizer step</span></span>
<span id="cb5-22">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span>(torch.isnan(loss) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> torch.isinf(loss)):</span>
<span id="cb5-23">        loss.backward()</span>
<span id="cb5-24">        optimizer.step()</span>
<span id="cb5-25">    </span>
<span id="cb5-26">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Log loss</span></span>
<span id="cb5-27">    loss_hist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.append(loss_hist, loss.to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).data.numpy())</span>
<span id="cb5-28">    </span>
<span id="cb5-29">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot learned distribution</span></span>
<span id="cb5-30">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (it <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> show_iter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb5-31">        model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="cb5-32">        log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.log_prob(zz)</span>
<span id="cb5-33">        model.train()</span>
<span id="cb5-34">        prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob.to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape))</span>
<span id="cb5-35">        prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb5-36"></span>
<span id="cb5-37">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plt.figure(figsize=(15, 15))</span></span>
<span id="cb5-38">        plt.pcolormesh(xx, yy, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb5-39">        plt.gca().set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb5-40">        plt.show()</span>
<span id="cb5-41">np.save(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'loss_history.npy'</span>, loss_hist)</span></code></pre></div>
<div id="e6fc4c0d" class="cell quarto-layout-panel" data-layout-nrow="2" data-execution_count="6" data-layout-ncol="4">

</div>
<div id="9b9296ff" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot loss</span></span>
<span id="cb6-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plt.figure(figsize=(10, 10))</span></span>
<span id="cb6-3">loss_hist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.load(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Files/loss_history.npy'</span>)</span>
<span id="cb6-4">plt.plot(loss_hist, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'loss'</span>)</span>
<span id="cb6-5">plt.legend()</span>
<span id="cb6-6">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/NF2_files/figure-html/cell-7-output-1.png" width="496" height="337" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="ff291ecb" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot target distribution</span></span>
<span id="cb7-2">f, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, sharey<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>))</span>
<span id="cb7-3"></span>
<span id="cb7-4">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target.log_prob(zz).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb7-5">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb7-6">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb7-7"></span>
<span id="cb7-8">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].pcolormesh(xx, yy, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb7-9"></span>
<span id="cb7-10">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb7-11">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_axis_off()</span>
<span id="cb7-12">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Target'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>)</span>
<span id="cb7-13"></span>
<span id="cb7-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot learned distribution</span></span>
<span id="cb7-15">model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="cb7-16">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.log_prob(zz).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb7-17">model.train()</span>
<span id="cb7-18">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb7-19">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb7-20"></span>
<span id="cb7-21">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].pcolormesh(xx, yy, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb7-22"></span>
<span id="cb7-23">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb7-24">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_axis_off()</span>
<span id="cb7-25">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Real NVP'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>)</span>
<span id="cb7-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plt.savefig("./Files/NF2.png")</span></span>
<span id="cb7-27">plt.subplots_adjust(wspace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>)</span>
<span id="cb7-28">plt.show()</span></code></pre></div>
</div>
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF2.png" class="img-fluid"></p>
</section>
<section id="neural-spline-flow-durkan2019" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="neural-spline-flow-durkan2019"><span class="header-section-number">2</span> Neural Spline Flow <span class="citation" data-cites="Durkan+2019">(Durkan et al., 2019)</span></h2>
<p>円周 <img src="https://latex.codecogs.com/png.latex?S%5E1"> 上の確率分布として，wrapped Normal 分布や <a href="https://en.wikipedia.org/wiki/Von_Mises_distribution">von Mises 分布</a>がある．</p>
<p>今回は後者を採用し，<img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E2"> 上で密度モデリングを試みる：</p>
<div id="210fda08" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set up target</span></span>
<span id="cb8-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> GaussianVonMises(nf.distributions.Target):</span>
<span id="cb8-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb8-4">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>().<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(prop_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.tensor(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.pi), </span>
<span id="cb8-5">                         prop_shift<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.tensor(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>np.pi))</span>
<span id="cb8-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.n_dims <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb8-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.99</span></span>
<span id="cb8-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.log_const <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.log(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.pi) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> np.log(np.i0(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb8-9">    </span>
<span id="cb8-10">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> log_prob(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x):</span>
<span id="cb8-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> torch.cos(x[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.log_const</span>
<span id="cb8-12"></span>
<span id="cb8-13">target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GaussianVonMises()</span>
<span id="cb8-14"></span>
<span id="cb8-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot target</span></span>
<span id="cb8-16">grid_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span></span>
<span id="cb8-17">xx, yy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.meshgrid(torch.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>, grid_size), torch.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>np.pi, np.pi, grid_size))</span>
<span id="cb8-18">zz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([xx.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), yy.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb8-19"></span>
<span id="cb8-20">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target.log_prob(zz).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb8-21">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb8-22">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb8-23"></span>
<span id="cb8-24">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>))</span>
<span id="cb8-25">plt.pcolormesh(yy, xx, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb8-26">plt.gca().set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb8-27">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/NF2_files/figure-html/cell-9-output-1.png" width="1164" height="930" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>今回は 12 層の Neural Spline Flow を採用し，２次元の Gaussian 分布に基底として採用する．</p>
<div id="52fe9d7d" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">base <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nf.distributions.UniformGaussian(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], torch.tensor([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.pi]))</span>
<span id="cb9-2"></span>
<span id="cb9-3">K <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span></span>
<span id="cb9-4"></span>
<span id="cb9-5">flow_layers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb9-6"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(K):</span>
<span id="cb9-7">    flow_layers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> [nf.flows.CircularAutoregressiveRationalQuadraticSpline(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span>, [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], num_bins<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>,</span>
<span id="cb9-8">                                                                           tail_bound<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.tensor([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.</span>, np.pi]),</span>
<span id="cb9-9">                                                                           permute_mask<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)]</span>
<span id="cb9-10"></span>
<span id="cb9-11">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nf.NormalizingFlow(base, flow_layers, target)</span>
<span id="cb9-12"></span>
<span id="cb9-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Move model on GPU if available</span></span>
<span id="cb9-14">device <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.device(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mps"</span>)</span>
<span id="cb9-15">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.to(device)</span></code></pre></div>
</div>
<div id="0d638753" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot model</span></span>
<span id="cb10-2">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.log_prob(zz.to(device)).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb10-3">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb10-4">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb10-5"></span>
<span id="cb10-6">plt.figure()</span>
<span id="cb10-7">plt.pcolormesh(yy, xx, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb10-8">plt.gca().set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb10-9">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/NF2_files/figure-html/cell-11-output-1.png" width="420" height="337" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="ff071cc4" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Train model</span></span>
<span id="cb11-2">max_iter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span></span>
<span id="cb11-3">num_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span></span>
<span id="cb11-4">show_iter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2500</span></span>
<span id="cb11-5"></span>
<span id="cb11-6"></span>
<span id="cb11-7">loss_hist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([])</span>
<span id="cb11-8"></span>
<span id="cb11-9">optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.optim.Adam(model.parameters(), lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5e-4</span>)</span>
<span id="cb11-10">scheduler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_iter)</span>
<span id="cb11-11"></span>
<span id="cb11-12"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> it <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> tqdm(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(max_iter)):</span>
<span id="cb11-13">    optimizer.zero_grad()</span>
<span id="cb11-14">    </span>
<span id="cb11-15">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute loss</span></span>
<span id="cb11-16">    loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.reverse_kld(num_samples)</span>
<span id="cb11-17">    </span>
<span id="cb11-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Do backprop and optimizer step</span></span>
<span id="cb11-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span>(torch.isnan(loss) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> torch.isinf(loss)):</span>
<span id="cb11-20">        loss.backward()</span>
<span id="cb11-21">        optimizer.step()</span>
<span id="cb11-22">    </span>
<span id="cb11-23">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Log loss</span></span>
<span id="cb11-24">    loss_hist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.append(loss_hist, loss.to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).data.numpy())</span>
<span id="cb11-25">    </span>
<span id="cb11-26">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot learned model</span></span>
<span id="cb11-27">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (it <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> show_iter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb11-28">        model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="cb11-29">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb11-30">            log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.log_prob(zz.to(device)).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb11-31">        model.train()</span>
<span id="cb11-32">        prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb11-33">        prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb11-34"></span>
<span id="cb11-35">        plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>))</span>
<span id="cb11-36">        plt.pcolormesh(yy, xx, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb11-37">        plt.gca().set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb11-38">        plt.show()</span>
<span id="cb11-39">    </span>
<span id="cb11-40">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Iterate scheduler</span></span>
<span id="cb11-41">    scheduler.step()</span>
<span id="cb11-42"></span>
<span id="cb11-43"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot loss</span></span>
<span id="cb11-44">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>))</span>
<span id="cb11-45">plt.plot(loss_hist, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'loss'</span>)</span>
<span id="cb11-46">plt.legend()</span>
<span id="cb11-47">plt.show()</span></code></pre></div>
</div>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="5">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 20.0%;justify-content: center;">
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_training0.png" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 20.0%;justify-content: center;">
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_training1.png" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 20.0%;justify-content: center;">
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_training2.png" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 20.0%;justify-content: center;">
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_training3.png" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 20.0%;justify-content: center;">
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_training4.png" class="img-fluid"></p>
</div>
</div>
</div>
<p>訓練は L4 で約１時間であった．</p>
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_training_loss.png" class="img-fluid"></p>
<div id="9fafb634" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2D plot</span></span>
<span id="cb12-2">f, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, sharey<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>))</span>
<span id="cb12-3"></span>
<span id="cb12-4">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target.log_prob(zz).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb12-5">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb12-6">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb12-7"></span>
<span id="cb12-8">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].pcolormesh(yy, xx, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb12-9">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb12-10"></span>
<span id="cb12-11">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_xticks(ticks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>np.pi, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>np.pi<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, np.pi<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, np.pi])</span>
<span id="cb12-12">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_xticklabels([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$-\pi$'</span>, <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'$-\frac{\pi}</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{2}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">$'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$0$'</span>, <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'$\frac{\pi}</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{2}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">$'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$\pi$'</span>],</span>
<span id="cb12-13">                      fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span>
<span id="cb12-14">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_yticks(ticks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>])</span>
<span id="cb12-15">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_yticklabels([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$-2$'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$-1$'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$0$'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$1$'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$2$'</span>],</span>
<span id="cb12-16">                      fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span>
<span id="cb12-17">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$\phi$'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>)</span>
<span id="cb12-18">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$x$'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>)</span>
<span id="cb12-19"></span>
<span id="cb12-20">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Target'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>)</span>
<span id="cb12-21"></span>
<span id="cb12-22">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.log_prob(zz.to(device)).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb12-23">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb12-24">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb12-25"></span>
<span id="cb12-26">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].pcolormesh(yy, xx, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb12-27">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb12-28"></span>
<span id="cb12-29">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_xticks(ticks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>np.pi, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>np.pi<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, np.pi<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, np.pi])</span>
<span id="cb12-30">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_xticklabels([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$-\pi$'</span>, <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'$-\frac{\pi}</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{2}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">$'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$0$'</span>, <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'$\frac{\pi}</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{2}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">$'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$\pi$'</span>],</span>
<span id="cb12-31">                      fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span>
<span id="cb12-32">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$\phi$'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>)</span>
<span id="cb12-33"></span>
<span id="cb12-34">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Neural Spline Flow'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>)</span>
<span id="cb12-35"></span>
<span id="cb12-36">plt.subplots_adjust(wspace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>)</span>
<span id="cb12-37"></span>
<span id="cb12-38">plt.show()</span></code></pre></div>
</div>
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_comparison.png" class="img-fluid"></p>
<div id="d66ec8f0" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3D plot</span></span>
<span id="cb13-2">fig <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>))</span>
<span id="cb13-3">ax1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fig.add_subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, projection<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'3d'</span>)</span>
<span id="cb13-4">ax2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fig.add_subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, projection<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'3d'</span>)</span>
<span id="cb13-5"></span>
<span id="cb13-6">phi <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>np.pi, np.pi, grid_size)</span>
<span id="cb13-7">z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>, grid_size)</span>
<span id="cb13-8"></span>
<span id="cb13-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># create the surface</span></span>
<span id="cb13-10">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.outer(np.ones(grid_size), np.cos(phi))</span>
<span id="cb13-11">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.outer(np.ones(grid_size), np.sin(phi))</span>
<span id="cb13-12">z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.outer(z, np.ones(grid_size))</span>
<span id="cb13-13"></span>
<span id="cb13-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Target</span></span>
<span id="cb13-15">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target.log_prob(zz).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb13-16">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb13-17">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb13-18"></span>
<span id="cb13-19">prob_vis <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(prob)</span>
<span id="cb13-20">myheatmap <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prob_vis.data.numpy()</span>
<span id="cb13-21"></span>
<span id="cb13-22">ax1._axis3don <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb13-23">ax1.plot_surface(x, y, z, cstride<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, rstride<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, facecolors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cm.coolwarm(myheatmap), shade<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb13-24"></span>
<span id="cb13-25">ax1.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Target'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.97</span>, pad<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb13-26"></span>
<span id="cb13-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Model</span></span>
<span id="cb13-28">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.log_prob(zz.to(device)).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb13-29">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb13-30">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb13-31"></span>
<span id="cb13-32">prob_vis <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(prob)</span>
<span id="cb13-33">myheatmap <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prob_vis.data.numpy()</span>
<span id="cb13-34"></span>
<span id="cb13-35">ax2._axis3don <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb13-36">ax2.plot_surface(x, y, z, cstride<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, rstride<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, facecolors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cm.coolwarm(myheatmap), shade<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb13-37"></span>
<span id="cb13-38">t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ax2.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Neural Spline Flow'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.97</span>, pad<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb13-39"></span>
<span id="cb13-40">plt.show()</span></code></pre></div>
</div>
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_result.png" class="img-fluid"></p>
</section>
<section id="glow-kingma-dhariwal2018" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="glow-kingma-dhariwal2018"><span class="header-section-number">3</span> Glow <span class="citation" data-cites="Kingma-Dhariwal2018">(Kingma and Dhariwal, 2018)</span></h2>
<p>今回は CIFAR-10 という手描き文字画像データセットを学習し，画像の生成を目指す．</p>
<p>この際には，<span class="citation" data-cites="Dinh+2017">(Dinh et al., 2017)</span> の multiscale architecture を採用し，基底分布も成分ごとにスケールが違う正規分布を用いる．</p>
<div id="807d7273" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set up model</span></span>
<span id="cb14-2"></span>
<span id="cb14-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define flows</span></span>
<span id="cb14-4">L <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span></span>
<span id="cb14-5">K <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span></span>
<span id="cb14-6">torch.manual_seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb14-7"></span>
<span id="cb14-8">input_shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>)</span>
<span id="cb14-9">n_dims <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.prod(input_shape)</span>
<span id="cb14-10">channels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span></span>
<span id="cb14-11">hidden_channels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span></span>
<span id="cb14-12">split_mode <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'channel'</span></span>
<span id="cb14-13">scale <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb14-14">num_classes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span></span>
<span id="cb14-15"></span>
<span id="cb14-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set up flows, distributions and merge operations</span></span>
<span id="cb14-17">q0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb14-18">merges <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb14-19">flows <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb14-20"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(L):</span>
<span id="cb14-21">    flows_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb14-22">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(K):</span>
<span id="cb14-23">        flows_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> [nf.flows.GlowBlock(channels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> (L <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> i), hidden_channels,</span>
<span id="cb14-24">                                     split_mode<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>split_mode, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>scale)]</span>
<span id="cb14-25">    flows_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> [nf.flows.Squeeze()]</span>
<span id="cb14-26">    flows <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> [flows_]</span>
<span id="cb14-27">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb14-28">        merges <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> [nf.flows.Merge()]</span>
<span id="cb14-29">        latent_shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (input_shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> (L <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> i), input_shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> (L <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> i),</span>
<span id="cb14-30">                        input_shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> (L <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> i))</span>
<span id="cb14-31">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb14-32">        latent_shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (input_shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> (L <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), input_shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> L,</span>
<span id="cb14-33">                        input_shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> L)</span>
<span id="cb14-34">    q0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> [nf.distributions.ClassCondDiagGaussian(latent_shape, num_classes)]</span>
<span id="cb14-35"></span>
<span id="cb14-36"></span>
<span id="cb14-37"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct flow model with the multiscale architecture</span></span>
<span id="cb14-38">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nf.MultiscaleFlow(q0, flows, merges)</span>
<span id="cb14-39">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.to(device)</span></code></pre></div>
</div>
<div id="2016fbfd" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare training data</span></span>
<span id="cb15-2">batch_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span></span>
<span id="cb15-3"></span>
<span id="cb15-4">transform <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tv.transforms.Compose([tv.transforms.ToTensor(), nf.utils.Scale(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">255.</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">256.</span>), nf.utils.Jitter(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">256.</span>)])</span>
<span id="cb15-5">train_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tv.datasets.CIFAR10(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'datasets/'</span>, train<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb15-6">                                 download<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transform)</span>
<span id="cb15-7">train_loader <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.utils.data.DataLoader(train_data, batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>batch_size, shuffle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb15-8">                                           drop_last<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb15-9"></span>
<span id="cb15-10">test_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tv.datasets.CIFAR10(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'datasets/'</span>, train<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,</span>
<span id="cb15-11">                                download<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transform)</span>
<span id="cb15-12">test_loader <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.utils.data.DataLoader(test_data, batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>batch_size)</span>
<span id="cb15-13"></span>
<span id="cb15-14">train_iter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">iter</span>(train_loader)</span></code></pre></div>
</div>
<div id="2d9214fd" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Train model</span></span>
<span id="cb16-2">max_iter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20000</span></span>
<span id="cb16-3"></span>
<span id="cb16-4">loss_hist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([])</span>
<span id="cb16-5"></span>
<span id="cb16-6">optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.optim.Adamax(model.parameters(), lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-3</span>, weight_decay<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-5</span>)</span>
<span id="cb16-7"></span>
<span id="cb16-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> tqdm(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(max_iter)):</span>
<span id="cb16-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="cb16-10">        x, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">next</span>(train_iter)</span>
<span id="cb16-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">StopIteration</span>:</span>
<span id="cb16-12">        train_iter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">iter</span>(train_loader)</span>
<span id="cb16-13">        x, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">next</span>(train_iter)</span>
<span id="cb16-14">    optimizer.zero_grad()</span>
<span id="cb16-15">    loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.forward_kld(x.to(device), y.to(device))</span>
<span id="cb16-16"></span>
<span id="cb16-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span>(torch.isnan(loss) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> torch.isinf(loss)):</span>
<span id="cb16-18">        loss.backward()</span>
<span id="cb16-19">        optimizer.step()</span>
<span id="cb16-20"></span>
<span id="cb16-21">    loss_hist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.append(loss_hist, loss.detach().to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).numpy())</span></code></pre></div>
</div>
<div id="4dea18cf" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>))</span>
<span id="cb17-2">plt.plot(loss_hist, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'loss'</span>)</span>
<span id="cb17-3">plt.legend()</span>
<span id="cb17-4">plt.savefig(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'fig1.png'</span>)</span>
<span id="cb17-5">plt.show()</span></code></pre></div>
</div>
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/Glow_training_loss.png" class="img-fluid"></p>
<p>2万イテレーションで1時間10分を要したが，cutting-edge な性能を出すには遥かに大きいモデルを 100 万イテレーションほどする必要があるという．</p>
<div id="69cdf5a8" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Model samples</span></span>
<span id="cb18-2">num_sample <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span></span>
<span id="cb18-3"></span>
<span id="cb18-4"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb18-5">    y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.arange(num_classes).repeat(num_sample).to(device)</span>
<span id="cb18-6">    x, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.sample(y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y)</span>
<span id="cb18-7">    x_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.clamp(x, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb18-8">    plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>))</span>
<span id="cb18-9">    plt.imshow(np.transpose(tv.utils.make_grid(x_, nrow<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>num_classes).cpu().numpy(), (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)))</span>
<span id="cb18-10">    plt.savefig(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'fig2.png'</span>)</span>
<span id="cb18-11">    plt.show()</span></code></pre></div>
</div>
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/Glow_output.png" class="img-fluid"></p>
</section>


<div id="quarto-appendix" class="default"><section id="文献" class="level2 appendix" data-number="4"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">4</span> 文献</h2><div class="quarto-appendix-contents">

<p><a href="https://evjang.com/">Eric Jang 氏</a> による <a href="https://github.com/ericjang/normalizing-flows-tutorial">チュートリアル</a> （や<a href="https://github.com/pierresegonne/VINF">その他のチュートリアル</a>）は，TensorFlow 1 を用いており，特に <code>tfb.Affine</code> はもうサポートされていない（<a href="https://github.com/tensorflow/probability/issues/448#issuecomment-555629330">対応表</a>）．</p>
<p><a href="https://github.com/VincentStimper/normalizing-flows?tab=readme-ov-file"><code>normflows</code> というパッケージ</a> <span class="citation" data-cites="Stimper+2023">(Stimper et al., 2023)</span> は PyTorch ベースの実装を提供しており，これを代わりに用いた．<a href="https://colab.research.google.com/github/VincentStimper/normalizing-flows/blob/master/examples/real_nvp_colab.ipynb">Real NVP</a>, <a href="https://colab.research.google.com/github/VincentStimper/normalizing-flows/blob/master/examples/paper_example_nsf_colab.ipynb">Neural Spline Flow</a>, <a href="https://colab.research.google.com/github/VincentStimper/normalizing-flows/blob/master/examples/glow_colab.ipynb">Glow</a> などのデモを公開している．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Dinh+2017" class="csl-entry">
Dinh, L., Sohl-Dickstein, J., and Bengio, S. (2017). <a href="https://openreview.net/forum?id=HkpbnH9lx">Density estimation using real <span>NVP</span></a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Durkan+2019" class="csl-entry">
Durkan, C., Bekasov, A., Murray, I., and Papamakarios, G. (2019). <a href="https://proceedings.neurips.cc/paper_files/paper/2019/file/7ac71d433f282034e088473244df8c02-Paper.pdf">Neural spline flows</a>. In H. Wallach, H. Larochelle, A. Beygelzimer, F. dAlché-Buc, E. Fox, and R. Garnett, editors, <em>Advances in neural information processing systems</em>,Vol. 32. Curran Associates, Inc.
</div>
<div id="ref-Kingma-Dhariwal2018" class="csl-entry">
Kingma, D. P., and Dhariwal, P. (2018). <a href="https://proceedings.neurips.cc/paper_files/paper/2018/file/d139db6a236200b21cc7f752979132d0-Paper.pdf">Glow: Generative flow with invertible 1x1 convolutions</a>. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, <em>Advances in neural information processing systems</em>,Vol. 31. Curran Associates, Inc.
</div>
<div id="ref-Stimper+2023" class="csl-entry">
Stimper, V., Liu, D., Campbell, A., Berenz, V., Ryll, L., Schölkopf, B., and Hernández-Lobato, J. M. (2023). <a href="https://doi.org/10.21105/joss.05361">Normflows: A PyTorch package for normalizing flows</a>. <em>Journal of Open Source Software</em>, <em>8</em>(86), 5361.
</div>
</div></section></div> ]]></description>
  <category>Deep</category>
  <category>Sampling</category>
  <category>Python</category>
  <guid>https://162348.github.io/posts/2024/Samplers/NF2.html</guid>
  <pubDate>Sat, 03 Aug 2024 00:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Samplers/Files/NF/Glow_output.png" medium="image" type="image/png" height="143" width="144"/>
</item>
</channel>
</rss>
