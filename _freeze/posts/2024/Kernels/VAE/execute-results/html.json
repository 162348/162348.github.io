{
  "hash": "3e908c54ffd3fdc9c3479aa6ebdb299a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"VAE：変分自己符号化器\"\nsubtitle: \"PyTorch によるハンズオン\"\nauthor: \"司馬博文\"\ndate: 7/28/2024\ncategories: [Deep, Sampling, Python]\nbibliography: \n    - ../../../mathematics.bib\n    - ../../../bib.bib\ncsl: ../../../apalike.csl\nabstract-title: 概要\nabstract: |\n    変分自己符号化器 (VAE) は，データを周辺分布にもつ潜在変数モデルを変分 Bayes 推論によって学習するアルゴリズムである．\n    従来計算・近似が困難であった変分下界を，ニューラルネットワークによって近似するアプローチである．\n    学習されたベイズ潜在変数モデルからはサンプリングによって新たなデータを生成することができるため，深層生成モデルの一つに分類されることもある．\ncode-fold: false\n---\n\n::: {.hidden}\n\n::: {.content-visible when-format=\"html\"}\n\nA Blog Entry on Bayesian Computation by an Applied Mathematician\n\n$$\n\n\\renewcommand{\\P}{\\operatorname{P}}\\newcommand{\\E}{\\operatorname{E}}\n\\newcommand{\\R}{\\mathbb{R}}\\newcommand{\\F}{\\mathcal{F}}\n\\newcommand{\\abs}[1]{\\lvert#1\\rvert}\\newcommand{\\Abs}[1]{\\left|#1\\right|}\\newcommand{\\ABs}[1]{\\biggl|#1\\biggr|}\\newcommand{\\norm}[1]{\\|#1\\|}\\newcommand{\\Norm}[1]{\\left\\|#1\\right\\|}\\newcommand{\\NOrm}[1]{\\biggl\\|#1\\biggr\\|}\\newcommand{\\Brace}[1]{\\left\\{#1\\right\\}}\\newcommand{\\BRace}[1]{\\biggl\\{#1\\biggr\\}}\\newcommand{\\paren}[1]{\\left(#1\\right)}\\newcommand{\\Paren}[1]{\\biggr(#1\\biggl)}\\newcommand{\\brac}[1]{\\langle#1\\rangle}\\newcommand{\\Brac}[1]{\\left\\langle#1\\right\\rangle}\\newcommand{\\BRac}[1]{\\biggl\\langle#1\\biggr\\rangle}\\newcommand{\\bra}[1]{\\left\\langle#1\\right|}\\newcommand{\\ket}[1]{\\left|#1\\right\\rangle}\\newcommand{\\Square}[1]{\\left[#1\\right]}\\newcommand{\\SQuare}[1]{\\biggl[#1\\biggr]}\\newcommand{\\rN}{\\mathrm{N}}\\newcommand{\\ov}[1]{\\overline{#1}}\\newcommand{\\un}[1]{\\underline{#1}}\\newcommand{\\wt}[1]{\\widetilde{#1}}\\newcommand{\\wh}[1]{\\widehat{#1}}\\newcommand{\\pp}[2]{\\frac{\\partial #1}{\\partial #2}}\\newcommand{\\ppp}[3]{\\frac{\\partial #1}{\\partial #2\\partial #3}}\\newcommand{\\dd}[2]{\\frac{d #1}{d #2}}\\newcommand{\\floor}[1]{\\lfloor#1\\rfloor}\\newcommand{\\Floor}[1]{\\left\\lfloor#1\\right\\rfloor}\\newcommand{\\ceil}[1]{\\lceil#1\\rceil}\\newcommand{\\ocinterval}[1]{(#1]}\\newcommand{\\cointerval}[1]{[#1)}\\newcommand{\\COinterval}[1]{\\left[#1\\right)}\\newcommand{\\iso}{\\overset{\\sim}{\\to}}\n\n\n\n\\newcommand{\\y}{\\b{y}}\\newcommand{\\mi}{\\,|\\,}\\newcommand{\\Mark}{\\mathrm{Mark}}\n\\newcommand{\\argmax}{\\operatorname*{argmax}}\\newcommand{\\argmin}{\\operatorname*{argmin}}\n\n\\newcommand{\\pr}{\\mathrm{pr}}\n\\newcommand{\\Map}{\\mathrm{Map}}\\newcommand{\\dom}{\\mathrm{Dom}\\;}\\newcommand{\\cod}{\\mathrm{Cod}\\;}\\newcommand{\\supp}{\\mathrm{supp}\\;}\n\\newcommand{\\grad}{\\operatorname{grad}}\\newcommand{\\rot}{\\operatorname{rot}}\\renewcommand{\\div}{\\operatorname{div}}\\newcommand{\\tr}{\\operatorname{tr}}\\newcommand{\\Tr}{\\operatorname{Tr}}\\newcommand{\\KL}{\\operatorname{KL}}\\newcommand{\\JS}{\\operatorname{JS}}\\newcommand{\\ESS}{\\operatorname{ESS}}\\newcommand{\\MSE}{\\operatorname{MSE}}\\newcommand{\\erf}{\\operatorname{erf}}\\newcommand{\\arctanh}{\\operatorname{arctanh}}\\newcommand{\\pl}{\\operatorname{pl}}\\newcommand{\\minimize}{\\operatorname{minimize}}\\newcommand{\\subjectto}{\\operatorname{subject to}}\\newcommand{\\sinc}{\\operatorname{sinc}}\\newcommand{\\Ent}{\\operatorname{Ent}}\\newcommand{\\Polya}{\\operatorname{Polya}}\\newcommand{\\Exp}{\\operatorname{Exp}}\\newcommand{\\codim}{\\operatorname{codim}}\\newcommand{\\sgn}{\\operatorname{sgn}}\\newcommand{\\rank}{\\operatorname{rank}}\n\n\\newcommand{\\vctr}[2]{\\begin{pmatrix}#1\\\\#2\\end{pmatrix}}\\newcommand{\\vctrr}[3]{\\begin{pmatrix}#1\\\\#2\\\\#3\\end{pmatrix}}\\newcommand{\\mtrx}[4]{\\begin{pmatrix}#1&#2\\\\#3&#4\\end{pmatrix}}\\newcommand{\\smtrx}[4]{\\paren{\\begin{smallmatrix}#1&#2\\\\#3&#4\\end{smallmatrix}}}\\newcommand{\\Ker}{\\mathrm{Ker}\\;}\\newcommand{\\Coker}{\\mathrm{Coker}\\;}\\newcommand{\\Coim}{\\mathrm{Coim}\\;}\\newcommand{\\lcm}{\\mathrm{lcm}}\\newcommand{\\GL}{\\mathrm{GL}}\\newcommand{\\SL}{\\mathrm{SL}}\\newcommand{\\alt}{\\mathrm{alt}}\n\n\\renewcommand{\\Re}{\\mathrm{Re}\\;}\\renewcommand{\\Im}{\\mathrm{Im}\\,}\\newcommand{\\Gal}{\\mathrm{Gal}}\\newcommand{\\PGL}{\\mathrm{PGL}}\\newcommand{\\PSL}{\\mathrm{PSL}}\\newcommand{\\Log}{\\mathrm{Log}\\,}\\newcommand{\\Res}{\\mathrm{Res}\\,}\\newcommand{\\on}{\\mathrm{on}\\;}\\newcommand{\\hatC}{\\widehat{\\C}}\\newcommand{\\hatR}{\\hat{\\R}}\\newcommand{\\PV}{\\mathrm{P.V.}}\\newcommand{\\diam}{\\mathrm{diam}}\\newcommand{\\Area}{\\mathrm{Area}}\\newcommand{\\Lap}{\\Laplace}\\newcommand{\\f}{\\mathbf{f}}\\newcommand{\\cR}{\\mathcal{R}}\\newcommand{\\const}{\\mathrm{const.}}\\newcommand{\\Om}{\\Omega}\\newcommand{\\Cinf}{C^\\infty}\\newcommand{\\ep}{\\epsilon}\\newcommand{\\dist}{\\mathrm{dist}}\\newcommand{\\opart}{\\o{\\partial}}\\newcommand{\\Length}{\\mathrm{Length}}\n\n\\newcommand{\\cA}{\\mathcal{A}}\\newcommand{\\cO}{\\mathcal{O}}\\newcommand{\\cW}{\\mathcal{W}}\\renewcommand{\\O}{\\mathcal{O}}\\renewcommand{\\S}{\\mathcal{S}}\\newcommand{\\U}{\\mathcal{U}}\\newcommand{\\V}{\\mathrm{V}}\\newcommand{\\N}{\\mathbb{N}}\\newcommand{\\bN}{\\mathbb{N}}\\newcommand{\\C}{\\mathrm{C}}\\newcommand{\\bC}{\\mathbb{C}}\\newcommand{\\Z}{\\mathcal{Z}}\\newcommand{\\Q}{\\mathbb{Q}}\\newcommand{\\bQ}{\\mathbb{Q}}\\newcommand{\\TV}{\\mathrm{TV}}\\newcommand{\\ORD}{\\mathrm{ORD}}\\newcommand{\\Card}{\\mathrm{Card}\\,}\\newcommand{\\Top}{\\mathrm{Top}}\\newcommand{\\Disc}{\\mathrm{Disc}}\\newcommand{\\Codisc}{\\mathrm{Codisc}}\\newcommand{\\CoDisc}{\\mathrm{CoDisc}}\\newcommand{\\Ult}{\\mathrm{Ult}}\\newcommand{\\ord}{\\mathrm{ord}}\\newcommand{\\bS}{\\mathbb{S}}\\newcommand{\\PConn}{\\mathrm{PConn}}\\newcommand{\\mult}{\\mathrm{mult}}\\newcommand{\\inv}{\\mathrm{inv}}\n\n\\newcommand{\\Der}{\\mathrm{Der}}\\newcommand{\\osub}{\\overset{\\mathrm{open}}{\\subset}}\\newcommand{\\osup}{\\overset{\\mathrm{open}}{\\supset}}\\newcommand{\\al}{\\alpha}\\newcommand{\\K}{\\mathbb{K}}\\newcommand{\\Sp}{\\mathrm{Sp}}\\newcommand{\\g}{\\mathfrak{g}}\\newcommand{\\h}{\\mathfrak{h}}\\newcommand{\\Imm}{\\mathrm{Imm}}\\newcommand{\\Imb}{\\mathrm{Imb}}\\newcommand{\\Gr}{\\mathrm{Gr}}\n\n\\newcommand{\\Ad}{\\mathrm{Ad}}\\newcommand{\\finsupp}{\\mathrm{fin\\;supp}}\\newcommand{\\SO}{\\mathrm{SO}}\\newcommand{\\SU}{\\mathrm{SU}}\\newcommand{\\acts}{\\curvearrowright}\\newcommand{\\mono}{\\hookrightarrow}\\newcommand{\\epi}{\\twoheadrightarrow}\\newcommand{\\Stab}{\\mathrm{Stab}}\\newcommand{\\nor}{\\mathrm{nor}}\\newcommand{\\T}{\\mathbb{T}}\\newcommand{\\Aff}{\\mathrm{Aff}}\\newcommand{\\rsup}{\\triangleright}\\newcommand{\\subgrp}{\\overset{\\mathrm{subgrp}}{\\subset}}\\newcommand{\\Ext}{\\mathrm{Ext}}\\newcommand{\\sbs}{\\subset}\\newcommand{\\sps}{\\supset}\\newcommand{\\In}{\\mathrm{in}\\;}\\newcommand{\\Tor}{\\mathrm{Tor}}\\newcommand{\\p}{\\b{p}}\\newcommand{\\q}{\\mathfrak{q}}\\newcommand{\\m}{\\mathfrak{m}}\\newcommand{\\cS}{\\mathcal{S}}\\newcommand{\\Frac}{\\mathrm{Frac}\\,}\\newcommand{\\Spec}{\\mathrm{Spec}\\,}\\newcommand{\\bA}{\\mathbb{A}}\\newcommand{\\Sym}{\\mathrm{Sym}}\\newcommand{\\Ann}{\\mathrm{Ann}}\\newcommand{\\Her}{\\mathrm{Her}}\\newcommand{\\Bil}{\\mathrm{Bil}}\\newcommand{\\Ses}{\\mathrm{Ses}}\\newcommand{\\FVS}{\\mathrm{FVS}}\n\n\\newcommand{\\Ho}{\\mathrm{Ho}}\\newcommand{\\CW}{\\mathrm{CW}}\\newcommand{\\lc}{\\mathrm{lc}}\\newcommand{\\cg}{\\mathrm{cg}}\\newcommand{\\Fib}{\\mathrm{Fib}}\\newcommand{\\Cyl}{\\mathrm{Cyl}}\\newcommand{\\Ch}{\\mathrm{Ch}}\n\\newcommand{\\rP}{\\mathrm{P}}\\newcommand{\\rE}{\\mathrm{E}}\\newcommand{\\e}{\\b{e}}\\renewcommand{\\k}{\\b{k}}\\newcommand{\\Christ}[2]{\\begin{Bmatrix}#1\\\\#2\\end{Bmatrix}}\\renewcommand{\\Vec}[1]{\\overrightarrow{\\mathrm{#1}}}\\newcommand{\\hen}[1]{\\mathrm{#1}}\\renewcommand{\\b}[1]{\\boldsymbol{#1}}\n\n\\newcommand{\\Inc}{\\mathrm{Inc}}\\newcommand{\\aInc}{\\mathrm{aInc}}\\newcommand{\\HS}{\\mathrm{HS}}\\newcommand{\\loc}{\\mathrm{loc}}\\newcommand{\\Lh}{\\mathrm{L.h.}}\\newcommand{\\Epi}{\\mathrm{Epi}}\\newcommand{\\slim}{\\mathrm{slim}}\\newcommand{\\Ban}{\\mathrm{Ban}}\\newcommand{\\Hilb}{\\mathrm{Hilb}}\\newcommand{\\Ex}{\\mathrm{Ex}}\\newcommand{\\Co}{\\mathrm{Co}}\\newcommand{\\sa}{\\mathrm{sa}}\\newcommand{\\nnorm}[1]{{\\left\\vert\\kern-0.25ex\\left\\vert\\kern-0.25ex\\left\\vert #1 \\right\\vert\\kern-0.25ex\\right\\vert\\kern-0.25ex\\right\\vert}}\\newcommand{\\dvol}{\\mathrm{dvol}}\\newcommand{\\Sconv}{\\mathrm{Sconv}}\\newcommand{\\I}{\\mathcal{I}}\\newcommand{\\nonunital}{\\mathrm{nu}}\\newcommand{\\cpt}{\\mathrm{cpt}}\\newcommand{\\lcpt}{\\mathrm{lcpt}}\\newcommand{\\com}{\\mathrm{com}}\\newcommand{\\Haus}{\\mathrm{Haus}}\\newcommand{\\proper}{\\mathrm{proper}}\\newcommand{\\infinity}{\\mathrm{inf}}\\newcommand{\\TVS}{\\mathrm{TVS}}\\newcommand{\\ess}{\\mathrm{ess}}\\newcommand{\\ext}{\\mathrm{ext}}\\newcommand{\\Index}{\\mathrm{Index}\\;}\\newcommand{\\SSR}{\\mathrm{SSR}}\\newcommand{\\vs}{\\mathrm{vs.}}\\newcommand{\\fM}{\\mathfrak{M}}\\newcommand{\\EDM}{\\mathrm{EDM}}\\newcommand{\\Tw}{\\mathrm{Tw}}\\newcommand{\\fC}{\\mathfrak{C}}\\newcommand{\\bn}{\\boldsymbol{n}}\\newcommand{\\br}{\\boldsymbol{r}}\\newcommand{\\Lam}{\\Lambda}\\newcommand{\\lam}{\\lambda}\\newcommand{\\one}{\\mathbf{1}}\\newcommand{\\dae}{\\text{-a.e.}}\\newcommand{\\das}{\\text{-a.s.}}\\newcommand{\\td}{\\text{-}}\\newcommand{\\RM}{\\mathrm{RM}}\\newcommand{\\BV}{\\mathrm{BV}}\\newcommand{\\normal}{\\mathrm{normal}}\\newcommand{\\lub}{\\mathrm{lub}\\;}\\newcommand{\\Graph}{\\mathrm{Graph}}\\newcommand{\\Ascent}{\\mathrm{Ascent}}\\newcommand{\\Descent}{\\mathrm{Descent}}\\newcommand{\\BIL}{\\mathrm{BIL}}\\newcommand{\\fL}{\\mathfrak{L}}\\newcommand{\\De}{\\Delta}\n\n\\newcommand{\\calA}{\\mathcal{A}}\\newcommand{\\calB}{\\mathcal{B}}\\newcommand{\\D}{\\mathcal{D}}\\newcommand{\\Y}{\\mathcal{Y}}\\newcommand{\\calC}{\\mathcal{C}}\\renewcommand{\\ae}{\\mathrm{a.e.}\\;}\\newcommand{\\cZ}{\\mathcal{Z}}\\newcommand{\\fF}{\\mathfrak{F}}\\newcommand{\\fI}{\\mathfrak{I}}\\newcommand{\\rV}{\\mathrm{V}}\\newcommand{\\cE}{\\mathcal{E}}\\newcommand{\\sMap}{\\sigma\\textrm{-}\\mathrm{Map}}\\newcommand{\\cC}{\\mathcal{C}}\\newcommand{\\comp}{\\complement}\\newcommand{\\J}{\\mathcal{J}}\\newcommand{\\sumN}[1]{\\sum_{#1\\in\\N}}\\newcommand{\\cupN}[1]{\\cup_{#1\\in\\N}}\\newcommand{\\capN}[1]{\\cap_{#1\\in\\N}}\\newcommand{\\Sum}[1]{\\sum_{#1=1}^\\infty}\\newcommand{\\sumn}{\\sum_{n=1}^\\infty}\\newcommand{\\summ}{\\sum_{m=1}^\\infty}\\newcommand{\\sumk}{\\sum_{k=1}^\\infty}\\newcommand{\\sumi}{\\sum_{i=1}^\\infty}\\newcommand{\\sumj}{\\sum_{j=1}^\\infty}\\newcommand{\\cupn}{\\cup_{n=1}^\\infty}\\newcommand{\\capn}{\\cap_{n=1}^\\infty}\\newcommand{\\cupk}{\\cup_{k=1}^\\infty}\\newcommand{\\cupi}{\\cup_{i=1}^\\infty}\\newcommand{\\cupj}{\\cup_{j=1}^\\infty}\\newcommand{\\limn}{\\lim_{n\\to\\infty}}\\renewcommand{\\L}{\\mathcal{L}}\\newcommand{\\cL}{\\mathcal{L}}\\newcommand{\\Cl}{\\mathrm{Cl}}\\newcommand{\\cN}{\\mathcal{N}}\\newcommand{\\Ae}{\\textrm{-a.e.}\\;}\\renewcommand{\\csub}{\\overset{\\textrm{closed}}{\\subset}}\\renewcommand{\\csup}{\\overset{\\textrm{closed}}{\\supset}}\\newcommand{\\wB}{\\wt{B}}\\newcommand{\\cG}{\\mathcal{G}}\\newcommand{\\Lip}{\\mathrm{Lip}}\\newcommand{\\AC}{\\mathrm{AC}}\\newcommand{\\Mol}{\\mathrm{Mol}}\n\n\\newcommand{\\Pe}{\\mathrm{Pe}}\\newcommand{\\wR}{\\wh{\\mathbb{\\R}}}\\newcommand*{\\Laplace}{\\mathop{}\\!\\mathbin\\bigtriangleup}\\newcommand*{\\DAlambert}{\\mathop{}\\!\\mathbin\\Box}\\newcommand{\\bT}{\\mathbb{T}}\\newcommand{\\dx}{\\dslash x}\\newcommand{\\dt}{\\dslash t}\\newcommand{\\ds}{\\dslash s}\n\n\\newcommand{\\round}{\\mathrm{round}}\\newcommand{\\cond}{\\mathrm{cond}}\\newcommand{\\diag}{\\mathrm{diag}}\n\\newcommand{\\Adj}{\\mathrm{Adj}}\\newcommand{\\Pf}{\\mathrm{Pf}}\\newcommand{\\Sg}{\\mathrm{Sg}}\n\n\n\\newcommand{\\aseq}{\\overset{\\text{a.s.}}{=}}\\newcommand{\\deq}{\\overset{\\text{d}}{=}}\\newcommand{\\cV}{\\mathcal{V}}\\newcommand{\\FM}{\\mathrm{FM}}\\newcommand{\\KR}{\\mathrm{KR}}\\newcommand{\\rba}{\\mathrm{rba}}\\newcommand{\\rca}{\\mathrm{rca}}\\newcommand{\\Prob}{\\mathrm{Prob}}\\newcommand{\\X}{\\mathcal{X}}\\newcommand{\\Meas}{\\mathrm{Meas}}\\newcommand{\\as}{\\;\\text{a.s.}}\\newcommand{\\io}{\\;\\mathrm{i.o.}}\\newcommand{\\fe}{\\;\\text{f.e.}}\\newcommand{\\bF}{\\mathbb{F}}\\newcommand{\\W}{\\mathcal{W}}\\newcommand{\\Pois}{\\mathrm{Pois}}\\newcommand{\\iid}{\\text{i.i.d.}}\\newcommand{\\wconv}{\\rightsquigarrow}\\newcommand{\\Var}{\\mathrm{Var}}\\newcommand{\\xrightarrown}{\\xrightarrow{n\\to\\infty}}\\newcommand{\\au}{\\mathrm{au}}\\newcommand{\\cT}{\\mathcal{T}}\\newcommand{\\wto}{\\overset{\\text{w}}{\\to}}\\newcommand{\\dto}{\\overset{\\text{d}}{\\to}}\\newcommand{\\sto}{\\overset{\\text{s}}{\\to}}\\newcommand{\\pto}{\\overset{\\text{p}}{\\to}}\\newcommand{\\mto}{\\overset{\\text{m}}{\\to}}\\newcommand{\\vto}{\\overset{v}{\\to}}\\newcommand{\\Cont}{\\mathrm{Cont}}\\newcommand{\\stably}{\\mathrm{stably}}\\newcommand{\\Np}{\\mathbb{N}^+}\\newcommand{\\oM}{\\overline{\\mathcal{M}}}\\newcommand{\\fP}{\\mathfrak{P}}\\newcommand{\\sign}{\\mathrm{sign}}\n\\newcommand{\\Borel}{\\mathrm{Borel}}\\newcommand{\\Mid}{\\,|\\,}\\newcommand{\\middleMid}{\\;\\middle|\\;}\\newcommand{\\CP}{\\mathrm{CP}}\\newcommand{\\bD}{\\mathbb{D}}\\newcommand{\\bL}{\\mathbb{L}}\\newcommand{\\fW}{\\mathfrak{W}}\\newcommand{\\DL}{\\mathcal{D}\\mathcal{L}}\\renewcommand{\\r}[1]{\\mathrm{#1}}\\newcommand{\\rC}{\\mathrm{C}}\\newcommand{\\qqquad}{\\qquad\\quad}\n\n\\newcommand{\\bit}{\\mathrm{bit}}\n\n\\newcommand{\\err}{\\mathrm{err}}\n\n\\newcommand{\\varparallel}{\\mathbin{\\!/\\mkern-5mu/\\!}}\\newcommand{\\Ri}{\\mathrm{Ri}}\\newcommand{\\Cone}{\\mathrm{Cone}}\\newcommand{\\Int}{\\mathrm{Int}}\n\n\\newcommand{\\pre}{\\mathrm{pre}}\\newcommand{\\om}{\\omega}\n\n\n\\newcommand{\\del}{\\partial}\n\\newcommand{\\LHS}{\\mathrm{LHS}}\\newcommand{\\RHS}{\\mathrm{RHS}}\\newcommand{\\bnu}{\\boldsymbol{\\nu}}\\newcommand{\\interior}{\\mathrm{in}\\;}\\newcommand{\\SH}{\\mathrm{SH}}\\renewcommand{\\v}{\\boldsymbol{\\nu}}\\newcommand{\\n}{\\mathbf{n}}\\newcommand{\\ssub}{\\Subset}\\newcommand{\\curl}{\\mathrm{curl}}\n\n\\newcommand{\\Ei}{\\mathrm{Ei}}\\newcommand{\\sn}{\\mathrm{sn}}\\newcommand{\\wgamma}{\\widetilde{\\gamma}}\n\n\\newcommand{\\Ens}{\\mathrm{Ens}}\n\n\\newcommand{\\cl}{\\mathrm{cl}}\\newcommand{\\x}{\\boldsymbol{x}}\n\n\\newcommand{\\Do}{\\mathrm{Do}}\\newcommand{\\IV}{\\mathrm{IV}}\n\n\\newcommand{\\AIC}{\\mathrm{AIC}}\\newcommand{\\mrl}{\\mathrm{mrl}}\\newcommand{\\dotx}{\\dot{x}}\\newcommand{\\UMV}{\\mathrm{UMV}}\\newcommand{\\BLU}{\\mathrm{BLU}}\n\n\\newcommand{\\comb}[2]{\\begin{pmatrix}#1\\\\#2\\end{pmatrix}}\\newcommand{\\bP}{\\mathbb{P}}\\newcommand{\\compsub}{\\overset{\\textrm{cpt}}{\\subset}}\\newcommand{\\lip}{\\textrm{lip}}\\newcommand{\\BL}{\\mathrm{BL}}\\newcommand{\\G}{\\mathbb{G}}\\newcommand{\\NB}{\\mathrm{NB}}\\newcommand{\\oR}{\\ov{\\R}}\\newcommand{\\liminfn}{\\liminf_{n\\to\\infty}}\\newcommand{\\limsupn}{\\limsup_{n\\to\\infty}}\\newcommand{\\esssup}{\\mathrm{ess.sup}}\\newcommand{\\asto}{\\xrightarrow{\\as}}\\newcommand{\\Cov}{\\mathrm{Cov}}\\newcommand{\\cQ}{\\mathcal{Q}}\\newcommand{\\VC}{\\mathrm{VC}}\\newcommand{\\mb}{\\mathrm{mb}}\\newcommand{\\Avar}{\\mathrm{Avar}}\\newcommand{\\bB}{\\mathbb{B}}\\newcommand{\\bW}{\\mathbb{W}}\\newcommand{\\sd}{\\mathrm{sd}}\\newcommand{\\w}[1]{\\widehat{#1}}\\newcommand{\\bZ}{\\mathbb{Z}}\\newcommand{\\Bernoulli}{\\mathrm{Ber}}\\newcommand{\\Ber}{\\mathrm{Ber}}\\newcommand{\\Mult}{\\mathrm{Mult}}\\newcommand{\\BPois}{\\mathrm{BPois}}\\newcommand{\\fraks}{\\mathfrak{s}}\\newcommand{\\frakk}{\\mathfrak{k}}\\newcommand{\\IF}{\\mathrm{IF}}\\newcommand{\\bX}{\\boldsymbol{X}}\\newcommand{\\bx}{\\boldsymbol{x}}\\newcommand{\\indep}{\\perp\\!\\!\\!\\perp}\\newcommand{\\IG}{\\mathrm{IG}}\\newcommand{\\Levy}{\\mathrm{Levy}}\\newcommand{\\MP}{\\mathrm{MP}}\\newcommand{\\Hermite}{\\mathrm{Hermite}}\\newcommand{\\Skellam}{\\mathrm{Skellam}}\\newcommand{\\Dirichlet}{\\mathrm{Dirichlet}}\\renewcommand{\\Beta}{\\mathrm{Beta}}\\newcommand{\\bE}{\\mathbb{E}}\\newcommand{\\bG}{\\mathbb{G}}\\newcommand{\\MISE}{\\mathrm{MISE}}\\newcommand{\\logit}{\\mathtt{logit}}\\newcommand{\\expit}{\\mathtt{expit}}\\newcommand{\\cK}{\\mathcal{K}}\\newcommand{\\dl}{\\dot{l}}\\newcommand{\\dotp}{\\dot{p}}\\newcommand{\\wl}{\\wt{l}}\\newcommand{\\Gauss}{\\mathrm{Gauss}}\\newcommand{\\fA}{\\mathfrak{A}}\\newcommand{\\under}{\\mathrm{under}\\;}\\newcommand{\\whtheta}{\\wh{\\theta}}\\newcommand{\\Em}{\\mathrm{Em}}\\newcommand{\\ztheta}{{\\theta_0}}\n\\newcommand{\\rO}{\\mathrm{O}}\\newcommand{\\Bin}{\\mathrm{Bin}}\\newcommand{\\rW}{\\mathrm{W}}\\newcommand{\\rG}{\\mathrm{G}}\\newcommand{\\rB}{\\mathrm{B}}\\newcommand{\\rU}{\\mathrm{U}}\\newcommand{\\HG}{\\mathrm{HG}}\\newcommand{\\GAMMA}{\\mathrm{Gamma}}\\newcommand{\\Cauchy}{\\mathrm{Cauchy}}\\newcommand{\\rt}{\\mathrm{t}}\\newcommand{\\rF}{\\mathrm{F}}\n\\newcommand{\\FE}{\\mathrm{FE}}\\newcommand{\\bV}{\\boldsymbol{V}}\\newcommand{\\GLS}{\\mathrm{GLS}}\\newcommand{\\be}{\\boldsymbol{e}}\\newcommand{\\POOL}{\\mathrm{POOL}}\\newcommand{\\GMM}{\\mathrm{GMM}}\\newcommand{\\MM}{\\mathrm{MM}}\\newcommand{\\SSIV}{\\mathrm{SSIV}}\\newcommand{\\JIV}{\\mathrm{JIV}}\\newcommand{\\AR}{\\mathrm{AR}}\\newcommand{\\ILS}{\\mathrm{ILS}}\\newcommand{\\SLS}{\\mathrm{SLS}}\\newcommand{\\LIML}{\\mathrm{LIML}}\n\n\\newcommand{\\Rad}{\\mathrm{Rad}}\\newcommand{\\bY}{\\boldsymbol{Y}}\\newcommand{\\pone}{{(1)}}\\newcommand{\\ptwo}{{(2)}}\\newcommand{\\ps}[1]{{(#1)}}\\newcommand{\\fsub}{\\overset{\\text{finite}}{\\subset}}\n\n\n\\newcommand{\\varlim}{\\varprojlim}\\newcommand{\\Hom}{\\mathrm{Hom}}\\newcommand{\\Iso}{\\mathrm{Iso}}\\newcommand{\\Mor}{\\mathrm{Mor}}\\newcommand{\\Isom}{\\mathrm{Isom}}\\newcommand{\\Aut}{\\mathrm{Aut}}\\newcommand{\\End}{\\mathrm{End}}\\newcommand{\\op}{\\mathrm{op}}\\newcommand{\\ev}{\\mathrm{ev}}\\newcommand{\\Ob}{\\mathrm{Ob}}\\newcommand{\\Ar}{\\mathrm{Ar}}\\newcommand{\\Arr}{\\mathrm{Arr}}\\newcommand{\\Set}{\\mathrm{Set}}\\newcommand{\\Grp}{\\mathrm{Grp}}\\newcommand{\\Cat}{\\mathrm{Cat}}\\newcommand{\\Mon}{\\mathrm{Mon}}\\newcommand{\\Ring}{\\mathrm{Ring}}\\newcommand{\\CRing}{\\mathrm{CRing}}\\newcommand{\\Ab}{\\mathrm{Ab}}\\newcommand{\\Pos}{\\mathrm{Pos}}\\newcommand{\\Vect}{\\mathrm{Vect}}\\newcommand{\\FinVect}{\\mathrm{FinVect}}\\newcommand{\\FinSet}{\\mathrm{FinSet}}\\newcommand{\\FinMeas}{\\mathrm{FinMeas}}\\newcommand{\\OmegaAlg}{\\Omega\\text{-}\\mathrm{Alg}}\\newcommand{\\OmegaEAlg}{(\\Omega,E)\\text{-}\\mathrm{Alg}}\\newcommand{\\Fun}{\\mathrm{Fun}}\\newcommand{\\Func}{\\mathrm{Func}}\n\n\\newcommand{\\Stoch}{\\mathrm{Stoch}}\\newcommand{\\FinStoch}{\\mathrm{FinStoch}}\\newcommand{\\Copy}{\\mathrm{copy}}\\newcommand{\\Delete}{\\mathrm{delete}}\n\\newcommand{\\Bool}{\\mathrm{Bool}}\\newcommand{\\CABool}{\\mathrm{CABool}}\\newcommand{\\CompBoolAlg}{\\mathrm{CompBoolAlg}}\\newcommand{\\BoolAlg}{\\mathrm{BoolAlg}}\\newcommand{\\BoolRng}{\\mathrm{BoolRng}}\\newcommand{\\HeytAlg}{\\mathrm{HeytAlg}}\\newcommand{\\CompHeytAlg}{\\mathrm{CompHeytAlg}}\\newcommand{\\Lat}{\\mathrm{Lat}}\\newcommand{\\CompLat}{\\mathrm{CompLat}}\\newcommand{\\SemiLat}{\\mathrm{SemiLat}}\\newcommand{\\Stone}{\\mathrm{Stone}}\\newcommand{\\Mfd}{\\mathrm{Mfd}}\\newcommand{\\LieAlg}{\\mathrm{LieAlg}}\n\\newcommand{\\Op}{\\mathrm{Op}}\n\\newcommand{\\Sh}{\\mathrm{Sh}}\n\\newcommand{\\Diff}{\\mathrm{Diff}}\n\\newcommand{\\B}{\\mathcal{B}}\\newcommand{\\cB}{\\mathcal{B}}\\newcommand{\\Span}{\\mathrm{Span}}\\newcommand{\\Corr}{\\mathrm{Corr}}\\newcommand{\\Decat}{\\mathrm{Decat}}\\newcommand{\\Rep}{\\mathrm{Rep}}\\newcommand{\\Grpd}{\\mathrm{Grpd}}\\newcommand{\\sSet}{\\mathrm{sSet}}\\newcommand{\\Mod}{\\mathrm{Mod}}\\newcommand{\\SmoothMnf}{\\mathrm{SmoothMnf}}\\newcommand{\\coker}{\\mathrm{coker}}\\newcommand{\\Ord}{\\mathrm{Ord}}\\newcommand{\\eq}{\\mathrm{eq}}\\newcommand{\\coeq}{\\mathrm{coeq}}\\newcommand{\\act}{\\mathrm{act}}\n\n\\newcommand{\\apf}{\\mathrm{apf}}\\newcommand{\\opt}{\\mathrm{opt}}\\newcommand{\\IS}{\\mathrm{IS}}\\newcommand{\\IR}{\\mathrm{IR}}\\newcommand{\\iidsim}{\\overset{\\text{iid}}{\\sim}}\\newcommand{\\propt}{\\,\\propto\\,}\\newcommand{\\bM}{\\mathbb{M}}\\newcommand{\\cX}{\\mathcal{X}}\\newcommand{\\cY}{\\mathcal{Y}}\\newcommand{\\cP}{\\mathcal{P}}\\newcommand{\\ola}[1]{\\overleftarrow{#1}}\n\n\\renewcommand{\\iff}{\\;\\mathrm{iff}\\;}\n\\newcommand{\\False}{\\mathrm{False}}\\newcommand{\\True}{\\mathrm{True}}\n\\newcommand{\\otherwise}{\\mathrm{otherwise}}\n\\newcommand{\\suchthat}{\\;\\mathrm{s.t.}\\;}\n\n\\newcommand{\\cM}{\\mathcal{M}}\\newcommand{\\M}{\\mathbb{M}}\\newcommand{\\cF}{\\mathcal{F}}\\newcommand{\\cD}{\\mathcal{D}}\\newcommand{\\fX}{\\mathfrak{X}}\\newcommand{\\fY}{\\mathfrak{Y}}\\newcommand{\\fZ}{\\mathfrak{Z}}\\renewcommand{\\H}{\\mathcal{H}}\\newcommand{\\cH}{\\mathcal{H}}\\newcommand{\\fH}{\\mathfrak{H}}\\newcommand{\\bH}{\\mathbb{H}}\\newcommand{\\id}{\\mathrm{id}}\\newcommand{\\A}{\\mathcal{A}}\n\\newcommand{\\lmd}{\\lambda}\n\\newcommand{\\Lmd}{\\Lambda}\n\\newcommand{\\cI}{\\mathcal{I}}\n\n\\newcommand{\\Lrarrow}{\\;\\;\\Leftrightarrow\\;\\;}\n$$\n\n:::\n\n:::\n\n\n\n## VAE [@Kingma-Welling2014]\n\n### 導入\n\n`PyTorch` を用いることで詳細を省略し，VAE の構造を概観することとする．\n\n::: {#8a58ef36 .cell execution_count=1}\n``` {.python .cell-code}\nimport torch\nimport torch.nn as nn\n\nimport numpy as np\n\nfrom tqdm import tqdm\nfrom torchvision.utils import save_image, make_grid\n```\n:::\n\n\n今回は，MNIST データセットを用い，隠れ次元 400 を通じて潜在次元 200 まで圧縮する．\n\n::: {#97d692e6 .cell execution_count=2}\n``` {.python .cell-code}\ndataset_path = '~/hirofumi/datasets'\n\nDEVICE = torch.device(\"mps\")\n\nbatch_size = 100\n\nx_dim = 784\nhidden_dim = 400\nlatent_dim = 200\n\nlr = 1e-3\n\nepochs = 30\n```\n:::\n\n\n::: {#c6e2189a .cell execution_count=3}\n``` {.python .cell-code code-summary=\"データセットをダウンロードして読み込む\"}\nfrom torchvision.datasets import MNIST\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\n\n\nmnist_transform = transforms.Compose([\n        transforms.ToTensor(),\n])\n\nkwargs = {'num_workers': 0, 'pin_memory': True} \n\ntrain_dataset = MNIST(dataset_path, transform=mnist_transform, train=True, download=True)\ntest_dataset  = MNIST(dataset_path, transform=mnist_transform, train=False, download=True)\n\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\ntest_loader  = DataLoader(dataset=test_dataset,  batch_size=batch_size, shuffle=False, **kwargs)\n```\n:::\n\n\nPyTorch の [Dataset と DataLoader](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) は，訓練やテスト用のデータセットの簡単なアクセスと，それに対する iterable オブジェクトを提供する．\n\n::: {.callout-important title=\"M2 Mac 上での実行\" collapse=\"true\" icon=\"false\"}\n\nまず，次のようにして仮想環境を用意する：\n```zsh\npython3 -m venv VAE\nsource VAE/bin/activate\npip install torch\n```\n\nM2 Mac では Metal Performance Shaders (MPS) という Apple の GPU アクセラレーション技術が利用可能で，PyTorch 1.12 からはこれをサポートしている．\n\n::: {#0d6f3388 .cell execution_count=4}\n``` {.python .cell-code}\nimport torch\nprint(torch.__version__)\nprint(torch.backends.mps.is_available())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2.4.0\nTrue\n```\n:::\n:::\n\n\n:::\n\n::: {.callout-important title=\"DataLoader worker (pid(s) 9044) exited unexpectedly\" collapse=\"true\" icon=\"false\"}\n\n上記のエラーは，`DataLoader` が並列処理によりデータを読み込むことに失敗したことを意味する．\n\nメモリ不足も考えられるが，`num_workers=0` として単一プロセスで実行することでもエラーが抑えられる．\n\n今回は軽量な計算であるから，これで良いということである．\n\n:::\n\n### モデルの定義\n\n#### エンコーダー\n\nエンコーダーはデータを受け取り，２層の全結合隠れ層を通じて，「平均」と「対数分散」の名前がついた計 400 次元の潜在表現を得る．\n\n::: {#f6cb0664 .cell execution_count=5}\n``` {.python .cell-code}\nclass Encoder(nn.Module):\n    \n    def __init__(self, input_dim, hidden_dim, latent_dim):\n        super(Encoder, self).__init__()\n\n        self.FC_input = nn.Linear(input_dim, hidden_dim)  # <1>\n        self.FC_input2 = nn.Linear(hidden_dim, hidden_dim)\n        self.FC_mean  = nn.Linear(hidden_dim, latent_dim)\n        self.FC_var   = nn.Linear(hidden_dim, latent_dim)\n        \n        self.LeakyReLU = nn.LeakyReLU(0.2)\n        \n        self.training = True\n        \n    def forward(self, x):\n        h_       = self.LeakyReLU(self.FC_input(x))\n        h_       = self.LeakyReLU(self.FC_input2(h_))  # <2>\n        mean     = self.FC_mean(h_)\n        log_var  = self.FC_var(h_)                     #  <3>\n        \n        return mean, log_var\n```\n:::\n\n\n1. [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) は PyTorch による全結合層 $y=xA^\\top+b$ の実装である．\n2. ここまで２層の全結合層にデータを通して，最終的な出力`h_`を得ており，次の段階で最終的な潜在表現を得る．\n3. 最後の隠れ層の出力`h_`に関して平均と対数分散という名前のついた最終的な出力を，やはり全結合層を通じて得る（最終層なので活性化なし）．\n\n#### デコーダー\n\n::: {#9b890e3f .cell execution_count=6}\n``` {.python .cell-code}\nclass Decoder(nn.Module):\n    def __init__(self, latent_dim, hidden_dim, output_dim):\n        super(Decoder, self).__init__()\n        self.FC_hidden = nn.Linear(latent_dim, hidden_dim)\n        self.FC_hidden2 = nn.Linear(hidden_dim, hidden_dim)\n        self.FC_output = nn.Linear(hidden_dim, output_dim)\n        \n        self.LeakyReLU = nn.LeakyReLU(0.2)\n        \n    def forward(self, x):\n        h     = self.LeakyReLU(self.FC_hidden(x))\n        h     = self.LeakyReLU(self.FC_hidden2(h))\n        \n        x_hat = torch.sigmoid(self.FC_output(h))  # <1>\n        return x_hat\n```\n:::\n\n\n1. 最後の出力は，エンコーダーとは違い，シグモイド関数を通して確率分布`x_hat`とする．\n\n#### モデル\n\nVAE はエンコーダーとデコーダーを連結し，１つのニューラルネットワークとして学習する．\n\n::: {#f06a27d0 .cell execution_count=7}\n``` {.python .cell-code}\nclass Model(nn.Module):\n    def __init__(self, Encoder, Decoder):\n        super(Model, self).__init__()\n        self.Encoder = Encoder\n        self.Decoder = Decoder\n        \n    def reparameterization(self, mean, var):\n        epsilon = torch.randn_like(var).to(DEVICE)  # <1>  \n        z = mean + var*epsilon   # <2>\n        return z\n        \n                \n    def forward(self, x):\n        mean, log_var = self.Encoder(x)  # <3>\n        z = self.reparameterization(mean, torch.exp(0.5 * log_var))  # <4>\n        x_hat            = self.Decoder(z)  # <5>\n        \n        return x_hat, mean, log_var  # <6>\n```\n:::\n\n\n1. これは **サンプリングイプシロン** と呼ばれる値である．\n2. ここで reparametrization trick を行っている．\n3. 入力 `x` があったならば，まずエンコーダーに通して `mean`, `log_var` を得る．\n4. 元々 `log_var` の名前の通り対数分散として扱うこととしていたので，２で割り指数関数に通すことで標準偏差を得る．この平均と標準偏差について reparametrization trick を実行し，デコーダーに繋ぐ．\n5. デコーダーではデータの潜在表現 `z` を受け取り，デコードしたものを `x_hat` とする．\n6. 返り値は，デコーダーの出力 `x_hat` だけでなく，潜在表現 `mean`, `log_var` も含むことに注意．\n\n::: {#bf8970f5 .cell execution_count=8}\n``` {.python .cell-code}\nencoder = Encoder(input_dim=x_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\ndecoder = Decoder(latent_dim=latent_dim, hidden_dim = hidden_dim, output_dim = x_dim)\n\nmodel = Model(Encoder=encoder, Decoder=decoder).to(DEVICE)  # <1>\n```\n:::\n\n\n1. `.to(DEVICE)` により，モデルを M2 Mac の MPS デバイス上に移送している．\n\n### モデルの訓練 {#sec-VAE-training}\n\n最適化には Adam [@Kingma-Ba2017] を用い，バイナリ交差エントロピー（BCE）を用いる．これは [`nn.BCELoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss) に実装がある．\n\n::: {#44fef760 .cell execution_count=9}\n``` {.python .cell-code}\nfrom torch.optim import Adam\n\nBCE_loss = nn.BCELoss()\n\ndef loss_function(x, x_hat, mean, log_var):\n    reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n    KLD      = - 0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n\n    return reproduction_loss + KLD\n\n\noptimizer = Adam(model.parameters(), lr=lr)\n```\n:::\n\n\nここでの損失関数は，真のデータ `x` をデコーダーが復元できているかを交差エントロピーで測った `reproduction_loss` と，潜在表現がどれだけ $\\rN_d(0,I_d),d=200$ に近いかを KL 乖離度で測った `KLD` の和で定義されている．^[なお，`mean.pow(2)` は Julia の `mean.^2` に同じ．]\n\n::: {.callout-important title=\"訓練の実行\" collapse=\"true\" icon=\"false\"}\n\n::: {#852b400f .cell execution_count=10}\n``` {.python .cell-code}\nimport time\n\nprint(\"Start training VAE...\")\nmodel.train()  # <1>\n\nstart_time = time.time()\n\nfor epoch in range(epochs):\n    overall_loss = 0\n    for batch_idx, (x, _) in enumerate(train_loader):\n        x = x.view(batch_size, x_dim)  # <2>\n        x = x.to(DEVICE)  # <3>\n\n        optimizer.zero_grad()  # <4>\n\n        x_hat, mean, log_var = model(x)\n        loss = loss_function(x, x_hat, mean, log_var)\n        \n        overall_loss += loss.item()\n        \n        loss.backward()\n        optimizer.step()\n        \n    print(\"\\tEpoch\", epoch + 1, \"complete!\", \"\\tAverage Loss: \", overall_loss / (batch_idx*batch_size))\n\ntotal_time = time.time() - start_time\nprint(\"Finish!! Total time: \", total_time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart training VAE...\n\tEpoch 1 complete! \tAverage Loss:  175.36252209085455\n\tEpoch 2 complete! \tAverage Loss:  129.14958457781196\n\tEpoch 3 complete! \tAverage Loss:  117.65271259390651\n\tEpoch 4 complete! \tAverage Loss:  113.45947293340463\n\tEpoch 5 complete! \tAverage Loss:  110.7511647178892\n\tEpoch 6 complete! \tAverage Loss:  108.6976742324447\n\tEpoch 7 complete! \tAverage Loss:  107.31498443043093\n\tEpoch 8 complete! \tAverage Loss:  106.26178927770242\n\tEpoch 9 complete! \tAverage Loss:  105.46850864722454\n\tEpoch 10 complete! \tAverage Loss:  104.81860570025563\n\tEpoch 11 complete! \tAverage Loss:  104.25153936573977\n\tEpoch 12 complete! \tAverage Loss:  103.755021438726\n\tEpoch 13 complete! \tAverage Loss:  103.36037327838064\n\tEpoch 14 complete! \tAverage Loss:  103.0021041253652\n\tEpoch 15 complete! \tAverage Loss:  102.73543854014504\n\tEpoch 16 complete! \tAverage Loss:  102.37967328359767\n\tEpoch 17 complete! \tAverage Loss:  102.22292182935101\n\tEpoch 18 complete! \tAverage Loss:  101.97767369443865\n\tEpoch 19 complete! \tAverage Loss:  101.75506798440108\n\tEpoch 20 complete! \tAverage Loss:  101.55393588924248\n\tEpoch 21 complete! \tAverage Loss:  101.39337562930405\n\tEpoch 22 complete! \tAverage Loss:  101.25349332220367\n\tEpoch 23 complete! \tAverage Loss:  101.01709069151711\n\tEpoch 24 complete! \tAverage Loss:  100.97026566086707\n\tEpoch 25 complete! \tAverage Loss:  100.7724350969063\n\tEpoch 26 complete! \tAverage Loss:  100.70291000952108\n\tEpoch 27 complete! \tAverage Loss:  100.5600941999687\n\tEpoch 28 complete! \tAverage Loss:  100.46706979079717\n\tEpoch 29 complete! \tAverage Loss:  100.34214339980697\n\tEpoch 30 complete! \tAverage Loss:  100.27846345471619\nFinish!! Total time:  129.9700391292572\n```\n:::\n:::\n\n\n1. `PyTorch` のモデルオブジェクトを訓練モードにするメソッド．Dropout や Batch Normalization 層がある場合は，これにより訓練時の挙動を示すようになる．\n2. 事前に定めた `batch_size` に従ってバッチを展開．\n3. データを GPU に移動．\n4. 勾配をゼロに初期化するとのこと．\n\n:::\n\n### モデルの評価\n\nテスト用データの最初のバッチについて処理し，入力データと出力データを見比べてみる．\n\n::: {#7ef8044c .cell execution_count=11}\n``` {.python .cell-code}\nmodel.eval()\n\nwith torch.no_grad():  # <1>\n    for batch_idx, (x, _) in enumerate(tqdm(test_loader)):\n        x = x.view(batch_size, x_dim)\n        x = x.to(DEVICE)\n        \n        x_hat, _, _ = model(x)\n\n\n        break\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r  0%|          | 0/100 [00:00<?, ?it/s]\r  0%|          | 0/100 [00:00<?, ?it/s]\n```\n:::\n:::\n\n\n1. 勾配評価を無効化するコンテクストマネージャーで，メモリの使用を節約できるという．\n\n::: {#fig-reconstruction .cell layout-ncol='2' execution_count=12}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\ndef show_image(x, idx):\n    x = x.view(batch_size, 28, 28)\n\n    fig = plt.figure()\n    plt.imshow(x[idx].cpu().numpy())\n\nshow_image(x, idx=0)\nshow_image(x_hat, idx=0)\n```\n\n::: {.cell-output .cell-output-display}\n![](VAE_files/figure-html/fig-reconstruction-output-1.png){#fig-reconstruction-1 width=341 height=337}\n:::\n\n::: {.cell-output .cell-output-display}\n![](VAE_files/figure-html/fig-reconstruction-output-2.png){#fig-reconstruction-2 width=341 height=337}\n:::\n:::\n\n\n左が入力で右が出力である．\n\n### データの生成\n\nここで，エンコーダを取り外してデコーダーからデータを生成する．\n\n損失関数（第 [-@sec-VAE-training] 節）には，潜在空間におけるデータを標準正規分布に近付けるための項が入っていたため，データの潜在表現は極めて標準正規分布に近いとみなすことにする．\n\nすると，潜在表現と同じ次元の正規乱数から，データセットに極めて似通ったデータが生成できるだろう．\n\n::: {#fig-generation .cell layout-ncol='2' layout-nrow='2' execution_count=13}\n``` {.python .cell-code}\nwith torch.no_grad():\n    noise = torch.randn(batch_size, latent_dim).to(DEVICE)\n    generated_images = decoder(noise)\n\nsave_image(generated_images.view(batch_size, 1, 28, 28), 'generated_sample.png')\nfor i in range(4):\n    show_image(generated_images, idx=i)\n```\n\n::: {.cell-output .cell-output-display}\n![](VAE_files/figure-html/fig-generation-output-1.png){#fig-generation-1 width=341 height=337}\n:::\n\n::: {.cell-output .cell-output-display}\n![](VAE_files/figure-html/fig-generation-output-2.png){#fig-generation-2 width=341 height=337}\n:::\n\n::: {.cell-output .cell-output-display}\n![](VAE_files/figure-html/fig-generation-output-3.png){#fig-generation-3 width=341 height=337}\n:::\n\n::: {.cell-output .cell-output-display}\n![](VAE_files/figure-html/fig-generation-output-4.png){#fig-generation-4 width=341 height=337}\n:::\n:::\n\n\n## VQ-VAE [@vandenOord+2017]\n\n### 導入\n\n::: {#5a14f9a8 .cell execution_count=14}\n``` {.python .cell-code}\nDEVICE = torch.device(\"mps\")\n\nbatch_size = 128\nimg_size = (32, 32)\n\ninput_dim = 3\nhidden_dim = 512\nlatent_dim = 16\nn_embeddings= 512\noutput_dim = 3\ncommitment_beta = 0.25\n\nlr = 2e-4\n\nepochs = 50\n\nprint_step = 50\n```\n:::\n\n\n::: {#d33f9627 .cell execution_count=15}\n``` {.python .cell-code}\nfrom torchvision.datasets import CIFAR10\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\n\n\nmnist_transform = transforms.Compose([\n        transforms.ToTensor(),\n])\n\nkwargs = {'num_workers': 1, 'pin_memory': True} \n\ntrain_dataset = CIFAR10(dataset_path, transform=mnist_transform, train=True, download=True)\ntest_dataset  = CIFAR10(dataset_path, transform=mnist_transform, train=False, download=True)\n\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\ntest_loader  = DataLoader(dataset=test_dataset,  batch_size=batch_size, shuffle=False,  **kwargs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDownloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /Users/hirofumi48/hirofumi/datasets/cifar-10-python.tar.gz\nExtracting /Users/hirofumi48/hirofumi/datasets/cifar-10-python.tar.gz to /Users/hirofumi48/hirofumi/datasets\nFiles already downloaded and verified\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\r  0%|          | 0/170498071 [00:00<?, ?it/s]\r  0%|          | 32768/170498071 [00:00<14:49, 191623.59it/s]\r  0%|          | 65536/170498071 [00:00<14:42, 193018.56it/s]\r  0%|          | 98304/170498071 [00:00<14:33, 195127.44it/s]\r  0%|          | 229376/170498071 [00:00<06:42, 422557.54it/s]\r  0%|          | 360448/170498071 [00:00<05:11, 545362.45it/s]\r  0%|          | 720896/170498071 [00:01<02:38, 1074009.10it/s]\r  1%|          | 1212416/170498071 [00:01<01:43, 1636624.16it/s]\r  1%|          | 1900544/170498071 [00:01<01:39, 1699659.02it/s]\r  1%|▏         | 2359296/170498071 [00:01<01:27, 1930286.27it/s]\r  2%|▏         | 3080192/170498071 [00:01<01:07, 2491143.12it/s]\r  2%|▏         | 3407872/170498071 [00:02<01:10, 2356931.50it/s]\r  2%|▏         | 3768320/170498071 [00:02<01:13, 2281554.55it/s]\r  2%|▏         | 4128768/170498071 [00:02<01:14, 2233632.08it/s]\r  3%|▎         | 4521984/170498071 [00:02<01:13, 2246254.02it/s]\r  3%|▎         | 4882432/170498071 [00:02<01:14, 2218315.85it/s]\r  3%|▎         | 5275648/170498071 [00:02<01:13, 2241772.26it/s]\r  3%|▎         | 5668864/170498071 [00:03<01:13, 2245866.51it/s]\r  4%|▎         | 6062080/170498071 [00:03<01:12, 2267121.70it/s]\r  4%|▍         | 6455296/170498071 [00:03<01:12, 2273558.89it/s]\r  4%|▍         | 6848512/170498071 [00:03<01:12, 2270113.97it/s]\r  4%|▍         | 7176192/170498071 [00:03<01:06, 2459558.64it/s]\r  4%|▍         | 7438336/170498071 [00:03<01:12, 2248855.81it/s]\r  5%|▍         | 7766016/170498071 [00:04<01:06, 2462892.44it/s]\r  5%|▍         | 8060928/170498071 [00:04<01:02, 2578708.93it/s]\r  5%|▍         | 8355840/170498071 [00:04<01:09, 2326172.37it/s]\r  5%|▌         | 8617984/170498071 [00:04<01:09, 2331998.18it/s]\r  5%|▌         | 8945664/170498071 [00:04<01:06, 2428505.56it/s]\r  5%|▌         | 9207808/170498071 [00:04<01:06, 2432062.92it/s]\r  6%|▌         | 9469952/170498071 [00:04<01:07, 2392038.98it/s]\r  6%|▌         | 9764864/170498071 [00:04<01:05, 2442558.88it/s]\r  6%|▌         | 10027008/170498071 [00:04<01:08, 2334444.41it/s]\r  6%|▌         | 10289152/170498071 [00:05<01:09, 2316417.26it/s]\r  6%|▌         | 10616832/170498071 [00:05<01:02, 2551834.06it/s]\r  6%|▋         | 10878976/170498071 [00:05<01:06, 2389105.30it/s]\r  7%|▋         | 11173888/170498071 [00:05<01:05, 2437405.93it/s]\r  7%|▋         | 11501568/170498071 [00:05<01:00, 2626282.53it/s]\r  7%|▋         | 11796480/170498071 [00:05<01:04, 2468508.75it/s]\r  7%|▋         | 12058624/170498071 [00:05<01:03, 2481743.09it/s]\r  7%|▋         | 12353536/170498071 [00:05<01:01, 2588997.19it/s]\r  7%|▋         | 12615680/170498071 [00:06<01:06, 2387813.83it/s]\r  8%|▊         | 12877824/170498071 [00:06<01:05, 2394626.54it/s]\r  8%|▊         | 13238272/170498071 [00:06<01:02, 2529705.77it/s]\r  8%|▊         | 13500416/170498071 [00:06<01:04, 2446001.42it/s]\r  8%|▊         | 13762560/170498071 [00:06<01:03, 2472887.49it/s]\r  8%|▊         | 14090240/170498071 [00:06<01:04, 2411630.73it/s]\r  8%|▊         | 14385152/170498071 [00:06<01:05, 2397501.40it/s]\r  9%|▊         | 14680064/170498071 [00:06<01:01, 2531404.46it/s]\r  9%|▉         | 14942208/170498071 [00:06<01:01, 2512307.06it/s]\r  9%|▉         | 15204352/170498071 [00:07<01:02, 2494952.47it/s]\r  9%|▉         | 15466496/170498071 [00:07<01:02, 2484274.40it/s]\r  9%|▉         | 15728640/170498071 [00:07<01:04, 2409858.06it/s]\r  9%|▉         | 16056320/170498071 [00:07<01:01, 2524217.79it/s]\r 10%|▉         | 16318464/170498071 [00:07<01:00, 2533264.88it/s]\r 10%|▉         | 16580608/170498071 [00:07<01:04, 2385864.85it/s]\r 10%|▉         | 16875520/170498071 [00:07<01:02, 2460944.96it/s]\r 10%|█         | 17170432/170498071 [00:07<00:59, 2580775.00it/s]\r 10%|█         | 17432576/170498071 [00:07<01:05, 2320490.35it/s]\r 10%|█         | 17727488/170498071 [00:08<01:02, 2459916.39it/s]\r 11%|█         | 18055168/170498071 [00:08<00:56, 2675570.57it/s]\r 11%|█         | 18350080/170498071 [00:08<01:02, 2434498.96it/s]\r 11%|█         | 18612224/170498071 [00:08<01:02, 2414135.62it/s]\r 11%|█         | 18939904/170498071 [00:08<00:58, 2611515.32it/s]\r 11%|█▏        | 19234816/170498071 [00:08<01:00, 2496458.61it/s]\r 11%|█▏        | 19496960/170498071 [00:08<01:02, 2413151.05it/s]\r 12%|█▏        | 19824640/170498071 [00:08<00:57, 2609291.94it/s]\r 12%|█▏        | 20119552/170498071 [00:09<01:01, 2428737.04it/s]\r 12%|█▏        | 20414464/170498071 [00:09<00:58, 2551727.18it/s]\r 12%|█▏        | 20676608/170498071 [00:09<00:59, 2501267.62it/s]\r 12%|█▏        | 20938752/170498071 [00:09<00:59, 2502489.15it/s]\r 12%|█▏        | 21200896/170498071 [00:09<01:03, 2361008.74it/s]\r 13%|█▎        | 21463040/170498071 [00:09<01:05, 2281011.83it/s]\r 13%|█▎        | 21856256/170498071 [00:09<01:03, 2323333.62it/s]\r 13%|█▎        | 22216704/170498071 [00:09<00:56, 2624390.27it/s]\r 13%|█▎        | 22511616/170498071 [00:09<00:59, 2497518.73it/s]\r 13%|█▎        | 22773760/170498071 [00:10<00:59, 2465656.20it/s]\r 14%|█▎        | 23101440/170498071 [00:10<00:55, 2663422.84it/s]\r 14%|█▎        | 23396352/170498071 [00:10<00:58, 2530971.33it/s]\r 14%|█▍        | 23658496/170498071 [00:10<00:58, 2514085.73it/s]\r 14%|█▍        | 24018944/170498071 [00:10<00:53, 2756946.59it/s]\r 14%|█▍        | 24313856/170498071 [00:10<00:57, 2552800.90it/s]\r 14%|█▍        | 24608768/170498071 [00:10<01:00, 2409601.72it/s]\r 15%|█▍        | 25001984/170498071 [00:10<00:52, 2748886.58it/s]\r 15%|█▍        | 25296896/170498071 [00:11<00:52, 2745262.03it/s]\r 15%|█▌        | 25591808/170498071 [00:11<00:57, 2528471.01it/s]\r 15%|█▌        | 25952256/170498071 [00:11<00:52, 2747399.70it/s]\r 15%|█▌        | 26279936/170498071 [00:11<00:52, 2736036.49it/s]\r 16%|█▌        | 26574848/170498071 [00:11<00:54, 2635224.09it/s]\r 16%|█▌        | 26935296/170498071 [00:11<00:49, 2871744.74it/s]\r 16%|█▌        | 27230208/170498071 [00:11<00:51, 2802702.13it/s]\r 16%|█▌        | 27525120/170498071 [00:11<00:56, 2525218.24it/s]\r 16%|█▋        | 27951104/170498071 [00:12<00:50, 2796770.26it/s]\r 17%|█▋        | 28278784/170498071 [00:12<00:49, 2860098.67it/s]\r 17%|█▋        | 28573696/170498071 [00:12<00:53, 2651501.82it/s]\r 17%|█▋        | 28966912/170498071 [00:12<00:47, 2975633.82it/s]\r 17%|█▋        | 29294592/170498071 [00:12<00:46, 3014151.89it/s]\r 17%|█▋        | 29622272/170498071 [00:12<00:50, 2775331.02it/s]\r 18%|█▊        | 30015488/170498071 [00:12<00:45, 3060160.89it/s]\r 18%|█▊        | 30375936/170498071 [00:12<00:48, 2882232.73it/s]\r 18%|█▊        | 30703616/170498071 [00:12<00:47, 2970199.00it/s]\r 18%|█▊        | 31129600/170498071 [00:13<00:44, 3152709.37it/s]\r 18%|█▊        | 31457280/170498071 [00:13<00:46, 2995528.55it/s]\r 19%|█▊        | 31817728/170498071 [00:13<00:44, 3128883.56it/s]\r 19%|█▉        | 32243712/170498071 [00:13<00:41, 3348427.78it/s]\r 19%|█▉        | 32604160/170498071 [00:13<00:45, 3027001.47it/s]\r 19%|█▉        | 33062912/170498071 [00:13<00:41, 3345974.87it/s]\r 20%|█▉        | 33456128/170498071 [00:13<00:41, 3326081.17it/s]\r 20%|█▉        | 33816576/170498071 [00:13<00:42, 3189607.18it/s]\r 20%|██        | 34275328/170498071 [00:14<00:38, 3502460.73it/s]\r 20%|██        | 34668544/170498071 [00:14<00:38, 3534854.66it/s]\r 21%|██        | 35028992/170498071 [00:14<00:40, 3385989.98it/s]\r 21%|██        | 35520512/170498071 [00:14<00:37, 3645872.34it/s]\r 21%|██        | 35913728/170498071 [00:14<00:36, 3641408.88it/s]\r 21%|██▏       | 36339712/170498071 [00:14<00:36, 3657707.52it/s]\r 22%|██▏       | 36831232/170498071 [00:14<00:35, 3779897.02it/s]\r 22%|██▏       | 37224448/170498071 [00:14<00:35, 3714381.75it/s]\r 22%|██▏       | 37683200/170498071 [00:14<00:34, 3879787.38it/s]\r 22%|██▏       | 38240256/170498071 [00:15<00:34, 3786617.22it/s]\r 23%|██▎       | 38731776/170498071 [00:15<00:32, 4018102.49it/s]\r 23%|██▎       | 39190528/170498071 [00:15<00:33, 3953585.22it/s]\r 23%|██▎       | 39714816/170498071 [00:15<00:32, 4080726.42it/s]\r 24%|██▎       | 40173568/170498071 [00:15<00:31, 4162042.09it/s]\r 24%|██▍       | 40697856/170498071 [00:15<00:31, 4170487.59it/s]\r 24%|██▍       | 41254912/170498071 [00:15<00:29, 4347485.52it/s]\r 24%|██▍       | 41746432/170498071 [00:15<00:29, 4433633.06it/s]\r 25%|██▍       | 42303488/170498071 [00:15<00:27, 4700229.30it/s]\r 25%|██▌       | 42795008/170498071 [00:16<00:28, 4546875.19it/s]\r 25%|██▌       | 43319296/170498071 [00:16<00:26, 4733476.70it/s]\r 26%|██▌       | 43810816/170498071 [00:16<00:26, 4746827.05it/s]\r 26%|██▌       | 44367872/170498071 [00:16<00:27, 4615776.19it/s]\r 26%|██▋       | 44924928/170498071 [00:16<00:26, 4739958.25it/s]\r 27%|██▋       | 45514752/170498071 [00:16<00:24, 5055079.47it/s]\r 27%|██▋       | 46104576/170498071 [00:16<00:24, 5148509.73it/s]\r 27%|██▋       | 46727168/170498071 [00:16<00:22, 5447435.16it/s]\r 28%|██▊       | 47284224/170498071 [00:16<00:24, 4948806.87it/s]\r 28%|██▊       | 47808512/170498071 [00:17<00:24, 4921550.77it/s]\r 29%|██▊       | 48594944/170498071 [00:17<00:21, 5686136.37it/s]\r 29%|██▉       | 49184768/170498071 [00:17<00:21, 5552185.63it/s]\r 29%|██▉       | 49807360/170498071 [00:17<00:22, 5349844.17it/s]\r 30%|██▉       | 50528256/170498071 [00:17<00:20, 5789829.01it/s]\r 30%|██▉       | 51118080/170498071 [00:17<00:20, 5740855.23it/s]\r 30%|███       | 51904512/170498071 [00:17<00:18, 6306669.85it/s]\r 31%|███       | 52559872/170498071 [00:17<00:19, 6088286.51it/s]\r 31%|███       | 53182464/170498071 [00:18<00:39, 3003204.00it/s]\r 32%|███▏      | 55246848/170498071 [00:18<00:20, 5577586.81it/s]\r 33%|███▎      | 56066048/170498071 [00:18<00:24, 4713449.14it/s]\r 33%|███▎      | 56721408/170498071 [00:18<00:24, 4628625.42it/s]\r 34%|███▎      | 57311232/170498071 [00:19<00:26, 4318574.75it/s]\r 34%|███▍      | 57835520/170498071 [00:19<00:27, 4107966.94it/s]\r 34%|███▍      | 58327040/170498071 [00:19<00:27, 4107434.36it/s]\r 34%|███▍      | 58785792/170498071 [00:19<00:28, 3968202.14it/s]\r 35%|███▍      | 59211776/170498071 [00:19<00:29, 3804581.87it/s]\r 35%|███▍      | 59637760/170498071 [00:19<00:29, 3734301.65it/s]\r 35%|███▌      | 60030976/170498071 [00:19<00:29, 3716431.56it/s]\r 35%|███▌      | 60424192/170498071 [00:19<00:30, 3644013.05it/s]\r 36%|███▌      | 60882944/170498071 [00:20<00:28, 3788781.69it/s]\r 36%|███▌      | 61276160/170498071 [00:20<00:30, 3634050.91it/s]\r 36%|███▌      | 61669376/170498071 [00:20<00:30, 3527835.45it/s]\r 36%|███▋      | 62193664/170498071 [00:20<00:27, 3879806.27it/s]\r 37%|███▋      | 62586880/170498071 [00:20<00:28, 3836788.30it/s]\r 37%|███▋      | 62980096/170498071 [00:20<00:29, 3661112.09it/s]\r 37%|███▋      | 63504384/170498071 [00:20<00:26, 4032345.52it/s]\r 37%|███▋      | 63930368/170498071 [00:20<00:32, 3282776.93it/s]\r 38%|███▊      | 64454656/170498071 [00:20<00:28, 3732595.30it/s]\r 38%|███▊      | 64880640/170498071 [00:21<00:27, 3772846.25it/s]\r 38%|███▊      | 65306624/170498071 [00:21<00:30, 3463303.60it/s]\r 39%|███▊      | 65896448/170498071 [00:21<00:25, 4047668.60it/s]\r 39%|███▉      | 66355200/170498071 [00:21<00:25, 4029928.59it/s]\r 39%|███▉      | 66781184/170498071 [00:21<00:28, 3640342.15it/s]\r 39%|███▉      | 67338240/170498071 [00:21<00:29, 3536398.12it/s]\r 40%|███▉      | 68026368/170498071 [00:21<00:26, 3887206.43it/s]\r 40%|████      | 68550656/170498071 [00:22<00:24, 4193551.76it/s]\r 40%|████      | 69009408/170498071 [00:22<00:26, 3784318.93it/s]\r 41%|████      | 69468160/170498071 [00:22<00:26, 3849309.12it/s]\r 41%|████      | 69959680/170498071 [00:22<00:24, 4079773.61it/s]\r 41%|████▏     | 70385664/170498071 [00:22<00:25, 4000140.59it/s]\r 42%|████▏     | 70877184/170498071 [00:22<00:24, 4045628.45it/s]\r 42%|████▏     | 71303168/170498071 [00:22<00:24, 4085518.27it/s]\r 42%|████▏     | 71729152/170498071 [00:22<00:24, 3970198.76it/s]\r 42%|████▏     | 72155136/170498071 [00:22<00:25, 3895700.47it/s]\r 43%|████▎     | 72548352/170498071 [00:23<00:31, 3083643.02it/s]\r 43%|████▎     | 73138176/170498071 [00:23<00:28, 3379457.95it/s]\r 43%|████▎     | 73629696/170498071 [00:23<00:29, 3292703.78it/s]\r 43%|████▎     | 74153984/170498071 [00:23<00:30, 3127523.79it/s]\r 44%|████▍     | 74678272/170498071 [00:23<00:31, 3042981.53it/s]\r 44%|████▍     | 75169792/170498071 [00:23<00:27, 3427494.93it/s]\r 44%|████▍     | 75563008/170498071 [00:24<00:30, 3135169.88it/s]\r 45%|████▍     | 75923456/170498071 [00:24<00:29, 3161415.76it/s]\r 45%|████▍     | 76283904/170498071 [00:24<00:32, 2900156.98it/s]\r 45%|████▌     | 76808192/170498071 [00:24<00:27, 3436104.46it/s]\r 45%|████▌     | 77201408/170498071 [00:24<00:28, 3302421.85it/s]\r 45%|████▌     | 77561856/170498071 [00:24<00:29, 3120396.06it/s]\r 46%|████▌     | 77955072/170498071 [00:24<00:30, 3073461.55it/s]\r 46%|████▌     | 78381056/170498071 [00:24<00:28, 3281716.15it/s]\r 46%|████▌     | 78741504/170498071 [00:25<00:29, 3090028.78it/s]\r 46%|████▋     | 79134720/170498071 [00:25<00:30, 3001755.80it/s]\r 47%|████▋     | 79691776/170498071 [00:25<00:28, 3216315.91it/s]\r 47%|████▋     | 80019456/170498071 [00:25<00:41, 2201381.38it/s]\r 47%|████▋     | 80445440/170498071 [00:25<00:34, 2586749.20it/s]\r 47%|████▋     | 80773120/170498071 [00:26<00:59, 1496031.88it/s]\r 48%|████▊     | 81100800/170498071 [00:26<00:55, 1605251.18it/s]\r 48%|████▊     | 81395712/170498071 [00:26<00:54, 1624896.43it/s]\r 48%|████▊     | 81690624/170498071 [00:26<00:54, 1630210.30it/s]\r 48%|████▊     | 81985536/170498071 [00:26<00:53, 1653603.06it/s]\r 48%|████▊     | 82280448/170498071 [00:27<00:49, 1774822.51it/s]\r 48%|████▊     | 82608128/170498071 [00:27<00:52, 1667066.07it/s]\r 49%|████▊     | 82935808/170498071 [00:27<00:50, 1733002.14it/s]\r 49%|████▉     | 83263488/170498071 [00:27<00:48, 1787624.55it/s]\r 49%|████▉     | 83591168/170498071 [00:27<00:47, 1832367.80it/s]\r 49%|████▉     | 83918848/170498071 [00:28<00:46, 1865314.00it/s]\r 49%|████▉     | 84246528/170498071 [00:28<00:45, 1894615.27it/s]\r 50%|████▉     | 84574208/170498071 [00:28<00:44, 1912321.40it/s]\r 50%|████▉     | 84901888/170498071 [00:28<00:40, 2112476.71it/s]\r 50%|████▉     | 85131264/170498071 [00:28<00:41, 2059467.75it/s]\r 50%|█████     | 85360640/170498071 [00:28<00:44, 1918494.08it/s]\r 50%|█████     | 85622784/170498071 [00:28<00:45, 1861719.68it/s]\r 50%|█████     | 85950464/170498071 [00:29<00:42, 1985951.36it/s]\r 51%|█████     | 86278144/170498071 [00:29<00:40, 2102895.97it/s]\r 51%|█████     | 86507520/170498071 [00:29<00:40, 2081286.88it/s]\r 51%|█████     | 86736896/170498071 [00:29<00:43, 1921653.76it/s]\r 51%|█████     | 86999040/170498071 [00:29<00:43, 1903226.72it/s]\r 51%|█████     | 87326720/170498071 [00:29<00:40, 2067215.80it/s]\r 51%|█████▏    | 87588864/170498071 [00:29<00:38, 2174961.16it/s]\r 52%|█████▏    | 87818240/170498071 [00:29<00:42, 1955465.68it/s]\r 52%|█████▏    | 88047616/170498071 [00:30<00:42, 1925643.32it/s]\r 52%|█████▏    | 88375296/170498071 [00:30<00:39, 2086827.72it/s]\r 52%|█████▏    | 88604672/170498071 [00:30<00:39, 2098393.53it/s]\r 52%|█████▏    | 88834048/170498071 [00:30<00:43, 1881308.81it/s]\r 52%|█████▏    | 89096192/170498071 [00:30<00:40, 1986770.32it/s]\r 52%|█████▏    | 89358336/170498071 [00:30<00:38, 2132216.27it/s]\r 53%|█████▎    | 89587712/170498071 [00:30<00:40, 1991875.32it/s]\r 53%|█████▎    | 89817088/170498071 [00:30<00:41, 1953742.02it/s]\r 53%|█████▎    | 90112000/170498071 [00:31<00:38, 2070920.09it/s]\r 53%|█████▎    | 90341376/170498071 [00:31<00:38, 2060808.62it/s]\r 53%|█████▎    | 90570752/170498071 [00:31<00:40, 1966966.07it/s]\r 53%|█████▎    | 90832896/170498071 [00:31<00:39, 2026413.51it/s]\r 53%|█████▎    | 91095040/170498071 [00:31<00:37, 2128046.09it/s]\r 54%|█████▎    | 91324416/170498071 [00:31<00:40, 1940176.05it/s]\r 54%|█████▎    | 91586560/170498071 [00:31<00:41, 1901927.45it/s]\r 54%|█████▍    | 91881472/170498071 [00:31<00:37, 2076229.06it/s]\r 54%|█████▍    | 92110848/170498071 [00:32<00:39, 2009786.20it/s]\r 54%|█████▍    | 92340224/170498071 [00:32<00:39, 1987949.29it/s]\r 54%|█████▍    | 92602368/170498071 [00:32<00:36, 2111832.14it/s]\r 54%|█████▍    | 92831744/170498071 [00:32<00:38, 2006463.05it/s]\r 55%|█████▍    | 93061120/170498071 [00:32<00:39, 1961596.73it/s]\r 55%|█████▍    | 93323264/170498071 [00:32<00:39, 1954350.47it/s]\r 55%|█████▍    | 93552640/170498071 [00:32<00:37, 2031191.57it/s]\r 55%|█████▌    | 93782016/170498071 [00:32<00:39, 1956169.93it/s]\r 55%|█████▌    | 94011392/170498071 [00:33<00:37, 2033536.30it/s]\r 55%|█████▌    | 94240768/170498071 [00:33<00:37, 2032265.79it/s]\r 55%|█████▌    | 94470144/170498071 [00:33<00:38, 1972213.72it/s]\r 56%|█████▌    | 94732288/170498071 [00:33<00:36, 2058383.10it/s]\r 56%|█████▌    | 94961664/170498071 [00:33<00:36, 2070920.41it/s]\r 56%|█████▌    | 95191040/170498071 [00:33<00:37, 2013066.00it/s]\r 56%|█████▌    | 95453184/170498071 [00:33<00:36, 2068119.22it/s]\r 56%|█████▌    | 95682560/170498071 [00:33<00:35, 2083547.26it/s]\r 56%|█████▋    | 95911936/170498071 [00:33<00:36, 2057681.12it/s]\r 56%|█████▋    | 96174080/170498071 [00:34<00:35, 2089206.52it/s]\r 57%|█████▋    | 96403456/170498071 [00:34<00:34, 2123016.87it/s]\r 57%|█████▋    | 96632832/170498071 [00:34<00:35, 2086904.47it/s]\r 57%|█████▋    | 96894976/170498071 [00:34<00:35, 2090709.29it/s]\r 57%|█████▋    | 97157120/170498071 [00:34<00:33, 2177051.11it/s]\r 57%|█████▋    | 97386496/170498071 [00:34<00:34, 2140838.09it/s]\r 57%|█████▋    | 97648640/170498071 [00:34<00:34, 2120534.67it/s]\r 57%|█████▋    | 97910784/170498071 [00:34<00:33, 2184616.14it/s]\r 58%|█████▊    | 98140160/170498071 [00:34<00:33, 2143449.30it/s]\r 58%|█████▊    | 98369536/170498071 [00:35<00:33, 2125758.82it/s]\r 58%|█████▊    | 98631680/170498071 [00:35<00:31, 2252204.02it/s]\r 58%|█████▊    | 98861056/170498071 [00:35<00:32, 2175246.93it/s]\r 58%|█████▊    | 99123200/170498071 [00:35<00:33, 2143921.49it/s]\r 58%|█████▊    | 99418112/170498071 [00:35<00:30, 2317479.78it/s]\r 58%|█████▊    | 99680256/170498071 [00:35<00:31, 2276822.26it/s]\r 59%|█████▊    | 99942400/170498071 [00:35<00:34, 2049621.73it/s]\r 59%|█████▉    | 100237312/170498071 [00:35<00:31, 2210637.05it/s]\r 59%|█████▉    | 100499456/170498071 [00:36<00:30, 2293805.44it/s]\r 59%|█████▉    | 100761600/170498071 [00:36<00:31, 2219287.25it/s]\r 59%|█████▉    | 101056512/170498071 [00:36<00:29, 2385767.28it/s]\r 59%|█████▉    | 101318656/170498071 [00:36<00:28, 2394371.52it/s]\r 60%|█████▉    | 101613568/170498071 [00:36<00:27, 2514412.74it/s]\r 60%|█████▉    | 101875712/170498071 [00:36<00:27, 2475883.14it/s]\r 60%|█████▉    | 102137856/170498071 [00:36<00:28, 2431567.49it/s]\r 60%|██████    | 102432768/170498071 [00:36<00:26, 2532487.16it/s]\r 60%|██████    | 102694912/170498071 [00:36<00:28, 2364466.36it/s]\r 60%|██████    | 103055360/170498071 [00:37<00:25, 2678292.64it/s]\r 61%|██████    | 103350272/170498071 [00:37<00:26, 2563784.53it/s]\r 61%|██████    | 103612416/170498071 [00:37<00:26, 2524021.82it/s]\r 61%|██████    | 104005632/170498071 [00:37<00:23, 2866997.89it/s]\r 61%|██████    | 104300544/170498071 [00:37<00:24, 2733336.16it/s]\r 61%|██████▏   | 104595456/170498071 [00:37<00:24, 2639477.56it/s]\r 62%|██████▏   | 104988672/170498071 [00:37<00:22, 2944120.01it/s]\r 62%|██████▏   | 105316352/170498071 [00:37<00:22, 2929416.05it/s]\r 62%|██████▏   | 105644032/170498071 [00:37<00:23, 2763266.06it/s]\r 62%|██████▏   | 106070016/170498071 [00:38<00:20, 3108479.83it/s]\r 62%|██████▏   | 106397696/170498071 [00:38<00:20, 3120192.21it/s]\r 63%|██████▎   | 106725376/170498071 [00:38<00:21, 2928768.08it/s]\r 63%|██████▎   | 107184128/170498071 [00:38<00:19, 3216869.59it/s]\r 63%|██████▎   | 107544576/170498071 [00:38<00:19, 3244364.22it/s]\r 63%|██████▎   | 107872256/170498071 [00:38<00:19, 3252262.18it/s]\r 63%|██████▎   | 108232704/170498071 [00:38<00:18, 3347000.24it/s]\r 64%|██████▎   | 108593152/170498071 [00:38<00:18, 3303317.43it/s]\r 64%|██████▍   | 108986368/170498071 [00:38<00:17, 3435329.23it/s]\r 64%|██████▍   | 109379584/170498071 [00:39<00:18, 3326454.69it/s]\r 64%|██████▍   | 109805568/170498071 [00:39<00:17, 3522026.20it/s]\r 65%|██████▍   | 110166016/170498071 [00:39<00:17, 3527954.40it/s]\r 65%|██████▍   | 110526464/170498071 [00:39<00:17, 3513987.77it/s]\r 65%|██████▌   | 111017984/170498071 [00:39<00:15, 3908122.03it/s]\r 65%|██████▌   | 111443968/170498071 [00:39<00:15, 3825219.35it/s]\r 66%|██████▌   | 111869952/170498071 [00:39<00:15, 3721974.15it/s]\r 66%|██████▌   | 112427008/170498071 [00:39<00:13, 4178232.86it/s]\r 66%|██████▌   | 112852992/170498071 [00:39<00:13, 4153106.36it/s]\r 66%|██████▋   | 113344512/170498071 [00:40<00:14, 3932372.86it/s]\r 67%|██████▋   | 113934336/170498071 [00:40<00:13, 4304569.40it/s]\r 67%|██████▋   | 114393088/170498071 [00:40<00:12, 4356401.11it/s]\r 67%|██████▋   | 114884608/170498071 [00:40<00:13, 4214310.15it/s]\r 68%|██████▊   | 115441664/170498071 [00:40<00:12, 4530556.35it/s]\r 68%|██████▊   | 115900416/170498071 [00:40<00:12, 4478063.56it/s]\r 68%|██████▊   | 116424704/170498071 [00:40<00:11, 4677002.91it/s]\r 69%|██████▊   | 116916224/170498071 [00:40<00:11, 4707534.32it/s]\r 69%|██████▉   | 117440512/170498071 [00:40<00:11, 4702455.68it/s]\r 69%|██████▉   | 117964800/170498071 [00:41<00:10, 4844670.71it/s]\r 70%|██████▉   | 118521856/170498071 [00:41<00:10, 5041596.31it/s]\r 70%|██████▉   | 119111680/170498071 [00:41<00:10, 5113065.81it/s]\r 70%|███████   | 119635968/170498071 [00:41<00:10, 4895320.35it/s]\r 71%|███████   | 120422400/170498071 [00:41<00:08, 5605980.33it/s]\r 71%|███████   | 121012224/170498071 [00:41<00:08, 5593911.21it/s]\r 71%|███████▏  | 121602048/170498071 [00:41<00:09, 5207737.13it/s]\r 72%|███████▏  | 122421248/170498071 [00:41<00:08, 5978540.12it/s]\r 72%|███████▏  | 123043840/170498071 [00:41<00:08, 5700525.39it/s]\r 73%|███████▎  | 123633664/170498071 [00:42<00:09, 5169031.89it/s]\r 73%|███████▎  | 124649472/170498071 [00:42<00:07, 6433072.92it/s]\r 74%|███████▎  | 125337600/170498071 [00:42<00:07, 5950994.60it/s]\r 74%|███████▍  | 125960192/170498071 [00:42<00:07, 5673089.51it/s]\r 74%|███████▍  | 126976000/170498071 [00:42<00:06, 6802406.81it/s]\r 75%|███████▍  | 127696896/170498071 [00:42<00:08, 5059592.44it/s]\r 76%|███████▌  | 128843776/170498071 [00:42<00:07, 5799145.62it/s]\r 76%|███████▌  | 129499136/170498071 [00:43<00:07, 5847864.87it/s]\r 76%|███████▋  | 130154496/170498071 [00:43<00:07, 5658690.07it/s]\r 77%|███████▋  | 130777088/170498071 [00:43<00:07, 5333116.50it/s]\r 77%|███████▋  | 131432448/170498071 [00:43<00:06, 5590287.62it/s]\r 77%|███████▋  | 132022272/170498071 [00:43<00:07, 5483220.25it/s]\r 78%|███████▊  | 132612096/170498071 [00:43<00:07, 5042966.16it/s]\r 78%|███████▊  | 133398528/170498071 [00:43<00:06, 5732120.58it/s]\r 79%|███████▊  | 134021120/170498071 [00:43<00:06, 5223006.69it/s]\r 79%|███████▉  | 134578176/170498071 [00:44<00:06, 5218205.74it/s]\r 79%|███████▉  | 135364608/170498071 [00:44<00:05, 5871504.51it/s]\r 80%|███████▉  | 135987200/170498071 [00:44<00:06, 5530083.82it/s]\r 80%|████████  | 136577024/170498071 [00:44<00:06, 5355482.81it/s]\r 80%|████████  | 137134080/170498071 [00:44<00:06, 5187342.23it/s]\r 81%|████████  | 137854976/170498071 [00:44<00:06, 4742905.08it/s]\r 81%|████████  | 138346496/170498071 [00:44<00:08, 3626040.27it/s]\r 81%|████████▏ | 138772480/170498071 [00:45<00:09, 3483373.78it/s]\r 82%|████████▏ | 139558912/170498071 [00:45<00:08, 3547786.21it/s]\r 82%|████████▏ | 140312576/170498071 [00:45<00:07, 4279604.24it/s]\r 83%|████████▎ | 140836864/170498071 [00:45<00:07, 3861755.49it/s]\r 83%|████████▎ | 141361152/170498071 [00:45<00:07, 3675193.25it/s]\r 83%|████████▎ | 141852672/170498071 [00:45<00:07, 3933382.18it/s]\r 83%|████████▎ | 142278656/170498071 [00:45<00:08, 3501925.01it/s]\r 84%|████████▎ | 142671872/170498071 [00:46<00:08, 3334946.31it/s]\r 84%|████████▍ | 143032320/170498071 [00:46<00:08, 3186035.62it/s]\r 84%|████████▍ | 143556608/170498071 [00:46<00:07, 3654469.84it/s]\r 84%|████████▍ | 143949824/170498071 [00:46<00:08, 3316425.70it/s]\r 85%|████████▍ | 144310272/170498071 [00:46<00:08, 3234464.37it/s]\r 85%|████████▍ | 144736256/170498071 [00:46<00:07, 3239569.57it/s]\r 85%|████████▌ | 145162240/170498071 [00:46<00:07, 3472545.17it/s]\r 85%|████████▌ | 145522688/170498071 [00:46<00:07, 3333921.79it/s]\r 86%|████████▌ | 145915904/170498071 [00:47<00:07, 3340025.41it/s]\r 86%|████████▌ | 146341888/170498071 [00:47<00:06, 3481041.28it/s]\r 86%|████████▌ | 146702336/170498071 [00:47<00:07, 3328950.28it/s]\r 86%|████████▋ | 147128320/170498071 [00:47<00:06, 3471840.18it/s]\r 87%|████████▋ | 147554304/170498071 [00:47<00:06, 3536345.01it/s]\r 87%|████████▋ | 147914752/170498071 [00:47<00:06, 3356385.34it/s]\r 87%|████████▋ | 148373504/170498071 [00:47<00:06, 3533383.66it/s]\r 87%|████████▋ | 148766720/170498071 [00:47<00:05, 3634017.28it/s]\r 87%|████████▋ | 149159936/170498071 [00:48<00:06, 3327223.58it/s]\r 88%|████████▊ | 149618688/170498071 [00:48<00:05, 3593892.73it/s]\r 88%|████████▊ | 150077440/170498071 [00:48<00:05, 3458187.45it/s]\r 88%|████████▊ | 150437888/170498071 [00:48<00:05, 3479407.59it/s]\r 88%|████████▊ | 150863872/170498071 [00:48<00:05, 3683023.23it/s]\r 89%|████████▊ | 151289856/170498071 [00:48<00:05, 3617397.52it/s]\r 89%|████████▉ | 151683072/170498071 [00:48<00:05, 3362566.10it/s]\r 89%|████████▉ | 152207360/170498071 [00:48<00:04, 3835185.34it/s]\r 90%|████████▉ | 152633344/170498071 [00:48<00:05, 3488234.22it/s]\r 90%|████████▉ | 153026560/170498071 [00:49<00:05, 3187415.23it/s]\r 90%|████████▉ | 153387008/170498071 [00:49<00:07, 2386705.42it/s]\r 90%|█████████ | 153681920/170498071 [00:49<00:10, 1671990.50it/s]\r 90%|█████████ | 153911296/170498071 [00:49<00:10, 1523964.04it/s]\r 90%|█████████ | 154238976/170498071 [00:50<00:10, 1613942.37it/s]\r 91%|█████████ | 154533888/170498071 [00:50<00:09, 1642668.35it/s]\r 91%|█████████ | 154861568/170498071 [00:50<00:09, 1698102.54it/s]\r 91%|█████████ | 155189248/170498071 [00:50<00:08, 1765610.06it/s]\r 91%|█████████ | 155516928/170498071 [00:50<00:08, 1802382.65it/s]\r 91%|█████████▏| 155844608/170498071 [00:50<00:07, 1836260.15it/s]\r 92%|█████████▏| 156172288/170498071 [00:51<00:07, 1879026.32it/s]\r 92%|█████████▏| 156532736/170498071 [00:51<00:07, 1936760.68it/s]\r 92%|█████████▏| 156893184/170498071 [00:51<00:06, 1971080.82it/s]\r 92%|█████████▏| 157220864/170498071 [00:51<00:06, 1962173.76it/s]\r 92%|█████████▏| 157581312/170498071 [00:51<00:06, 1997692.92it/s]\r 93%|█████████▎| 157908992/170498071 [00:51<00:05, 2251379.95it/s]\r 93%|█████████▎| 158171136/170498071 [00:52<00:06, 2038152.52it/s]\r 93%|█████████▎| 158400512/170498071 [00:52<00:05, 2070915.98it/s]\r 93%|█████████▎| 158662656/170498071 [00:52<00:05, 2028921.15it/s]\r 93%|█████████▎| 158892032/170498071 [00:52<00:05, 2087817.88it/s]\r 93%|█████████▎| 159154176/170498071 [00:52<00:05, 2180611.46it/s]\r 94%|█████████▎| 159416320/170498071 [00:52<00:05, 2022597.24it/s]\r 94%|█████████▎| 159645696/170498071 [00:52<00:05, 2047411.91it/s]\r 94%|█████████▍| 159940608/170498071 [00:52<00:04, 2204451.27it/s]\r 94%|█████████▍| 160169984/170498071 [00:53<00:04, 2086933.05it/s]\r 94%|█████████▍| 160399360/170498071 [00:53<00:04, 2086451.25it/s]\r 94%|█████████▍| 160661504/170498071 [00:53<00:04, 2213384.84it/s]\r 94%|█████████▍| 160890880/170498071 [00:53<00:04, 2087391.92it/s]\r 94%|█████████▍| 161120256/170498071 [00:53<00:04, 2076007.91it/s]\r 95%|█████████▍| 161415168/170498071 [00:53<00:03, 2280666.84it/s]\r 95%|█████████▍| 161677312/170498071 [00:53<00:04, 2098736.97it/s]\r 95%|█████████▍| 161906688/170498071 [00:53<00:04, 2128874.92it/s]\r 95%|█████████▌| 162201600/170498071 [00:53<00:03, 2207318.19it/s]\r 95%|█████████▌| 162430976/170498071 [00:54<00:03, 2025151.24it/s]\r 95%|█████████▌| 162725888/170498071 [00:54<00:03, 2249147.67it/s]\r 96%|█████████▌| 162988032/170498071 [00:54<00:03, 1951236.36it/s]\r 96%|█████████▌| 163348480/170498071 [00:54<00:03, 2347283.55it/s]\r 96%|█████████▌| 163610624/170498071 [00:54<00:03, 2042143.53it/s]\r 96%|█████████▌| 163840000/170498071 [00:54<00:03, 2087165.64it/s]\r 96%|█████████▌| 164069376/170498071 [00:54<00:03, 2108543.21it/s]\r 96%|█████████▋| 164298752/170498071 [00:55<00:03, 1925464.43it/s]\r 97%|█████████▋| 164560896/170498071 [00:55<00:02, 2085104.73it/s]\r 97%|█████████▋| 164790272/170498071 [00:55<00:02, 2139216.08it/s]\r 97%|█████████▋| 165019648/170498071 [00:55<00:02, 2080212.77it/s]\r 97%|█████████▋| 165249024/170498071 [00:55<00:02, 2035109.66it/s]\r 97%|█████████▋| 165543936/170498071 [00:55<00:02, 2233040.69it/s]\r 97%|█████████▋| 165773312/170498071 [00:55<00:02, 2139003.36it/s]\r 97%|█████████▋| 166002688/170498071 [00:55<00:02, 2100545.63it/s]\r 97%|█████████▋| 166232064/170498071 [00:55<00:02, 2023093.44it/s]\r 98%|█████████▊| 166494208/170498071 [00:56<00:01, 2177918.64it/s]\r 98%|█████████▊| 166723584/170498071 [00:56<00:01, 2116784.89it/s]\r 98%|█████████▊| 166985728/170498071 [00:56<00:01, 2121397.95it/s]\r 98%|█████████▊| 167247872/170498071 [00:56<00:01, 2234763.22it/s]\r 98%|█████████▊| 167477248/170498071 [00:56<00:01, 2170764.43it/s]\r 98%|█████████▊| 167739392/170498071 [00:56<00:01, 2147222.38it/s]\r 99%|█████████▊| 167968768/170498071 [00:56<00:01, 2170961.69it/s]\r 99%|█████████▊| 168198144/170498071 [00:56<00:01, 2140786.05it/s]\r 99%|█████████▉| 168427520/170498071 [00:56<00:00, 2127483.43it/s]\r 99%|█████████▉| 168722432/170498071 [00:57<00:00, 2221089.65it/s]\r 99%|█████████▉| 168951808/170498071 [00:57<00:00, 2144422.91it/s]\r 99%|█████████▉| 169213952/170498071 [00:57<00:00, 2241924.21it/s]\r 99%|█████████▉| 169443328/170498071 [00:57<00:00, 1571189.18it/s]\r100%|█████████▉| 169967616/170498071 [00:57<00:00, 2206227.41it/s]\r100%|█████████▉| 170229760/170498071 [00:57<00:00, 2110958.15it/s]\r100%|█████████▉| 170459136/170498071 [00:57<00:00, 1930798.40it/s]\r100%|██████████| 170498071/170498071 [00:57<00:00, 2941778.59it/s]\n```\n:::\n:::\n\n\n### モデルの定義\n\n#### エンコーダー\n\nVQ-VAE は画像への応用を念頭に置いているため，エンコーダーには [CNN アーキテクチャ](../Kernels/Deep.qmd#sec-CNN) を採用する．\n\n::: {#c8c929e8 .cell execution_count=16}\n``` {.python .cell-code}\nclass Encoder(nn.Module):\n    \n    def __init__(self, input_dim, hidden_dim, output_dim, kernel_size=(4, 4, 3, 1), stride=2):\n        super(Encoder, self).__init__()\n        \n        kernel_1, kernel_2, kernel_3, kernel_4 = kernel_size\n        \n        self.strided_conv_1 = nn.Conv2d(input_dim, hidden_dim, kernel_1, stride, padding=1)\n        self.strided_conv_2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_2, stride, padding=1)\n        \n        self.residual_conv_1 = nn.Conv2d(hidden_dim, hidden_dim, kernel_3, padding=1)\n        self.residual_conv_2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_4, padding=0)\n        \n        self.proj = nn.Conv2d(hidden_dim, output_dim, kernel_size=1)\n        \n    def forward(self, x):\n        \n        x = self.strided_conv_1(x)\n        x = self.strided_conv_2(x)\n        \n        x = F.relu(x)\n        y = self.residual_conv_1(x)\n        y = y+x\n        \n        x = F.relu(y)\n        y = self.residual_conv_2(x)\n        y = y+x\n        \n        y = self.proj(y)\n        return y\n```\n:::\n\n\n## 参考文献 {.appendix}\n\n本稿は，[Minsu Jackson Kang 氏](https://velog.io/@mskang/about) による [チュートリアル](https://github.com/Jackson-Kang/Pytorch-VAE-tutorial) を参考にした．\n\nVAE の潜在表現は [t-SNE](https://ja.wikipedia.org/wiki/T分布型確率的近傍埋め込み法) などを用いて可視化でき，[@Murphy2023 p.635] の例などでも，潜在空間において手書き数字がクラスごとによく分離されていることが確認できる．\n\n",
    "supporting": [
      "VAE_files"
    ],
    "filters": [],
    "includes": {}
  }
}