{
  "hash": "3a3a21f029bb7b08123130a313873d19",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"正規化流\"\nsubtitle: \"`normflows` によるハンズオン\"\nauthor: \"司馬博文\"\ndate: 8/3/2024\ndate-modified: 8/19/2024\nimage: Files/NF/Glow_output.png\ncategories: [Deep, Sampling, Python]\nbibliography: \n    - ../../../assets/mathematics.bib\n    - ../../../assets/bib.bib\n    - ../../../assets/bib1.bib\ncsl: ../../../assets/apalike.csl\nabstract-title: 概要\nabstract: 確率分布を Gauss 潜在変数の非線型な押し出しとしてモデリングする．この押し出しを深層ニューラルネットワークでモデリングすれば，豊かな表現力が得られる．加えて，このニューラルネットワークを可逆に設計すれば，このモデルの尤度も評価することが出来る．今回は `PyTorch` を用いて，正規化流の実装の概要を見る．\ncode-fold: false\nlisting: \n    -   id: flow-listing\n        type: grid\n        sort: false\n        contents:\n            - \"NF.qmd\"\n            - \"NF1.qmd\"\n            - \"Diffusion.qmd\"\n        date-format: iso\n        fields: [title,image,date,subtitle]\n---\n\n::: {.hidden}\n\n::: {.content-visible when-format=\"html\"}\n\nA Blog Entry on Bayesian Computation by an Applied Mathematician\n\n$$\n\n\\renewcommand{\\P}{\\operatorname{P}}\\newcommand{\\E}{\\operatorname{E}}\n\\newcommand{\\R}{\\mathbb{R}}\\newcommand{\\F}{\\mathcal{F}}\n\\newcommand{\\abs}[1]{\\lvert#1\\rvert}\\newcommand{\\Abs}[1]{\\left|#1\\right|}\\newcommand{\\ABs}[1]{\\biggl|#1\\biggr|}\\newcommand{\\norm}[1]{\\|#1\\|}\\newcommand{\\Norm}[1]{\\left\\|#1\\right\\|}\\newcommand{\\NOrm}[1]{\\biggl\\|#1\\biggr\\|}\\newcommand{\\Brace}[1]{\\left\\{#1\\right\\}}\\newcommand{\\BRace}[1]{\\biggl\\{#1\\biggr\\}}\\newcommand{\\paren}[1]{\\left(#1\\right)}\\newcommand{\\Paren}[1]{\\biggr(#1\\biggl)}\\newcommand{\\brac}[1]{\\langle#1\\rangle}\\newcommand{\\Brac}[1]{\\left\\langle#1\\right\\rangle}\\newcommand{\\BRac}[1]{\\biggl\\langle#1\\biggr\\rangle}\\newcommand{\\bra}[1]{\\left\\langle#1\\right|}\\newcommand{\\ket}[1]{\\left|#1\\right\\rangle}\\newcommand{\\Square}[1]{\\left[#1\\right]}\\newcommand{\\SQuare}[1]{\\biggl[#1\\biggr]}\\newcommand{\\rN}{\\mathrm{N}}\\newcommand{\\ov}[1]{\\overline{#1}}\\newcommand{\\un}[1]{\\underline{#1}}\\newcommand{\\wt}[1]{\\widetilde{#1}}\\newcommand{\\wh}[1]{\\widehat{#1}}\\newcommand{\\pp}[2]{\\frac{\\partial #1}{\\partial #2}}\\newcommand{\\ppp}[3]{\\frac{\\partial #1}{\\partial #2\\partial #3}}\\newcommand{\\dd}[2]{\\frac{d #1}{d #2}}\\newcommand{\\floor}[1]{\\lfloor#1\\rfloor}\\newcommand{\\Floor}[1]{\\left\\lfloor#1\\right\\rfloor}\\newcommand{\\ceil}[1]{\\lceil#1\\rceil}\\newcommand{\\ocinterval}[1]{(#1]}\\newcommand{\\cointerval}[1]{[#1)}\\newcommand{\\COinterval}[1]{\\left[#1\\right)}\\newcommand{\\iso}{\\overset{\\sim}{\\to}}\n\n\n\n\\newcommand{\\y}{\\b{y}}\\newcommand{\\mi}{\\,|\\,}\\newcommand{\\Mark}{\\mathrm{Mark}}\n\\newcommand{\\argmax}{\\operatorname*{argmax}}\\newcommand{\\argmin}{\\operatorname*{argmin}}\n\n\\newcommand{\\pr}{\\mathrm{pr}}\\newcommand{\\Conv}{\\operatorname{Conv}}\\newcommand{\\cU}{\\mathcal{U}}\n\\newcommand{\\Map}{\\mathrm{Map}}\\newcommand{\\dom}{\\mathrm{Dom}\\;}\\newcommand{\\cod}{\\mathrm{Cod}\\;}\\newcommand{\\supp}{\\mathrm{supp}\\;}\n\\newcommand{\\grad}{\\operatorname{grad}}\\newcommand{\\rot}{\\operatorname{rot}}\\renewcommand{\\div}{\\operatorname{div}}\\newcommand{\\tr}{\\operatorname{tr}}\\newcommand{\\Tr}{\\operatorname{Tr}}\\newcommand{\\KL}{\\operatorname{KL}}\\newcommand{\\JS}{\\operatorname{JS}}\\newcommand{\\ESS}{\\operatorname{ESS}}\\newcommand{\\MSE}{\\operatorname{MSE}}\\newcommand{\\erf}{\\operatorname{erf}}\\newcommand{\\arctanh}{\\operatorname{arctanh}}\\newcommand{\\pl}{\\operatorname{pl}}\\newcommand{\\minimize}{\\operatorname{minimize}}\\newcommand{\\subjectto}{\\operatorname{subject to}}\\newcommand{\\sinc}{\\operatorname{sinc}}\\newcommand{\\Ent}{\\operatorname{Ent}}\\newcommand{\\Polya}{\\operatorname{Polya}}\\newcommand{\\Exp}{\\operatorname{Exp}}\\newcommand{\\codim}{\\operatorname{codim}}\\newcommand{\\sgn}{\\operatorname{sgn}}\\newcommand{\\rank}{\\operatorname{rank}}\n\n\\newcommand{\\vctr}[2]{\\begin{pmatrix}#1\\\\#2\\end{pmatrix}}\\newcommand{\\vctrr}[3]{\\begin{pmatrix}#1\\\\#2\\\\#3\\end{pmatrix}}\\newcommand{\\mtrx}[4]{\\begin{pmatrix}#1&#2\\\\#3&#4\\end{pmatrix}}\\newcommand{\\smtrx}[4]{\\paren{\\begin{smallmatrix}#1&#2\\\\#3&#4\\end{smallmatrix}}}\\newcommand{\\Ker}{\\mathrm{Ker}\\;}\\newcommand{\\Coker}{\\mathrm{Coker}\\;}\\newcommand{\\Coim}{\\mathrm{Coim}\\;}\\newcommand{\\lcm}{\\mathrm{lcm}}\\newcommand{\\GL}{\\mathrm{GL}}\\newcommand{\\SL}{\\mathrm{SL}}\\newcommand{\\alt}{\\mathrm{alt}}\n\n\\renewcommand{\\Re}{\\mathrm{Re}\\;}\\renewcommand{\\Im}{\\mathrm{Im}\\,}\\newcommand{\\Gal}{\\mathrm{Gal}}\\newcommand{\\PGL}{\\mathrm{PGL}}\\newcommand{\\PSL}{\\mathrm{PSL}}\\newcommand{\\Log}{\\mathrm{Log}\\,}\\newcommand{\\Res}{\\mathrm{Res}\\,}\\newcommand{\\on}{\\mathrm{on}\\;}\\newcommand{\\hatC}{\\widehat{\\C}}\\newcommand{\\hatR}{\\hat{\\R}}\\newcommand{\\PV}{\\mathrm{P.V.}}\\newcommand{\\diam}{\\mathrm{diam}}\\newcommand{\\Area}{\\mathrm{Area}}\\newcommand{\\Lap}{\\Laplace}\\newcommand{\\f}{\\mathbf{f}}\\newcommand{\\cR}{\\mathcal{R}}\\newcommand{\\const}{\\mathrm{const.}}\\newcommand{\\Om}{\\Omega}\\newcommand{\\Cinf}{C^\\infty}\\newcommand{\\ep}{\\epsilon}\\newcommand{\\dist}{\\mathrm{dist}}\\newcommand{\\opart}{\\o{\\partial}}\\newcommand{\\Length}{\\mathrm{Length}}\n\n\\newcommand{\\cA}{\\mathcal{A}}\\newcommand{\\cO}{\\mathcal{O}}\\newcommand{\\cW}{\\mathcal{W}}\\renewcommand{\\O}{\\mathcal{O}}\\renewcommand{\\S}{\\mathcal{S}}\\newcommand{\\U}{\\mathcal{U}}\\newcommand{\\V}{\\mathrm{V}}\\newcommand{\\N}{\\mathbb{N}}\\newcommand{\\bN}{\\mathbb{N}}\\newcommand{\\C}{\\mathrm{C}}\\newcommand{\\bC}{\\mathbb{C}}\\newcommand{\\Z}{\\mathcal{Z}}\\newcommand{\\Q}{\\mathbb{Q}}\\newcommand{\\bQ}{\\mathbb{Q}}\\newcommand{\\TV}{\\mathrm{TV}}\\newcommand{\\ORD}{\\mathrm{ORD}}\\newcommand{\\Card}{\\mathrm{Card}\\,}\\newcommand{\\Top}{\\mathrm{Top}}\\newcommand{\\Disc}{\\mathrm{Disc}}\\newcommand{\\Codisc}{\\mathrm{Codisc}}\\newcommand{\\CoDisc}{\\mathrm{CoDisc}}\\newcommand{\\Ult}{\\mathrm{Ult}}\\newcommand{\\ord}{\\mathrm{ord}}\\newcommand{\\bS}{\\mathbb{S}}\\newcommand{\\PConn}{\\mathrm{PConn}}\\newcommand{\\mult}{\\mathrm{mult}}\\newcommand{\\inv}{\\mathrm{inv}}\n\n\\newcommand{\\Der}{\\mathrm{Der}}\\newcommand{\\osub}{\\overset{\\mathrm{open}}{\\subset}}\\newcommand{\\osup}{\\overset{\\mathrm{open}}{\\supset}}\\newcommand{\\al}{\\alpha}\\newcommand{\\K}{\\mathbb{K}}\\newcommand{\\Sp}{\\mathrm{Sp}}\\newcommand{\\g}{\\mathfrak{g}}\\newcommand{\\h}{\\mathfrak{h}}\\newcommand{\\Imm}{\\mathrm{Imm}}\\newcommand{\\Imb}{\\mathrm{Imb}}\\newcommand{\\Gr}{\\mathrm{Gr}}\n\n\\newcommand{\\Ad}{\\mathrm{Ad}}\\newcommand{\\finsupp}{\\mathrm{fin\\;supp}}\\newcommand{\\SO}{\\mathrm{SO}}\\newcommand{\\SU}{\\mathrm{SU}}\\newcommand{\\acts}{\\curvearrowright}\\newcommand{\\mono}{\\hookrightarrow}\\newcommand{\\epi}{\\twoheadrightarrow}\\newcommand{\\Stab}{\\mathrm{Stab}}\\newcommand{\\nor}{\\mathrm{nor}}\\newcommand{\\T}{\\mathbb{T}}\\newcommand{\\Aff}{\\mathrm{Aff}}\\newcommand{\\rsup}{\\triangleright}\\newcommand{\\subgrp}{\\overset{\\mathrm{subgrp}}{\\subset}}\\newcommand{\\Ext}{\\mathrm{Ext}}\\newcommand{\\sbs}{\\subset}\\newcommand{\\sps}{\\supset}\\newcommand{\\In}{\\mathrm{in}\\;}\\newcommand{\\Tor}{\\mathrm{Tor}}\\newcommand{\\p}{\\b{p}}\\newcommand{\\q}{\\mathfrak{q}}\\newcommand{\\m}{\\mathfrak{m}}\\newcommand{\\cS}{\\mathcal{S}}\\newcommand{\\Frac}{\\mathrm{Frac}\\,}\\newcommand{\\Spec}{\\mathrm{Spec}\\,}\\newcommand{\\bA}{\\mathbb{A}}\\newcommand{\\Sym}{\\mathrm{Sym}}\\newcommand{\\Ann}{\\mathrm{Ann}}\\newcommand{\\Her}{\\mathrm{Her}}\\newcommand{\\Bil}{\\mathrm{Bil}}\\newcommand{\\Ses}{\\mathrm{Ses}}\\newcommand{\\FVS}{\\mathrm{FVS}}\n\n\\newcommand{\\Ho}{\\mathrm{Ho}}\\newcommand{\\CW}{\\mathrm{CW}}\\newcommand{\\lc}{\\mathrm{lc}}\\newcommand{\\cg}{\\mathrm{cg}}\\newcommand{\\Fib}{\\mathrm{Fib}}\\newcommand{\\Cyl}{\\mathrm{Cyl}}\\newcommand{\\Ch}{\\mathrm{Ch}}\n\\newcommand{\\rP}{\\mathrm{P}}\\newcommand{\\rE}{\\mathrm{E}}\\newcommand{\\e}{\\b{e}}\\renewcommand{\\k}{\\b{k}}\\newcommand{\\Christ}[2]{\\begin{Bmatrix}#1\\\\#2\\end{Bmatrix}}\\renewcommand{\\Vec}[1]{\\overrightarrow{\\mathrm{#1}}}\\newcommand{\\hen}[1]{\\mathrm{#1}}\\renewcommand{\\b}[1]{\\boldsymbol{#1}}\n\n\\newcommand{\\Inc}{\\mathrm{Inc}}\\newcommand{\\aInc}{\\mathrm{aInc}}\\newcommand{\\HS}{\\mathrm{HS}}\\newcommand{\\loc}{\\mathrm{loc}}\\newcommand{\\Lh}{\\mathrm{L.h.}}\\newcommand{\\Epi}{\\mathrm{Epi}}\\newcommand{\\slim}{\\mathrm{slim}}\\newcommand{\\Ban}{\\mathrm{Ban}}\\newcommand{\\Hilb}{\\mathrm{Hilb}}\\newcommand{\\Ex}{\\mathrm{Ex}}\\newcommand{\\Co}{\\mathrm{Co}}\\newcommand{\\sa}{\\mathrm{sa}}\\newcommand{\\nnorm}[1]{{\\left\\vert\\kern-0.25ex\\left\\vert\\kern-0.25ex\\left\\vert #1 \\right\\vert\\kern-0.25ex\\right\\vert\\kern-0.25ex\\right\\vert}}\\newcommand{\\dvol}{\\mathrm{dvol}}\\newcommand{\\Sconv}{\\mathrm{Sconv}}\\newcommand{\\I}{\\mathcal{I}}\\newcommand{\\nonunital}{\\mathrm{nu}}\\newcommand{\\cpt}{\\mathrm{cpt}}\\newcommand{\\lcpt}{\\mathrm{lcpt}}\\newcommand{\\com}{\\mathrm{com}}\\newcommand{\\Haus}{\\mathrm{Haus}}\\newcommand{\\proper}{\\mathrm{proper}}\\newcommand{\\infinity}{\\mathrm{inf}}\\newcommand{\\TVS}{\\mathrm{TVS}}\\newcommand{\\ess}{\\mathrm{ess}}\\newcommand{\\ext}{\\mathrm{ext}}\\newcommand{\\Index}{\\mathrm{Index}\\;}\\newcommand{\\SSR}{\\mathrm{SSR}}\\newcommand{\\vs}{\\mathrm{vs.}}\\newcommand{\\fM}{\\mathfrak{M}}\\newcommand{\\EDM}{\\mathrm{EDM}}\\newcommand{\\Tw}{\\mathrm{Tw}}\\newcommand{\\fC}{\\mathfrak{C}}\\newcommand{\\bn}{\\boldsymbol{n}}\\newcommand{\\br}{\\boldsymbol{r}}\\newcommand{\\Lam}{\\Lambda}\\newcommand{\\lam}{\\lambda}\\newcommand{\\one}{\\mathbf{1}}\\newcommand{\\dae}{\\text{-a.e.}}\\newcommand{\\das}{\\text{-a.s.}}\\newcommand{\\td}{\\text{-}}\\newcommand{\\RM}{\\mathrm{RM}}\\newcommand{\\BV}{\\mathrm{BV}}\\newcommand{\\normal}{\\mathrm{normal}}\\newcommand{\\lub}{\\mathrm{lub}\\;}\\newcommand{\\Graph}{\\mathrm{Graph}}\\newcommand{\\Ascent}{\\mathrm{Ascent}}\\newcommand{\\Descent}{\\mathrm{Descent}}\\newcommand{\\BIL}{\\mathrm{BIL}}\\newcommand{\\fL}{\\mathfrak{L}}\\newcommand{\\De}{\\Delta}\n\n\\newcommand{\\calA}{\\mathcal{A}}\\newcommand{\\calB}{\\mathcal{B}}\\newcommand{\\D}{\\mathcal{D}}\\newcommand{\\Y}{\\mathcal{Y}}\\newcommand{\\calC}{\\mathcal{C}}\\renewcommand{\\ae}{\\mathrm{a.e.}\\;}\\newcommand{\\cZ}{\\mathcal{Z}}\\newcommand{\\fF}{\\mathfrak{F}}\\newcommand{\\fI}{\\mathfrak{I}}\\newcommand{\\rV}{\\mathrm{V}}\\newcommand{\\cE}{\\mathcal{E}}\\newcommand{\\sMap}{\\sigma\\textrm{-}\\mathrm{Map}}\\newcommand{\\cC}{\\mathcal{C}}\\newcommand{\\comp}{\\complement}\\newcommand{\\J}{\\mathcal{J}}\\newcommand{\\sumN}[1]{\\sum_{#1\\in\\N}}\\newcommand{\\cupN}[1]{\\cup_{#1\\in\\N}}\\newcommand{\\capN}[1]{\\cap_{#1\\in\\N}}\\newcommand{\\Sum}[1]{\\sum_{#1=1}^\\infty}\\newcommand{\\sumn}{\\sum_{n=1}^\\infty}\\newcommand{\\summ}{\\sum_{m=1}^\\infty}\\newcommand{\\sumk}{\\sum_{k=1}^\\infty}\\newcommand{\\sumi}{\\sum_{i=1}^\\infty}\\newcommand{\\sumj}{\\sum_{j=1}^\\infty}\\newcommand{\\cupn}{\\cup_{n=1}^\\infty}\\newcommand{\\capn}{\\cap_{n=1}^\\infty}\\newcommand{\\cupk}{\\cup_{k=1}^\\infty}\\newcommand{\\cupi}{\\cup_{i=1}^\\infty}\\newcommand{\\cupj}{\\cup_{j=1}^\\infty}\\newcommand{\\limn}{\\lim_{n\\to\\infty}}\\renewcommand{\\L}{\\mathcal{L}}\\newcommand{\\cL}{\\mathcal{L}}\\newcommand{\\Cl}{\\mathrm{Cl}}\\newcommand{\\cN}{\\mathcal{N}}\\newcommand{\\Ae}{\\textrm{-a.e.}\\;}\\renewcommand{\\csub}{\\overset{\\textrm{closed}}{\\subset}}\\renewcommand{\\csup}{\\overset{\\textrm{closed}}{\\supset}}\\newcommand{\\wB}{\\wt{B}}\\newcommand{\\cG}{\\mathcal{G}}\\newcommand{\\Lip}{\\mathrm{Lip}}\\newcommand{\\AC}{\\mathrm{AC}}\\newcommand{\\Mol}{\\mathrm{Mol}}\n\n\\newcommand{\\Pe}{\\mathrm{Pe}}\\newcommand{\\wR}{\\wh{\\mathbb{\\R}}}\\newcommand*{\\Laplace}{\\mathop{}\\!\\mathbin\\bigtriangleup}\\newcommand*{\\DAlambert}{\\mathop{}\\!\\mathbin\\Box}\\newcommand{\\bT}{\\mathbb{T}}\\newcommand{\\dx}{\\dslash x}\\newcommand{\\dt}{\\dslash t}\\newcommand{\\ds}{\\dslash s}\n\n\\newcommand{\\round}{\\mathrm{round}}\\newcommand{\\cond}{\\mathrm{cond}}\\newcommand{\\diag}{\\mathrm{diag}}\n\\newcommand{\\Adj}{\\mathrm{Adj}}\\newcommand{\\Pf}{\\mathrm{Pf}}\\newcommand{\\Sg}{\\mathrm{Sg}}\n\n\n\\newcommand{\\aseq}{\\overset{\\text{a.s.}}{=}}\\newcommand{\\deq}{\\overset{\\text{d}}{=}}\\newcommand{\\cV}{\\mathcal{V}}\\newcommand{\\FM}{\\mathrm{FM}}\\newcommand{\\KR}{\\mathrm{KR}}\\newcommand{\\rba}{\\mathrm{rba}}\\newcommand{\\rca}{\\mathrm{rca}}\\newcommand{\\Prob}{\\mathrm{Prob}}\\newcommand{\\X}{\\mathcal{X}}\\newcommand{\\Meas}{\\mathrm{Meas}}\\newcommand{\\as}{\\;\\text{a.s.}}\\newcommand{\\io}{\\;\\mathrm{i.o.}}\\newcommand{\\fe}{\\;\\text{f.e.}}\\newcommand{\\bF}{\\mathbb{F}}\\newcommand{\\W}{\\mathcal{W}}\\newcommand{\\Pois}{\\mathrm{Pois}}\\newcommand{\\iid}{\\text{i.i.d.}}\\newcommand{\\wconv}{\\rightsquigarrow}\\newcommand{\\Var}{\\mathrm{Var}}\\newcommand{\\xrightarrown}{\\xrightarrow{n\\to\\infty}}\\newcommand{\\au}{\\mathrm{au}}\\newcommand{\\cT}{\\mathcal{T}}\\newcommand{\\wto}{\\overset{\\text{w}}{\\to}}\\newcommand{\\dto}{\\overset{\\text{d}}{\\to}}\\newcommand{\\sto}{\\overset{\\text{s}}{\\to}}\\newcommand{\\pto}{\\overset{\\text{p}}{\\to}}\\newcommand{\\mto}{\\overset{\\text{m}}{\\to}}\\newcommand{\\vto}{\\overset{v}{\\to}}\\newcommand{\\Cont}{\\mathrm{Cont}}\\newcommand{\\stably}{\\mathrm{stably}}\\newcommand{\\Np}{\\mathbb{N}^+}\\newcommand{\\oM}{\\overline{\\mathcal{M}}}\\newcommand{\\fP}{\\mathfrak{P}}\\newcommand{\\sign}{\\mathrm{sign}}\n\\newcommand{\\Borel}{\\mathrm{Borel}}\\newcommand{\\Mid}{\\,|\\,}\\newcommand{\\middleMid}{\\;\\middle|\\;}\\newcommand{\\CP}{\\mathrm{CP}}\\newcommand{\\bD}{\\mathbb{D}}\\newcommand{\\bL}{\\mathbb{L}}\\newcommand{\\fW}{\\mathfrak{W}}\\newcommand{\\DL}{\\mathcal{D}\\mathcal{L}}\\renewcommand{\\r}[1]{\\mathrm{#1}}\\newcommand{\\rC}{\\mathrm{C}}\\newcommand{\\qqquad}{\\qquad\\quad}\n\n\\newcommand{\\bit}{\\mathrm{bit}}\n\n\\newcommand{\\err}{\\mathrm{err}}\n\n\\newcommand{\\varparallel}{\\mathbin{\\!/\\mkern-5mu/\\!}}\\newcommand{\\Ri}{\\mathrm{Ri}}\\newcommand{\\Cone}{\\mathrm{Cone}}\\newcommand{\\Int}{\\mathrm{Int}}\n\n\\newcommand{\\pre}{\\mathrm{pre}}\\newcommand{\\om}{\\omega}\n\n\n\\newcommand{\\del}{\\partial}\n\\newcommand{\\LHS}{\\mathrm{LHS}}\\newcommand{\\RHS}{\\mathrm{RHS}}\\newcommand{\\bnu}{\\boldsymbol{\\nu}}\\newcommand{\\interior}{\\mathrm{in}\\;}\\newcommand{\\SH}{\\mathrm{SH}}\\renewcommand{\\v}{\\boldsymbol{\\nu}}\\newcommand{\\n}{\\mathbf{n}}\\newcommand{\\ssub}{\\Subset}\\newcommand{\\curl}{\\mathrm{curl}}\n\n\\newcommand{\\Ei}{\\mathrm{Ei}}\\newcommand{\\sn}{\\mathrm{sn}}\\newcommand{\\wgamma}{\\widetilde{\\gamma}}\n\n\\newcommand{\\Ens}{\\mathrm{Ens}}\n\n\\newcommand{\\cl}{\\mathrm{cl}}\\newcommand{\\x}{\\boldsymbol{x}}\n\n\\newcommand{\\Do}{\\mathrm{Do}}\\newcommand{\\IV}{\\mathrm{IV}}\n\n\\newcommand{\\AIC}{\\mathrm{AIC}}\\newcommand{\\mrl}{\\mathrm{mrl}}\\newcommand{\\dotx}{\\dot{x}}\\newcommand{\\UMV}{\\mathrm{UMV}}\\newcommand{\\BLU}{\\mathrm{BLU}}\n\n\\newcommand{\\comb}[2]{\\begin{pmatrix}#1\\\\#2\\end{pmatrix}}\\newcommand{\\bP}{\\mathbb{P}}\\newcommand{\\compsub}{\\overset{\\textrm{cpt}}{\\subset}}\\newcommand{\\lip}{\\textrm{lip}}\\newcommand{\\BL}{\\mathrm{BL}}\\newcommand{\\G}{\\mathbb{G}}\\newcommand{\\NB}{\\mathrm{NB}}\\newcommand{\\oR}{\\ov{\\R}}\\newcommand{\\liminfn}{\\liminf_{n\\to\\infty}}\\newcommand{\\limsupn}{\\limsup_{n\\to\\infty}}\\newcommand{\\esssup}{\\mathrm{ess.sup}}\\newcommand{\\asto}{\\xrightarrow{\\as}}\\newcommand{\\Cov}{\\mathrm{Cov}}\\newcommand{\\cQ}{\\mathcal{Q}}\\newcommand{\\VC}{\\mathrm{VC}}\\newcommand{\\mb}{\\mathrm{mb}}\\newcommand{\\Avar}{\\mathrm{Avar}}\\newcommand{\\bB}{\\mathbb{B}}\\newcommand{\\bW}{\\mathbb{W}}\\newcommand{\\sd}{\\mathrm{sd}}\\newcommand{\\w}[1]{\\widehat{#1}}\\newcommand{\\bZ}{\\mathbb{Z}}\\newcommand{\\Bernoulli}{\\mathrm{Ber}}\\newcommand{\\Ber}{\\mathrm{Ber}}\\newcommand{\\Mult}{\\mathrm{Mult}}\\newcommand{\\BPois}{\\mathrm{BPois}}\\newcommand{\\fraks}{\\mathfrak{s}}\\newcommand{\\frakk}{\\mathfrak{k}}\\newcommand{\\IF}{\\mathrm{IF}}\\newcommand{\\bX}{\\boldsymbol{X}}\\newcommand{\\bx}{\\boldsymbol{x}}\\newcommand{\\indep}{\\perp\\!\\!\\!\\perp}\\newcommand{\\IG}{\\mathrm{IG}}\\newcommand{\\Levy}{\\mathrm{Levy}}\\newcommand{\\MP}{\\mathrm{MP}}\\newcommand{\\Hermite}{\\mathrm{Hermite}}\\newcommand{\\Skellam}{\\mathrm{Skellam}}\\newcommand{\\Dirichlet}{\\mathrm{Dirichlet}}\\renewcommand{\\Beta}{\\mathrm{Beta}}\\newcommand{\\bE}{\\mathbb{E}}\\newcommand{\\bG}{\\mathbb{G}}\\newcommand{\\MISE}{\\mathrm{MISE}}\\newcommand{\\logit}{\\mathtt{logit}}\\newcommand{\\expit}{\\mathtt{expit}}\\newcommand{\\cK}{\\mathcal{K}}\\newcommand{\\dl}{\\dot{l}}\\newcommand{\\dotp}{\\dot{p}}\\newcommand{\\wl}{\\wt{l}}\\newcommand{\\Gauss}{\\mathrm{Gauss}}\\newcommand{\\fA}{\\mathfrak{A}}\\newcommand{\\under}{\\mathrm{under}\\;}\\newcommand{\\whtheta}{\\wh{\\theta}}\\newcommand{\\Em}{\\mathrm{Em}}\\newcommand{\\ztheta}{{\\theta_0}}\n\\newcommand{\\rO}{\\mathrm{O}}\\newcommand{\\Bin}{\\mathrm{Bin}}\\newcommand{\\rW}{\\mathrm{W}}\\newcommand{\\rG}{\\mathrm{G}}\\newcommand{\\rB}{\\mathrm{B}}\\newcommand{\\rU}{\\mathrm{U}}\\newcommand{\\HG}{\\mathrm{HG}}\\newcommand{\\GAMMA}{\\mathrm{Gamma}}\\newcommand{\\Cauchy}{\\mathrm{Cauchy}}\\newcommand{\\rt}{\\mathrm{t}}\\newcommand{\\rF}{\\mathrm{F}}\n\\newcommand{\\FE}{\\mathrm{FE}}\\newcommand{\\bV}{\\boldsymbol{V}}\\newcommand{\\GLS}{\\mathrm{GLS}}\\newcommand{\\be}{\\boldsymbol{e}}\\newcommand{\\POOL}{\\mathrm{POOL}}\\newcommand{\\GMM}{\\mathrm{GMM}}\\newcommand{\\MM}{\\mathrm{MM}}\\newcommand{\\SSIV}{\\mathrm{SSIV}}\\newcommand{\\JIV}{\\mathrm{JIV}}\\newcommand{\\AR}{\\mathrm{AR}}\\newcommand{\\ILS}{\\mathrm{ILS}}\\newcommand{\\SLS}{\\mathrm{SLS}}\\newcommand{\\LIML}{\\mathrm{LIML}}\n\n\\newcommand{\\Rad}{\\mathrm{Rad}}\\newcommand{\\bY}{\\boldsymbol{Y}}\\newcommand{\\pone}{{(1)}}\\newcommand{\\ptwo}{{(2)}}\\newcommand{\\ps}[1]{{(#1)}}\\newcommand{\\fsub}{\\overset{\\text{finite}}{\\subset}}\n\n\n\\newcommand{\\varlim}{\\varprojlim}\\newcommand{\\Hom}{\\mathrm{Hom}}\\newcommand{\\Iso}{\\mathrm{Iso}}\\newcommand{\\Mor}{\\mathrm{Mor}}\\newcommand{\\Isom}{\\mathrm{Isom}}\\newcommand{\\Aut}{\\mathrm{Aut}}\\newcommand{\\End}{\\mathrm{End}}\\newcommand{\\op}{\\mathrm{op}}\\newcommand{\\ev}{\\mathrm{ev}}\\newcommand{\\Ob}{\\mathrm{Ob}}\\newcommand{\\Ar}{\\mathrm{Ar}}\\newcommand{\\Arr}{\\mathrm{Arr}}\\newcommand{\\Set}{\\mathrm{Set}}\\newcommand{\\Grp}{\\mathrm{Grp}}\\newcommand{\\Cat}{\\mathrm{Cat}}\\newcommand{\\Mon}{\\mathrm{Mon}}\\newcommand{\\Ring}{\\mathrm{Ring}}\\newcommand{\\CRing}{\\mathrm{CRing}}\\newcommand{\\Ab}{\\mathrm{Ab}}\\newcommand{\\Pos}{\\mathrm{Pos}}\\newcommand{\\Vect}{\\mathrm{Vect}}\\newcommand{\\FinVect}{\\mathrm{FinVect}}\\newcommand{\\FinSet}{\\mathrm{FinSet}}\\newcommand{\\FinMeas}{\\mathrm{FinMeas}}\\newcommand{\\OmegaAlg}{\\Omega\\text{-}\\mathrm{Alg}}\\newcommand{\\OmegaEAlg}{(\\Omega,E)\\text{-}\\mathrm{Alg}}\\newcommand{\\Fun}{\\mathrm{Fun}}\\newcommand{\\Func}{\\mathrm{Func}}\n\n\\newcommand{\\Stoch}{\\mathrm{Stoch}}\\newcommand{\\FinStoch}{\\mathrm{FinStoch}}\\newcommand{\\Copy}{\\mathrm{copy}}\\newcommand{\\Delete}{\\mathrm{delete}}\n\\newcommand{\\Bool}{\\mathrm{Bool}}\\newcommand{\\CABool}{\\mathrm{CABool}}\\newcommand{\\CompBoolAlg}{\\mathrm{CompBoolAlg}}\\newcommand{\\BoolAlg}{\\mathrm{BoolAlg}}\\newcommand{\\BoolRng}{\\mathrm{BoolRng}}\\newcommand{\\HeytAlg}{\\mathrm{HeytAlg}}\\newcommand{\\CompHeytAlg}{\\mathrm{CompHeytAlg}}\\newcommand{\\Lat}{\\mathrm{Lat}}\\newcommand{\\CompLat}{\\mathrm{CompLat}}\\newcommand{\\SemiLat}{\\mathrm{SemiLat}}\\newcommand{\\Stone}{\\mathrm{Stone}}\\newcommand{\\Mfd}{\\mathrm{Mfd}}\\newcommand{\\LieAlg}{\\mathrm{LieAlg}}\n\\newcommand{\\Op}{\\mathrm{Op}}\n\\newcommand{\\Sh}{\\mathrm{Sh}}\n\\newcommand{\\Diff}{\\mathrm{Diff}}\n\\newcommand{\\B}{\\mathcal{B}}\\newcommand{\\cB}{\\mathcal{B}}\\newcommand{\\Span}{\\mathrm{Span}}\\newcommand{\\Corr}{\\mathrm{Corr}}\\newcommand{\\Decat}{\\mathrm{Decat}}\\newcommand{\\Rep}{\\mathrm{Rep}}\\newcommand{\\Grpd}{\\mathrm{Grpd}}\\newcommand{\\sSet}{\\mathrm{sSet}}\\newcommand{\\Mod}{\\mathrm{Mod}}\\newcommand{\\SmoothMnf}{\\mathrm{SmoothMnf}}\\newcommand{\\coker}{\\mathrm{coker}}\\newcommand{\\Ord}{\\mathrm{Ord}}\\newcommand{\\eq}{\\mathrm{eq}}\\newcommand{\\coeq}{\\mathrm{coeq}}\\newcommand{\\act}{\\mathrm{act}}\n\n\\newcommand{\\apf}{\\mathrm{apf}}\\newcommand{\\opt}{\\mathrm{opt}}\\newcommand{\\IS}{\\mathrm{IS}}\\newcommand{\\IR}{\\mathrm{IR}}\\newcommand{\\iidsim}{\\overset{\\text{iid}}{\\sim}}\\newcommand{\\propt}{\\,\\propto\\,}\\newcommand{\\bM}{\\mathbb{M}}\\newcommand{\\cX}{\\mathcal{X}}\\newcommand{\\cY}{\\mathcal{Y}}\\newcommand{\\cP}{\\mathcal{P}}\\newcommand{\\ola}[1]{\\overleftarrow{#1}}\n\n\\renewcommand{\\iff}{\\;\\mathrm{iff}\\;}\n\\newcommand{\\False}{\\mathrm{False}}\\newcommand{\\True}{\\mathrm{True}}\n\\newcommand{\\otherwise}{\\mathrm{otherwise}}\n\\newcommand{\\suchthat}{\\;\\mathrm{s.t.}\\;}\n\n\\newcommand{\\cM}{\\mathcal{M}}\\newcommand{\\M}{\\mathbb{M}}\\newcommand{\\cF}{\\mathcal{F}}\\newcommand{\\cD}{\\mathcal{D}}\\newcommand{\\fX}{\\mathfrak{X}}\\newcommand{\\fY}{\\mathfrak{Y}}\\newcommand{\\fZ}{\\mathfrak{Z}}\\renewcommand{\\H}{\\mathcal{H}}\\newcommand{\\cH}{\\mathcal{H}}\\newcommand{\\fH}{\\mathfrak{H}}\\newcommand{\\bH}{\\mathbb{H}}\\newcommand{\\id}{\\mathrm{id}}\\newcommand{\\A}{\\mathcal{A}}\n\\newcommand{\\lmd}{\\lambda}\n\\newcommand{\\Lmd}{\\Lambda}\n\\newcommand{\\cI}{\\mathcal{I}}\n\n\\newcommand{\\Lrarrow}{\\;\\;\\Leftrightarrow\\;\\;}\n\\DeclareMathOperator{\\des}{des}\n\\DeclareMathOperator{\\nd}{nd}\n\\DeclareMathOperator{\\dsep}{d-sep}\n\\DeclareMathOperator{\\sep}{sep}\n$$\n\n:::\n\n:::\n\n\n\n### 関連ページ {.unnumbered .unlisted}\n\n::: {#flow-listing}\n:::\n\n\n```{=html}\n<div class=\"article-card-container\">\n    <div class=\"article-card\">\n        <a href=\"https://162348.github.io/posts/2024/Samplers/NF.html\" target=\"_blank\">\n            <img src=\"https://162348.github.io/posts/2024/Samplers/Files/NF2.png\" alt=\"Article Image\" class=\"article-image\">\n            <div class=\"article-content\">\n                <h3 class=\"article-title\">正規化流</h3>\n                <p class=\"article-description\">深層生成モデル４</p>\n            </div>\n        </a>\n    </div>\n</div>\n```\n\n\n## Real NVP [@Dinh+2017]\n\n::: {#a6e8370b .cell execution_count=2}\n``` {.python .cell-code}\n# Import required packages\nimport torch\nimport torchvision as tv\nimport numpy as np\nimport normflows as nf\n\nfrom matplotlib import pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\n\nfrom tqdm import tqdm\n```\n:::\n\n\n::: {#38109043 .cell execution_count=3}\n``` {.python .cell-code}\n# Set up model\n\n# Define 2D Gaussian base distribution\nbase = nf.distributions.base.DiagGaussian(2)\n\n# Define list of flows\nnum_layers = 32\nflows = []\nfor i in range(num_layers):\n    # Neural network with two hidden layers having 64 units each\n    # Last layer is initialized by zeros making training more stable\n    param_map = nf.nets.MLP([1, 64, 64, 2], init_zeros=True)\n    # Add flow layer\n    flows.append(nf.flows.AffineCouplingBlock(param_map))\n    # Swap dimensions\n    flows.append(nf.flows.Permute(2, mode='swap'))\n    \n# Construct flow model\nmodel = nf.NormalizingFlow(base, flows)\ndevice = torch.device(\"mps\")\nmodel = model.to(device)\n```\n:::\n\n\n::: {#9430f9d1 .cell execution_count=4}\n``` {.python .cell-code}\n# Define target distribution\ntarget = nf.distributions.TwoMoons()\n\n# Plot target distribution\ngrid_size = 200\nxx, yy = torch.meshgrid(torch.linspace(-3, 3, grid_size), torch.linspace(-3, 3, grid_size))\nzz = torch.cat([xx.unsqueeze(2), yy.unsqueeze(2)], 2).view(-1, 2)\nzz = zz.to(device)\n\nlog_prob = target.log_prob(zz).to('cpu').view(*xx.shape)\nprob = torch.exp(log_prob)\nprob[torch.isnan(prob)] = 0\n\n# plt.figure(figsize=(15, 15))\nplt.pcolormesh(xx, yy, prob.data.numpy(), cmap='coolwarm')\nplt.gca().set_aspect('equal', 'box')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](NF2_files/figure-html/cell-4-output-1.png){width=347 height=341}\n:::\n:::\n\n\n::: {#22c827ea .cell execution_count=5}\n``` {.python .cell-code}\n# Plot initial flow distribution\nmodel.eval()\nlog_prob = model.log_prob(zz).to('cpu').view(*xx.shape)\nmodel.train()\nprob = torch.exp(log_prob)\nprob[torch.isnan(prob)] = 0\n\n# plt.figure(figsize=(15, 15))\nplt.pcolormesh(xx, yy, prob.data.numpy(), cmap='coolwarm')\nplt.gca().set_aspect('equal', 'box')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](NF2_files/figure-html/cell-5-output-1.png){width=347 height=341}\n:::\n:::\n\n\n::: {#e6fc4c0d .cell layout-ncol='4' layout-nrow='2' execution_count=6}\n``` {.python .cell-code}\n# Train model\nmax_iter = 4000\nnum_samples = 2 ** 9\nshow_iter = 500\n\n\nloss_hist = np.array([])\n\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-5)\n\nfor it in tqdm(range(max_iter)#, disable=True\n):\n    optimizer.zero_grad()\n    \n    # Get training samples\n    x = target.sample(num_samples).to(device)\n    \n    # Compute loss\n    loss = model.forward_kld(x)\n    \n    # Do backprop and optimizer step\n    if ~(torch.isnan(loss) | torch.isinf(loss)):\n        loss.backward()\n        optimizer.step()\n    \n    # Log loss\n    loss_hist = np.append(loss_hist, loss.to('cpu').data.numpy())\n    \n    # Plot learned distribution\n    if (it + 1) % show_iter == 0:\n        model.eval()\n        log_prob = model.log_prob(zz)\n        model.train()\n        prob = torch.exp(log_prob.to('cpu').view(*xx.shape))\n        prob[torch.isnan(prob)] = 0\n\n        # plt.figure(figsize=(15, 15))\n        plt.pcolormesh(xx, yy, prob.data.numpy(), cmap='coolwarm')\n        plt.gca().set_aspect('equal', 'box')\n        plt.show()\nnp.save('loss_history.npy', loss_hist)\n```\n:::\n\n\n::: {#9b9296ff .cell execution_count=7}\n``` {.python .cell-code}\n# Plot loss\n# plt.figure(figsize=(10, 10))\nloss_hist = np.load('Files/loss_history.npy')\nplt.plot(loss_hist, label='loss')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](NF2_files/figure-html/cell-7-output-1.png){width=496 height=337}\n:::\n:::\n\n\n::: {#ff291ecb .cell execution_count=8}\n``` {.python .cell-code}\n# Plot target distribution\nf, ax = plt.subplots(1, 2, sharey=True, figsize=(15, 7))\n\nlog_prob = target.log_prob(zz).to('cpu').view(*xx.shape)\nprob = torch.exp(log_prob)\nprob[torch.isnan(prob)] = 0\n\nax[0].pcolormesh(xx, yy, prob.data.numpy(), cmap='coolwarm')\n\nax[0].set_aspect('equal', 'box')\nax[0].set_axis_off()\nax[0].set_title('Target', fontsize=24)\n\n# Plot learned distribution\nmodel.eval()\nlog_prob = model.log_prob(zz).to('cpu').view(*xx.shape)\nmodel.train()\nprob = torch.exp(log_prob)\nprob[torch.isnan(prob)] = 0\n\nax[1].pcolormesh(xx, yy, prob.data.numpy(), cmap='coolwarm')\n\nax[1].set_aspect('equal', 'box')\nax[1].set_axis_off()\nax[1].set_title('Real NVP', fontsize=24)\n# plt.savefig(\"./Files/NF2.png\")\nplt.subplots_adjust(wspace=0.1)\nplt.show()\n```\n:::\n\n\n![](Files/NF2.png)\n\n## Neural Spline Flow [@Durkan+2019]\n\n円周 $S^1$ 上の確率分布として，wrapped Normal 分布や [von Mises 分布](https://en.wikipedia.org/wiki/Von_Mises_distribution)がある．\n\n今回は後者を採用し，$\\R^2$ 上で密度モデリングを試みる：\n\n::: {#210fda08 .cell execution_count=9}\n``` {.python .cell-code}\n# Set up target\nclass GaussianVonMises(nf.distributions.Target):\n    def __init__(self):\n        super().__init__(prop_scale=torch.tensor(2 * np.pi), \n                         prop_shift=torch.tensor(-np.pi))\n        self.n_dims = 2\n        self.max_log_prob = -1.99\n        self.log_const = -1.5 * np.log(2 * np.pi) - np.log(np.i0(1))\n    \n    def log_prob(self, x):\n        return -0.5 * x[:, 0] ** 2 + torch.cos(x[:, 1] - 3 * x[:, 0]) + self.log_const\n\ntarget = GaussianVonMises()\n\n# Plot target\ngrid_size = 300\nxx, yy = torch.meshgrid(torch.linspace(-2.5, 2.5, grid_size), torch.linspace(-np.pi, np.pi, grid_size))\nzz = torch.cat([xx.unsqueeze(2), yy.unsqueeze(2)], 2).view(-1, 2)\n\nlog_prob = target.log_prob(zz).view(*xx.shape)\nprob = torch.exp(log_prob)\nprob[torch.isnan(prob)] = 0\n\nplt.figure(figsize=(15, 15))\nplt.pcolormesh(yy, xx, prob.data.numpy(), cmap='coolwarm')\nplt.gca().set_aspect('equal', 'box')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](NF2_files/figure-html/cell-9-output-1.png){width=1164 height=930}\n:::\n:::\n\n\n今回は 12 層の Neural Spline Flow を採用し，２次元の Gaussian 分布に基底として採用する．\n\n::: {#52fe9d7d .cell execution_count=10}\n``` {.python .cell-code}\nbase = nf.distributions.UniformGaussian(2, [1], torch.tensor([1., 2 * np.pi]))\n\nK = 12\n\nflow_layers = []\nfor i in range(K):\n    flow_layers += [nf.flows.CircularAutoregressiveRationalQuadraticSpline(2, 1, 512, [1], num_bins=10,\n                                                                           tail_bound=torch.tensor([5., np.pi]),\n                                                                           permute_mask=True)]\n\nmodel = nf.NormalizingFlow(base, flow_layers, target)\n\n# Move model on GPU if available\ndevice = torch.device(\"mps\")\nmodel = model.to(device)\n```\n:::\n\n\n::: {#0d638753 .cell execution_count=11}\n``` {.python .cell-code}\n# Plot model\nlog_prob = model.log_prob(zz.to(device)).to('cpu').view(*xx.shape)\nprob = torch.exp(log_prob)\nprob[torch.isnan(prob)] = 0\n\nplt.figure()\nplt.pcolormesh(yy, xx, prob.data.numpy(), cmap='coolwarm')\nplt.gca().set_aspect('equal', 'box')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](NF2_files/figure-html/cell-11-output-1.png){width=420 height=337}\n:::\n:::\n\n\n::: {#ff071cc4 .cell execution_count=12}\n``` {.python .cell-code}\n# Train model\nmax_iter = 10000\nnum_samples = 2 ** 14\nshow_iter = 2500\n\n\nloss_hist = np.array([])\n\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_iter)\n\nfor it in tqdm(range(max_iter)):\n    optimizer.zero_grad()\n    \n    # Compute loss\n    loss = model.reverse_kld(num_samples)\n    \n    # Do backprop and optimizer step\n    if ~(torch.isnan(loss) | torch.isinf(loss)):\n        loss.backward()\n        optimizer.step()\n    \n    # Log loss\n    loss_hist = np.append(loss_hist, loss.to('cpu').data.numpy())\n    \n    # Plot learned model\n    if (it + 1) % show_iter == 0:\n        model.eval()\n        with torch.no_grad():\n            log_prob = model.log_prob(zz.to(device)).to('cpu').view(*xx.shape)\n        model.train()\n        prob = torch.exp(log_prob)\n        prob[torch.isnan(prob)] = 0\n\n        plt.figure(figsize=(15, 15))\n        plt.pcolormesh(yy, xx, prob.data.numpy(), cmap='coolwarm')\n        plt.gca().set_aspect('equal', 'box')\n        plt.show()\n    \n    # Iterate scheduler\n    scheduler.step()\n\n# Plot loss\nplt.figure(figsize=(10, 10))\nplt.plot(loss_hist, label='loss')\nplt.legend()\nplt.show()\n```\n:::\n\n\n::: {layout-ncol=5}\n\n![](Files/NF/NSF_training0.png)\n\n![](Files/NF/NSF_training1.png)\n\n![](Files/NF/NSF_training2.png)\n\n![](Files/NF/NSF_training3.png)\n\n![](Files/NF/NSF_training4.png)\n\n:::\n\n訓練は L4 で約１時間であった．\n\n![](Files/NF/NSF_training_loss.png)\n\n::: {#9fafb634 .cell execution_count=13}\n``` {.python .cell-code}\n# 2D plot\nf, ax = plt.subplots(1, 2, sharey=True, figsize=(15, 7))\n\nlog_prob = target.log_prob(zz).view(*xx.shape)\nprob = torch.exp(log_prob)\nprob[torch.isnan(prob)] = 0\n\nax[0].pcolormesh(yy, xx, prob.data.numpy(), cmap='coolwarm')\nax[0].set_aspect('equal', 'box')\n\nax[0].set_xticks(ticks=[-np.pi, -np.pi/2, 0, np.pi/2, np.pi])\nax[0].set_xticklabels(['$-\\pi$', r'$-\\frac{\\pi}{2}$', '$0$', r'$\\frac{\\pi}{2}$', '$\\pi$'],\n                      fontsize=20)\nax[0].set_yticks(ticks=[-2, -1, 0, 1, 2])\nax[0].set_yticklabels(['$-2$', '$-1$', '$0$', '$1$', '$2$'],\n                      fontsize=20)\nax[0].set_xlabel('$\\phi$', fontsize=24)\nax[0].set_ylabel('$x$', fontsize=24)\n\nax[0].set_title('Target', fontsize=24)\n\nlog_prob = model.log_prob(zz.to(device)).to('cpu').view(*xx.shape)\nprob = torch.exp(log_prob)\nprob[torch.isnan(prob)] = 0\n\nax[1].pcolormesh(yy, xx, prob.data.numpy(), cmap='coolwarm')\nax[1].set_aspect('equal', 'box')\n\nax[1].set_xticks(ticks=[-np.pi, -np.pi/2, 0, np.pi/2, np.pi])\nax[1].set_xticklabels(['$-\\pi$', r'$-\\frac{\\pi}{2}$', '$0$', r'$\\frac{\\pi}{2}$', '$\\pi$'],\n                      fontsize=20)\nax[1].set_xlabel('$\\phi$', fontsize=24)\n\nax[1].set_title('Neural Spline Flow', fontsize=24)\n\nplt.subplots_adjust(wspace=0.1)\n\nplt.show()\n```\n:::\n\n\n![](Files/NF/NSF_comparison.png)\n\n::: {#d66ec8f0 .cell execution_count=14}\n``` {.python .cell-code}\n# 3D plot\nfig = plt.figure(figsize=(15, 7))\nax1 = fig.add_subplot(1, 2, 1, projection='3d')\nax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\nphi = np.linspace(-np.pi, np.pi, grid_size)\nz = np.linspace(-2.5, 2.5, grid_size)\n\n# create the surface\nx = np.outer(np.ones(grid_size), np.cos(phi))\ny = np.outer(np.ones(grid_size), np.sin(phi))\nz = np.outer(z, np.ones(grid_size))\n\n# Target\nlog_prob = target.log_prob(zz).view(*xx.shape)\nprob = torch.exp(log_prob)\nprob[torch.isnan(prob)] = 0\n\nprob_vis = prob / torch.max(prob)\nmyheatmap = prob_vis.data.numpy()\n\nax1._axis3don = False\nax1.plot_surface(x, y, z, cstride=1, rstride=1, facecolors=cm.coolwarm(myheatmap), shade=False)\n\nax1.set_title('Target', fontsize=24, y=0.97, pad=0)\n\n# Model\nlog_prob = model.log_prob(zz.to(device)).to('cpu').view(*xx.shape)\nprob = torch.exp(log_prob)\nprob[torch.isnan(prob)] = 0\n\nprob_vis = prob / torch.max(prob)\nmyheatmap = prob_vis.data.numpy()\n\nax2._axis3don = False\nax2.plot_surface(x, y, z, cstride=1, rstride=1, facecolors=cm.coolwarm(myheatmap), shade=False)\n\nt = ax2.set_title('Neural Spline Flow', fontsize=24, y=0.97, pad=0)\n\nplt.show()\n```\n:::\n\n\n![](Files/NF/NSF_result.png)\n\n## Glow [@Kingma-Dhariwal2018]\n\n今回は CIFAR-10 という手描き文字画像データセットを学習し，画像の生成を目指す．\n\nこの際には，[@Dinh+2017] の multiscale architecture を採用し，基底分布も成分ごとにスケールが違う正規分布を用いる．\n\n::: {#807d7273 .cell execution_count=15}\n``` {.python .cell-code}\n# Set up model\n\n# Define flows\nL = 3\nK = 16\ntorch.manual_seed(0)\n\ninput_shape = (3, 32, 32)\nn_dims = np.prod(input_shape)\nchannels = 3\nhidden_channels = 256\nsplit_mode = 'channel'\nscale = True\nnum_classes = 10\n\n# Set up flows, distributions and merge operations\nq0 = []\nmerges = []\nflows = []\nfor i in range(L):\n    flows_ = []\n    for j in range(K):\n        flows_ += [nf.flows.GlowBlock(channels * 2 ** (L + 1 - i), hidden_channels,\n                                     split_mode=split_mode, scale=scale)]\n    flows_ += [nf.flows.Squeeze()]\n    flows += [flows_]\n    if i > 0:\n        merges += [nf.flows.Merge()]\n        latent_shape = (input_shape[0] * 2 ** (L - i), input_shape[1] // 2 ** (L - i),\n                        input_shape[2] // 2 ** (L - i))\n    else:\n        latent_shape = (input_shape[0] * 2 ** (L + 1), input_shape[1] // 2 ** L,\n                        input_shape[2] // 2 ** L)\n    q0 += [nf.distributions.ClassCondDiagGaussian(latent_shape, num_classes)]\n\n\n# Construct flow model with the multiscale architecture\nmodel = nf.MultiscaleFlow(q0, flows, merges)\nmodel = model.to(device)\n```\n:::\n\n\n::: {#2016fbfd .cell execution_count=16}\n``` {.python .cell-code}\n# Prepare training data\nbatch_size = 128\n\ntransform = tv.transforms.Compose([tv.transforms.ToTensor(), nf.utils.Scale(255. / 256.), nf.utils.Jitter(1 / 256.)])\ntrain_data = tv.datasets.CIFAR10('datasets/', train=True,\n                                 download=True, transform=transform)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True,\n                                           drop_last=True)\n\ntest_data = tv.datasets.CIFAR10('datasets/', train=False,\n                                download=True, transform=transform)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n\ntrain_iter = iter(train_loader)\n```\n:::\n\n\n::: {#2d9214fd .cell execution_count=17}\n``` {.python .cell-code}\n# Train model\nmax_iter = 20000\n\nloss_hist = np.array([])\n\noptimizer = torch.optim.Adamax(model.parameters(), lr=1e-3, weight_decay=1e-5)\n\nfor i in tqdm(range(max_iter)):\n    try:\n        x, y = next(train_iter)\n    except StopIteration:\n        train_iter = iter(train_loader)\n        x, y = next(train_iter)\n    optimizer.zero_grad()\n    loss = model.forward_kld(x.to(device), y.to(device))\n\n    if ~(torch.isnan(loss) | torch.isinf(loss)):\n        loss.backward()\n        optimizer.step()\n\n    loss_hist = np.append(loss_hist, loss.detach().to('cpu').numpy())\n```\n:::\n\n\n::: {#4dea18cf .cell execution_count=18}\n``` {.python .cell-code}\nplt.figure(figsize=(10, 10))\nplt.plot(loss_hist, label='loss')\nplt.legend()\nplt.savefig('fig1.png')\nplt.show()\n```\n:::\n\n\n![](Files/NF/Glow_training_loss.png)\n\n2万イテレーションで1時間10分を要したが，cutting-edge な性能を出すには遥かに大きいモデルを 100 万イテレーションほどする必要があるという．\n\n::: {#69cdf5a8 .cell execution_count=19}\n``` {.python .cell-code}\n# Model samples\nnum_sample = 10\n\nwith torch.no_grad():\n    y = torch.arange(num_classes).repeat(num_sample).to(device)\n    x, _ = model.sample(y=y)\n    x_ = torch.clamp(x, 0, 1)\n    plt.figure(figsize=(10, 10))\n    plt.imshow(np.transpose(tv.utils.make_grid(x_, nrow=num_classes).cpu().numpy(), (1, 2, 0)))\n    plt.savefig('fig2.png')\n    plt.show()\n```\n:::\n\n\n![](Files/NF/Glow_output.png)\n\n## 文献 {.appendix}\n\n[Eric Jang 氏](https://evjang.com/) による [チュートリアル](https://github.com/ericjang/normalizing-flows-tutorial) （や[その他のチュートリアル](https://github.com/pierresegonne/VINF)）は，TensorFlow 1 を用いており，特に `tfb.Affine` はもうサポートされていない（[対応表](https://github.com/tensorflow/probability/issues/448#issuecomment-555629330)）．\n\n[`normflows` というパッケージ](https://github.com/VincentStimper/normalizing-flows?tab=readme-ov-file) [@Stimper+2023] は PyTorch ベースの実装を提供しており，これを代わりに用いた．[Real NVP](https://colab.research.google.com/github/VincentStimper/normalizing-flows/blob/master/examples/real_nvp_colab.ipynb), [Neural Spline Flow](https://colab.research.google.com/github/VincentStimper/normalizing-flows/blob/master/examples/paper_example_nsf_colab.ipynb), [Glow](https://colab.research.google.com/github/VincentStimper/normalizing-flows/blob/master/examples/glow_colab.ipynb) などのデモを公開している．\n\n",
    "supporting": [
      "NF2_files"
    ],
    "filters": [],
    "includes": {}
  }
}