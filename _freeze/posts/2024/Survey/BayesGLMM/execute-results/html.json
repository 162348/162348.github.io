{
  "hash": "8d75ed36faf3fe2d7cb0b59bfe35061a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"`brms` を用いたベイズ混合ロジスティック回帰分析\"\nsubtitle: \"項目応答モデルと特異項目機能を題材として\"\nauthor: \"司馬博文\"\ndate: 12/14/2024\ncategories: [Bayesian, Statistics, R, Stan]\nbibliography: \n    - ../../../assets/mathematics.bib\n    - ../../../assets/bib.bib\n    - ../../../assets/bib1.bib\ncsl: ../../../assets/apalike.csl\nabstract-title: 概要\nabstract: |\n    項目反応モデルとは，被験者と項目のそれぞれが独自のパラメータを持った一般化線型混合効果モデルである．\n    被験者ごとの特性の違いや，項目ごとの性質の違いが視覚化できるが，\n    本稿では能力・難易度パラメータに更なる階層構造を考える．\n    これにより能力パラメータを変化させている背後の要因や，項目特性と個人特性の交絡効果（特異項目機能）を解析することが可能になる．\n    `brms` パッケージは極めて直感的な方法でモデルのフィッティングから事後分布の推論までを実行できる．\nimage: Files/DIF.png\ncode-fold: false\nexecute:\n    cache: true\nlisting: \n    -   id: lst-survey\n        type: grid\n        sort: false\n        contents:\n            - \"BDA2.qmd\"\n            - \"BayesRegression.qmd\"\n            - \"../TransDimensionalModels/IdealPoint1.qmd\"\n        date-format: iso\n        fields: [title,image,date,subtitle]\n    # -   id: lst-embedding\n    #     type: grid\n    #     grid-columns: 1\n    #     grid-item-align: center\n    #     sort: false\n    #     contents:\n    #         - \"BDA2.qmd\"\n    #     date-format: iso\n    #     fields: [title,image,date,subtitle]\n---\n\n\n\n::: {.hidden}\n\n::: {.content-visible when-format=\"html\"}\n\nA Blog Entry on Bayesian Computation by an Applied Mathematician\n\n$$\n\n\\renewcommand{\\P}{\\operatorname{P}}\\newcommand{\\E}{\\operatorname{E}}\n\\newcommand{\\R}{\\mathbb{R}}\\newcommand{\\F}{\\mathcal{F}}\n\\newcommand{\\abs}[1]{\\lvert#1\\rvert}\\newcommand{\\Abs}[1]{\\left|#1\\right|}\\newcommand{\\ABs}[1]{\\biggl|#1\\biggr|}\\newcommand{\\norm}[1]{\\|#1\\|}\\newcommand{\\Norm}[1]{\\left\\|#1\\right\\|}\\newcommand{\\NOrm}[1]{\\biggl\\|#1\\biggr\\|}\\newcommand{\\Brace}[1]{\\left\\{#1\\right\\}}\\newcommand{\\BRace}[1]{\\biggl\\{#1\\biggr\\}}\\newcommand{\\paren}[1]{\\left(#1\\right)}\\newcommand{\\Paren}[1]{\\biggr(#1\\biggl)}\\newcommand{\\brac}[1]{\\langle#1\\rangle}\\newcommand{\\Brac}[1]{\\left\\langle#1\\right\\rangle}\\newcommand{\\BRac}[1]{\\biggl\\langle#1\\biggr\\rangle}\\newcommand{\\bra}[1]{\\left\\langle#1\\right|}\\newcommand{\\ket}[1]{\\left|#1\\right\\rangle}\\newcommand{\\Square}[1]{\\left[#1\\right]}\\newcommand{\\SQuare}[1]{\\biggl[#1\\biggr]}\\newcommand{\\rN}{\\mathrm{N}}\\newcommand{\\ov}[1]{\\overline{#1}}\\newcommand{\\un}[1]{\\underline{#1}}\\newcommand{\\wt}[1]{\\widetilde{#1}}\\newcommand{\\wh}[1]{\\widehat{#1}}\\newcommand{\\pp}[2]{\\frac{\\partial #1}{\\partial #2}}\\newcommand{\\ppp}[3]{\\frac{\\partial #1}{\\partial #2\\partial #3}}\\newcommand{\\dd}[2]{\\frac{d #1}{d #2}}\\newcommand{\\floor}[1]{\\lfloor#1\\rfloor}\\newcommand{\\Floor}[1]{\\left\\lfloor#1\\right\\rfloor}\\newcommand{\\ceil}[1]{\\lceil#1\\rceil}\\newcommand{\\ocinterval}[1]{(#1]}\\newcommand{\\cointerval}[1]{[#1)}\\newcommand{\\COinterval}[1]{\\left[#1\\right)}\\newcommand{\\iso}{\\overset{\\sim}{\\to}}\n\n\n\n\\newcommand{\\y}{\\b{y}}\\newcommand{\\mi}{\\,|\\,}\\newcommand{\\Mark}{\\mathrm{Mark}}\n\\newcommand{\\argmax}{\\operatorname*{argmax}}\\newcommand{\\argmin}{\\operatorname*{argmin}}\n\n\\newcommand{\\pr}{\\mathrm{pr}}\\newcommand{\\Conv}{\\operatorname{Conv}}\\newcommand{\\cU}{\\mathcal{U}}\n\\newcommand{\\Map}{\\mathrm{Map}}\\newcommand{\\dom}{\\mathrm{Dom}\\;}\\newcommand{\\cod}{\\mathrm{Cod}\\;}\\newcommand{\\supp}{\\mathrm{supp}\\;}\n\\newcommand{\\grad}{\\operatorname{grad}}\\newcommand{\\rot}{\\operatorname{rot}}\\renewcommand{\\div}{\\operatorname{div}}\\newcommand{\\tr}{\\operatorname{tr}}\\newcommand{\\Tr}{\\operatorname{Tr}}\\newcommand{\\KL}{\\operatorname{KL}}\\newcommand{\\JS}{\\operatorname{JS}}\\newcommand{\\ESS}{\\operatorname{ESS}}\\newcommand{\\MSE}{\\operatorname{MSE}}\\newcommand{\\erf}{\\operatorname{erf}}\\newcommand{\\arctanh}{\\operatorname{arctanh}}\\newcommand{\\pl}{\\operatorname{pl}}\\newcommand{\\minimize}{\\operatorname{minimize}}\\newcommand{\\subjectto}{\\operatorname{subject to}}\\newcommand{\\sinc}{\\operatorname{sinc}}\\newcommand{\\Ent}{\\operatorname{Ent}}\\newcommand{\\Polya}{\\operatorname{Polya}}\\newcommand{\\Exp}{\\operatorname{Exp}}\\newcommand{\\codim}{\\operatorname{codim}}\\newcommand{\\sgn}{\\operatorname{sgn}}\\newcommand{\\rank}{\\operatorname{rank}}\n\n\\newcommand{\\vctr}[2]{\\begin{pmatrix}#1\\\\#2\\end{pmatrix}}\\newcommand{\\vctrr}[3]{\\begin{pmatrix}#1\\\\#2\\\\#3\\end{pmatrix}}\\newcommand{\\mtrx}[4]{\\begin{pmatrix}#1&#2\\\\#3&#4\\end{pmatrix}}\\newcommand{\\smtrx}[4]{\\paren{\\begin{smallmatrix}#1&#2\\\\#3&#4\\end{smallmatrix}}}\\newcommand{\\Ker}{\\mathrm{Ker}\\;}\\newcommand{\\Coker}{\\mathrm{Coker}\\;}\\newcommand{\\Coim}{\\mathrm{Coim}\\;}\\newcommand{\\lcm}{\\mathrm{lcm}}\\newcommand{\\GL}{\\mathrm{GL}}\\newcommand{\\SL}{\\mathrm{SL}}\\newcommand{\\alt}{\\mathrm{alt}}\n\n\\renewcommand{\\Re}{\\mathrm{Re}\\;}\\renewcommand{\\Im}{\\mathrm{Im}\\,}\\newcommand{\\Gal}{\\mathrm{Gal}}\\newcommand{\\PGL}{\\mathrm{PGL}}\\newcommand{\\PSL}{\\mathrm{PSL}}\\newcommand{\\Log}{\\mathrm{Log}\\,}\\newcommand{\\Res}{\\mathrm{Res}\\,}\\newcommand{\\on}{\\mathrm{on}\\;}\\newcommand{\\hatC}{\\widehat{\\C}}\\newcommand{\\hatR}{\\hat{\\R}}\\newcommand{\\PV}{\\mathrm{P.V.}}\\newcommand{\\diam}{\\mathrm{diam}}\\newcommand{\\Area}{\\mathrm{Area}}\\newcommand{\\Lap}{\\Laplace}\\newcommand{\\f}{\\mathbf{f}}\\newcommand{\\cR}{\\mathcal{R}}\\newcommand{\\const}{\\mathrm{const.}}\\newcommand{\\Om}{\\Omega}\\newcommand{\\Cinf}{C^\\infty}\\newcommand{\\ep}{\\epsilon}\\newcommand{\\dist}{\\mathrm{dist}}\\newcommand{\\opart}{\\o{\\partial}}\\newcommand{\\Length}{\\mathrm{Length}}\n\n\\newcommand{\\cA}{\\mathcal{A}}\\newcommand{\\cO}{\\mathcal{O}}\\newcommand{\\cW}{\\mathcal{W}}\\renewcommand{\\O}{\\mathcal{O}}\\renewcommand{\\S}{\\mathcal{S}}\\newcommand{\\U}{\\mathcal{U}}\\newcommand{\\V}{\\mathrm{V}}\\newcommand{\\N}{\\mathbb{N}}\\newcommand{\\bN}{\\mathbb{N}}\\newcommand{\\C}{\\mathrm{C}}\\newcommand{\\bC}{\\mathbb{C}}\\newcommand{\\Z}{\\mathcal{Z}}\\newcommand{\\Q}{\\mathbb{Q}}\\newcommand{\\bQ}{\\mathbb{Q}}\\newcommand{\\TV}{\\mathrm{TV}}\\newcommand{\\ORD}{\\mathrm{ORD}}\\newcommand{\\Card}{\\mathrm{Card}\\,}\\newcommand{\\Top}{\\mathrm{Top}}\\newcommand{\\Disc}{\\mathrm{Disc}}\\newcommand{\\Codisc}{\\mathrm{Codisc}}\\newcommand{\\CoDisc}{\\mathrm{CoDisc}}\\newcommand{\\Ult}{\\mathrm{Ult}}\\newcommand{\\ord}{\\mathrm{ord}}\\newcommand{\\bS}{\\mathbb{S}}\\newcommand{\\PConn}{\\mathrm{PConn}}\\newcommand{\\mult}{\\mathrm{mult}}\\newcommand{\\inv}{\\mathrm{inv}}\n\n\\newcommand{\\Der}{\\mathrm{Der}}\\newcommand{\\osub}{\\overset{\\mathrm{open}}{\\subset}}\\newcommand{\\osup}{\\overset{\\mathrm{open}}{\\supset}}\\newcommand{\\al}{\\alpha}\\newcommand{\\K}{\\mathbb{K}}\\newcommand{\\Sp}{\\mathrm{Sp}}\\newcommand{\\g}{\\mathfrak{g}}\\newcommand{\\h}{\\mathfrak{h}}\\newcommand{\\Imm}{\\mathrm{Imm}}\\newcommand{\\Imb}{\\mathrm{Imb}}\\newcommand{\\Gr}{\\mathrm{Gr}}\n\n\\newcommand{\\Ad}{\\mathrm{Ad}}\\newcommand{\\finsupp}{\\mathrm{fin\\;supp}}\\newcommand{\\SO}{\\mathrm{SO}}\\newcommand{\\SU}{\\mathrm{SU}}\\newcommand{\\acts}{\\curvearrowright}\\newcommand{\\mono}{\\hookrightarrow}\\newcommand{\\epi}{\\twoheadrightarrow}\\newcommand{\\Stab}{\\mathrm{Stab}}\\newcommand{\\nor}{\\mathrm{nor}}\\newcommand{\\T}{\\mathbb{T}}\\newcommand{\\Aff}{\\mathrm{Aff}}\\newcommand{\\rsup}{\\triangleright}\\newcommand{\\subgrp}{\\overset{\\mathrm{subgrp}}{\\subset}}\\newcommand{\\Ext}{\\mathrm{Ext}}\\newcommand{\\sbs}{\\subset}\\newcommand{\\sps}{\\supset}\\newcommand{\\In}{\\mathrm{in}\\;}\\newcommand{\\Tor}{\\mathrm{Tor}}\\newcommand{\\p}{\\b{p}}\\newcommand{\\q}{\\mathfrak{q}}\\newcommand{\\m}{\\mathfrak{m}}\\newcommand{\\cS}{\\mathcal{S}}\\newcommand{\\Frac}{\\mathrm{Frac}\\,}\\newcommand{\\Spec}{\\mathrm{Spec}\\,}\\newcommand{\\bA}{\\mathbb{A}}\\newcommand{\\Sym}{\\mathrm{Sym}}\\newcommand{\\Ann}{\\mathrm{Ann}}\\newcommand{\\Her}{\\mathrm{Her}}\\newcommand{\\Bil}{\\mathrm{Bil}}\\newcommand{\\Ses}{\\mathrm{Ses}}\\newcommand{\\FVS}{\\mathrm{FVS}}\n\n\\newcommand{\\Ho}{\\mathrm{Ho}}\\newcommand{\\CW}{\\mathrm{CW}}\\newcommand{\\lc}{\\mathrm{lc}}\\newcommand{\\cg}{\\mathrm{cg}}\\newcommand{\\Fib}{\\mathrm{Fib}}\\newcommand{\\Cyl}{\\mathrm{Cyl}}\\newcommand{\\Ch}{\\mathrm{Ch}}\n\\newcommand{\\rP}{\\mathrm{P}}\\newcommand{\\rE}{\\mathrm{E}}\\newcommand{\\e}{\\b{e}}\\renewcommand{\\k}{\\b{k}}\\newcommand{\\Christ}[2]{\\begin{Bmatrix}#1\\\\#2\\end{Bmatrix}}\\renewcommand{\\Vec}[1]{\\overrightarrow{\\mathrm{#1}}}\\newcommand{\\hen}[1]{\\mathrm{#1}}\\renewcommand{\\b}[1]{\\boldsymbol{#1}}\n\n\\newcommand{\\Inc}{\\mathrm{Inc}}\\newcommand{\\aInc}{\\mathrm{aInc}}\\newcommand{\\HS}{\\mathrm{HS}}\\newcommand{\\loc}{\\mathrm{loc}}\\newcommand{\\Lh}{\\mathrm{L.h.}}\\newcommand{\\Epi}{\\mathrm{Epi}}\\newcommand{\\slim}{\\mathrm{slim}}\\newcommand{\\Ban}{\\mathrm{Ban}}\\newcommand{\\Hilb}{\\mathrm{Hilb}}\\newcommand{\\Ex}{\\mathrm{Ex}}\\newcommand{\\Co}{\\mathrm{Co}}\\newcommand{\\sa}{\\mathrm{sa}}\\newcommand{\\nnorm}[1]{{\\left\\vert\\kern-0.25ex\\left\\vert\\kern-0.25ex\\left\\vert #1 \\right\\vert\\kern-0.25ex\\right\\vert\\kern-0.25ex\\right\\vert}}\\newcommand{\\dvol}{\\mathrm{dvol}}\\newcommand{\\Sconv}{\\mathrm{Sconv}}\\newcommand{\\I}{\\mathcal{I}}\\newcommand{\\nonunital}{\\mathrm{nu}}\\newcommand{\\cpt}{\\mathrm{cpt}}\\newcommand{\\lcpt}{\\mathrm{lcpt}}\\newcommand{\\com}{\\mathrm{com}}\\newcommand{\\Haus}{\\mathrm{Haus}}\\newcommand{\\proper}{\\mathrm{proper}}\\newcommand{\\infinity}{\\mathrm{inf}}\\newcommand{\\TVS}{\\mathrm{TVS}}\\newcommand{\\ess}{\\mathrm{ess}}\\newcommand{\\ext}{\\mathrm{ext}}\\newcommand{\\Index}{\\mathrm{Index}\\;}\\newcommand{\\SSR}{\\mathrm{SSR}}\\newcommand{\\vs}{\\mathrm{vs.}}\\newcommand{\\fM}{\\mathfrak{M}}\\newcommand{\\EDM}{\\mathrm{EDM}}\\newcommand{\\Tw}{\\mathrm{Tw}}\\newcommand{\\fC}{\\mathfrak{C}}\\newcommand{\\bn}{\\boldsymbol{n}}\\newcommand{\\br}{\\boldsymbol{r}}\\newcommand{\\Lam}{\\Lambda}\\newcommand{\\lam}{\\lambda}\\newcommand{\\one}{\\mathbf{1}}\\newcommand{\\dae}{\\text{-a.e.}}\\newcommand{\\das}{\\text{-a.s.}}\\newcommand{\\td}{\\text{-}}\\newcommand{\\RM}{\\mathrm{RM}}\\newcommand{\\BV}{\\mathrm{BV}}\\newcommand{\\normal}{\\mathrm{normal}}\\newcommand{\\lub}{\\mathrm{lub}\\;}\\newcommand{\\Graph}{\\mathrm{Graph}}\\newcommand{\\Ascent}{\\mathrm{Ascent}}\\newcommand{\\Descent}{\\mathrm{Descent}}\\newcommand{\\BIL}{\\mathrm{BIL}}\\newcommand{\\fL}{\\mathfrak{L}}\\newcommand{\\De}{\\Delta}\n\n\\newcommand{\\calA}{\\mathcal{A}}\\newcommand{\\calB}{\\mathcal{B}}\\newcommand{\\D}{\\mathcal{D}}\\newcommand{\\Y}{\\mathcal{Y}}\\newcommand{\\calC}{\\mathcal{C}}\\renewcommand{\\ae}{\\mathrm{a.e.}\\;}\\newcommand{\\cZ}{\\mathcal{Z}}\\newcommand{\\fF}{\\mathfrak{F}}\\newcommand{\\fI}{\\mathfrak{I}}\\newcommand{\\rV}{\\mathrm{V}}\\newcommand{\\cE}{\\mathcal{E}}\\newcommand{\\sMap}{\\sigma\\textrm{-}\\mathrm{Map}}\\newcommand{\\cC}{\\mathcal{C}}\\newcommand{\\comp}{\\complement}\\newcommand{\\J}{\\mathcal{J}}\\newcommand{\\sumN}[1]{\\sum_{#1\\in\\N}}\\newcommand{\\cupN}[1]{\\cup_{#1\\in\\N}}\\newcommand{\\capN}[1]{\\cap_{#1\\in\\N}}\\newcommand{\\Sum}[1]{\\sum_{#1=1}^\\infty}\\newcommand{\\sumn}{\\sum_{n=1}^\\infty}\\newcommand{\\summ}{\\sum_{m=1}^\\infty}\\newcommand{\\sumk}{\\sum_{k=1}^\\infty}\\newcommand{\\sumi}{\\sum_{i=1}^\\infty}\\newcommand{\\sumj}{\\sum_{j=1}^\\infty}\\newcommand{\\cupn}{\\cup_{n=1}^\\infty}\\newcommand{\\capn}{\\cap_{n=1}^\\infty}\\newcommand{\\cupk}{\\cup_{k=1}^\\infty}\\newcommand{\\cupi}{\\cup_{i=1}^\\infty}\\newcommand{\\cupj}{\\cup_{j=1}^\\infty}\\newcommand{\\limn}{\\lim_{n\\to\\infty}}\\renewcommand{\\L}{\\mathcal{L}}\\newcommand{\\cL}{\\mathcal{L}}\\newcommand{\\Cl}{\\mathrm{Cl}}\\newcommand{\\cN}{\\mathcal{N}}\\newcommand{\\Ae}{\\textrm{-a.e.}\\;}\\renewcommand{\\csub}{\\overset{\\textrm{closed}}{\\subset}}\\renewcommand{\\csup}{\\overset{\\textrm{closed}}{\\supset}}\\newcommand{\\wB}{\\wt{B}}\\newcommand{\\cG}{\\mathcal{G}}\\newcommand{\\Lip}{\\mathrm{Lip}}\\newcommand{\\AC}{\\mathrm{AC}}\\newcommand{\\Mol}{\\mathrm{Mol}}\n\n\\newcommand{\\Pe}{\\mathrm{Pe}}\\newcommand{\\wR}{\\wh{\\mathbb{\\R}}}\\newcommand*{\\Laplace}{\\mathop{}\\!\\mathbin\\bigtriangleup}\\newcommand*{\\DAlambert}{\\mathop{}\\!\\mathbin\\Box}\\newcommand{\\bT}{\\mathbb{T}}\\newcommand{\\dx}{\\dslash x}\\newcommand{\\dt}{\\dslash t}\\newcommand{\\ds}{\\dslash s}\n\n\\newcommand{\\round}{\\mathrm{round}}\\newcommand{\\cond}{\\mathrm{cond}}\\newcommand{\\diag}{\\mathrm{diag}}\n\\newcommand{\\Adj}{\\mathrm{Adj}}\\newcommand{\\Pf}{\\mathrm{Pf}}\\newcommand{\\Sg}{\\mathrm{Sg}}\n\n\n\\newcommand{\\aseq}{\\overset{\\text{a.s.}}{=}}\\newcommand{\\deq}{\\overset{\\text{d}}{=}}\\newcommand{\\cV}{\\mathcal{V}}\\newcommand{\\FM}{\\mathrm{FM}}\\newcommand{\\KR}{\\mathrm{KR}}\\newcommand{\\rba}{\\mathrm{rba}}\\newcommand{\\rca}{\\mathrm{rca}}\\newcommand{\\Prob}{\\mathrm{Prob}}\\newcommand{\\X}{\\mathcal{X}}\\newcommand{\\Meas}{\\mathrm{Meas}}\\newcommand{\\as}{\\;\\text{a.s.}}\\newcommand{\\io}{\\;\\mathrm{i.o.}}\\newcommand{\\fe}{\\;\\text{f.e.}}\\newcommand{\\bF}{\\mathbb{F}}\\newcommand{\\W}{\\mathcal{W}}\\newcommand{\\Pois}{\\mathrm{Pois}}\\newcommand{\\iid}{\\text{i.i.d.}}\\newcommand{\\wconv}{\\rightsquigarrow}\\newcommand{\\Var}{\\mathrm{Var}}\\newcommand{\\xrightarrown}{\\xrightarrow{n\\to\\infty}}\\newcommand{\\au}{\\mathrm{au}}\\newcommand{\\cT}{\\mathcal{T}}\\newcommand{\\wto}{\\overset{\\text{w}}{\\to}}\\newcommand{\\dto}{\\overset{\\text{d}}{\\to}}\\newcommand{\\sto}{\\overset{\\text{s}}{\\to}}\\newcommand{\\pto}{\\overset{\\text{p}}{\\to}}\\newcommand{\\mto}{\\overset{\\text{m}}{\\to}}\\newcommand{\\vto}{\\overset{v}{\\to}}\\newcommand{\\Cont}{\\mathrm{Cont}}\\newcommand{\\stably}{\\mathrm{stably}}\\newcommand{\\Np}{\\mathbb{N}^+}\\newcommand{\\oM}{\\overline{\\mathcal{M}}}\\newcommand{\\fP}{\\mathfrak{P}}\\newcommand{\\sign}{\\mathrm{sign}}\n\\newcommand{\\Borel}{\\mathrm{Borel}}\\newcommand{\\Mid}{\\,|\\,}\\newcommand{\\middleMid}{\\;\\middle|\\;}\\newcommand{\\CP}{\\mathrm{CP}}\\newcommand{\\bD}{\\mathbb{D}}\\newcommand{\\bL}{\\mathbb{L}}\\newcommand{\\fW}{\\mathfrak{W}}\\newcommand{\\DL}{\\mathcal{D}\\mathcal{L}}\\renewcommand{\\r}[1]{\\mathrm{#1}}\\newcommand{\\rC}{\\mathrm{C}}\\newcommand{\\qqquad}{\\qquad\\quad}\n\n\\newcommand{\\bit}{\\mathrm{bit}}\n\n\\newcommand{\\err}{\\mathrm{err}}\n\n\\newcommand{\\varparallel}{\\mathbin{\\!/\\mkern-5mu/\\!}}\\newcommand{\\Ri}{\\mathrm{Ri}}\\newcommand{\\Cone}{\\mathrm{Cone}}\\newcommand{\\Int}{\\mathrm{Int}}\n\n\\newcommand{\\pre}{\\mathrm{pre}}\\newcommand{\\om}{\\omega}\n\n\n\\newcommand{\\del}{\\partial}\n\\newcommand{\\LHS}{\\mathrm{LHS}}\\newcommand{\\RHS}{\\mathrm{RHS}}\\newcommand{\\bnu}{\\boldsymbol{\\nu}}\\newcommand{\\interior}{\\mathrm{in}\\;}\\newcommand{\\SH}{\\mathrm{SH}}\\renewcommand{\\v}{\\boldsymbol{\\nu}}\\newcommand{\\n}{\\mathbf{n}}\\newcommand{\\ssub}{\\Subset}\\newcommand{\\curl}{\\mathrm{curl}}\n\n\\newcommand{\\Ei}{\\mathrm{Ei}}\\newcommand{\\sn}{\\mathrm{sn}}\\newcommand{\\wgamma}{\\widetilde{\\gamma}}\n\n\\newcommand{\\Ens}{\\mathrm{Ens}}\n\n\\newcommand{\\cl}{\\mathrm{cl}}\\newcommand{\\x}{\\boldsymbol{x}}\n\n\\newcommand{\\Do}{\\mathrm{Do}}\\newcommand{\\IV}{\\mathrm{IV}}\n\n\\newcommand{\\AIC}{\\mathrm{AIC}}\\newcommand{\\mrl}{\\mathrm{mrl}}\\newcommand{\\dotx}{\\dot{x}}\\newcommand{\\UMV}{\\mathrm{UMV}}\\newcommand{\\BLU}{\\mathrm{BLU}}\n\n\\newcommand{\\comb}[2]{\\begin{pmatrix}#1\\\\#2\\end{pmatrix}}\\newcommand{\\bP}{\\mathbb{P}}\\newcommand{\\compsub}{\\overset{\\textrm{cpt}}{\\subset}}\\newcommand{\\lip}{\\textrm{lip}}\\newcommand{\\BL}{\\mathrm{BL}}\\newcommand{\\G}{\\mathbb{G}}\\newcommand{\\NB}{\\mathrm{NB}}\\newcommand{\\oR}{\\ov{\\R}}\\newcommand{\\liminfn}{\\liminf_{n\\to\\infty}}\\newcommand{\\limsupn}{\\limsup_{n\\to\\infty}}\\newcommand{\\esssup}{\\mathrm{ess.sup}}\\newcommand{\\asto}{\\xrightarrow{\\as}}\\newcommand{\\Cov}{\\mathrm{Cov}}\\newcommand{\\cQ}{\\mathcal{Q}}\\newcommand{\\VC}{\\mathrm{VC}}\\newcommand{\\mb}{\\mathrm{mb}}\\newcommand{\\Avar}{\\mathrm{Avar}}\\newcommand{\\bB}{\\mathbb{B}}\\newcommand{\\bW}{\\mathbb{W}}\\newcommand{\\sd}{\\mathrm{sd}}\\newcommand{\\w}[1]{\\widehat{#1}}\\newcommand{\\bZ}{\\mathbb{Z}}\\newcommand{\\Bernoulli}{\\mathrm{Ber}}\\newcommand{\\Ber}{\\mathrm{Ber}}\\newcommand{\\Mult}{\\mathrm{Mult}}\\newcommand{\\BPois}{\\mathrm{BPois}}\\newcommand{\\fraks}{\\mathfrak{s}}\\newcommand{\\frakk}{\\mathfrak{k}}\\newcommand{\\IF}{\\mathrm{IF}}\\newcommand{\\bX}{\\boldsymbol{X}}\\newcommand{\\bx}{\\boldsymbol{x}}\\newcommand{\\indep}{\\perp\\!\\!\\!\\perp}\\newcommand{\\IG}{\\mathrm{IG}}\\newcommand{\\Levy}{\\mathrm{Levy}}\\newcommand{\\MP}{\\mathrm{MP}}\\newcommand{\\Hermite}{\\mathrm{Hermite}}\\newcommand{\\Skellam}{\\mathrm{Skellam}}\\newcommand{\\Dirichlet}{\\mathrm{Dirichlet}}\\renewcommand{\\Beta}{\\operatorname{Beta}}\\newcommand{\\bE}{\\mathbb{E}}\\newcommand{\\bG}{\\mathbb{G}}\\newcommand{\\MISE}{\\mathrm{MISE}}\\newcommand{\\logit}{\\mathtt{logit}}\\newcommand{\\expit}{\\mathtt{expit}}\\newcommand{\\cK}{\\mathcal{K}}\\newcommand{\\dl}{\\dot{l}}\\newcommand{\\dotp}{\\dot{p}}\\newcommand{\\wl}{\\wt{l}}\\newcommand{\\Gauss}{\\mathrm{Gauss}}\\newcommand{\\fA}{\\mathfrak{A}}\\newcommand{\\under}{\\mathrm{under}\\;}\\newcommand{\\whtheta}{\\wh{\\theta}}\\newcommand{\\Em}{\\mathrm{Em}}\\newcommand{\\ztheta}{{\\theta_0}}\n\\newcommand{\\rO}{\\mathrm{O}}\\newcommand{\\Bin}{\\mathrm{Bin}}\\newcommand{\\rW}{\\mathrm{W}}\\newcommand{\\rG}{\\mathrm{G}}\\newcommand{\\rB}{\\mathrm{B}}\\newcommand{\\rU}{\\mathrm{U}}\\newcommand{\\HG}{\\mathrm{HG}}\\newcommand{\\GAMMA}{\\mathrm{Gamma}}\\newcommand{\\Cauchy}{\\mathrm{Cauchy}}\\newcommand{\\rt}{\\mathrm{t}}\\newcommand{\\rF}{\\mathrm{F}}\n\\newcommand{\\FE}{\\mathrm{FE}}\\newcommand{\\bV}{\\boldsymbol{V}}\\newcommand{\\GLS}{\\mathrm{GLS}}\\newcommand{\\be}{\\boldsymbol{e}}\\newcommand{\\POOL}{\\mathrm{POOL}}\\newcommand{\\GMM}{\\mathrm{GMM}}\\newcommand{\\MM}{\\mathrm{MM}}\\newcommand{\\SSIV}{\\mathrm{SSIV}}\\newcommand{\\JIV}{\\mathrm{JIV}}\\newcommand{\\AR}{\\mathrm{AR}}\\newcommand{\\ILS}{\\mathrm{ILS}}\\newcommand{\\SLS}{\\mathrm{SLS}}\\newcommand{\\LIML}{\\mathrm{LIML}}\n\n\\newcommand{\\Rad}{\\mathrm{Rad}}\\newcommand{\\bY}{\\boldsymbol{Y}}\\newcommand{\\pone}{{(1)}}\\newcommand{\\ptwo}{{(2)}}\\newcommand{\\ps}[1]{{(#1)}}\\newcommand{\\fsub}{\\overset{\\text{finite}}{\\subset}}\n\n\n\\newcommand{\\varlim}{\\varprojlim}\\newcommand{\\Hom}{\\mathrm{Hom}}\\newcommand{\\Iso}{\\mathrm{Iso}}\\newcommand{\\Mor}{\\mathrm{Mor}}\\newcommand{\\Isom}{\\mathrm{Isom}}\\newcommand{\\Aut}{\\mathrm{Aut}}\\newcommand{\\End}{\\mathrm{End}}\\newcommand{\\op}{\\mathrm{op}}\\newcommand{\\ev}{\\mathrm{ev}}\\newcommand{\\Ob}{\\mathrm{Ob}}\\newcommand{\\Ar}{\\mathrm{Ar}}\\newcommand{\\Arr}{\\mathrm{Arr}}\\newcommand{\\Set}{\\mathrm{Set}}\\newcommand{\\Grp}{\\mathrm{Grp}}\\newcommand{\\Cat}{\\mathrm{Cat}}\\newcommand{\\Mon}{\\mathrm{Mon}}\\newcommand{\\Ring}{\\mathrm{Ring}}\\newcommand{\\CRing}{\\mathrm{CRing}}\\newcommand{\\Ab}{\\mathrm{Ab}}\\newcommand{\\Pos}{\\mathrm{Pos}}\\newcommand{\\Vect}{\\mathrm{Vect}}\\newcommand{\\FinVect}{\\mathrm{FinVect}}\\newcommand{\\FinSet}{\\mathrm{FinSet}}\\newcommand{\\FinMeas}{\\mathrm{FinMeas}}\\newcommand{\\OmegaAlg}{\\Omega\\text{-}\\mathrm{Alg}}\\newcommand{\\OmegaEAlg}{(\\Omega,E)\\text{-}\\mathrm{Alg}}\\newcommand{\\Fun}{\\mathrm{Fun}}\\newcommand{\\Func}{\\mathrm{Func}}\n\n\\newcommand{\\Stoch}{\\mathrm{Stoch}}\\newcommand{\\FinStoch}{\\mathrm{FinStoch}}\\newcommand{\\Copy}{\\mathrm{copy}}\\newcommand{\\Delete}{\\mathrm{delete}}\n\\newcommand{\\Bool}{\\mathrm{Bool}}\\newcommand{\\CABool}{\\mathrm{CABool}}\\newcommand{\\CompBoolAlg}{\\mathrm{CompBoolAlg}}\\newcommand{\\BoolAlg}{\\mathrm{BoolAlg}}\\newcommand{\\BoolRng}{\\mathrm{BoolRng}}\\newcommand{\\HeytAlg}{\\mathrm{HeytAlg}}\\newcommand{\\CompHeytAlg}{\\mathrm{CompHeytAlg}}\\newcommand{\\Lat}{\\mathrm{Lat}}\\newcommand{\\CompLat}{\\mathrm{CompLat}}\\newcommand{\\SemiLat}{\\mathrm{SemiLat}}\\newcommand{\\Stone}{\\mathrm{Stone}}\\newcommand{\\Mfd}{\\mathrm{Mfd}}\\newcommand{\\LieAlg}{\\mathrm{LieAlg}}\n\\newcommand{\\Op}{\\mathrm{Op}}\n\\newcommand{\\Sh}{\\mathrm{Sh}}\n\\newcommand{\\Diff}{\\mathrm{Diff}}\n\\newcommand{\\B}{\\mathcal{B}}\\newcommand{\\cB}{\\mathcal{B}}\\newcommand{\\Span}{\\mathrm{Span}}\\newcommand{\\Corr}{\\mathrm{Corr}}\\newcommand{\\Decat}{\\mathrm{Decat}}\\newcommand{\\Rep}{\\mathrm{Rep}}\\newcommand{\\Grpd}{\\mathrm{Grpd}}\\newcommand{\\sSet}{\\mathrm{sSet}}\\newcommand{\\Mod}{\\mathrm{Mod}}\\newcommand{\\SmoothMnf}{\\mathrm{SmoothMnf}}\\newcommand{\\coker}{\\mathrm{coker}}\\newcommand{\\Ord}{\\mathrm{Ord}}\\newcommand{\\eq}{\\mathrm{eq}}\\newcommand{\\coeq}{\\mathrm{coeq}}\\newcommand{\\act}{\\mathrm{act}}\n\n\\newcommand{\\apf}{\\mathrm{apf}}\\newcommand{\\opt}{\\mathrm{opt}}\\newcommand{\\IS}{\\mathrm{IS}}\\newcommand{\\IR}{\\mathrm{IR}}\\newcommand{\\iidsim}{\\overset{\\text{i.i.d.}}{\\sim}}\\newcommand{\\propt}{\\,\\propto\\,}\\newcommand{\\bM}{\\mathbb{M}}\\newcommand{\\cX}{\\mathcal{X}}\\newcommand{\\cY}{\\mathcal{Y}}\\newcommand{\\cP}{\\mathcal{P}}\\newcommand{\\ola}[1]{\\overleftarrow{#1}}\n\n\\renewcommand{\\iff}{\\;\\mathrm{iff}\\;}\n\\newcommand{\\False}{\\mathrm{False}}\\newcommand{\\True}{\\mathrm{True}}\n\\newcommand{\\otherwise}{\\mathrm{otherwise}}\n\\newcommand{\\suchthat}{\\;\\mathrm{s.t.}\\;}\n\n\\newcommand{\\cM}{\\mathcal{M}}\\newcommand{\\M}{\\mathbb{M}}\\newcommand{\\cF}{\\mathcal{F}}\\newcommand{\\cD}{\\mathcal{D}}\\newcommand{\\fX}{\\mathfrak{X}}\\newcommand{\\fY}{\\mathfrak{Y}}\\newcommand{\\fZ}{\\mathfrak{Z}}\\renewcommand{\\H}{\\mathcal{H}}\\newcommand{\\cH}{\\mathcal{H}}\\newcommand{\\fH}{\\mathfrak{H}}\\newcommand{\\bH}{\\mathbb{H}}\\newcommand{\\id}{\\mathrm{id}}\\newcommand{\\A}{\\mathcal{A}}\n\\newcommand{\\lmd}{\\lambda}\n\\newcommand{\\Lmd}{\\Lambda}\n\\newcommand{\\cI}{\\mathcal{I}}\n\n\\newcommand{\\Lrarrow}{\\;\\;\\Leftrightarrow\\;\\;}\n\\DeclareMathOperator{\\des}{des}\n\\DeclareMathOperator{\\nd}{nd}\n\\DeclareMathOperator{\\dsep}{d-sep}\n\\DeclareMathOperator{\\sep}{sep}\n\\newcommand{\\rLL}{\\mathrm{LL}}\\newcommand{\\HT}{\\mathrm{HT}}\\newcommand{\\PS}{\\mathrm{PS}}\\newcommand{\\rI}{\\mathrm{I}}\n$$\n\n:::\n\n:::\n\n\n\n## 項目応答モデル\n\n### データの概観\n\n[@Vansteelandt2001], [@Boeck-Wilson2004] による「怒るかどうか？」のデータ [`VerbAgg`](https://rdrr.io/cran/lme4/man/VerbAgg.html) を用いる．混合モデルの点推定のためのパッケージ `lme4` [@Bates+2015] で利用可能になっている．\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\ndata(\"VerbAgg\", package = \"lme4\")\ndf <- VerbAgg\n```\n:::\n\n\n\n\n質問票は「自分が意思表示をしたのにバスが止まってくれなかったので悪態をついた」などのもので，同意できるかを３段階 \"yes\", \"perhaps\", \"no\" で評価する [@Boeck-Wilson2004 pp.7-8]．\n\n応答は３段階の順序応答 `resp` とこれを２段階にしたもの `r2` である．\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkable(head(df))\n```\n\n::: {.cell-output-display}\n\n\n| Anger|Gender |item        |resp    |id |btype |situ  |mode |r2 |\n|-----:|:------|:-----------|:-------|:--|:-----|:-----|:----|:--|\n|    20|M      |S1WantCurse |no      |1  |curse |other |want |N  |\n|    11|M      |S1WantCurse |no      |2  |curse |other |want |N  |\n|    17|F      |S1WantCurse |perhaps |3  |curse |other |want |Y  |\n|    21|F      |S1WantCurse |perhaps |4  |curse |other |want |Y  |\n|    17|F      |S1WantCurse |perhaps |5  |curse |other |want |Y  |\n|    21|F      |S1WantCurse |yes     |6  |curse |other |want |Y  |\n\n\n:::\n:::\n\n\n\n\n### 固定効果１母数モデル\n\n通常の１母数モデルに，過分散を説明するための固定効果の項 $\\al_0$ を加えたモデルを考える：\n\n$$\ng(\\P[Y_{ik}=1])=\\al_{j[i]}-\\beta_{k[i]}+\\al_0,\\qquad\\al_0\\sim\\rt(3;0,2.5),\n$$\n$$\n\\al_j\\sim\\rN(\\mu_\\al,\\sigma_\\al^2),\\quad\\mu_\\al\\sim\\rN(0,3),\\quad\\sigma_\\al\\sim\\rN(0,3),\n$$\n$$\n\\beta_k\\sim\\rN(\\mu_\\beta,\\sigma_\\beta^2),\\quad\\mu_\\beta\\sim\\rN(0,3),\\quad\\sigma_\\beta\\sim\\rN(0,3).\n$$\n\n`sd` というクラスはグループレベル変数の標準偏差を意味する．\n\n$\\al_j,\\beta_k$ の定数の違いに関する識別不可能性は，いずれも $0$ を中心とした\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nformula_1PL <- bf(r2 ~ 1 + (1|item) + (1|id))\nprior_1PL <-  prior(\"normal(0,3)\", class=\"sd\", group = \"id\") +\n  prior(\"normal(0,3)\", class=\"sd\", group = \"item\")\nfit_1PL <- brm(\n  formula_1PL,\n  data = df,\n  family = brmsfamily(\"bernoulli\", link = \"logit\"),\n  prior = prior_1PL,\n  chains = 4, cores = 4\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_summary(fit_1PL)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                prior     class      coef group resp dpar nlpar lb ub\n student_t(3, 0, 2.5) Intercept                                      \n student_t(3, 0, 2.5)        sd                                  0   \n          normal(0,3)        sd              id                  0   \n          normal(0,3)        sd Intercept    id                  0   \n          normal(0,3)        sd            item                  0   \n          normal(0,3)        sd Intercept  item                  0   \n       source\n      default\n      default\n         user\n (vectorized)\n         user\n (vectorized)\n```\n\n\n:::\n:::\n\n\n\n\n`vectorized` というのは，下記 Stan コード内で尤度は for 文で構成されるが，このループに入れなくて良いものがある場合をいう．\n\n::: {.callout-tip collapse=\"true\" title=\"Stan コードの表示\"}\n\n```r\nstancode(fit_1PL)\n```\n\nによって推定に用いられた Stan コードが表示できる．\n\n次を見る限り，確かに意図したモデルになっている：\n\n```stan\n// generated with brms 2.21.0\nfunctions {\n}\ndata {\n  int<lower=1> N;  // total number of observations\n  array[N] int Y;  // response variable\n  // data for group-level effects of ID 1\n  int<lower=1> N_1;  // number of grouping levels\n  int<lower=1> M_1;  // number of coefficients per level\n  array[N] int<lower=1> J_1;  // grouping indicator per observation\n  // group-level predictor values\n  vector[N] Z_1_1;\n  // data for group-level effects of ID 2\n  int<lower=1> N_2;  // number of grouping levels\n  int<lower=1> M_2;  // number of coefficients per level\n  array[N] int<lower=1> J_2;  // grouping indicator per observation\n  // group-level predictor values\n  vector[N] Z_2_1;\n  int prior_only;  // should the likelihood be ignored?\n}\ntransformed data {\n}\nparameters {\n  real Intercept;  // temporary intercept for centered predictors\n  vector<lower=0>[M_1] sd_1;  // group-level standard deviations\n  array[M_1] vector[N_1] z_1;  // standardized group-level effects\n  vector<lower=0>[M_2] sd_2;  // group-level standard deviations\n  array[M_2] vector[N_2] z_2;  // standardized group-level effects\n}\ntransformed parameters {\n  vector[N_1] r_1_1;  // actual group-level effects\n  vector[N_2] r_2_1;  // actual group-level effects\n  real lprior = 0;  // prior contributions to the log posterior\n  r_1_1 = (sd_1[1] * (z_1[1]));\n  r_2_1 = (sd_2[1] * (z_2[1]));\n  lprior += student_t_lpdf(Intercept | 3, 0, 2.5);\n  lprior += normal_lpdf(sd_1 | 0,3)\n    - 1 * normal_lccdf(0 | 0,3);\n  lprior += normal_lpdf(sd_2 | 0,3)\n    - 1 * normal_lccdf(0 | 0,3);\n}\nmodel {\n  // likelihood including constants\n  if (!prior_only) {\n    // initialize linear predictor term\n    vector[N] mu = rep_vector(0.0, N);\n    mu += Intercept;\n    for (n in 1:N) {\n      // add more terms to the linear predictor\n      mu[n] += r_1_1[J_1[n]] * Z_1_1[n] + r_2_1[J_2[n]] * Z_2_1[n];\n    }\n    target += bernoulli_logit_lpmf(Y | mu);\n  }\n  // priors including constants\n  target += lprior;\n  target += std_normal_lpdf(z_1[1]);\n  target += std_normal_lpdf(z_2[1]);\n}\ngenerated quantities {\n  // actual population-level intercept\n  real b_Intercept = Intercept;\n}\n```\n\n`-1*normal_lccdf(0|0,3)` というのは定数であり，推定には全く影響を与えないが，後続の `bridgesampling` パッケージ [@Gronau-Singmann-Wagenmakers2020] によるモデル比較の API 構築のために付けられたものである [@Burkner2021 p.21]．\n\n:::\n\n<!-- \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum <- summary(fit_1PL)\nrow1 <- data.frame(sum$fix)\nrow2 <- data.frame(sum$random[1]) %>%\n  setNames(colnames(row1))\nrow3 <- data.frame(sum$random[2]) %>%\n  setNames(colnames(row1))\nkable(rbind(row1, row2, row3))\n```\n\n::: {.cell-output-display}\n\n\n|               |   Estimate| Est.Error|   l.95..CI|  u.95..CI|     Rhat|  Bulk_ESS|  Tail_ESS|\n|:--------------|----------:|---------:|----------:|---------:|--------:|---------:|---------:|\n|Intercept      | -0.1564909| 0.2435213| -0.6341661| 0.3100085| 1.004683|  354.7554|  811.8406|\n|sd(Intercept)  |  1.3877896| 0.0728928|  1.2496141| 1.5372286| 1.004518| 1004.1877| 1840.1941|\n|sd(Intercept)1 |  1.2233172| 0.1905751|  0.9072381| 1.6420208| 1.000758|  470.7709| 1009.1518|\n\n\n:::\n:::\n\n\n\n-->\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit_1PL)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: bernoulli \n  Links: mu = logit \nFormula: r2 ~ 1 + (1 | item) + (1 | id) \n   Data: df (Number of observations: 7584) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~id (Number of levels: 316) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     1.39      0.07     1.25     1.54 1.00     1004     1840\n\n~item (Number of levels: 24) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     1.22      0.19     0.91     1.64 1.00      471     1009\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    -0.16      0.24    -0.63     0.31 1.00      355      812\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\n\n低い ESS から変動効果の項 $\\ep_i$ の推定に苦労していることがわかる．\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit_1PL)\n```\n\n::: {.cell-output-display}\n![](BayesGLMM_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\nここにはグローバルなパラメータしか表示されておらず，ランダム効果の結果は次のように見る必要がある：\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nranef_item <- ranef(fit_1PL)$item\nposterior_means <- ranef_item[,1,1]\nlower_bounds <- ranef_item[,3,1]\nupper_bounds <- ranef_item[,4,1]\nplot_df_item <- data.frame(\n  item = rownames(ranef_item),\n  mean = posterior_means,\n  lower = lower_bounds,\n  upper = upper_bounds\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np_PL1 <- ggplot(plot_df_item, aes(x = mean, y = item)) +\n  geom_point() +\n  geom_errorbar(aes(xmin = lower, xmax = upper), width = 0.2) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n  labs(title = \"Posterior Means and 95% Credible Intervals for Items\",\n       x = \"Posterior Estimate\",\n       y = \"Item\")\np_PL1\n```\n\n::: {.cell-output-display}\n![](BayesGLMM_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\n多くの参加者にとって腹立たしい例とそうでない例が区別できているようである．\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_df_id <- plot_df_id %>% arrange(mean) %>% mutate(rank = row_number())\np_PL1_id <- ggplot(plot_df_id, aes(x = mean, y = rank)) +\n  geom_point() +\n  geom_errorbar(aes(xmin = lower, xmax = upper), width = 0.2) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n  labs(title = \"Posterior Means and 95% Credible Intervals for Individuals\",\n       x = \"Posterior Estimate\",\n       y = \"Individual\")\np_PL1_id\n```\n\n::: {.cell-output-display}\n![](BayesGLMM_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\nこうして怒りやすかった人を並べることができる．\n\nしかしガタガタしている区分定数的な模様が見れる．実はこれは item の分だけある．というのも，「何個の項目に Yes と答えたか」だけが $\\al_j$ を決める要因になってしまっているためである．\n\nこれが項目識別のできない１母数モデルの限界である．\n\n### 固定効果２母数モデル\n\n項目識別力母数 $\\gamma_k$ を導入する：\n$$\ng(\\mu_i)=\\gamma_{k[i]}\\Paren{\\al_{j[i]}-\\beta_{k[i]}},\n$$\n\nすると追加の制約が必要になる．ここでは理想点モデルの場合と違い，研究のデザインから $\\gamma_{k[i]}$ は正として良いだろう．\n\nこれを変数変換 $\\gamma_k=\\exp(\\log\\gamma_k)$ によってモデルに知らせることとする．\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nformula_2PL <- bf(\n  r2 ~ exp(loggamma) * eta,\n  loggamma ~ 1 + (1|i|item),\n  eta ~ 1 + (1|i|item) + (1|id),\n  nl = TRUE\n)\n```\n:::\n\n\n\n\n$g(\\mu_i)$ の右辺はもはや $\\log\\gamma_k$ の線型関数ではないので，これを `nl=TRUE` によって知らせる必要がある．\n\n`|i|` によって，$\\log\\gamma_k$ と $\\eta_{jk}$ 内の項 $\\beta_k$ には相関があることを知らせている [@Burkner2018 p.397]．項目難易度 $\\beta_k$ が低いほど識別力 $\\log\\gamma_k$ は低いとしているのである．\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_2PL <-  prior(\"normal(0,5)\", class=\"b\", nlpar = \"eta\") +\n  prior(\"normal(0,1)\", class=\"b\", nlpar = \"loggamma\") +\n  prior(\"constant(1)\", class=\"sd\", group = \"id\", nlpar = \"eta\") +\n  prior(\"normal(0,3)\", class=\"sd\", group = \"item\", nlpar = \"eta\") +\n  prior(\"normal(0,1)\", class=\"sd\", group = \"item\", nlpar = \"loggamma\")\n\nfit_2PL <- brm(\n  formula = formula_2PL,\n  data = df,\n  family = brmsfamily(\"bernoulli\", link = \"logit\"),\n  prior = prior_2PL,\n  chains = 4, cores = 4\n)\n```\n:::\n\n\n\n\nついに Stan が２分ほどかかるようになった上に，収束に苦労しており，ESS が低くなっている．\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit_2PL)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: There were 1 divergent transitions after warmup. Increasing\nadapt_delta above 0.8 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: bernoulli \n  Links: mu = logit \nFormula: r2 ~ exp(loggamma) * eta \n         loggamma ~ 1 + (1 | i | item)\n         eta ~ 1 + (1 | i | item) + (1 | id)\n   Data: df (Number of observations: 7584) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~item (Number of levels: 24) \n                                      Estimate Est.Error l-95% CI u-95% CI Rhat\nsd(loggamma_Intercept)                    0.12      0.06     0.01     0.24 1.01\nsd(eta_Intercept)                         0.93      0.16     0.68     1.28 1.00\ncor(loggamma_Intercept,eta_Intercept)     0.31      0.36    -0.46     0.90 1.01\n                                      Bulk_ESS Tail_ESS\nsd(loggamma_Intercept)                     712      874\nsd(eta_Intercept)                         1076     1826\ncor(loggamma_Intercept,eta_Intercept)      264      645\n\n~id (Number of levels: 316) \n                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(eta_Intercept)     1.00      0.00     1.00     1.00   NA       NA       NA\n\nRegression Coefficients:\n                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nloggamma_Intercept     0.32      0.06     0.20     0.44 1.00     1193     1895\neta_Intercept         -0.14      0.20    -0.52     0.25 1.00     1186     1676\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nranef_item2 <- ranef(fit_2PL)$item\nposterior_means <- ranef_item2[,1,\"eta_Intercept\"]\nlower_bounds <- ranef_item2[,3,\"eta_Intercept\"]\nupper_bounds <- ranef_item2[,4,\"eta_Intercept\"]\nplot_df_item2 <- data.frame(\n  item = rownames(ranef_item2),\n  mean = posterior_means,\n  lower = lower_bounds,\n  upper = upper_bounds\n)\np_PL2 <- ggplot(plot_df_item2, aes(x = mean, y = item)) +\n  geom_point() +\n  geom_errorbar(aes(xmin = lower, xmax = upper), width = 0.2) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n  labs(title = \"2PL Model\",\n       x = \"Posterior Estimate\",\n       y = \"Item\")\ngrid.arrange(p_PL1, p_PL2, nrow = 1)\n```\n\n::: {.cell-output-display}\n![](BayesGLMM_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n\n識別力パラメータ $\\gamma_k$ が $1$ より大きい値をとっており，これが変動を吸収しているため，$\\al_j$ は $0$ に縮小されて推定されるようになっている．\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nranef_id2 <- ranef(fit_2PL)$id\nposterior_means <- ranef_id2[,1,\"eta_Intercept\"]\nlower_bounds <- ranef_id2[,3,\"eta_Intercept\"]\nupper_bounds <- ranef_id2[,4,\"eta_Intercept\"]\nplot_df_id2 <- data.frame(\n  id = rownames(ranef_id2),\n  mean = posterior_means,\n  lower = lower_bounds,\n  upper = upper_bounds\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_df_id2 <- plot_df_id2 %>% arrange(mean) %>% mutate(rank = row_number())\np_PL2_id <- ggplot(plot_df_id2, aes(x = mean, y = rank)) +\n  geom_point() +\n  geom_errorbar(aes(xmin = lower, xmax = upper), width = 0.2) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n  labs(title = \"2PL Model\",\n       x = \"Posterior Estimate\",\n       y = \"Individual\")\ngrid.arrange(p_PL1_id, p_PL2_id, nrow = 1)\n```\n\n::: {.cell-output-display}\n![](BayesGLMM_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\n\n少し滑らかになっている．\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(ranef_id[,1,\"Intercept\"], ranef_id2[,1,\"eta_Intercept\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9994873\n```\n\n\n:::\n:::\n\n\n\n\nしかし線型の相関になっており，軟化以上の変化は導入されなかったことがわかる．\n\nそれもそうである．モデルの表現力はあげたから解像度は高くなったが，モデルに新しい情報を入れたわけではないのである．\n\n### 共変量の追加\n\n理想点モデルなど多くの項目応答モデルは，$\\al_j,\\beta_k$ の推定に終始してきたが，本当のリサーチクエスチョンはその先にある．\n\n個人レベルの共変量を追加した階層モデルを構築して，$\\al_j$ の位置や応答の傾向への影響を調べることが真の目標であった．\n\n#### 項目共変量の追加\n\n本データにおいて項目は $2\\times2\\times3$ の split-plot デザインがなされている．\n\n`mode` とは「悪態をつきたい」と「咄嗟についてしまう」という２種の行動を区別するためのものである．この２つの行動容態は，本人の抑制的な意識が実際に働いたかどうかにおいて全く質的に異なる．モデルにこれを教えたらどうなるだろうか？\n\n`situ` とはシチュエーションであり，自分に責任があるか（「店に入ろうとした瞬間閉店時間になった」など）他人に責任があるか（「バスが止まってくれなかった」など）の２項目がある．\n\n`btype` は行動様式であり，「悪態をつく」「叱る」「怒鳴りつける」の３項目がある．後に行くほど他人への攻撃性が強い．\n\n最初に考えられるモデル\n\n```r\nr2 ~ btype + situ + mode + (1|item) + (1 + mode|id)\n```\n\nは，元々の１母数モデルに変動切片項を３つ追加した上に，`mode` の係数を個人ごとに変えることを許したものである．これは `mode` の効果が個人ごとに異なるだろうという信念による．\n\nしかしこのモデルに至る前に，`1` を `0` にすることで `modedo` と `modewant` 双方の標準偏差を推定することを考える（`1` の場合は `modewant` の標準偏差の代わりに `Intercept` の標準偏差を推定する）．\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nformula_1PL_cov <- bf(\n  r2 ~ btype + situ + mode + (1|item) + (0 + mode|id)\n)\nfit_1PL_cov <- brm(\n  formula = formula_1PL_cov,\n  data = df,\n  family = brmsfamily(\"bernoulli\", link = \"logit\"),\n  prior = prior_1PL,\n  chains = 4, cores = 4\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit_1PL_cov)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: bernoulli \n  Links: mu = logit \nFormula: r2 ~ btype + situ + mode + (1 | item) + (0 + mode | id) \n   Data: df (Number of observations: 7584) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~id (Number of levels: 316) \n                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(modewant)             1.47      0.09     1.30     1.65 1.00     1898\nsd(modedo)               1.67      0.10     1.48     1.88 1.00     1932\ncor(modewant,modedo)     0.77      0.04     0.69     0.84 1.00     1674\n                     Tail_ESS\nsd(modewant)             3005\nsd(modedo)               2826\ncor(modewant,modedo)     2675\n\n~item (Number of levels: 24) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.46      0.09     0.32     0.68 1.00     1643     2370\n\nRegression Coefficients:\n           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      1.88      0.23     1.42     2.32 1.00     1923     2640\nbtypescold    -1.12      0.24    -1.60    -0.63 1.00     2004     2515\nbtypeshout    -2.23      0.25    -2.73    -1.74 1.00     1962     2482\nsituself      -1.12      0.21    -1.53    -0.70 1.00     1941     2500\nmodedo        -0.77      0.21    -1.18    -0.33 1.00     2114     2523\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\n\n`modedo` の係数が負になっており，悪態をつきたくなっても，実際にする人の割合は下がることがわかる．\n\nだが係数の `-0.77` が大きいかどうかがわからない．これには対数オッズ比のスケールから元のスケールに戻す便利な関数がある：\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconditional_effects(fit_1PL_cov, \"mode\")\n```\n\n::: {.cell-output-display}\n![](BayesGLMM_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\n\n確率としての減少は軽微だがあることがわかる．次に気づくことは `do` の方がエラーバーが長いことである．２つの係数は相関しているので，頻度論的な検定は難しいかもしれないが，２つの標準偏差の差の事後分布を見ることでチェックすることができる：\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhyp <- \"modedo - modewant > 0\"\nhypothesis(fit_1PL_cov, hyp, class = \"sd\", group = \"id\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nHypothesis Tests for class sd_id:\n             Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n1 (modedo-modewant) > 0      0.2      0.12     0.01     0.39       23.1\n  Post.Prob Star\n1      0.96    *\n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n```\n\n\n:::\n:::\n\n\n\n\n`0.96` の確率で `modedo` の標準偏差の方が大きいことがわかるが，その差も `0.2` ほどで，対数オッズ比としては大したことがないと思われる．\n\n#### 個人共変量の追加\n\nTrait Anger スコア [@Spielberger2010] が個人ごとに算出されており（`Anger` 変数），そのスコアによってどのように項目への反応が違うかを調べる．こうするとどんどん心理学の研究っぽくなる．\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nformula_1PL_cov_id <- bf(\n  r2 ~ Anger + Gender + btype + situ + mode + mode:Gender + (0+Gender|item) + (0+mode|id)\n)\nfit_1PL_cov_id <- brm(\n  formula = formula_1PL_cov_id,\n  data = df,\n  family = brmsfamily(\"bernoulli\", link = \"logit\"),\n  prior = prior_1PL,\n  chains = 4, cores = 4,\n  iter = 3000  # これ以上大きくすると GitHub にあげられない\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit_1PL_cov_id)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: bernoulli \n  Links: mu = logit \nFormula: r2 ~ Anger + Gender + btype + situ + mode + mode:Gender + (0 + Gender | item) + (0 + mode | id) \n   Data: df (Number of observations: 7584) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~id (Number of levels: 316) \n                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(modewant)             1.49      0.09     1.32     1.67 1.00     1998\nsd(modedo)               1.58      0.10     1.40     1.78 1.00     1715\ncor(modewant,modedo)     0.78      0.04     0.70     0.85 1.00     1529\n                     Tail_ESS\nsd(modewant)             2740\nsd(modedo)               2531\ncor(modewant,modedo)     2380\n\n~item (Number of levels: 24) \n                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(GenderF)              0.52      0.11     0.35     0.77 1.01     1342\nsd(GenderM)              0.34      0.11     0.16     0.57 1.00     1659\ncor(GenderF,GenderM)     0.78      0.18     0.32     0.99 1.00     2178\n                     Tail_ESS\nsd(GenderF)              2491\nsd(GenderM)              2553\ncor(GenderF,GenderM)     1911\n\nRegression Coefficients:\n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept          0.74      0.44    -0.14     1.59 1.00     1293     2072\nAnger              0.06      0.02     0.02     0.09 1.00     1274     2101\nGenderM           -0.10      0.24    -0.56     0.38 1.00      931     1839\nbtypescold        -1.03      0.22    -1.46    -0.60 1.00     1931     2144\nbtypeshout        -2.43      0.25    -2.90    -1.94 1.00     1472     1396\nsituself          -1.04      0.18    -1.38    -0.68 1.00     1919     2346\nmodedo            -0.98      0.23    -1.43    -0.51 1.00     1738     2315\nGenderM:modedo     0.89      0.24     0.40     1.35 1.00     2525     2932\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nconditional_effects(fit_1PL_cov_id, \"Anger\")\n```\n\n::: {.cell-output-display}\n![個人共変量の効果と，特異項目機能](BayesGLMM_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nconditional_effects(fit_1PL_cov_id, \"mode:Gender\")\n```\n\n::: {.cell-output-display}\n![](BayesGLMM_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n\n\n![](Files/cond_Anger.png)\n\n\n\n`Anger` の値が大きいほど悪態をつく確率が綺麗に上がっていく様子がわかる．\n\n加えて，女性の方が悪態を吐こうと思っても，実際に行動に移すには大きな壁があることがわかる．こうして `mode` と `Gender` の間の交絡が陽の下に明らかになった．\n\nこのような，項目共変量と個人共変量の間の交絡は **特異項目機能** (DIF: Differential Item Functioning) と呼ばれる．項目の特性が，被験者のグループによって違った機能を示すことは，例えばテスト理論では個人の潜在特性を推定する際の重大なノイズ要因となっており，これを統制することが重要な課題になる．\n\n### 特異項目機能の解析\n\nこの特異項目機能を，項目の特性ごとにさらに詳しく見ていく．\n\n特に怒鳴りつける行動様式を除き，悪態をつく行為と叱る行為は，男性と女性において違う機能を持っているのではないか？という仮説を検証してみる．\n\n女性が実際に悪態をつく／叱る行為にだけマークをつけるダミー変数 `dif` を用意する：\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf$dif <- as.numeric(with(\n  df,\n  Gender == \"F\" & mode == \"do\" & btype %in% c(\"curse\", \"scold\")\n))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nformula_1PL_dif <- bf(\n  r2 ~ Gender + dif + (1|item) + (1|id)\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_1PL_dif <- brm(\n  formula = formula_1PL_dif,\n  data = df,\n  family = brmsfamily(\"bernoulli\", link = \"logit\"),\n  prior = prior_1PL,\n  chains = 3, cores = 3,\n  # iter = 3000  # これ以上大きくすると GitHub にあげられない\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit_1PL_dif)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: bernoulli \n  Links: mu = logit \nFormula: r2 ~ Gender + dif + (1 | item) + (1 | id) \n   Data: df (Number of observations: 7584) \n  Draws: 3 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 3000\n\nMultilevel Hyperparameters:\n~id (Number of levels: 316) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     1.40      0.07     1.26     1.54 1.00      793     1557\n\n~item (Number of levels: 24) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     1.34      0.21     1.00     1.84 1.01      684     1088\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     0.12      0.31    -0.51     0.72 1.00      304      502\nGenderM      -0.01      0.21    -0.45     0.41 1.00      573      864\ndif          -0.95      0.14    -1.23    -0.67 1.00     2875     1778\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\n\n`dif` の係数 `-0.94` を見ることで，殊に「女性」と「実際に悪態を吐いたり叱ったりする」という組み合わせは特異な項目機能を持っていることがわかる．\n\n<!--\n\n### 極大階層モデルの推論\n\n関連のある共変量を全てモデルに含めて推論する方法が，最終的にはやはり好ましいとされる [@Barr+2013]．\n\n複雑な階層モデルであっても，Stan が実装する HMC サンプラーは効率的に推論を実行してくれるようである．これを見ていこう．\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nformula_1PL_maximal <- bf(\n  r2 ~ 1 + Anger + Gender + btype + situ + mode + (1 + Anger + Gender | item) + (1 + btype + situ + mode | id)\n)\nfit_1PL_maximal <- brm(\n  formula = formula_1PL_maximal,\n  data = df,\n  family = brmsfamily(\"bernoulli\", link = \"logit\"),\n  prior = prior_1PL,\n  chains = 4, cores = 4\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit_1PL_maximal)\n```\n:::\n\n\n\n\n-->\n\n## 文献案内 {.appendix}\n\n[@Burkner2021] に項目応答モデルのベイズ的な扱いが取り上げられている．特にパッケージ `brms` を用いた例が３つある．\n\nDIF に関する日本語文献に [@熊谷龍一2012] がある．",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}