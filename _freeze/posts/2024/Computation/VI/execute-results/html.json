{
  "hash": "746d30d9d35887c7ab9fff328109a4c3",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"変分推論（１）K-平均アルゴリズム\"\nauthor: \"Draft Draft\"\ndate: 2/3/2024\ndate-modified: 2/10/2024\ncategories: [Bayesian Machine Learning, Computation, Python]\ntoc: true\nnumber-sections: true\ncode-block-bg: true\ncode-overflow: wrap\ncode-fold: true\ncode-annotations: select\nbibliography: \n    - ../../../mathematics.bib\n    - ../../../bib.bib\ncsl: ../../../apa.csl\ncrossref:\n    sec-prefix: 節\n    eq-prefix: 式\n    def-prefix: 定義\n    def-title: 定義\n    thm-prefix: 定理\n    thm-title: 定理\n    fig-prefix: 図\n    fig-title: 図\nabstract-title: 概要\nabstract: 数学者のために，変分推論の基本的な考え方を説明するシリーズであるが，今回は変分 Bayes アルゴリズムの特殊な場合である EM アルゴリズムの，さらにその特殊な場合である $K$-平均法の説明から始める．\n---\n\n::: {.hidden}\n$$\n\\usepackage[all]{xy}\\usepackage{amsmath}\\newcommand{\\y}{\\b{y}}\\newcommand{\\mi}{\\,|\\,}\n\n%%% 演算子\n\\DeclareMathOperator{\\grad}{\\mathrm{grad}}\\DeclareMathOperator{\\rot}{\\mathrm{rot}}\\DeclareMathOperator{\\divergence}{\\mathrm{div}}\\DeclareMathOperator{\\tr}{tr}\\DeclareMathOperator{\\Tr}{Tr}\\newcommand{\\pr}{\\mathrm{pr}}\n\\newcommand{\\Map}{\\mathrm{Map}}\\newcommand{\\dom}{\\mathrm{Dom}\\;}\\newcommand{\\cod}{\\mathrm{Cod}\\;}\\newcommand{\\supp}{\\mathrm{supp}\\;}\n\n\n%%% 線型代数学\n\\newcommand{\\vctr}[2]{\\begin{pmatrix}#1\\\\#2\\end{pmatrix}}\\newcommand{\\vctrr}[3]{\\begin{pmatrix}#1\\\\#2\\\\#3\\end{pmatrix}}\\newcommand{\\mtrx}[4]{\\begin{pmatrix}#1&#2\\\\#3&#4\\end{pmatrix}}\\newcommand{\\smtrx}[4]{\\paren{\\begin{smallmatrix}#1&#2\\\\#3&#4\\end{smallmatrix}}}\\newcommand{\\Ker}{\\mathrm{Ker}\\;}\\newcommand{\\Coker}{\\mathrm{Coker}\\;}\\newcommand{\\Coim}{\\mathrm{Coim}\\;}\\DeclareMathOperator{\\rank}{\\mathrm{rank}}\\newcommand{\\lcm}{\\mathrm{lcm}}\\newcommand{\\GL}{\\mathrm{GL}}\\newcommand{\\SL}{\\mathrm{SL}}\\newcommand{\\alt}{\\mathrm{alt}}\\DeclareMathOperator{\\sgn}{sgn}\n%%% 複素解析学\n\\renewcommand{\\Re}{\\mathrm{Re}\\;}\\renewcommand{\\Im}{\\mathrm{Im}\\,}\\newcommand{\\Gal}{\\mathrm{Gal}}\\newcommand{\\PGL}{\\mathrm{PGL}}\\newcommand{\\PSL}{\\mathrm{PSL}}\\newcommand{\\Log}{\\mathrm{Log}\\,}\\newcommand{\\Res}{\\mathrm{Res}\\,}\\newcommand{\\on}{\\mathrm{on}\\;}\\newcommand{\\hatC}{\\widehat{\\C}}\\newcommand{\\hatR}{\\hat{\\R}}\\newcommand{\\PV}{\\mathrm{P.V.}}\\newcommand{\\diam}{\\mathrm{diam}}\\newcommand{\\Area}{\\mathrm{Area}}\\newcommand{\\Lap}{\\Laplace}\\newcommand{\\f}{\\mathbf{f}}\\newcommand{\\cR}{\\mathcal{R}}\\newcommand{\\const}{\\mathrm{const.}}\\newcommand{\\Om}{\\Omega}\\newcommand{\\Cinf}{C^\\infty}\\newcommand{\\ep}{\\epsilon}\\newcommand{\\dist}{\\mathrm{dist}}\\newcommand{\\opart}{\\o{\\partial}}\\newcommand{\\Length}{\\mathrm{Length}}\n%%% 集合と位相\n\\newcommand{\\cA}{\\mathcal{A}}\\newcommand{\\cO}{\\mathcal{O}}\\newcommand{\\cW}{\\mathcal{W}}\\renewcommand{\\O}{\\mathcal{O}}\\renewcommand{\\S}{\\mathcal{S}}\\newcommand{\\U}{\\mathcal{U}}\\newcommand{\\V}{\\mathrm{V}}\\renewcommand{\\P}{\\operatorname{P}}\\newcommand{\\R}{\\mathbb{R}}\\newcommand{\\N}{\\mathbb{N}}\\newcommand{\\bN}{\\mathbb{N}}\\newcommand{\\C}{\\mathrm{C}}\\newcommand{\\bC}{\\mathbb{C}}\\newcommand{\\Z}{\\mathcal{Z}}\\newcommand{\\Q}{\\mathbb{Q}}\\newcommand{\\bQ}{\\mathbb{Q}}\\newcommand{\\TV}{\\mathrm{TV}}\\newcommand{\\ORD}{\\mathrm{ORD}}\\newcommand{\\Card}{\\mathrm{Card}\\,}\\newcommand{\\Top}{\\mathrm{Top}}\\newcommand{\\Disc}{\\mathrm{Disc}}\\newcommand{\\Codisc}{\\mathrm{Codisc}}\\newcommand{\\CoDisc}{\\mathrm{CoDisc}}\\newcommand{\\Ult}{\\mathrm{Ult}}\\newcommand{\\ord}{\\mathrm{ord}}\\DeclareMathOperator{\\maj}{\\mathrm{maj}}\\newcommand{\\bS}{\\mathbb{S}}\\newcommand{\\PConn}{\\mathrm{PConn}}\n\n%%% 形式言語理論\n\\newcommand{\\REGEX}{\\mathrm{REGEX}}\\newcommand{\\RE}{\\mathbf{RE}}\n%%% Graph Theory\n\\newcommand{\\SimpGph}{\\mathrm{SimpGph}}\\newcommand{\\Gph}{\\mathrm{Gph}}\\newcommand{\\mult}{\\mathrm{mult}}\\newcommand{\\inv}{\\mathrm{inv}}\n\n%%% 多様体\n\\newcommand{\\Der}{\\mathrm{Der}}\\newcommand{\\osub}{\\overset{\\mathrm{open}}{\\subset}}\\newcommand{\\osup}{\\overset{\\mathrm{open}}{\\supset}}\\newcommand{\\al}{\\alpha}\\newcommand{\\K}{\\mathbb{K}}\\newcommand{\\Sp}{\\mathrm{Sp}}\\newcommand{\\g}{\\mathfrak{g}}\\newcommand{\\h}{\\mathfrak{h}}\\newcommand{\\Imm}{\\mathrm{Imm}}\\newcommand{\\Imb}{\\mathrm{Imb}}\\newcommand{\\Gr}{\\mathrm{Gr}}\n\\DeclareMathOperator{\\Exp}{Exp}\\DeclareMathOperator{\\codim}{codim}\n%%% 代数\n\\newcommand{\\Ad}{\\mathrm{Ad}}\\newcommand{\\finsupp}{\\mathrm{fin\\;supp}}\\newcommand{\\SO}{\\mathrm{SO}}\\newcommand{\\SU}{\\mathrm{SU}}\\newcommand{\\acts}{\\curvearrowright}\\newcommand{\\mono}{\\hookrightarrow}\\newcommand{\\epi}{\\twoheadrightarrow}\\newcommand{\\Stab}{\\mathrm{Stab}}\\newcommand{\\nor}{\\mathrm{nor}}\\newcommand{\\T}{\\mathbb{T}}\\newcommand{\\Aff}{\\mathrm{Aff}}\\newcommand{\\rsub}{\\triangleleft}\\newcommand{\\rsup}{\\triangleright}\\newcommand{\\subgrp}{\\overset{\\mathrm{subgrp}}{\\subset}}\\newcommand{\\Ext}{\\mathrm{Ext}}\\newcommand{\\sbs}{\\subset}\\newcommand{\\sps}{\\supset}\\newcommand{\\In}{\\mathrm{in}\\;}\\newcommand{\\Tor}{\\mathrm{Tor}}\\newcommand{\\p}{\\b{p}}\\newcommand{\\q}{\\mathfrak{q}}\\newcommand{\\m}{\\mathfrak{m}}\\newcommand{\\cS}{\\mathcal{S}}\\newcommand{\\Frac}{\\mathrm{Frac}\\,}\\newcommand{\\Spec}{\\mathrm{Spec}\\,}\\newcommand{\\bA}{\\mathbb{A}}\\newcommand{\\Sym}{\\mathrm{Sym}}\\newcommand{\\Ann}{\\mathrm{Ann}}\\newcommand{\\Her}{\\mathrm{Her}}\\newcommand{\\Bil}{\\mathrm{Bil}}\\newcommand{\\Ses}{\\mathrm{Ses}}\\newcommand{\\FVS}{\\mathrm{FVS}}\n%%% 代数的位相幾何学\n\\newcommand{\\Ho}{\\mathrm{Ho}}\\newcommand{\\CW}{\\mathrm{CW}}\\newcommand{\\lc}{\\mathrm{lc}}\\newcommand{\\cg}{\\mathrm{cg}}\\newcommand{\\Fib}{\\mathrm{Fib}}\\newcommand{\\Cyl}{\\mathrm{Cyl}}\\newcommand{\\Ch}{\\mathrm{Ch}}\n%%% 微分幾何学\n\\newcommand{\\rP}{\\mathrm{P}}\\newcommand{\\rE}{\\mathrm{E}}\\newcommand{\\e}{\\b{e}}\\renewcommand{\\k}{\\b{k}}\\newcommand{\\Christ}[2]{\\begin{Bmatrix}#1\\\\#2\\end{Bmatrix}}\\renewcommand{\\Vec}[1]{\\overrightarrow{\\mathrm{#1}}}\\newcommand{\\hen}[1]{\\mathrm{#1}}\\renewcommand{\\b}[1]{\\boldsymbol{#1}}\n\n%%% 函数解析\n\\newcommand{\\Inc}{\\mathrm{Inc}}\\newcommand{\\aInc}{\\mathrm{aInc}}\\newcommand{\\HS}{\\mathrm{HS}}\\newcommand{\\loc}{\\mathrm{loc}}\\newcommand{\\Lh}{\\mathrm{L.h.}}\\newcommand{\\Epi}{\\mathrm{Epi}}\\newcommand{\\slim}{\\mathrm{slim}}\\newcommand{\\Ban}{\\mathrm{Ban}}\\newcommand{\\Hilb}{\\mathrm{Hilb}}\\newcommand{\\Ex}{\\mathrm{Ex}}\\newcommand{\\Co}{\\mathrm{Co}}\\newcommand{\\sa}{\\mathrm{sa}}\\newcommand{\\nnorm}[1]{{\\left\\vert\\kern-0.25ex\\left\\vert\\kern-0.25ex\\left\\vert #1 \\right\\vert\\kern-0.25ex\\right\\vert\\kern-0.25ex\\right\\vert}}\\newcommand{\\dvol}{\\mathrm{dvol}}\\newcommand{\\Sconv}{\\mathrm{Sconv}}\\newcommand{\\I}{\\mathcal{I}}\\newcommand{\\nonunital}{\\mathrm{nu}}\\newcommand{\\cpt}{\\mathrm{cpt}}\\newcommand{\\lcpt}{\\mathrm{lcpt}}\\newcommand{\\com}{\\mathrm{com}}\\newcommand{\\Haus}{\\mathrm{Haus}}\\newcommand{\\proper}{\\mathrm{proper}}\\newcommand{\\infinity}{\\mathrm{inf}}\\newcommand{\\TVS}{\\mathrm{TVS}}\\newcommand{\\ess}{\\mathrm{ess}}\\newcommand{\\ext}{\\mathrm{ext}}\\newcommand{\\Index}{\\mathrm{Index}\\;}\\newcommand{\\SSR}{\\mathrm{SSR}}\\newcommand{\\vs}{\\mathrm{vs.}}\\newcommand{\\fM}{\\mathfrak{M}}\\newcommand{\\EDM}{\\mathrm{EDM}}\\newcommand{\\Tw}{\\mathrm{Tw}}\\newcommand{\\fC}{\\mathfrak{C}}\\newcommand{\\bn}{\\boldsymbol{n}}\\newcommand{\\br}{\\boldsymbol{r}}\\newcommand{\\Lam}{\\Lambda}\\newcommand{\\lam}{\\lambda}\\newcommand{\\one}{\\mathbf{1}}\\newcommand{\\dae}{\\text{-a.e.}}\\newcommand{\\das}{\\text{-a.s.}}\\newcommand{\\td}{\\text{-}}\\newcommand{\\RM}{\\mathrm{RM}}\\newcommand{\\BV}{\\mathrm{BV}}\\newcommand{\\normal}{\\mathrm{normal}}\\newcommand{\\lub}{\\mathrm{lub}\\;}\\newcommand{\\Graph}{\\mathrm{Graph}}\\newcommand{\\Ascent}{\\mathrm{Ascent}}\\newcommand{\\Descent}{\\mathrm{Descent}}\\newcommand{\\BIL}{\\mathrm{BIL}}\\newcommand{\\fL}{\\mathfrak{L}}\\newcommand{\\De}{\\Delta}\n%%% 積分論\n\\newcommand{\\calA}{\\mathcal{A}}\\newcommand{\\calB}{\\mathcal{B}}\\newcommand{\\D}{\\mathcal{D}}\\newcommand{\\Y}{\\mathcal{Y}}\\newcommand{\\calC}{\\mathcal{C}}\\renewcommand{\\ae}{\\mathrm{a.e.}\\;}\\newcommand{\\cZ}{\\mathcal{Z}}\\newcommand{\\fF}{\\mathfrak{F}}\\newcommand{\\fI}{\\mathfrak{I}}\\newcommand{\\E}{\\operatorname{E}}\\newcommand{\\rV}{\\mathrm{V}}\\newcommand{\\cE}{\\mathcal{E}}\\newcommand{\\sMap}{\\sigma\\textrm{-}\\mathrm{Map}}\\DeclareMathOperator*{\\argmax}{arg\\,max}\\DeclareMathOperator*{\\argmin}{arg\\,min}\\newcommand{\\cC}{\\mathcal{C}}\\newcommand{\\comp}{\\complement}\\newcommand{\\J}{\\mathcal{J}}\\newcommand{\\sumN}[1]{\\sum_{#1\\in\\N}}\\newcommand{\\cupN}[1]{\\cup_{#1\\in\\N}}\\newcommand{\\capN}[1]{\\cap_{#1\\in\\N}}\\newcommand{\\Sum}[1]{\\sum_{#1=1}^\\infty}\\newcommand{\\sumn}{\\sum_{n=1}^\\infty}\\newcommand{\\summ}{\\sum_{m=1}^\\infty}\\newcommand{\\sumk}{\\sum_{k=1}^\\infty}\\newcommand{\\sumi}{\\sum_{i=1}^\\infty}\\newcommand{\\sumj}{\\sum_{j=1}^\\infty}\\newcommand{\\cupn}{\\cup_{n=1}^\\infty}\\newcommand{\\capn}{\\cap_{n=1}^\\infty}\\newcommand{\\cupk}{\\cup_{k=1}^\\infty}\\newcommand{\\cupi}{\\cup_{i=1}^\\infty}\\newcommand{\\cupj}{\\cup_{j=1}^\\infty}\\newcommand{\\limn}{\\lim_{n\\to\\infty}}\\renewcommand{\\L}{\\mathcal{L}}\\newcommand{\\cL}{\\mathcal{L}}\\newcommand{\\Cl}{\\mathrm{Cl}}\\newcommand{\\cN}{\\mathcal{N}}\\newcommand{\\Ae}{\\textrm{-a.e.}\\;}\\newcommand{\\csub}{\\overset{\\textrm{closed}}{\\subset}}\\newcommand{\\csup}{\\overset{\\textrm{closed}}{\\supset}}\\newcommand{\\wB}{\\wt{B}}\\newcommand{\\cG}{\\mathcal{G}}\\newcommand{\\Lip}{\\mathrm{Lip}}\\DeclareMathOperator{\\Dom}{\\mathrm{Dom}}\\newcommand{\\AC}{\\mathrm{AC}}\\newcommand{\\Mol}{\\mathrm{Mol}}\n%%% Fourier解析\n\\newcommand{\\Pe}{\\mathrm{Pe}}\\newcommand{\\wR}{\\wh{\\mathbb{\\R}}}\\newcommand*{\\Laplace}{\\mathop{}\\!\\mathbin\\bigtriangleup}\\newcommand*{\\DAlambert}{\\mathop{}\\!\\mathbin\\Box}\\newcommand{\\bT}{\\mathbb{T}}\\newcommand{\\dx}{\\dslash x}\\newcommand{\\dt}{\\dslash t}\\newcommand{\\ds}{\\dslash s}\n%%% 数値解析\n\\newcommand{\\round}{\\mathrm{round}}\\newcommand{\\cond}{\\mathrm{cond}}\\newcommand{\\diag}{\\mathrm{diag}}\n\\newcommand{\\Adj}{\\mathrm{Adj}}\\newcommand{\\Pf}{\\mathrm{Pf}}\\newcommand{\\Sg}{\\mathrm{Sg}}\n\n%%% 確率論\n\\newcommand{\\aseq}{\\overset{\\text{a.s.}}{=}}\\newcommand{\\deq}{\\overset{\\text{d}}{=}}\\newcommand{\\cV}{\\mathcal{V}}\\newcommand{\\FM}{\\mathrm{FM}}\\newcommand{\\KR}{\\mathrm{KR}}\\newcommand{\\rba}{\\mathrm{rba}}\\newcommand{\\rca}{\\mathrm{rca}}\\newcommand{\\Prob}{\\mathrm{Prob}}\\newcommand{\\X}{\\mathcal{X}}\\newcommand{\\Meas}{\\mathrm{Meas}}\\newcommand{\\as}{\\;\\text{a.s.}}\\newcommand{\\io}{\\;\\mathrm{i.o.}}\\newcommand{\\fe}{\\;\\text{f.e.}}\\newcommand{\\F}{\\mathcal{F}}\\newcommand{\\bF}{\\mathbb{F}}\\newcommand{\\W}{\\mathcal{W}}\\newcommand{\\Pois}{\\mathrm{Pois}}\\newcommand{\\iid}{\\text{i.i.d.}}\\newcommand{\\wconv}{\\rightsquigarrow}\\newcommand{\\Var}{\\mathrm{Var}}\\newcommand{\\xrightarrown}{\\xrightarrow{n\\to\\infty}}\\newcommand{\\au}{\\mathrm{au}}\\newcommand{\\cT}{\\mathcal{T}}\\newcommand{\\wto}{\\overset{\\text{w}}{\\to}}\\newcommand{\\dto}{\\overset{\\text{d}}{\\to}}\\newcommand{\\sto}{\\overset{\\text{s}}{\\to}}\\newcommand{\\pto}{\\overset{\\text{p}}{\\to}}\\newcommand{\\mto}{\\overset{\\text{m}}{\\to}}\\newcommand{\\vto}{\\overset{v}{\\to}}\\newcommand{\\Cont}{\\mathrm{Cont}}\\newcommand{\\stably}{\\mathrm{stably}}\\newcommand{\\Np}{\\mathbb{N}^+}\\newcommand{\\oM}{\\overline{\\mathcal{M}}}\\newcommand{\\fP}{\\mathfrak{P}}\\newcommand{\\sign}{\\mathrm{sign}}\n\\DeclareMathOperator{\\Ent}{Ent}\\DeclareMathOperator{\\Polya}{Polya}\\newcommand{\\Borel}{\\mathrm{Borel}}\\newcommand{\\Mid}{\\,|\\,}\\newcommand{\\middleMid}{\\;\\middle|\\;}\\DeclareMathOperator{\\LR}{LR}\\newcommand{\\CP}{\\mathrm{CP}}\\newcommand{\\bD}{\\mathbb{D}}\\newcommand{\\fW}{\\mathfrak{W}}\\newcommand{\\DL}{\\mathcal{D}\\mathcal{L}}\\renewcommand{\\r}[1]{\\mathrm{#1}}\\newcommand{\\rC}{\\mathrm{C}}\\newcommand{\\qqquad}{\\qquad\\quad}\n%%% 情報理論\n\\newcommand{\\bit}{\\mathrm{bit}}\\DeclareMathOperator{\\sinc}{sinc}\n%%% 量子論\n\\newcommand{\\err}{\\mathrm{err}}\n%%% 最適化\n\\newcommand{\\varparallel}{\\mathbin{\\!/\\mkern-5mu/\\!}}\\DeclareMathOperator{\\minimize}{minimize}\\DeclareMathOperator{\\subjectto}{subject to}\\newcommand{\\Ri}{\\mathrm{Ri}}\\newcommand{\\Cone}{\\mathrm{Cone}}\\newcommand{\\Int}{\\mathrm{Int}}\n%%% 数理ファイナンス\n\\newcommand{\\pre}{\\mathrm{pre}}\\newcommand{\\om}{\\omega}\n\n%%% 偏微分方程式\n\\DeclareMathOperator{\\div}{div}\n\\newcommand{\\del}{\\partial}\n\\newcommand{\\LHS}{\\mathrm{LHS}}\\newcommand{\\RHS}{\\mathrm{RHS}}\\newcommand{\\bnu}{\\boldsymbol{\\nu}}\\newcommand{\\interior}{\\mathrm{in}\\;}\\newcommand{\\SH}{\\mathrm{SH}}\\renewcommand{\\v}{\\boldsymbol{\\nu}}\\newcommand{\\n}{\\mathbf{n}}\\newcommand{\\ssub}{\\Subset}\\newcommand{\\curl}{\\mathrm{curl}}\n%%% 常微分方程式\n\\newcommand{\\Ei}{\\mathrm{Ei}}\\newcommand{\\sn}{\\mathrm{sn}}\\newcommand{\\wgamma}{\\widetilde{\\gamma}}\n%%% 統計力学\n\\newcommand{\\Ens}{\\mathrm{Ens}}\n%%% 解析力学\n\\newcommand{\\cl}{\\mathrm{cl}}\\newcommand{\\x}{\\boldsymbol{x}}\n\n%%% 統計的因果推論\n\\newcommand{\\Do}{\\mathrm{Do}}\\newcommand{\\IV}{\\mathrm{IV}}\n%%% 応用統計学\n\\DeclareMathOperator{\\pl}{pl}\\newcommand{\\AIC}{\\mathrm{AIC}}\\newcommand{\\mrl}{\\mathrm{mrl}}\\newcommand{\\dotx}{\\dot{x}}\\newcommand{\\UMV}{\\mathrm{UMV}}\\newcommand{\\BLU}{\\mathrm{BLU}}\n%%% 数理統計\n\\DeclareMathOperator{\\arctanh}{arctanh}\\newcommand{\\comb}[2]{\\begin{pmatrix}#1\\\\#2\\end{pmatrix}}\\newcommand{\\bP}{\\mathbb{P}}\\newcommand{\\compsub}{\\overset{\\textrm{cpt}}{\\subset}}\\newcommand{\\lip}{\\textrm{lip}}\\newcommand{\\BL}{\\mathrm{BL}}\\newcommand{\\G}{\\mathbb{G}}\\newcommand{\\NB}{\\mathrm{NB}}\\newcommand{\\oR}{\\ov{\\R}}\\newcommand{\\liminfn}{\\liminf_{n\\to\\infty}}\\newcommand{\\limsupn}{\\limsup_{n\\to\\infty}}\\newcommand{\\esssup}{\\mathrm{ess.sup}}\\newcommand{\\asto}{\\xrightarrow{\\as}}\\newcommand{\\Cov}{\\mathrm{Cov}}\\newcommand{\\cQ}{\\mathcal{Q}}\\newcommand{\\VC}{\\mathrm{VC}}\\newcommand{\\mb}{\\mathrm{mb}}\\newcommand{\\Avar}{\\mathrm{Avar}}\\newcommand{\\bB}{\\mathbb{B}}\\newcommand{\\bW}{\\mathbb{W}}\\newcommand{\\sd}{\\mathrm{sd}}\\newcommand{\\w}[1]{\\widehat{#1}}\\newcommand{\\bZ}{\\mathbb{Z}}\\newcommand{\\Bernoulli}{\\mathrm{Ber}}\\newcommand{\\Ber}{\\mathrm{Ber}}\\newcommand{\\Mult}{\\mathrm{Mult}}\\newcommand{\\BPois}{\\mathrm{BPois}}\\newcommand{\\fraks}{\\mathfrak{s}}\\newcommand{\\frakk}{\\mathfrak{k}}\\newcommand{\\IF}{\\mathrm{IF}}\\newcommand{\\bX}{\\boldsymbol{X}}\\newcommand{\\bx}{\\boldsymbol{x}}\\newcommand{\\indep}{\\perp\\!\\!\\!\\perp}\\newcommand{\\IG}{\\mathrm{IG}}\\newcommand{\\Levy}{\\mathrm{Levy}}\\newcommand{\\MP}{\\mathrm{MP}}\\newcommand{\\Hermite}{\\mathrm{Hermite}}\\newcommand{\\Skellam}{\\mathrm{Skellam}}\\newcommand{\\Dirichlet}{\\mathrm{Dirichlet}}\\newcommand{\\Beta}{\\mathrm{Beta}}\\newcommand{\\bE}{\\mathbb{E}}\\newcommand{\\bG}{\\mathbb{G}}\\newcommand{\\MISE}{\\mathrm{MISE}}\\newcommand{\\logit}{\\mathtt{logit}}\\newcommand{\\expit}{\\mathtt{expit}}\\newcommand{\\cK}{\\mathcal{K}}\\newcommand{\\dl}{\\dot{l}}\\newcommand{\\dotp}{\\dot{p}}\\newcommand{\\wl}{\\wt{l}}\\newcommand{\\Gauss}{\\mathrm{Gauss}}\\newcommand{\\fA}{\\mathfrak{A}}\\newcommand{\\under}{\\mathrm{under}\\;}\\newcommand{\\whtheta}{\\wh{\\theta}}\\newcommand{\\Em}{\\mathrm{Em}}\\newcommand{\\ztheta}{{\\theta_0}}\n\\newcommand{\\rO}{\\mathrm{O}}\\newcommand{\\Bin}{\\mathrm{Bin}}\\newcommand{\\rW}{\\mathrm{W}}\\newcommand{\\rG}{\\mathrm{G}}\\newcommand{\\rB}{\\mathrm{B}}\\newcommand{\\rN}{\\mathrm{N}}\\newcommand{\\rU}{\\mathrm{U}}\\newcommand{\\HG}{\\mathrm{HG}}\\newcommand{\\GAMMA}{\\mathrm{Gamma}}\\newcommand{\\Cauchy}{\\mathrm{Cauchy}}\\newcommand{\\rt}{\\mathrm{t}}\\newcommand{\\rF}{\\mathrm{F}}\n\\DeclareMathOperator{\\erf}{erf}\n%%% 計量経済学\n\\newcommand{\\FE}{\\mathrm{FE}}\\newcommand{\\bV}{\\boldsymbol{V}}\\newcommand{\\GLS}{\\mathrm{GLS}}\\newcommand{\\be}{\\boldsymbol{e}}\\newcommand{\\POOL}{\\mathrm{POOL}}\\newcommand{\\GMM}{\\mathrm{GMM}}\\newcommand{\\MM}{\\mathrm{MM}}\\newcommand{\\SSIV}{\\mathrm{SSIV}}\\newcommand{\\JIV}{\\mathrm{JIV}}\\newcommand{\\AR}{\\mathrm{AR}}\\newcommand{\\ILS}{\\mathrm{ILS}}\\newcommand{\\SLS}{\\mathrm{SLS}}\\newcommand{\\LIML}{\\mathrm{LIML}}\n\n%%% 無限次元統計模型の理論\n\\newcommand{\\Rad}{\\mathrm{Rad}}\\newcommand{\\bY}{\\boldsymbol{Y}}\\newcommand{\\pone}{{(1)}}\\newcommand{\\ptwo}{{(2)}}\\newcommand{\\ps}[1]{{(#1)}}\\newcommand{\\fsub}{\\overset{\\text{finite}}{\\subset}}\n%%% Banach Lattices\n\\newcommand{\\Slv}{\\mathrm{Slv}}\\newcommand{\\Hypo}{\\mathrm{Hypo}}\\newcommand{\\CL}{\\mathrm{CL}}\\DeclareMathOperator{\\ba}{ba}\\DeclareMathOperator{\\ca}{ca}\n\n%%% 圏\n\\newcommand{\\varlim}{\\varprojlim}\\newcommand{\\Hom}{\\mathrm{Hom}}\\newcommand{\\Iso}{\\mathrm{Iso}}\\newcommand{\\Mor}{\\mathrm{Mor}}\\newcommand{\\Isom}{\\mathrm{Isom}}\\newcommand{\\Aut}{\\mathrm{Aut}}\\newcommand{\\End}{\\mathrm{End}}\\newcommand{\\op}{\\mathrm{op}}\\newcommand{\\ev}{\\mathrm{ev}}\\newcommand{\\Ob}{\\mathrm{Ob}}\\newcommand{\\Ar}{\\mathrm{Ar}}\\newcommand{\\Arr}{\\mathrm{Arr}}\\newcommand{\\Set}{\\mathrm{Set}}\\newcommand{\\Grp}{\\mathrm{Grp}}\\newcommand{\\Cat}{\\mathrm{Cat}}\\newcommand{\\Mon}{\\mathrm{Mon}}\\newcommand{\\Ring}{\\mathrm{Ring}}\\newcommand{\\CRing}{\\mathrm{CRing}}\\newcommand{\\Ab}{\\mathrm{Ab}}\\newcommand{\\Pos}{\\mathrm{Pos}}\\newcommand{\\Vect}{\\mathrm{Vect}}\\newcommand{\\FinVect}{\\mathrm{FinVect}}\\newcommand{\\FinSet}{\\mathrm{FinSet}}\\newcommand{\\FinMeas}{\\mathrm{FinMeas}}\\newcommand{\\OmegaAlg}{\\Omega\\text{-}\\mathrm{Alg}}\\newcommand{\\OmegaEAlg}{(\\Omega,E)\\text{-}\\mathrm{Alg}}\\newcommand{\\Fun}{\\mathrm{Fun}}\\newcommand{\\Func}{\\mathrm{Func}}\\newcommand{\\Alg}{\\mathrm{Alg}} %代数の圏\n\\newcommand{\\Met}{\\mathrm{Met}} %Metric space & Contraction maps\n\\newcommand{\\Stoch}{\\mathrm{Stoch}}\\newcommand{\\FinStoch}{\\mathrm{FinStoch}}\\newcommand{\\Copy}{\\mathrm{copy}}\\newcommand{\\Delete}{\\mathrm{delete}} %確率空間とMarkov核の圏\n\\newcommand{\\Bool}{\\mathrm{Bool}}\\newcommand{\\CABool}{\\mathrm{CABool}}\\newcommand{\\CompBoolAlg}{\\mathrm{CompBoolAlg}}\\newcommand{\\BoolAlg}{\\mathrm{BoolAlg}}\\newcommand{\\BoolRng}{\\mathrm{BoolRng}}\\newcommand{\\HeytAlg}{\\mathrm{HeytAlg}}\\newcommand{\\CompHeytAlg}{\\mathrm{CompHeytAlg}}\\newcommand{\\Lat}{\\mathrm{Lat}}\\newcommand{\\CompLat}{\\mathrm{CompLat}}\\newcommand{\\SemiLat}{\\mathrm{SemiLat}}\\newcommand{\\Stone}{\\mathrm{Stone}}\\newcommand{\\Mfd}{\\mathrm{Mfd}}\\newcommand{\\LieAlg}{\\mathrm{LieAlg}}\n\\newcommand{\\Sob}{\\mathrm{Sob}} %Sober space & continuous map\n\\newcommand{\\Op}{\\mathrm{Op}} %Category of open subsets\n\\newcommand{\\Sh}{\\mathrm{Sh}} %Category of sheave\n\\newcommand{\\PSh}{\\mathrm{PSh}} %Category of presheave, PSh(C)=[C^op,set]のこと\n\\DeclareMathOperator{\\Conv}{Conv} %Convergence spaceの圏\n\\newcommand{\\Unif}{\\mathrm{Unif}} %一様空間と一様連続写像の圏\n\\newcommand{\\Frm}{\\mathrm{Frm}} %フレームとフレームの射\n\\newcommand{\\Locale}{\\mathrm{Locale}} %その反対圏\n\\newcommand{\\Diff}{\\mathrm{Diff}} %滑らかな多様体の圏\n\\newcommand{\\Quiv}{\\mathrm{Quiv}} %Quiverの圏\n\\newcommand{\\B}{\\mathcal{B}}\\newcommand{\\cB}{\\mathcal{B}}\\newcommand{\\Span}{\\mathrm{Span}}\\newcommand{\\Corr}{\\mathrm{Corr}}\\newcommand{\\Decat}{\\mathrm{Decat}}\\newcommand{\\Rep}{\\mathrm{Rep}}\\newcommand{\\Grpd}{\\mathrm{Grpd}}\\newcommand{\\sSet}{\\mathrm{sSet}}\\newcommand{\\Mod}{\\mathrm{Mod}}\\newcommand{\\SmoothMnf}{\\mathrm{SmoothMnf}}\\newcommand{\\coker}{\\mathrm{coker}}\\newcommand{\\Ord}{\\mathrm{Ord}}\\newcommand{\\eq}{\\mathrm{eq}}\\newcommand{\\coeq}{\\mathrm{coeq}}\\newcommand{\\act}{\\mathrm{act}}\n\n%%% SMC\n\\newcommand{\\apf}{\\mathrm{apf}}\\newcommand{\\opt}{\\mathrm{opt}}\\newcommand{\\IS}{\\mathrm{IS}}\\newcommand{\\IR}{\\mathrm{IR}}\\newcommand{\\iidsim}{\\overset{\\text{iid}}{\\sim}}\\newcommand{\\KL}{\\mathrm{KL}}\\DeclareMathOperator{\\ESS}{ESS}\\DeclareMathOperator{\\MSE}{MSE}\\newcommand{\\propt}{\\,\\propto\\,}\\newcommand{\\bM}{\\mathbb{M}}\\newcommand{\\cX}{\\mathcal{X}}\\newcommand{\\cY}{\\mathcal{Y}}\\newcommand{\\cP}{\\mathcal{P}}\\newcommand{\\ola}[1]{\\overleftarrow{#1}}\n\n%%% 括弧類\n\\newcommand{\\abs}[1]{\\lvert#1\\rvert}\\newcommand{\\Abs}[1]{\\left|#1\\right|}\\newcommand{\\ABs}[1]{\\biggl|#1\\biggr|}\\newcommand{\\norm}[1]{\\|#1\\|}\\newcommand{\\Norm}[1]{\\left\\|#1\\right\\|}\\newcommand{\\NOrm}[1]{\\biggl\\|#1\\biggr\\|}\\newcommand{\\Brace}[1]{\\left\\{#1\\right\\}}\\newcommand{\\BRace}[1]{\\biggl\\{#1\\biggr\\}}\\newcommand{\\paren}[1]{\\left(#1\\right)}\\newcommand{\\Paren}[1]{\\biggr(#1\\biggl)}\\newcommand{\\bracket}[1]{\\langle#1\\rangle}\\newcommand{\\brac}[1]{\\langle#1\\rangle}\\newcommand{\\Bracket}[1]{\\left\\langle#1\\right\\rangle}\\newcommand{\\Brac}[1]{\\left\\langle#1\\right\\rangle}\\newcommand{\\bra}[1]{\\left\\langle#1\\right|}\\newcommand{\\ket}[1]{\\left|#1\\right\\rangle}\\newcommand{\\Square}[1]{\\left[#1\\right]}\\newcommand{\\SQuare}[1]{\\biggl[#1\\biggr]}\n\\newcommand{\\ov}[1]{\\overline{#1}}\\newcommand{\\un}[1]{\\underline{#1}}\\newcommand{\\wt}[1]{\\widetilde{#1}}\\newcommand{\\wh}[1]{\\widehat{#1}}\n\\newcommand{\\pp}[2]{\\frac{\\partial #1}{\\partial #2}}\\newcommand{\\ppp}[3]{\\frac{\\partial #1}{\\partial #2\\partial #3}}\\newcommand{\\dd}[2]{\\frac{d #1}{d #2}}\n\\newcommand{\\floor}[1]{\\lfloor#1\\rfloor}\\newcommand{\\Floor}[1]{\\left\\lfloor#1\\right\\rfloor}\\newcommand{\\ceil}[1]{\\lceil#1\\rceil}\n\\newcommand{\\ocinterval}[1]{(#1]}\\newcommand{\\cointerval}[1]{[#1)}\\newcommand{\\COinterval}[1]{\\left[#1\\right)}\n\n%%% 予約語\n\\renewcommand{\\iff}{\\;\\mathrm{iff}\\;}\n\\newcommand{\\False}{\\mathrm{False}}\\newcommand{\\True}{\\mathrm{True}}\n\\newcommand{\\otherwise}{\\mathrm{otherwise}}\n\\newcommand{\\suchthat}{\\;\\mathrm{s.t.}\\;}\n\n%%% 略記\n\\newcommand{\\cM}{\\mathcal{M}}\\newcommand{\\M}{\\mathbb{M}}\\newcommand{\\cF}{\\mathcal{F}}\\newcommand{\\cD}{\\mathcal{D}}\\newcommand{\\fX}{\\mathfrak{X}}\\newcommand{\\fY}{\\mathfrak{Y}}\\newcommand{\\fZ}{\\mathfrak{Z}}\\renewcommand{\\H}{\\mathcal{H}}\\newcommand{\\cH}{\\mathcal{H}}\\newcommand{\\fH}{\\mathfrak{H}}\\newcommand{\\bH}{\\mathbb{H}}\\newcommand{\\id}{\\mathrm{id}}\\newcommand{\\A}{\\mathcal{A}}\n\\newcommand{\\lmd}{\\lambda}\n\\newcommand{\\Lmd}{\\Lambda}\n\\newcommand{\\cI}{\\mathcal{I}}\n\n%%% 矢印類\n\\newcommand{\\iso}{\\overset{\\sim}{\\to}}\n\\newcommand{\\Lrarrow}{\\;\\;\\Leftrightarrow\\;\\;}\n$$\n:::\n\n\n\n本稿では，[$K$-平均アルゴリズム](https://ja.wikipedia.org/wiki/K%E5%B9%B3%E5%9D%87%E6%B3%95) によるクラスタリングの考え方と問題点を，Python による実演を通じてみる．次の [稿](VI2.qmd) で，$K$-平均アルゴリズムの統計モデリングの観点からの一般化である [EM アルゴリズム](https://ja.wikipedia.org/wiki/EM%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0) を説明し，その問題点の数理的な理解を目指す．\n\n## 用いるデータ\n\n次のような２次元のデータ（＋最左列に教師データ付き）を考える．\n\n::: {#12212d5d .cell execution_count=1}\n\n::: {.cell-output .cell-output-stdout}\n```\n    0      1      2\n0   1  3.885  1.650\n1   1  1.005  2.745\n2   1  1.734  0.716\n3   1  1.605  2.549\n4   1  1.530  2.950\n.. ..    ...    ...\n85  3  1.056 -2.227\n86  3  1.055 -2.333\n87  3  1.436 -2.944\n88  3  1.206 -2.149\n89  3  0.974 -1.496\n\n[90 rows x 3 columns]\n```\n:::\n:::\n\n\n::: {#d076ecde .cell execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![](VI_files/figure-html/cell-3-output-1.png){width=327 height=302}\n:::\n:::\n\n\n## ハード $K$-平均法 {#sec-hard-k-means}\n\nhead $K$-means algorithm はデータ $\\{x^{(n)}\\}_{n=1}^N\\subset\\R^I$ とクラスタ数 $K\\in\\N^+$，そして初期クラスター中心 $(m^{(k)})_{k=1}^K\\in(\\R^I)^K$ の３組をパラメータに持つ．\n\nsoft $K$-means algorithm はさらに硬度パラメータ $\\beta\\in\\R_+$ を持つ．\n\n特に `numpy` の提供する行列積を利用して，これを Python により実装した例を以下に示す．\n\nソフト $K$-平均法の実装と対比できるように，負担率を通じた実装を意識した例である．\n\nアノテーションを付してあるので，該当箇所（右端の丸囲み数字）をクリックすることで適宜解説が読めるようになっている．\n\n\n\n```{.python}\ndef hkmeans_2d(data, K, init, max_iter=100):\n    \"\"\"\n    ２次元データに対するハード K-平均法の実装例．\n\n    Parameters:\n    - data: (N,2)-numpy.ndarray\n    - K: int クラスター数\n    - init: (2,K)-numpy.ndarray 初期値\n\n    Returns:\n    - clusters: (N,)-numpy.ndarray クラスター番号\n    \"\"\"\n\n    N = data.shape[0]  # <1>\n    I = data.shape[1]  # <2>\n    m = init  # <3>\n    r = np.zeros((K, N), dtype=float)  # <4>\n\n    for _ in range(max_iter):\n        # Assignment Step\n        for i in range(N):\n            distances = np.array([d(data[i], m[:,k]) for k in range(K)]) # <5>\n            k_hat = np.argmin(distances)  # <6>\n            r[:,i] = 0  # <7>\n            r[k_hat,i] = 1\n        \n        # Update Step\n        new_m = np.zeros_like(m, dtype=float) # <8>\n        numerator = np.dot(r, data)  # <9>\n        denominator = np.sum(r, axis=1) # <10>\n        for k in range(K): # <11>\n            if denominator[k] > 0:\n                new_m[:,k] = numerator[k] / denominator[k]\n            else:\n                new_m[:,k] = m[:,k]\n\n        if np.allclose(m, new_m): # <12>\n            break\n        m = new_m\n    \n    return np.argmax(r, axis=0)  # <13>\n```\n\n1. データ数を取得している．\n2. データの次元を取得している．今回はすべて２次元データを用いる．\n3. クラスター中心に引数として受け取った初期値を代入. $2×K$-行列であることに注意．\n4. 負担率を $K×N$-行列として格納している．その理由は後ほど行列積を通じた計算を行うためである．`dtype=float` の理由は後述．\n5. この `distances` 変数は `(K,)-numpy.ndarray` になる．すなわち，第 $k$ 成分が，第 $k$ クラスター中心との距離となっているようなベクトルである．ただし，`d` は Euclid 距離を計算する関数として定義済みとした．\n6. 距離が最小となるクラスター番号 $\\hat{k}:=[\\argmin_{k\\in[K]}d(m_k,x_i)]$ を，$i\\in[N]$ 番目のデータについて求める．\n7. $\\hat{k}$ に基づいて負担率を更新するが，ループ内で前回の結果をリセットする必要があることに注意．\n8. ここで `dtype=float` と指定しないと，初め引数 `init` が整数のみで構成されていた場合に，Python の自動型付機能が `int` 型だと判定し，クラスター中心 `m` の値が整数に限られてしまう．すると，アルゴリズムがすぐに手頃な格子点に収束してしまう．\n9. `numpy` の行列積を計算する関数 `np.dot` を使用している．更新式\n$$\nm^{(k)}\\gets\\frac{\\sum_{n=1}^Nr^{(n)}_kx^{(n)}}{\\sum_{n=1}^Nr^{(n)}_k}\n$$\nの分子を行列積と見たのである．\n10. 分母 (denominator) は $(K,N)$-行列 `r` の行和として得られる．\n11. ゼロによる除算が起こらないように場合わけをしている．\n12. クラスター中心がもはや変わらない場合はアルゴリズムを終了する．\n13. 負担率の最も大きいクラスター番号を返す．今回は `hat_k` の列をそのまま返せば良いが，soft $K$-means アルゴリズムにも通じる形で実装した．\n\n::: {.callout-caution icon=\"false\" title=\"注：実際に用いる実装\" collapse=\"true\"}\n\nただし，本記事の背後では次の実装を用いる．\n\nクラスター中心の推移のヒストリーを保存して図示に利用したり，負担率 `r` の中身を見たりすることが出来るようにするため，assignment step と update step とに分けてクラスメソッドとして実装し，`run` メソッドでそれらを呼び出すようにしている．これに `fetch_cluster` と `fetch_history` メソッドを加えることで，クラスター番号とクラスター中心の推移を取得することが出来る．フィールド `.r` から（最終的な）負担率を見ることもできる．\n\n::: {#a44e8882 .cell execution_count=4}\n``` {.python .cell-code code-fold=\"true\"}\nclass kmeans_2d:\n    \"\"\"\n    ２次元データに対するソフト K-平均法の実装．\n\n    Usage:\n        kmeans = kmeans_2d(data, K, init, beta)\n        kmeans.run()\n\n    Parameters:\n    - data: (N,2)-numpy.ndarray\n    - K: int クラスター数\n    - init: (2,K)-numpy.ndarray 初期値\n    - beta: float 硬度パラメータ\n    \"\"\"\n\n    def __init__(self, data, K, init, beta, max_iter=100):\n        self.data = np.array(data, dtype=float)\n        self.K = K\n        self.init = np.array(init, dtype=float)\n        self.beta = float(beta)\n        self.max_iter = max_iter\n        self.N = data.shape[0]  # データ数\n        self.I = data.shape[1]  # 次元数 今回は２\n        self.m = init  # クラスター中心の初期化．2×K行列．\n        self.r = np.zeros((K, self.N), dtype=float)  # 負担率．K×N行列．\n        self.history = [init.copy()] # クラスター中心の履歴．2×K行列．\n    \n    def soft_assigment(self):\n        \"\"\"soft K-means の場合の負担率の更新\"\"\"\n        for i in range(self.N):\n            distances = np.array([d(self.data[i], self.m[:,j]) for j in range(self.K)]) # (N,)-numpy.ndarray\n            denominator_ = np.sum(np.exp(-self.beta * distances))  # 分母\n            self.r[:,i] = np.exp(- self.beta * distances) / denominator_\n\n    def hard_assigment(self):\n        \"\"\"hard K-means の場合の負担率の更新\"\"\"\n        for i in range(self.N):\n            distances = np.array([d(self.data[i], self.m[:,j]) for j in range(self.K)]) # (N,)-numpy.ndarray\n            k_hat = np.argmin(distances)  # 最小距離のクラスター番号\n            self.r[:,i] = 0  # 前のループの結果をリセット\n            self.r[k_hat,i] = 1\n    \n    def update(self):\n        \"\"\"クラスター中心の更新\"\"\"\n        new_m = np.zeros_like(self.m, dtype=float) # ここで float にしないと，クラスター中心が整数に限られてしまう．\n        numerator = np.dot(self.r, self.data)  # (K,2)-numpy.ndarray\n        denominator = np.sum(self.r, axis=1)  # 各クラスターの負担率の和\n        for k in range(self.K):\n            if denominator[k] > 0:\n                new_m[:,k] = numerator[k] / denominator[k]\n            else:\n                new_m[:,k] = self.m[:,k]\n        self.m = new_m\n\n    def fetch_cluster(self):\n        \"\"\"最終的なクラスター番号を格納した (N,)-array を返す\"\"\"\n        return np.argmax(self.r, axis=0)\n    \n    def fetch_history(self):\n        \"\"\"クラスター中心の履歴を格納したリストを，３次元の np.array に変換して返す\"\"\"\n        return np.stack(self.history, axis=0)\n\n    def run_soft(self):\n        \"\"\"soft K-means アルゴリズムの実行\"\"\"\n        for _ in range(self.max_iter):\n            self.soft_assigment()\n            self.update()\n            self.history.append(self.m.copy())\n            if np.allclose(self.history[-1], self.history[-2]):\n                break\n    \n    def run_hard(self):\n        \"\"\"hard K-means アルゴリズムの実行\"\"\"\n        for _ in range(self.max_iter):\n            self.hard_assigment()\n            self.update()\n            self.history.append(self.m.copy())\n            if np.allclose(self.history[-1], self.history[-2]):\n                break\n```\n:::\n\n\nなお，この実装は $\\beta\\ge500$ などの場合にオーバーフローが起こることに注意．\n\n:::\n\n### 正解率の観察\n\n次の２つの初期値を与えてみる．\n$$\nm_1:=\\vctr{4}{0},\\quad m_2:=\\vctr{1}{4},\\quad m_3=\\vctr{-1}{1},\n$$\nと，$m_2,m_3$ は変えずに $m_1$ の $y$-座標を $1$ だけ下げたもの\n$$\nm_1':=\\vctr{4}{-1}\n$$\nとを初期値として与えてみる．\n\n::: {#cell-fig-1 .cell execution_count=5}\n\n::: {.cell-output .cell-output-display}\n![ハード K-平均法によるクラスタリングの結果．初期値は $(m_1,m_2,m_3)=\\paren{\\vctr{4}{0},\\vctr{1}{4},\\vctr{-1}{1}}$．赤丸で囲まれている点がクラスター中心 (CoC / Center of Cluster) の初期値で，その後の移動が図示されている．](VI_files/figure-html/fig-1-output-1.png){#fig-1 width=662 height=374}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n正解数: 39     正解率: 43.3 %     反復数: 9 回\n```\n:::\n:::\n\n\n別の初期値を与えてみる（右下の点 $m_1$ を $1$ だけ下に下げただけ）：\n$$\n\\vctr{4}{0}=m_1\\mapsto m_1':=\\vctr{4}{-1}\n$$\n\n::: {#cell-fig-2 .cell execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![ハード K-平均法によるクラスタリングの結果．初期値は $(m_1',m_2,m_3)=\\paren{\\vctr{4}{-1},\\vctr{1}{4},\\vctr{-1}{1}}$．](VI_files/figure-html/fig-2-output-1.png){#fig-2 width=662 height=374}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n正解数: 85     正解率: 94.4 %     反復数: 7 回\n```\n:::\n:::\n\n\n結果が全く変わり，$(m_1',m_2,m_3)$ を与えた方が，大きく正解に近づいている．具体的には，右下の初期値 $m_1$ は右上の島に行くが，$m_1'$ は左下の島に行ってくれる．\n\n**ハード $K$-平均アルゴリズムは初期値に敏感である** ことがよく分かる．\n\n### 正解率を上げる試み\n\n直前の結果ではクラスター２と３の境界線で４つのミスを犯しており，これを修正できないか試したい．\n\nそこで，答えに近いように，\n$$\nm_1\\gets\\vctr{2.5}{2},\\;\\; m_2\\gets\\vctr{-1}{-1},\\;\\; m_3\\gets\\vctr{1}{-2},\n$$\nを初期値として与えてみて，正答率の変化を観察する．\n\n::: {#e6c09920 .cell execution_count=7}\n\n::: {.cell-output .cell-output-display}\n![](VI_files/figure-html/cell-8-output-1.png){width=662 height=374}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n正解数: 85     正解率: 94.4 %     反復数: 5 回\n```\n:::\n:::\n\n\nもはや初期値から殆ど動いていないが，目標のクラスター３に分類された３つの点が，相変わらず３のままであり，加えてクラスター２の中心がこれらから逃げているようにも見えるので，クラスター２の初期値をよりクラスター３に近いように誘導し，クラスター３の中心をより右側から開始する：\n\n$$\nm_2:\\vctr{-1}{-1}\\mapsto\\vctr{0}{-2}\\;\\; m_3:\\vctr{1}{-2}\\mapsto\\vctr{2}{-2}\n$$\n\n::: {#0ea2df32 .cell execution_count=8}\n\n::: {.cell-output .cell-output-display}\n![](VI_files/figure-html/cell-9-output-1.png){width=662 height=374}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n正解数: 85     正解率: 94.4 %     反復数: 6 回\n```\n:::\n:::\n\n\nこんなに誘導をしても，正しく分類してくれない．\n\n実は，以上２つの初期値では，最終的に３つのクラスター中心は同じ値に収束している．よって，これ以上どのように初期値を変更しても，正答率は上がらないシナリオが考えられる．\n\n以上の観察から，ハード $K$-平均法はある種の **局所解に収束する** ようなアルゴリズムであると考えられる．\n\n## ソフト $K$-平均法\n\nハード $K$-平均法では，負担率\n$$\nr_{kn}\\gets\\delta_{k}(\\argmax_{i\\in[k]}d(m_i,x_n))\n$$\nは $0,1$ のいずれかの値しか取らなかった．この振る舞いを，\n$$\n\\sigma(z;e)_i:=\\frac{e^{z_i}}{\\sum_{j=1}^Ke^{e_j}}\\quad(i\\in[K])\n$$\nで定まる [**ソフトマックス関数**](https://ja.wikipedia.org/wiki/%E3%82%BD%E3%83%95%E3%83%88%E3%83%9E%E3%83%83%E3%82%AF%E3%82%B9%E9%96%A2%E6%95%B0) $\\sigma:\\R^K\\to(0,1)^K$ を用いて，「軟化」する．\n\nここでは，$\\beta\\ge0$ として，\n$$\n\\sigma(z;e^{-\\beta})_i=\\frac{e^{-\\beta z_i}}{\\sum_{j=1}^Ke^{-\\beta e_j}}\n$$\nの形で用い，$\\argmax$ の代わりに\n$$\n\\begin{align*}\n    r_{kn}&\\gets\\sigma(d(-,x_n)\\circ m;e^{-\\beta})_k\\\\\n    &=\\frac{e^{-\\beta d(m_k,x_n)}}{\\sum_{j=1}^K e^{-\\beta d(m_j,x_n)}}\n\\end{align*}\n$$\nとする．\n\n$\\beta$ は **硬度 (stiffness)** または逆温度と呼ぶ．^[stiffness の用語は [@MacKay2003 p.289] から．] $\\beta=0$ のときは温度が無限大の場合にあたり，常に負担率は一様になる．絶対零度に当たる $\\beta\\to\\infty$ の極限が hard $K$-means アルゴリズムに相当する．\n\n実装は例えば hard $K$-means アルゴリズム（ @sec-hard-k-means ）から，負担率計算の部分のみを変更すれば良い：\n\n```{.python}\nfor i in range(N):\n        distances = np.array([d(data[i], m[:,k]) for k in range(K)]) # <1>\n        denominator_ = np.sum(np.exp(-beta * distances))  # <2>\n        r[:,i] = np.exp(-beta * distances) / denominator_ # <3>\n```\n1. データ $x_i$ とクラスター中心 $(m_k)_{k=1}^K$ との距離を計算し，ベクトル $(d(x_n,m_k))_{k=1}^K$ を `distances` に格納している．\n2. 負担率の計算\n$$\nr_{ik}=\\frac{\\exp(-\\beta d(m_k,x_i))}{\\sum_{j=1}^K\\exp(-\\beta d(m_j,x_i))}\n$$\nを２段階に分けて行なっており，分母を先に計算して変数 `denominator_` に格納している．\n3. すでに計算してある分母 `denominator_` を用いてデータ $x_i$ の負担率 $(r_{ki})_{k=1}^K$ を計算し，$(K,N)$-行列 `r` の各列に格納している．\n\n### 正解率の観察\n\n逆温度をひとまず $\\beta=1$ としてみる．@fig-1 と全く同様な初期値\n$$\nm_1:=\\vctr{4}{0},\\quad m_2:=\\vctr{1}{4},\\quad m_3=\\vctr{-1}{1},\n$$\nを与えてみると，次の通りの結果を得る：\n\n::: {#cell-fig-3 .cell execution_count=9}\n\n::: {.cell-output .cell-output-display}\n![左がソフト K-平均法（$\\beta=1$），右がハード K-平均法によるクラスタリングの結果（図２の左と全く同じもの）．初期値は $(m_1,m_2,m_3)=\\paren{\\vctr{4}{0},\\vctr{1}{4},\\vctr{-1}{1}}$．赤丸で囲まれている点がクラスター中心 (CoC / Center of Cluster) の初期値で，その後の移動が図示されている．](VI_files/figure-html/fig-3-output-1.png){#fig-3 width=950 height=374}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n正解数: 49 vs. 39     正解率: 54.4 % vs. 43.3 %     反復数: 65 回 vs. 9 回\n```\n:::\n:::\n\n\n正解率 43.3% であったところから少し改善している．さらに，反復数が９回であったところから，劇的に増えている（65回）．\n\nまた，右上の２つのクラスター中心の収束先は，微妙にずれているが **ほとんど一致している** 点も注目に値する．\n\n::: {.callout-note icon=\"false\" title=\"参考：最終的なクラスター中心の座標\" collapse=\"true\"}\n```{.python}\ncenters = history[-1, :, :]\ndf = pd.DataFrame(centers, columns=['Cluster1', 'Cluster2', 'Cluster3'])\nprint(df)\n```\n\n::: {#5f758b35 .cell execution_count=10}\n\n::: {.cell-output .cell-output-stdout}\n```\n   Cluster1  Cluster2  Cluster3\nx  2.217840  2.218129  0.015051\ny  1.797156  1.797323 -1.385450\n```\n:::\n:::\n\n\n:::\n\n@fig-2 で与えた初期値 $(m_1',m_2,m_3)$ も与えてみる．\n\n::: {#cell-fig-4 .cell execution_count=11}\n\n::: {.cell-output .cell-output-display}\n![ソフト K-平均法（$\\beta=1$）によるクラスタリングの結果，右がハード K-平均法によるクラスタリングの結果（図２の右と全く同じもの）．初期値は $(m_1',m_2,m_3)=\\paren{\\vctr{4}{-1},\\vctr{1}{4},\\vctr{-1}{1}}$．](VI_files/figure-html/fig-4-output-1.png){#fig-4 width=662 height=374}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n正解数: 87 vs. 85     正解率: 96.7 % vs. 94.4 %     反復数: 101 回 vs. 7 回\n```\n:::\n:::\n\n\n正答率は 94.4% からやはり少し改善しており，反復数が７回から大きく増えている．\n\n結果はやはり @fig-3 とは大きく異なっており，ハード $K$-平均法で観察された初期値鋭敏性が，変わらず残っている．\n\n加えてこの場合も @fig-3 のクラスター１と２と同様に，クラスター２と３の中心がほぼ一致している．\n\n::: {.callout-note icon=\"false\" title=\"参考：最終的なクラスター中心の座標\" collapse=\"true\"}\n\n::: {#ebe4a490 .cell execution_count=12}\n\n::: {.cell-output .cell-output-stdout}\n```\n   Cluster1  Cluster2  Cluster3\nx  2.451958  0.257367  0.258702\ny  2.080430 -0.984350 -0.984790\n```\n:::\n:::\n\n\n:::\n\n$\\beta=1$ の場合のソフト $K$-平均法は，この例では **クラスター中心が融合する傾向にある** ようである．\n\n一般に，$\\beta$ が小さく，温度が大きいほど，エネルギーランドスケープに極小点が少なくなり，クラスターは同じ場所へ収束しやすくなると予想される．\n\n### 硬度パラメータに依る挙動の変化\n\n初期値を直前で用いた\n$$\nm_1\\gets\\vctr{4}{-1},\\quad m_2\\gets\\vctr{1}{4},\\quad m_3\\gets\\vctr{-1}{1},\n$$\nで固定とし，さらに温度を上げて，逆温度を $\\beta=0.1$ としてみる．\n\n::: {#cell-fig-5 .cell execution_count=13}\n\n::: {.cell-output .cell-output-display}\n![ソフト K-平均法（左$\\beta=0.1$，右$\\beta=1$）によるクラスタリングの結果．初期値は $(m_1',m_2,m_3)=\\paren{\\vctr{4}{-1},\\vctr{1}{4},\\vctr{-1}{1}}$．](VI_files/figure-html/fig-5-output-1.png){#fig-5 width=950 height=374}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n正解数: 68 vs. 87     正解率: 75.6 % vs. 96.7 %     反復数: 10 回 vs. 101 回\n```\n:::\n:::\n\n\n反復数は減少し，全てがほとんど同じクラスターに属する結果となってしまった．\n\n::: {#87fee7e3 .cell execution_count=14}\n\n::: {.cell-output .cell-output-stdout}\n```\n   Cluster1  Cluster2  Cluster3\nx  1.302467  1.302466  1.302467\ny  0.474545  0.474544  0.474544\n```\n:::\n:::\n\n\n３つのクラスター中心の座標が小数点以下５桁の精度で一致してしまっている．\n\n温度が大変に高い状態では，全てが乱雑で，３つのクラスターが一様・公平に負担率を持つようになった．そのため，第一歩からほとんど全体の中心へと移動し，反復数が減る．\n\n加えて，関数 `argmax` が全ての $k$ に対してほとんど同じ値を返してしまっているのである．\n\n次に，温度を少し下げて，逆温度を $\\beta=10$ としてみる．\n\n::: {#cell-fig-6 .cell execution_count=15}\n\n::: {.cell-output .cell-output-display}\n![ソフト K-平均法（$\\beta=10$）によるクラスタリングの結果．初期値は $(m_1',m_2,m_3)=\\paren{\\vctr{4}{-1},\\vctr{1}{4},\\vctr{-1}{1}}$．](VI_files/figure-html/fig-6-output-1.png){#fig-6 width=662 height=374}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n正解数: 85     正解率: 94.4 %     反復数: 18 回\n```\n:::\n:::\n\n\n初めて soft $K$-means アルゴリズムを用いた場合で，３つのクラスター中心がはっきりと別れた．反復回数は，$\\beta=1$ の場合と比べればやはり落ち着いている．\n\nしかし，正解率は head $K$-means の場合（ @fig-2 など）と全く同じである．実は，最終的なクラスター中心も @fig-2 の最終的なクラスター中心とほとんど同じになっている．\n\n::: {#44a38570 .cell execution_count=16}\n\n::: {.cell-output .cell-output-stdout}\n```\n   Cluster1  Cluster2  Cluster3\nx  2.413880  0.870308 -1.368158\ny  2.084395 -1.931050 -0.806831 （今回のソフト K-平均法の最終的なクラスター中心）\n```\n:::\n:::\n\n\n::: {#68cf4641 .cell execution_count=17}\n\n::: {.cell-output .cell-output-stdout}\n```\n   Cluster1  Cluster2  Cluster3\nx  2.426102  0.868333 -1.323353\ny  2.091429 -1.948458 -0.765176 （図２のハード K-平均法の最終的なクラスター中心）\n```\n:::\n:::\n\n\n以上より，ソフト $K$-平均法は温度を上げるほどクラスター数が少なくなり，温度を下げるほどクラスター数は上がり，**十分に温度を下げるとハード $K$-平均法に挙動が似通う**．\n\n### 最適な硬度の選択\n\n$\\beta=1$ ではクラスターが２つに縮退し，$\\beta=10$ では hard $K$-means アルゴリズムの結果とほとんど変わらなくなった．そこで，この中間の値での挙動の変化を調べる．\n\n::: {#cell-fig-7 .cell execution_count=18}\n\n::: {.cell-output .cell-output-display}\n![ソフト K-平均法によるクラスタリングの結果の比較（$\\beta=1.1$ vs. $\\beta=1.2$）．](VI_files/figure-html/fig-7-output-1.png){#fig-7 width=677 height=374}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n正解数: 87 vs. 85\n正解率: 96.7 % vs. 94.4 %\n```\n:::\n:::\n\n\n::: {#cell-fig-8 .cell execution_count=19}\n\n::: {.cell-output .cell-output-display}\n![ソフト K-平均法によるクラスタリングの結果の比較（$\\beta=1.5$ vs. $\\beta=1.8$）．](VI_files/figure-html/fig-8-output-1.png){#fig-8 width=677 height=374}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n正解数: 84 vs. 85\n正解率: 93.3 % vs. 94.4 %\n```\n:::\n:::\n\n\nクラスター２と３の中心が，温度の低下と共に徐々に離れていくことが観察できる．やはり，温度が高い場合はクラスター中心が合流・融合してしまいやすいが，冷却することでクラスター数は大きい状態で安定する．\n\n",
    "supporting": [
      "VI_files"
    ],
    "filters": [],
    "includes": {}
  }
}