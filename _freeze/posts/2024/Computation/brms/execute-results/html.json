{
  "hash": "46dace8ae201b61f7b98daf1be3a1b99",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"R によるベイズ混合モデリング入門\"\nsubtitle: \"brms を用いた混合効果モデリング入門\"\nauthor: \"司馬博文\"\ndate: 5/12/2024\ndate-modified: 6/17/2024\ncategories: [MCMC, Stan, R]\nimage: ./brms_files/figure-html/unnamed-chunk-4-1.png\nbibliography: \n    - ../../../mathematics.bib\n    - ../../../bib.bib\ncsl: ../../../apa.csl\nabstract-title: 概要\nabstract: |\n  `brms` はベイズ階層モデリングを，確率的プログラミング言語 Stan をエンジンとして行うための R パッケージである．本稿では，`brms` の基本的な使い方と，その実装を紹介する．また，ランダム効果モデルや一般化推定方程式などの文脈で扱われる種々のモデルを，階層モデルの観点から統一的にレビューし，ベイズ統計学の観点の透徹性を強調する．現代では，まだ複雑で大規模なモデルに対して，完全なベイズ推定を実行するには困難が多く，ベイズのモデリング上の透徹性と，最適化による点推定の計算上の優位性とのバランスを考えることが重要である．\nformat:\n  html:\n    code-fold: false\nexecute:\n  cache: true\n---\n::: {.hidden}\n\nA Blog Entry on Bayesian Computation by an Applied Mathematician\n\n$$\n%%% 汎用コード列\n\\renewcommand{\\P}{\\operatorname{P}}\\newcommand{\\E}{\\operatorname{E}}\n\\newcommand{\\R}{\\mathbb{R}}\\newcommand{\\F}{\\mathcal{F}}\n\\newcommand{\\abs}[1]{\\lvert#1\\rvert}\\newcommand{\\Abs}[1]{\\left|#1\\right|}\\newcommand{\\ABs}[1]{\\biggl|#1\\biggr|}\\newcommand{\\norm}[1]{\\|#1\\|}\\newcommand{\\Norm}[1]{\\left\\|#1\\right\\|}\\newcommand{\\NOrm}[1]{\\biggl\\|#1\\biggr\\|}\\newcommand{\\Brace}[1]{\\left\\{#1\\right\\}}\\newcommand{\\BRace}[1]{\\biggl\\{#1\\biggr\\}}\\newcommand{\\paren}[1]{\\left(#1\\right)}\\newcommand{\\Paren}[1]{\\biggr(#1\\biggl)}\\newcommand{\\bracket}[1]{\\langle#1\\rangle}\\newcommand{\\brac}[1]{\\langle#1\\rangle}\\newcommand{\\Bracket}[1]{\\left\\langle#1\\right\\rangle}\\newcommand{\\Brac}[1]{\\left\\langle#1\\right\\rangle}\\newcommand{\\bra}[1]{\\left\\langle#1\\right|}\\newcommand{\\ket}[1]{\\left|#1\\right\\rangle}\\newcommand{\\Square}[1]{\\left[#1\\right]}\\newcommand{\\SQuare}[1]{\\biggl[#1\\biggr]}\n\n\\usepackage[all]{xy}\\usepackage{amsmath}\\newcommand{\\y}{\\b{y}}\\newcommand{\\mi}{\\,|\\,}\\newcommand{\\Mark}{\\mathrm{Mark}}\n\n%%% 演算子\n\\DeclareMathOperator{\\grad}{\\mathrm{grad}}\\DeclareMathOperator{\\rot}{\\mathrm{rot}}\\DeclareMathOperator{\\divergence}{\\mathrm{div}}\\DeclareMathOperator{\\tr}{tr}\\DeclareMathOperator{\\Tr}{Tr}\\newcommand{\\pr}{\\mathrm{pr}}\n\\newcommand{\\Map}{\\mathrm{Map}}\\newcommand{\\dom}{\\mathrm{Dom}\\;}\\newcommand{\\cod}{\\mathrm{Cod}\\;}\\newcommand{\\supp}{\\mathrm{supp}\\;}\n\n\n%%% 線型代数学\n\\newcommand{\\vctr}[2]{\\begin{pmatrix}#1\\\\#2\\end{pmatrix}}\\newcommand{\\vctrr}[3]{\\begin{pmatrix}#1\\\\#2\\\\#3\\end{pmatrix}}\\newcommand{\\mtrx}[4]{\\begin{pmatrix}#1&#2\\\\#3&#4\\end{pmatrix}}\\newcommand{\\smtrx}[4]{\\paren{\\begin{smallmatrix}#1&#2\\\\#3&#4\\end{smallmatrix}}}\\newcommand{\\Ker}{\\mathrm{Ker}\\;}\\newcommand{\\Coker}{\\mathrm{Coker}\\;}\\newcommand{\\Coim}{\\mathrm{Coim}\\;}\\DeclareMathOperator{\\rank}{\\mathrm{rank}}\\newcommand{\\lcm}{\\mathrm{lcm}}\\newcommand{\\GL}{\\mathrm{GL}}\\newcommand{\\SL}{\\mathrm{SL}}\\newcommand{\\alt}{\\mathrm{alt}}\\DeclareMathOperator{\\sgn}{sgn}\n%%% 複素解析学\n\\renewcommand{\\Re}{\\mathrm{Re}\\;}\\renewcommand{\\Im}{\\mathrm{Im}\\,}\\newcommand{\\Gal}{\\mathrm{Gal}}\\newcommand{\\PGL}{\\mathrm{PGL}}\\newcommand{\\PSL}{\\mathrm{PSL}}\\newcommand{\\Log}{\\mathrm{Log}\\,}\\newcommand{\\Res}{\\mathrm{Res}\\,}\\newcommand{\\on}{\\mathrm{on}\\;}\\newcommand{\\hatC}{\\widehat{\\C}}\\newcommand{\\hatR}{\\hat{\\R}}\\newcommand{\\PV}{\\mathrm{P.V.}}\\newcommand{\\diam}{\\mathrm{diam}}\\newcommand{\\Area}{\\mathrm{Area}}\\newcommand{\\Lap}{\\Laplace}\\newcommand{\\f}{\\mathbf{f}}\\newcommand{\\cR}{\\mathcal{R}}\\newcommand{\\const}{\\mathrm{const.}}\\newcommand{\\Om}{\\Omega}\\newcommand{\\Cinf}{C^\\infty}\\newcommand{\\ep}{\\epsilon}\\newcommand{\\dist}{\\mathrm{dist}}\\newcommand{\\opart}{\\o{\\partial}}\\newcommand{\\Length}{\\mathrm{Length}}\n%%% 集合と位相\n\\newcommand{\\cA}{\\mathcal{A}}\\newcommand{\\cO}{\\mathcal{O}}\\newcommand{\\cW}{\\mathcal{W}}\\renewcommand{\\O}{\\mathcal{O}}\\renewcommand{\\S}{\\mathcal{S}}\\newcommand{\\U}{\\mathcal{U}}\\newcommand{\\V}{\\mathrm{V}}\\newcommand{\\N}{\\mathbb{N}}\\newcommand{\\bN}{\\mathbb{N}}\\newcommand{\\C}{\\mathrm{C}}\\newcommand{\\bC}{\\mathbb{C}}\\newcommand{\\Z}{\\mathcal{Z}}\\newcommand{\\Q}{\\mathbb{Q}}\\newcommand{\\bQ}{\\mathbb{Q}}\\newcommand{\\TV}{\\mathrm{TV}}\\newcommand{\\ORD}{\\mathrm{ORD}}\\newcommand{\\Card}{\\mathrm{Card}\\,}\\newcommand{\\Top}{\\mathrm{Top}}\\newcommand{\\Disc}{\\mathrm{Disc}}\\newcommand{\\Codisc}{\\mathrm{Codisc}}\\newcommand{\\CoDisc}{\\mathrm{CoDisc}}\\newcommand{\\Ult}{\\mathrm{Ult}}\\newcommand{\\ord}{\\mathrm{ord}}\\DeclareMathOperator{\\maj}{\\mathrm{maj}}\\newcommand{\\bS}{\\mathbb{S}}\\newcommand{\\PConn}{\\mathrm{PConn}}\n\n%%% 形式言語理論\n\\newcommand{\\REGEX}{\\mathrm{REGEX}}\\newcommand{\\RE}{\\mathbf{RE}}\n%%% Graph Theory\n\\newcommand{\\SimpGph}{\\mathrm{SimpGph}}\\newcommand{\\Gph}{\\mathrm{Gph}}\\newcommand{\\mult}{\\mathrm{mult}}\\newcommand{\\inv}{\\mathrm{inv}}\n\n%%% 多様体\n\\newcommand{\\Der}{\\mathrm{Der}}\\newcommand{\\osub}{\\overset{\\mathrm{open}}{\\subset}}\\newcommand{\\osup}{\\overset{\\mathrm{open}}{\\supset}}\\newcommand{\\al}{\\alpha}\\newcommand{\\K}{\\mathbb{K}}\\newcommand{\\Sp}{\\mathrm{Sp}}\\newcommand{\\g}{\\mathfrak{g}}\\newcommand{\\h}{\\mathfrak{h}}\\newcommand{\\Imm}{\\mathrm{Imm}}\\newcommand{\\Imb}{\\mathrm{Imb}}\\newcommand{\\Gr}{\\mathrm{Gr}}\n\\DeclareMathOperator{\\Exp}{Exp}\\DeclareMathOperator{\\codim}{codim}\n%%% 代数\n\\newcommand{\\Ad}{\\mathrm{Ad}}\\newcommand{\\finsupp}{\\mathrm{fin\\;supp}}\\newcommand{\\SO}{\\mathrm{SO}}\\newcommand{\\SU}{\\mathrm{SU}}\\newcommand{\\acts}{\\curvearrowright}\\newcommand{\\mono}{\\hookrightarrow}\\newcommand{\\epi}{\\twoheadrightarrow}\\newcommand{\\Stab}{\\mathrm{Stab}}\\newcommand{\\nor}{\\mathrm{nor}}\\newcommand{\\T}{\\mathbb{T}}\\newcommand{\\Aff}{\\mathrm{Aff}}\\newcommand{\\rsub}{\\triangleleft}\\newcommand{\\rsup}{\\triangleright}\\newcommand{\\subgrp}{\\overset{\\mathrm{subgrp}}{\\subset}}\\newcommand{\\Ext}{\\mathrm{Ext}}\\newcommand{\\sbs}{\\subset}\\newcommand{\\sps}{\\supset}\\newcommand{\\In}{\\mathrm{in}\\;}\\newcommand{\\Tor}{\\mathrm{Tor}}\\newcommand{\\p}{\\b{p}}\\newcommand{\\q}{\\mathfrak{q}}\\newcommand{\\m}{\\mathfrak{m}}\\newcommand{\\cS}{\\mathcal{S}}\\newcommand{\\Frac}{\\mathrm{Frac}\\,}\\newcommand{\\Spec}{\\mathrm{Spec}\\,}\\newcommand{\\bA}{\\mathbb{A}}\\newcommand{\\Sym}{\\mathrm{Sym}}\\newcommand{\\Ann}{\\mathrm{Ann}}\\newcommand{\\Her}{\\mathrm{Her}}\\newcommand{\\Bil}{\\mathrm{Bil}}\\newcommand{\\Ses}{\\mathrm{Ses}}\\newcommand{\\FVS}{\\mathrm{FVS}}\n%%% 代数的位相幾何学\n\\newcommand{\\Ho}{\\mathrm{Ho}}\\newcommand{\\CW}{\\mathrm{CW}}\\newcommand{\\lc}{\\mathrm{lc}}\\newcommand{\\cg}{\\mathrm{cg}}\\newcommand{\\Fib}{\\mathrm{Fib}}\\newcommand{\\Cyl}{\\mathrm{Cyl}}\\newcommand{\\Ch}{\\mathrm{Ch}}\n%%% 微分幾何学\n\\newcommand{\\rP}{\\mathrm{P}}\\newcommand{\\rE}{\\mathrm{E}}\\newcommand{\\e}{\\b{e}}\\renewcommand{\\k}{\\b{k}}\\newcommand{\\Christ}[2]{\\begin{Bmatrix}#1\\\\#2\\end{Bmatrix}}\\renewcommand{\\Vec}[1]{\\overrightarrow{\\mathrm{#1}}}\\newcommand{\\hen}[1]{\\mathrm{#1}}\\renewcommand{\\b}[1]{\\boldsymbol{#1}}\n\n%%% 函数解析\n\\newcommand{\\Inc}{\\mathrm{Inc}}\\newcommand{\\aInc}{\\mathrm{aInc}}\\newcommand{\\HS}{\\mathrm{HS}}\\newcommand{\\loc}{\\mathrm{loc}}\\newcommand{\\Lh}{\\mathrm{L.h.}}\\newcommand{\\Epi}{\\mathrm{Epi}}\\newcommand{\\slim}{\\mathrm{slim}}\\newcommand{\\Ban}{\\mathrm{Ban}}\\newcommand{\\Hilb}{\\mathrm{Hilb}}\\newcommand{\\Ex}{\\mathrm{Ex}}\\newcommand{\\Co}{\\mathrm{Co}}\\newcommand{\\sa}{\\mathrm{sa}}\\newcommand{\\nnorm}[1]{{\\left\\vert\\kern-0.25ex\\left\\vert\\kern-0.25ex\\left\\vert #1 \\right\\vert\\kern-0.25ex\\right\\vert\\kern-0.25ex\\right\\vert}}\\newcommand{\\dvol}{\\mathrm{dvol}}\\newcommand{\\Sconv}{\\mathrm{Sconv}}\\newcommand{\\I}{\\mathcal{I}}\\newcommand{\\nonunital}{\\mathrm{nu}}\\newcommand{\\cpt}{\\mathrm{cpt}}\\newcommand{\\lcpt}{\\mathrm{lcpt}}\\newcommand{\\com}{\\mathrm{com}}\\newcommand{\\Haus}{\\mathrm{Haus}}\\newcommand{\\proper}{\\mathrm{proper}}\\newcommand{\\infinity}{\\mathrm{inf}}\\newcommand{\\TVS}{\\mathrm{TVS}}\\newcommand{\\ess}{\\mathrm{ess}}\\newcommand{\\ext}{\\mathrm{ext}}\\newcommand{\\Index}{\\mathrm{Index}\\;}\\newcommand{\\SSR}{\\mathrm{SSR}}\\newcommand{\\vs}{\\mathrm{vs.}}\\newcommand{\\fM}{\\mathfrak{M}}\\newcommand{\\EDM}{\\mathrm{EDM}}\\newcommand{\\Tw}{\\mathrm{Tw}}\\newcommand{\\fC}{\\mathfrak{C}}\\newcommand{\\bn}{\\boldsymbol{n}}\\newcommand{\\br}{\\boldsymbol{r}}\\newcommand{\\Lam}{\\Lambda}\\newcommand{\\lam}{\\lambda}\\newcommand{\\one}{\\mathbf{1}}\\newcommand{\\dae}{\\text{-a.e.}}\\newcommand{\\das}{\\text{-a.s.}}\\newcommand{\\td}{\\text{-}}\\newcommand{\\RM}{\\mathrm{RM}}\\newcommand{\\BV}{\\mathrm{BV}}\\newcommand{\\normal}{\\mathrm{normal}}\\newcommand{\\lub}{\\mathrm{lub}\\;}\\newcommand{\\Graph}{\\mathrm{Graph}}\\newcommand{\\Ascent}{\\mathrm{Ascent}}\\newcommand{\\Descent}{\\mathrm{Descent}}\\newcommand{\\BIL}{\\mathrm{BIL}}\\newcommand{\\fL}{\\mathfrak{L}}\\newcommand{\\De}{\\Delta}\n%%% 積分論\n\\newcommand{\\calA}{\\mathcal{A}}\\newcommand{\\calB}{\\mathcal{B}}\\newcommand{\\D}{\\mathcal{D}}\\newcommand{\\Y}{\\mathcal{Y}}\\newcommand{\\calC}{\\mathcal{C}}\\renewcommand{\\ae}{\\mathrm{a.e.}\\;}\\newcommand{\\cZ}{\\mathcal{Z}}\\newcommand{\\fF}{\\mathfrak{F}}\\newcommand{\\fI}{\\mathfrak{I}}\\newcommand{\\rV}{\\mathrm{V}}\\newcommand{\\cE}{\\mathcal{E}}\\newcommand{\\sMap}{\\sigma\\textrm{-}\\mathrm{Map}}\\DeclareMathOperator*{\\argmax}{arg\\,max}\\DeclareMathOperator*{\\argmin}{arg\\,min}\\newcommand{\\cC}{\\mathcal{C}}\\newcommand{\\comp}{\\complement}\\newcommand{\\J}{\\mathcal{J}}\\newcommand{\\sumN}[1]{\\sum_{#1\\in\\N}}\\newcommand{\\cupN}[1]{\\cup_{#1\\in\\N}}\\newcommand{\\capN}[1]{\\cap_{#1\\in\\N}}\\newcommand{\\Sum}[1]{\\sum_{#1=1}^\\infty}\\newcommand{\\sumn}{\\sum_{n=1}^\\infty}\\newcommand{\\summ}{\\sum_{m=1}^\\infty}\\newcommand{\\sumk}{\\sum_{k=1}^\\infty}\\newcommand{\\sumi}{\\sum_{i=1}^\\infty}\\newcommand{\\sumj}{\\sum_{j=1}^\\infty}\\newcommand{\\cupn}{\\cup_{n=1}^\\infty}\\newcommand{\\capn}{\\cap_{n=1}^\\infty}\\newcommand{\\cupk}{\\cup_{k=1}^\\infty}\\newcommand{\\cupi}{\\cup_{i=1}^\\infty}\\newcommand{\\cupj}{\\cup_{j=1}^\\infty}\\newcommand{\\limn}{\\lim_{n\\to\\infty}}\\renewcommand{\\L}{\\mathcal{L}}\\newcommand{\\cL}{\\mathcal{L}}\\newcommand{\\Cl}{\\mathrm{Cl}}\\newcommand{\\cN}{\\mathcal{N}}\\newcommand{\\Ae}{\\textrm{-a.e.}\\;}\\newcommand{\\csub}{\\overset{\\textrm{closed}}{\\subset}}\\newcommand{\\csup}{\\overset{\\textrm{closed}}{\\supset}}\\newcommand{\\wB}{\\wt{B}}\\newcommand{\\cG}{\\mathcal{G}}\\newcommand{\\Lip}{\\mathrm{Lip}}\\DeclareMathOperator{\\Dom}{\\mathrm{Dom}}\\newcommand{\\AC}{\\mathrm{AC}}\\newcommand{\\Mol}{\\mathrm{Mol}}\n%%% Fourier解析\n\\newcommand{\\Pe}{\\mathrm{Pe}}\\newcommand{\\wR}{\\wh{\\mathbb{\\R}}}\\newcommand*{\\Laplace}{\\mathop{}\\!\\mathbin\\bigtriangleup}\\newcommand*{\\DAlambert}{\\mathop{}\\!\\mathbin\\Box}\\newcommand{\\bT}{\\mathbb{T}}\\newcommand{\\dx}{\\dslash x}\\newcommand{\\dt}{\\dslash t}\\newcommand{\\ds}{\\dslash s}\n%%% 数値解析\n\\newcommand{\\round}{\\mathrm{round}}\\newcommand{\\cond}{\\mathrm{cond}}\\newcommand{\\diag}{\\mathrm{diag}}\n\\newcommand{\\Adj}{\\mathrm{Adj}}\\newcommand{\\Pf}{\\mathrm{Pf}}\\newcommand{\\Sg}{\\mathrm{Sg}}\n\n%%% 確率論\n\\newcommand{\\aseq}{\\overset{\\text{a.s.}}{=}}\\newcommand{\\deq}{\\overset{\\text{d}}{=}}\\newcommand{\\cV}{\\mathcal{V}}\\newcommand{\\FM}{\\mathrm{FM}}\\newcommand{\\KR}{\\mathrm{KR}}\\newcommand{\\rba}{\\mathrm{rba}}\\newcommand{\\rca}{\\mathrm{rca}}\\newcommand{\\Prob}{\\mathrm{Prob}}\\newcommand{\\X}{\\mathcal{X}}\\newcommand{\\Meas}{\\mathrm{Meas}}\\newcommand{\\as}{\\;\\text{a.s.}}\\newcommand{\\io}{\\;\\mathrm{i.o.}}\\newcommand{\\fe}{\\;\\text{f.e.}}\\newcommand{\\bF}{\\mathbb{F}}\\newcommand{\\W}{\\mathcal{W}}\\newcommand{\\Pois}{\\mathrm{Pois}}\\newcommand{\\iid}{\\text{i.i.d.}}\\newcommand{\\wconv}{\\rightsquigarrow}\\newcommand{\\Var}{\\mathrm{Var}}\\newcommand{\\xrightarrown}{\\xrightarrow{n\\to\\infty}}\\newcommand{\\au}{\\mathrm{au}}\\newcommand{\\cT}{\\mathcal{T}}\\newcommand{\\wto}{\\overset{\\text{w}}{\\to}}\\newcommand{\\dto}{\\overset{\\text{d}}{\\to}}\\newcommand{\\sto}{\\overset{\\text{s}}{\\to}}\\newcommand{\\pto}{\\overset{\\text{p}}{\\to}}\\newcommand{\\mto}{\\overset{\\text{m}}{\\to}}\\newcommand{\\vto}{\\overset{v}{\\to}}\\newcommand{\\Cont}{\\mathrm{Cont}}\\newcommand{\\stably}{\\mathrm{stably}}\\newcommand{\\Np}{\\mathbb{N}^+}\\newcommand{\\oM}{\\overline{\\mathcal{M}}}\\newcommand{\\fP}{\\mathfrak{P}}\\newcommand{\\sign}{\\mathrm{sign}}\n\\DeclareMathOperator{\\Ent}{Ent}\\DeclareMathOperator{\\Polya}{Polya}\\newcommand{\\Borel}{\\mathrm{Borel}}\\newcommand{\\Mid}{\\,|\\,}\\newcommand{\\middleMid}{\\;\\middle|\\;}\\DeclareMathOperator{\\LR}{LR}\\newcommand{\\CP}{\\mathrm{CP}}\\newcommand{\\bD}{\\mathbb{D}}\\newcommand{\\bL}{\\mathbb{L}}\\newcommand{\\fW}{\\mathfrak{W}}\\newcommand{\\DL}{\\mathcal{D}\\mathcal{L}}\\renewcommand{\\r}[1]{\\mathrm{#1}}\\newcommand{\\rC}{\\mathrm{C}}\\newcommand{\\qqquad}{\\qquad\\quad}\n%%% 情報理論\n\\newcommand{\\bit}{\\mathrm{bit}}\\DeclareMathOperator{\\sinc}{sinc}\n%%% 量子論\n\\newcommand{\\err}{\\mathrm{err}}\n%%% 最適化\n\\newcommand{\\varparallel}{\\mathbin{\\!/\\mkern-5mu/\\!}}\\DeclareMathOperator{\\minimize}{minimize}\\DeclareMathOperator{\\subjectto}{subject to}\\newcommand{\\Ri}{\\mathrm{Ri}}\\newcommand{\\Cone}{\\mathrm{Cone}}\\newcommand{\\Int}{\\mathrm{Int}}\n%%% 数理ファイナンス\n\\newcommand{\\pre}{\\mathrm{pre}}\\newcommand{\\om}{\\omega}\n\n%%% 偏微分方程式\n\\DeclareMathOperator{\\div}{div}\n\\newcommand{\\del}{\\partial}\n\\newcommand{\\LHS}{\\mathrm{LHS}}\\newcommand{\\RHS}{\\mathrm{RHS}}\\newcommand{\\bnu}{\\boldsymbol{\\nu}}\\newcommand{\\interior}{\\mathrm{in}\\;}\\newcommand{\\SH}{\\mathrm{SH}}\\renewcommand{\\v}{\\boldsymbol{\\nu}}\\newcommand{\\n}{\\mathbf{n}}\\newcommand{\\ssub}{\\Subset}\\newcommand{\\curl}{\\mathrm{curl}}\n%%% 常微分方程式\n\\newcommand{\\Ei}{\\mathrm{Ei}}\\newcommand{\\sn}{\\mathrm{sn}}\\newcommand{\\wgamma}{\\widetilde{\\gamma}}\n%%% 統計力学\n\\newcommand{\\Ens}{\\mathrm{Ens}}\n%%% 解析力学\n\\newcommand{\\cl}{\\mathrm{cl}}\\newcommand{\\x}{\\boldsymbol{x}}\n\n%%% 統計的因果推論\n\\newcommand{\\Do}{\\mathrm{Do}}\\newcommand{\\IV}{\\mathrm{IV}}\n%%% 応用統計学\n\\DeclareMathOperator{\\pl}{pl}\\newcommand{\\AIC}{\\mathrm{AIC}}\\newcommand{\\mrl}{\\mathrm{mrl}}\\newcommand{\\dotx}{\\dot{x}}\\newcommand{\\UMV}{\\mathrm{UMV}}\\newcommand{\\BLU}{\\mathrm{BLU}}\n%%% 数理統計\n\\DeclareMathOperator{\\arctanh}{arctanh}\\newcommand{\\comb}[2]{\\begin{pmatrix}#1\\\\#2\\end{pmatrix}}\\newcommand{\\bP}{\\mathbb{P}}\\newcommand{\\compsub}{\\overset{\\textrm{cpt}}{\\subset}}\\newcommand{\\lip}{\\textrm{lip}}\\newcommand{\\BL}{\\mathrm{BL}}\\newcommand{\\G}{\\mathbb{G}}\\newcommand{\\NB}{\\mathrm{NB}}\\newcommand{\\oR}{\\ov{\\R}}\\newcommand{\\liminfn}{\\liminf_{n\\to\\infty}}\\newcommand{\\limsupn}{\\limsup_{n\\to\\infty}}\\newcommand{\\esssup}{\\mathrm{ess.sup}}\\newcommand{\\asto}{\\xrightarrow{\\as}}\\newcommand{\\Cov}{\\mathrm{Cov}}\\newcommand{\\cQ}{\\mathcal{Q}}\\newcommand{\\VC}{\\mathrm{VC}}\\newcommand{\\mb}{\\mathrm{mb}}\\newcommand{\\Avar}{\\mathrm{Avar}}\\newcommand{\\bB}{\\mathbb{B}}\\newcommand{\\bW}{\\mathbb{W}}\\newcommand{\\sd}{\\mathrm{sd}}\\newcommand{\\w}[1]{\\widehat{#1}}\\newcommand{\\bZ}{\\mathbb{Z}}\\newcommand{\\Bernoulli}{\\mathrm{Ber}}\\newcommand{\\Ber}{\\mathrm{Ber}}\\newcommand{\\Mult}{\\mathrm{Mult}}\\newcommand{\\BPois}{\\mathrm{BPois}}\\newcommand{\\fraks}{\\mathfrak{s}}\\newcommand{\\frakk}{\\mathfrak{k}}\\newcommand{\\IF}{\\mathrm{IF}}\\newcommand{\\bX}{\\boldsymbol{X}}\\newcommand{\\bx}{\\boldsymbol{x}}\\newcommand{\\indep}{\\perp\\!\\!\\!\\perp}\\newcommand{\\IG}{\\mathrm{IG}}\\newcommand{\\Levy}{\\mathrm{Levy}}\\newcommand{\\MP}{\\mathrm{MP}}\\newcommand{\\Hermite}{\\mathrm{Hermite}}\\newcommand{\\Skellam}{\\mathrm{Skellam}}\\newcommand{\\Dirichlet}{\\mathrm{Dirichlet}}\\newcommand{\\Beta}{\\mathrm{Beta}}\\newcommand{\\bE}{\\mathbb{E}}\\newcommand{\\bG}{\\mathbb{G}}\\newcommand{\\MISE}{\\mathrm{MISE}}\\newcommand{\\logit}{\\mathtt{logit}}\\newcommand{\\expit}{\\mathtt{expit}}\\newcommand{\\cK}{\\mathcal{K}}\\newcommand{\\dl}{\\dot{l}}\\newcommand{\\dotp}{\\dot{p}}\\newcommand{\\wl}{\\wt{l}}\\newcommand{\\Gauss}{\\mathrm{Gauss}}\\newcommand{\\fA}{\\mathfrak{A}}\\newcommand{\\under}{\\mathrm{under}\\;}\\newcommand{\\whtheta}{\\wh{\\theta}}\\newcommand{\\Em}{\\mathrm{Em}}\\newcommand{\\ztheta}{{\\theta_0}}\n\\newcommand{\\rO}{\\mathrm{O}}\\newcommand{\\Bin}{\\mathrm{Bin}}\\newcommand{\\rW}{\\mathrm{W}}\\newcommand{\\rG}{\\mathrm{G}}\\newcommand{\\rB}{\\mathrm{B}}\\newcommand{\\rN}{\\mathrm{N}}\\newcommand{\\rU}{\\mathrm{U}}\\newcommand{\\HG}{\\mathrm{HG}}\\newcommand{\\GAMMA}{\\mathrm{Gamma}}\\newcommand{\\Cauchy}{\\mathrm{Cauchy}}\\newcommand{\\rt}{\\mathrm{t}}\\newcommand{\\rF}{\\mathrm{F}}\n\\DeclareMathOperator{\\erf}{erf}\n%%% 計量経済学\n\\newcommand{\\FE}{\\mathrm{FE}}\\newcommand{\\bV}{\\boldsymbol{V}}\\newcommand{\\GLS}{\\mathrm{GLS}}\\newcommand{\\be}{\\boldsymbol{e}}\\newcommand{\\POOL}{\\mathrm{POOL}}\\newcommand{\\GMM}{\\mathrm{GMM}}\\newcommand{\\MM}{\\mathrm{MM}}\\newcommand{\\SSIV}{\\mathrm{SSIV}}\\newcommand{\\JIV}{\\mathrm{JIV}}\\newcommand{\\AR}{\\mathrm{AR}}\\newcommand{\\ILS}{\\mathrm{ILS}}\\newcommand{\\SLS}{\\mathrm{SLS}}\\newcommand{\\LIML}{\\mathrm{LIML}}\n\n%%% 無限次元統計模型の理論\n\\newcommand{\\Rad}{\\mathrm{Rad}}\\newcommand{\\bY}{\\boldsymbol{Y}}\\newcommand{\\pone}{{(1)}}\\newcommand{\\ptwo}{{(2)}}\\newcommand{\\ps}[1]{{(#1)}}\\newcommand{\\fsub}{\\overset{\\text{finite}}{\\subset}}\n%%% Banach Lattices\n\\newcommand{\\Slv}{\\mathrm{Slv}}\\newcommand{\\Hypo}{\\mathrm{Hypo}}\\newcommand{\\CL}{\\mathrm{CL}}\\DeclareMathOperator{\\ba}{ba}\\DeclareMathOperator{\\ca}{ca}\n\n%%% 圏\n\\newcommand{\\varlim}{\\varprojlim}\\newcommand{\\Hom}{\\mathrm{Hom}}\\newcommand{\\Iso}{\\mathrm{Iso}}\\newcommand{\\Mor}{\\mathrm{Mor}}\\newcommand{\\Isom}{\\mathrm{Isom}}\\newcommand{\\Aut}{\\mathrm{Aut}}\\newcommand{\\End}{\\mathrm{End}}\\newcommand{\\op}{\\mathrm{op}}\\newcommand{\\ev}{\\mathrm{ev}}\\newcommand{\\Ob}{\\mathrm{Ob}}\\newcommand{\\Ar}{\\mathrm{Ar}}\\newcommand{\\Arr}{\\mathrm{Arr}}\\newcommand{\\Set}{\\mathrm{Set}}\\newcommand{\\Grp}{\\mathrm{Grp}}\\newcommand{\\Cat}{\\mathrm{Cat}}\\newcommand{\\Mon}{\\mathrm{Mon}}\\newcommand{\\Ring}{\\mathrm{Ring}}\\newcommand{\\CRing}{\\mathrm{CRing}}\\newcommand{\\Ab}{\\mathrm{Ab}}\\newcommand{\\Pos}{\\mathrm{Pos}}\\newcommand{\\Vect}{\\mathrm{Vect}}\\newcommand{\\FinVect}{\\mathrm{FinVect}}\\newcommand{\\FinSet}{\\mathrm{FinSet}}\\newcommand{\\FinMeas}{\\mathrm{FinMeas}}\\newcommand{\\OmegaAlg}{\\Omega\\text{-}\\mathrm{Alg}}\\newcommand{\\OmegaEAlg}{(\\Omega,E)\\text{-}\\mathrm{Alg}}\\newcommand{\\Fun}{\\mathrm{Fun}}\\newcommand{\\Func}{\\mathrm{Func}}\\newcommand{\\Alg}{\\mathrm{Alg}} %代数の圏\n\\newcommand{\\Met}{\\mathrm{Met}} %Metric space & Contraction maps\n\\newcommand{\\Stoch}{\\mathrm{Stoch}}\\newcommand{\\FinStoch}{\\mathrm{FinStoch}}\\newcommand{\\Copy}{\\mathrm{copy}}\\newcommand{\\Delete}{\\mathrm{delete}} %確率空間とMarkov核の圏\n\\newcommand{\\Bool}{\\mathrm{Bool}}\\newcommand{\\CABool}{\\mathrm{CABool}}\\newcommand{\\CompBoolAlg}{\\mathrm{CompBoolAlg}}\\newcommand{\\BoolAlg}{\\mathrm{BoolAlg}}\\newcommand{\\BoolRng}{\\mathrm{BoolRng}}\\newcommand{\\HeytAlg}{\\mathrm{HeytAlg}}\\newcommand{\\CompHeytAlg}{\\mathrm{CompHeytAlg}}\\newcommand{\\Lat}{\\mathrm{Lat}}\\newcommand{\\CompLat}{\\mathrm{CompLat}}\\newcommand{\\SemiLat}{\\mathrm{SemiLat}}\\newcommand{\\Stone}{\\mathrm{Stone}}\\newcommand{\\Mfd}{\\mathrm{Mfd}}\\newcommand{\\LieAlg}{\\mathrm{LieAlg}}\n\\newcommand{\\Sob}{\\mathrm{Sob}} %Sober space & continuous map\n\\newcommand{\\Op}{\\mathrm{Op}} %Category of open subsets\n\\newcommand{\\Sh}{\\mathrm{Sh}} %Category of sheave\n\\newcommand{\\PSh}{\\mathrm{PSh}} %Category of presheave, PSh(C)=[C^op,set]のこと\n\\DeclareMathOperator{\\Conv}{Conv} %Convergence spaceの圏\n\\newcommand{\\Unif}{\\mathrm{Unif}} %一様空間と一様連続写像の圏\n\\newcommand{\\Frm}{\\mathrm{Frm}} %フレームとフレームの射\n\\newcommand{\\Locale}{\\mathrm{Locale}} %その反対圏\n\\newcommand{\\Diff}{\\mathrm{Diff}} %滑らかな多様体の圏\n\\newcommand{\\Quiv}{\\mathrm{Quiv}} %Quiverの圏\n\\newcommand{\\B}{\\mathcal{B}}\\newcommand{\\cB}{\\mathcal{B}}\\newcommand{\\Span}{\\mathrm{Span}}\\newcommand{\\Corr}{\\mathrm{Corr}}\\newcommand{\\Decat}{\\mathrm{Decat}}\\newcommand{\\Rep}{\\mathrm{Rep}}\\newcommand{\\Grpd}{\\mathrm{Grpd}}\\newcommand{\\sSet}{\\mathrm{sSet}}\\newcommand{\\Mod}{\\mathrm{Mod}}\\newcommand{\\SmoothMnf}{\\mathrm{SmoothMnf}}\\newcommand{\\coker}{\\mathrm{coker}}\\newcommand{\\Ord}{\\mathrm{Ord}}\\newcommand{\\eq}{\\mathrm{eq}}\\newcommand{\\coeq}{\\mathrm{coeq}}\\newcommand{\\act}{\\mathrm{act}}\n\n%%% SMC\n\\newcommand{\\apf}{\\mathrm{apf}}\\newcommand{\\opt}{\\mathrm{opt}}\\newcommand{\\IS}{\\mathrm{IS}}\\newcommand{\\IR}{\\mathrm{IR}}\\newcommand{\\iidsim}{\\overset{\\text{iid}}{\\sim}}\\DeclareMathOperator{\\KL}{KL}\\DeclareMathOperator{\\JS}{JS}\\DeclareMathOperator{\\ESS}{ESS}\\DeclareMathOperator{\\MSE}{MSE}\\newcommand{\\propt}{\\,\\propto\\,}\\newcommand{\\bM}{\\mathbb{M}}\\newcommand{\\cX}{\\mathcal{X}}\\newcommand{\\cY}{\\mathcal{Y}}\\newcommand{\\cP}{\\mathcal{P}}\\newcommand{\\ola}[1]{\\overleftarrow{#1}}\n\n%%% 括弧類\n\\newcommand{\\ov}[1]{\\overline{#1}}\\newcommand{\\un}[1]{\\underline{#1}}\\newcommand{\\wt}[1]{\\widetilde{#1}}\\newcommand{\\wh}[1]{\\widehat{#1}}\n\\newcommand{\\pp}[2]{\\frac{\\partial #1}{\\partial #2}}\\newcommand{\\ppp}[3]{\\frac{\\partial #1}{\\partial #2\\partial #3}}\\newcommand{\\dd}[2]{\\frac{d #1}{d #2}}\n\\newcommand{\\floor}[1]{\\lfloor#1\\rfloor}\\newcommand{\\Floor}[1]{\\left\\lfloor#1\\right\\rfloor}\\newcommand{\\ceil}[1]{\\lceil#1\\rceil}\n\\newcommand{\\ocinterval}[1]{(#1]}\\newcommand{\\cointerval}[1]{[#1)}\\newcommand{\\COinterval}[1]{\\left[#1\\right)}\n\n%%% 予約語\n\\renewcommand{\\iff}{\\;\\mathrm{iff}\\;}\n\\newcommand{\\False}{\\mathrm{False}}\\newcommand{\\True}{\\mathrm{True}}\n\\newcommand{\\otherwise}{\\mathrm{otherwise}}\n\\newcommand{\\suchthat}{\\;\\mathrm{s.t.}\\;}\n\n%%% 略記\n\\newcommand{\\cM}{\\mathcal{M}}\\newcommand{\\M}{\\mathbb{M}}\\newcommand{\\cF}{\\mathcal{F}}\\newcommand{\\cD}{\\mathcal{D}}\\newcommand{\\fX}{\\mathfrak{X}}\\newcommand{\\fY}{\\mathfrak{Y}}\\newcommand{\\fZ}{\\mathfrak{Z}}\\renewcommand{\\H}{\\mathcal{H}}\\newcommand{\\cH}{\\mathcal{H}}\\newcommand{\\fH}{\\mathfrak{H}}\\newcommand{\\bH}{\\mathbb{H}}\\newcommand{\\id}{\\mathrm{id}}\\newcommand{\\A}{\\mathcal{A}}\n\\newcommand{\\lmd}{\\lambda}\n\\newcommand{\\Lmd}{\\Lambda}\n\\newcommand{\\cI}{\\mathcal{I}}\n\n%%% 矢印類\n\\newcommand{\\iso}{\\overset{\\sim}{\\to}}\n\\newcommand{\\Lrarrow}{\\;\\;\\Leftrightarrow\\;\\;}\n$$\n:::\n\n\n\n::: {.callout-tip title=\"brms: Bayesian Regression Models using 'Stan' リンク集\" appearance=\"simple\"}\n\n* [r-project](https://cran.r-project.org/web/packages/brms/)\n* [Documentation](https://paul-buerkner.github.io/brms/)\n* [GitHub](https://github.com/paul-buerkner/brms)\n* [discourse](https://discourse.mc-stan.org/)\n* [@Burkner2017]\n* [@Burkner2018]\n* [@Burkner2021]\n\n:::\n\nダウンロードは：^[R を最新バージョン 4.3.1 → 4.4.0 にアップデートしなければインストールに失敗したことに注意．]\n\n```r\ninstall.packages(\"brms\")\n```\n\n## 例：カウントデータのモデリング {#sec-example}\n\nDocumentation で紹介されている，[`Epilepsy Seizures Data`](https://search.r-project.org/CRAN/refmans/dhglm/html/epilepsy.html) [@Leppik+1987]，[@Thall-Vail1990] を用いた [例](https://paul-buerkner.github.io/brms/) を実行してみる：\n\n```r\nlibrary(brms)\nfit1 <- brm(count ~ zAge + zBase * Trt + (1|patient),\n            data = epilepsy, family = poisson())\n```\n\nてんかん (epilepsy) 患者の発作回数`count`を被説明変数とし，処置の効果を表す説明変数`Trt`と患者毎のランダムな切片項`(1|patient)`と`zAge`,`zBase`への依存構造を調べたい．被説明変数`count`のモデルとしては，Poisson 分布族を用いる．\n\n::: {.callout-note appearance=\"simple\" title=\"説明変数\"}\n\n* `zAge`：標準化された年齢\n* `zBase`：ベースの発作回数\n* `Trt`：治療の有無を表す２値変数\n* `(1|patient)`：患者ごとに異なるとした切片項\n\n`zBase * Trt`という記法は，この２つの交互作用もモデルに含めることを意味する．\n\nまた，59 人の患者に関して，４回の入院時の発作回数を記録した，全 236 データからなる．`patient`が患者を識別する ID であり，`(1|patient)`は患者ごとのランダム効果ということになる．\n\n従って本モデルは`zAge`, `zBase`, `Trt`, `Trt*zBase`という固定効果，`(1|patient)`というランダム効果を取り入れた混合効果モデルということになり，回帰式は次の通りである：\n$$\n\\text{count}_{it} = \\beta_1 \\cdot\\text{zAge}_i+ \\beta_2 \\cdot \\text{zBase}_i + \\beta_3 \\cdot \\text{Trt}_i\n$$\n$$\n+ \\beta_4 \\cdot (\\text{zBase}_i \\cdot \\text{Trt}_i) + u_i +\\ep_{it}.\n$$\n\nベースの発作回数が高いほど，治療効果が高い／低いのではないか？という仮説を検証する，`zBase*Trt`を曝露因子としたモデルである．\n\n:::\n\n::: {.callout-caution collapse=\"true\" title=\"全データ\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nepilepsy\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Age Base Trt patient visit count obs        zAge        zBase\n1    31   11   0       1     1     5   1  0.42499501 -0.757172825\n2    30   11   0       2     1     3   2  0.26528351 -0.757172825\n3    25    6   0       3     1     2   3 -0.53327400 -0.944403322\n4    36    8   0       4     1     4   4  1.22355252 -0.869511123\n5    22   66   0       5     1     7   5 -1.01240850  1.302362646\n6    29   27   0       6     1     5   6  0.10557201 -0.158035233\n7    31   12   0       7     1     6   7  0.42499501 -0.719726725\n8    42   52   0       8     1    40   8  2.18182153  0.778117253\n9    37   23   0       9     1     5   9  1.38326402 -0.307819631\n10   28   10   0      10     1    14  10 -0.05413949 -0.794618924\n11   36   52   0      11     1    26  11  1.22355252  0.778117253\n12   24   33   0      12     1    12  12 -0.69298550  0.066641363\n13   23   18   0      13     1     4  13 -0.85269700 -0.495050128\n14   36   42   0      14     1     7  14  1.22355252  0.403656259\n15   26   87   0      15     1    16  15 -0.37356249  2.088730734\n16   26   50   0      16     1    11  16 -0.37356249  0.703225054\n17   28   18   0      17     1     0  17 -0.05413949 -0.495050128\n18   31  111   0      18     1    37  18  0.42499501  2.987437121\n19   32   18   0      19     1     3  19  0.58470651 -0.495050128\n20   21   20   0      20     1     3  20 -1.17212000 -0.420157930\n21   29   12   0      21     1     3  21  0.10557201 -0.719726725\n22   21    9   0      22     1     3  22 -1.17212000 -0.832065024\n23   32   17   0      23     1     2  23  0.58470651 -0.532496228\n24   25   28   0      24     1     8  24 -0.53327400 -0.120589134\n25   30   55   0      25     1    18  25  0.26528351  0.890455552\n26   40    9   0      26     1     2  26  1.86239852 -0.832065024\n27   19   10   0      27     1     3  27 -1.49154300 -0.794618924\n28   22   47   0      28     1    13  28 -1.01240850  0.590886756\n29   18   76   1      29     1    11  29 -1.65125450  1.676823640\n30   32   38   1      30     1     8  30  0.58470651  0.253871861\n31   20   19   1      31     1     0  31 -1.33183150 -0.457604029\n32   30   10   1      32     1     3  32  0.26528351 -0.794618924\n33   18   19   1      33     1     2  33 -1.65125450 -0.457604029\n34   24   24   1      34     1     4  34 -0.69298550 -0.270373532\n35   30   31   1      35     1    22  35  0.26528351 -0.008250835\n36   35   14   1      36     1     5  36  1.06384102 -0.644834526\n37   27   11   1      37     1     2  37 -0.21385099 -0.757172825\n38   20   67   1      38     1     3  38 -1.33183150  1.339808745\n39   22   41   1      39     1     4  39 -1.01240850  0.366210159\n40   28    7   1      40     1     2  40 -0.05413949 -0.906957223\n41   23   22   1      41     1     0  41 -0.85269700 -0.345265731\n42   40   13   1      42     1     5  42  1.86239852 -0.682280626\n43   33   46   1      43     1    11  43  0.74441801  0.553440656\n44   21   36   1      44     1    10  44 -1.17212000  0.178979662\n45   35   38   1      45     1    19  45  1.06384102  0.253871861\n46   25    7   1      46     1     1  46 -0.53327400 -0.906957223\n47   26   36   1      47     1     6  47 -0.37356249  0.178979662\n48   25   11   1      48     1     2  48 -0.53327400 -0.757172825\n49   22  151   1      49     1   102  49 -1.01240850  4.485281100\n50   32   22   1      50     1     4  50  0.58470651 -0.345265731\n51   25   41   1      51     1     8  51 -0.53327400  0.366210159\n52   35   32   1      52     1     1  52  1.06384102  0.029195264\n53   21   56   1      53     1    18  53 -1.17212000  0.927901651\n54   41   24   1      54     1     6  54  2.02211002 -0.270373532\n55   32   16   1      55     1     3  55  0.58470651 -0.569942327\n56   26   22   1      56     1     1  56 -0.37356249 -0.345265731\n57   21   25   1      57     1     2  57 -1.17212000 -0.232927432\n58   36   13   1      58     1     0  58  1.22355252 -0.682280626\n59   37   12   1      59     1     1  59  1.38326402 -0.719726725\n60   31   11   0       1     2     3  60  0.42499501 -0.757172825\n61   30   11   0       2     2     5  61  0.26528351 -0.757172825\n62   25    6   0       3     2     4  62 -0.53327400 -0.944403322\n63   36    8   0       4     2     4  63  1.22355252 -0.869511123\n64   22   66   0       5     2    18  64 -1.01240850  1.302362646\n65   29   27   0       6     2     2  65  0.10557201 -0.158035233\n66   31   12   0       7     2     4  66  0.42499501 -0.719726725\n67   42   52   0       8     2    20  67  2.18182153  0.778117253\n68   37   23   0       9     2     6  68  1.38326402 -0.307819631\n69   28   10   0      10     2    13  69 -0.05413949 -0.794618924\n70   36   52   0      11     2    12  70  1.22355252  0.778117253\n71   24   33   0      12     2     6  71 -0.69298550  0.066641363\n72   23   18   0      13     2     4  72 -0.85269700 -0.495050128\n73   36   42   0      14     2     9  73  1.22355252  0.403656259\n74   26   87   0      15     2    24  74 -0.37356249  2.088730734\n75   26   50   0      16     2     0  75 -0.37356249  0.703225054\n76   28   18   0      17     2     0  76 -0.05413949 -0.495050128\n77   31  111   0      18     2    29  77  0.42499501  2.987437121\n78   32   18   0      19     2     5  78  0.58470651 -0.495050128\n79   21   20   0      20     2     0  79 -1.17212000 -0.420157930\n80   29   12   0      21     2     4  80  0.10557201 -0.719726725\n81   21    9   0      22     2     4  81 -1.17212000 -0.832065024\n82   32   17   0      23     2     3  82  0.58470651 -0.532496228\n83   25   28   0      24     2    12  83 -0.53327400 -0.120589134\n84   30   55   0      25     2    24  84  0.26528351  0.890455552\n85   40    9   0      26     2     1  85  1.86239852 -0.832065024\n86   19   10   0      27     2     1  86 -1.49154300 -0.794618924\n87   22   47   0      28     2    15  87 -1.01240850  0.590886756\n88   18   76   1      29     2    14  88 -1.65125450  1.676823640\n89   32   38   1      30     2     7  89  0.58470651  0.253871861\n90   20   19   1      31     2     4  90 -1.33183150 -0.457604029\n91   30   10   1      32     2     6  91  0.26528351 -0.794618924\n92   18   19   1      33     2     6  92 -1.65125450 -0.457604029\n93   24   24   1      34     2     3  93 -0.69298550 -0.270373532\n94   30   31   1      35     2    17  94  0.26528351 -0.008250835\n95   35   14   1      36     2     4  95  1.06384102 -0.644834526\n96   27   11   1      37     2     4  96 -0.21385099 -0.757172825\n97   20   67   1      38     2     7  97 -1.33183150  1.339808745\n98   22   41   1      39     2    18  98 -1.01240850  0.366210159\n99   28    7   1      40     2     1  99 -0.05413949 -0.906957223\n100  23   22   1      41     2     2 100 -0.85269700 -0.345265731\n101  40   13   1      42     2     4 101  1.86239852 -0.682280626\n102  33   46   1      43     2    14 102  0.74441801  0.553440656\n103  21   36   1      44     2     5 103 -1.17212000  0.178979662\n104  35   38   1      45     2     7 104  1.06384102  0.253871861\n105  25    7   1      46     2     1 105 -0.53327400 -0.906957223\n106  26   36   1      47     2    10 106 -0.37356249  0.178979662\n107  25   11   1      48     2     1 107 -0.53327400 -0.757172825\n108  22  151   1      49     2    65 108 -1.01240850  4.485281100\n109  32   22   1      50     2     3 109  0.58470651 -0.345265731\n110  25   41   1      51     2     6 110 -0.53327400  0.366210159\n111  35   32   1      52     2     3 111  1.06384102  0.029195264\n112  21   56   1      53     2    11 112 -1.17212000  0.927901651\n113  41   24   1      54     2     3 113  2.02211002 -0.270373532\n114  32   16   1      55     2     5 114  0.58470651 -0.569942327\n115  26   22   1      56     2    23 115 -0.37356249 -0.345265731\n116  21   25   1      57     2     3 116 -1.17212000 -0.232927432\n117  36   13   1      58     2     0 117  1.22355252 -0.682280626\n118  37   12   1      59     2     4 118  1.38326402 -0.719726725\n119  31   11   0       1     3     3 119  0.42499501 -0.757172825\n120  30   11   0       2     3     3 120  0.26528351 -0.757172825\n121  25    6   0       3     3     0 121 -0.53327400 -0.944403322\n122  36    8   0       4     3     1 122  1.22355252 -0.869511123\n123  22   66   0       5     3     9 123 -1.01240850  1.302362646\n124  29   27   0       6     3     8 124  0.10557201 -0.158035233\n125  31   12   0       7     3     0 125  0.42499501 -0.719726725\n126  42   52   0       8     3    21 126  2.18182153  0.778117253\n127  37   23   0       9     3     6 127  1.38326402 -0.307819631\n128  28   10   0      10     3     6 128 -0.05413949 -0.794618924\n129  36   52   0      11     3     6 129  1.22355252  0.778117253\n130  24   33   0      12     3     8 130 -0.69298550  0.066641363\n131  23   18   0      13     3     6 131 -0.85269700 -0.495050128\n132  36   42   0      14     3    12 132  1.22355252  0.403656259\n133  26   87   0      15     3    10 133 -0.37356249  2.088730734\n134  26   50   0      16     3     0 134 -0.37356249  0.703225054\n135  28   18   0      17     3     3 135 -0.05413949 -0.495050128\n136  31  111   0      18     3    28 136  0.42499501  2.987437121\n137  32   18   0      19     3     2 137  0.58470651 -0.495050128\n138  21   20   0      20     3     6 138 -1.17212000 -0.420157930\n139  29   12   0      21     3     3 139  0.10557201 -0.719726725\n140  21    9   0      22     3     3 140 -1.17212000 -0.832065024\n141  32   17   0      23     3     3 141  0.58470651 -0.532496228\n142  25   28   0      24     3     2 142 -0.53327400 -0.120589134\n143  30   55   0      25     3    76 143  0.26528351  0.890455552\n144  40    9   0      26     3     2 144  1.86239852 -0.832065024\n145  19   10   0      27     3     4 145 -1.49154300 -0.794618924\n146  22   47   0      28     3    13 146 -1.01240850  0.590886756\n147  18   76   1      29     3     9 147 -1.65125450  1.676823640\n148  32   38   1      30     3     9 148  0.58470651  0.253871861\n149  20   19   1      31     3     3 149 -1.33183150 -0.457604029\n150  30   10   1      32     3     1 150  0.26528351 -0.794618924\n151  18   19   1      33     3     7 151 -1.65125450 -0.457604029\n152  24   24   1      34     3     1 152 -0.69298550 -0.270373532\n153  30   31   1      35     3    19 153  0.26528351 -0.008250835\n154  35   14   1      36     3     7 154  1.06384102 -0.644834526\n155  27   11   1      37     3     0 155 -0.21385099 -0.757172825\n156  20   67   1      38     3     7 156 -1.33183150  1.339808745\n157  22   41   1      39     3     2 157 -1.01240850  0.366210159\n158  28    7   1      40     3     1 158 -0.05413949 -0.906957223\n159  23   22   1      41     3     4 159 -0.85269700 -0.345265731\n160  40   13   1      42     3     0 160  1.86239852 -0.682280626\n161  33   46   1      43     3    25 161  0.74441801  0.553440656\n162  21   36   1      44     3     3 162 -1.17212000  0.178979662\n163  35   38   1      45     3     6 163  1.06384102  0.253871861\n164  25    7   1      46     3     2 164 -0.53327400 -0.906957223\n165  26   36   1      47     3     8 165 -0.37356249  0.178979662\n166  25   11   1      48     3     0 166 -0.53327400 -0.757172825\n167  22  151   1      49     3    72 167 -1.01240850  4.485281100\n168  32   22   1      50     3     2 168  0.58470651 -0.345265731\n169  25   41   1      51     3     5 169 -0.53327400  0.366210159\n170  35   32   1      52     3     1 170  1.06384102  0.029195264\n171  21   56   1      53     3    28 171 -1.17212000  0.927901651\n172  41   24   1      54     3     4 172  2.02211002 -0.270373532\n173  32   16   1      55     3     4 173  0.58470651 -0.569942327\n174  26   22   1      56     3    19 174 -0.37356249 -0.345265731\n175  21   25   1      57     3     0 175 -1.17212000 -0.232927432\n176  36   13   1      58     3     0 176  1.22355252 -0.682280626\n177  37   12   1      59     3     3 177  1.38326402 -0.719726725\n178  31   11   0       1     4     3 178  0.42499501 -0.757172825\n179  30   11   0       2     4     3 179  0.26528351 -0.757172825\n180  25    6   0       3     4     5 180 -0.53327400 -0.944403322\n181  36    8   0       4     4     4 181  1.22355252 -0.869511123\n182  22   66   0       5     4    21 182 -1.01240850  1.302362646\n183  29   27   0       6     4     7 183  0.10557201 -0.158035233\n184  31   12   0       7     4     2 184  0.42499501 -0.719726725\n185  42   52   0       8     4    12 185  2.18182153  0.778117253\n186  37   23   0       9     4     5 186  1.38326402 -0.307819631\n187  28   10   0      10     4     0 187 -0.05413949 -0.794618924\n188  36   52   0      11     4    22 188  1.22355252  0.778117253\n189  24   33   0      12     4     4 189 -0.69298550  0.066641363\n190  23   18   0      13     4     2 190 -0.85269700 -0.495050128\n191  36   42   0      14     4    14 191  1.22355252  0.403656259\n192  26   87   0      15     4     9 192 -0.37356249  2.088730734\n193  26   50   0      16     4     5 193 -0.37356249  0.703225054\n194  28   18   0      17     4     3 194 -0.05413949 -0.495050128\n195  31  111   0      18     4    29 195  0.42499501  2.987437121\n196  32   18   0      19     4     5 196  0.58470651 -0.495050128\n197  21   20   0      20     4     7 197 -1.17212000 -0.420157930\n198  29   12   0      21     4     4 198  0.10557201 -0.719726725\n199  21    9   0      22     4     4 199 -1.17212000 -0.832065024\n200  32   17   0      23     4     5 200  0.58470651 -0.532496228\n201  25   28   0      24     4     8 201 -0.53327400 -0.120589134\n202  30   55   0      25     4    25 202  0.26528351  0.890455552\n203  40    9   0      26     4     1 203  1.86239852 -0.832065024\n204  19   10   0      27     4     2 204 -1.49154300 -0.794618924\n205  22   47   0      28     4    12 205 -1.01240850  0.590886756\n206  18   76   1      29     4     8 206 -1.65125450  1.676823640\n207  32   38   1      30     4     4 207  0.58470651  0.253871861\n208  20   19   1      31     4     0 208 -1.33183150 -0.457604029\n209  30   10   1      32     4     3 209  0.26528351 -0.794618924\n210  18   19   1      33     4     4 210 -1.65125450 -0.457604029\n211  24   24   1      34     4     3 211 -0.69298550 -0.270373532\n212  30   31   1      35     4    16 212  0.26528351 -0.008250835\n213  35   14   1      36     4     4 213  1.06384102 -0.644834526\n214  27   11   1      37     4     4 214 -0.21385099 -0.757172825\n215  20   67   1      38     4     7 215 -1.33183150  1.339808745\n216  22   41   1      39     4     5 216 -1.01240850  0.366210159\n217  28    7   1      40     4     0 217 -0.05413949 -0.906957223\n218  23   22   1      41     4     0 218 -0.85269700 -0.345265731\n219  40   13   1      42     4     3 219  1.86239852 -0.682280626\n220  33   46   1      43     4    15 220  0.74441801  0.553440656\n221  21   36   1      44     4     8 221 -1.17212000  0.178979662\n222  35   38   1      45     4     7 222  1.06384102  0.253871861\n223  25    7   1      46     4     3 223 -0.53327400 -0.906957223\n224  26   36   1      47     4     8 224 -0.37356249  0.178979662\n225  25   11   1      48     4     0 225 -0.53327400 -0.757172825\n226  22  151   1      49     4    63 226 -1.01240850  4.485281100\n227  32   22   1      50     4     4 227  0.58470651 -0.345265731\n228  25   41   1      51     4     7 228 -0.53327400  0.366210159\n229  35   32   1      52     4     5 229  1.06384102  0.029195264\n230  21   56   1      53     4    13 230 -1.17212000  0.927901651\n231  41   24   1      54     4     0 231  2.02211002 -0.270373532\n232  32   16   1      55     4     3 232  0.58470651 -0.569942327\n233  26   22   1      56     4     8 233 -0.37356249 -0.345265731\n234  21   25   1      57     4     1 234 -1.17212000 -0.232927432\n235  36   13   1      58     4     0 235  1.22355252 -0.682280626\n236  37   12   1      59     4     2 236  1.38326402 -0.719726725\n```\n\n\n:::\n:::\n\n:::\n\n### モデルの推定とプロット\n\n::: {.callout-caution collapse=\"true\" title=\"フィッティングの出力\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(brms)\nfit1 <- brm(count ~ zAge + zBase * Trt + (1|patient),\n            data = epilepsy, family = poisson())\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nStart sampling\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 5.1e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.51 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 1.039 seconds (Warm-up)\nChain 1:                0.712 seconds (Sampling)\nChain 1:                1.751 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 1.2e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 1.102 seconds (Warm-up)\nChain 2:                0.763 seconds (Sampling)\nChain 2:                1.865 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 1.6e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 1.02 seconds (Warm-up)\nChain 3:                0.79 seconds (Sampling)\nChain 3:                1.81 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 1.2e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 1.008 seconds (Warm-up)\nChain 4:                0.74 seconds (Sampling)\nChain 4:                1.748 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: poisson \n  Links: mu = log \nFormula: count ~ zAge + zBase * Trt + (1 | patient) \n   Data: epilepsy (Number of observations: 236) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~patient (Number of levels: 59) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.58      0.07     0.46     0.74 1.00      719     1600\n\nRegression Coefficients:\n           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      1.77      0.12     1.54     2.00 1.00      690     1215\nzAge           0.10      0.09    -0.09     0.28 1.00      618     1043\nzBase          0.70      0.12     0.47     0.94 1.01      675     1415\nTrt1          -0.27      0.16    -0.59     0.06 1.00      724     1395\nzBase:Trt1     0.05      0.16    -0.27     0.37 1.00      758     1479\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n基本的な解析の前提がまず出力され，推定結果はグループ毎（今回は患者毎）の変数（今回は $u_i$）から表示される．\n\n後半に固定効果の係数，すなわち回帰係数の推定結果が表示される．\n\n治療効果`Trt`の係数は負で，平均的に処置効果はある可能性があるが，95% 信頼区間は $0$ を跨いでいるという意味で，有意とは言えない．また，交差項`zBase*Trt`の係数は小さく，交互効果の存在を示す証拠はないと思われる．\n\n$\\wh{R}$ が１より大きい場合，MCMC が収束していない可能性を意味する [@Vehtari+2021]．通説には $\\wh{R}\\le1.1$ などの基準がある．\n\n変数を指定して，事後分布と MCMC の軌跡をプロットできる：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit1, variable = c(\"b_Trt1\", \"b_zBase\"))\n```\n\n::: {.cell-output-display}\n![](brms_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nより詳しく見るには`conditional_effects`関数を用いることもできる．交差項の効果はほとんどないことがわかる：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(conditional_effects(fit1, effects = \"zBase:Trt\"))\n```\n\n::: {.cell-output-display}\n![](brms_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n### モデルによる予測\n\nfit したモデル `fit1` を用いて，平均年齢と平均ベースレートを持つ患者に対する治療効果を予測する：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnewdata <- data.frame(Trt = c(0, 1), zAge = 0, zBase = 0)\npredict(fit1, newdata = newdata, re_formula = NA)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Estimate Est.Error Q2.5 Q97.5\n[1,]  5.93450  2.522360    2    11\n[2,]  4.54775  2.183898    1     9\n```\n\n\n:::\n:::\n\n\n関数[`predict()`](https://paul-buerkner.github.io/brms/reference/predict.brmsfit.html)は事後予測分布からのサンプリングを行う．一方で，関数[`fitted()`](https://paul-buerkner.github.io/brms/reference/fitted.brmsfit.html)は平均を返す．\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfitted(fit1, newdata = newdata, re_formula = NA)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Estimate Est.Error     Q2.5    Q97.5\n[1,] 5.939461 0.7104193 4.648686 7.423907\n[2,] 4.519774 0.5232029 3.604023 5.638578\n```\n\n\n:::\n:::\n\n\n::: {.callout-caution collapse=\"true\" title=\"予測の出力\"}\n\n従って，もう１度ずつ実行すると，`predict`では値が変わるが，`fitted`では同じ値が出力される．\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(fit1, newdata = newdata, re_formula = NA)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Estimate Est.Error Q2.5 Q97.5\n[1,]  5.93175  2.544250    2    11\n[2,]  4.48125  2.199286    1     9\n```\n\n\n:::\n\n```{.r .cell-code}\nfitted(fit1, newdata = newdata, re_formula = NA)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Estimate Est.Error     Q2.5    Q97.5\n[1,] 5.939461 0.7104193 4.648686 7.423907\n[2,] 4.519774 0.5232029 3.604023 5.638578\n```\n\n\n:::\n:::\n\n\n:::\n\n### モデルの比較 {#sec-model-comparison}\n\nモデル`fit1`で行った Poisson 回帰分析は，個々の観測が独立であるという仮定の上に成り立っている（第 [-@sec-ubsubsec-covariance-structure] 節）．\n\nこの仮定が破れているとき，Poisson 分布の性質\n$$\n\\E[X]=\\V[X]=\\lambda\\qquad (X\\sim\\Pois(\\lambda))\n$$\nからの離反として現れ，この現象は **過分散**（overdispersion）とも呼ばれる．\n\n#### 観測レベルランダム効果\n\nということで，Poisson 分布族ではなく，分散が平均よりも大きいような別の分布族を用いて，フィット度合いを比較してみることを考えたい．\n\nそこで，追加の変動をモデルに追加するべく，モデル`fit1`に観測ごとの切片項 $\\eta_{it}$ を追加してみる（この手法は観測レベルランダム効果と呼ばれる．第 [-@sec-subsec-count-data] 節参照）．\n\n```r\nfit2 <- brm(count ~ zAge + zBase * Trt + (1|patient) + (1|obs),\n            data = epilepsy, family = poisson())\n```\n\n::: {.callout-caution collapse=\"true\" title=\"フィッティングの出力\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2 <- brm(count ~ zAge + zBase * Trt + (1|patient) + (1|obs),\n            data = epilepsy, family = poisson())\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nStart sampling\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 7.3e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.73 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 1.976 seconds (Warm-up)\nChain 1:                1.156 seconds (Sampling)\nChain 1:                3.132 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 1.8e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 2.089 seconds (Warm-up)\nChain 2:                1.839 seconds (Sampling)\nChain 2:                3.928 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 1.8e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 1.888 seconds (Warm-up)\nChain 3:                1.158 seconds (Sampling)\nChain 3:                3.046 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 2.3e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 1.96 seconds (Warm-up)\nChain 4:                1.613 seconds (Sampling)\nChain 4:                3.573 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n\n:::\n\nこうして得た２つのモデル`fit1`,`fit2`を比較する．\n\nLLO (Leave-One-Out) cross-validation が関数`loo`によって実行できる：\n\n```r\nloo(fit1, fit2)\n```\n\n::: {.callout-caution collapse=\"true\" title=\"LOO-CV の結果\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloo(fit1, fit2)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Found 6 observations with a pareto_k > 0.7 in model 'fit1'. We\nrecommend to set 'moment_match = TRUE' in order to perform moment matching for\nproblematic observations.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Found 55 observations with a pareto_k > 0.7 in model 'fit2'. We\nrecommend to set 'moment_match = TRUE' in order to perform moment matching for\nproblematic observations.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOutput of model 'fit1':\n\nComputed from 4000 by 236 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -673.3 37.4\np_loo        96.0 15.4\nlooic      1346.6 74.8\n------\nMCSE of elpd_loo is NA.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.4, 2.3]).\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     230   97.5%   144     \n   (0.7, 1]   (bad)        4    1.7%   <NA>    \n   (1, Inf)   (very bad)   2    0.8%   <NA>    \nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'fit2':\n\nComputed from 4000 by 236 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -595.0 14.0\np_loo       107.7  7.1\nlooic      1190.1 27.9\n------\nMCSE of elpd_loo is NA.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.4, 1.6]).\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     181   76.7%   65      \n   (0.7, 1]   (bad)       50   21.2%   <NA>    \n   (1, Inf)   (very bad)   5    2.1%   <NA>    \nSee help('pareto-k-diagnostic') for details.\n\nModel comparisons:\n     elpd_diff se_diff\nfit2   0.0       0.0  \nfit1 -78.3      27.9  \n```\n\n\n:::\n:::\n\n\n:::\n\n`elpd_diff` は expected log posterior density の差異を表す．`fit2`の方が大きく当てはまりが良いことが見て取れる．\n\nまた，WAIC (Watanabe-Akaike Information Criterion) も実装されている：\n\n```r\nprint(waic(fit1))\n```\n\n::: {.callout-caution collapse=\"true\" title=\"WAIC の結果\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(waic(fit1))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: \n52 (22.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nComputed from 4000 by 236 log-likelihood matrix.\n\n          Estimate   SE\nelpd_waic   -668.5 36.5\np_waic        91.2 14.5\nwaic        1337.0 73.1\n\n52 (22.0%) p_waic estimates greater than 0.4. We recommend trying loo instead. \n```\n\n\n:::\n\n```{.r .cell-code}\nprint(waic(fit2))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: \n64 (27.1%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nComputed from 4000 by 236 log-likelihood matrix.\n\n          Estimate   SE\nelpd_waic   -572.5 12.0\np_waic        85.1  5.2\nwaic        1144.9 24.1\n\n64 (27.1%) p_waic estimates greater than 0.4. We recommend trying loo instead. \n```\n\n\n:::\n:::\n\n\n:::\n\n他にも，`reloo`, `kfold` などの関数もある．\n\n::: {.callout-caution collapse=\"true\" title=\"他の関数一覧\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmethods(class=\"brmsfit\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] add_criterion           add_ic                  as_draws_array         \n [4] as_draws_df             as_draws_list           as_draws_matrix        \n [7] as_draws_rvars          as_draws                as.array               \n[10] as.data.frame           as.matrix               as.mcmc                \n[13] autocor                 bayes_factor            bayes_R2               \n[16] bridge_sampler          coef                    conditional_effects    \n[19] conditional_smooths     control_params          default_prior          \n[22] expose_functions        family                  fitted                 \n[25] fixef                   formula                 getCall                \n[28] hypothesis              kfold                   log_lik                \n[31] log_posterior           logLik                  loo_compare            \n[34] loo_linpred             loo_model_weights       loo_moment_match       \n[37] loo_predict             loo_predictive_interval loo_R2                 \n[40] loo_subsample           loo                     LOO                    \n[43] marginal_effects        marginal_smooths        mcmc_plot              \n[46] model_weights           model.frame             nchains                \n[49] ndraws                  neff_ratio              ngrps                  \n[52] niterations             nobs                    nsamples               \n[55] nuts_params             nvariables              pairs                  \n[58] parnames                plot                    post_prob              \n[61] posterior_average       posterior_epred         posterior_interval     \n[64] posterior_linpred       posterior_predict       posterior_samples      \n[67] posterior_smooths       posterior_summary       pp_average             \n[70] pp_check                pp_mixture              predict                \n[73] predictive_error        predictive_interval     prepare_predictions    \n[76] print                   prior_draws             prior_summary          \n[79] psis                    ranef                   reloo                  \n[82] residuals               restructure             rhat                   \n[85] stancode                standata                stanplot               \n[88] summary                 update                  VarCorr                \n[91] variables               vcov                    waic                   \n[94] WAIC                   \nsee '?methods' for accessing help and source code\n```\n\n\n:::\n:::\n\n\n:::\n\n#### 患者内の相関構造のモデリング\n\nまた，`fit1`において，同一患者の異なる訪問の間には全く相関がないと仮定されており，これは全く非現実的な仮定をおいてしまっていると言える．\n\n患者間の相関構造は，`brm()`関数の`autocor`引数で指定できる（第 [-@sec-autocor-argument] 節）．\n\n例えば，全く構造を仮定しない場合は，[`unstr`](http://paul-buerkner.github.io/brms/reference/unstr.html)を指定する：\n\n```r\nfit3 <- brm(count ~ zAge + zBase * Trt + (1|patient),\n            autocor = ~unstr(time=visit, gr=patient),\n            data = epilepsy, family = poisson())\n```\n\n::: {.callout-caution collapse=\"true\" title=\"フィッティングの出力\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit3 <- brm(count ~ zAge + zBase * Trt + (1|patient),\n            autocor = ~unstr(time=visit, gr=patient),\n            data = epilepsy, family = poisson())\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Argument 'autocor' should be specified within the 'formula' argument.\nSee ?brmsformula for help.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nStart sampling\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.000117 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.17 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 4.071 seconds (Warm-up)\nChain 1:                2.597 seconds (Sampling)\nChain 1:                6.668 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 3.4e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.34 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 3.856 seconds (Warm-up)\nChain 2:                2.163 seconds (Sampling)\nChain 2:                6.019 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 3.4e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.34 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 3.833 seconds (Warm-up)\nChain 3:                2.182 seconds (Sampling)\nChain 3:                6.015 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 6.8e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.68 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 3.859 seconds (Warm-up)\nChain 4:                2.367 seconds (Sampling)\nChain 4:                6.226 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n\n:::\n\nこのモデルも`fit1`より遥かに当てはまりが良く，`fit2`とほとんど同じ当てはまりの良さが見られる：\n\n::: {.callout-caution collapse=\"true\" title=\"LOO-CV の結果\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloo(fit2,fit3)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Found 55 observations with a pareto_k > 0.7 in model 'fit2'. We\nrecommend to set 'moment_match = TRUE' in order to perform moment matching for\nproblematic observations.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Found 64 observations with a pareto_k > 0.7 in model 'fit3'. We\nrecommend to set 'moment_match = TRUE' in order to perform moment matching for\nproblematic observations.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOutput of model 'fit2':\n\nComputed from 4000 by 236 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -595.0 14.0\np_loo       107.7  7.1\nlooic      1190.1 27.9\n------\nMCSE of elpd_loo is NA.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.4, 1.6]).\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     181   76.7%   65      \n   (0.7, 1]   (bad)       50   21.2%   <NA>    \n   (1, Inf)   (very bad)   5    2.1%   <NA>    \nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'fit3':\n\nComputed from 4000 by 236 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -602.5 15.0\np_loo       113.4  8.1\nlooic      1204.9 30.0\n------\nMCSE of elpd_loo is NA.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.4, 1.5]).\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     172   72.9%   122     \n   (0.7, 1]   (bad)       56   23.7%   <NA>    \n   (1, Inf)   (very bad)   8    3.4%   <NA>    \nSee help('pareto-k-diagnostic') for details.\n\nModel comparisons:\n     elpd_diff se_diff\nfit2  0.0       0.0   \nfit3 -7.4       2.6   \n```\n\n\n:::\n:::\n\n\n:::\n\n### その他の例\n\nSebastian Weber らにより，[新薬の治験における実際の解析事例をまとめたウェブサイト](https://opensource.nibr.com/bamdd/) が公開されている．^[Statistical Modeling, Causal Inference, and Social Science における [こちらのエントリ](https://statmodeling.stat.columbia.edu/2024/05/08/bamdd/) も参照．]\n\n## 混合効果モデルに関する補足\n\n::: {.callout-important appearance=\"simple\" icon=\"false\" title=\"概要\"}\n\n* ランダム効果モデルとは，グループ毎に異なる切片項 $\\al_{s[i]}$ を追加し，これにも誤差を仮定してモデルに入れて得る階層モデルである．\n* しかし，$\\al_{s[i]}$ が（ユニットレベルの）説明変数 $x_i$ と相関を持つ場合，推定量の一致性が失われる．これを回避するために，$x_i$ の係数 $\\beta$ にのみ関心がある場合は，固定効果モデルが用いられることも多い．\n* だが，簡単なトリック（$\\al_{s[i]}$ の説明変数に $\\ov{x}_s$ を追加すること）で，推定量の一致性を回復することができる．\n* このトリックを取り入れたランダム効果モデルは，$x_i$ と $\\al_{s[i]}$ に相関がない場合は固定効果モデルと等価な $\\beta$ の推定量を与え，相関がある場合でも，$\\beta$ を一致推定し，各変動切片項 $\\al_{s[i]}$ の構造にも洞察を与えてくれる．\n\n:::\n\n### ランダム効果のモデル\n\nランダム効果は，変動する切片項と呼んだ方がわかりやすい [@Bafumi-Gelman2007] と言われるように，サブグループ毎に異なる切片を加えたモデルである．\n\n従って，ユニットレベルの回帰式を書き下すと，グループ選択関数 $s:[n]\\to[S]\\;(S\\le n)$ を通じて，\n$$\ny_i=\\al_{s[i]}+\\beta x_i+\\ep_i,\\qquad i\\in[n],\n$$ {#eq-stage-1}\nというようになる．\n\nこれは，確率変数 $\\al_{s[i]}$ の平均を $\\al_0$ とすると，グループレベルの回帰式\n$$\n\\al_s=\\al_0+\\eta_s,\\qquad s\\in[S]\n$$ {#eq-stage-2}\nが背後にある階層モデルだとみなすこともできる．\n\n### 説明変数との相関の問題\n\n#### 問題の所在\n\nランダム効果では，ユニットレベルの説明変数 $x_i$ と変動切片項 $\\al_{s[i]}$ が相関を持たないという仮定が Gauss-Markov の定理の仮定に等価になるため，これが違反されると推定量の不偏性・一致性が約束されず，推定量の分散も大きくなる．^[[@Hansen2022 p.333] 第12.3節，[@Bafumi-Gelman2007 p.3], [@Hansen2022 p.604]，[@Gardiner+2009 p.228]．]\n\n実際，ランダム効果モデルの階層構造を，@eq-stage-2 を @eq-stage-1 に代入することで一つの式にまとめると\n$$\ny_i=\\al_0+\\beta x_i+\\underbrace{\\ep_i'}_{\\ep_i+\\eta_{s[i]}}\n$$ {#eq-RF}\nを得る．^[このような誤差項の構造 $e_{it}=u_i+\\ep_{it}$ を一元誤差成分モデル (one-way error component model) ともいう [@Hansen2022 p.600]．] $x_i$ と $\\al_{s[i]}$ の相関をモデルに含めていない場合，$x_i$ と $\\eta_s$ が相関を持ってしまい，結果として @eq-RF では説明変数と誤差 $\\ep_i'$ に相関が生じてしまう．^[この，説明変数と誤差の間に相関があることを，計量経済学では **内生性** (endogeneity) という．]\n\n#### 業界の現状\n\nそのため，ランダム効果モデルは避けられる傾向にあり，切片項 $\\al_{s[i]}\\equiv\\al_0$ は変動しないとし，グループレベルの効果を無視してモデリングすることも多い：\n$$\ny_i=\\al_0+\\beta x_i+\\ep_i.\n$$\nこのことを complete pooling model と呼び，ランダム効果モデルを partial pooling model と対比させることがある．^[[@Bafumi-Gelman2007 p.5]．]\n\n実際，これ以上の仮定を置かず，ランダム効果は局外母数として一般化推定方程式の方法（第 [-@sec-GEE] 節）によれば，$\\beta$ の不偏推定が可能である．\n\nリンク関数 $g$ を通じた非線型モデル\n$$\ng(\\E[y_i|x_i])=\\beta x_i\n$$\nであっても，指数型分布族を仮定すれば，$\\beta$ の一致推定が可能である．\n\nこのような場合は，marginal model や population-average model とも呼ばれる [@Gardiner+2009 p.228]．\n\n#### 固定効果モデルという解決 {#sec-fixed-effects-model}\n\n問題を起こさずに，しかしながらグループレベルの効果をモデリングしたい場合，\n$$\ny_i=\\al_{s[i]}^{\\text{unmodeled}}+\\beta x_i+\\ep_i\n$$\n$$\n\\al_s^{\\text{unmodeled}}\\sim\\rN(\\al_0,\\infty)\n$$\nとして，グループ毎に変動する切片項 $\\al_{s[i]}^{\\text{unmodeled}}$ を許すが，この変数自体にモデルは仮定しない．\n\nこのようなモデルは，グループ毎に別々の回帰分析を実行し，$\\beta$ の値はこれらのグループの間で適切に重みづけて最終的な推定値としているに等しい．\n\nすなわち，グループの数だけ，グループへの所属を表す２値変数 $1_{s[i]=s}$ を導入し，$S$ 個の項 $\\sum_{s=1}^S1_{s[i]=s}\\al_{s[i]}^{\\text{unmodeled}}$ を説明変数に加えて回帰分析を行うことに等しい．\n\n::: {.callout-caution title=\"名前\" icon=\"false\" appearance=\"simple\"}\n\n* [@Bafumi-Gelman2007] は unmodeled varying intercept と呼んでいる．\n* [@Hansen2022] をはじめ，計量経済学では fixed effects model と呼ばれる．\n* least squares dummy variable regression とも呼べる．^[[@Bafumi-Gelman2007 p.5]，[@Hansen2022 p.609] 17.11節 など．狭義では，fixed effects model は within transformation を行い，グループ間の影響を引いたあとに回帰を実行する……という手続きを指すこともあるが，２つは等価な結果を生む．詳しくは [@Cunningham21-Mixtape] なども参照．]\n\n:::\n\n::: {.callout-caution title=\"利点\" icon=\"false\" appearance=\"simple\"}\n\n$x_i$ と $\\al_{s[i]}$ が相関を持ち得る場合も，固定効果モデルでは関係がない．^[[@Hansen2022 p.624] 17.25節．]\n\n:::\n\n::: {.callout-caution title=\"問題点\" icon=\"false\" appearance=\"simple\"}\n\n異なるグループのデータが相互作用する機構がランダム効果モデルに比べて貧しい．\n\n（正しく特定された）ランダム効果モデルの方は，外れ値グループが存在しても，$\\eta_s$ を通じて緩やかに情報が伝達され，$\\beta$ の値は平均へ縮小されて推定されるが，固定効果モデルではそのような頑健性を持たない．^[[@Bafumi-Gelman2007 pp.4-5]．]\n\n:::\n\n固定効果モデルは $\\beta$ （のみ）に関心がある場合，$\\al_{s[i]}$ と $x_i$ の相関の存在に対してロバストな推定法として有用であり，その理由で計量経済学（特に線型パネルデータ）では主流の推定手法となっている．^[[@Hansen2022 p.624]，[@Bafumi-Gelman2007 p.6]．] 実際，$\\al_{s[i]}$ と $x_i$ が無相関であるとき，$\\beta$ に関しては等価な推定量を与える．\n\n> Current econometric practice is to prefer robustness over efficiency. Consequently, current practice is (nearly uniformly) to use the fixed effects estmimator for linear panel data models. [@Hansen2022 p.624]\n\n逆に言えば，固定効果モデルは $x_i$ と $\\al_{s[i]}$ の構造のモデリングを放棄したモデリング法であり，各 $\\al_{s[i]}$ の値にも興味がある場合，および $\\beta$ のグループ毎の値も考えたい場合にはやはり $\\al_{s[i]}$ の誤差と相関構造もモデルに取り入れたランダム効果モデルを用いたい，ということになる．\n\n### ランダム効果モデルにおける相関のモデリング\n\n$x_i$ と $\\al_{s[i]}$ との相関は，欠落変数が存在するため，と考えることができる．\n\nそして，この相関は，説明変数の平均 $\\ov{x}_s$ を変動する切片項 $\\al_s$ の説明変数として追加することで除去できる：^[[@Bafumi-Gelman2007 p.6]．]\n\n$$\ny_i=\\al_{s[i]}+\\beta x_i+\\ep_i\n$$\n$$\n\\al_s=\\al_0+\\al_1\\ov{x}_s+\\eta_s\n$$\n\nこれにより，Gauss-Markov の仮定（外生性）が回復される．\n\n[@Bafumi-Gelman2007 pp.7-9] にシミュレーションによる検証が掲載されている．\n\n> Practitioners can get around this problem by taking advantage of the multilevel structure of their regression equation. [@Bafumi-Gelman2007 p.12]\n\n### 混合効果モデル\n\n以上，解説してきた「ランダム効果モデル」であるが，混合効果モデルとも呼ばれる．^[[@Hubbard+2010] では両方の名前で呼んでいる．]\n\n何を言っているのかわからないかもしれないが，式 @eq-stage-1 \n$$\ny_i=\\al_{s[i]}+\\beta x_i+\\ep_i,\\qquad i\\in[n],\n$$\nにおいて，$\\al_{s[i]}$ がランダム効果であるが，回帰係数 $\\beta$ を固定効果とも呼ぶのである．\n\n現代的には，必要ならば $\\beta$ を確率変数とみなしても良いだろうが，慣習的にそう呼ぶため，これに従わざるを得ない，というのが [@Hansen2022 p.625] などを見る限り共通了解であるようである．\n\nこれが計量経済学における固定効果モデル（第 [-@sec-fixed-effects-model] 節）の名前の由来である．^[[@Hansen2022 p.625] 17.25節．疫学・生物統計学では，実験計画法でしか「固定効果」「変量効果モデル」とは言わない，という認識であることも筆者は聞いたことがある．] 固定効果モデルは，たしかに（ユニットレベルでの回帰係数という意味での）「固定効果」を表す変数しか含んでいない（少なくとも見た目上は）．\n\nそこで，式 @eq-stage-1 自体は，固定効果と変量効果の両方を含んだ **混合（効果）モデル** というのである．\n\n::: {.callout-caution title=\"名前\" icon=\"false\" appearance=\"simple\"}\n\n[@Chung+2013] によると\n\n* 線型混合モデル (linear mixed models) [@Kincaid2005]\n* 階層モデル (hierarchical models)\n* マルチレベル線型モデル (multilevel linear models)\n* 混合効果モデル (mixed-effects models) [@Chung+2015]\n* ランダム効果モデル (random effects model) [@Hubbard+2010] （え？）\n* 分散成分モデル (variance component model)^[$\\V[\\eta_s]$ はブロック行列の構造を持つためこう呼ばれるs．]\n\nなどと呼ばれる．\n\nただし，ランダム効果モデルと呼んでしまうことも多い．[@Bafumi-Gelman2007] のアブストラクトなど．\n\n:::\n\n#### GEE との違い {#sec-GEE}\n\n::: {.callout-caution title=\"一般化推定方程式 (GEE: Generalized Estimating Equation) との違い\" icon=\"false\"}\n\n1. [回帰式が違う]{.underline}\n\n      線型の場合の GEE は\n      $$\n      Y_{it}=\\al+\\beta_1x_{1,i,t}+\\cdots+\\beta_px_{p,i,t}\n      $$\n      とも表され，ランダムな切片項というものは見当たらない．その代わり，グループ間の影響は相関係数行列としてモデル化を行う．ランダム効果モデルでは，この相関構造を，ランダムな切片項を追加し，その回帰式も立てることでモデルに取り込む．\n\n2. [推定目標が違う]{.underline}\n\n      GEE は population average model でよく用いられる [@Hubbard+2010] ように，あくまで応答 $Y_{it}$ の平均の不偏推定が目標であり，共分散構造はいわば局外母数である．一方，混合効果モデルは，その階層モデルとしての性質の通り，平均構造と分散構造のいずれも推定対象として扱う志向性がある．\n\n3. [推定方法が違う]{.underline}\n\n      混合効果モデルは主に最尤法により推定される [@Hubbard+2010]．GEE はモーメント法により推定され，最尤法ベースではないため，完全にランダムとは言えない欠測がある場合は弱く，IPW などの方法が用いられる．\n\n:::\n\nGEE にとって相関構造は局外母数であり，正確な特定は目的に含まれない．この意味で GEE の相関係数⾏列におく仮定は「間違えていてもよい便宜的な仮定」であるため，作業相関係数行列 (working correlation coefficient matrix) とも呼ばれる．相関構造を誤特定していても，平均構造は一致推定が可能であり，ロバストである．両方の特定に成功した場合はセミパラメトリック有効性が達成される．\n\n一方で，混合効果モデルは，階層モデルとして，平均構造と分散構造のいずれにも明示的な仮定をおくため，片方（例えば共分散構造）の特定を間違えていた場合，もう片方の解釈性が失われる，というリスクがあると論じることができる．特に [@Hubbard+2010] に見られる論調である．\n\nしかし，子供の身長の成長曲線の描画が主な研究目標である場合など，ユニットの平均効果ではなく各個人に注目したい場合には，（特に変動係数を取り入れた）混合効果モデルの方が適していることになる [@Gardiner+2009]．実際，モデルの特定に成功していれば，いずれのパラメータも最尤推定されるため，一致性を持つ．\n\n従って，モデル選択において用いられる基準も違う．GEE における作業相関係数行列と説明変数の選択には QIC (Quasi-likelihood Information Criterion) が，混合効果モデルには AIC や BIC （または cAIC や mAIC [@Vaida-Blanchard2005]）が用いられる [@Gardiner+2009 p.228]．\n\n<!--\n\n本データを扱った論文 [@Thall-Vail1990] では，[@Liang-Zeger1986] の一般化推定方程式の枠組みに則り，共分散の構造にどのようなパラメトリック分布を仮定するのが良いかが，漸近論の観点から議論されている．\n\n-->\n\n#### ベイズ混合効果モデルという光……？\n\nしかし，結局ベイズ統計学の立場からは，２つの違いはほとんど重要ではなく，混合効果モデルを推定した後に，周辺化をして平均構造に関する marginal estimator を構成すれば，GEE の代用になっているのではないか？\n\n計算機の性能と，計算統計手法の発展が目まぐるしい現代にて，過去の議論を踏襲しすぎることは，問題の本質を誤るということもあるのだろう．\n\nということで，以上議論したグループレベル構造を持ったデータに対する２階の階層モデルを，本稿では「混合効果モデル」と呼ぶことにする．\n\nこの節はこれで終わり．\n\n### グループレベル分散の推定 {#sec-group-level-variance-estimation}\n\n混合効果モデル（階層モデル）の推定において，特にグループ数 $S$ が小さい場合，グループレベルの変動切片項 $\\al_{s[i]}$ の共分散行列 $\\V[\\eta_s]$ の推定が不安定になるという問題点が古くからの問題である [@Harville1977]．^[[@Laird-Ware1982]，[@Chung+2013]，[@Chung+2015]，[Statistical Modeling, Causal Inference, and Social Science ブログ 6/2/2023](https://statmodeling.stat.columbia.edu/2023/06/02/blme-bayesian-linear-mixed-effects-models/)．]\n\nこの $\\V[\\eta_s]$ は何の仮定も置かれておらず，グループ間の相関構造のモデリングを一手に引き受けている．EM アルゴリズムが提案されたばかりの頃 [@Laird-Ware1982] では，共分散構造にパラメトリックな仮定をおいていたが，現代ではこれを取り去った最尤推定法・ベイズ推定法が主流である．\n\nしかし，最尤推定法と，一定の事前分布を仮定したベイズ MAP 推定法では，推定された共分散行列が退化してしまうことがある．これは Wishart 事前分布を仮定することでこれが回避される [@Chung+2015]．^[逆 Wishart ではないらしい [@Chung+2015]．] これは最尤法の文脈では，penalized likelihood と等価になる [@Chung+2013]．\n\nモデルのサイズによっては，完全なベイズ推定を実行することが難しく，一部は等価な頻度論的な方法や近似を用いることもある．その際，最適化ソルバーの収束を速めるために，共分散構造に（データや計画とは無関係に）パラメトリックモデルを仮定してしまうこともある [@Kincaid2005]．\n\n### カウントデータのモデリング {#sec-subsec-count-data}\n\nカウントデータの基本は Poisson 分布であろうが，過分散を考慮するために，負の二項分布でモデリングすることもできる．これは例えば，マーケティングにおいて，顧客の購買回数をモデル化する際に用いられる [@森岡-今西16-確率思考の戦略論]．\n\nこの行為は，Poisson 分布の Gamma 分布による混合分布族を用いた，混合モデリングを行っているとみなせる：\n\n::: {.callout-tip title=\"命題\" icon=\"false\"}\n\nPoisson 分布 $\\Pois(\\theta)$ の $\\GAMMA(\\al,\\nu)$-混合は負の二項分布 $\\NB\\paren{\\nu,\\frac{\\al}{\\al+1}}$ になる．\n\nただし，負の二項分布 $\\NB(\\nu,p)$ は，次の確率質量関数 $p(x;\\nu,p)$ が定める $\\N$ 上の確率分布である：\n$$\np(x;\\nu,p)=\\comb{x+\\nu-1}{x}p^\\nu(1-p)^x.\n$$\n\n:::\n\n::: {.callout-note title=\"証明\" collapse=\"true\" icon=\"false\"}\n\n確率分布の変換則より，次のように計算できる：\n\n\\begin{align*}\n  p(x)&=\\int_{\\R_+}\\frac{\\theta^x}{x!}e^{-\\theta}\\frac{1}{\\Gamma(\\nu)}\\al^\\nu\\theta^{\\nu-1}e^{-\\al\\theta}d\\theta\\\\\n  &=\\frac{\\al^\\nu}{x!\\Gamma(\\nu)}\\int_{\\R_+}\\theta^{x+\\nu-1}e^{-(\\al+1)\\theta}d\\theta\\\\\n  &=\\frac{\\al^\\nu}{x!\\Gamma(\\nu)}\\frac{\\Gamma(x+\\nu)}{(\\al+1)^{x+\\nu}}\\\\\n  &=\\comb{\\nu+x-1}{x}\\paren{\\frac{1}{\\al+1}}^x\\paren{\\frac{\\al}{\\al+1}}^\\nu.\n\\end{align*}\n\nこの最右辺は，たしかに負の二項分布の質量関数である．\n\nこの証明方法と，Gamma 分布については次の記事を参照：\n\n\n```{=html}\n<div class=\"article-card-container\">\n  <div class=\"article-card\">\n    <a href=\"https://162348.github.io/posts/2023/Probability/Beta-Gamma.html\" target=\"_blank\">\n      <img src=\"https://162348.github.io/posts/2023/Probability/Beta-Gamma_files/figure-html/cell-4-output-1.png\" alt=\"Article Image\" class=\"article-image\">\n      <div class=\"article-content\">\n        <h3 class=\"article-title\">確率測度の変換則</h3>\n        <p class=\"article-description\">Gamma 分布とBeta 分布を例に</p>\n      </div>\n    </a>\n  </div>\n</div>\n```\n\n\n:::\n\nPoisson 回帰\n\n$$\n\\begin{align*} y_{it} & \\sim \\operatorname{Pois}(\\lambda_{s[i]}) \\\\ \\log(\\lambda_{s[i]}) & = u_i + \\eta_{it} \\\\ \\eta_{it} & \\sim \\operatorname{N}(0, \\sigma). \\end{align*}\n$$\n\nを考えると，各 $y_{it}$ を，（グループ毎に条件付ければ）Poisson 分布の対数正規分布による混合分布を用いてモデル化していることにあたる．\n\nこの，Poisson-対数正規分布族は，[@Bulmer1974] により生物種の個体数分布のモデリングで，過分散を説明するために用いられている．\n\nすなわち，第 [-@sec-example] 節のモデルの比較 [-@sec-model-comparison] で扱った，**観測レベルランダム効果** (OLRE: Observation-level Random Effects) の方法は，観測毎に $\\eta_{it}$ というランダム切片項を追加するだけで，本質的には混合モデリングを実施するという，いわばハックのような使い方である．^[[Solomon Kurtz (2021)](https://solomonkurz.netlify.app/blog/2021-07-12-got-overdispersion-try-observation-level-random-effects-with-the-poisson-lognormal-mixture/#negative-binomial-counts) による解説，[RPubs](https://rpubs.com/INBOstats/OLRE) も参照．]\n\n今回はモデル比較の結果が良かったため，本格的に対数正規混合を実施してみるのも良いかもしれない．\n\n## `brms`の実装\n\n[`brm` 関数](https://paul-buerkner.github.io/brms/reference/brm.html)（コードは [こちら](https://github.com/paul-buerkner/brms/blob/master/R/brm.R)）の実装を調べる．\n\n::: {.callout-important appearance=\"simple\" icon=\"false\"}\n\n* [`brms`](https://github.com/paul-buerkner/brms/blob/master/R/brm.R#L436)\n\nStan コードを扱っている関数は [`.stancode()`](https://github.com/paul-buerkner/brms/blob/d42adcd22f5af441870038b1d78ad4d9408f344f/R/stancode.R) であった．最終的に，[`.compile_model_rstan()`](https://github.com/paul-buerkner/brms/blob/d42adcd22f5af441870038b1d78ad4d9408f344f/R/backends.R#L67) と [`.fit_model_rstan()`](https://github.com/paul-buerkner/brms/blob/d42adcd22f5af441870038b1d78ad4d9408f344f/R/backends.R#L145) が呼ばれるようになっている．\n\n* [`.standata`](https://github.com/paul-buerkner/brms/blob/d42adcd22f5af441870038b1d78ad4d9408f344f/R/standata.R#L109)\n\n:::\n\n### モデリング機能\n\n#### 事前分布\n\n[`brm`関数](https://paul-buerkner.github.io/brms/reference/brm.html) では，デフォルトでは無情報事前分布が用いられる．\n\n> Default priors are chosen to be non or very weakly informative so that their influence on the results will be negligible and you usually don't have to worry about them. However, after getting more familiar with Bayesian statistics, I recommend you to start thinking about reasonable informative priors for your model parameters: Nearly always, there is at least some prior information available that can be used to improve your inference.<br>[brm(): Fit Bayesian Generalized (Non-)Linear Multivariate Multilevel Models](https://paul-buerkner.github.io/brms/reference/brm.html)\n\n#### 回帰式\n\n`brm()`関数の第一引数は`brmsformula`オブジェクトを取る．\n\n[`brmsformula()`関数](http://paul-buerkner.github.io/brms/reference/brmsformula.html) は，R の`formula`オブジェクトを通じて，階層モデルを定義できるようになっている（実装は[リスト](R3.qmd)）．\n\n#### 共分散構造 {#sec-ubsubsec-covariance-structure}\n\n共分散構造は２つの観点から，`brmsformula`オブジェクトから自動的に指定される．\n\n１つ目がグルーピング構造（共分散行列のブロック構造）であり，これは[`gr`関数](https://paul-buerkner.github.io/brms/reference/gr.html) が使用される．２つ目がグループ内の相関構造であり，これは`brm()`関数の`autocor`引数を用いる．\n\n##### `gr`関数\n\nこの関数は`brm`関数の第一引数として与えられたモデル定義式から，暗黙のうちに内部で呼び出される．\n\n例えば，回帰式に`(1|patient)`が含まれていた場合，`gr(patient)`が呼び出される．\n\n共分散構造におく仮定について，重要なデフォルト設定が２つある：\n\n::: {.callout-tip appearance=\"simple\" icon=\"false\"}\n* グループ間の相関構造は想定されている：`cor=True`．\n* 一方で，グループ内の相関構造は想定されておらず，独立とされている．具体的に指定したい場合は引数`cov`を用いる．\n\n    > By default, levels of the same grouping factor are modeled as independent of each other.<br>[gr(): Set up basic grouping terms in brms](https://paul-buerkner.github.io/brms/reference/gr.html)\n\nすなわち，$\\V[\\eta_s]$ には一才仮定が置かれておらず（第 [-@sec-group-level-variance-estimation] 節），一方で $\\{\\ep_{it}\\}_{t=1}^T$ は互いに独立とされている．\n:::\n\nまた，この二階層目の分布族（第 [-@sec-example] 節での $u_i$ と $\\eta_{it}$）は，分散共分散行列 $\\V[\\eta_s]$ を持った正規分布がデフォルトで，現状他の分布族は指定できないでいる．\n\n> dist: Name of the distribution of the group-level effects. Currently \"gaussian\" is the only option.<br>[gr(): Set up basic grouping terms in brms](https://paul-buerkner.github.io/brms/reference/gr.html)\n\n##### `autocor`引数 {#sec-autocor-argument}\n\n`brm()`関数には，[`autocor`引数](http://paul-buerkner.github.io/brms/reference/autocor-terms.html) が用意されている．\n\n`gr()`のデフォルト値では独立とされていたグループ内の相関構造を，具体的に指定するのに用いられる．\n\n::: {.callout-tip appearance=\"simple\" icon=\"false\"}\n* `unstr`：一才の仮定を置かない．\n* `AR`：一次の自己相関構造．\n:::\n\n### モデリング実装\n\n#### 回帰式\n\n`brm`関数に与えられた`formula`は，`validate_formula`関数に渡される．\n\nこの関数は S3 のメソッドのディスパッチを用いて実装されており，`brmsformula`オブジェクトに対しては，`validate_formula.brmsformula`関数が呼び出される．\n\nここでは`autocor`引数が引かれている場合，出力の`formula`属性に追加される：^[[Line 1363](https://github.com/paul-buerkner/brms/blob/deb56d02d0f897422a4d1d5a43d18e99400f80a0/R/brmsformula.R#L1363)．]\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit3$formula\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ncount ~ zAge + zBase * Trt + (1 | patient) \nautocor ~ unstr(time = visit, gr = patient)\n```\n\n\n:::\n:::\n\n\n\n### 推論エンジン\n\n[`brm`関数](https://paul-buerkner.github.io/brms/reference/brm.html) は，Stan による MCMC サンプリングを通じて，事後分布を計算する．",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}