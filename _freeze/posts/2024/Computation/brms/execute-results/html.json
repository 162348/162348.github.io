{
  "hash": "ca82895503a6d254117d2961955975d2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"`brms` によるベイズ混合モデリング入門\"\nsubtitle: \"ポアソン混合効果モデルを例に\"\nauthor: \"司馬博文\"\ndate: 5/12/2024\ndate-modified: 12/13/2024\ncategories: [Bayesian, MCMC, R, Stan, Statistics]\nimage: ./brms_files/figure-html/unnamed-chunk-4-1.png\nbibliography: \n    - ../../../assets/mathematics.bib\n    - ../../../assets/bib.bib\n    - ../../../assets/bib1.bib\ncsl: ../../../assets/apalike.csl\nabstract-title: 概要\nabstract: |\n  `brms` はベイズ階層モデリングを，確率的プログラミング言語 Stan をエンジンとして行うための R パッケージである．本稿では，`brms` の基本的な使い方と，その実装を紹介する．\n  \n  また，ランダム効果モデルとは何であるか，固定効果モデル・混合効果モデル・一般化推定方程式などとの違いをレビューする．ランダム効果の追加は縮小推定などの自動的な正則化を可能とする美点がある一方で，係数の不偏推定やロバスト推定に拘る場合はこれを避ける判断もあり得る．\nformat:\n  html:\n    code-fold: false\nexecute:\n  cache: true\nlisting: \n    -   id: lst-brms\n        type: grid\n        sort: false\n        contents:\n            - \"../Survey/BayesRegression.qmd\"\n            - \"../Survey/BayesGLM.qmd\"\n            - \"../TransDimensionalModels/BayesSelection.qmd\"\n        date-format: iso\n        fields: [title,image,date,subtitle]\n    -   id: lst-embed\n        type: grid\n        sort: false\n        contents:\n            - \"../Lifestyle/FixedRandom.qmd\"\n        date-format: iso\n        fields: [title,image,date,subtitle]\n---\n\n\n::: {.hidden}\n\n::: {.content-visible when-format=\"html\"}\n\nA Blog Entry on Bayesian Computation by an Applied Mathematician\n\n$$\n\n\\renewcommand{\\P}{\\operatorname{P}}\\newcommand{\\E}{\\operatorname{E}}\n\\newcommand{\\R}{\\mathbb{R}}\\newcommand{\\F}{\\mathcal{F}}\n\\newcommand{\\abs}[1]{\\lvert#1\\rvert}\\newcommand{\\Abs}[1]{\\left|#1\\right|}\\newcommand{\\ABs}[1]{\\biggl|#1\\biggr|}\\newcommand{\\norm}[1]{\\|#1\\|}\\newcommand{\\Norm}[1]{\\left\\|#1\\right\\|}\\newcommand{\\NOrm}[1]{\\biggl\\|#1\\biggr\\|}\\newcommand{\\Brace}[1]{\\left\\{#1\\right\\}}\\newcommand{\\BRace}[1]{\\biggl\\{#1\\biggr\\}}\\newcommand{\\paren}[1]{\\left(#1\\right)}\\newcommand{\\Paren}[1]{\\biggr(#1\\biggl)}\\newcommand{\\brac}[1]{\\langle#1\\rangle}\\newcommand{\\Brac}[1]{\\left\\langle#1\\right\\rangle}\\newcommand{\\BRac}[1]{\\biggl\\langle#1\\biggr\\rangle}\\newcommand{\\bra}[1]{\\left\\langle#1\\right|}\\newcommand{\\ket}[1]{\\left|#1\\right\\rangle}\\newcommand{\\Square}[1]{\\left[#1\\right]}\\newcommand{\\SQuare}[1]{\\biggl[#1\\biggr]}\\newcommand{\\rN}{\\mathrm{N}}\\newcommand{\\ov}[1]{\\overline{#1}}\\newcommand{\\un}[1]{\\underline{#1}}\\newcommand{\\wt}[1]{\\widetilde{#1}}\\newcommand{\\wh}[1]{\\widehat{#1}}\\newcommand{\\pp}[2]{\\frac{\\partial #1}{\\partial #2}}\\newcommand{\\ppp}[3]{\\frac{\\partial #1}{\\partial #2\\partial #3}}\\newcommand{\\dd}[2]{\\frac{d #1}{d #2}}\\newcommand{\\floor}[1]{\\lfloor#1\\rfloor}\\newcommand{\\Floor}[1]{\\left\\lfloor#1\\right\\rfloor}\\newcommand{\\ceil}[1]{\\lceil#1\\rceil}\\newcommand{\\ocinterval}[1]{(#1]}\\newcommand{\\cointerval}[1]{[#1)}\\newcommand{\\COinterval}[1]{\\left[#1\\right)}\\newcommand{\\iso}{\\overset{\\sim}{\\to}}\n\n\n\n\\newcommand{\\y}{\\b{y}}\\newcommand{\\mi}{\\,|\\,}\\newcommand{\\Mark}{\\mathrm{Mark}}\n\\newcommand{\\argmax}{\\operatorname*{argmax}}\\newcommand{\\argmin}{\\operatorname*{argmin}}\n\n\\newcommand{\\pr}{\\mathrm{pr}}\\newcommand{\\Conv}{\\operatorname{Conv}}\\newcommand{\\cU}{\\mathcal{U}}\n\\newcommand{\\Map}{\\mathrm{Map}}\\newcommand{\\dom}{\\mathrm{Dom}\\;}\\newcommand{\\cod}{\\mathrm{Cod}\\;}\\newcommand{\\supp}{\\mathrm{supp}\\;}\n\\newcommand{\\grad}{\\operatorname{grad}}\\newcommand{\\rot}{\\operatorname{rot}}\\renewcommand{\\div}{\\operatorname{div}}\\newcommand{\\tr}{\\operatorname{tr}}\\newcommand{\\Tr}{\\operatorname{Tr}}\\newcommand{\\KL}{\\operatorname{KL}}\\newcommand{\\JS}{\\operatorname{JS}}\\newcommand{\\ESS}{\\operatorname{ESS}}\\newcommand{\\MSE}{\\operatorname{MSE}}\\newcommand{\\erf}{\\operatorname{erf}}\\newcommand{\\arctanh}{\\operatorname{arctanh}}\\newcommand{\\pl}{\\operatorname{pl}}\\newcommand{\\minimize}{\\operatorname{minimize}}\\newcommand{\\subjectto}{\\operatorname{subject to}}\\newcommand{\\sinc}{\\operatorname{sinc}}\\newcommand{\\Ent}{\\operatorname{Ent}}\\newcommand{\\Polya}{\\operatorname{Polya}}\\newcommand{\\Exp}{\\operatorname{Exp}}\\newcommand{\\codim}{\\operatorname{codim}}\\newcommand{\\sgn}{\\operatorname{sgn}}\\newcommand{\\rank}{\\operatorname{rank}}\n\n\\newcommand{\\vctr}[2]{\\begin{pmatrix}#1\\\\#2\\end{pmatrix}}\\newcommand{\\vctrr}[3]{\\begin{pmatrix}#1\\\\#2\\\\#3\\end{pmatrix}}\\newcommand{\\mtrx}[4]{\\begin{pmatrix}#1&#2\\\\#3&#4\\end{pmatrix}}\\newcommand{\\smtrx}[4]{\\paren{\\begin{smallmatrix}#1&#2\\\\#3&#4\\end{smallmatrix}}}\\newcommand{\\Ker}{\\mathrm{Ker}\\;}\\newcommand{\\Coker}{\\mathrm{Coker}\\;}\\newcommand{\\Coim}{\\mathrm{Coim}\\;}\\newcommand{\\lcm}{\\mathrm{lcm}}\\newcommand{\\GL}{\\mathrm{GL}}\\newcommand{\\SL}{\\mathrm{SL}}\\newcommand{\\alt}{\\mathrm{alt}}\n\n\\renewcommand{\\Re}{\\mathrm{Re}\\;}\\renewcommand{\\Im}{\\mathrm{Im}\\,}\\newcommand{\\Gal}{\\mathrm{Gal}}\\newcommand{\\PGL}{\\mathrm{PGL}}\\newcommand{\\PSL}{\\mathrm{PSL}}\\newcommand{\\Log}{\\mathrm{Log}\\,}\\newcommand{\\Res}{\\mathrm{Res}\\,}\\newcommand{\\on}{\\mathrm{on}\\;}\\newcommand{\\hatC}{\\widehat{\\C}}\\newcommand{\\hatR}{\\hat{\\R}}\\newcommand{\\PV}{\\mathrm{P.V.}}\\newcommand{\\diam}{\\mathrm{diam}}\\newcommand{\\Area}{\\mathrm{Area}}\\newcommand{\\Lap}{\\Laplace}\\newcommand{\\f}{\\mathbf{f}}\\newcommand{\\cR}{\\mathcal{R}}\\newcommand{\\const}{\\mathrm{const.}}\\newcommand{\\Om}{\\Omega}\\newcommand{\\Cinf}{C^\\infty}\\newcommand{\\ep}{\\epsilon}\\newcommand{\\dist}{\\mathrm{dist}}\\newcommand{\\opart}{\\o{\\partial}}\\newcommand{\\Length}{\\mathrm{Length}}\n\n\\newcommand{\\cA}{\\mathcal{A}}\\newcommand{\\cO}{\\mathcal{O}}\\newcommand{\\cW}{\\mathcal{W}}\\renewcommand{\\O}{\\mathcal{O}}\\renewcommand{\\S}{\\mathcal{S}}\\newcommand{\\U}{\\mathcal{U}}\\newcommand{\\V}{\\mathrm{V}}\\newcommand{\\N}{\\mathbb{N}}\\newcommand{\\bN}{\\mathbb{N}}\\newcommand{\\C}{\\mathrm{C}}\\newcommand{\\bC}{\\mathbb{C}}\\newcommand{\\Z}{\\mathcal{Z}}\\newcommand{\\Q}{\\mathbb{Q}}\\newcommand{\\bQ}{\\mathbb{Q}}\\newcommand{\\TV}{\\mathrm{TV}}\\newcommand{\\ORD}{\\mathrm{ORD}}\\newcommand{\\Card}{\\mathrm{Card}\\,}\\newcommand{\\Top}{\\mathrm{Top}}\\newcommand{\\Disc}{\\mathrm{Disc}}\\newcommand{\\Codisc}{\\mathrm{Codisc}}\\newcommand{\\CoDisc}{\\mathrm{CoDisc}}\\newcommand{\\Ult}{\\mathrm{Ult}}\\newcommand{\\ord}{\\mathrm{ord}}\\newcommand{\\bS}{\\mathbb{S}}\\newcommand{\\PConn}{\\mathrm{PConn}}\\newcommand{\\mult}{\\mathrm{mult}}\\newcommand{\\inv}{\\mathrm{inv}}\n\n\\newcommand{\\Der}{\\mathrm{Der}}\\newcommand{\\osub}{\\overset{\\mathrm{open}}{\\subset}}\\newcommand{\\osup}{\\overset{\\mathrm{open}}{\\supset}}\\newcommand{\\al}{\\alpha}\\newcommand{\\K}{\\mathbb{K}}\\newcommand{\\Sp}{\\mathrm{Sp}}\\newcommand{\\g}{\\mathfrak{g}}\\newcommand{\\h}{\\mathfrak{h}}\\newcommand{\\Imm}{\\mathrm{Imm}}\\newcommand{\\Imb}{\\mathrm{Imb}}\\newcommand{\\Gr}{\\mathrm{Gr}}\n\n\\newcommand{\\Ad}{\\mathrm{Ad}}\\newcommand{\\finsupp}{\\mathrm{fin\\;supp}}\\newcommand{\\SO}{\\mathrm{SO}}\\newcommand{\\SU}{\\mathrm{SU}}\\newcommand{\\acts}{\\curvearrowright}\\newcommand{\\mono}{\\hookrightarrow}\\newcommand{\\epi}{\\twoheadrightarrow}\\newcommand{\\Stab}{\\mathrm{Stab}}\\newcommand{\\nor}{\\mathrm{nor}}\\newcommand{\\T}{\\mathbb{T}}\\newcommand{\\Aff}{\\mathrm{Aff}}\\newcommand{\\rsup}{\\triangleright}\\newcommand{\\subgrp}{\\overset{\\mathrm{subgrp}}{\\subset}}\\newcommand{\\Ext}{\\mathrm{Ext}}\\newcommand{\\sbs}{\\subset}\\newcommand{\\sps}{\\supset}\\newcommand{\\In}{\\mathrm{in}\\;}\\newcommand{\\Tor}{\\mathrm{Tor}}\\newcommand{\\p}{\\b{p}}\\newcommand{\\q}{\\mathfrak{q}}\\newcommand{\\m}{\\mathfrak{m}}\\newcommand{\\cS}{\\mathcal{S}}\\newcommand{\\Frac}{\\mathrm{Frac}\\,}\\newcommand{\\Spec}{\\mathrm{Spec}\\,}\\newcommand{\\bA}{\\mathbb{A}}\\newcommand{\\Sym}{\\mathrm{Sym}}\\newcommand{\\Ann}{\\mathrm{Ann}}\\newcommand{\\Her}{\\mathrm{Her}}\\newcommand{\\Bil}{\\mathrm{Bil}}\\newcommand{\\Ses}{\\mathrm{Ses}}\\newcommand{\\FVS}{\\mathrm{FVS}}\n\n\\newcommand{\\Ho}{\\mathrm{Ho}}\\newcommand{\\CW}{\\mathrm{CW}}\\newcommand{\\lc}{\\mathrm{lc}}\\newcommand{\\cg}{\\mathrm{cg}}\\newcommand{\\Fib}{\\mathrm{Fib}}\\newcommand{\\Cyl}{\\mathrm{Cyl}}\\newcommand{\\Ch}{\\mathrm{Ch}}\n\\newcommand{\\rP}{\\mathrm{P}}\\newcommand{\\rE}{\\mathrm{E}}\\newcommand{\\e}{\\b{e}}\\renewcommand{\\k}{\\b{k}}\\newcommand{\\Christ}[2]{\\begin{Bmatrix}#1\\\\#2\\end{Bmatrix}}\\renewcommand{\\Vec}[1]{\\overrightarrow{\\mathrm{#1}}}\\newcommand{\\hen}[1]{\\mathrm{#1}}\\renewcommand{\\b}[1]{\\boldsymbol{#1}}\n\n\\newcommand{\\Inc}{\\mathrm{Inc}}\\newcommand{\\aInc}{\\mathrm{aInc}}\\newcommand{\\HS}{\\mathrm{HS}}\\newcommand{\\loc}{\\mathrm{loc}}\\newcommand{\\Lh}{\\mathrm{L.h.}}\\newcommand{\\Epi}{\\mathrm{Epi}}\\newcommand{\\slim}{\\mathrm{slim}}\\newcommand{\\Ban}{\\mathrm{Ban}}\\newcommand{\\Hilb}{\\mathrm{Hilb}}\\newcommand{\\Ex}{\\mathrm{Ex}}\\newcommand{\\Co}{\\mathrm{Co}}\\newcommand{\\sa}{\\mathrm{sa}}\\newcommand{\\nnorm}[1]{{\\left\\vert\\kern-0.25ex\\left\\vert\\kern-0.25ex\\left\\vert #1 \\right\\vert\\kern-0.25ex\\right\\vert\\kern-0.25ex\\right\\vert}}\\newcommand{\\dvol}{\\mathrm{dvol}}\\newcommand{\\Sconv}{\\mathrm{Sconv}}\\newcommand{\\I}{\\mathcal{I}}\\newcommand{\\nonunital}{\\mathrm{nu}}\\newcommand{\\cpt}{\\mathrm{cpt}}\\newcommand{\\lcpt}{\\mathrm{lcpt}}\\newcommand{\\com}{\\mathrm{com}}\\newcommand{\\Haus}{\\mathrm{Haus}}\\newcommand{\\proper}{\\mathrm{proper}}\\newcommand{\\infinity}{\\mathrm{inf}}\\newcommand{\\TVS}{\\mathrm{TVS}}\\newcommand{\\ess}{\\mathrm{ess}}\\newcommand{\\ext}{\\mathrm{ext}}\\newcommand{\\Index}{\\mathrm{Index}\\;}\\newcommand{\\SSR}{\\mathrm{SSR}}\\newcommand{\\vs}{\\mathrm{vs.}}\\newcommand{\\fM}{\\mathfrak{M}}\\newcommand{\\EDM}{\\mathrm{EDM}}\\newcommand{\\Tw}{\\mathrm{Tw}}\\newcommand{\\fC}{\\mathfrak{C}}\\newcommand{\\bn}{\\boldsymbol{n}}\\newcommand{\\br}{\\boldsymbol{r}}\\newcommand{\\Lam}{\\Lambda}\\newcommand{\\lam}{\\lambda}\\newcommand{\\one}{\\mathbf{1}}\\newcommand{\\dae}{\\text{-a.e.}}\\newcommand{\\das}{\\text{-a.s.}}\\newcommand{\\td}{\\text{-}}\\newcommand{\\RM}{\\mathrm{RM}}\\newcommand{\\BV}{\\mathrm{BV}}\\newcommand{\\normal}{\\mathrm{normal}}\\newcommand{\\lub}{\\mathrm{lub}\\;}\\newcommand{\\Graph}{\\mathrm{Graph}}\\newcommand{\\Ascent}{\\mathrm{Ascent}}\\newcommand{\\Descent}{\\mathrm{Descent}}\\newcommand{\\BIL}{\\mathrm{BIL}}\\newcommand{\\fL}{\\mathfrak{L}}\\newcommand{\\De}{\\Delta}\n\n\\newcommand{\\calA}{\\mathcal{A}}\\newcommand{\\calB}{\\mathcal{B}}\\newcommand{\\D}{\\mathcal{D}}\\newcommand{\\Y}{\\mathcal{Y}}\\newcommand{\\calC}{\\mathcal{C}}\\renewcommand{\\ae}{\\mathrm{a.e.}\\;}\\newcommand{\\cZ}{\\mathcal{Z}}\\newcommand{\\fF}{\\mathfrak{F}}\\newcommand{\\fI}{\\mathfrak{I}}\\newcommand{\\rV}{\\mathrm{V}}\\newcommand{\\cE}{\\mathcal{E}}\\newcommand{\\sMap}{\\sigma\\textrm{-}\\mathrm{Map}}\\newcommand{\\cC}{\\mathcal{C}}\\newcommand{\\comp}{\\complement}\\newcommand{\\J}{\\mathcal{J}}\\newcommand{\\sumN}[1]{\\sum_{#1\\in\\N}}\\newcommand{\\cupN}[1]{\\cup_{#1\\in\\N}}\\newcommand{\\capN}[1]{\\cap_{#1\\in\\N}}\\newcommand{\\Sum}[1]{\\sum_{#1=1}^\\infty}\\newcommand{\\sumn}{\\sum_{n=1}^\\infty}\\newcommand{\\summ}{\\sum_{m=1}^\\infty}\\newcommand{\\sumk}{\\sum_{k=1}^\\infty}\\newcommand{\\sumi}{\\sum_{i=1}^\\infty}\\newcommand{\\sumj}{\\sum_{j=1}^\\infty}\\newcommand{\\cupn}{\\cup_{n=1}^\\infty}\\newcommand{\\capn}{\\cap_{n=1}^\\infty}\\newcommand{\\cupk}{\\cup_{k=1}^\\infty}\\newcommand{\\cupi}{\\cup_{i=1}^\\infty}\\newcommand{\\cupj}{\\cup_{j=1}^\\infty}\\newcommand{\\limn}{\\lim_{n\\to\\infty}}\\renewcommand{\\L}{\\mathcal{L}}\\newcommand{\\cL}{\\mathcal{L}}\\newcommand{\\Cl}{\\mathrm{Cl}}\\newcommand{\\cN}{\\mathcal{N}}\\newcommand{\\Ae}{\\textrm{-a.e.}\\;}\\renewcommand{\\csub}{\\overset{\\textrm{closed}}{\\subset}}\\renewcommand{\\csup}{\\overset{\\textrm{closed}}{\\supset}}\\newcommand{\\wB}{\\wt{B}}\\newcommand{\\cG}{\\mathcal{G}}\\newcommand{\\Lip}{\\mathrm{Lip}}\\newcommand{\\AC}{\\mathrm{AC}}\\newcommand{\\Mol}{\\mathrm{Mol}}\n\n\\newcommand{\\Pe}{\\mathrm{Pe}}\\newcommand{\\wR}{\\wh{\\mathbb{\\R}}}\\newcommand*{\\Laplace}{\\mathop{}\\!\\mathbin\\bigtriangleup}\\newcommand*{\\DAlambert}{\\mathop{}\\!\\mathbin\\Box}\\newcommand{\\bT}{\\mathbb{T}}\\newcommand{\\dx}{\\dslash x}\\newcommand{\\dt}{\\dslash t}\\newcommand{\\ds}{\\dslash s}\n\n\\newcommand{\\round}{\\mathrm{round}}\\newcommand{\\cond}{\\mathrm{cond}}\\newcommand{\\diag}{\\mathrm{diag}}\n\\newcommand{\\Adj}{\\mathrm{Adj}}\\newcommand{\\Pf}{\\mathrm{Pf}}\\newcommand{\\Sg}{\\mathrm{Sg}}\n\n\n\\newcommand{\\aseq}{\\overset{\\text{a.s.}}{=}}\\newcommand{\\deq}{\\overset{\\text{d}}{=}}\\newcommand{\\cV}{\\mathcal{V}}\\newcommand{\\FM}{\\mathrm{FM}}\\newcommand{\\KR}{\\mathrm{KR}}\\newcommand{\\rba}{\\mathrm{rba}}\\newcommand{\\rca}{\\mathrm{rca}}\\newcommand{\\Prob}{\\mathrm{Prob}}\\newcommand{\\X}{\\mathcal{X}}\\newcommand{\\Meas}{\\mathrm{Meas}}\\newcommand{\\as}{\\;\\text{a.s.}}\\newcommand{\\io}{\\;\\mathrm{i.o.}}\\newcommand{\\fe}{\\;\\text{f.e.}}\\newcommand{\\bF}{\\mathbb{F}}\\newcommand{\\W}{\\mathcal{W}}\\newcommand{\\Pois}{\\mathrm{Pois}}\\newcommand{\\iid}{\\text{i.i.d.}}\\newcommand{\\wconv}{\\rightsquigarrow}\\newcommand{\\Var}{\\mathrm{Var}}\\newcommand{\\xrightarrown}{\\xrightarrow{n\\to\\infty}}\\newcommand{\\au}{\\mathrm{au}}\\newcommand{\\cT}{\\mathcal{T}}\\newcommand{\\wto}{\\overset{\\text{w}}{\\to}}\\newcommand{\\dto}{\\overset{\\text{d}}{\\to}}\\newcommand{\\sto}{\\overset{\\text{s}}{\\to}}\\newcommand{\\pto}{\\overset{\\text{p}}{\\to}}\\newcommand{\\mto}{\\overset{\\text{m}}{\\to}}\\newcommand{\\vto}{\\overset{v}{\\to}}\\newcommand{\\Cont}{\\mathrm{Cont}}\\newcommand{\\stably}{\\mathrm{stably}}\\newcommand{\\Np}{\\mathbb{N}^+}\\newcommand{\\oM}{\\overline{\\mathcal{M}}}\\newcommand{\\fP}{\\mathfrak{P}}\\newcommand{\\sign}{\\mathrm{sign}}\n\\newcommand{\\Borel}{\\mathrm{Borel}}\\newcommand{\\Mid}{\\,|\\,}\\newcommand{\\middleMid}{\\;\\middle|\\;}\\newcommand{\\CP}{\\mathrm{CP}}\\newcommand{\\bD}{\\mathbb{D}}\\newcommand{\\bL}{\\mathbb{L}}\\newcommand{\\fW}{\\mathfrak{W}}\\newcommand{\\DL}{\\mathcal{D}\\mathcal{L}}\\renewcommand{\\r}[1]{\\mathrm{#1}}\\newcommand{\\rC}{\\mathrm{C}}\\newcommand{\\qqquad}{\\qquad\\quad}\n\n\\newcommand{\\bit}{\\mathrm{bit}}\n\n\\newcommand{\\err}{\\mathrm{err}}\n\n\\newcommand{\\varparallel}{\\mathbin{\\!/\\mkern-5mu/\\!}}\\newcommand{\\Ri}{\\mathrm{Ri}}\\newcommand{\\Cone}{\\mathrm{Cone}}\\newcommand{\\Int}{\\mathrm{Int}}\n\n\\newcommand{\\pre}{\\mathrm{pre}}\\newcommand{\\om}{\\omega}\n\n\n\\newcommand{\\del}{\\partial}\n\\newcommand{\\LHS}{\\mathrm{LHS}}\\newcommand{\\RHS}{\\mathrm{RHS}}\\newcommand{\\bnu}{\\boldsymbol{\\nu}}\\newcommand{\\interior}{\\mathrm{in}\\;}\\newcommand{\\SH}{\\mathrm{SH}}\\renewcommand{\\v}{\\boldsymbol{\\nu}}\\newcommand{\\n}{\\mathbf{n}}\\newcommand{\\ssub}{\\Subset}\\newcommand{\\curl}{\\mathrm{curl}}\n\n\\newcommand{\\Ei}{\\mathrm{Ei}}\\newcommand{\\sn}{\\mathrm{sn}}\\newcommand{\\wgamma}{\\widetilde{\\gamma}}\n\n\\newcommand{\\Ens}{\\mathrm{Ens}}\n\n\\newcommand{\\cl}{\\mathrm{cl}}\\newcommand{\\x}{\\boldsymbol{x}}\n\n\\newcommand{\\Do}{\\mathrm{Do}}\\newcommand{\\IV}{\\mathrm{IV}}\n\n\\newcommand{\\AIC}{\\mathrm{AIC}}\\newcommand{\\mrl}{\\mathrm{mrl}}\\newcommand{\\dotx}{\\dot{x}}\\newcommand{\\UMV}{\\mathrm{UMV}}\\newcommand{\\BLU}{\\mathrm{BLU}}\n\n\\newcommand{\\comb}[2]{\\begin{pmatrix}#1\\\\#2\\end{pmatrix}}\\newcommand{\\bP}{\\mathbb{P}}\\newcommand{\\compsub}{\\overset{\\textrm{cpt}}{\\subset}}\\newcommand{\\lip}{\\textrm{lip}}\\newcommand{\\BL}{\\mathrm{BL}}\\newcommand{\\G}{\\mathbb{G}}\\newcommand{\\NB}{\\mathrm{NB}}\\newcommand{\\oR}{\\ov{\\R}}\\newcommand{\\liminfn}{\\liminf_{n\\to\\infty}}\\newcommand{\\limsupn}{\\limsup_{n\\to\\infty}}\\newcommand{\\esssup}{\\mathrm{ess.sup}}\\newcommand{\\asto}{\\xrightarrow{\\as}}\\newcommand{\\Cov}{\\mathrm{Cov}}\\newcommand{\\cQ}{\\mathcal{Q}}\\newcommand{\\VC}{\\mathrm{VC}}\\newcommand{\\mb}{\\mathrm{mb}}\\newcommand{\\Avar}{\\mathrm{Avar}}\\newcommand{\\bB}{\\mathbb{B}}\\newcommand{\\bW}{\\mathbb{W}}\\newcommand{\\sd}{\\mathrm{sd}}\\newcommand{\\w}[1]{\\widehat{#1}}\\newcommand{\\bZ}{\\mathbb{Z}}\\newcommand{\\Bernoulli}{\\mathrm{Ber}}\\newcommand{\\Ber}{\\mathrm{Ber}}\\newcommand{\\Mult}{\\mathrm{Mult}}\\newcommand{\\BPois}{\\mathrm{BPois}}\\newcommand{\\fraks}{\\mathfrak{s}}\\newcommand{\\frakk}{\\mathfrak{k}}\\newcommand{\\IF}{\\mathrm{IF}}\\newcommand{\\bX}{\\boldsymbol{X}}\\newcommand{\\bx}{\\boldsymbol{x}}\\newcommand{\\indep}{\\perp\\!\\!\\!\\perp}\\newcommand{\\IG}{\\mathrm{IG}}\\newcommand{\\Levy}{\\mathrm{Levy}}\\newcommand{\\MP}{\\mathrm{MP}}\\newcommand{\\Hermite}{\\mathrm{Hermite}}\\newcommand{\\Skellam}{\\mathrm{Skellam}}\\newcommand{\\Dirichlet}{\\mathrm{Dirichlet}}\\renewcommand{\\Beta}{\\operatorname{Beta}}\\newcommand{\\bE}{\\mathbb{E}}\\newcommand{\\bG}{\\mathbb{G}}\\newcommand{\\MISE}{\\mathrm{MISE}}\\newcommand{\\logit}{\\mathtt{logit}}\\newcommand{\\expit}{\\mathtt{expit}}\\newcommand{\\cK}{\\mathcal{K}}\\newcommand{\\dl}{\\dot{l}}\\newcommand{\\dotp}{\\dot{p}}\\newcommand{\\wl}{\\wt{l}}\\newcommand{\\Gauss}{\\mathrm{Gauss}}\\newcommand{\\fA}{\\mathfrak{A}}\\newcommand{\\under}{\\mathrm{under}\\;}\\newcommand{\\whtheta}{\\wh{\\theta}}\\newcommand{\\Em}{\\mathrm{Em}}\\newcommand{\\ztheta}{{\\theta_0}}\n\\newcommand{\\rO}{\\mathrm{O}}\\newcommand{\\Bin}{\\mathrm{Bin}}\\newcommand{\\rW}{\\mathrm{W}}\\newcommand{\\rG}{\\mathrm{G}}\\newcommand{\\rB}{\\mathrm{B}}\\newcommand{\\rU}{\\mathrm{U}}\\newcommand{\\HG}{\\mathrm{HG}}\\newcommand{\\GAMMA}{\\mathrm{Gamma}}\\newcommand{\\Cauchy}{\\mathrm{Cauchy}}\\newcommand{\\rt}{\\mathrm{t}}\\newcommand{\\rF}{\\mathrm{F}}\n\\newcommand{\\FE}{\\mathrm{FE}}\\newcommand{\\bV}{\\boldsymbol{V}}\\newcommand{\\GLS}{\\mathrm{GLS}}\\newcommand{\\be}{\\boldsymbol{e}}\\newcommand{\\POOL}{\\mathrm{POOL}}\\newcommand{\\GMM}{\\mathrm{GMM}}\\newcommand{\\MM}{\\mathrm{MM}}\\newcommand{\\SSIV}{\\mathrm{SSIV}}\\newcommand{\\JIV}{\\mathrm{JIV}}\\newcommand{\\AR}{\\mathrm{AR}}\\newcommand{\\ILS}{\\mathrm{ILS}}\\newcommand{\\SLS}{\\mathrm{SLS}}\\newcommand{\\LIML}{\\mathrm{LIML}}\n\n\\newcommand{\\Rad}{\\mathrm{Rad}}\\newcommand{\\bY}{\\boldsymbol{Y}}\\newcommand{\\pone}{{(1)}}\\newcommand{\\ptwo}{{(2)}}\\newcommand{\\ps}[1]{{(#1)}}\\newcommand{\\fsub}{\\overset{\\text{finite}}{\\subset}}\n\n\n\\newcommand{\\varlim}{\\varprojlim}\\newcommand{\\Hom}{\\mathrm{Hom}}\\newcommand{\\Iso}{\\mathrm{Iso}}\\newcommand{\\Mor}{\\mathrm{Mor}}\\newcommand{\\Isom}{\\mathrm{Isom}}\\newcommand{\\Aut}{\\mathrm{Aut}}\\newcommand{\\End}{\\mathrm{End}}\\newcommand{\\op}{\\mathrm{op}}\\newcommand{\\ev}{\\mathrm{ev}}\\newcommand{\\Ob}{\\mathrm{Ob}}\\newcommand{\\Ar}{\\mathrm{Ar}}\\newcommand{\\Arr}{\\mathrm{Arr}}\\newcommand{\\Set}{\\mathrm{Set}}\\newcommand{\\Grp}{\\mathrm{Grp}}\\newcommand{\\Cat}{\\mathrm{Cat}}\\newcommand{\\Mon}{\\mathrm{Mon}}\\newcommand{\\Ring}{\\mathrm{Ring}}\\newcommand{\\CRing}{\\mathrm{CRing}}\\newcommand{\\Ab}{\\mathrm{Ab}}\\newcommand{\\Pos}{\\mathrm{Pos}}\\newcommand{\\Vect}{\\mathrm{Vect}}\\newcommand{\\FinVect}{\\mathrm{FinVect}}\\newcommand{\\FinSet}{\\mathrm{FinSet}}\\newcommand{\\FinMeas}{\\mathrm{FinMeas}}\\newcommand{\\OmegaAlg}{\\Omega\\text{-}\\mathrm{Alg}}\\newcommand{\\OmegaEAlg}{(\\Omega,E)\\text{-}\\mathrm{Alg}}\\newcommand{\\Fun}{\\mathrm{Fun}}\\newcommand{\\Func}{\\mathrm{Func}}\n\n\\newcommand{\\Stoch}{\\mathrm{Stoch}}\\newcommand{\\FinStoch}{\\mathrm{FinStoch}}\\newcommand{\\Copy}{\\mathrm{copy}}\\newcommand{\\Delete}{\\mathrm{delete}}\n\\newcommand{\\Bool}{\\mathrm{Bool}}\\newcommand{\\CABool}{\\mathrm{CABool}}\\newcommand{\\CompBoolAlg}{\\mathrm{CompBoolAlg}}\\newcommand{\\BoolAlg}{\\mathrm{BoolAlg}}\\newcommand{\\BoolRng}{\\mathrm{BoolRng}}\\newcommand{\\HeytAlg}{\\mathrm{HeytAlg}}\\newcommand{\\CompHeytAlg}{\\mathrm{CompHeytAlg}}\\newcommand{\\Lat}{\\mathrm{Lat}}\\newcommand{\\CompLat}{\\mathrm{CompLat}}\\newcommand{\\SemiLat}{\\mathrm{SemiLat}}\\newcommand{\\Stone}{\\mathrm{Stone}}\\newcommand{\\Mfd}{\\mathrm{Mfd}}\\newcommand{\\LieAlg}{\\mathrm{LieAlg}}\n\\newcommand{\\Op}{\\mathrm{Op}}\n\\newcommand{\\Sh}{\\mathrm{Sh}}\n\\newcommand{\\Diff}{\\mathrm{Diff}}\n\\newcommand{\\B}{\\mathcal{B}}\\newcommand{\\cB}{\\mathcal{B}}\\newcommand{\\Span}{\\mathrm{Span}}\\newcommand{\\Corr}{\\mathrm{Corr}}\\newcommand{\\Decat}{\\mathrm{Decat}}\\newcommand{\\Rep}{\\mathrm{Rep}}\\newcommand{\\Grpd}{\\mathrm{Grpd}}\\newcommand{\\sSet}{\\mathrm{sSet}}\\newcommand{\\Mod}{\\mathrm{Mod}}\\newcommand{\\SmoothMnf}{\\mathrm{SmoothMnf}}\\newcommand{\\coker}{\\mathrm{coker}}\\newcommand{\\Ord}{\\mathrm{Ord}}\\newcommand{\\eq}{\\mathrm{eq}}\\newcommand{\\coeq}{\\mathrm{coeq}}\\newcommand{\\act}{\\mathrm{act}}\n\n\\newcommand{\\apf}{\\mathrm{apf}}\\newcommand{\\opt}{\\mathrm{opt}}\\newcommand{\\IS}{\\mathrm{IS}}\\newcommand{\\IR}{\\mathrm{IR}}\\newcommand{\\iidsim}{\\overset{\\text{i.i.d.}}{\\sim}}\\newcommand{\\propt}{\\,\\propto\\,}\\newcommand{\\bM}{\\mathbb{M}}\\newcommand{\\cX}{\\mathcal{X}}\\newcommand{\\cY}{\\mathcal{Y}}\\newcommand{\\cP}{\\mathcal{P}}\\newcommand{\\ola}[1]{\\overleftarrow{#1}}\n\n\\renewcommand{\\iff}{\\;\\mathrm{iff}\\;}\n\\newcommand{\\False}{\\mathrm{False}}\\newcommand{\\True}{\\mathrm{True}}\n\\newcommand{\\otherwise}{\\mathrm{otherwise}}\n\\newcommand{\\suchthat}{\\;\\mathrm{s.t.}\\;}\n\n\\newcommand{\\cM}{\\mathcal{M}}\\newcommand{\\M}{\\mathbb{M}}\\newcommand{\\cF}{\\mathcal{F}}\\newcommand{\\cD}{\\mathcal{D}}\\newcommand{\\fX}{\\mathfrak{X}}\\newcommand{\\fY}{\\mathfrak{Y}}\\newcommand{\\fZ}{\\mathfrak{Z}}\\renewcommand{\\H}{\\mathcal{H}}\\newcommand{\\cH}{\\mathcal{H}}\\newcommand{\\fH}{\\mathfrak{H}}\\newcommand{\\bH}{\\mathbb{H}}\\newcommand{\\id}{\\mathrm{id}}\\newcommand{\\A}{\\mathcal{A}}\n\\newcommand{\\lmd}{\\lambda}\n\\newcommand{\\Lmd}{\\Lambda}\n\\newcommand{\\cI}{\\mathcal{I}}\n\n\\newcommand{\\Lrarrow}{\\;\\;\\Leftrightarrow\\;\\;}\n\\DeclareMathOperator{\\des}{des}\n\\DeclareMathOperator{\\nd}{nd}\n\\DeclareMathOperator{\\dsep}{d-sep}\n\\DeclareMathOperator{\\sep}{sep}\n\\newcommand{\\rLL}{\\mathrm{LL}}\\newcommand{\\HT}{\\mathrm{HT}}\\newcommand{\\PS}{\\mathrm{PS}}\\newcommand{\\rI}{\\mathrm{I}}\n$$\n\n:::\n\n:::\n\n\n\n## `brms` リンク集\n\n::: {#lst-brms}\n:::\n\n::: {.callout-tip title=\"brms: Bayesian Regression Models using 'Stan' リンク集\" appearance=\"simple\"}\n\n* [r-project](https://cran.r-project.org/web/packages/brms/)\n* [Documentation](https://paul-buerkner.github.io/brms/)\n* [GitHub](https://github.com/paul-buerkner/brms)\n* [discourse](https://discourse.mc-stan.org/)\n* [@Burkner2017], [@Burkner2018], [@Burkner2021]\n\n:::\n\nダウンロードは：\n\n```r\ninstall.packages(\"brms\")\n```\n\n## 例で学ぶ `brms` の使い方\n\n### カウントデータのモデリング {#sec-example}\n\nDocumentation で紹介されている，[`Epilepsy Seizures Data`](https://search.r-project.org/CRAN/refmans/dhglm/html/epilepsy.html) [@Leppik+1987]，[@Thall-Vail1990] を用いた [例](https://paul-buerkner.github.io/brms/) を実行してみる：\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(brms)\nfit1 <- brm(count ~ zAge + zBase * Trt + (1|patient),\n            data = epilepsy, family = poisson())\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\nてんかん (epilepsy) 患者の発作回数 `count` を被説明変数とし，処置の有無を表す説明変数 `Trt` と患者毎のランダム誤差を表す切片項 `(1|patient)`，及び標準化された説明変数 `zAge`, `zBase` への依存構造を調べたい．\n\n被説明変数 `count` は離散変数であり，Poisson 分布に従うと仮定する．過分散への対応を次の段階で考慮する．\n\n::: {.callout-note appearance=\"simple\" title=\"説明変数\"}\n\n* `zAge`：標準化された年齢\n* `zBase`：ベースの発作回数\n* `Trt`：治療の有無を表す２値変数\n* `(1|patient)`：患者ごとに異なるとした変動切片項\n\n`zBase * Trt`という記法は，この２つの交互作用もモデルに含めることを意味する．この項の追加により，モデルは `zBase` の違いに応じて `Trt` の効果が変わる度合い $\\beta_4$ を取り入れることができる．\n\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkable(head(epilepsy))\n```\n\n::: {.cell-output-display}\n\n\n| Age| Base|Trt |patient |visit | count|obs |       zAge|      zBase|\n|---:|----:|:---|:-------|:-----|-----:|:---|----------:|----------:|\n|  31|   11|0   |1       |1     |     5|1   |  0.4249950| -0.7571728|\n|  30|   11|0   |2       |1     |     3|2   |  0.2652835| -0.7571728|\n|  25|    6|0   |3       |1     |     2|3   | -0.5332740| -0.9444033|\n|  36|    8|0   |4       |1     |     4|4   |  1.2235525| -0.8695111|\n|  22|   66|0   |5       |1     |     7|5   | -1.0124085|  1.3023626|\n|  29|   27|0   |6       |1     |     5|6   |  0.1055720| -0.1580352|\n\n\n:::\n:::\n\n\n\n::: {.callout-note appearance=\"simple\" title=\"データの詳細\"}\n\n`epilepsy`は59 人の患者に関して，４回の入院時の発作回数を記録した，全 236 データからなる．`patient`が患者を識別する ID であり，`(1|patient)`は患者ごとのランダム効果ということになる．\n\n:::\n\n従って本モデルは`zAge`, `zBase`, `Trt`, `Trt*zBase`という固定効果（係数），`(1|patient)`というランダム効果を取り入れた（一般化線型）**混合効果モデル** である．回帰式は次の通り：\n$$\ny_{it} = \\beta_1 \\cdot\\texttt{zAge}_i+ \\beta_2 \\cdot \\texttt{zBase}_i + \\beta_3 \\cdot \\texttt{Trt}_i\n$$\n$$\n+ \\beta_4 \\cdot (\\texttt{zBase}_i \\cdot \\texttt{Trt}_i) + \\al_i +\\ep_{it}.\n$$\nただし，$\\texttt{count}_{it}$ の Poisson 母数を $\\lambda_{it}$ として，$y_{it}:=\\log(\\lambda_{it})$ とした．\n\n<!-- \n解析意図としては，ベースの発作回数が高いほど，治療効果が高い／低いのではないか？という仮説を検証する，`zBase*Trt`を曝露因子としたモデルである．\n-->\n\n### `brm()` 関数\n\n#### `family` 引数\n\nここでは被説明変数 $y$ に仮定するパラメトリック分布族と，リンク関数 $g$ を指定する：\n\n```r\nfamily = brmsfamily(family = \"<family>\", link = \"<link>\")\n```\n\n多くの場合 `link` 引数は省略可能である．\n\n::: {.callout-caution collapse=\"true\" title=\"利用可能な分布族の一覧\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrmsfamily\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nfunction (family, link = NULL, link_sigma = \"log\", link_shape = \"log\", \n    link_nu = \"logm1\", link_phi = \"log\", link_kappa = \"log\", \n    link_beta = \"log\", link_zi = \"logit\", link_hu = \"logit\", \n    link_zoi = \"logit\", link_coi = \"logit\", link_disc = \"log\", \n    link_bs = \"log\", link_ndt = \"log\", link_bias = \"logit\", link_xi = \"log1p\", \n    link_alpha = \"identity\", link_quantile = \"logit\", threshold = \"flexible\", \n    refcat = NULL, bhaz = NULL) \n{\n    slink <- substitute(link)\n    .brmsfamily(family, link = link, slink = slink, link_sigma = link_sigma, \n        link_shape = link_shape, link_nu = link_nu, link_phi = link_phi, \n        link_kappa = link_kappa, link_beta = link_beta, link_zi = link_zi, \n        link_hu = link_hu, link_zoi = link_zoi, link_coi = link_coi, \n        link_disc = link_disc, link_bs = link_bs, link_ndt = link_ndt, \n        link_bias = link_bias, link_alpha = link_alpha, link_xi = link_xi, \n        link_quantile = link_quantile, threshold = threshold, \n        refcat = refcat, bhaz = bhaz)\n}\n<bytecode: 0x13fdc5fe0>\n<environment: namespace:brms>\n```\n\n\n:::\n:::\n\n\n:::\n\nこの２つの情報を通じて，一般化線型モデルを取り扱うことができる．\n\n### モデルの推定と結果の解釈\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: poisson \n  Links: mu = log \nFormula: count ~ zAge + zBase * Trt + (1 | patient) \n   Data: epilepsy (Number of observations: 236) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~patient (Number of levels: 59) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.58      0.07     0.46     0.75 1.00     1016     1779\n\nRegression Coefficients:\n           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      1.78      0.12     1.54     2.02 1.01      959     1321\nzAge           0.09      0.09    -0.08     0.26 1.01      765     1399\nzBase          0.70      0.12     0.47     0.93 1.01      813     1369\nTrt1          -0.27      0.17    -0.61     0.06 1.00      817     1205\nzBase:Trt1     0.05      0.16    -0.26     0.36 1.01      819     1692\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\n基本的な解析の前提がまず出力され，推定結果はグループ毎（今回は患者毎）の変数（今回は $\\al_i$）から表示される．\n\n後半に固定効果の係数，すなわち回帰係数の推定結果が表示される．\n\n治療効果`Trt`の係数は負で，平均的に処置効果はある可能性があるが，95% 信頼区間は $0$ を跨いでいるという意味で，有意とは言えない．また，交差項`zBase*Trt`の係数は小さく，交互効果の存在を示す証拠はないと思われる．\n\n$\\wh{R}$ [@Gelman-Rubin1992] は MCMC の収束に関する指標で，１より大きい場合，MCMC が収束していない可能性を意味する [@Vehtari+2021]．通説には $\\wh{R}\\le1.1$ などの基準がある．\n\n### プロット\n\n変数を指定して，事後分布と MCMC の軌跡をプロットできる：\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit1, variable = c(\"b_Trt1\", \"b_zBase\"))\n```\n\n::: {.cell-output-display}\n![](brms_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\nより詳しく見るには`conditional_effects`関数を用いることもできる．交差項の効果はほとんどないことがわかる：\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(conditional_effects(fit1, effects = \"zBase:Trt\"))\n```\n\n::: {.cell-output-display}\n![](brms_files/figure-html/fig-conditional_effects-1.png){#fig-conditional_effects width=672}\n:::\n:::\n\n\n\n### モデルによる予測\n\nfit したモデル `fit1` を用いて，平均年齢と平均ベースレートを持つ患者に対する治療効果を予測する：\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnewdata <- data.frame(Trt = c(0, 1), zAge = 0, zBase = 0)\npredict(fit1, newdata = newdata, re_formula = NA)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Estimate Est.Error Q2.5  Q97.5\n[1,]   5.9710  2.530960    2 11.025\n[2,]   4.5425  2.178275    1  9.000\n```\n\n\n:::\n:::\n\n\n\n関数[`predict()`](https://paul-buerkner.github.io/brms/reference/predict.brmsfit.html)は事後予測分布からのサンプリングを行う．一方で，関数[`fitted()`](https://paul-buerkner.github.io/brms/reference/fitted.brmsfit.html)は平均を返す．\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfitted(fit1, newdata = newdata, re_formula = NA)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Estimate Est.Error     Q2.5    Q97.5\n[1,] 5.953824  0.712907 4.682468 7.518386\n[2,] 4.525703  0.545437 3.518021 5.614800\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-caution collapse=\"true\" title=\"予測の出力\"}\n\n従って，もう１度ずつ実行すると，`predict`では値が変わるが，`fitted`では同じ値が出力される．\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(fit1, newdata = newdata, re_formula = NA)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Estimate Est.Error Q2.5 Q97.5\n[1,]  5.90800  2.532418    2    11\n[2,]  4.57725  2.256725    1    10\n```\n\n\n:::\n\n```{.r .cell-code}\nfitted(fit1, newdata = newdata, re_formula = NA)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Estimate Est.Error     Q2.5    Q97.5\n[1,] 5.953824  0.712907 4.682468 7.518386\n[2,] 4.525703  0.545437 3.518021 5.614800\n```\n\n\n:::\n:::\n\n\n\n:::\n\n### モデルの比較 {#sec-model-comparison}\n\nモデル`fit1`で行った Poisson 回帰分析は，`fit1`に含めた説明変数の違いを除けば，個々の観測が独立になる，という仮定の上に成り立っている（第 [-@sec-ubsubsec-covariance-structure] 節）．\n\nこの仮定が破れているとき＝全ての説明変数をモデルに含めきれていないとき，Poisson 分布の性質\n$$\n\\E[X]=\\V[X]=\\lambda\\qquad (X\\sim\\Pois(\\lambda))\n$$\nからの離反として現れ，この現象は **過分散**（overdispersion）とも呼ばれる．\n\n#### 観測レベルランダム効果\n\nということで，他の説明変数が存在した場合を想定して， Poisson 分布族ではなく，分散が平均よりも大きいような別の分布族を用いて，フィット度合いを比較してみることを考えたい．\n\nそこで，追加の変動をモデルに追加するべく，モデル`fit1`に観測ごとの切片項 $\\eta_{it}$ を追加してみる（この手法は観測レベルランダム効果と呼ばれる．第 [-@sec-subsec-count-data] 節参照）．\n\n```r\nfit2 <- brm(count ~ zAge + zBase * Trt + (1|patient) + (1|obs),\n            data = epilepsy, family = poisson())\n```\n\n::: {.callout-caution collapse=\"true\" title=\"フィッティングの出力\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2 <- brm(count ~ zAge + zBase * Trt + (1|patient) + (1|obs),\n            data = epilepsy, family = poisson())\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nStart sampling\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 7.5e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.75 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 1.921 seconds (Warm-up)\nChain 1:                1.224 seconds (Sampling)\nChain 1:                3.145 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 2e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 2.043 seconds (Warm-up)\nChain 2:                1.508 seconds (Sampling)\nChain 2:                3.551 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 1.8e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 1.829 seconds (Warm-up)\nChain 3:                1.111 seconds (Sampling)\nChain 3:                2.94 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 2.4e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.24 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 1.784 seconds (Warm-up)\nChain 4:                1.121 seconds (Sampling)\nChain 4:                2.905 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n\n\n:::\n\nこうして得た２つのモデル`fit1`,`fit2`を比較する．\n\nLLO (Leave-One-Out) cross-validation が関数`loo`によって実行できる：\n\n```r\nloo(fit1, fit2)\n```\n\n::: {.callout-caution collapse=\"true\" title=\"LOO-CV の結果\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloo(fit1, fit2)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Found 9 observations with a pareto_k > 0.7 in model 'fit1'. We\nrecommend to set 'moment_match = TRUE' in order to perform moment matching for\nproblematic observations.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Found 61 observations with a pareto_k > 0.7 in model 'fit2'. We\nrecommend to set 'moment_match = TRUE' in order to perform moment matching for\nproblematic observations.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOutput of model 'fit1':\n\nComputed from 4000 by 236 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -670.5 35.9\np_loo        93.4 13.7\nlooic      1341.1 71.9\n------\nMCSE of elpd_loo is NA.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.4, 1.9]).\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     227   96.2%   135     \n   (0.7, 1]   (bad)        8    3.4%   <NA>    \n   (1, Inf)   (very bad)   1    0.4%   <NA>    \nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'fit2':\n\nComputed from 4000 by 236 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -594.9 13.8\np_loo       107.4  7.0\nlooic      1189.8 27.7\n------\nMCSE of elpd_loo is NA.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.4, 1.5]).\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     175   74.2%   169     \n   (0.7, 1]   (bad)       57   24.2%   <NA>    \n   (1, Inf)   (very bad)   4    1.7%   <NA>    \nSee help('pareto-k-diagnostic') for details.\n\nModel comparisons:\n     elpd_diff se_diff\nfit2   0.0       0.0  \nfit1 -75.7      26.5  \n```\n\n\n:::\n:::\n\n\n\n:::\n\n`elpd_diff` は expected log posterior density の差異を表す．`fit2`の方が大きく当てはまりが良いことが見て取れる．\n\nまた，WAIC (Watanabe-Akaike Information Criterion) も実装されている：\n\n```r\nprint(waic(fit1))\n```\n\n::: {.callout-caution collapse=\"true\" title=\"WAIC の結果\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(waic(fit1))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: \n53 (22.5%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nComputed from 4000 by 236 log-likelihood matrix.\n\n          Estimate   SE\nelpd_waic   -668.6 36.8\np_waic        91.4 14.7\nwaic        1337.2 73.6\n\n53 (22.5%) p_waic estimates greater than 0.4. We recommend trying loo instead. \n```\n\n\n:::\n\n```{.r .cell-code}\nprint(waic(fit2))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: \n63 (26.7%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nComputed from 4000 by 236 log-likelihood matrix.\n\n          Estimate   SE\nelpd_waic   -572.5 12.0\np_waic        85.0  5.2\nwaic        1144.9 24.0\n\n63 (26.7%) p_waic estimates greater than 0.4. We recommend trying loo instead. \n```\n\n\n:::\n:::\n\n\n\n:::\n\n他にも，`reloo`, `kfold` などの関数もある．\n\n::: {.callout-caution collapse=\"true\" title=\"他の関数一覧\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmethods(class=\"brmsfit\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] add_criterion           add_ic                  as_draws_array         \n [4] as_draws_df             as_draws_list           as_draws_matrix        \n [7] as_draws_rvars          as_draws                as.array               \n[10] as.data.frame           as.matrix               as.mcmc                \n[13] autocor                 bayes_factor            bayes_R2               \n[16] bridge_sampler          coef                    conditional_effects    \n[19] conditional_smooths     control_params          default_prior          \n[22] expose_functions        family                  fitted                 \n[25] fixef                   formula                 getCall                \n[28] hypothesis              kfold                   log_lik                \n[31] log_posterior           logLik                  loo_compare            \n[34] loo_linpred             loo_model_weights       loo_moment_match       \n[37] loo_predict             loo_predictive_interval loo_R2                 \n[40] loo_subsample           loo                     LOO                    \n[43] marginal_effects        marginal_smooths        mcmc_plot              \n[46] model_weights           model.frame             nchains                \n[49] ndraws                  neff_ratio              ngrps                  \n[52] niterations             nobs                    nsamples               \n[55] nuts_params             nvariables              pairs                  \n[58] parnames                plot                    post_prob              \n[61] posterior_average       posterior_epred         posterior_interval     \n[64] posterior_linpred       posterior_predict       posterior_samples      \n[67] posterior_smooths       posterior_summary       pp_average             \n[70] pp_check                pp_mixture              predict                \n[73] predictive_error        predictive_interval     prepare_predictions    \n[76] print                   prior_draws             prior_summary          \n[79] psis                    ranef                   reloo                  \n[82] residuals               restructure             rhat                   \n[85] stancode                standata                stanplot               \n[88] summary                 update                  VarCorr                \n[91] variables               vcov                    waic                   \n[94] WAIC                   \nsee '?methods' for accessing help and source code\n```\n\n\n:::\n:::\n\n\n\n:::\n\n#### 患者内の相関構造のモデリング\n\nまた，`fit1`において，同一患者の異なる訪問の間には全く相関がないと仮定されており，これは全く非現実的な仮定をおいてしまっていると言える．^[通常は時間的に離れている観測は相関が薄いとしても，直近の観測と関連性が高いだろう．]\n\n患者内の相関構造は，`brm()`関数の`autocor`引数で指定できる（第 [-@sec-autocor-argument] 節）．\n\n例えば，全く構造を仮定しない場合は，[`unstr`](http://paul-buerkner.github.io/brms/reference/unstr.html)を指定する：\n\n```r\nfit3 <- brm(count ~ zAge + zBase * Trt + (1|patient),\n            autocor = ~unstr(time=visit, gr=patient),\n            data = epilepsy, family = poisson())\n```\n\n::: {.callout-caution collapse=\"true\" title=\"フィッティングの出力\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit3 <- brm(count ~ zAge + zBase * Trt + (1|patient),\n            autocor = ~unstr(time=visit, gr=patient),\n            data = epilepsy, family = poisson())\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Argument 'autocor' should be specified within the 'formula' argument.\nSee ?brmsformula for help.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nStart sampling\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.000156 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.56 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 3.895 seconds (Warm-up)\nChain 1:                2.466 seconds (Sampling)\nChain 1:                6.361 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 3.5e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.35 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 3.683 seconds (Warm-up)\nChain 2:                2.587 seconds (Sampling)\nChain 2:                6.27 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 3.4e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.34 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 4.36 seconds (Warm-up)\nChain 3:                2.661 seconds (Sampling)\nChain 3:                7.021 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 3.7e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.37 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 3.937 seconds (Warm-up)\nChain 4:                2.28 seconds (Sampling)\nChain 4:                6.217 seconds (Total)\nChain 4: \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.\nRunning the chains for more iterations may help. See\nhttps://mc-stan.org/misc/warnings.html#bulk-ess\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.\nRunning the chains for more iterations may help. See\nhttps://mc-stan.org/misc/warnings.html#tail-ess\n```\n\n\n:::\n:::\n\n\n\n:::\n\nこのモデルも`fit1`より遥かに当てはまりが良く，`fit2`とほとんど同じ当てはまりの良さが見られる：\n\n::: {.callout-caution collapse=\"true\" title=\"LOO-CV の結果\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloo(fit2,fit3)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Found 61 observations with a pareto_k > 0.7 in model 'fit2'. We\nrecommend to set 'moment_match = TRUE' in order to perform moment matching for\nproblematic observations.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Found 62 observations with a pareto_k > 0.7 in model 'fit3'. We\nrecommend to set 'moment_match = TRUE' in order to perform moment matching for\nproblematic observations.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOutput of model 'fit2':\n\nComputed from 4000 by 236 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -594.9 13.8\np_loo       107.4  7.0\nlooic      1189.8 27.7\n------\nMCSE of elpd_loo is NA.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.4, 1.5]).\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     175   74.2%   169     \n   (0.7, 1]   (bad)       57   24.2%   <NA>    \n   (1, Inf)   (very bad)   4    1.7%   <NA>    \nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'fit3':\n\nComputed from 4000 by 236 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -601.1 14.6\np_loo       112.2  7.8\nlooic      1202.2 29.3\n------\nMCSE of elpd_loo is NA.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.4, 1.6]).\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     174   73.7%   157     \n   (0.7, 1]   (bad)       54   22.9%   <NA>    \n   (1, Inf)   (very bad)   8    3.4%   <NA>    \nSee help('pareto-k-diagnostic') for details.\n\nModel comparisons:\n     elpd_diff se_diff\nfit2  0.0       0.0   \nfit3 -6.2       2.6   \n```\n\n\n:::\n:::\n\n\n\n:::\n\n思ったよりも`fit2`の当てはまりが良いため，Poisson-対数正規混合モデリングを本格的に実施してみることが，次の選択肢になり得る（第 [-@sec-subsec-count-data] 節参照）．\n\n### その他の例\n\nSebastian Weber らにより，[新薬の治験における実際の解析事例をまとめたウェブサイト](https://opensource.nibr.com/bamdd/) が公開されている．^[Statistical Modeling, Causal Inference, and Social Science における [こちらのエントリ](https://statmodeling.stat.columbia.edu/2024/05/08/bamdd/) も参照．]\n\n特に，[13 章](https://opensource.nibr.com/bamdd/src/02h_mmrm.html#brms-implementation)で，同様の経時的繰り返し観測データを扱っているが，ここではカウントデータではなく連続な応用変数が扱われている．\n\n## ランダム効果モデルの正しい使い方\n\n::: {.callout-important appearance=\"simple\" icon=\"false\" title=\"概要\"}\n\n* **ランダム効果モデル** とは，グループ毎に異なる切片項 $\\al_{s[i]}$ を追加し，これにも誤差を仮定してモデルに入れて得る階層モデルである．\n* しかし，$\\al_{s[i]}$ が（ユニットレベルの）説明変数 $x_i$ と相関を持つ場合，推定量の一致性が失われる．これを回避するために，$x_i$ の係数 $\\beta$ にのみ関心がある場合は，固定効果モデルが用いられることも多い．\n* だが，簡単なトリック（$\\al_{s[i]}$ の説明変数に $\\ov{x}_s$ を追加すること）で，推定量の一致性を回復することができる．\n* このトリックを取り入れたランダム効果モデルは，$x_i$ と $\\al_{s[i]}$ に相関がない場合は固定効果モデルと等価な $\\beta$ の推定量を与え，相関がある場合でも，$\\beta$ を一致推定し，各変動切片項 $\\al_{s[i]}$ の構造にも洞察を与えてくれる．\n\n:::\n\nランダム効果モデルは線型混合モデル (Linear Mixed Model; LMM) とも呼ばれる．\n\n> LMM は，母数の共通化によるデータのプーリングと変動効果による標本平均の縮小作用を生み出すことのできるモデルであり，その結果生ずる予測量が EBLUE になる．したがって，EBLUE は，各々の地域の標本平均とプールされた回帰推定量との加重平均になっており，データ数が少ないときには標本平均をプールされた推定量の方向へ縮小することにより，推定精度の改善を図っている．[@久保川達也2006]\n\n### ランダム効果モデル {#sec-RF}\n\n**ランダム効果** は，変動する切片項と呼んだ方がわかりやすい [@Bafumi-Gelman2007] と言われるように，サブグループ毎に異なる切片項のことである．^[すなわち，ある確率変数の従う項と考えており，**変量効果** とも呼ばれる．一方で未知母数とみなす場合は **母数効果** ともいう [@久保川達也2006]．]\n\nユニット（個人などの最小単位）レベルの回帰式を書き下すと，グループ選択関数 $s:[n]\\to[S]\\;(S\\le n)$ を通じて，\n$$\ny_i=\\al_{s[i]}+\\beta x_i+\\ep_i,\\qquad i\\in[n],\n$$ {#eq-stage-1}\nというようになる．\n\nこれは，確率変数 $\\al_{s[i]}$ の平均を $\\al_0$ とすると，グループレベルの回帰式\n$$\n\\al_s=\\al_0+\\eta_s,\\qquad s\\in[S]\n$$ {#eq-stage-2}\nが背後にある **階層モデル** (multilevel / hierarchical model) だとみなすこともできる．\n\n### 説明変数との相関の問題\n\n#### 問題の所在\n\nランダム効果では，ユニットレベルの説明変数 $x_i$ と変動切片項 $\\al_{s[i]}$ が相関を持たないという仮定が Gauss-Markov の定理の仮定に等価になるため，これが違反されると推定量の不偏性・一致性が約束されず，推定量の分散も大きくなる．^[[@Hansen2022 p.333] 第12.3節，[@Bafumi-Gelman2007 p.3], [@Hansen2022 p.604]，[@Gardiner+2009 p.228]．]\n\n::: {.callout-tip appearance=\"simple\" icon=\"false\" title=\"Gauss-Markov の仮定\"}\n\nユニットレベル回帰式\n$$\ny_i=\\al_{s[i]}+\\beta x_i+\\ep_i,\\qquad i\\in[n],\\tag{1}\n$$\nにおいて，ユニットレベルの説明変数 $x_i$ と変動切片項 $\\al_{s[i]}$ が相関を持たないこと．\n\n:::\n\n実際，ランダム効果モデルの階層構造を，([-@eq-stage-2]) を ([-@eq-stage-1]) に代入することで一つの式にまとめると\n$$\ny_i=\\al_0+\\beta x_i+\\underbrace{\\ep_i'}_{\\ep_i+\\eta_{s[i]}}\n$$ {#eq-RF}\nを得る．\n\nこのような誤差項の構造 $e_{it}=\\al_i+\\ep_{it}$ を **一元配置モデル** (one-way error component model) ともいう [@Hansen2022 p.600], [@久保川達也2006 p.155]．\n\n$x_i$ と $\\al_{s[i]}$ に相関がある場合，$x_i$ と $\\eta_s$ にも相関があるため，結果として ([-@eq-RF]) では説明変数と誤差 $\\ep_i'$ に相関が生じてしまう．これは計量経済学では **内生性** (endogeneity) の問題と呼ばれているものに他ならない．\n\n#### 業界の現状：母数効果モデル\n\nそのため，ランダム効果モデルは避けられる傾向にあり，切片項 $\\al_{s[i]}\\equiv\\al_0$ は変動しないとし，グループレベルの効果を無視してモデリングすることも多い：\n$$\ny_i=\\al_0+\\beta x_i+\\ep_i.\n$$\nこのことを **完全プーリングモデル** (complete pooling model) または母数効果モデルと呼び，ランダム効果モデルを **部分プーリングモデル** (partial pooling model) と呼んで対比させることがある．^[[@Bafumi-Gelman2007 p.5] や [@久保川達也2006 p.141] も参照．[@Cunningham21-Mixtape] は pooled OLS と呼んでいる．]\n\n周辺モデル (marginal model) や **母平均モデル** (population-average model) とも呼ばれる [@Gardiner+2009 p.228]．\n\n実際，これ以上の仮定を置かず，ランダム効果は局外母数として（**母数効果**ともいう）一般化推定方程式の方法（第 [-@sec-GEE] 節）によれば，$\\beta$ の不偏推定が可能である．\n\nリンク関数 $g$ を通じた非線型モデル\n$$\ng(\\E[y_i|x_i])=\\beta x_i\n$$\nであっても，指数型分布族を仮定すれば，$\\beta$ の一致推定が可能である．\n\nだが，切片項の変動を消してしまうことで，回帰係数 $\\beta$ の推定に対する縮小効果（第 [-@sec-shrinkage-estimation] 節）が得られないという欠点もあり，小地域推定などにおいては $\\al_{s[i]}$ を確率変数とみなす積極的理由もある．この点については [@久保川達也2006] も参照．\n\n#### 固定効果モデルという解決 {#sec-fixed-effects-model}\n\n問題を起こさずに，しかしながらグループレベルの効果をモデリングしたい場合，\n$$\ny_i=\\al_{s[i]}^{\\text{unmodeled}}+\\beta x_i+\\ep_i\n$$\nとして，グループ毎に変動する切片項 $\\al_{s[i]}^{\\text{unmodeled}}$ を許すが，この変数自体にモデルは仮定しない，とすることもできる．\n\nしたがってグループ毎に別々の回帰分析を実行し，別々の切片 $\\al_{s[i]}^{\\text{unmodeled}}$ を得て，$\\beta$ の値はこれらのグループの間で適切に重みづけて最終的な推定値としているに等しい．\n\nすなわち，グループの数だけ，グループへの所属を表す２値変数 $1_{\\Brace{s[i]=s}}$ を導入し，$S$ 個の項 $\\sum_{s=1}^S1_{\\Brace{s[i]=s}}\\al_{s[i]}^{\\text{unmodeled}}$ を説明変数に加えて回帰分析を行うことに等しい．\n\nベイズ的には，変動係数の場合は更なる構造\n$$\n\\al_s=\\al_0+\\eta_s,\\qquad s\\in[S],\n$$\nに基づきグループレベルにばらつく確率構造が仮定されているのと対照的に，improper な一様事前分布\n$$\n\\al_s^{\\text{unmodeled}}\\iidsim\\rN(\\al_0,\\infty)\n$$\nを仮定した場合が固定効果モデルであると理解される [@BDA p.383]．\n\nまた群内平均を引いた値 $y_i-\\ov{y}_{s[i]}$ を目的変数として，説明変数 $x_i-\\ov{x}_{s[i]}$ により回帰分析を行うこととも等価である．この変換により $\\al_{s[i]}^{\\text{unmodeled}}$ が消去されると考えられるのである．\n\n::: {.callout-caution title=\"固定効果モデルの別名\" icon=\"false\" appearance=\"simple\"}\n\n* [@Hansen2022] をはじめ，計量経済学では fixed effects model と呼ばれる．^[特にパネルデータの文脈では within estimator ともいう [@Cunningham21-Mixtape]．]\n* [@Bafumi-Gelman2007] は unmodeled varying intercept と呼んでいる．\n* least squares dummy variable regression とも呼べる．^[[@Bafumi-Gelman2007 p.5]，[@Hansen2022 p.609] 17.11節 など．狭義では，fixed effects model は within transformation を行い，グループ間の影響を引いたあとに回帰を実行する……という手続きを指すこともあるが，２つは等価な結果を生む．詳しくは [@Cunningham21-Mixtape] なども参照．]\n\n:::\n\n### 固定効果 vs. 変量効果\n\n::: {.callout-caution title=\"利点\" icon=\"false\" appearance=\"simple\"}\n\n$x_i$ と $\\al_{s[i]}$ が相関を持ち得る場合も，固定効果モデルでは問題が生じない．^[[@Hansen2022 p.624] 17.25節．]\n\n:::\n\n::: {.callout-caution title=\"問題点\" icon=\"false\" appearance=\"simple\"}\n\n異なるグループのデータが相互作用する機構がランダム効果モデルに比べて貧しい．\n\n例えばランダム効果モデルを用いた場合，外れ値グループが存在するなどノイズの大きなデータに対しても，$\\eta_s$ を通じて緩やかに情報が伝達され，$\\beta$ の値は平均へ縮小されて推定される（第 [-@sec-shrinkage-estimation] 節）．固定効果モデルではそのような頑健性を持たない [@Bafumi-Gelman2007 pp.4-5]．\n\n:::\n\n固定効果モデルは $\\beta$ （のみ）に関心がある場合，$\\al_{s[i]}$ と $x_i$ の相関の存在に対してロバストな推定法として有用であり，その理由で計量経済学（特に線型パネルデータ）では主流の推定手法となっている．^[[@Hansen2022 p.624]，[@Bafumi-Gelman2007 p.6]．]\n\n実際，$\\al_{s[i]}$ と $x_i$ が無相関であるとき，変量効果モデルと固定効果モデルは $\\beta$ に関しては等価な推定量を与える．\n\n> Current econometric practice is to prefer robustness over efficiency. Consequently, current practice is (nearly uniformly) to use the fixed effects estmimator for linear panel data models. [@Hansen2022 p.624]\n\n逆に言えば，固定効果モデルは $x_i$ と $\\al_{s[i]}$ の構造のモデリングを放棄したモデリング法であり，各 $\\al_{s[i]}$ の値にも興味がある場合，または $\\beta$ のより精度の高い推定が実行したい場合には，やはり $\\al_{s[i]}$ の誤差と相関構造もモデルに取り入れたランダム効果モデルを用いたいということになる．\n\n### ランダム効果モデルにおける相関のモデリング\n\n$x_i$ と $\\al_{s[i]}$ が相関を持つ場合に一致推定が保証されないことがランダム効果モデルの欠陥だと述べたが，実はこれは簡単な方法で解決できる．\n\n$x_i$ と $\\al_{s[i]}$ との相関は，欠落変数が存在するため，と考えることができる．\n\nそしてこの相関は，説明変数の平均 $\\ov{x}_s$ を変動する切片項 $\\al_s$ の説明変数として追加することで除去できる：^[[@Bafumi-Gelman2007 p.6]．]\n\n$$\ny_i=\\al_{s[i]}+\\beta x_i+\\ep_i\n$$\n$$\n\\al_s=\\al_0+\\al_1\\ov{x}_s+\\eta_s\n$$\n\nこれにより，Gauss-Markov の仮定（外生性）が回復される．\n\n[@Bafumi-Gelman2007 pp.7-9] にシミュレーションによる検証が掲載されている．\n\n> Practitioners can get around this problem by taking advantage of the **multilevel structure** of their regression equation. [@Bafumi-Gelman2007 p.12]\n\n### 第三の名前：混合効果モデル\n\n以上，解説してきたランダム効果モデル／変量効果モデルであるが，**混合効果モデル** とも呼ばれる．^[[@Hubbard+2010] では両方の名前で呼んでいる．]\n\n何を言っているのかわからないかもしれないが，式 ([-@eq-stage-1])\n$$\ny_i=\\al_{s[i]}+\\beta x_i+\\ep_i,\\qquad i\\in[n],\\tag{1}\n$$\nにおいて，$\\al_{s[i]}$ がランダム効果であるが，回帰係数 $\\beta$ を **固定効果** とも呼ぶことがあるのである．\n\nそしてこう見ると全体として固定効果と変量効果が同居した **混合（効果）モデル** とも呼べそうである．\n\n現代的には，必要ならば $\\beta$ を確率変数とみなしても良いだろうが，慣習的にそう呼ぶため，これに従わざるを得ない，というのが [@Hansen2022 p.625] などを見る限り共通了解であるようである．\n\nこれが計量経済学における固定効果モデル（第 [-@sec-fixed-effects-model] 節）の名前の由来である．^[[@Hansen2022 p.625] 17.25節．疫学・生物統計学では，実験計画法でしか「固定効果」「変量効果モデル」とは言わない，という認識であることも筆者は聞いたことがある．] 実際，固定効果モデルは，たしかに（ユニットレベルでの回帰係数という意味での）「固定効果」を表す変数しか含んでいない（少なくとも見た目上は）．\n\n::: {.callout-caution title=\"線型混合モデルの別名\" icon=\"false\" appearance=\"simple\"}\n\n式 ([-@eq-stage-1])\n$$\ny_i=\\al_{s[i]}+\\beta x_i+\\ep_i,\\qquad i\\in[n],\\tag{1}\n$$\nで定義されるモデルは，[@Chung+2013] によると次のような複数の名前を持つ：\n\n* 線型混合モデル (linear mixed models) [@Kincaid2005]\n* 階層モデル (hierarchical models)\n* マルチレベル線型モデル (multilevel linear models)\n* 混合効果モデル (mixed-effects models) [@Chung+2015]\n* ランダム効果モデル (random effects model) [@Hubbard+2010] や [@Bafumi-Gelman2007]．\n* 分散成分モデル (variance component model)^[$\\V[\\eta_s]$ はブロック行列の構造を持つためこう呼ばれる．[@久保川達也2006 p.141] でも LMM と併記されている．]\n\n:::\n\n詳しくは [第6章 @Gelman2005 pp.20-] も参照．\n\n### GEE との違い {#sec-GEE}\n\n**一般化推定方程式** (GEE: Generalized Estimating Equation) では，ランダム効果モデルにおける階層的な議論を全て「局外母数」として捨象し，母数 $\\beta$ の推定に集中する見方をする．\n\n::: {.callout-caution title=\"GEE との違い\" icon=\"false\"}\n\n1. [回帰式が違う]{.underline}\n\n      線型の場合の GEE は\n      $$\n      Y_{it}=\\al+\\beta_1x_{1,i,t}+\\cdots+\\beta_px_{p,i,t}\n      $$\n      とも表され，ランダムな切片項というものは見当たらない．その代わり，グループ間の影響は相関係数行列としてモデル化を行う．ランダム効果モデルでは，この相関構造をランダムな切片項を追加することで表現し，回帰式を複数立てることでモデルを表現する．\n\n2. [推定目標が違う]{.underline}\n\n      GEE は population average model でよく用いられる [@Hubbard+2010] ように，あくまで応答 $Y_{it}$ の平均の不偏推定が目標であり，共分散構造はいわば局外母数である．一方，混合効果モデルは，その階層モデルとしての性質の通り，平均構造と分散構造のいずれも推定対象として扱う志向性がある．\n\n3. [推定方法が違う]{.underline}\n\n      混合効果モデルは主に最尤法により推定される [@Hubbard+2010]．GEE はモーメント法により推定され，最尤法ベースではないため，完全にランダムとは言えない欠測がある場合は弱く，欠測データに対しては IPW などの方法が用いられる．\n\n:::\n\nGEE にとって相関構造は局外母数であり，正確な特定は目的に含まれない．この意味で GEE の相関係数⾏列におく仮定は「間違えていてもよい便宜的な仮定」であるため，**作業相関係数行列** (working correlation coefficient matrix) とも呼ばれる．相関構造を誤特定していても，平均構造は一致推定が可能であり，ロバストである．両方の特定に成功した場合はセミパラメトリック有効性が達成される．\n\n一方で混合効果モデルは，階層モデルとして平均構造と分散構造のいずれにも明示的な仮定をおくため，片方（例えば共分散構造）の特定を間違えていた場合，もう片方の解釈性が失われる，というリスクがあると論じることができる．特に [@Hubbard+2010] に見られる論調である．\n\nしかし小地域推定や，「子供の身長の成長曲線の描画」が主な研究目的である場合など，ユニットの平均効果ではなく個別効果に注目したい場合には混合効果モデルの方が適していることになる [@Gardiner+2009]．実際，モデルの特定に成功していれば，いずれのパラメータも最尤推定されるため，一致性を持つ．\n\n従って，モデル選択において用いられる基準も違う．GEE における作業相関係数行列と説明変数の選択には QIC (Quasi-likelihood Information Criterion) が，混合効果モデルには AIC や BIC （または cAIC や mAIC [@Vaida-Blanchard2005]）が用いられる [@Gardiner+2009 p.228]．\n\n<!--\n\n本データを扱った論文 [@Thall-Vail1990] では，[@Liang-Zeger1986] の一般化推定方程式の枠組みに則り，共分散の構造にどのようなパラメトリック分布を仮定するのが良いかが，漸近論の観点から議論されている．\n\n-->\n\n### ベイズ混合効果モデルという光……？\n\nしかし，結局ベイズ統計学の立場からは，２つの違いはほとんど重要ではなく，混合効果モデルを推定した後に，周辺化をして平均構造に関する marginal estimator を構成すれば，GEE の代用になっているのではないか？\n\n計算機の性能と，計算統計手法の発展が目まぐるしい現代にて，過去の議論を踏襲しすぎることは，問題の本質を誤るということもあるのだろう．\n\nということで，以上議論したグループレベル構造を持ったデータに対する２階の階層モデルを，本稿では「混合効果モデル」と呼ぶことにする．\n\nこの節はこれで終わり．\n\n## 混合効果モデリングのテクニック集\n\n::: {.callout-important appearance=\"simple\" icon=\"false\" title=\"概要\"}\n\n* 混合効果モデルの推定において，グループレベル変動 $\\al_{s[i]}$ の共分散行列 $\\V[\\eta_s]$ の推定が不安定になり得る．特に，グループ数 $S$ が小さい場合に顕著である．\n* カウントデータの Poisson モデルでは，「観測レベルのランダム効果」を追加することで，実質的に Poisson-対数正規混合モデリングを実行できる．\n\n:::\n\n### グループレベル分散の推定 {#sec-group-level-variance-estimation}\n\n#### 問題\n\n混合効果モデル（階層モデル）\n$$\ny_i=\\al_{s[i]}+\\beta x_i+\\ep_i,\\qquad i\\in[n],\\tag{1}\n$$\nの推定において，特にグループ数 $S$ が小さい場合，グループレベルの変動切片項 $\\al_{s[i]}$ の共分散行列 $\\V[\\eta_s]$ の推定が不安定になったり，分散が負の値をとったりするという問題点が古くからある [@Harville1977]．^[[@Laird-Ware1982]，[@Chung+2013]，[@Chung+2015]，[Statistical Modeling, Causal Inference, and Social Science ブログ 6/2/2023](https://statmodeling.stat.columbia.edu/2023/06/02/blme-bayesian-linear-mixed-effects-models/)．]\n\n変量効果 $\\eta_s$ を $\\eta_s\\iidsim(0,\\sigma^2_s)$，誤差を $\\ep_i\\iidsim(0,\\sigma^2_e)$ とすると，この $\\V[\\eta_s]$ は次の形をもち，グループ間の相関構造のモデリングを一手に引き受けている：\n$$\n\\V[\\eta_{s}]=\\sigma^2_sJ_{n_s}+\\sigma_e^2I_{n_s},\\qquad J_{n_s}:=\\b{1}_{n_s}\\b{1}_{n_s}^\\top.\n$$\n\nEM アルゴリズムが提案されたばかりの頃 [@Laird-Ware1982] では，共分散構造にパラメトリックな仮定をおいていたが，現代ではこれを取り去った最尤推定法・ベイズ推定法が主流である．\n\n#### 退化しない共分散行列推定\n\nしかし，最尤推定法と，一定の事前分布を仮定したベイズ MAP 推定法では，推定された共分散行列が退化してしまったり，分散が負の値を取ってしまうことがある．\n\n打ち切り推定量 [@Kubokawa-Srivastava1999], [@Kubokawa2000] なども提案されているが，ベイズでは Wishart 事前分布を仮定することでこれが回避される [@Chung+2015]．^[逆 Wishart ではないらしい [@Chung+2015]．] これは最尤法の文脈では，penalized likelihood と等価になる [@Chung+2013]．\n\nモデルのサイズによっては，完全なベイズ推定を実行することが難しく，一部は等価な頻度論的な方法や近似を用いることもある．その際，最適化ソルバーの収束を速めるために，共分散構造に（データや計画とは無関係に）パラメトリックモデルを仮定してしまうこともある [@Kincaid2005]．\n\n### 係数の縮小推定 {#sec-shrinkage-estimation}\n\n分散 $\\V[\\eta_s]$ を推定して分散比 $\\rho:=\\sigma_v^2/\\sigma_e^2$ の推定量 $\\wh{\\rho}$ を得て，これを最良線型不偏推定量 (BLUE) $\\wh{\\beta}$ に代入して得られる，グループごとの $y_s$ の推定量に\n$$\n\\wh{y}_s:=\\frac{\\wh{\\rho}n_s}{1+\\wh{\\rho}n_s}\\ov{y}_s+\\frac{1}{1+\\wh{\\rho}n_s}\\ov{x}_s^\\top\\wt{\\beta}(\\wh{\\rho})\n$$\nというものがあり，これを **経験 BLUE** という [@久保川達也2006 p.143]．\n\nこれは，各グループ $s\\in[S]$ における値 $y_s$ を，単なる経験平均 $\\ov{y}_s$ ではなく，全データプールから得られる推定量 $\\ov{x}_s^\\top\\wt{\\beta}(\\wh{\\rho})$ で補正した推定量になっている．\n\nこのことにより，各グループ $s\\in[S]$ のデータ数が少なく，経験平均 $\\ov{y}_s$ では分散が大きくなってしまう場合でも，安定した推定量を得ることができる．\n\n縮小推定は小地域推定 [@Battese+1988] に応用を持つ．例えば $s\\in[S]$ をアメリカ合衆国の各州とし，投票行動のデータに応用した例が [@Gelman2014] にある．\n\nこのように，変量効果 $\\al_{s[i]}$ を追加したモデリングを実行することにより，グループごとの被説明変数を縮小推定することができる．\n\n#### 経験ベイズ {#sec-empirical-bayes}\n\n縮小推定の効用は初め，経験ベイズの枠組みで説明された．\n\n> 以上の考え方は，経験ベイズの枠組みで [@Efron-Morris1975] の一連の論文の中で示されてきたものであり，ベイズ的アプローチの現実的な有用性は基本的には上述の考え方に基づいている．\n\nそもそも１元配置混合線型モデルは\n$$\ny_{ij}=\\theta_{ij}+e_{ij},\\qquad \\theta_{ij}=x_{ij}^\\top\\beta+v_i\n$$\nとも理解できる．これは階層モデル\n$$\ny_{ij}\\sim\\rN(\\theta_{ij},\\sigma^2_e),\\qquad\\theta_{ij}\\sim\\rN(x_{ij}^\\top\\beta,\\sigma_v^2)\n$$\nとも見れる．\n\n$\\beta,\\sigma^2_v,\\sigma^2_e$ を未知母数として扱った場合を **経験ベイズモデル**，変量として扱って更なる分布を仮定した場合を（狭義の） **階層ベイズ** ともいう [@久保川達也2006 p.155]．\n\n### カウントデータ過分散へのお手軽対処法 {#sec-subsec-count-data}\n\nこれはカウントデータのモデリング限定のテクニックである．\n\nカウントデータも，一般化線型（混合）モデルの範疇で扱うことができるため，リンク関数 $g$ を通じてほとんど同等の扱いが可能である．\n\n#### 負の二項分布によるモデリング\n\nカウントデータの基本は Poisson 分布であろうが，過分散を考慮するために負の二項分布でモデリングすることもできる．[17.2節 @BDA] なども参照．\n\n負の二項分布は例えばマーケティングにおいて，顧客の購買回数をモデル化する際に用いられる [@森岡-今西16-確率思考の戦略論]．\n\nこの行為は，Poisson 分布の Gamma 分布による混合分布族を用いた，混合モデリングを行っているとみなせる：\n\n::: {.callout-tip title=\"命題\" icon=\"false\"}\n\nPoisson 分布 $\\Pois(\\theta)$ の $\\GAMMA(\\al,\\nu)$-混合は負の二項分布 $\\NB\\paren{\\nu,\\frac{\\al}{\\al+1}}$ になる．\n\nただし，負の二項分布 $\\NB(\\nu,p)$ は，次の確率質量関数 $p(x;\\nu,p)$ が定める $\\N$ 上の確率分布である：\n$$\np(x;\\nu,p)=\\comb{x+\\nu-1}{x}p^\\nu(1-p)^x.\n$$\n\n:::\n\n::: {.callout-note title=\"証明\" collapse=\"true\" icon=\"false\"}\n\n確率分布の変換則より，次のように計算できる：\n\n\\begin{align*}\n  p(x)&=\\int_{\\R_+}\\frac{\\theta^x}{x!}e^{-\\theta}\\frac{1}{\\Gamma(\\nu)}\\al^\\nu\\theta^{\\nu-1}e^{-\\al\\theta}d\\theta\\\\\n  &=\\frac{\\al^\\nu}{x!\\Gamma(\\nu)}\\int_{\\R_+}\\theta^{x+\\nu-1}e^{-(\\al+1)\\theta}d\\theta\\\\\n  &=\\frac{\\al^\\nu}{x!\\Gamma(\\nu)}\\frac{\\Gamma(x+\\nu)}{(\\al+1)^{x+\\nu}}\\\\\n  &=\\comb{\\nu+x-1}{x}\\paren{\\frac{1}{\\al+1}}^x\\paren{\\frac{\\al}{\\al+1}}^\\nu.\n\\end{align*}\n\nこの最右辺は，たしかに負の二項分布の質量関数である．\n\nこの証明方法と，Gamma 分布については次の記事を参照：\n\n\n\n```{=html}\n<div class=\"article-card-container\">\n  <div class=\"article-card\">\n    <a href=\"https://162348.github.io/posts/2023/Probability/Beta-Gamma.html\" target=\"_blank\">\n      <img src=\"https://162348.github.io/posts/2023/Probability/Beta-Gamma_files/figure-html/cell-4-output-1.png\" alt=\"Article Image\" class=\"article-image\">\n      <div class=\"article-content\">\n        <h3 class=\"article-title\">確率測度の変換則</h3>\n        <p class=\"article-description\">Gamma 分布とBeta 分布を例に</p>\n      </div>\n    </a>\n  </div>\n</div>\n```\n\n\n\n:::\n\nこれは\n$$\ny_{it}\\sim\\Pois(\\theta)\n$$\n$$\n\\theta\\sim\\GAMMA(\\al,\\nu)\n$$\nという Gamma 分布を仮定した経験ベイズモデル（第 [-@sec-empirical-bayes] 節）に当たる．\n\nGamma 分布は Poisson 分布の共役事前分布であるため計算が容易であり，早くから質病地図の作成などにも用いられていた [@Clayton-Kaldor1987], [@丹後俊郎1988]．\n\n#### Poisson-対数正規混合によるモデリング\n\nPoisson 回帰\n\n$$\n\\begin{align*} y_{it} & \\sim \\operatorname{Pois}(\\lambda_{s[i]}) \\\\ \\log(\\lambda_{s[i]}) & = \\al_i + \\eta_{it} \\\\ \\eta_{it} & \\sim \\operatorname{N}(0, \\sigma). \\end{align*}\n$$\n\nを考えると，各 $y_{it}$ を，（グループ毎に条件付ければ）Poisson 分布の対数正規分布による混合分布を用いてモデル化していることにあたる．\n\nこの，Poisson-対数正規分布族は，[@Bulmer1974] により生物種の個体数分布のモデリングで，過分散を説明するために用いられている．\n\nすなわち，第 [-@sec-example] 節のモデルの比較 [-@sec-model-comparison] で扱った，**観測レベルランダム効果** (OLRE: Observation-level Random Effects) の方法は，[観測毎に $\\eta_{it}$ というランダム切片項を追加するだけで，本質的には Poisson-対数正規混合モデリングを実施する]{.underline} という，いわばハックのような使い方である．^[[Solomon Kurtz (2021)](https://solomonkurz.netlify.app/blog/2021-07-12-got-overdispersion-try-observation-level-random-effects-with-the-poisson-lognormal-mixture/#negative-binomial-counts) による解説，[RPubs](https://rpubs.com/INBOstats/OLRE) も参照．]\n\n今回はモデル比較の結果が良かったため，本格的に対数正規混合を実施してみるのも良いかもしれない．\n\n### 変量係数モデルによる非線型モデリング\n\n::: {.callout-caution icon=\"false\" title=\"混合モデルの種々の拡張\" collapse=\"true\" appearance=\"simple\"}\n\n前節 [-@sec-subsec-count-data] では，カウントデータに適用するための一般化線型混合モデルをみた．\n\n[@久保川達也2006] では，ここまで考慮した１元配置混合線型モデルの拡張をいくつか紹介している：\n\n* 各グループ $s\\in[S]$ の中でもいくつかのクラスターに分けられる場合，**２元配置混合モデル** が考えられる：\n  $$\n  y_{ijk}=x_{ijk}^\\top\\beta+v_i+u_{ij}+e_{ijk}.\n  $$\n* 誤差分散が一定であるという仮定が怪しい場合，**変動分散モデル** が考えられる．これは，グループ内の分散を $e_{ij}|\\sigma_i^2\\sim\\rN(0,\\sigma_i^2)$ とし，$\\sigma_i$ をグループ内で同一の分布に従う i.i.d. と仮定した階層モデルをいう．\n* 係数 $\\beta$ にもモデルを仮定した階層モデルは **変量係数モデル** ともいう：\n  $$\n  \\beta_i=W_i\\al+v_i.\n  $$\n  州ごとの，収入因子が投票行動に与える影響の差を突き止めた [@Gelman2014] ではこの変量係数モデルを用いている．\n\n:::\n\n#### 例：投票行動の州ごとの違い\n\n[@Gelman2014] では州ごとの投票行動の違いを説明するために，まずは次のロジスティック混合モデルを考えている：\n$$\n\\operatorname{Pr}(y_i=1)=\\operatorname{logit}^{-1}(\\alpha_{s[i]}+x_i\\beta)\n$$\n$$\n\\al_s=W_s^\\top\\gamma+\\ep_s,\\qquad\\ep_s\\iidsim\\rN(0,\\sigma^2_\\al).\n$$\n\n::: {.callout-tip appearance=\"simple\" icon=\"false\" collapse=\"true\" title=\"各変数の説明\"}\n\n* $y_i\\in\\{0,1\\}$ は共和党に投票したか，民主党に投票したかを表す２値変数．\n* $x_i\\in\\{\\pm2,\\pm1,0\\}$ は収入のレベルを５段階で表す離散変数．\n* $W_j$ は各州の共変量のベクトル．\n\n:::\n\nしかしこのままではモデルの当てはまりが良くなかった．これは州ごとに収入が投票に与える影響が異なるためであった．これを考慮するために，[@Gelman2014] は変量係数モデルを用いた．\n\n#### 混合モデルの変量係数モデル化\n\n$\\beta$ を州ごとに変化させ，これに\n$$\n\\beta_s=W_s^\\top\\gamma'+\\ep'_s,\\qquad \\ep'_s\\iidsim\\rN(0,\\sigma^2_\\beta),\n$$\nというモデルをおく．\n\nこれにより，州ごとに変化する収入-投票関係をモデリングできる．\n\n#### 非線型モデル化\n\nこれに加えて，$\\beta_s$ を収入カテゴリのアイテム $x_i\\in\\{\\pm2,\\pm1,0\\}$ ごとに変化させることも考えられる．\n\nこれは値も持つダミー変数\n$$\n\\b{x}_i^j=(j-3)1_{\\Brace{x_i=j}},\\qquad j\\in\\{1,2,3,4,5\\},\n$$\nを成分にもつ $\\b{x}_i\\in\\bZ^5$ を用いて，\n$$\n\\operatorname{Pr}(y_i=1)=\\operatorname{logit}^{-1}(\\alpha_{s[i]}+\\b{x}_i^\\top\\b{\\beta}_{s[i]})\n$$ {#eq-nonlinear-logistic-model}\nというモデルを考えることにあたる．\n\nこの小さな変更により，非線型な関係もモデリングできるようになる．\n\n#### 多重共線型性の霧消\n\nこのようなトリックが可能な理由は，ベイズ回帰においては多重線型性が問題にならないためである．\n\nモデル ([-@eq-nonlinear-logistic-model]) では，３通りで収入が説明変数に入っている：\n\n1. 各収入カテゴリのダミー変数 $1_{\\Brace{x_i=j}}$ として\n2. 収入カテゴリの値 $\\b{x}_i^j$ として．\n3. 州ごとの収入として $W_s$ にも入っている．\n\nこのことに気づけただろうか？\n\n頻度論的に回帰分析を実行していたならば，このような多重共線性は問題になっていただろうが，階層ベイズモデリングにおいては有用なトリックとして積極的に活用することができる．\n\n## `brms`の実装\n\n[`brm` 関数](https://paul-buerkner.github.io/brms/reference/brm.html)（コードは [こちら](https://github.com/paul-buerkner/brms/blob/master/R/brm.R)）の実装を調べる．\n\n::: {.callout-important appearance=\"simple\" icon=\"false\"}\n\n* [`brms`](https://github.com/paul-buerkner/brms/blob/master/R/brm.R#L436)\n\nStan コードを扱っている関数は [`.stancode()`](https://github.com/paul-buerkner/brms/blob/d42adcd22f5af441870038b1d78ad4d9408f344f/R/stancode.R) であった．最終的に，[`.compile_model_rstan()`](https://github.com/paul-buerkner/brms/blob/d42adcd22f5af441870038b1d78ad4d9408f344f/R/backends.R#L67) と [`.fit_model_rstan()`](https://github.com/paul-buerkner/brms/blob/d42adcd22f5af441870038b1d78ad4d9408f344f/R/backends.R#L145) が呼ばれるようになっている．\n\n* [`.standata`](https://github.com/paul-buerkner/brms/blob/d42adcd22f5af441870038b1d78ad4d9408f344f/R/standata.R#L109)\n\n:::\n\n### 事前分布\n\n[`brm`関数](https://paul-buerkner.github.io/brms/reference/brm.html) では，デフォルトでは無情報事前分布が用いられる．\n\n> Default priors are chosen to be non or very weakly informative so that their influence on the results will be negligible and you usually don't have to worry about them. However, after getting more familiar with Bayesian statistics, I recommend you to start thinking about reasonable informative priors for your model parameters: Nearly always, there is at least some prior information available that can be used to improve your inference.<br>[brm(): Fit Bayesian Generalized (Non-)Linear Multivariate Multilevel Models](https://paul-buerkner.github.io/brms/reference/brm.html)\n\n### 回帰式\n\n`brm()`関数の第一引数は，`validate_formula`関数に渡される．\n\nこの関数は S3 のメソッドのディスパッチを用いて実装されており，`brmsformula`オブジェクトに対しては，`validate_formula.brmsformula`関数が呼び出される．\n\nここでは`autocor`引数が引かれている場合，出力の`formula`属性に追加される：^[[Line 1363](https://github.com/paul-buerkner/brms/blob/deb56d02d0f897422a4d1d5a43d18e99400f80a0/R/brmsformula.R#L1363)．]\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit3$formula\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ncount ~ zAge + zBase * Trt + (1 | patient) \nautocor ~ unstr(time = visit, gr = patient)\n```\n\n\n:::\n:::\n\n\n\nなお，`brmsformula`オブジェクトのコンストラクタは [`brmsformula()`関数](http://paul-buerkner.github.io/brms/reference/brmsformula.html) である．これは，R の`formula`オブジェクトを通じて，階層モデルを定義できるようになっている（実装は[リスト](../R/R3.qmd)）．\n\n### 共分散構造 {#sec-ubsubsec-covariance-structure}\n\n共分散構造は２つの観点から，`brmsformula`オブジェクトから自動的に指定される．\n\n１つ目がグルーピング構造（共分散行列のブロック構造）であり，これは[`gr`関数](https://paul-buerkner.github.io/brms/reference/gr.html) が使用される．\n\n２つ目がグループ内の相関構造であり，これは`brm()`関数の`autocor`引数を用いる．\n\n#### `gr`関数\n\nこの関数は`brm`関数の第一引数として与えられたモデル定義式から，暗黙のうちに内部で呼び出される．\n\n例えば，回帰式に`(1|patient)`が含まれていた場合，`gr(patient)`が呼び出される．\n\n共分散構造におく仮定について，重要なデフォルト設定が２つある：\n\n::: {.callout-tip appearance=\"simple\" icon=\"false\"}\n* グループ間の相関構造は想定されている：`cor=True`．\n\n    > If `TRUE` (the default), group-level terms will be modelled as correlated.<br>[gr(): Set up basic grouping terms in brms](https://paul-buerkner.github.io/brms/reference/gr.html)\n\n* 一方で，グループ内の相関構造は想定されておらず，独立とされている．具体的に指定したい場合は引数`cov`を用いる．\n\n    > By default, levels of the same grouping factor are modeled as independent of each other.<br>[gr(): Set up basic grouping terms in brms](https://paul-buerkner.github.io/brms/reference/gr.html)\n\nすなわち，$\\V[\\eta_s]$ には一切仮定が置かれておらず（第 [-@sec-group-level-variance-estimation] 節），一方で $\\{\\ep_{it}\\}_{t=1}^T$ は互いに独立とされている．\n:::\n\nまた，この二階層目の分布族（第 [-@sec-RF] 節での $\\al_i$ と $\\eta_{it}$）は，分散共分散行列 $\\V[\\eta_s]$ を持った正規分布がデフォルトで，現状他の分布族は指定できないでいる．\n\n> dist: Name of the distribution of the group-level effects. Currently \"gaussian\" is the only option.<br>[gr(): Set up basic grouping terms in brms](https://paul-buerkner.github.io/brms/reference/gr.html)\n\n#### `autocor`引数 {#sec-autocor-argument}\n\n`brm()`関数には，[`autocor`引数](http://paul-buerkner.github.io/brms/reference/autocor-terms.html) が用意されている．\n\n`gr()`のデフォルト値では独立とされていたグループ内の相関構造を，具体的に指定するのに用いられる．\n\n::: {.callout-tip appearance=\"simple\" icon=\"false\"}\n* `unstr`：一才の仮定を置かない．\n* `AR`：一次の自己相関構造．\n:::\n\n### 推論エンジン\n\n[`brm`関数](https://paul-buerkner.github.io/brms/reference/brm.html) は，Stan による MCMC サンプリングを通じて，事後分布を計算する．\n\n## 文献紹介 {.appendix}\n\nここでは計量経済学の呼称に従い，固定効果モデルと変量効果モデルと呼んだが，同じモデルを母数モデル (fixed effect model) と変量モデル (random effect model) と呼んだりもする [@足立浩平2000]．\n\n## Acknowledgements {.appendix}\n\nI would like to extend my gratitude to Robert Long, who kindly shared me the knowledge about the covariance structure implicitly defined via `brms` formula on [this Cross Validated post](https://stats.stackexchange.com/questions/649358/the-default-covariance-structure-implicitly-assumed-in-the-brms-formula/650015#650015). His insights were instrumental in enhancing this work.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}