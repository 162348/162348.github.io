{
  "hash": "a70337bc614ca19c85bbb2f072e5dc17",
  "result": {
    "markdown": "---\ntitle: \"ベイズ計算とは何か | About Bayesian Computation\"\nauthor: \"Hirofumi Shiba\"\ndate: 12/6/2023\ndate-modified: 12/10/2023\ncategories: [Survey, Computation]\ntoc: true\nnumber-sections: true\ntwitter-card:\n    image: history.png\nopen-graph:\n    image: history.png\ncode-block-bg: true\ncode-block-border-left: \"#31BAE9\"\ncode-overflow: wrap\ncode-fold: true\nbibliography: ../../../mathematics.bib\ncsl: ../../../apa.csl\ncover: history.png\nabstract-title: 概要\nabstract: 「ベイズ統計学」は一大トピックであるが，「ベイズ計算」という分野があることはそれほど周知のことではない．しかし，ベイズ統計学は常に「計算が困難で実行が難しい」という問題と共にあってきたのであり，ここ30年のベイズ統計学の興隆は計算機の普及と効率的なベイズ計算法の発明に因る．モデル・データがいずれも大規模で複雑になっていく現代において，ベイズの枠組みも柔軟に取り入れた更なる統計計算法の発展が欠かせない．\ncrossref:\n    sec-prefix: 節\n    eq-prefix: 式\n---\n\n![History of Bayesian Computation [@Martin+2023-history p.4]](history.png)\n\n# 「ベイズ計算」の「ベイズ」とは何者か？\n\n> 賭博，生命保険，確率論この三つの間には，その発生に切っても切れない因縁がある．この点を明確に摘出することは，統計学の黎明を知るのに不可欠であろう． [@北川敏男49-統計学の認識]\n\n> de Moivre を彼の著 Approximation に，また Bayes を彼の定理に導いた原因は，純然たる数学的なものというよりも，神学的及び社会学的のものであった． [@Pearson1926]\n\n## ベイズまでの統計学の黎明\n\n統計学の黎明を要請したものは，社会への不安であった．筆者に言わせれば，この社会への不安を直視したのがドイツ，数で解決しようとしたのがイギリスで，解決への筋道を確率論で基礎づけたのがフランスである．\n\n17世紀初頭から何度も流行を繰り返し，遂に1665年にはロンドンの人口の1/4を死に至らしめた [ペストの大流行](https://ja.wikipedia.org/wiki/%E3%83%AD%E3%83%B3%E3%83%89%E3%83%B3%E3%81%AE%E5%A4%A7%E7%96%AB%E7%97%85) は恐怖の対象であった．パンデミックは現代でも恐怖の対象であるが，当時はその全貌の把握が難しく，これが第一に切望された．月の運行による健康被害，国王の統治が疫病を引き起こす，などの俗見が流布していた時代である．しかし，「数」という解決手段は極めて功を奏した．\n\n数による解決が他でもないイギリスから生まれたことは，Francis Bacon 1561-1626 に象徴される自然科学の風土，「Aristotelesの三段論法を通じて，経験的に因果関係を発見することで，我々は自然を理解できる」という希望が当時のイギリスには存在したことが挙げられる．\n\n> 海へ行け，きっと獲物があるぞという先輩が Bacon であった．漁獲法一般の講義をする先生が，例えば後世の J. S. Mill の帰納論理学に相当するのである．統計学を作った漁師たちは，Mill 先生の帰納法の論理学の講義などは，上の空で聞いた．そして各自の漁獲法を自らの浜で覚えたのである． [@北川敏男49-統計学の認識 p.12]\n\n### John Grauntの死亡表\n\nペスト流行の激しさの判定に寄与する人口状況を，最初に数によって理解しようとしたのが [John Graunt](https://en.wikipedia.org/wiki/John_Graunt) 1620-1674 であった．\n\n当時の英国王立理学協会^[正式名称をThe Royal Society for the Improvement of Natural Knowledge by Experimentという] は，封建的な諸関係の崩壊解消と同時に，商品生産・貨幣による売買の全面支配によって貨幣的表現が富の大部分に侵入したことにより新たに誕生した市民階級が勢力を占めており，Graunt もこのような商人階級の出身であった．\n\nそのような身分の Graunt が英国王の推薦を受けて王立協会員の名誉を勝ち取った論文 [@Graunt1662] は，ギルド発行の死亡統計 [Bills of Mortality](https://en.wikipedia.org/wiki/Bills_of_mortality) と教会に蓄積していた統計資料^[当局の人間に死亡を報告する義務は全くなかった。その代わり、それぞれの教区では2人かそれ以上の死体を調査し、死因を決定する義務を負う調査員を任命していた。「調査員」は死亡を報告する毎に遺族より少額の手数料を徴収する資格が与えられていたので、教区では任命しなければ貧困のため救貧税による支援が必要となりそうな人間を割り当てていた。（[Wikipediaページより](https://ja.wikipedia.org/wiki/%E3%83%AD%E3%83%B3%E3%83%89%E3%83%B3%E3%81%AE%E5%A4%A7%E7%96%AB%E7%97%85)）] から統計的な処理を通じて世界初の「死亡表」を作成し，次の内容を初めて結論づけた．\n\n- 36%の幼児は６歳未満で死亡する．\n- 洗礼数をみると，男女比は16:15くらいである．\n- 都市の死亡率は地方より高い．\n- Londonの城外では死亡率は３倍である．\n\n加えてLondonの世帯数を3通りの方法で推算し，世帯数は5万であろうと結論づけた．なお，当時の俗見ではLondon人口は100万と言われていた．\n\nその後このような「生命表」は精緻化の一途を辿り，イギリスのギルド的な共助制度の土壌の上で，生命保険の成立という実を結んだ．\n\n### 統計学への期待と希望\n\nこのイギリスの数を使った解決は，[政治算術学派](https://ja.wikipedia.org/wiki/%E6%94%BF%E6%B2%BB%E7%AE%97%E8%A1%93) と呼ばれ，海外への輸出が進んだ．\n\nドイツの牧師 [Johann Peter Süβmilch](https://ja.wikipedia.org/wiki/%E3%83%A8%E3%83%8F%E3%83%B3%E3%83%BB%E3%83%9A%E3%83%BC%E3%82%BF%E3%83%BC%E3%83%BB%E3%82%B8%E3%83%A5%E3%83%BC%E3%82%B9%E3%83%9F%E3%83%AB%E3%83%92) 1707-1767 は Graunt に倣って，教会に蓄積していた統計資料を用い，出生率の性別比が長期的には女性1,000対男性1,050に収束することを発見した．\n\n中でも特に，「たくさんのデータを集めると何かが見えてくる」ことに大きな希望を持ち，Graunt が教会の資料に注目したことを Columbus の新大陸発見になぞらえている．そう，**歴史上最初の統計分析は，教会の資料によるものであった**のである．\n\n> 若し我々が家を一軒一軒数えていくならば，ある家では娘だけに，またある家では息子だけに，あるいはそうでなくとも，非常に不釣り合いな両者の配合にでくわすであろう．小さな社会や村落でも秩序的なものを認めることは，容易ではない．（中略）．かかる場合に，誰が，能く規則と秩序とに想達し得るだろう．所で，教会の記録はこの秩序の確認のための大きな手段である．それは教会用及び世俗用のためにすでに数世紀前から取られ，**とくに宗教改革後はかなり正確にとられてきた**．誰がそれを利用したか？その発見はアメリカ発見と同時に可能であったのだ．（中略）**それをGrauntがなし得たのである**．\n> --Süβmilch (1741) 『神の秩序』 訳文は [@北川敏男49-統計学の認識] より．\n\nこのように Süβmilch は男児の出生率の方が高いことを神の存在証明と見なしたのであった．この宗教的な外被を取り去るには，確率論の登場をまたねばならなかったが，これにはさらにフランスの学派が合流するのを待つ必要があり，それには100年を要したのであった（ @sec-France も参照）．\n\n## ベイズが取り組んだ問題\n\nというわけで，$i=1,\\cdots,n$ 番目の世帯の新生児が，男児である $y_i=1$ か女児である $y_i=0$ かのデータなどから，人口・疫病・国家動態に役立つ知識を引き出すことが当時の重要な問題意識であることをわかっていただけただろう．\n\nイギリスの牧師 [Thomas Bayes](https://ja.wikipedia.org/wiki/%E3%83%88%E3%83%BC%E3%83%9E%E3%82%B9%E3%83%BB%E3%83%99%E3%82%A4%E3%82%BA) 1701-1761 は，より抽象的な設定で統計的推定の問題を研究していた．Bayes は就中，次のような区間推定の問題を考えていた．\n\n\n\n::: {.hidden}\n$$\n\\usepackage[all]{xy}\\usepackage{amsmath}\\newcommand{\\y}{\\b{y}}\n\n%%% 演算子\n\\DeclareMathOperator{\\grad}{\\mathrm{grad}}\\DeclareMathOperator{\\rot}{\\mathrm{rot}}\\DeclareMathOperator{\\divergence}{\\mathrm{div}}\\DeclareMathOperator{\\tr}{\\mathrm{tr}}\\newcommand{\\pr}{\\mathrm{pr}}\n\\newcommand{\\Map}{\\mathrm{Map}}\\newcommand{\\dom}{\\mathrm{Dom}\\;}\\newcommand{\\cod}{\\mathrm{Cod}\\;}\\newcommand{\\supp}{\\mathrm{supp}\\;}\n\n\n%%% 線型代数学\n\\newcommand{\\vctr}[2]{\\begin{pmatrix}#1\\\\#2\\end{pmatrix}}\\newcommand{\\vctrr}[3]{\\begin{pmatrix}#1\\\\#2\\\\#3\\end{pmatrix}}\\newcommand{\\mtrx}[4]{\\begin{pmatrix}#1&#2\\\\#3&#4\\end{pmatrix}}\\newcommand{\\smtrx}[4]{\\paren{\\begin{smallmatrix}#1&#2\\\\#3&#4\\end{smallmatrix}}}\\newcommand{\\Ker}{\\mathrm{Ker}\\;}\\newcommand{\\Coker}{\\mathrm{Coker}\\;}\\newcommand{\\Coim}{\\mathrm{Coim}\\;}\\DeclareMathOperator{\\rank}{\\mathrm{rank}}\\newcommand{\\lcm}{\\mathrm{lcm}}\\newcommand{\\sgn}{\\mathrm{sgn}\\,}\\newcommand{\\GL}{\\mathrm{GL}}\\newcommand{\\SL}{\\mathrm{SL}}\\newcommand{\\alt}{\\mathrm{alt}}\n%%% 複素解析学\n\\renewcommand{\\Re}{\\mathrm{Re}\\;}\\renewcommand{\\Im}{\\mathrm{Im}\\,}\\newcommand{\\Gal}{\\mathrm{Gal}}\\newcommand{\\PGL}{\\mathrm{PGL}}\\newcommand{\\PSL}{\\mathrm{PSL}}\\newcommand{\\Log}{\\mathrm{Log}\\,}\\newcommand{\\Res}{\\mathrm{Res}\\,}\\newcommand{\\on}{\\mathrm{on}\\;}\\newcommand{\\hatC}{\\widehat{\\C}}\\newcommand{\\hatR}{\\hat{\\R}}\\newcommand{\\PV}{\\mathrm{P.V.}}\\newcommand{\\diam}{\\mathrm{diam}}\\newcommand{\\Area}{\\mathrm{Area}}\\newcommand{\\Lap}{\\Laplace}\\newcommand{\\f}{\\mathbf{f}}\\newcommand{\\cR}{\\mathcal{R}}\\newcommand{\\const}{\\mathrm{const.}}\\newcommand{\\Om}{\\Omega}\\newcommand{\\Cinf}{C^\\infty}\\newcommand{\\ep}{\\epsilon}\\newcommand{\\dist}{\\mathrm{dist}}\\newcommand{\\opart}{\\o{\\partial}}\\newcommand{\\Length}{\\mathrm{Length}}\n%%% 集合と位相\n\\newcommand{\\cA}{\\mathcal{A}}\\newcommand{\\cO}{\\mathcal{O}}\\newcommand{\\cW}{\\mathcal{W}}\\renewcommand{\\O}{\\mathcal{O}}\\renewcommand{\\S}{\\mathcal{S}}\\newcommand{\\U}{\\mathcal{U}}\\newcommand{\\V}{\\mathrm{V}}\\renewcommand{\\P}{\\mathrm{P}}\\newcommand{\\R}{\\mathbb{R}}\\newcommand{\\N}{\\mathbb{N}}\\newcommand{\\C}{\\mathrm{C}}\\newcommand{\\bC}{\\mathbb{C}}\\newcommand{\\Z}{\\mathbb{Z}}\\newcommand{\\Q}{\\mathbb{Q}}\\newcommand{\\TV}{\\mathrm{TV}}\\newcommand{\\ORD}{\\mathrm{ORD}}\\newcommand{\\Tr}{\\mathrm{Tr}}\\newcommand{\\Card}{\\mathrm{Card}\\;}\\newcommand{\\Top}{\\mathrm{Top}}\\newcommand{\\Disc}{\\mathrm{Disc}}\\newcommand{\\Codisc}{\\mathrm{Codisc}}\\newcommand{\\CoDisc}{\\mathrm{CoDisc}}\\newcommand{\\Ult}{\\mathrm{Ult}}\\newcommand{\\ord}{\\mathrm{ord}}\\DeclareMathOperator{\\maj}{\\mathrm{maj}}\\newcommand{\\bS}{\\mathbb{S}}\\newcommand{\\PConn}{\\mathrm{PConn}}\n\n%%% 形式言語理論\n\\newcommand{\\REGEX}{\\mathrm{REGEX}}\\newcommand{\\RE}{\\mathbf{RE}}\n%%% Graph Theory\n\\newcommand{\\SimpGph}{\\mathrm{SimpGph}}\\newcommand{\\Gph}{\\mathrm{Gph}}\\newcommand{\\mult}{\\mathrm{mult}}\\newcommand{\\inv}{\\mathrm{inv}}\n\n%%% 多様体\n\\newcommand{\\Der}{\\mathrm{Der}}\\newcommand{\\osub}{\\overset{\\mathrm{open}}{\\subset}}\\newcommand{\\osup}{\\overset{\\mathrm{open}}{\\supset}}\\newcommand{\\al}{\\alpha}\\newcommand{\\K}{\\mathbb{K}}\\newcommand{\\Sp}{\\mathrm{Sp}}\\newcommand{\\g}{\\mathfrak{g}}\\newcommand{\\h}{\\mathfrak{h}}\\newcommand{\\Exp}{\\mathrm{Exp}\\;}\\newcommand{\\Imm}{\\mathrm{Imm}}\\newcommand{\\Imb}{\\mathrm{Imb}}\\newcommand{\\codim}{\\mathrm{codim}\\;}\\newcommand{\\Gr}{\\mathrm{Gr}}\n%%% 代数\n\\newcommand{\\Ad}{\\mathrm{Ad}}\\newcommand{\\finsupp}{\\mathrm{fin\\;supp}}\\newcommand{\\SO}{\\mathrm{SO}}\\newcommand{\\SU}{\\mathrm{SU}}\\newcommand{\\acts}{\\curvearrowright}\\newcommand{\\mono}{\\hookrightarrow}\\newcommand{\\epi}{\\twoheadrightarrow}\\newcommand{\\Stab}{\\mathrm{Stab}}\\newcommand{\\nor}{\\mathrm{nor}}\\newcommand{\\T}{\\mathbb{T}}\\newcommand{\\Aff}{\\mathrm{Aff}}\\newcommand{\\rsub}{\\triangleleft}\\newcommand{\\rsup}{\\triangleright}\\newcommand{\\subgrp}{\\overset{\\mathrm{subgrp}}{\\subset}}\\newcommand{\\Ext}{\\mathrm{Ext}}\\newcommand{\\sbs}{\\subset}\\newcommand{\\sps}{\\supset}\\newcommand{\\In}{\\mathrm{in}\\;}\\newcommand{\\Tor}{\\mathrm{Tor}}\\newcommand{\\p}{\\b{p}}\\newcommand{\\q}{\\mathfrak{q}}\\newcommand{\\m}{\\mathfrak{m}}\\newcommand{\\cS}{\\mathcal{S}}\\newcommand{\\Frac}{\\mathrm{Frac}\\,}\\newcommand{\\Spec}{\\mathrm{Spec}\\,}\\newcommand{\\bA}{\\mathbb{A}}\\newcommand{\\Sym}{\\mathrm{Sym}}\\newcommand{\\Ann}{\\mathrm{Ann}}\\newcommand{\\Her}{\\mathrm{Her}}\\newcommand{\\Bil}{\\mathrm{Bil}}\\newcommand{\\Ses}{\\mathrm{Ses}}\\newcommand{\\FVS}{\\mathrm{FVS}}\n%%% 代数的位相幾何学\n\\newcommand{\\Ho}{\\mathrm{Ho}}\\newcommand{\\CW}{\\mathrm{CW}}\\newcommand{\\lc}{\\mathrm{lc}}\\newcommand{\\cg}{\\mathrm{cg}}\\newcommand{\\Fib}{\\mathrm{Fib}}\\newcommand{\\Cyl}{\\mathrm{Cyl}}\\newcommand{\\Ch}{\\mathrm{Ch}}\n%%% 微分幾何学\n\\newcommand{\\rP}{\\mathrm{P}}\\newcommand{\\rE}{\\mathrm{E}}\\newcommand{\\e}{\\b{e}}\\renewcommand{\\k}{\\b{k}}\\newcommand{\\Christ}[2]{\\begin{Bmatrix}#1\\\\#2\\end{Bmatrix}}\\renewcommand{\\Vec}[1]{\\overrightarrow{\\mathrm{#1}}}\\newcommand{\\hen}[1]{\\mathrm{#1}}\\renewcommand{\\b}[1]{\\boldsymbol{#1}}\n\n%%% 函数解析\n\\newcommand{\\Inc}{\\mathrm{Inc}}\\newcommand{\\aInc}{\\mathrm{aInc}}\\newcommand{\\HS}{\\mathrm{HS}}\\newcommand{\\loc}{\\mathrm{loc}}\\newcommand{\\Lh}{\\mathrm{L.h.}}\\newcommand{\\Epi}{\\mathrm{Epi}}\\newcommand{\\slim}{\\mathrm{slim}}\\newcommand{\\Ban}{\\mathrm{Ban}}\\newcommand{\\Hilb}{\\mathrm{Hilb}}\\newcommand{\\Ex}{\\mathrm{Ex}}\\newcommand{\\Co}{\\mathrm{Co}}\\newcommand{\\sa}{\\mathrm{sa}}\\newcommand{\\nnorm}[1]{{\\left\\vert\\kern-0.25ex\\left\\vert\\kern-0.25ex\\left\\vert #1 \\right\\vert\\kern-0.25ex\\right\\vert\\kern-0.25ex\\right\\vert}}\\newcommand{\\dvol}{\\mathrm{dvol}}\\newcommand{\\Sconv}{\\mathrm{Sconv}}\\newcommand{\\I}{\\mathcal{I}}\\newcommand{\\nonunital}{\\mathrm{nu}}\\newcommand{\\cpt}{\\mathrm{cpt}}\\newcommand{\\lcpt}{\\mathrm{lcpt}}\\newcommand{\\com}{\\mathrm{com}}\\newcommand{\\Haus}{\\mathrm{Haus}}\\newcommand{\\proper}{\\mathrm{proper}}\\newcommand{\\infinity}{\\mathrm{inf}}\\newcommand{\\TVS}{\\mathrm{TVS}}\\newcommand{\\ess}{\\mathrm{ess}}\\newcommand{\\ext}{\\mathrm{ext}}\\newcommand{\\Index}{\\mathrm{Index}\\;}\\newcommand{\\SSR}{\\mathrm{SSR}}\\newcommand{\\vs}{\\mathrm{vs.}}\\newcommand{\\fM}{\\mathfrak{M}}\\newcommand{\\EDM}{\\mathrm{EDM}}\\newcommand{\\Tw}{\\mathrm{Tw}}\\newcommand{\\fC}{\\mathfrak{C}}\\newcommand{\\bn}{\\boldsymbol{n}}\\newcommand{\\br}{\\boldsymbol{r}}\\newcommand{\\Lam}{\\Lambda}\\newcommand{\\lam}{\\lambda}\\newcommand{\\one}{\\mathbf{1}}\\newcommand{\\dae}{\\text{-a.e.}}\\newcommand{\\das}{\\text{-a.s.}}\\newcommand{\\td}{\\text{-}}\\newcommand{\\RM}{\\mathrm{RM}}\\newcommand{\\BV}{\\mathrm{BV}}\\newcommand{\\normal}{\\mathrm{normal}}\\newcommand{\\lub}{\\mathrm{lub}\\;}\\newcommand{\\Graph}{\\mathrm{Graph}}\\newcommand{\\Ascent}{\\mathrm{Ascent}}\\newcommand{\\Descent}{\\mathrm{Descent}}\\newcommand{\\BIL}{\\mathrm{BIL}}\\newcommand{\\fL}{\\mathfrak{L}}\\newcommand{\\De}{\\Delta}\n%%% 積分論\n\\newcommand{\\calA}{\\mathcal{A}}\\newcommand{\\calB}{\\mathcal{B}}\\newcommand{\\D}{\\mathcal{D}}\\newcommand{\\Y}{\\mathcal{Y}}\\newcommand{\\calC}{\\mathcal{C}}\\renewcommand{\\ae}{\\mathrm{a.e.}\\;}\\newcommand{\\cZ}{\\mathcal{Z}}\\newcommand{\\fF}{\\mathfrak{F}}\\newcommand{\\fI}{\\mathfrak{I}}\\newcommand{\\E}{\\mathrm{E}}\\newcommand{\\rV}{\\mathrm{V}}\\newcommand{\\cE}{\\mathcal{E}}\\newcommand{\\sMap}{\\sigma\\textrm{-}\\mathrm{Map}}\\DeclareMathOperator*{\\argmax}{arg\\,max}\\DeclareMathOperator*{\\argmin}{arg\\,min}\\newcommand{\\cC}{\\mathcal{C}}\\newcommand{\\comp}{\\complement}\\newcommand{\\J}{\\mathcal{J}}\\newcommand{\\sumN}[1]{\\sum_{#1\\in\\N}}\\newcommand{\\cupN}[1]{\\cup_{#1\\in\\N}}\\newcommand{\\capN}[1]{\\cap_{#1\\in\\N}}\\newcommand{\\Sum}[1]{\\sum_{#1=1}^\\infty}\\newcommand{\\sumn}{\\sum_{n=1}^\\infty}\\newcommand{\\summ}{\\sum_{m=1}^\\infty}\\newcommand{\\sumk}{\\sum_{k=1}^\\infty}\\newcommand{\\sumi}{\\sum_{i=1}^\\infty}\\newcommand{\\sumj}{\\sum_{j=1}^\\infty}\\newcommand{\\cupn}{\\cup_{n=1}^\\infty}\\newcommand{\\capn}{\\cap_{n=1}^\\infty}\\newcommand{\\cupk}{\\cup_{k=1}^\\infty}\\newcommand{\\cupi}{\\cup_{i=1}^\\infty}\\newcommand{\\cupj}{\\cup_{j=1}^\\infty}\\newcommand{\\limn}{\\lim_{n\\to\\infty}}\\renewcommand{\\L}{\\mathcal{L}}\\newcommand{\\Cl}{\\mathrm{Cl}}\\newcommand{\\cN}{\\mathcal{N}}\\newcommand{\\Ae}{\\textrm{-a.e.}\\;}\\newcommand{\\csub}{\\overset{\\textrm{closed}}{\\subset}}\\newcommand{\\csup}{\\overset{\\textrm{closed}}{\\supset}}\\newcommand{\\wB}{\\wt{B}}\\newcommand{\\cG}{\\mathcal{G}}\\newcommand{\\Lip}{\\mathrm{Lip}}\\DeclareMathOperator{\\Dom}{\\mathrm{Dom}}\\newcommand{\\AC}{\\mathrm{AC}}\\newcommand{\\Mol}{\\mathrm{Mol}}\n%%% Fourier解析\n\\newcommand{\\Pe}{\\mathrm{Pe}}\\newcommand{\\wR}{\\wh{\\mathbb{\\R}}}\\newcommand*{\\Laplace}{\\mathop{}\\!\\mathbin\\bigtriangleup}\\newcommand*{\\DAlambert}{\\mathop{}\\!\\mathbin\\Box}\\newcommand{\\bT}{\\mathbb{T}}\\newcommand{\\dx}{\\dslash x}\\newcommand{\\dt}{\\dslash t}\\newcommand{\\ds}{\\dslash s}\n%%% 数値解析\n\\newcommand{\\round}{\\mathrm{round}}\\newcommand{\\cond}{\\mathrm{cond}}\\newcommand{\\diag}{\\mathrm{diag}}\n\\newcommand{\\Adj}{\\mathrm{Adj}}\\newcommand{\\Pf}{\\mathrm{Pf}}\\newcommand{\\Sg}{\\mathrm{Sg}}\n\n%%% 確率論\n\\newcommand{\\cV}{\\mathcal{V}}\\newcommand{\\FM}{\\mathrm{FM}}\\newcommand{\\KR}{\\mathrm{KR}}\\newcommand{\\rba}{\\mathrm{rba}}\\newcommand{\\rca}{\\mathrm{rca}}\\newcommand{\\Prob}{\\mathrm{Prob}}\\newcommand{\\X}{\\mathcal{X}}\\newcommand{\\Meas}{\\mathrm{Meas}}\\newcommand{\\as}{\\;\\mathrm{a.s.}}\\newcommand{\\io}{\\;\\mathrm{i.o.}}\\newcommand{\\fe}{\\;\\mathrm{f.e.}}\\newcommand{\\F}{\\mathcal{F}}\\newcommand{\\bF}{\\mathbb{F}}\\newcommand{\\W}{\\mathcal{W}}\\newcommand{\\Pois}{\\mathrm{Pois}}\\newcommand{\\iid}{\\mathrm{i.i.d.}}\\newcommand{\\wconv}{\\rightsquigarrow}\\newcommand{\\Var}{\\mathrm{Var}}\\newcommand{\\xrightarrown}{\\xrightarrow{n\\to\\infty}}\\newcommand{\\au}{\\mathrm{au}}\\newcommand{\\cT}{\\mathcal{T}}\\newcommand{\\wto}{\\overset{w}{\\to}}\\newcommand{\\dto}{\\overset{d}{\\to}}\\newcommand{\\pto}{\\overset{p}{\\to}}\\newcommand{\\mto}{\\overset{m}{\\to}}\\newcommand{\\vto}{\\overset{v}{\\to}}\\newcommand{\\Cont}{\\mathrm{Cont}}\\newcommand{\\stably}{\\mathrm{stably}}\\newcommand{\\Np}{\\mathbb{N}^+}\\newcommand{\\oM}{\\overline{\\mathcal{M}}}\\newcommand{\\fP}{\\mathfrak{P}}\\newcommand{\\sign}{\\mathrm{sign}}\n\\DeclareMathOperator{\\Ent}{Ent}\\DeclareMathOperator{\\Polya}{Polya}\\newcommand{\\Borel}{\\mathrm{Borel}}\\newcommand{\\Mid}{\\,|\\,}\\newcommand{\\middleMid}{\\;\\middle|\\;}\\DeclareMathOperator{\\LR}{LR}\\newcommand{\\CP}{\\mathrm{CP}}\\newcommand{\\bD}{\\mathbb{D}}\\newcommand{\\fW}{\\mathfrak{W}}\\newcommand{\\DL}{\\mathcal{D}\\mathcal{L}}\\renewcommand{\\r}[1]{\\mathrm{#1}}\\newcommand{\\rC}{\\mathrm{C}}\\newcommand{\\qqquad}{\\qquad\\quad}\n%%% 情報理論\n\\newcommand{\\bit}{\\mathrm{bit}}\\DeclareMathOperator{\\sinc}{sinc}\n%%% 量子論\n\\newcommand{\\err}{\\mathrm{err}}\n%%% 最適化\n\\newcommand{\\varparallel}{\\mathbin{\\!/\\mkern-5mu/\\!}}\\DeclareMathOperator{\\minimize}{minimize}\\DeclareMathOperator{\\subjectto}{subject to}\\newcommand{\\Ri}{\\mathrm{Ri}}\\newcommand{\\Cone}{\\mathrm{Cone}}\\newcommand{\\Int}{\\mathrm{Int}}\n%%% 数理ファイナンス\n\\newcommand{\\pre}{\\mathrm{pre}}\\newcommand{\\om}{\\omega}\n\n%%% 偏微分方程式\n\\let\\div\\relax\n\\newcommand{\\del}{\\partial}\n\\newcommand{\\LHS}{\\mathrm{LHS}}\\newcommand{\\RHS}{\\mathrm{RHS}}\\newcommand{\\bnu}{\\boldsymbol{\\nu}}\\newcommand{\\interior}{\\mathrm{in}\\;}\\newcommand{\\SH}{\\mathrm{SH}}\\renewcommand{\\v}{\\boldsymbol{\\nu}}\\newcommand{\\n}{\\mathbf{n}}\\newcommand{\\ssub}{\\Subset}\\newcommand{\\curl}{\\mathrm{curl}}\n%%% 常微分方程式\n\\newcommand{\\Ei}{\\mathrm{Ei}}\\newcommand{\\sn}{\\mathrm{sn}}\\newcommand{\\wgamma}{\\widetilde{\\gamma}}\n%%% 統計力学\n\\newcommand{\\Ens}{\\mathrm{Ens}}\n%%% 解析力学\n\\newcommand{\\cl}{\\mathrm{cl}}\\newcommand{\\x}{\\boldsymbol{x}}\n\n%%% 統計的因果推論\n\\newcommand{\\Do}{\\mathrm{Do}}\\newcommand{\\IV}{\\mathrm{IV}}\n%%% 応用統計学\n\\DeclareMathOperator{\\pl}{pl}\\newcommand{\\AIC}{\\mathrm{AIC}}\\newcommand{\\mrl}{\\mathrm{mrl}}\\newcommand{\\dotx}{\\dot{x}}\\newcommand{\\UMV}{\\mathrm{UMV}}\\newcommand{\\BLU}{\\mathrm{BLU}}\n%%% 数理統計\n\\DeclareMathOperator{\\arctanh}{arctanh}\\newcommand{\\comb}[2]{\\begin{pmatrix}#1\\\\#2\\end{pmatrix}}\\newcommand{\\bP}{\\mathbb{P}}\\newcommand{\\compsub}{\\overset{\\textrm{cpt}}{\\subset}}\\newcommand{\\lip}{\\textrm{lip}}\\newcommand{\\BL}{\\mathrm{BL}}\\newcommand{\\G}{\\mathbb{G}}\\newcommand{\\NB}{\\mathrm{NB}}\\newcommand{\\oR}{\\ov{\\R}}\\newcommand{\\liminfn}{\\liminf_{n\\to\\infty}}\\newcommand{\\limsupn}{\\limsup_{n\\to\\infty}}\\newcommand{\\esssup}{\\mathrm{ess.sup}}\\newcommand{\\asto}{\\xrightarrow{\\as}}\\newcommand{\\Cov}{\\mathrm{Cov}}\\newcommand{\\cQ}{\\mathcal{Q}}\\newcommand{\\VC}{\\mathrm{VC}}\\newcommand{\\mb}{\\mathrm{mb}}\\newcommand{\\Avar}{\\mathrm{Avar}}\\newcommand{\\bB}{\\mathbb{B}}\\newcommand{\\bW}{\\mathbb{W}}\\newcommand{\\sd}{\\mathrm{sd}}\\newcommand{\\w}[1]{\\widehat{#1}}\\newcommand{\\bZ}{\\boldsymbol{Z}}\\newcommand{\\Bernoulli}{\\mathrm{Ber}}\\newcommand{\\Ber}{\\mathrm{Ber}}\\newcommand{\\Mult}{\\mathrm{Mult}}\\newcommand{\\BPois}{\\mathrm{BPois}}\\newcommand{\\fraks}{\\mathfrak{s}}\\newcommand{\\frakk}{\\mathfrak{k}}\\newcommand{\\IF}{\\mathrm{IF}}\\newcommand{\\bX}{\\boldsymbol{X}}\\newcommand{\\bx}{\\boldsymbol{x}}\\newcommand{\\indep}{\\perp\\!\\!\\!\\perp}\\newcommand{\\IG}{\\mathrm{IG}}\\newcommand{\\Levy}{\\mathrm{Levy}}\\newcommand{\\MP}{\\mathrm{MP}}\\newcommand{\\Hermite}{\\mathrm{Hermite}}\\newcommand{\\Skellam}{\\mathrm{Skellam}}\\newcommand{\\Dirichlet}{\\mathrm{Dirichlet}}\\newcommand{\\Beta}{\\mathrm{Beta}}\\newcommand{\\bE}{\\mathbb{E}}\\newcommand{\\bG}{\\mathbb{G}}\\newcommand{\\MISE}{\\mathrm{MISE}}\\newcommand{\\logit}{\\mathtt{logit}}\\newcommand{\\expit}{\\mathtt{expit}}\\newcommand{\\cK}{\\mathcal{K}}\\newcommand{\\dl}{\\dot{l}}\\newcommand{\\dotp}{\\dot{p}}\\newcommand{\\wl}{\\wt{l}}\\newcommand{\\Gauss}{\\mathrm{Gauss}}\\newcommand{\\fA}{\\mathfrak{A}}\\newcommand{\\under}{\\mathrm{under}\\;}\\newcommand{\\whtheta}{\\wh{\\theta}}\\newcommand{\\Em}{\\mathrm{Em}}\\newcommand{\\ztheta}{{\\theta_0}}\n\\newcommand{\\rO}{\\mathrm{O}}\\newcommand{\\Bin}{\\mathrm{Bin}}\\newcommand{\\rW}{\\mathrm{W}}\\newcommand{\\rG}{\\mathrm{G}}\\newcommand{\\rB}{\\mathrm{B}}\\newcommand{\\rN}{\\mathrm{N}}\\newcommand{\\rU}{\\mathrm{U}}\\newcommand{\\HG}{\\mathrm{HG}}\\newcommand{\\GAMMA}{\\mathrm{Gamma}}\\newcommand{\\Cauchy}{\\mathrm{Cauchy}}\\newcommand{\\rt}{\\mathrm{t}}\\newcommand{\\rF}{\\mathrm{F}}\n\\DeclareMathOperator{\\erf}{erf}\n%%% 計量経済学\n\\newcommand{\\FE}{\\mathrm{FE}}\\newcommand{\\bV}{\\boldsymbol{V}}\\newcommand{\\GLS}{\\mathrm{GLS}}\\newcommand{\\be}{\\boldsymbol{e}}\\newcommand{\\POOL}{\\mathrm{POOL}}\\newcommand{\\GMM}{\\mathrm{GMM}}\\newcommand{\\MM}{\\mathrm{MM}}\\newcommand{\\SSIV}{\\mathrm{SSIV}}\\newcommand{\\JIV}{\\mathrm{JIV}}\\newcommand{\\AR}{\\mathrm{AR}}\\newcommand{\\ILS}{\\mathrm{ILS}}\\newcommand{\\SLS}{\\mathrm{SLS}}\\newcommand{\\LIML}{\\mathrm{LIML}}\n\n%%% 無限次元統計模型の理論\n\\newcommand{\\Rad}{\\mathrm{Rad}}\\newcommand{\\bY}{\\boldsymbol{Y}}\\newcommand{\\pone}{{(1)}}\\newcommand{\\ptwo}{{(2)}}\\newcommand{\\ps}[1]{{(#1)}}\\newcommand{\\fsub}{\\overset{\\text{finite}}{\\subset}}\n%%% Banach Lattices\n\\newcommand{\\Slv}{\\mathrm{Slv}}\\newcommand{\\Hypo}{\\mathrm{Hypo}}\\newcommand{\\CL}{\\mathrm{CL}}\\DeclareMathOperator{\\ba}{ba}\\DeclareMathOperator{\\ca}{ca}\n\n%%% 圏\n\\newcommand{\\varlim}{\\varprojlim}\\newcommand{\\Hom}{\\mathrm{Hom}}\\newcommand{\\Iso}{\\mathrm{Iso}}\\newcommand{\\Mor}{\\mathrm{Mor}}\\newcommand{\\Isom}{\\mathrm{Isom}}\\newcommand{\\Aut}{\\mathrm{Aut}}\\newcommand{\\End}{\\mathrm{End}}\\newcommand{\\op}{\\mathrm{op}}\\newcommand{\\ev}{\\mathrm{ev}}\\newcommand{\\Ob}{\\mathrm{Ob}}\\newcommand{\\Ar}{\\mathrm{Ar}}\\newcommand{\\Arr}{\\mathrm{Arr}}\\newcommand{\\Set}{\\mathrm{Set}}\\newcommand{\\Grp}{\\mathrm{Grp}}\\newcommand{\\Cat}{\\mathrm{Cat}}\\newcommand{\\Mon}{\\mathrm{Mon}}\\newcommand{\\Ring}{\\mathrm{Ring}}\\newcommand{\\CRing}{\\mathrm{CRing}}\\newcommand{\\Ab}{\\mathrm{Ab}}\\newcommand{\\Pos}{\\mathrm{Pos}}\\newcommand{\\Vect}{\\mathrm{Vect}}\\newcommand{\\FinVect}{\\mathrm{FinVect}}\\newcommand{\\FinSet}{\\mathrm{FinSet}}\\newcommand{\\FinMeas}{\\mathrm{FinMeas}}\\newcommand{\\OmegaAlg}{\\Omega\\text{-}\\mathrm{Alg}}\\newcommand{\\OmegaEAlg}{(\\Omega,E)\\text{-}\\mathrm{Alg}}\\newcommand{\\Fun}{\\mathrm{Fun}}\\newcommand{\\Func}{\\mathrm{Func}}\\newcommand{\\Alg}{\\mathrm{Alg}} %代数の圏\n\\newcommand{\\Met}{\\mathrm{Met}} %Metric space & Contraction maps\n\\newcommand{\\Stoch}{\\mathrm{Stoch}}\\newcommand{\\FinStoch}{\\mathrm{FinStoch}}\\newcommand{\\Copy}{\\mathrm{copy}}\\newcommand{\\Delete}{\\mathrm{delete}} %確率空間とMarkov核の圏\n\\newcommand{\\Bool}{\\mathrm{Bool}}\\newcommand{\\CABool}{\\mathrm{CABool}}\\newcommand{\\CompBoolAlg}{\\mathrm{CompBoolAlg}}\\newcommand{\\BoolAlg}{\\mathrm{BoolAlg}}\\newcommand{\\BoolRng}{\\mathrm{BoolRng}}\\newcommand{\\HeytAlg}{\\mathrm{HeytAlg}}\\newcommand{\\CompHeytAlg}{\\mathrm{CompHeytAlg}}\\newcommand{\\Lat}{\\mathrm{Lat}}\\newcommand{\\CompLat}{\\mathrm{CompLat}}\\newcommand{\\SemiLat}{\\mathrm{SemiLat}}\\newcommand{\\Stone}{\\mathrm{Stone}}\\newcommand{\\Mfd}{\\mathrm{Mfd}}\\newcommand{\\LieAlg}{\\mathrm{LieAlg}}\n\\newcommand{\\Sob}{\\mathrm{Sob}} %Sober space & continuous map\n\\newcommand{\\Op}{\\mathrm{Op}} %Category of open subsets\n\\newcommand{\\Sh}{\\mathrm{Sh}} %Category of sheave\n\\newcommand{\\PSh}{\\mathrm{PSh}} %Category of presheave, PSh(C)=[C^op,set]のこと\n\\newcommand{\\Conv}{\\mathrm{Conv}} %Convergence spaceの圏\n\\newcommand{\\Unif}{\\mathrm{Unif}} %一様空間と一様連続写像の圏\n\\newcommand{\\Frm}{\\mathrm{Frm}} %フレームとフレームの射\n\\newcommand{\\Locale}{\\mathrm{Locale}} %その反対圏\n\\newcommand{\\Diff}{\\mathrm{Diff}} %滑らかな多様体の圏\n\\newcommand{\\Quiv}{\\mathrm{Quiv}} %Quiverの圏\n\\newcommand{\\B}{\\mathcal{B}}\\newcommand{\\Span}{\\mathrm{Span}}\\newcommand{\\Corr}{\\mathrm{Corr}}\\newcommand{\\Decat}{\\mathrm{Decat}}\\newcommand{\\Rep}{\\mathrm{Rep}}\\newcommand{\\Grpd}{\\mathrm{Grpd}}\\newcommand{\\sSet}{\\mathrm{sSet}}\\newcommand{\\Mod}{\\mathrm{Mod}}\\newcommand{\\SmoothMnf}{\\mathrm{SmoothMnf}}\\newcommand{\\coker}{\\mathrm{coker}}\\newcommand{\\Ord}{\\mathrm{Ord}}\\newcommand{\\eq}{\\mathrm{eq}}\\newcommand{\\coeq}{\\mathrm{coeq}}\\newcommand{\\act}{\\mathrm{act}}\n\n%%% SMC\n\\newcommand{\\apf}{\\mathrm{apf}}\\newcommand{\\opt}{\\mathrm{opt}}\\newcommand{\\IS}{\\mathrm{IS}}\\newcommand{\\IR}{\\mathrm{IR}}\\newcommand{\\iidsim}{\\overset{\\iid}{\\sim}}\\newcommand{\\KL}{\\mathrm{KL}}\\DeclareMathOperator{\\ESS}{ESS}\\DeclareMathOperator{\\MSE}{MSE}\\newcommand{\\propt}{\\,\\propto\\,}\\newcommand{\\bM}{\\mathbb{M}}\\newcommand{\\cX}{\\mathcal{X}}\\newcommand{\\cY}{\\mathcal{Y}}\\newcommand{\\cP}{\\mathcal{P}}\\newcommand{\\ola}[1]{\\overleftarrow{#1}}\n\n%%% 括弧類\n\\newcommand{\\abs}[1]{\\lvert#1\\rvert}\\newcommand{\\Abs}[1]{\\left|#1\\right|}\\newcommand{\\ABs}[1]{\\biggl|#1\\biggr|}\\newcommand{\\norm}[1]{\\|#1\\|}\\newcommand{\\Norm}[1]{\\left\\|#1\\right\\|}\\newcommand{\\NOrm}[1]{\\biggl\\|#1\\biggr\\|}\\newcommand{\\Brace}[1]{\\left\\{#1\\right\\}}\\newcommand{\\BRace}[1]{\\biggl\\{#1\\biggr\\}}\\newcommand{\\paren}[1]{\\left(#1\\right)}\\newcommand{\\Paren}[1]{\\biggr(#1\\biggl)}\\newcommand{\\bracket}[1]{\\langle#1\\rangle}\\newcommand{\\brac}[1]{\\langle#1\\rangle}\\newcommand{\\Bracket}[1]{\\left\\langle#1\\right\\rangle}\\newcommand{\\Brac}[1]{\\left\\langle#1\\right\\rangle}\\newcommand{\\bra}[1]{\\left\\langle#1\\right|}\\newcommand{\\ket}[1]{\\left|#1\\right\\rangle}\\newcommand{\\Square}[1]{\\left[#1\\right]}\\newcommand{\\SQuare}[1]{\\biggl[#1\\biggr]}\n\\newcommand{\\ov}[1]{\\overline{#1}}\\newcommand{\\un}[1]{\\underline{#1}}\\newcommand{\\wt}[1]{\\widetilde{#1}}\\newcommand{\\wh}[1]{\\widehat{#1}}\n\\newcommand{\\pp}[2]{\\frac{\\partial #1}{\\partial #2}}\\newcommand{\\ppp}[3]{\\frac{\\partial #1}{\\partial #2\\partial #3}}\\newcommand{\\dd}[2]{\\frac{d #1}{d #2}}\n\\newcommand{\\floor}[1]{\\lfloor#1\\rfloor}\\newcommand{\\Floor}[1]{\\left\\lfloor#1\\right\\rfloor}\\newcommand{\\ceil}[1]{\\lceil#1\\rceil}\n\\newcommand{\\ocinterval}[1]{(#1]}\\newcommand{\\cointerval}[1]{[#1)}\\newcommand{\\COinterval}[1]{\\left[#1\\right)}\n\n%%% 予約語\n\\renewcommand{\\iff}{\\;\\mathrm{iff}\\;}\n\\newcommand{\\False}{\\mathrm{False}}\\newcommand{\\True}{\\mathrm{True}}\n\\newcommand{\\otherwise}{\\mathrm{otherwise}}\n\\newcommand{\\suchthat}{\\;\\mathrm{s.t.}\\;}\n\n%%% 略記\n\\newcommand{\\cM}{\\mathcal{M}}\\newcommand{\\M}{\\mathbb{M}}\\newcommand{\\cF}{\\mathcal{F}}\\newcommand{\\cD}{\\mathcal{D}}\\newcommand{\\fX}{\\mathfrak{X}}\\newcommand{\\fY}{\\mathfrak{Y}}\\newcommand{\\fZ}{\\mathfrak{Z}}\\renewcommand{\\H}{\\mathcal{H}}\\newcommand{\\fH}{\\mathfrak{H}}\\newcommand{\\bH}{\\mathbb{H}}\\newcommand{\\id}{\\mathrm{id}}\\newcommand{\\A}{\\mathcal{A}}\n\\newcommand{\\lmd}{\\lambda}\n\\newcommand{\\Lmd}{\\Lambda}\n\\newcommand{\\cI}{\\mathcal{I}}\n\n%%% 矢印類\n\\newcommand{\\iso}{\\xrightarrow{\\,\\smash{\\raisebox{-0.45ex}{\\ensuremath{\\scriptstyle\\sim}}}\\,}}\n\\newcommand{\\Lrarrow}{\\;\\;\\Leftrightarrow\\;\\;}\n$$\n:::\n\n\n\n::: {.callout-tip icon=\"false\" title=\"ベイズが取り組んだ問題（現代語訳）\"}\n2値のデータ $Y_i\\in\\{0,1\\}$ は，ある未知の「成功率」 $\\theta\\in(0,1)$ に従って，\n$$\nY_i=\\begin{cases}\n1&\\text{確率 }\\theta\\text{ で}\\\\\n0&\\text{残りの確率} 1-\\theta\\text{ で}\n\\end{cases}\n$$\nという値を取るとする．^[これは統計的モデルとしてBernoulli分布 $Y_i|\\theta\\iidsim\\Ber(\\theta)$ を仮定するということである．] このようなデータの独立観測標本 $\\y:=(y_1,\\cdots,y_n)^\\top$ から．神のみぞ知る，このデータ $\\y$ を生み出した真の成功率 $\\theta$ が，区間 $(a,b)\\subset(0,1)$ に入っているという確率 $\\P[a<\\theta<b|\\b{y}]$ をどう見積もれば良いか？\n:::\n\nここでは引き続き $Y_i$ は性別で，$\\theta$ は男児が生まれる確率 $\\theta=\\P[Y_i=1]$ だと解釈する．Bayes 自身は「ある未知の位置に白線が引かれたテーブル上にボールを $n$ 個転がし，それぞれの領域に幾つのボールが入ったかの情報のみから，白線の位置を推定する」という表現によって問題を定式化した [@Bayes1763]．これは後世ではビリヤード台の問題とも呼ばれた．[こちらのサイト](https://www.tcbegley.com/blog/posts/bayesian-billiards)も参照．\n\n## ベイズのアイデア\n\n彼の発想は極めてシンプルであり，次の3段階によって推定を試みた：\n\n1. **事前分布** $p(\\theta)$ と呼ばれる，最初の $\\theta\\in(0,1)$ に対する予想 $p(\\theta)$ を自由に表現する．^[パラメータ $\\theta$ は「男児が生まれる確率」であるが，これ自体にも事前分布という「確率」$p(\\theta)$ を導入することに戸惑う読者も居るだろう．しかし，**これがベイズ統計学の特徴である**．「男児が生まれる確率 $\\theta$」だろうとなんだろうと，「わからない」「不確実性がある」と主観的に感じるあらゆる対象に，確率分布を導入して事後分布を得ることで推論を実行する，これがベイズ統計学の枠組みの普遍性であり，無差別性であり，有用性を支えている．]\n2. 事前分布のデータ $\\y$ を観測した下での条件付き分布 $$p(\\theta|\\y):=\\frac{p(\\theta,\\y)}{p(\\y)}$$ を計算する．これを**事後分布**という．\n3. この事後分布 $p(\\theta|\\y)$ の形から区間推定を実行する．\n\nこの 3.の部分は，Bayes が特に区間推定に拘ったためのものであり，点推定でも良ければ次期予測でも良い．推定対象 3.を目的に応じて自由に入れ替えても，1.と 2.の部分が同じように動作するということ，これが**ベイズ統計学**の枠組みである．\n\nそれだけに事後分布というものが表現力に富んでいるのである．また，以下の例で納得していただけるかもしれないが，ベイズ統計学の手続きは「眼前のデータは，事前の信念を変えるのにどれほど説得的であるか？」という観点からも見れ，**定量的であると同時に定性的な判断も可能にする**． @sec-BayesianCausalInference で紹介するように，この特徴は意思決定への応用おいても重要である．\n\n::: {.callout-note icon=\"false\" title=\"問題に対する [@Bayes1763] の解決\"}\n1. まず，事前分布 $p(\\theta)$ を設定する．Bayes は前述のビリヤードの問題を考えていたこともあり， 「$\\theta\\in(0,1)$ は全く予想がつかない」「どんな $\\theta$ も同様にあり得る」という立場を取った．横軸を $\\theta\\in(0,1)$ の値，縦軸を「主観的にあり得ると思う度合い」として図で表すと次の通りである：\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define the range for x-axis\nx = np.linspace(0, 1, 1000)\n\n# Uniform distribution density function is constant\ny = np.ones_like(x)\n\n# Plot the graph\nplt.figure(figsize=(3, 2)) # Size suitable for a smartphone screen\nplt.plot(x, y, label='Uniform Distribution (0,1)', color=(0.35, 0.71, 0.73, 1))\nplt.fill_between(x, y, color=(0.35, 0.71, 0.73, 0.3))\nplt.xlabel('x')\nplt.ylim(0, 1.5)\nplt.ylabel('Density')\nplt.title('Posterior Distribution')\nplt.legend()\nplt.grid(True)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](BayesianComp_files/figure-html/cell-2-output-1.png){width=296 height=228}\n:::\n:::\n\n\nこの図が表す $(0,1)$ 上の確率分布を一様分布という．このように，一様分布とは「どのような $\\theta$ の値も同様に確からしい」という予想の表現である．\n\n2. 次に，データ $\\y=(y_1,\\cdots,y_n)^\\top$ が観測された後の条件付き分布 $p(\\theta|\\y)$ を計算することで，本データ $\\y$ が事前の信念 $p(\\theta)$ をどのように変えてしまうかを観る．簡単な確率論の結果として，条件付き分布は次の公式によって計算できる（[講義ノート](%E6%B3%95%E5%BE%8B%E5%AE%B6%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E7%B5%B1%E8%A8%88%E6%95%B0%E7%90%862.qmd#sec-Bayes-formula)も参照）：^[各 $\\theta$ の下で目の前のデータ $y_1,\\cdots,y_n$ が生成される確率 $p(\\y|\\theta)$ が低いということは，「その $\\theta$ から生成されたデータである確率は低い」という逆の発想ができる．そこで $p(\\y|\\theta)$ という条件付き確率を**尤度**ともいう．今回は $p(\\y|\\theta)=\\theta^{\\sum_{i=1}^ny_i}(1-\\theta)^{\\sum_{i=1}^n(1-y_i)}$ である．]\n$$\np(\\theta|\\y)=\\frac{p(\\y|\\theta)p(\\theta)}{\\int_\\Theta p(\\y|\\theta)p(\\theta)\\,d\\theta}\n$$ {#eq-Bayes-formula}\n    \n    例えば [日本の2021年の出生児性別のデータ](https://www.e-stat.go.jp/dbview?sid=0003411595) を用いると次のようになる．\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nfrom scipy.stats import beta\n\n# パラメータの設定\nn = 811622\nmale = 415903\nfemale = n - male\n\n# ベータ分布のPDFを計算\nx = np.linspace(0, 1, 1000)\ny = beta.pdf(x, 1+male, 1+female)\n\n# プロット\nplt.figure(figsize=(3, 2))\nplt.plot(x, y, label=f'Beta({1+male}, {1+female})', color=(0.35, 0.71, 0.73, 1))\nplt.fill_between(x, y, color=(0.35, 0.71, 0.73, 0.3))\nplt.xlabel('p')\nplt.xlim(0.4, 0.6)\nplt.ylabel('Probability Density')\nplt.title('Bayesian Posterior Distribution')\nplt.legend()\nplt.grid()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](BayesianComp_files/figure-html/cell-3-output-1.png){width=310 height=228}\n:::\n:::\n\n\nこうして極めて鋭い事後分布が出来た．事前に設定した分布 $p(\\theta)$ は極めて平坦な一様分布であったのに，それをデータで条件付けた $p(\\theta|\\y)$ には極めて鋭いスパイクが現れたのである．@eq-Bayes-formula を認めるならば，この図は「男児の方が女児よりも生まれる確率が高い」ことの証拠として，極めて説得的ではないだろうか？\n\n3. では区間推定の例として，$(a,b)=(0.5,1.0)$ として，「男児の方が女児よりも多い確率」を推定しよう．これは次を計算することになる：\n$$\n\\begin{align*}\n    &\\P\\Square{\\frac{1}{2}<\\theta<1}\\\\\n    &=\\int^1_{\\frac{1}{2}}p(\\y|\\theta)\\,d\\theta.\n\\end{align*}\n$$\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nprint(sum(y[500:600])/1000)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1.003097768300707\n```\n:::\n:::\n\n\nもはや丸め誤差により $1$ を越してしまっている．ほとんど確実に「男児の方が生まれる確率が高い」と結論づけて良いだろう．\n:::\n\nこの [@Bayes1763] が実行したように，**事後分布 $p(\\theta|\\y)$ をみて $\\theta$ に関する推論をする**，という立場からの統計的営み全体を**ベイズ統計学**．\n\n## ベイズ統計学の基本問題 {#sec-fundamental-problem-of-Bayes}\n\n事後分布 $p(\\theta|\\y)$ を導く際に用いた条件付き確率の公式である @eq-Bayes-formula \n$$\np(\\theta|\\y)=\\frac{p(\\y|\\theta)p(\\theta)}{\\int_\\Theta p(\\y|\\theta)p(\\theta)\\,d\\theta}\\quad\\text{(1)}\n$$\nは [**Bayesの公式**](%E6%B3%95%E5%BE%8B%E5%AE%B6%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E7%B5%B1%E8%A8%88%E6%95%B0%E7%90%862.qmd#sec-Bayes-formula) と呼ばれるようになった．今回の場合では，Pythonコードをご覧になった方はわかったかもしれないが，事後分布は\n$$\np(\\theta|\\y)=\\frac{\\theta^m(1-\\theta)^{n-m}}{B(m+1,n-m+1)}\n$$\nとなり，これはパラメータの空間 $(0,1)$ 上の [Beta分布](../2023-11-24/Beta-Gamma.qmd) と呼ばれるものである．\n\n現代のベイズ統計学の多くの統計量は，ある可積分関数 $g:\\Theta\\to\\cX$ を用いて\n$$\n\\E[g(\\theta)|\\y]=\\int_{\\Theta}g(\\theta)p(\\theta|\\y)\\,d\\theta\n$$ {#eq-object-integral}\nと表される．先ほどの Bayes の区間推定の例では $g=1_{(a,b)}$ と取った場合に当たる．^[さらに，$g(\\theta)=\\theta^p$ と取った場合，事後積率という統計量になる．等に $p=1$ の場合が事後平均である．] 実は，**この積分は，この最も簡単と思われる $p(\\theta),p(\\y|\\theta)$ の設定でも，殆ど計算できないのである**．\n\n鮮やかな解決法を提示したかと思えば，結局実行出来ないのでは全く本末転倒である！そのこともあってか，論文 [@Bayes1763] は実は Bayes の死後に [Richard Price](https://en.wikipedia.org/wiki/Richard_Price) によって投稿されたものであり，生前に自ら投稿・発表した訳ではなかった．^[なお，1763に出版されたものはPriceによる補遺も付いた短縮版であり，全文は1974年に出版された．[@Stigler1990]] 当然，発表当時は全く注目を受けなかった [@Stigler1990]．\n\n> Hence, despite the analytical availability of $p(\\theta|\\y)$ via (2)--“Bayes’ rule” as it is now known-—the quantity that was of interest to Bayes needed to be estimated, or *computed*. The quest for a computational solution to a Bayesian problem was thus born. [@Martin+2023-history p.2]\n\n::: {.callout-important title=\"まとめ：ベイズ統計学の基本問題\" icon=\"false\"}\nベイズの提示した統一的な統計推測の枠組み\n\n1. 推定したい値 $\\theta$ の空間上に**事前分布** $p(\\theta)$ を設定する．\n2. 事前分布 $p(\\theta)$ のデータ $\\y$ に関する条件付き分布として**事後分布** $p(\\theta|\\y)$ を得る．\n\nは非常に自然で，特に確率分布 $p(\\theta),p(\\theta|\\y)$ を簡単に視覚化できる現代では「データ $\\y$ は，パラメータ $\\theta$ に対する事前の信念をどれほど変えるに値するか？」を定量的にも定性的にも実感出来るという美点がある．\n\nしかしながら，モデル $p(\\theta),p(\\y|\\theta)$ の設定をいくら簡単にしても根本的に計算が困難で実行不可能なのである．これを解決する分野を**ベイズ計算**という．ベイズの論文 [@Bayes1763] でも，計算法の開発が約半分を占めた．^[pp.376-403 がBayesの論文の本論の内容であり pp.399-403 で計算法を３つのルールにまとめているが，その導出部は一部「長すぎるから掲載を省略する」とされている．] このように，**Bayes統計学は当初からBayes計算の問題を懐胎していた**のである．\n\n> In short, the implementation of all forms of Bayesian analysis relies heavily on numerical computation. [@Martin+2023-history p.2]\n:::\n\n## Laplaceの近似 {#sec-Laplace}\n\nフランスの数学者 Laplace は25歳時の初めての統計に関する著作 [@Laplace1774] を発表した．この中で，Bayes が解こうとしたものと全く同じ\n\n$$\\begin{align*}\n    &\\P[a<\\theta<b|\\y]\\\\\n    &\\quad=\\frac{\\int^b_a\\theta^m(1-\\theta)^{n-m}\\,d\\theta}{B(m+1,n-m+1)}\n\\end{align*}$$ {#eq-Beta-integral}\n\nという積分計算の問題を，被積分関数を\n$$\nf(\\theta):=\\frac{\\log p(\\theta|\\y)}{n}\n$$\nを用いて指数関数の形に表すことで解いた：^[一方で，Bayesの逆確率の問題への言及自体は，Laplaceの後年の1781年の著作*Mémoire sur les probabilités*へのCondorcetによる序文で初めて登場する [@Martin+2023-history p.5]．]\n$$\n\\begin{align*}\n    \\P[a<\\theta<b|\\y]&=\\int^b_ap(\\theta|\\y)\\,d\\theta\\\\\n    &=\\int^b_ae^{nf(\\theta)}\\,d\\theta\n\\end{align*}\n$$\nこの形に変形することがどのように役立つかは，次の定理が説明してくれる：\n\n::: {.callout-tip title=\"定理（Laplace近似）\"}\n^[[nCatLab](https://golem.ph.utexas.edu/category/2021/10/stirlings_formula.html) 参照．]\n関数 $f:[a,b]\\to\\R$ はただ一つの最大値を $x_0\\in(a,b)$ で取り，$f''(x_0)>0$ を満たすとする．このとき $n\\to\\infty$ の極限について，\n$$\n\\int^b_ae^{nf(x)}\\,dx\\sim\\sqrt{-\\frac{2\\pi}{nf''(x_0)}}e^{nf(x_0)}\n$$\n:::\n\nこれを $f$ の二次近似について適用することで，あらゆる確率分布 $p(\\theta|\\y)\\,d\\theta$ に関する積分 @eq-Beta-integral を，その正規近似に関する積分で近似できるのである．\n\nこの手法は現在のBayes計算手法のアイデアの源泉であり続けている [@Rue+2009]．\n\n## ベイズ統計学の長く苦しい時代\n\n「ベイズの枠組みは理念的に好ましかろうと，実際には実行不可能である」というベイズ統計学の基本問題は，Laplace が普遍的な近似計算法を開発したこと（ @sec-Laplace ）を除いて，次の進展を見るには計算機の発明と普及を待つ必要があった．その間実に2世紀超えである．\n\nまた，Laplace の近似手法は普遍的であり，Bayes の最初の設定のような簡単な設定の $p(\\theta|\\y),g$ に限らずとも使えるという，ベイズ統計学に大きく資する特徴も備えていたが，パラメータ $\\theta\\in(0,1)$ の次元が1ではなくなると途端に使えなくなるという欠点がある．\n\n> （前略）ベイズ統計学の有用性は以前から理解されていたが，この問題の抜本的な解決は1980年代まで待たざるを得なかった．**それ以前は，ベイズの定理自体は18世紀に早々に発見されたにもかかわらず，長い間，確率の解釈，事前分布の設定，事後分布の計算の困難さのために哲学的議論に終始し，実用化にはほど遠かったのである**．実用化の扉の鍵となったのは，一つは計算機の急速な発達，もう一つは計算集約的な画期的アルゴリズムの提案である． [@樋口知之2014 p.17]\n\n## フランスでの確率論の歴史 {#sec-France}\n\nこのように，Laplace が，ベイズ統計学暗黒の時代の中で唯一の小さな前進を生んだ．それだけでなく，Laplace は後の1812年に当時の確率論最大の集大成と言える大著『確率論の解析理論』を産んでおり，これが他でもないフランスから生まれたことにも相応の理由があった．\n\nまず第一に，賭博の流行により，確率というものの理解と征服が嘱望された．\n\n> その（確率論の）発展の動きを与えたものは，交易を賭ける商業資本家が占星術よりも確実な指導をこの学術に求めるという様な社会が基盤となって存在したことである．例えば，17世紀中葉のPascalとFermatの間の往復文書に取り扱われたカード遊びの数学的問題が，広く人々の関心を呼び起こした事情の裏には，至富の途を確実に求める商人たちの渇望が学問が外の世界にあったことを忘れてはならない． [@北川敏男49-統計学の認識]\n\n第二に，統計的現象を神学的な畏怖の対象と見るのではなく，自然科学による自然の理解と征服の文脈の最先端として理解する土壌がフランスにあったことが指摘できる．\n\n> 17, 18世紀の啓蒙的合理主義は，偶然的な事象に対しても数学的な取り扱いを行うことに特別の興味を持った．思想的にはこの時代精神こと確率論を発展させた最大の動力であった．その駆使する数学解析の多彩と合理主義の徹底とに於て，Laplace の大著はよくこの時代を代表するものと言うべきであろう．\n\n当時の財務総監 Jacques Turgot を通じてパリ造幣局の監査官も務めた [Nicolas de Condorcet](https://ja.wikipedia.org/wiki/%E3%83%8B%E3%82%B3%E3%83%A9%E3%83%BB%E3%83%89%E3%83%BB%E3%82%B3%E3%83%B3%E3%83%89%E3%83%AB%E3%82%BB) 1743-94 は Laplace の確率論を積極的に社会分析に応用した．「社会数学」と呼んだこの運動は社会学の源流ともみなされる．\n当然後進も Laplace に続いた．ベルギーの数学者 [Adolphe Quetelet](https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%89%E3%83%AB%E3%83%95%E3%83%BB%E3%82%B1%E3%83%88%E3%83%AC%E3%83%BC) 1796-74 は Laplace の確率論を社会に応用することを目指し「社会物理学」なる分野を創始し，BMIの別名「ケトレー指数」にも名を残している．\n\n> 古典確率論の一応の完成は典雅に見えるであろう．**だが人は，確率論のもった政治的，社会的意義を忘れてはならない**．理知を一切の尺度として「**代数学の炉火によって倫理学及び政治学を照さん**」(Condorcet) という時代精神，神の啓示に代らんとする確率論，それはフランス革命の思想的基礎に連関することを見失ってはならないのである． [@北川敏男49-統計学の認識]\n\n# MCMCとSMCの発明 {#sec-MCMC-SMC}\n\n「積分が計算できない」というベイズ統計学の基本問題（ @sec-fundamental-problem-of-Bayes ）は，計算機の発達と普及も欠かせなかったが，**シミュレーションを取り入れた確率的アルゴリズムであるマルコフ連鎖モンテカルロ法 (MCMC) の発明**によって本質的に解決された．\n\nしかし，この解決は必ずしも初めからベイズ統計学のために考案されたわけではなく，むしろ物理学と第二次世界大戦とが着火剤となった．アメリカの原爆開発計画において，当時の数値積分法では解けないような高次元の積分を，通常のモンテカルロ積分法は使えない状況下で解く必要があったことが，MCMC発明の契機となった．\n\n> In fact, until Bayesians discovered MCMC, the only computational methodology that seemed to offer much chance of making practical Bayesian statistics practical was the portfolio of quadrature methods developed under Adrian Smith’s leadership at Nottingham. [@Green+2015 p.836]\n\n## マルコフ連鎖によるモンテカルロ法の発明 {#sec-MCMC}\n\n乱数のシミュレーションを用いた確率的なアルゴリズムをモンテカルロ法と総称する．これは Metropolis が同僚 Ulam のポーカー好きから，モナコの首都 Monte Carlo にちなんで名付けたものである [@Metropolis-Ulam1949]．このようなアルゴリズムが最初に生まれたのが，第二次世界大戦中の [Los Alamos研究所](https://ja.wikipedia.org/wiki/%E3%83%AD%E3%82%B9%E3%82%A2%E3%83%A9%E3%83%A2%E3%82%B9%E5%9B%BD%E7%AB%8B%E7%A0%94%E7%A9%B6%E6%89%80) で進行中だった原爆開発計画である [Manhattan計画](https://ja.wikipedia.org/wiki/%E3%83%9E%E3%83%B3%E3%83%8F%E3%83%83%E3%82%BF%E3%83%B3%E8%A8%88%E7%94%BB) においてである．\n\n当時の問題は，原子爆弾着火時における Schödinger 作用素の基底状態のエネルギーを計算することにあった．抽象的には，$p$ を $N$ 個の粒子が従う Boltzmann 分布として，積分 @eq-object-integral を計算することにあった：\n\n$$\n\\E[g(\\b{\\theta})]=\\int_\\Theta g(\\b{\\theta})p(\\b{\\theta})\\,d\\b{\\theta}\\quad\\text{(2)}\n$$\n\nただし，\n\n1. 積分領域 $\\Theta$ が $2N$ 次元というとてつもない高次元空間上であること\n2. 分布 $p$ は定数倍を除いてしか計算できない\n\nという，2つの大きな制約があった．1.のために通常の数値積分法が使えず，また 2.により $p$ からの直接の乱数シミュレーションが出来ないので，$p$ からの乱数 $X_1,\\cdots,X_M$ を十分多く生成することで積分 @eq-object-integral を\n$$\n\\frac{1}{M}\\sum_{i=1}^Mg(X_i)\n$$\nによって近似するという通常の Monte Carlo 積分法を実行することも出来ない．そこで，Metropolis ら当時の Los Alamos に集まった物理学者たちは新しい方法を考える必要があった．\n\n最終的な解決 [@Metropolis+1953] は，Monte Carlo 法の中でもとりわけ画期的な発想によるものであった．それは，**Markov 連鎖を用いる**ということである．[Markov連鎖](https://ja.wikipedia.org/wiki/%E3%83%9E%E3%83%AB%E3%82%B3%E3%83%95%E9%80%A3%E9%8E%96)とは（ある一定の条件を満たす）確率過程のクラスであり，$p$ から直接のシミュレーションが出来ない状況でも，$p$ に収束するようなMarkov 連鎖を構成することは可能だったのである．\n\n制約 1.と 2.は広く物理学とベイズ統計学の至る所で見られる障壁であり，これをものともしない汎用アルゴリズムの発明は極めて大きなブレイクスルーであった．[@Dongarra-Sulliavn2000] は Metropolis アルゴリズムを理学・工学分野に20世紀最大の影響を与えたアルゴリズムの1つとしている．\n\n## 重点サンプリング法の発明 {#sec-importance-sampling}\n\n実は Manhattan 計画に最中に，もう一つのサンプリング技法が生まれていた．厚い壁で中性子線とガンマ線がどのように吸収されるかに取り組んでいたグループにて，[Herman Kahn](https://ja.wikipedia.org/wiki/%E3%83%8F%E3%83%BC%E3%83%9E%E3%83%B3%E3%83%BB%E3%82%AB%E3%83%BC%E3%83%B3) らが中心となり，@eq-object-integral の分布 $p$ に関する積分が\n$$\n\\begin{align*}\n    \\E[g(\\b{\\theta})]&=\\int_\\Theta g(\\b{\\theta})p(\\b{\\theta})\\,d\\b{\\theta}\\\\\n    &=\\int_\\Theta\\frac{g(\\b{\\theta})p(\\b{\\theta})}{p^*(\\b{\\theta})}p^*(\\b{\\theta})\\,d\\b{\\theta}\n\\end{align*}\n$$\nという式変形により，別の分布 $p^*$ からのサンプリングを通じて計算できる，という技法が利用された．彼らはこれに**重点サンプリング法**という名前をつけた．これは [Gerald Goertzel](https://en.wikipedia.org/wiki/Gerald_Goertzel) による命名である可能性が高い [@Charly2022]．\n\nなお，当時は $p$ からのサンプリングを回避できるという点よりも，$p^*$ をうまく選ぶことにより元々の $p$ を用いた Monte Carlo 積分法を適用するよりも近似の精度をあげることが出来るという点の方が注目された [@Hammersley-Handscomb1964]．\n\n前節の Metropolis 法がMCMCの先駆けであるとしたら，この2つの美点を持った重点サンプリング法は，[SMC（粒子フィルター）](../2023-11-25/ParticleFilter.qmd) の先駆けであった．\n\n## MCMCの普及とギブスサンプラー\n\nMetropolis 法の発明から，すぐにMCMCの画期性が広く認識された訳ではなかった．特に，元々物理学の文脈で発明されたこともあり，統計学の文脈への応用が始まるには [@Hastings1970] の仕事を待つ必要があった．\n\nしかし1970年代とはマイクロプロセッサが開発されたばかりの時代であり，^[1970年にインテルが世界初の DRAMである Intel 1103 を発売した．[Wikipediaページ](https://ja.wikipedia.org/wiki/%E6%83%85%E5%A0%B1%E9%9D%A9%E5%91%BD)参照．] MCMCが実際の統計解析の現場で採用可能な計算手法になるとは（そもそも現代のように小型なコンピュータを個人が所有するようになるとは）夢にも思われなかった時代であったが，ここからたったの20年で現代人の生活とベイズ統計学は大きく変わることになる．\n\n1. 各人が安価に高性能なコンピュータを所有するようになった．\n2. 高次元分布からのサンプリングを可能にするアルゴリズムが発見された．\n\nの2点が最後に加わることで，MCMCがベイズ計算法不動の金科玉条となった．\n\nこの 2.は計算機の性能の問題だけでなく，**Gibbsサンプラー**という新たなアルゴリズムの開発 [@Geman-Geman1984] によって実現された．^[物理学ではHeat Bath法と呼ばれ古くから同様のアルゴリズムが存在したが，統計学界隈では現在でもGibbsサンプラーと呼ばれる．] これは，パラメータ $\\b{\\theta}=(\\theta_1,\\theta_2)^\\top$ と表されるとき，適切に定めた初期値 $\\theta_2^{(0)}$ から初めて，条件付き分布からのサンプリング\n$$\n\\theta_1^{(i)}\\sim p_1(\\theta_1^{(i)}|\\theta_2^{(i-1)},\\y),\n$$\n$$\n\\theta_2^{(i)}\\sim p_2(\\theta_2^{(i)}|\\theta_1^{(i)},\\y),\n$$\nを繰り返すことで，最終的に $\\b{\\theta}^{(i)}:=(\\theta_1^{(i)},\\theta_2^{(i)})^\\top$ は全体として $p(\\b{\\theta}|\\y)$ に従うように収束する，という技法である．\n\nGibbs 法により，パラメータ $\\b{\\theta}$ の次元が大きく，直接のサンプリングが難しい場合でも，$\\b{\\theta}=(\\theta_1,\\theta_2,\\cdots)$ というように低次元変数の結合と理解することで，あるいは**補助変数**を追加してわざと問題を高次元化してでもそのような状況をうまく作り出すことで [@Tanner-Wong1987] ，部分的な低次元サンプリングから組み上げることが出来るようになった．さらにその後も，このアイデアが [@Roberts-Rosenthal1999-SliceSampler] のスライスサンプラーにつながっている．\n\nこの点をはっきり強調して示し，ベイズ統計学がすでに実行可能なものになっており，ベイズ統計学の基本問題（ @sec-fundamental-problem-of-Bayes ）もすでに過去の遺物となっているということを，統計学界隈に広く知らしめたのが [@Gelfand-Smith1990] であった．\n\n# ベイズ統計学のこれから\n\n複雑化の一途を辿るモデル・データに対応できるベイズ計算手法の開発が，今後最も重要な課題である．情報コミュニケーション技術が高度に発展した現代ならではの課題は，次の3つに大きく分類できる：\n\n1. 尤度不明モデル：尤度が解析的に得られない（または計算不可能）ほどに複雑なモデル\n2. 変数 $\\b{\\theta}$ が高次元である：多くの変数を考慮に入れた高次元モデル\n3. 観測 $\\y$ が高次元である：ビッグデータを用いた解析\n\n## 擬似周辺尤度法\n\n実は尤度 $p(\\y|\\b{\\theta})$ が解析的に得られない場合や計算が極めて困難になる場合でも，この不偏推定量があればMCMCを実行して事後分布を得るのに十分である [@Andrieu-Roberts2009]．この尤度 $p(\\y|\\b{\\theta})$ の不偏推定量を得るのに粒子フィルターを用いた場合を，特に**粒子MCMC**という [@Andrieu+2010-PMCMC]．\n\nこのときの不偏推定量の性能が最終的な Monte Carlo 推定量に影響する．不偏推定量の分散を改善するには，サブルーチンである粒子フィルターの反復数を増やす必要がある．すると本体であるMCMCの反復数とのトレードオフが生じる．こうしてアルゴリズムの最適な調整が課題になる．\n\n## 高次元問題に対処するMCMC\n\nほとんどのMCMC手法は，データサイズやモデルのパラメータサイズの増加に対して，計算負荷が飛躍的に上昇する次元の呪いに苦しむ．これを克服する手法は**scalability**の名の下に盛んに研究されている [@鎌谷2021 p.394]．\n\n1. 対象分布の探索を効率よく行う手法として，HMC (Hamiltonian Monte Carlo) 法が提案された [@Neal2011-HMC]．他にも NUTS (No U-Turn Sampling) [@Hoffman-Gelman2014-NUTS], Metropolis-Adjusted Langevin Algorithm [@Roberts-Tweedie1996], Stochastic Gradient MCMC [@Nemeth-Fearnhead2021], PDMP (区分的確定なMCMC) [@Bierkens+2018-PDMC], [@Fearnhead+2018-PDMC] とジグザグサンプラー [@Bierkens+2019-ZigZag] などがある，\n2. より良い提案分布の選択法について，MH法の最適スケーリング法，適応的サンプリング，焼き戻しなどの手法がある．\n3. 並列計算による効率化の方向性には，並列MCMC，完全サンプリングなどの手法がある．\n4. 他の分散低減法に，Rao-Blackwell化 [@Casella-Robert1996]，操作変数法などがある．\n\n## 近似ベイズ手法\n\n上述までの手法はいずれもシミュレーションを十分多く行えば（理論的には）任意の精度で正しい値を得ることができるが，^[この性質を指して，approximateの対義語としてexactという形容詞で表現される．] その適用範囲やスケーラビリティが課題なのであった．そこで同時に，最初からある許容精度を定めた下での近似を実行することとし，代わりにより広い適用可能性と計算速度を得るための手法も探求されている．これを**近似ベイズ法**という．\n\n一つのアプローチはシミュレーションによる方法である．これにはABC (Approximation Bayesian Computation) [@Tavare97-ABC-for-DNA] と BSL (Bayesian synthetic likelihood) [@Price2018-BSL] の2つの手法があるが，いずれもデータ生成過程（モデル）の複雑性と高次元性という２つの障壁が併存したときでも使える手法である．ABCではまず事後分布 $p(\\b{\\theta}|\\y)$ をある低次元な要約統計量 $S:\\mathcal{Y}\\to\\R^d$ を用いて $p(\\b{\\theta}|S(\\y))$ で近似し，さらに尤度 $p(\\y|\\b{\\theta})$ を直接評価することは回避し，シミュレーションのみを用いて $p(\\b{\\theta}|S(\\y))$ を推定する．BSLはさらに尤度 $p(S(\\y)|\\b{\\theta})$ にパラメトリックな仮定をおく．\n\n第二に最適化による方法がある．変分ベイズ手法とは，これは大きなパラメトリックモデル $\\{q^*(\\b{\\theta})\\}$ の中から $p(\\b{\\theta}|\\y)$ に最も近いものを選ぶ手法である．一方で INLA (integrated nested Laplace approximation) とは，Laplaceの近似（ @sec-Laplace ）に最適化を組み合わせて高次元の問題にも対応する．\n\nABCでは逐次モンテカルロ法も大きな役割を果たしており，ABC-SMC [@Sisson+2007]，ABCフィルタリング [@Jasra+2012-ABCFiltering]，更には変分Bayes法への応用 [@Tran+2017] なども進んでいる．\n\n変分Bayesの枠組みでは，モデルの誤想定に頑健な手法の開発も試みられている [@Wang-Blei2019]．\n\n## ベイズ統計モデリングが理論モデルの実証に役立つ {#sec-BayesianModeling}\n\nベイズモデリングの有用性は，（上述のベイズ計算の問題を除けば）どんなに複雑で大規模なモデルでも，統一的な思想と方法で対応できる点にある．\n\n> **メカニズムを明示的に表現した数理社会学の数理モデルを，論理的に飛躍することなくダイレクトに統計モデルへと接続できる**ベイズ統計モデリングは，理論モデルベースの実証研究と相性のよい，たいへん便利な方法と言えるだろう． [@浜田宏2022 p.137]\n\nMCMCの開発とパッケージへの実装，そして安価で高性能な計算機が普及してからというもの，ベイズ統計学の興隆は目覚ましく，現在ではベイズ統計学は統計学に関する論文の1割強を占め，諸科学分野全体に浸透しつつある．経済学・心理学への応用は早かったのに比べて，政治科学・社会科学への応用は遅れ気味であり，社会学での使用はまだ稀であると言える [@Lynch-Bartlett2019]．\n\n## ベイズによる因果推論 {#sec-BayesianCausalInference}\n\n前節に挙げたベイズモデリングの美点は因果推論の文脈でも全く同様である．特に因果推論の問題では推定対象が複雑であることが多いが，このような場合でも全く同じ枠組みを提供してくれるのがベイズである．頻度論的接近では設定に応じた個別具体的な議論がベイズ計算の問題に帰着する点が利点として働くことは多いようである [@Li+2023-BayesianCausalInference]．\n\n実際，ベイズノンパラメトリック手法は2016年の大西洋因果推論カンファレンスのコンペティションで大きな成功を見ている [@Dorie+2019]．加えて強い理論的な保証も得られつつあり [@Ray-vanderVaart2000]，これにより因果推論分野で大きな注目を集めている [@Linero-Antonelli2023], [@Daniels+2023-BayesianNonparametrics4Causal]．\n\n加えて，「あらゆる種の不確実性に対する統一的な定量化を与える」というベイズの性質は，因果推論から意思決定までの接続を地続きにし，例えば属人化医療などの現場でのダイナミックな意思決定に活用できることが期待される．\n\n> 不確実性を定量化するのに、ベイズ計算では必ず『確率』を使います。一般の人から見たら、統計で確率を使うのは当たり前と思うでしょうが、じつは他の統計手法ではそうでもなく、さまざまな解釈が生まれてしまう。定量化にはすべて統一的に確率を使うベイズ計算は、非常にシンプルなので、最終的にすべての統計はベイズに行き着くしかないと思っています．[鎌谷研吾](https://www.ism.ac.jp/ism_info_j/labo/project/162.html) \n\nしかし，ベイズの方法が因果推論の分野で普及するための障壁は，近づきやすさにあると議論できる [@Li+2023-BayesianCausalInference]．従来の頻度論的な因果推論手法の成功には，潜在反応モデルの特定を殆どしなくて良いこと（モデルフリー），実装が簡単であることが少なからず寄与しているとすれば，ベイズ的接近もこれに当たるものを提供できるようになる必要があるだろう．Stan言語 [@Carpenter+2017-Stan] はこの方向への大きな試みである．\n\n## ベイズ学習\n\n機械学習の手法を用いてベイズ推論を実行する営みをベイズ学習，または単に「機械学習への確率論的アプローチ」と言ってベイズの枠組みを暗に指す場合も多い [@Murphy2022-PML], [@Ghahramani2013]．\n\n古典的な統計手法と同様，多くの既存の（頻度論的）手法にはベイズ手法の対応物が存在する．ベイズの方法だと推定の確信度合いもセットで定量化され，頻度論的対応物よりも得られる情報が多い一方で，計算は既存手法よりも難しいことが多いという構造は，機械学習においても変わらない．\n\n実際，現存のニューラルネットワークの訓練法を超えるベイズ計算法が今後提案されるとは考えにくいが，その最適化する所の目的関数が例えば正則化項付きの平均自乗誤差である場合は，ある正規事前分布と正規尤度に対するMAP推定量に対応する ([Seitz 2022](https://www.sarem-seitz.com/posts/when-is-bayesian-machine-learning-actually-useful.html#bayesian-deep-learning-light-with-mc-dropout))．畢竟，多くの既存手法も「ベイズ学習を非ベイズ的な方法で実行している」と捉えられるのである（逆も然り）．\n\n中でもベイズ学習を採用するのが良い場面としては，モデルの大きさに対して学習に使えるデータの数が少ない場合や，モデルに事前情報を組み込みたい場合^[functional Bayes [@Sun2018functional] という手法では，希望する入力と出力の組を事前に用意するのみで，適切な事前分布を提案してくれる枠組みである．] ，さらには医療・政策への応用など意思決定に繋げるために不確実性の定量化が肝要な場面などがあり得る．\n\n実際，ベイジアン・ニューラルネットワークでは計算の困難ささえ乗り越えれば，複数の適切なモデルに対し，事後分布によって平均を取って最終的なモデルとすることで，過学習を防止し [@Mackay1995]，大きな性能改善を得ることができる [@Wilson-Izmailov2020]．\n\n## 21世紀の統計学とベイズの役割\n\nこのように，21世紀に入ってからベイズの成功は目まぐるしく，この傾向はさらに進むと思われる．これは統計計算の手法の進化によって達成された．今後とも統計計算の手法は，シミュレーション・変分法・最適化の垣根を超えて多様化の一途を辿るだろう [@Green+2015 p.857]．\n\nその中でも筆者は，ベイズ手法が提供する事後分布として得られる不確実性の表現・視覚化が，計算機・自然・人間の間のよきインターフェイスとなっていくことを願っている．^[推定結果に自信がないときはそう表明してくれる機械は親しみやすい．]\n\n> The applied statistician should be Bayesian in principle and calibrated to the real world in practice-—appropriate frequency calculations help to define such a tie. [@Rubin84-ABC]\n\n",
    "supporting": [
      "BayesianComp_files"
    ],
    "filters": [],
    "includes": {}
  }
}