---
title: "Whispter API を通じて日本語音声を書き起こす方法"
author: "Hirofumi Shiba"
date: "11/23/2023"
categories: [Lifestyle, Python]
toc: true
number-sections: true
image: 書き起こし.png
twitter-card: true
code-block-bg: true
code-block-border-left: "#5AB5BA"
code-overflow: wrap
abstract-title: 概要
abstract: Whispter API は25MBまでの音声ファイルしか書き起こししてくれないので，長時間の音声ファイルを一度に書き起こしてもらうには工夫が必要．
---

[![Whispter](書き起こし.png)](https://github.com/openai/whisper)

## Whispter のダウンロード

まず Whisper を [OpenAI の GitHub](https://github.com/openai/whisper) からダウンロードします．

```bash
pip install git+https://github.com/openai/whisper.git
```

さらに，内部で `ffmpeg` が必要になるので，これもダウンロードしておく必要があります．MacOS の場合は次のコマンドでインストールできます．^[それ以外の OS の場合は [こちら](https://github.com/openai/whisper) の `README.md` にやり方が書いてあります．]
```bash
brew install ffmpeg
```

ローカル環境ではなくとも，[Google Colaboratory](https://colab.research.google.com/?hl=ja) を用いてブラウザ上で実行することもできます．その場合の詳しいやり方は，[こちらのサイト](https://aismiley.co.jp/ai_news/what-is-whisper/) が参考になります．

## ファイルの分割

Whispter はどんなに大きな音声ファイルを渡しても 25MB 時点までしか書き起こしてくれません．そのため，ファイルを分割して Whispter に渡すこととします．次のコードは大きなファイルを分割するための関数を定義しています． `duration=240` で，何秒間でファイルを区切るかを指定します．筆者の経験上 240 秒（４分）がうまくいきます．

### `.wav` ファイルの場合

```python
import wave

def split_wav_file(filename, duration=240):
    # WAVファイルを開く
    with wave.open(filename, 'rb') as wav:
        # パラメータの取得
        n_channels, sampwidth, framerate, n_frames, comptype, compname = wav.getparams()

        # 5分間のフレーム数を計算
        frames_per_split = framerate * duration * n_channels * sampwidth

        # 全フレームを読み込み
        frames = wav.readframes(n_frames)

        # 分割してファイルに書き込む
        for i in range(0, len(frames), frames_per_split):
            # 新しいファイル名
            new_file = f'split_{i // frames_per_split}.wav'

            # 新しいファイルを書き込む
            with wave.open(new_file, 'wb') as new_wav:
                new_wav.setparams((n_channels, sampwidth, framerate, frames_per_split // (n_channels * sampwidth), comptype, compname))
                new_wav.writeframes(frames[i:i+frames_per_split])
```

こうして定義した関数を次のように用いると， `split_n.wav` という名前で，複数のファイルに分割してくれます．
```python
split_wav_file('［あなたの手元のファイル名］.wav')
```

### `.mp3` ファイルの場合

```python
from pydub import AudioSegment

def split_audio_file(filename, duration=240000):  # durationはミリ秒単位
    # ファイル形式を拡張子から判断
    extension = filename.split('.')[-1].lower()
    
    # AudioSegmentを使用してオーディオファイルを読み込む
    if extension == "wav":
        audio = AudioSegment.from_wav(filename)
    elif extension == "mp3":
        audio = AudioSegment.from_mp3(filename)
    else:
        raise ValueError("Unsupported file format")
    
    # 分割してファイルに書き込む
    start = 0
    part = 1
    while start < len(audio):
        # 新しいファイル名
        new_file = f'split_{part}.{extension}'
        # セグメントを切り出して保存
        segment = audio[start:start+duration]
        segment.export(new_file, format=extension)
        
        start += duration
        part += 1
```

ただし，目的となるファイルが存在するディレクトリで
```python
split_audio_file("［あなたの手元のファイル名］.mp3")
```
と使うようにしてください．

## 書き起こし

続いて，細かく分けたファイル `split_n.wav` たちを順に Whisper に渡して書き起こしてもらい，結果を１つのテキストファイル `書き起こし.txt` にまとめてもらいます．

```python
import whisper

# モデルのロード
model = whisper.load_model("large")  # やっぱ精度が違います

# ファイルのリスト
files = [f"split_{i}.wav" for i in range(27)]  # split_0.wav から split_26.wav まで

# 結果を格納するための空の文字列
transcription = ""

# 各ファイルを順番に処理
for file in files:
    # ファイルを書き起こし
    result = model.transcribe(file, language='ja')
    transcription += result["text"] + "\n\n"

# 書き起こし結果をテキストファイルに書き込む
with open("書き起こし.txt", "w", encoding="utf-8") as text_file:
    text_file.write(transcription)

```

ここでは最大のモデル `large` を用いています．その場合，結構な時間がかかります．