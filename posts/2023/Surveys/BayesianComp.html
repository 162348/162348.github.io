<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="司馬博文">
<meta name="dcterms.date" content="2023-12-06">

<title>ベイズ計算とは何か | About Bayesian Computation – Hirofumi Shiba</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../assets/Shiba2.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-69a118ed5aa843c5d3f13e92a12ee77e.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-f8de076aeb9658a6c96d343f1d6c5546.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-69a118ed5aa843c5d3f13e92a12ee77e.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-4c09742be2272f701a3e51422777528f.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-4c09742be2272f701a3e51422777528f.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-4c09742be2272f701a3e51422777528f.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "?",
    "H"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-36GX2G6GLL"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-36GX2G6GLL', { 'anonymize_ip': true});
</script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Zen+Kurenaido&amp;display=swap" rel="stylesheet">

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=BIZ+UDPGothic&amp;display=swap" rel="stylesheet">

<style>
  h1, .title, .description, .subtitle {
    font-family: "Zen Kurenaido", sans-serif !important;
  }
</style>

<!-- <style>
  .menu-text {
      font-family: "Gill Sans", sans-serif !important;
      font-weight: 400;
      font-style: normal;
  }
  .navbar-title {
      font-family: "Gill Sans", sans-serif !important;
      font-weight: 400;
      font-style: normal;
  }
</style> -->

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../assets/styles.css">
<meta property="og:title" content="ベイズ計算とは何か | About Bayesian Computation – Hirofumi Shiba">
<meta property="og:description" content="「ベイズ統計学」は一大トピックであるが，「ベイズ計算」という分野があることはそれほど周知のことではない．しかし，ベイズ統計学は常に「計算が困難で実行が難しい」という問題と共にあってきたのであり，ここ30年のベイズ統計学の興隆は計算機の普及と効率的なベイズ計算法の発明に因る．モデル・データがいずれも大規模で複雑になっていく現代において，ベイズの枠組みも柔軟に取り入れた更なる統計計算法の発展が欠かせない．">
<meta property="og:image" content="https://162348.github.io/posts/2023/Surveys/history.png">
<meta property="og:site_name" content="Hirofumi Shiba">
<meta property="og:image:height" content="400">
<meta property="og:image:width" content="1236">
<meta name="twitter:title" content="ベイズ計算とは何か | About Bayesian Computation – Hirofumi Shiba">
<meta name="twitter:description" content="「ベイズ統計学」は一大トピックであるが，「ベイズ計算」という分野があることはそれほど周知のことではない．しかし，ベイズ統計学は常に「計算が困難で実行が難しい」という問題と共にあってきたのであり，ここ30年のベイズ統計学の興隆は計算機の普及と効率的なベイズ計算法の発明に因る．モデル・データがいずれも大規模で複雑になっていく現代において，ベイズの枠組みも柔軟に取り入れた更なる統計計算法の発展が欠かせない．">
<meta name="twitter:image" content="https://162348.github.io/posts/2023/Surveys/history.png">
<meta name="twitter:creator" content="@ano2math5">
<meta name="twitter:image-height" content="400">
<meta name="twitter:image-width" content="1236">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Hirofumi Shiba</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-notes" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Notes</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-notes">    
        <li>
    <a class="dropdown-item" href="../../../static/English.html">
 <span class="dropdown-text">English Notes</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../blog.html">
 <span class="dropdown-text">ノート (Japanese)</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Materials.html"> 
<span class="menu-text">Materials</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Slides.html"> 
<span class="menu-text">Slides</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Software.html"> 
<span class="menu-text">Software</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
    <a href="https://github.com/162348/162348.github.io/" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">ベイズ計算とは何か | About Bayesian Computation</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Bayesian</div>
                <div class="quarto-category">Computation</div>
                <div class="quarto-category">Sampling</div>
                <div class="quarto-category">Survey</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>司馬博文 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">12/06/2023</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">12/10/2023</p>
      </div>
    </div>
      
    </div>
    
  <div>
    <div class="abstract">
      <div class="block-title">概要</div>
      「ベイズ統計学」は一大トピックであるが，「ベイズ計算」という分野があることはそれほど周知のことではない．しかし，ベイズ統計学は常に「計算が困難で実行が難しい」という問題と共にあってきたのであり，ここ30年のベイズ統計学の興隆は計算機の普及と効率的なベイズ計算法の発明に因る．モデル・データがいずれも大規模で複雑になっていく現代において，ベイズの枠組みも柔軟に取り入れた更なる統計計算法の発展が欠かせない．
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">目次</h2>
   
  <ul>
  <li><a href="#ベイズ計算のベイズとは何者か" id="toc-ベイズ計算のベイズとは何者か" class="nav-link active" data-scroll-target="#ベイズ計算のベイズとは何者か"><span class="header-section-number">1</span> 「ベイズ計算」の「ベイズ」とは何者か？</a>
  <ul class="collapse">
  <li><a href="#ベイズまでの統計学の黎明" id="toc-ベイズまでの統計学の黎明" class="nav-link" data-scroll-target="#ベイズまでの統計学の黎明"><span class="header-section-number">1.1</span> ベイズまでの統計学の黎明</a>
  <ul class="collapse">
  <li><a href="#john-grauntの死亡表" id="toc-john-grauntの死亡表" class="nav-link" data-scroll-target="#john-grauntの死亡表"><span class="header-section-number">1.1.1</span> John Grauntの死亡表</a></li>
  <li><a href="#統計学への期待と希望" id="toc-統計学への期待と希望" class="nav-link" data-scroll-target="#統計学への期待と希望"><span class="header-section-number">1.1.2</span> 統計学への期待と希望</a></li>
  </ul></li>
  <li><a href="#ベイズが取り組んだ問題" id="toc-ベイズが取り組んだ問題" class="nav-link" data-scroll-target="#ベイズが取り組んだ問題"><span class="header-section-number">1.2</span> ベイズが取り組んだ問題</a></li>
  <li><a href="#ベイズのアイデア" id="toc-ベイズのアイデア" class="nav-link" data-scroll-target="#ベイズのアイデア"><span class="header-section-number">1.3</span> ベイズのアイデア</a></li>
  <li><a href="#sec-fundamental-problem-of-Bayes" id="toc-sec-fundamental-problem-of-Bayes" class="nav-link" data-scroll-target="#sec-fundamental-problem-of-Bayes"><span class="header-section-number">1.4</span> ベイズ統計学の基本問題</a></li>
  <li><a href="#sec-Laplace" id="toc-sec-Laplace" class="nav-link" data-scroll-target="#sec-Laplace"><span class="header-section-number">1.5</span> Laplaceの近似</a></li>
  <li><a href="#ベイズ統計学の長く苦しい時代" id="toc-ベイズ統計学の長く苦しい時代" class="nav-link" data-scroll-target="#ベイズ統計学の長く苦しい時代"><span class="header-section-number">1.6</span> ベイズ統計学の長く苦しい時代</a></li>
  <li><a href="#sec-France" id="toc-sec-France" class="nav-link" data-scroll-target="#sec-France"><span class="header-section-number">1.7</span> フランスでの確率論の歴史</a></li>
  <li><a href="#quetelet-による綜合" id="toc-quetelet-による綜合" class="nav-link" data-scroll-target="#quetelet-による綜合"><span class="header-section-number">1.8</span> Quetelet による綜合</a></li>
  </ul></li>
  <li><a href="#sec-MCMC-SMC" id="toc-sec-MCMC-SMC" class="nav-link" data-scroll-target="#sec-MCMC-SMC"><span class="header-section-number">2</span> MCMCとSMCの発明</a>
  <ul class="collapse">
  <li><a href="#sec-MCMC" id="toc-sec-MCMC" class="nav-link" data-scroll-target="#sec-MCMC"><span class="header-section-number">2.1</span> マルコフ連鎖によるモンテカルロ法の発明</a></li>
  <li><a href="#sec-importance-sampling" id="toc-sec-importance-sampling" class="nav-link" data-scroll-target="#sec-importance-sampling"><span class="header-section-number">2.2</span> 重点サンプリング法の発明</a></li>
  <li><a href="#mcmcの普及とギブスサンプラー" id="toc-mcmcの普及とギブスサンプラー" class="nav-link" data-scroll-target="#mcmcの普及とギブスサンプラー"><span class="header-section-number">2.3</span> MCMCの普及とギブスサンプラー</a></li>
  </ul></li>
  <li><a href="#ベイズ統計学のこれから" id="toc-ベイズ統計学のこれから" class="nav-link" data-scroll-target="#ベイズ統計学のこれから"><span class="header-section-number">3</span> ベイズ統計学のこれから</a>
  <ul class="collapse">
  <li><a href="#擬似周辺尤度法" id="toc-擬似周辺尤度法" class="nav-link" data-scroll-target="#擬似周辺尤度法"><span class="header-section-number">3.1</span> 擬似周辺尤度法</a></li>
  <li><a href="#高次元問題に対処するmcmc" id="toc-高次元問題に対処するmcmc" class="nav-link" data-scroll-target="#高次元問題に対処するmcmc"><span class="header-section-number">3.2</span> 高次元問題に対処するMCMC</a></li>
  <li><a href="#近似ベイズ手法" id="toc-近似ベイズ手法" class="nav-link" data-scroll-target="#近似ベイズ手法"><span class="header-section-number">3.3</span> 近似ベイズ手法</a></li>
  <li><a href="#sec-BayesianModeling" id="toc-sec-BayesianModeling" class="nav-link" data-scroll-target="#sec-BayesianModeling"><span class="header-section-number">3.4</span> ベイズ統計モデリングが理論モデルの実証に役立つ</a></li>
  <li><a href="#ベイズによる逆問題" id="toc-ベイズによる逆問題" class="nav-link" data-scroll-target="#ベイズによる逆問題"><span class="header-section-number">3.5</span> ベイズによる逆問題</a></li>
  <li><a href="#sec-BayesianCausalInference" id="toc-sec-BayesianCausalInference" class="nav-link" data-scroll-target="#sec-BayesianCausalInference"><span class="header-section-number">3.6</span> ベイズによる因果推論</a></li>
  <li><a href="#ベイズ学習" id="toc-ベイズ学習" class="nav-link" data-scroll-target="#ベイズ学習"><span class="header-section-number">3.7</span> ベイズ学習</a></li>
  <li><a href="#世紀の統計学とベイズの役割" id="toc-世紀の統計学とベイズの役割" class="nav-link" data-scroll-target="#世紀の統計学とベイズの役割"><span class="header-section-number">3.8</span> 21世紀の統計学とベイズの役割</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="history.png" class="img-fluid figure-img"></p>
<figcaption>History of Bayesian Computation <span class="citation" data-cites="Martin+2023-history">(<a href="#ref-Martin+2023-history" role="doc-biblioref"><strong>Martin+2023-history?</strong></a>)</span></figcaption>
</figure>
</div>
<section id="ベイズ計算のベイズとは何者か" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> 「ベイズ計算」の「ベイズ」とは何者か？</h1>
<blockquote class="blockquote">
<p>賭博，生命保険，確率論この三つの間には，その発生に切っても切れない因縁がある．この点を明確に摘出することは，統計学の黎明を知るのに不可欠であろう． <span class="citation" data-cites="北川敏男49-統計学の認識">(<a href="#ref-北川敏男49-統計学の認識" role="doc-biblioref">北川敏男, 1949</a>)</span></p>
</blockquote>
<blockquote class="blockquote">
<p>de Moivre を彼の著 Approximation に，また Bayes を彼の定理に導いた原因は，純然たる数学的なものというよりも，神学的及び社会学的のものであった． <span class="citation" data-cites="Pearson1926">(<a href="#ref-Pearson1926" role="doc-biblioref">Pearson, 1926</a>)</span></p>
</blockquote>
<section id="ベイズまでの統計学の黎明" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="ベイズまでの統計学の黎明"><span class="header-section-number">1.1</span> ベイズまでの統計学の黎明</h2>
<p>統計学の黎明を要請したものは，社会への不安であった．筆者に言わせれば，この社会への不安を直視したのがドイツ，数で解決しようとしたのがイギリスで，解決への筋道を確率論で基礎づけたのがフランスである．</p>
<blockquote class="blockquote">
<p>プロシヤにおける国勢学，イギリスにおける政治算術，フランスにおける古典確率論–統計学はこれら３つの異った厳選を持つと言われる <span class="citation" data-cites="増山1950">(<a href="#ref-増山1950" role="doc-biblioref">増山元三郎, 1950, p. 6</a>)</span>．</p>
</blockquote>
<p>17世紀初頭から何度も流行を繰り返し，遂に1665年にはロンドンの人口の1/4を死に至らしめた <a href="https://ja.wikipedia.org/wiki/%E3%83%AD%E3%83%B3%E3%83%89%E3%83%B3%E3%81%AE%E5%A4%A7%E7%96%AB%E7%97%85">ペストの大流行</a> は恐怖の対象であった．パンデミックは現代でも恐怖の対象であるが，当時はその全貌の把握が難しく，これが第一に切望された．月の運行による健康被害，国王の統治が疫病を引き起こす，などの俗見が流布していた時代である．しかし，「数」という解決手段は極めて功を奏した．</p>
<p>数による解決が他でもないイギリスから生まれたことは，<a href="https://ja.wikipedia.org/wiki/%E3%83%95%E3%83%A9%E3%83%B3%E3%82%B7%E3%82%B9%E3%83%BB%E3%83%99%E3%83%BC%E3%82%B3%E3%83%B3_(%E5%93%B2%E5%AD%A6%E8%80%85)">Francis Bacon</a> 1561-1626 と <a href="https://ja.wikipedia.org/wiki/%E3%83%88%E3%83%9E%E3%82%B9%E3%83%BB%E3%83%9B%E3%83%83%E3%83%96%E3%82%BA">Thomas Hobbes</a> 1588-1679 に象徴される自然科学の風土，「Aristotelesの三段論法を通じて，経験的に因果関係を発見することで，我々は自然を理解できる」という希望が当時のイギリスには存在したことが挙げられる．</p>
<blockquote class="blockquote">
<p>海へ行け，きっと獲物があるぞという先輩が Bacon であった．漁獲法一般の講義をする先生が，例えば後世の J. S. Mill の帰納論理学に相当するのである．統計学を作った漁師たちは，Mill 先生の帰納法の論理学の講義などは，上の空で聞いた．そして各自の漁獲法を自らの浜で覚えたのである． <span class="citation" data-cites="北川敏男49-統計学の認識">(<a href="#ref-北川敏男49-統計学の認識" role="doc-biblioref">北川敏男, 1949, p. 12</a>)</span></p>
</blockquote>
<blockquote class="blockquote">
<p>新大陸の発見，東洋への海路の開拓により，世界商業の中心は砂漠の商隊と地中海の商人とを介して栄えていたイタリアから，スペイン・ポルトガル・オランダを経て16世紀の終り頃には，すでにイギリスに移っていたのである．ここに興隆の一路を辿る市民社会・殷盛を極める海上貿易・繁栄する英都の商業・封建制の崩壊を示す Cromwell 革命 (1649) 後のイギリス社会に，市民科学としての政治算術が起ったことは敢えて異とするに足りないであろう <span class="citation" data-cites="増山1950">(<a href="#ref-増山1950" role="doc-biblioref">増山元三郎, 1950, p. 10</a>)</span>．</p>
</blockquote>
<section id="john-grauntの死亡表" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="john-grauntの死亡表"><span class="header-section-number">1.1.1</span> John Grauntの死亡表</h3>
<p>ペスト流行の激しさの判定に寄与する人口状況を，最初に数によって理解しようとしたのが <a href="https://en.wikipedia.org/wiki/John_Graunt">John Graunt</a> 1620-1674 であった．</p>
<p>当時の英国王立理学協会<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> は，封建的な諸関係の崩壊解消と同時に，商品生産・貨幣による売買の全面支配によって貨幣的表現が富の大部分に侵入したことにより新たに誕生した市民階級が勢力を占めており，Graunt もこのような商人階級の出身であった．</p>
<p>そのような身分の Graunt が英国王の推薦を受けて王立協会員の名誉を勝ち取った論文 <span class="citation" data-cites="Graunt1662">(<a href="#ref-Graunt1662" role="doc-biblioref">Graunt, 1662</a>)</span> は，ギルド発行の死亡統計 <a href="https://en.wikipedia.org/wiki/Bills_of_mortality">Bills of Mortality</a> と教会に蓄積していた統計資料<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> から統計的な処理を通じて世界初の「死亡表」を作成し，次の内容を初めて結論づけた．</p>
<ul>
<li>36%の幼児は６歳未満で死亡する．</li>
<li>洗礼数をみると，男女比は16:15くらいである．</li>
<li>都市の死亡率は地方より高い．</li>
<li>Londonの城外では死亡率は３倍である．</li>
</ul>
<p>加えてLondonの世帯数を3通りの方法で推算し，世帯数は5万であろうと結論づけた．なお，当時の俗見ではLondon人口は100万と言われていた．</p>
<p>その後このような「生命表」は精緻化の一途を辿り，イギリスのギルド的な共助制度の土壌の上で，生命保険の成立という実を結んだ．</p>
</section>
<section id="統計学への期待と希望" class="level3" data-number="1.1.2">
<h3 data-number="1.1.2" class="anchored" data-anchor-id="統計学への期待と希望"><span class="header-section-number">1.1.2</span> 統計学への期待と希望</h3>
<p>このイギリスの数を使った解決は，<a href="https://ja.wikipedia.org/wiki/%E6%94%BF%E6%B2%BB%E7%AE%97%E8%A1%93">政治算術学派</a> と呼ばれ，海外への輸出が進んだ．</p>
<p>ドイツの牧師 <a href="https://ja.wikipedia.org/wiki/%E3%83%A8%E3%83%8F%E3%83%B3%E3%83%BB%E3%83%9A%E3%83%BC%E3%82%BF%E3%83%BC%E3%83%BB%E3%82%B8%E3%83%A5%E3%83%BC%E3%82%B9%E3%83%9F%E3%83%AB%E3%83%92">Johann Peter Süβmilch</a> 1707-1767 は Graunt に倣って，教会に蓄積していた統計資料を用い，出生率の性別比が長期的には女性1,000対男性1,050に収束することを発見した．</p>
<p>中でも特に，「たくさんのデータを集めると何かが見えてくる」ことに大きな希望を持ち，Graunt が教会の資料に注目したことを Columbus の新大陸発見になぞらえている．そう，<strong>歴史上最初の統計分析は，教会の資料によるものであった</strong>のである．</p>
<blockquote class="blockquote">
<p>若し我々が家を一軒一軒数えていくならば，ある家では娘だけに，またある家では息子だけに，あるいはそうでなくとも，非常に不釣り合いな両者の配合にでくわすであろう．小さな社会や村落でも秩序的なものを認めることは，容易ではない．（中略）．かかる場合に，誰が，能く規則と秩序とに想達し得るだろう．所で，教会の記録はこの秩序の確認のための大きな手段である．それは教会用及び世俗用のためにすでに数世紀前から取られ，<strong>とくに宗教改革後はかなり正確にとられてきた</strong>．誰がそれを利用したか？その発見はアメリカ発見と同時に可能であったのだ．（中略）<strong>それをGrauntがなし得たのである</strong>． –Süβmilch (1741) 『神の秩序』 (Göttliche Ordnung) 訳文は <span class="citation" data-cites="北川敏男49-統計学の認識">(<a href="#ref-北川敏男49-統計学の認識" role="doc-biblioref">北川敏男, 1949</a>)</span> より．</p>
</blockquote>
<p>このように Süβmilch は男児の出生率の方が高いことを神の存在証明と見なしたのであった．この宗教的な外被を取り去るには，確率論の登場をまたねばならなかったが，これにはさらにフランスの学派が合流するのを待つ必要があり，それには100年を要したのであった（ <a href="#sec-France" class="quarto-xref">Section&nbsp;1.7</a> も参照）．</p>
</section>
</section>
<section id="ベイズが取り組んだ問題" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="ベイズが取り組んだ問題"><span class="header-section-number">1.2</span> ベイズが取り組んだ問題</h2>
<p>というわけで，<span class="math inline">\(i=1,\cdots,n\)</span> 番目の世帯の新生児が，男児である <span class="math inline">\(y_i=1\)</span> か女児である <span class="math inline">\(y_i=0\)</span> かのデータなどから，人口・疫病・国家動態に役立つ知識を引き出すことが当時の重要な問題意識であることをわかっていただけただろう．</p>
<p>イギリスの牧師 <a href="https://ja.wikipedia.org/wiki/%E3%83%88%E3%83%BC%E3%83%9E%E3%82%B9%E3%83%BB%E3%83%99%E3%82%A4%E3%82%BA">Thomas Bayes</a> 1701-1761 は，より抽象的な設定で統計的推定の問題を研究していた．Bayes は就中，次のような区間推定の問題を考えていた．</p>
<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="ベイズが取り組んだ問題（現代語訳）">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>ベイズが取り組んだ問題（現代語訳）
</div>
</div>
<div class="callout-body-container callout-body">
<p>2値のデータ <span class="math inline">\(Y_i\in\{0,1\}\)</span> は，ある未知の「成功率」 <span class="math inline">\(\theta\in(0,1)\)</span> に従って， <span class="math display">\[
Y_i=\begin{cases}
1&amp;\text{確率 }\theta\text{ で}\\
0&amp;\text{残りの確率} 1-\theta\text{ で}
\end{cases}
\]</span> という値を取るとする．<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> このようなデータの独立観測標本 <span class="math inline">\(\boldsymbol{y}:=(y_1,\cdots,y_n)^\top\)</span> から．神のみぞ知る，このデータ <span class="math inline">\(\boldsymbol{y}\)</span> を生み出した真の成功率 <span class="math inline">\(\theta\)</span> が，区間 <span class="math inline">\((a,b)\subset(0,1)\)</span> に入っているという確率 <span class="math inline">\(\operatorname{P}[a&lt;\theta&lt;b|\boldsymbol{y}]\)</span> をどう見積もれば良いか？</p>
</div>
</div>
<p>ここでは引き続き <span class="math inline">\(Y_i\)</span> は性別で，<span class="math inline">\(\theta\)</span> は男児が生まれる確率 <span class="math inline">\(\theta=\operatorname{P}[Y_i=1]\)</span> だと解釈する．Bayes 自身は「ある未知の位置に白線が引かれたテーブル上にボールを <span class="math inline">\(n\)</span> 個転がし，それぞれの領域に幾つのボールが入ったかの情報のみから，白線の位置を推定する」という表現によって問題を定式化した <span class="citation" data-cites="Bayes1763">(<a href="#ref-Bayes1763" role="doc-biblioref">Bayes, 1763</a>)</span>．これは後世ではビリヤード台の問題とも呼ばれた．<a href="https://www.tcbegley.com/blog/posts/bayesian-billiards">こちらのサイト</a>も参照．</p>
</section>
<section id="ベイズのアイデア" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="ベイズのアイデア"><span class="header-section-number">1.3</span> ベイズのアイデア</h2>
<p>彼の発想は極めてシンプルであり，次の3段階によって推定を試みた：</p>
<ol type="1">
<li><strong>事前分布</strong> <span class="math inline">\(p(\theta)\)</span> と呼ばれる，最初の <span class="math inline">\(\theta\in(0,1)\)</span> に対する予想 <span class="math inline">\(p(\theta)\)</span> を自由に表現する．<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></li>
<li>事前分布のデータ <span class="math inline">\(\boldsymbol{y}\)</span> を観測した下での条件付き分布 <span class="math display">\[p(\theta|\boldsymbol{y}):=\frac{p(\theta,\boldsymbol{y})}{p(\boldsymbol{y})}\]</span> を計算する．これを<strong>事後分布</strong>という．</li>
<li>この事後分布 <span class="math inline">\(p(\theta|\boldsymbol{y})\)</span> の形から区間推定を実行する．</li>
</ol>
<p>この 3.の部分は，Bayes が特に区間推定に拘ったためのものであり，点推定でも良ければ次期予測でも良い．推定対象 3.を目的に応じて自由に入れ替えても，1.と 2.の部分が同じように動作するということ，これが<strong>ベイズ統計学</strong>の枠組みである．</p>
<p>それだけに事後分布というものが表現力に富んでいるのである．また，以下の例で納得していただけるかもしれないが，ベイズ統計学の手続きは「眼前のデータは，事前の信念を変えるのにどれほど説得的であるか？」という観点からも見れ，<strong>定量的であると同時に定性的な判断も可能にする</strong>． <a href="#sec-BayesianCausalInference" class="quarto-xref">Section&nbsp;3.6</a> で紹介するように，この特徴は意思決定への応用おいても重要である．</p>
<div class="callout callout-style-default callout-note no-icon callout-titled" title="問題に対する [@Bayes1763] の解決">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>問題に対する <span class="citation" data-cites="Bayes1763">(<a href="#ref-Bayes1763" role="doc-biblioref">Bayes, 1763</a>)</span> の解決
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>まず，事前分布 <span class="math inline">\(p(\theta)\)</span> を設定する．Bayes は前述のビリヤードの問題を考えていたこともあり， 「<span class="math inline">\(\theta\in(0,1)\)</span> は全く予想がつかない」「どんな <span class="math inline">\(\theta\)</span> も同様にあり得る」という立場を取った．横軸を <span class="math inline">\(\theta\in(0,1)\)</span> の値，縦軸を「主観的にあり得ると思う度合い」として図で表すと次の通りである：</li>
</ol>
<div id="21616c9c" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the range for x-axis</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Uniform distribution density function is constant</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.ones_like(x)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the graph</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">2</span>)) <span class="co"># Size suitable for a smartphone screen</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>plt.plot(x, y, label<span class="op">=</span><span class="st">'Uniform Distribution (0,1)'</span>, color<span class="op">=</span>(<span class="fl">0.35</span>, <span class="fl">0.71</span>, <span class="fl">0.73</span>, <span class="dv">1</span>))</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>plt.fill_between(x, y, color<span class="op">=</span>(<span class="fl">0.35</span>, <span class="fl">0.71</span>, <span class="fl">0.73</span>, <span class="fl">0.3</span>))</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="dv">0</span>, <span class="fl">1.5</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Posterior Distribution'</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="BayesianComp_files/figure-html/cell-2-output-1.png" width="296" height="228" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>この図が表す <span class="math inline">\((0,1)\)</span> 上の確率分布を一様分布という．このように，一様分布とは「どのような <span class="math inline">\(\theta\)</span> の値も同様に確からしい」という予想の表現である．</p>
<ol start="2" type="1">
<li><p>次に，データ <span class="math inline">\(\boldsymbol{y}=(y_1,\cdots,y_n)^\top\)</span> が観測された後の条件付き分布 <span class="math inline">\(p(\theta|\boldsymbol{y})\)</span> を計算することで，本データ <span class="math inline">\(\boldsymbol{y}\)</span> が事前の信念 <span class="math inline">\(p(\theta)\)</span> をどのように変えてしまうかを観る．簡単な確率論の結果として，条件付き分布は次の公式によって計算できる（<a href="../../../posts/2023/数理法務/法律家のための統計数理2.html#sec-Bayes-formula">講義ノート</a>も参照）：<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> <span id="eq-Bayes-formula"><span class="math display">\[
p(\theta|\boldsymbol{y})=\frac{p(\boldsymbol{y}|\theta)p(\theta)}{\int_\Theta p(\boldsymbol{y}|\theta)p(\theta)\,d\theta}
\tag{1}\]</span></span></p>
<p>例えば <a href="https://www.e-stat.go.jp/dbview?sid=0003411595">日本の2021年の出生児性別のデータ</a> を用いると次のようになる．</p></li>
</ol>
<div id="35494567" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> beta</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># パラメータの設定</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">811622</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>male <span class="op">=</span> <span class="dv">415903</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>female <span class="op">=</span> n <span class="op">-</span> male</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># ベータ分布のPDFを計算</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> beta.pdf(x, <span class="dv">1</span><span class="op">+</span>male, <span class="dv">1</span><span class="op">+</span>female)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co"># プロット</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">2</span>))</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>plt.plot(x, y, label<span class="op">=</span><span class="ss">f'Beta(</span><span class="sc">{</span><span class="dv">1</span><span class="op">+</span>male<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span><span class="dv">1</span><span class="op">+</span>female<span class="sc">}</span><span class="ss">)'</span>, color<span class="op">=</span>(<span class="fl">0.35</span>, <span class="fl">0.71</span>, <span class="fl">0.73</span>, <span class="dv">1</span>))</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>plt.fill_between(x, y, color<span class="op">=</span>(<span class="fl">0.35</span>, <span class="fl">0.71</span>, <span class="fl">0.73</span>, <span class="fl">0.3</span>))</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'p'</span>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>plt.xlim(<span class="fl">0.4</span>, <span class="fl">0.6</span>)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Probability Density'</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Bayesian Posterior Distribution'</span>)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="BayesianComp_files/figure-html/cell-3-output-1.png" width="310" height="228" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>こうして極めて鋭い事後分布が出来た．事前に設定した分布 <span class="math inline">\(p(\theta)\)</span> は極めて平坦な一様分布であったのに，それをデータで条件付けた <span class="math inline">\(p(\theta|\boldsymbol{y})\)</span> には極めて鋭いスパイクが現れたのである．<a href="#eq-Bayes-formula" class="quarto-xref">Equation&nbsp;1</a> を認めるならば，この図は「男児の方が女児よりも生まれる確率が高い」ことの証拠として，極めて説得的ではないだろうか？</p>
<ol start="3" type="1">
<li>では区間推定の例として，<span class="math inline">\((a,b)=(0.5,1.0)\)</span> として，「男児の方が女児よりも多い確率」を推定しよう．これは次を計算することになる： <span class="math display">\[
\begin{align*}
&amp;\operatorname{P}\left[\frac{1}{2}&lt;\theta&lt;1\right]\\
&amp;=\int^1_{\frac{1}{2}}p(\boldsymbol{y}|\theta)\,d\theta.
\end{align*}
\]</span></li>
</ol>
<div id="2ec6d9a7" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">sum</span>(y[<span class="dv">500</span>:<span class="dv">600</span>])<span class="op">/</span><span class="dv">1000</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>1.0030977682960893</code></pre>
</div>
</div>
<p>もはや丸め誤差により <span class="math inline">\(1\)</span> を越してしまっている．ほとんど確実に「男児の方が生まれる確率が高い」と結論づけて良いだろう．</p>
</div>
</div>
<p>この <span class="citation" data-cites="Bayes1763">(<a href="#ref-Bayes1763" role="doc-biblioref">Bayes, 1763</a>)</span> が実行したように，<strong>事後分布 <span class="math inline">\(p(\theta|\boldsymbol{y})\)</span> をみて <span class="math inline">\(\theta\)</span> に関する推論をする</strong>，という立場からの統計的営み全体を<strong>ベイズ統計学</strong>．</p>
</section>
<section id="sec-fundamental-problem-of-Bayes" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="sec-fundamental-problem-of-Bayes"><span class="header-section-number">1.4</span> ベイズ統計学の基本問題</h2>
<p>事後分布 <span class="math inline">\(p(\theta|\boldsymbol{y})\)</span> を導く際に用いた条件付き確率の公式である <a href="#eq-Bayes-formula" class="quarto-xref">Equation&nbsp;1</a> <span class="math display">\[
p(\theta|\boldsymbol{y})=\frac{p(\boldsymbol{y}|\theta)p(\theta)}{\int_\Theta p(\boldsymbol{y}|\theta)p(\theta)\,d\theta}\quad\text{(1)}
\]</span> は <a href="../../../posts/2023/数理法務/法律家のための統計数理2.html#sec-Bayes-formula"><strong>Bayesの公式</strong></a> と呼ばれるようになった．今回の場合では，Pythonコードをご覧になった方はわかったかもしれないが，事後分布は <span class="math display">\[
p(\theta|\boldsymbol{y})=\frac{\theta^m(1-\theta)^{n-m}}{B(m+1,n-m+1)}
\]</span> となり，これはパラメータの空間 <span class="math inline">\((0,1)\)</span> 上の <a href="../../../posts/2023/Probability/Beta-Gamma.html">Beta分布</a> と呼ばれるものである．</p>
<p>現代のベイズ統計学の多くの統計量は，ある可積分関数 <span class="math inline">\(g:\Theta\to\mathcal{X}\)</span> を用いて <span id="eq-object-integral"><span class="math display">\[
\operatorname{E}[g(\theta)|\boldsymbol{y}]=\int_{\Theta}g(\theta)p(\theta|\boldsymbol{y})\,d\theta
\tag{2}\]</span></span> と表される．先ほどの Bayes の区間推定の例では <span class="math inline">\(g=1_{(a,b)}\)</span> と取った場合に当たる．<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> 実は，<strong>この積分は，この最も簡単と思われる <span class="math inline">\(p(\theta),p(\boldsymbol{y}|\theta)\)</span> の設定でも，殆ど計算できないのである</strong>．</p>
<p>鮮やかな解決法を提示したかと思えば，結局実行出来ないのでは全く本末転倒である！そのこともあってか，論文 <span class="citation" data-cites="Bayes1763">(<a href="#ref-Bayes1763" role="doc-biblioref">Bayes, 1763</a>)</span> は実は Bayes の死後に <a href="https://en.wikipedia.org/wiki/Richard_Price">Richard Price</a> によって投稿されたものであり，生前に自ら投稿・発表した訳ではなかった．<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> 当然，発表当時は全く注目を受けなかった <span class="citation" data-cites="Stigler1990">(<a href="#ref-Stigler1990" role="doc-biblioref">Stigler, 1990</a>)</span>．</p>
<blockquote class="blockquote">
<p>Hence, despite the analytical availability of <span class="math inline">\(p(\theta|\boldsymbol{y})\)</span> via (2)–“Bayes’ rule” as it is now known-—the quantity that was of interest to Bayes needed to be estimated, or <em>computed</em>. The quest for a computational solution to a Bayesian problem was thus born. <span class="citation" data-cites="Martin+2023-history">(<a href="#ref-Martin+2023-history" role="doc-biblioref"><strong>Martin+2023-history?</strong></a>)</span></p>
</blockquote>
<div class="callout callout-style-default callout-important no-icon callout-titled" title="まとめ：ベイズ統計学の基本問題">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>まとめ：ベイズ統計学の基本問題
</div>
</div>
<div class="callout-body-container callout-body">
<p>ベイズの提示した統一的な統計推測の枠組み</p>
<ol type="1">
<li>推定したい値 <span class="math inline">\(\theta\)</span> の空間上に<strong>事前分布</strong> <span class="math inline">\(p(\theta)\)</span> を設定する．</li>
<li>事前分布 <span class="math inline">\(p(\theta)\)</span> のデータ <span class="math inline">\(\boldsymbol{y}\)</span> に関する条件付き分布として<strong>事後分布</strong> <span class="math inline">\(p(\theta|\boldsymbol{y})\)</span> を得る．</li>
</ol>
<p>は非常に自然で，特に確率分布 <span class="math inline">\(p(\theta),p(\theta|\boldsymbol{y})\)</span> を簡単に視覚化できる現代では「データ <span class="math inline">\(\boldsymbol{y}\)</span> は，パラメータ <span class="math inline">\(\theta\)</span> に対する事前の信念をどれほど変えるに値するか？」を定量的にも定性的にも実感出来るという美点がある．</p>
<p>しかしながら，モデル <span class="math inline">\(p(\theta),p(\boldsymbol{y}|\theta)\)</span> の設定をいくら簡単にしても根本的に計算が困難で実行不可能なのである．これを解決する分野を<strong>ベイズ計算</strong>という．ベイズの論文 <span class="citation" data-cites="Bayes1763">(<a href="#ref-Bayes1763" role="doc-biblioref">Bayes, 1763</a>)</span> でも，計算法の開発が約半分を占めた．<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> このように，<strong>Bayes統計学は当初からBayes計算の問題を懐胎していた</strong>のである．</p>
<blockquote class="blockquote">
<p>In short, the implementation of all forms of Bayesian analysis relies heavily on numerical computation. <span class="citation" data-cites="Martin+2023-history">(<a href="#ref-Martin+2023-history" role="doc-biblioref"><strong>Martin+2023-history?</strong></a>)</span></p>
</blockquote>
</div>
</div>
</section>
<section id="sec-Laplace" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="sec-Laplace"><span class="header-section-number">1.5</span> Laplaceの近似</h2>
<p>フランスの数学者 Laplace は25歳時の初めての統計に関する著作 <span class="citation" data-cites="Laplace1774">(<a href="#ref-Laplace1774" role="doc-biblioref">Laplace, 1774</a>)</span> を発表した．この中で，Bayes が解こうとしたものと全く同じ</p>
<p><span id="eq-Beta-integral"><span class="math display">\[\begin{align*}
    &amp;\operatorname{P}[a&lt;\theta&lt;b|\boldsymbol{y}]\\
    &amp;\quad=\frac{\int^b_a\theta^m(1-\theta)^{n-m}\,d\theta}{B(m+1,n-m+1)}
\end{align*} \tag{3}\]</span></span></p>
<p>という積分計算の問題を，被積分関数を <span class="math display">\[
f(\theta):=\frac{\log p(\theta|\boldsymbol{y})}{n}
\]</span> を用いて指数関数の形に表すことで解いた：<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> <span class="math display">\[
\begin{align*}
    \operatorname{P}[a&lt;\theta&lt;b|\boldsymbol{y}]&amp;=\int^b_ap(\theta|\boldsymbol{y})\,d\theta\\
    &amp;=\int^b_ae^{nf(\theta)}\,d\theta
\end{align*}
\]</span> この形に変形することがどのように役立つかは，次の定理が説明してくれる：</p>
<div class="callout callout-style-default callout-tip callout-titled" title="定理（Laplace近似）">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>定理（Laplace近似）
</div>
</div>
<div class="callout-body-container callout-body">
<p><a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> 関数 <span class="math inline">\(f:[a,b]\to\mathbb{R}\)</span> はただ一つの最大値を <span class="math inline">\(x_0\in(a,b)\)</span> で取り，<span class="math inline">\(f''(x_0)&gt;0\)</span> を満たすとする．このとき <span class="math inline">\(n\to\infty\)</span> の極限について， <span class="math display">\[
\int^b_ae^{nf(x)}\,dx\sim\sqrt{-\frac{2\pi}{nf''(x_0)}}e^{nf(x_0)}
\]</span></p>
</div>
</div>
<p>これを <span class="math inline">\(f\)</span> の二次近似について適用することで，あらゆる確率分布 <span class="math inline">\(p(\theta|\boldsymbol{y})\,d\theta\)</span> に関する積分 <a href="#eq-Beta-integral" class="quarto-xref">Equation&nbsp;3</a> を，その正規近似に関する積分で近似できるのである．</p>
<p>この手法は現在のBayes計算手法のアイデアの源泉であり続けている <span class="citation" data-cites="Rue+2009">(<a href="#ref-Rue+2009" role="doc-biblioref">Rue et al., 2009</a>)</span>, <span class="citation" data-cites="MacKay2003">(<a href="#ref-MacKay2003" role="doc-biblioref">MacKay, 2003</a>)</span>．</p>
</section>
<section id="ベイズ統計学の長く苦しい時代" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="ベイズ統計学の長く苦しい時代"><span class="header-section-number">1.6</span> ベイズ統計学の長く苦しい時代</h2>
<p>「ベイズの枠組みは理念的に好ましかろうと，実際には実行不可能である」というベイズ統計学の基本問題は，Laplace が普遍的な近似計算法を開発したこと（ <a href="#sec-Laplace" class="quarto-xref">Section&nbsp;1.5</a> ）を除いて，次の進展を見るには計算機の発明と普及を待つ必要があった．その間実に2世紀超えである．</p>
<p>また，Laplace の近似手法は普遍的であり，Bayes の最初の設定のような簡単な設定の <span class="math inline">\(p(\theta|\boldsymbol{y}),g\)</span> に限らずとも使えるという，ベイズ統計学に大きく資する特徴も備えていたが，パラメータ <span class="math inline">\(\theta\in(0,1)\)</span> の次元が1ではなくなると途端に使えなくなるという欠点がある．</p>
<blockquote class="blockquote">
<p>（前略）ベイズ統計学の有用性は以前から理解されていたが，この問題の抜本的な解決は1980年代まで待たざるを得なかった．<strong>それ以前は，ベイズの定理自体は18世紀に早々に発見されたにもかかわらず，長い間，確率の解釈，事前分布の設定，事後分布の計算の困難さのために哲学的議論に終始し，実用化にはほど遠かったのである</strong>．実用化の扉の鍵となったのは，一つは計算機の急速な発達，もう一つは計算集約的な画期的アルゴリズムの提案である． <span class="citation" data-cites="樋口知之2014">(<a href="#ref-樋口知之2014" role="doc-biblioref">樋口知之, 2014, p. 17</a>)</span></p>
</blockquote>
</section>
<section id="sec-France" class="level2" data-number="1.7">
<h2 data-number="1.7" class="anchored" data-anchor-id="sec-France"><span class="header-section-number">1.7</span> フランスでの確率論の歴史</h2>
<p>このように，Laplace が，ベイズ統計学暗黒の時代の中で唯一の小さな前進を生んだ．それだけでなく，Laplace は後の1812年に当時の確率論最大の集大成と言える大著『確率論の解析理論』を産んでおり，これが他でもないフランスから生まれたことにも相応の理由があった．</p>
<p>まず第一に，賭博の流行により，確率というものの理解と征服が嘱望された．</p>
<blockquote class="blockquote">
<p>その（確率論の）発展の動きを与えたものは，交易を賭ける商業資本家が占星術よりも確実な指導をこの学術に求めるという様な社会が基盤となって存在したことである．例えば，17世紀中葉のPascalとFermatの間の往復文書に取り扱われたカード遊びの数学的問題が，広く人々の関心を呼び起こした事情の裏には，至富の途を確実に求める商人たちの渇望が学問が外の世界にあったことを忘れてはならない． <span class="citation" data-cites="北川敏男49-統計学の認識">(<a href="#ref-北川敏男49-統計学の認識" role="doc-biblioref">北川敏男, 1949</a>)</span></p>
</blockquote>
<p>第二に，統計的現象を神学的な畏怖の対象と見るのではなく，自然科学による自然の理解と征服の文脈の最先端として理解する土壌がフランスにあったことが指摘できる．</p>
<blockquote class="blockquote">
<p>17, 18世紀の啓蒙的合理主義は，偶然的な事象に対しても数学的な取り扱いを行うことに特別の興味を持った．思想的にはこの時代精神こと確率論を発展させた最大の動力であった．その駆使する数学解析の多彩と合理主義の徹底とに於て，Laplace の大著はよくこの時代を代表するものと言うべきであろう．</p>
</blockquote>
<p>当時の財務総監 Jacques Turgot を通じてパリ造幣局の監査官も務めた <a href="https://ja.wikipedia.org/wiki/%E3%83%8B%E3%82%B3%E3%83%A9%E3%83%BB%E3%83%89%E3%83%BB%E3%82%B3%E3%83%B3%E3%83%89%E3%83%AB%E3%82%BB">Nicolas de Condorcet</a> 1743-94 は Laplace の確率論を積極的に社会分析に応用した．「社会数学」と呼んだこの運動は社会学の源流ともみなされる． 当然後進も Laplace に続いた．ベルギーの数学者 <a href="https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%89%E3%83%AB%E3%83%95%E3%83%BB%E3%82%B1%E3%83%88%E3%83%AC%E3%83%BC">Adolphe Quetelet</a> 1796-74 は Laplace の確率論を社会に応用することを目指し「社会物理学」なる分野を創始し，BMIの別名「ケトレー指数」にも名を残している．<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a></p>
<blockquote class="blockquote">
<p>古典確率論の一応の完成は典雅に見えるであろう．<strong>だが人は，確率論のもった政治的，社会的意義を忘れてはならない</strong>．理知を一切の尺度として「<strong>代数学の炉火によって倫理学及び政治学を照さん</strong>」(Condorcet) という時代精神，神の啓示に代らんとする確率論，それはフランス革命の思想的基礎に連関することを見失ってはならないのである． <span class="citation" data-cites="北川敏男49-統計学の認識">(<a href="#ref-北川敏男49-統計学の認識" role="doc-biblioref">北川敏男, 1949</a>)</span></p>
</blockquote>
</section>
<section id="quetelet-による綜合" class="level2" data-number="1.8">
<h2 data-number="1.8" class="anchored" data-anchor-id="quetelet-による綜合"><span class="header-section-number">1.8</span> Quetelet による綜合</h2>
<p>Quetelet は応用統計学の祖とも呼ばれる．</p>
<blockquote class="blockquote">
<p>［政治算術学派から人口理論 <span class="citation" data-cites="Malthus1798">(<a href="#ref-Malthus1798" role="doc-biblioref">Malthus, 1798</a>)</span> をはじめとする数多くの統計的法則の発見など，多くの成果があったにも拘らず，］18世紀の後半は理論的成果の観点からは全く空白の時代であった．吾々はその原因を方法論が進歩しなかった点に見出しうる．先験的対数法則を中枢とする古典確率論の方法がこれと合流するに至るまで，統計学の理論的分野は足踏みを続けざるを得なかったのである．後述 <strong>Quetelet の手による，この合流の着手は，応に近代的意味における統計学の発足を示すものであるとともに，記述統計学の定礎を意味するものでなければならなかった</strong>．<span class="citation" data-cites="増山1950">(<a href="#ref-増山1950" role="doc-biblioref">増山元三郎, 1950, p. 12</a>)</span></p>
</blockquote>
</section>
</section>
<section id="sec-MCMC-SMC" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> MCMCとSMCの発明</h1>
<p>「積分が計算できない」というベイズ統計学の基本問題（ <a href="#sec-fundamental-problem-of-Bayes" class="quarto-xref">Section&nbsp;1.4</a> ）は，計算機の発達と普及も欠かせなかったが，<strong>シミュレーションを取り入れた確率的アルゴリズムであるマルコフ連鎖モンテカルロ法 (MCMC) の発明</strong>によって本質的に解決された．</p>
<p>しかし，この解決は必ずしも初めからベイズ統計学のために考案されたわけではなく，むしろ物理学と第二次世界大戦とが着火剤となった．アメリカの原爆開発計画において，当時の数値積分法では解けないような高次元の積分を，通常のモンテカルロ積分法は使えない状況下で解く必要があったことが，MCMC発明の契機となった．</p>
<blockquote class="blockquote">
<p>In fact, until Bayesians discovered MCMC, the only computational methodology that seemed to offer much chance of making practical Bayesian statistics practical was the portfolio of quadrature methods developed under Adrian Smith’s leadership at Nottingham. <span class="citation" data-cites="Green+2015">(<a href="#ref-Green+2015" role="doc-biblioref">Green et al., 2015, p. 836</a>)</span></p>
</blockquote>
<section id="sec-MCMC" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="sec-MCMC"><span class="header-section-number">2.1</span> マルコフ連鎖によるモンテカルロ法の発明</h2>
<p>乱数のシミュレーションを用いた確率的なアルゴリズムをモンテカルロ法と総称する．これは Metropolis が同僚 Ulam のポーカー好きから，モナコの首都 Monte Carlo にちなんで名付けたものである <span class="citation" data-cites="Metropolis-Ulam1949">(<a href="#ref-Metropolis-Ulam1949" role="doc-biblioref">Nicholas Metropolis and Ulam, 1949</a>)</span>．このようなアルゴリズムが最初に生まれたのが，第二次世界大戦中の <a href="https://ja.wikipedia.org/wiki/%E3%83%AD%E3%82%B9%E3%82%A2%E3%83%A9%E3%83%A2%E3%82%B9%E5%9B%BD%E7%AB%8B%E7%A0%94%E7%A9%B6%E6%89%80">Los Alamos研究所</a> で進行中だった原爆開発計画である <a href="https://ja.wikipedia.org/wiki/%E3%83%9E%E3%83%B3%E3%83%8F%E3%83%83%E3%82%BF%E3%83%B3%E8%A8%88%E7%94%BB">Manhattan計画</a> においてである．</p>
<p>当時の問題は，原子爆弾着火時における Schödinger 作用素の基底状態のエネルギーを計算することにあった．抽象的には，<span class="math inline">\(p\)</span> を <span class="math inline">\(N\)</span> 個の粒子が従う Boltzmann 分布として，積分 <a href="#eq-object-integral" class="quarto-xref">Equation&nbsp;2</a> を計算することにあった：</p>
<p><span class="math display">\[
\operatorname{E}[g(\boldsymbol{\theta})]=\int_\Theta g(\boldsymbol{\theta})p(\boldsymbol{\theta})\,d\boldsymbol{\theta}\quad\text{(2)}
\]</span></p>
<p>ただし，</p>
<ol type="1">
<li>積分領域 <span class="math inline">\(\Theta\)</span> が <span class="math inline">\(2N\)</span> 次元というとてつもない高次元空間上であること</li>
<li>分布 <span class="math inline">\(p\)</span> は定数倍を除いてしか計算できない</li>
</ol>
<p>という，2つの大きな制約があった．1.のために通常の数値積分法が使えず，また 2.により <span class="math inline">\(p\)</span> からの直接の乱数シミュレーションが出来ないので，<span class="math inline">\(p\)</span> からの乱数 <span class="math inline">\(X_1,\cdots,X_M\)</span> を十分多く生成することで積分 <a href="#eq-object-integral" class="quarto-xref">Equation&nbsp;2</a> を <span class="math display">\[
\frac{1}{M}\sum_{i=1}^Mg(X_i)
\]</span> によって近似するという通常の Monte Carlo 積分法を実行することも出来ない．そこで，Metropolis ら当時の Los Alamos に集まった物理学者たちは新しい方法を考える必要があった．</p>
<p>最終的な解決 <span class="citation" data-cites="Metropolis+1953">(<a href="#ref-Metropolis+1953" role="doc-biblioref">N. Metropolis et al., 1953</a>)</span> は，Monte Carlo 法の中でもとりわけ画期的な発想によるものであった．それは，<strong>Markov 連鎖を用いる</strong>ということである．<a href="https://ja.wikipedia.org/wiki/%E3%83%9E%E3%83%AB%E3%82%B3%E3%83%95%E9%80%A3%E9%8E%96">Markov連鎖</a>とは（ある一定の条件を満たす）確率過程のクラスであり，<span class="math inline">\(p\)</span> から直接のシミュレーションが出来ない状況でも，<span class="math inline">\(p\)</span> に収束するようなMarkov 連鎖を構成することは可能だったのである．</p>
<p>制約 1.と 2.は広く物理学とベイズ統計学の至る所で見られる障壁であり，これをものともしない汎用アルゴリズムの発明は極めて大きなブレイクスルーであった．<span class="citation" data-cites="Dongarra-Sulliavn2000">(<a href="#ref-Dongarra-Sulliavn2000" role="doc-biblioref">Dongarra and Sullivan, 2000</a>)</span> は Metropolis アルゴリズムを理学・工学分野に20世紀最大の影響を与えたアルゴリズムの1つとしている．</p>
</section>
<section id="sec-importance-sampling" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="sec-importance-sampling"><span class="header-section-number">2.2</span> 重点サンプリング法の発明</h2>
<p>実は Manhattan 計画に最中に，もう一つのサンプリング技法が生まれていた．厚い壁で中性子線とガンマ線がどのように吸収されるかに取り組んでいたグループにて，<a href="https://ja.wikipedia.org/wiki/%E3%83%8F%E3%83%BC%E3%83%9E%E3%83%B3%E3%83%BB%E3%82%AB%E3%83%BC%E3%83%B3">Herman Kahn</a> らが中心となり，<a href="#eq-object-integral" class="quarto-xref">Equation&nbsp;2</a> の分布 <span class="math inline">\(p\)</span> に関する積分が <span class="math display">\[
\begin{align*}
    \operatorname{E}[g(\boldsymbol{\theta})]&amp;=\int_\Theta g(\boldsymbol{\theta})p(\boldsymbol{\theta})\,d\boldsymbol{\theta}\\
    &amp;=\int_\Theta\frac{g(\boldsymbol{\theta})p(\boldsymbol{\theta})}{p^*(\boldsymbol{\theta})}p^*(\boldsymbol{\theta})\,d\boldsymbol{\theta}
\end{align*}
\]</span> という式変形により，別の分布 <span class="math inline">\(p^*\)</span> からのサンプリングを通じて計算できる，という技法が利用された．彼らはこれに<strong>重点サンプリング法</strong>という名前をつけた．これは <a href="https://en.wikipedia.org/wiki/Gerald_Goertzel">Gerald Goertzel</a> による命名である可能性が高い <span class="citation" data-cites="Charly2022">(<a href="#ref-Charly2022" role="doc-biblioref">Andral, 2022</a>)</span>．</p>
<p>なお，当時は <span class="math inline">\(p\)</span> からのサンプリングを回避できるという点よりも，<span class="math inline">\(p^*\)</span> をうまく選ぶことにより元々の <span class="math inline">\(p\)</span> を用いた Monte Carlo 積分法を適用するよりも近似の精度をあげることが出来るという点の方が注目された <span class="citation" data-cites="Hammersley-Handscomb1964">(<a href="#ref-Hammersley-Handscomb1964" role="doc-biblioref">Hammersley and Handscomb, 1964</a>)</span>．</p>
<p>前節の Metropolis 法がMCMCの先駆けであるとしたら，この2つの美点を持った重点サンプリング法は，<a href="../../../posts/2023/Surveys/ParticleFilter.html">SMC（粒子フィルター）</a> の先駆けであった．</p>
</section>
<section id="mcmcの普及とギブスサンプラー" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="mcmcの普及とギブスサンプラー"><span class="header-section-number">2.3</span> MCMCの普及とギブスサンプラー</h2>
<p>Metropolis 法の発明から，すぐにMCMCの画期性が広く認識された訳ではなかった．特に，元々物理学の文脈で発明されたこともあり，統計学の文脈への応用が始まるには <span class="citation" data-cites="Hastings1970">(<a href="#ref-Hastings1970" role="doc-biblioref">Hastings, 1970</a>)</span> の仕事を待つ必要があった．</p>
<p>しかし1970年代とはマイクロプロセッサが開発されたばかりの時代であり，<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> MCMCが実際の統計解析の現場で採用可能な計算手法になるとは（そもそも現代のように小型なコンピュータを個人が所有するようになるとは）夢にも思われなかった時代であったが，ここからたったの20年で現代人の生活とベイズ統計学は大きく変わることになる．</p>
<ol type="1">
<li>各人が安価に高性能なコンピュータを所有するようになった．</li>
<li>高次元分布からのサンプリングを可能にするアルゴリズムが発見された．</li>
</ol>
<p>の2点が最後に加わることで，MCMCがベイズ計算法不動の金科玉条となった．</p>
<p>この 2.は計算機の性能の問題だけでなく，<a href="../../../posts/2024/Computation/PGM1.html#sec-separation-in-markov-network">統計的画像処理</a> の分野から <strong>Gibbsサンプラー</strong> という新たなアルゴリズムが生まれた <span class="citation" data-cites="Geman-Geman1984">(<a href="#ref-Geman-Geman1984" role="doc-biblioref">Geman and Geman, 1984</a>)</span> ことによって実現された．<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a> これは，パラメータが <span class="math inline">\(\boldsymbol{\theta}=(\theta_1,\theta_2)^\top\)</span> と表されるとき，適切に定めた初期値 <span class="math inline">\(\theta_2^{(0)}\)</span> から初めて，条件付き分布からのサンプリング <span class="math display">\[
\theta_1^{(i)}\sim p_1(\theta_1^{(i)}|\theta_2^{(i-1)},\boldsymbol{y}),
\]</span> <span class="math display">\[
\theta_2^{(i)}\sim p_2(\theta_2^{(i)}|\theta_1^{(i)},\boldsymbol{y}),
\]</span> を繰り返すことで，最終的に <span class="math inline">\(\boldsymbol{\theta}^{(i)}:=(\theta_1^{(i)},\theta_2^{(i)})^\top\)</span> は全体として <span class="math inline">\(p(\boldsymbol{\theta}|\boldsymbol{y})\)</span> に従うように収束する，という技法である．</p>
<p>Gibbs 法により，パラメータ <span class="math inline">\(\boldsymbol{\theta}\)</span> の次元が大きく，直接のサンプリングが難しい場合や，条件付き分布の系はわかっているが結合分布がわからない場合<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> でも，<span class="math inline">\(\boldsymbol{\theta}=(\theta_1,\theta_2,\cdots)\)</span> というように低次元変数の結合と理解することで，あるいは<strong>補助変数</strong>を追加してわざと問題を高次元化してでもそのような状況をうまく作り出すことで <span class="citation" data-cites="Tanner-Wong1987">(<a href="#ref-Tanner-Wong1987" role="doc-biblioref">Tanner and Wong, 1987</a>)</span> ，部分的な低次元サンプリングから組み上げることが出来るようになった．これを <a href="../../../posts/2024/Computation/VI2.html#sec-data-augmentation">データ拡張</a> ともいう．さらにその後も，このアイデアが <span class="citation" data-cites="Roberts-Rosenthal1999-SliceSampler">(<a href="#ref-Roberts-Rosenthal1999-SliceSampler" role="doc-biblioref">Roberts and Rosenthal, 1999</a>)</span> のスライスサンプラーにつながっている．</p>
<p>この点をはっきり強調して示し，ベイズ統計学がすでに実行可能なものになっており，ベイズ統計学の基本問題（ <a href="#sec-fundamental-problem-of-Bayes" class="quarto-xref">Section&nbsp;1.4</a> ）もすでに過去の遺物となっているということを，統計学界隈に広く知らしめたのが <span class="citation" data-cites="Gelfand-Smith1990">(<a href="#ref-Gelfand-Smith1990" role="doc-biblioref">Gelfand and Smith, 1990</a>)</span> であった．</p>
</section>
</section>
<section id="ベイズ統計学のこれから" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> ベイズ統計学のこれから</h1>
<p>複雑化の一途を辿るモデル・データに対応できるベイズ計算手法の開発が，今後最も重要な課題である．情報コミュニケーション技術が高度に発展した現代ならではの課題は，次の3つに大きく分類できる：</p>
<ol type="1">
<li>尤度不明モデル：尤度が解析的に得られない（または計算不可能）ほどに複雑なモデル</li>
<li>変数 <span class="math inline">\(\boldsymbol{\theta}\)</span> が高次元である：多くの変数を考慮に入れた高次元モデル</li>
<li>観測 <span class="math inline">\(\boldsymbol{y}\)</span> が高次元である：ビッグデータを用いた解析</li>
</ol>
<section id="擬似周辺尤度法" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="擬似周辺尤度法"><span class="header-section-number">3.1</span> 擬似周辺尤度法</h2>
<p>実は尤度 <span class="math inline">\(p(\boldsymbol{y}|\boldsymbol{\theta})\)</span> が解析的に得られない場合や計算が極めて困難になる場合でも，この不偏推定量があればMCMCを実行して事後分布を得るのに十分である <span class="citation" data-cites="Andrieu-Roberts2009">(<a href="#ref-Andrieu-Roberts2009" role="doc-biblioref">Andrieu and Roberts, 2009</a>)</span>．この尤度 <span class="math inline">\(p(\boldsymbol{y}|\boldsymbol{\theta})\)</span> の不偏推定量を得るのに粒子フィルターを用いた場合を，特に<strong>粒子MCMC</strong>という <span class="citation" data-cites="Andrieu+2010">(<a href="#ref-Andrieu+2010" role="doc-biblioref">Andrieu et al., 2010</a>)</span>．</p>
<p>このときの不偏推定量の性能が最終的な Monte Carlo 推定量に影響する．不偏推定量の分散を改善するには，サブルーチンである粒子フィルターの反復数を増やす必要がある．すると本体であるMCMCの反復数とのトレードオフが生じる．こうしてアルゴリズムの最適な調整が課題になる．</p>
</section>
<section id="高次元問題に対処するmcmc" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="高次元問題に対処するmcmc"><span class="header-section-number">3.2</span> 高次元問題に対処するMCMC</h2>
<p>ほとんどのMCMC手法は，データサイズやモデルのパラメータサイズの増加に対して，計算負荷が飛躍的に上昇する次元の呪いに苦しむ．これを克服する手法は<strong>scalability</strong>の名の下に盛んに研究されている <span class="citation" data-cites="鎌谷研吾2021">(<a href="#ref-鎌谷研吾2021" role="doc-biblioref">鎌谷研吾, 2021, p. 394</a>)</span>．</p>
<ol type="1">
<li>対象分布の探索を効率よく行う手法として，HMC (Hamiltonian Monte Carlo) 法が提案された <span class="citation" data-cites="Neal2011-HMC">(<a href="#ref-Neal2011-HMC" role="doc-biblioref"><strong>Neal2011-HMC?</strong></a>)</span>．他にも NUTS (No U-Turn Sampling) <span class="citation" data-cites="Hoffman-Gelman2014-NUTS">(<a href="#ref-Hoffman-Gelman2014-NUTS" role="doc-biblioref">Hoffman and Gelman, 2014</a>)</span>, Metropolis-Adjusted Langevin Algorithm <span class="citation" data-cites="Roberts-Tweedie1996">(<a href="#ref-Roberts-Tweedie1996" role="doc-biblioref">Roberts and Tweedie, 1996</a>)</span>, Stochastic Gradient MCMC <span class="citation" data-cites="Nemeth-Fearnhead2021">(<a href="#ref-Nemeth-Fearnhead2021" role="doc-biblioref">Nemeth and Fearnhead, 2021</a>)</span>, PDMP (区分的確定なMCMC) <span class="citation" data-cites="Bierkens+2018-PDMC">(<a href="#ref-Bierkens+2018-PDMC" role="doc-biblioref">Bierkens et al., 2018</a>)</span>, <span class="citation" data-cites="Fearnhead+2018-PDMC">(<a href="#ref-Fearnhead+2018-PDMC" role="doc-biblioref"><strong>Fearnhead+2018-PDMC?</strong></a>)</span> とジグザグサンプラーなどがある，</li>
<li>より良い提案分布の選択法について，MH法の最適スケーリング法，適応的サンプリング，焼き戻しなどの手法がある．</li>
<li>並列計算による効率化の方向性には，並列MCMC，完全サンプリングなどの手法がある．</li>
<li>他の分散低減法に，Rao-Blackwell化 <span class="citation" data-cites="Casella-Robert1996">(<a href="#ref-Casella-Robert1996" role="doc-biblioref">Casella and Robert, 1996</a>)</span>，操作変数法などがある．</li>
</ol>
<p>ジグザグサンプラーについては，以下の記事も参照：</p>
<div class="article-card-container">
  <div class="article-card">
    <a href="https://162348.github.io/posts/2024/Computation/MCMC.html" target="_blank">
      <img src="https://github.com/162348/162348.github.io/blob/main/posts/2024/Computation/Files/eyecatch.png?raw=true" alt="Article Image" class="article-image">
      <div class="article-content">
        <h3 class="article-title anchored">新時代の MCMC を迎えるために</h3>
        <p class="article-description">モンテカルロ法の発展とは，背後の物理現象からの離陸の歴史でした．非対称な Metropolis-Hastings アルゴリズムがどのように生まれたかと，その最先端のアイデアと言える連続時間 MCMC 法の歴史を，サンプルコード付きで紹介します．（2024 年度統計数理研究所オープンハウス）</p>
      </div>
    </a>
  </div>
</div>
</section>
<section id="近似ベイズ手法" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="近似ベイズ手法"><span class="header-section-number">3.3</span> 近似ベイズ手法</h2>
<p>上述までの手法はいずれもシミュレーションを十分多く行えば（理論的には）任意の精度で正しい値を得ることができるが，<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a> その適用範囲やスケーラビリティが課題なのであった．そこで同時に，最初からある許容精度を定めた下での近似を実行することとし，代わりにより広い適用可能性と計算速度を得るための手法も探求されている．これを<strong>近似ベイズ法</strong>という．</p>
<p>一つのアプローチはシミュレーションによる方法である．これにはABC (Approximation Bayesian Computation) <span class="citation" data-cites="Tavare97-ABC-for-DNA">(<a href="#ref-Tavare97-ABC-for-DNA" role="doc-biblioref">Tavaré et al., 1997</a>)</span> と BSL (Bayesian synthetic likelihood) <span class="citation" data-cites="Price2018-BSL">(<a href="#ref-Price2018-BSL" role="doc-biblioref">Price et al., 2018</a>)</span> の2つの手法があるが，いずれもデータ生成過程（モデル）の複雑性と高次元性という２つの障壁が併存したときでも使える手法である．ABCではまず事後分布 <span class="math inline">\(p(\boldsymbol{\theta}|\boldsymbol{y})\)</span> をある低次元な要約統計量 <span class="math inline">\(S:\mathcal{Y}\to\mathbb{R}^d\)</span> を用いて <span class="math inline">\(p(\boldsymbol{\theta}|S(\boldsymbol{y}))\)</span> で近似し，さらに尤度 <span class="math inline">\(p(\boldsymbol{y}|\boldsymbol{\theta})\)</span> を直接評価することは回避し，シミュレーションのみを用いて <span class="math inline">\(p(\boldsymbol{\theta}|S(\boldsymbol{y}))\)</span> を推定する．BSLはさらに尤度 <span class="math inline">\(p(S(\boldsymbol{y})|\boldsymbol{\theta})\)</span> にパラメトリックな仮定をおく．</p>
<p>第二に最適化による方法がある．変分ベイズ手法とは，これは大きなパラメトリックモデル <span class="math inline">\(\{q^*(\boldsymbol{\theta})\}\)</span> の中から <span class="math inline">\(p(\boldsymbol{\theta}|\boldsymbol{y})\)</span> に最も近いものを選ぶ手法である．一方で INLA (integrated nested Laplace approximation) とは，Laplaceの近似（ <a href="#sec-Laplace" class="quarto-xref">Section&nbsp;1.5</a> ）に最適化を組み合わせて高次元の問題にも対応する．</p>
<p>ABCでは逐次モンテカルロ法も大きな役割を果たしており，ABC-SMC <span class="citation" data-cites="Sisson+2007">(<a href="#ref-Sisson+2007" role="doc-biblioref">Sisson et al., 2007</a>)</span>，ABCフィルタリング <span class="citation" data-cites="Jasra+2012-ABCFiltering">(<a href="#ref-Jasra+2012-ABCFiltering" role="doc-biblioref">Jasra et al., 2012</a>)</span>，更には変分Bayes法への応用 <span class="citation" data-cites="Tran+2017">(<a href="#ref-Tran+2017" role="doc-biblioref">Tran et al., 2017</a>)</span> なども進んでいる．</p>
<p>変分Bayesの枠組みでは，モデルの誤想定に頑健な手法の開発も試みられている <span class="citation" data-cites="Wang-Blei2019">(<a href="#ref-Wang-Blei2019" role="doc-biblioref">Wang and Blei, 2019</a>)</span>．</p>
</section>
<section id="sec-BayesianModeling" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="sec-BayesianModeling"><span class="header-section-number">3.4</span> ベイズ統計モデリングが理論モデルの実証に役立つ</h2>
<p>ベイズモデリングの有用性は，（上述のベイズ計算の問題を除けば）どんなに複雑で大規模なモデルでも，統一的な思想と方法で対応できる点にある．</p>
<blockquote class="blockquote">
<p><strong>メカニズムを明示的に表現した数理社会学の数理モデルを，論理的に飛躍することなくダイレクトに統計モデルへと接続できる</strong>ベイズ統計モデリングは，理論モデルベースの実証研究と相性のよい，たいへん便利な方法と言えるだろう． <span class="citation" data-cites="浜田宏2022">(<a href="#ref-浜田宏2022" role="doc-biblioref">浜田宏, 2022, p. 137</a>)</span></p>
</blockquote>
<p>MCMCの開発とパッケージへの実装，そして安価で高性能な計算機が普及してからというもの，ベイズ統計学の興隆は目覚ましく，現在ではベイズ統計学は統計学に関する論文の1割強を占め，諸科学分野全体に浸透しつつある．経済学・心理学への応用は早かったのに比べて，政治科学・社会科学への応用は遅れ気味であり，社会学での使用はまだ稀であると言える <span class="citation" data-cites="Lynch-Bartlett2019">(<a href="#ref-Lynch-Bartlett2019" role="doc-biblioref">Lynch and Bartlett, 2019</a>)</span>．</p>
</section>
<section id="ベイズによる逆問題" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="ベイズによる逆問題"><span class="header-section-number">3.5</span> ベイズによる逆問題</h2>
<p>ベイズ統計学の枠組みは，逆問題の文脈においても有用である．逆問題とは，観測データ <span class="math inline">\(\boldsymbol{y}\)</span> が与えられたときに，そのデータを説明するようなモデルのパラメータ <span class="math inline">\(\boldsymbol{\theta}\)</span> を推定する問題である．</p>
</section>
<section id="sec-BayesianCausalInference" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="sec-BayesianCausalInference"><span class="header-section-number">3.6</span> ベイズによる因果推論</h2>
<p>前節に挙げたベイズモデリングの美点は因果推論の文脈でも全く同様である．特に因果推論の問題では推定対象が複雑であることが多いが，このような場合でも全く同じ枠組みを提供してくれるのがベイズである．頻度論的接近では設定に応じた個別具体的な議論がベイズ計算の問題に帰着する点が利点として働くことは多いようである <span class="citation" data-cites="Li+2023-BayesianCausalInference">(<a href="#ref-Li+2023-BayesianCausalInference" role="doc-biblioref">Li et al., 2023</a>)</span>．</p>
<p>実際，ベイズノンパラメトリック手法は2016年の大西洋因果推論カンファレンスのコンペティションで大きな成功を見ている <span class="citation" data-cites="Dorie+2019">(<a href="#ref-Dorie+2019" role="doc-biblioref">Dorie et al., 2019</a>)</span>．加えて強い理論的な保証も得られつつあり <span class="citation" data-cites="Ray-vanderVaart2000">(<a href="#ref-Ray-vanderVaart2000" role="doc-biblioref">Ray and van&nbsp;der&nbsp;Vaart, 2020</a>)</span>，これにより因果推論分野で大きな注目を集めている <span class="citation" data-cites="Linero-Antonelli2023">(<a href="#ref-Linero-Antonelli2023" role="doc-biblioref">Linero and Antonelli, 2023</a>)</span>, <span class="citation" data-cites="Daniels+2023-BayesianNonparametrics4Causal">(<a href="#ref-Daniels+2023-BayesianNonparametrics4Causal" role="doc-biblioref">Daniels et al., 2023</a>)</span>．</p>
<p>加えて，「あらゆる種の不確実性に対する統一的な定量化を与える」というベイズの性質は，<strong>因果推論から意思決定までの接続を地続きにし，例えば属人化医療などの現場でのダイナミックな意思決定に活用できることが期待される</strong>．</p>
<blockquote class="blockquote">
<p>不確実性を定量化するのに、ベイズ計算では必ず『確率』を使います。一般の人から見たら、統計で確率を使うのは当たり前と思うでしょうが、じつは他の統計手法ではそうでもなく、さまざまな解釈が生まれてしまう。定量化にはすべて統一的に確率を使うベイズ計算は、非常にシンプルなので、最終的にすべての統計はベイズに行き着くしかないと思っています．<a href="https://www.ism.ac.jp/ism_info_j/labo/project/162.html">鎌谷研吾</a></p>
</blockquote>
<p>しかし，ベイズの方法が因果推論の分野で普及するための障壁は，近づきやすさにあると議論できる <span class="citation" data-cites="Li+2023-BayesianCausalInference">(<a href="#ref-Li+2023-BayesianCausalInference" role="doc-biblioref">Li et al., 2023</a>)</span>．従来の頻度論的な因果推論手法の成功には，潜在反応モデルの特定を殆どしなくて良いこと（モデルフリー），実装が簡単であることが少なからず寄与しているとすれば，ベイズ的接近もこれに当たるものを提供できるようになる必要があるだろう．Stan言語 <span class="citation" data-cites="Carpenter+2017-Stan">(<a href="#ref-Carpenter+2017-Stan" role="doc-biblioref">Carpenter et al., 2017</a>)</span> はこの方向への大きな試みである．</p>
</section>
<section id="ベイズ学習" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="ベイズ学習"><span class="header-section-number">3.7</span> ベイズ学習</h2>
<p>機械学習の手法を用いてベイズ推論を実行する営みをベイズ学習，または単に「機械学習への確率論的アプローチ」と言ってベイズの枠組みを暗に指す場合も多い <span class="citation" data-cites="Murphy2022">(<a href="#ref-Murphy2022" role="doc-biblioref">Murphy, 2022</a>)</span>, <span class="citation" data-cites="Ghahramani2013">(<a href="#ref-Ghahramani2013" role="doc-biblioref">Ghahramani, 2013</a>)</span>．</p>
<p>古典的な統計手法と同様，多くの既存の（頻度論的）手法にはベイズ手法の対応物が存在する．ベイズの方法だと推定の確信度合いもセットで定量化され，頻度論的対応物よりも得られる情報が多い一方で，計算は既存手法よりも難しいことが多いという構造は，機械学習においても変わらない．</p>
<p>実際，現存のニューラルネットワークの訓練法を超えるベイズ計算法が今後提案されるとは考えにくいが，その最適化する所の目的関数が例えば正則化項付きの平均自乗誤差である場合は，ある正規事前分布と正規尤度に対するMAP推定量に対応する (<a href="https://www.sarem-seitz.com/posts/when-is-bayesian-machine-learning-actually-useful.html#bayesian-deep-learning-light-with-mc-dropout">Seitz 2022</a>)．畢竟，多くの既存手法も「ベイズ学習を非ベイズ的な方法で実行している」と捉えられるのである（逆も然り）．</p>
<p>中でもベイズ学習を採用するのが良い場面としては，モデルの大きさに対して学習に使えるデータの数が少ない場合や，モデルに事前情報を組み込みたい場合<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a> ，さらには医療・政策への応用など意思決定に繋げるために不確実性の定量化が肝要な場面などがあり得る．</p>
<p>実際，ベイジアン・ニューラルネットワークでは計算の困難ささえ乗り越えれば，複数の適切なモデルに対し，事後分布によって平均を取って最終的なモデルとすることで，過学習を防止し <span class="citation" data-cites="Mackay1995">(<a href="#ref-Mackay1995" role="doc-biblioref">Mackay, 1995</a>)</span>，大きな性能改善を得ることができる <span class="citation" data-cites="Wilson-Izmailov2020">(<a href="#ref-Wilson-Izmailov2020" role="doc-biblioref">Wilson and Izmailov, 2020</a>)</span>．<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a></p>
</section>
<section id="世紀の統計学とベイズの役割" class="level2" data-number="3.8">
<h2 data-number="3.8" class="anchored" data-anchor-id="世紀の統計学とベイズの役割"><span class="header-section-number">3.8</span> 21世紀の統計学とベイズの役割</h2>
<p>このように，21世紀に入ってからベイズの成功は目まぐるしく，この傾向はさらに進むと思われる．これは統計計算の手法の進化によって達成された．今後とも統計計算の手法は，シミュレーション・変分法・最適化の垣根を超えて多様化の一途を辿るだろう <span class="citation" data-cites="Green+2015">(<a href="#ref-Green+2015" role="doc-biblioref">Green et al., 2015, p. 857</a>)</span>．</p>
<p>その中でも筆者は，ベイズ手法が提供する事後分布として得られる不確実性の表現・視覚化が，計算機・自然・人間の間のよきインターフェイスとなっていくことを願っている．<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a></p>
<blockquote class="blockquote">
<p>The applied statistician should be Bayesian in principle and calibrated to the real world in practice-—appropriate frequency calculations help to define such a tie. <span class="citation" data-cites="Rubin84-ABC">(<a href="#ref-Rubin84-ABC" role="doc-biblioref">Rubin, 1984</a>)</span></p>
</blockquote>



</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-Charly2022" class="csl-entry" role="listitem">
Andral, C. (2022). <em><a href="https://arxiv.org/abs/2206.12286">An attempt to trace the birth of importance sampling</a></em>.
</div>
<div id="ref-Andrieu+2010" class="csl-entry" role="listitem">
Andrieu, C., Doucet, A., and Holenstein, R. (2010). <a href="https://www.jstor.org/stable/40802151">Particle markov chain monte carlo methods</a>. <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em>, <em>72</em>(3), 269–342.
</div>
<div id="ref-Andrieu-Roberts2009" class="csl-entry" role="listitem">
Andrieu, C., and Roberts, G. O. (2009). The pseudo-marginal approach for efficient monte carlo computations. <em>The Annals of Statistics</em>, <em>37</em>(2), 697–725.
</div>
<div id="ref-Bayes1763" class="csl-entry" role="listitem">
Bayes, T. (1763). <a href="https://www.jstor.org/stable/105741">An essay towards solving a problem in the doctrine of chances. By the late rev. Mr. Bayes, f. R. S. Communicated by mr. Price, in a letter to john canton, a. M. F. R. s.</a> <em>Philosophical Transactions</em>, <em>53</em>(1763), 370–418.
</div>
<div id="ref-Bierkens+2018-PDMC" class="csl-entry" role="listitem">
Bierkens, J., Bouchard-Côté, A., Doucet, A., Duncan, A. B., Fearnhead, P., Lienart, T., … Vollmer, S. J. (2018). <a href="https://www.sciencedirect.com/science/article/pii/S016771521830066X">Piecewise deterministic markov processes for scalable monte carlo on restricted domains</a>. <em>Statistics &amp; Probability Letters</em>, <em>136</em>, 148–154.
</div>
<div id="ref-Carpenter+2017-Stan" class="csl-entry" role="listitem">
Carpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B., Betancourt, M., … Riddell, A. (2017). <a href="https://www.jstatsoft.org/article/view/v076i01">Stan: A probabilistic programming language</a>. <em>Journal of Statistical Software</em>, <em>76</em>(1), 1–32.
</div>
<div id="ref-Casella-Robert1996" class="csl-entry" role="listitem">
Casella, G., and Robert, C. P. (1996). Rao-blackwellisation of sampling schemes. <em>Biometrika</em>, <em>83</em>(1), 81–94.
</div>
<div id="ref-Daniels+2023-BayesianNonparametrics4Causal" class="csl-entry" role="listitem">
Daniels, M. J., Linero, A., and Roy, J. (2023). <em>Bayesian nonparametrics for causal inference and missing data</em>. Chapman; Hall/CRC.
</div>
<div id="ref-Dongarra-Sulliavn2000" class="csl-entry" role="listitem">
Dongarra, J., and Sullivan, F. (2000). Guest editors introduction to the top 10 algorithms. <em>Computing in Science &amp; Engineering</em>, <em>2</em>, 22–23.
</div>
<div id="ref-Dorie+2019" class="csl-entry" role="listitem">
Dorie, V., Hill, J., Shalit, U., Scott, M., and Cervone, D. (2019). <a href="https://www.jstor.org/stable/26771031">Automated versus do-it-yourself methods for causal inference: Lessons learned from a data analysis competition</a>. <em>Statistical Science</em>, <em>34</em>(1), 43–68.
</div>
<div id="ref-Gelfand-Smith1990" class="csl-entry" role="listitem">
Gelfand, A. E., and Smith, A. F. M. (1990). <a href="https://doi.org/10.2307/2289776">Sampling-based approaches to calculating marginal densities</a>. <em>Journal of the American Statistical Association</em>, <em>85</em>(410), 398–409.
</div>
<div id="ref-Geman-Geman1984" class="csl-entry" role="listitem">
Geman, S., and Geman, D. (1984). <a href="https://doi.org/10.1109/TPAMI.1984.4767596"><span class="nocase">Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images</span></a>. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, <em>PAMI-6</em>(6), 721–741.
</div>
<div id="ref-Ghahramani2013" class="csl-entry" role="listitem">
Ghahramani, Z. (2013). <a href="https://royalsocietypublishing.org/doi/10.1098/rsta.2011.0553">Bayesian non-parametrics and the probabilistic approach to modelling</a>. <em>Philosophical Transactions of the Royal Society A: Mathematical Physical and Engineering Sciences</em>, <em>371</em>.
</div>
<div id="ref-Graunt1662" class="csl-entry" role="listitem">
Graunt, J. (1662). Natural and political observations mentioned in following index, and made upon the bills of mortality.
</div>
<div id="ref-Green+2015" class="csl-entry" role="listitem">
Green, P. J., Łatuszyński, K., Pereyra, M., and Robert, C. P. (2015). <a href="https://link.springer.com/article/10.1007/s11222-015-9574-5">Bayesian computation: A summary of the current state, and samples backwards and forwards</a>. <em>Statistics and Computing</em>, <em>25</em>(4), 835–862.
</div>
<div id="ref-Hammersley-Handscomb1964" class="csl-entry" role="listitem">
Hammersley, J. M., and Handscomb, D. C. (1964). <em>Monte carlo methods</em>. Springer Dordrecht.
</div>
<div id="ref-Hastings1970" class="csl-entry" role="listitem">
Hastings, W. K. (1970). <a href="https://doi.org/10.1093/biomet/57.1.97"><span class="nocase">Monte Carlo Sampling Methods Using Markov Chains and Their Applications</span></a>. <em>Biometrika</em>, <em>57</em>(1), 97–109.
</div>
<div id="ref-Hoffman-Gelman2014-NUTS" class="csl-entry" role="listitem">
Hoffman, M. D., and Gelman, A. (2014). The no-u-turn sampler: Adaptively setting path lengths in hamiltonian monte carlo. <em>Journal of Machine Learning Research</em>, <em>15</em>, 1593–1623.
</div>
<div id="ref-Jasra+2012-ABCFiltering" class="csl-entry" role="listitem">
Jasra, A., Singh, S. S., Martin, J. S., and McCoy, E. (2012). <a href="https://link.springer.com/article/10.1007/s11222-010-9185-0">Filtergin via approximate bayesian computation</a>. <em>Statistics and Computing</em>, <em>22</em>, 1223–1237.
</div>
<div id="ref-Laplace1774" class="csl-entry" role="listitem">
Laplace, P. S. (1774). Mémoire sur la probabilité des causes par les évènemens. <em>Mémoires de Mathématique Et de Physique Presentés à l’Académie Royale Des Sciences, Par Divers Savans, &amp; Lûs Dans Ses Assemblées</em>, <em>6</em>, 621–656.
</div>
<div id="ref-Li+2023-BayesianCausalInference" class="csl-entry" role="listitem">
Li, F., Ding, P., and Mealli, F. (2023). <a href="https://doi.org/10.1098/rsta.2022.0153">Bayesian causal inference: A critical review</a>. <em>Philosophical Transactions of the Royal Society A: Mathematical Physical and Engineering Sciences</em>, <em>381</em>(2247).
</div>
<div id="ref-Linero-Antonelli2023" class="csl-entry" role="listitem">
Linero, A. R., and Antonelli, J. L. (2023). <a href="https://wires.onlinelibrary.wiley.com/doi/full/10.1002/wics.1583">The how and why of bayesian nonparametric causal inference</a>. <em>WIREs Computational Statistics</em>, <em>15</em>(1), e1583.
</div>
<div id="ref-Lynch-Bartlett2019" class="csl-entry" role="listitem">
Lynch, S. M., and Bartlett, B. (2019). <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-soc-073018-022457">Bayesian statistics in sociology: Past, present, and future</a>. <em>Annual Review of Sociology</em>, <em>45</em>, 47–68.
</div>
<div id="ref-Mackay1995" class="csl-entry" role="listitem">
Mackay, D. J. C. (1995). Probable networks and plausible predictions —a review of practical bayesian methods for supervised neural networks. <em>Network: Computation in Neural Systems</em>, <em>6</em>(3), 469–505.
</div>
<div id="ref-MacKay2003" class="csl-entry" role="listitem">
MacKay, D. J. C. (2003). <em><a href="https://www.cambridge.org/gb/universitypress/subjects/computer-science/pattern-recognition-and-machine-learning/information-theory-inference-and-learning-algorithms?format=HB&amp;isbn=9780521642989">Information theory, inference and learning algorithms</a></em>. Cambridge University Press.
</div>
<div id="ref-Malthus1798" class="csl-entry" role="listitem">
Malthus, T. R. (1798). <em><a href="">An essay on the principle of population, as it affects the future improvement of society, with remarks on the speculations of mr. Godwin, m. Condorcet and other writers.</a></em> J. Johnson, London.
</div>
<div id="ref-Metropolis+1953" class="csl-entry" role="listitem">
Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., and Teller, E. (1953). <a href="https://doi.org/10.1063/1.1699114">Equation of state calculations by fast computing machines</a>. <em>The Journal of Chemical Physics</em>, <em>21</em>(6), 1087–1092.
</div>
<div id="ref-Metropolis-Ulam1949" class="csl-entry" role="listitem">
Metropolis, Nicholas, and Ulam, S. M. (1949). <a href="https://doi.org/10.2307/2280232">The monte carlo method</a>. <em>Journal of the American Statistical Association</em>, <em>44</em>(247), 335–341.
</div>
<div id="ref-Murphy2022" class="csl-entry" role="listitem">
Murphy, K. P. (2022). <em><a href="https://probml.github.io/pml-book/book1.html">Probabilistic machine learning: An introduction</a></em>. MIT Press.
</div>
<div id="ref-Nemeth-Fearnhead2021" class="csl-entry" role="listitem">
Nemeth, C., and Fearnhead, P. (2021). <a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1847120">Stochastic gradient markov chain monte carlo</a>. <em>Journal of the American Statistical Association</em>, <em>116</em>(533), 433–450.
</div>
<div id="ref-Pearson1926" class="csl-entry" role="listitem">
Pearson, K. (1926). Letters to editor. <em>Nature</em>, <em>117</em>(2946), 551–552.
</div>
<div id="ref-Price2018-BSL" class="csl-entry" role="listitem">
Price, L. F., Drovandi, C. C., Lee, A., and Nott, D. J. (2018). <a href="https://www.tandfonline.com/doi/abs/10.1080/10618600.2017.1302882">Bayesian synthetic likelihood</a>. <em>Journal of Computational and Graphical Statistics</em>, <em>27</em>(1), 1–11.
</div>
<div id="ref-Ray-vanderVaart2000" class="csl-entry" role="listitem">
Ray, K., and van&nbsp;der&nbsp;Vaart, A. (2020). Semiparametric bayesian causal inference. <em>The Annals of Statistics</em>, <em>48</em>(5), 2999–3020.
</div>
<div id="ref-Roberts-Rosenthal1999-SliceSampler" class="csl-entry" role="listitem">
Roberts, G. O., and Rosenthal, J. S. (1999). Convergence of slice sampler markov chains. <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em>, <em>61</em>(3).
</div>
<div id="ref-Roberts-Tweedie1996" class="csl-entry" role="listitem">
Roberts, G. O., and Tweedie, R. L. (1996). <a href="https://www.jstor.org/stable/3318418">Exponential convergence of langevin distributions and their discrete approximations</a>. <em>Bernoulli</em>, <em>2</em>(4), 341–363.
</div>
<div id="ref-Rubin84-ABC" class="csl-entry" role="listitem">
Rubin, D. B. (1984). Bayesianly justifiable and relevant frequency calculations for the applied statistician. <em>The Annals of Statistics</em>, <em>12</em>(4), 1151–1172.
</div>
<div id="ref-Rue+2009" class="csl-entry" role="listitem">
Rue, H., Martino, S., and Chopin, N. (2009). <a href="https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1467-9868.2008.00700.x">Approximate bayesian inference for latent gaussian models by using integrated nested laplace approximations</a>. <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em>, <em>71</em>(2), 319–392.
</div>
<div id="ref-Sisson+2007" class="csl-entry" role="listitem">
Sisson, S. A., Fan, Y., and Tanaka, M. M. (2007). <a href="https://www.pnas.org/doi/full/10.1073/pnas.0607208104">Sequential monte carlo without likelihood</a>. <em>PNAS (Proceedings of the National Academy of Sciences of the United States of America)</em>, <em>104</em>(6), 1760–1765.
</div>
<div id="ref-Stigler1990" class="csl-entry" role="listitem">
Stigler, S. M. (1990). <em>The history of statistics: The measurement of uncertainty before 1990</em>. Harvard University Press.
</div>
<div id="ref-Sun2018functional" class="csl-entry" role="listitem">
Sun, S., Zhang, G., Shi, J., and Grosse, R. (2019). <a href="https://openreview.net/forum?id=rkxacs0qY7">Functional variational bayesian neural networks</a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Tanner-Wong1987" class="csl-entry" role="listitem">
Tanner, M. A., and Wong, W. H. (1987). <a href="https://www.jstor.org/stable/2289457">The calculation of posterior distributions by data augmentation</a>. <em>Journal of the American Statistical Association</em>, <em>82</em>(398).
</div>
<div id="ref-Tavare97-ABC-for-DNA" class="csl-entry" role="listitem">
Tavaré, S., Balding, D. J., Griffiths, R. C., and Donnelly, P. (1997). Inferring coalescence times from DNA sequence data. <em>Genetics</em>, <em>145</em>(2), 505–518.
</div>
<div id="ref-Tran+2017" class="csl-entry" role="listitem">
Tran, M.-N., Nott, D. J., and Kohn, R. (2017). Variational bayes with intractable likelihood. <em>Journal of Computational and Graphical Statistics</em>, <em>26</em>(4), 873–882.
</div>
<div id="ref-Wang-Blei2019" class="csl-entry" role="listitem">
Wang, Y., and Blei, D. M. (2019). Variational bayes under model misspecification. <em>Proceedings of the 33rd International Conference on Neural Information Processing Systems</em>, (1198), 13379–13389.
</div>
<div id="ref-Wilson-Izmailov2020" class="csl-entry" role="listitem">
Wilson, A. G., and Izmailov, P. (2020). <a href="https://proceedings.neurips.cc/paper/2020/hash/322f62469c5e3c7dc3e58f5a4d1ea399-Abstract.html">Bayesian deep learning and a probabilistic perspective of generalization</a>. In <em>Proceedings of the 34th international conference on neural information processing systems</em>. Red Hook, NY, USA: Curran Associates Inc.
</div>
<div id="ref-北川敏男49-統計学の認識" class="csl-entry" role="listitem">
北川敏男. (1949). <em>統計学の認識</em>. 白揚社.
</div>
<div id="ref-増山1950" class="csl-entry" role="listitem">
増山元三郎. (1950). <em><a href="">推計学への道</a></em>. 東大協組出版部.
</div>
<div id="ref-安藤洋美-OLS" class="csl-entry" role="listitem">
安藤洋美. (1995). <em>最小二乗法の歴史</em>. 現代数学社.
</div>
<div id="ref-樋口知之2014" class="csl-entry" role="listitem">
樋口知之. (2014). <a href="https://www.jstage.jst.go.jp/article/trafst/8/1/8_14/_article/-char/ja/">統計数理の誕生とその広がり</a>. <em>横幹</em>, <em>8</em>(1), 14–21.
</div>
<div id="ref-浜田宏2022" class="csl-entry" role="listitem">
浜田宏. (2022). <a href="https://www.jstage.jst.go.jp/article/ojjams/37/1/37_124/_article/-char/ja/">ベイズで広がる数理社会学の世界</a>. <em>理論と方法</em>, <em>37</em>(1), 124–137.
</div>
<div id="ref-鎌谷研吾2021" class="csl-entry" role="listitem">
鎌谷研吾. (2021). <a href="https://www.jstage.jst.go.jp/article/jjssj/50/2/50_381/_article/-char/ja/">マルコフ連鎖モンテカルロ法における平均回帰</a>. <em>日本統計学会誌</em>, <em>50</em>(2), 381–402.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>正式名称をThe Royal Society for the Improvement of Natural Knowledge by Experimentという<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>当局の人間に死亡を報告する義務は全くなかった。その代わり、それぞれの教区では2人かそれ以上の死体を調査し、死因を決定する義務を負う調査員を任命していた。「調査員」は死亡を報告する毎に遺族より少額の手数料を徴収する資格が与えられていたので、教区では任命しなければ貧困のため救貧税による支援が必要となりそうな人間を割り当てていた。（<a href="https://ja.wikipedia.org/wiki/%E3%83%AD%E3%83%B3%E3%83%89%E3%83%B3%E3%81%AE%E5%A4%A7%E7%96%AB%E7%97%85">Wikipediaページより</a>）<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>これは統計的モデルとしてBernoulli分布 <span class="math inline">\(Y_i|\theta\overset{\text{iid}}{\sim}\mathrm{Ber}(\theta)\)</span> を仮定するということである．<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>パラメータ <span class="math inline">\(\theta\)</span> は「男児が生まれる確率」であるが，これ自体にも事前分布という「確率」<span class="math inline">\(p(\theta)\)</span> を導入することに戸惑う読者も居るだろう．しかし，<strong>これがベイズ統計学の特徴である</strong>．「男児が生まれる確率 <span class="math inline">\(\theta\)</span>」だろうとなんだろうと，「わからない」「不確実性がある」と主観的に感じるあらゆる対象に，確率分布を導入して事後分布を得ることで推論を実行する，これがベイズ統計学の枠組みの普遍性であり，無差別性であり，有用性を支えている．<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>各 <span class="math inline">\(\theta\)</span> の下で目の前のデータ <span class="math inline">\(y_1,\cdots,y_n\)</span> が生成される確率 <span class="math inline">\(p(\boldsymbol{y}|\theta)\)</span> が低いということは，「その <span class="math inline">\(\theta\)</span> から生成されたデータである確率は低い」という逆の発想ができる．そこで <span class="math inline">\(p(\boldsymbol{y}|\theta)\)</span> という条件付き確率を<strong>尤度</strong>ともいう．今回は <span class="math inline">\(p(\boldsymbol{y}|\theta)=\theta^{\sum_{i=1}^ny_i}(1-\theta)^{\sum_{i=1}^n(1-y_i)}\)</span> である．<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>さらに，<span class="math inline">\(g(\theta)=\theta^p\)</span> と取った場合，事後積率という統計量になる．等に <span class="math inline">\(p=1\)</span> の場合が事後平均である．<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>なお，1763に出版されたものはPriceによる補遺も付いた短縮版であり，全文は1974年に出版された．<span class="citation" data-cites="Stigler1990">(<a href="#ref-Stigler1990" role="doc-biblioref">Stigler, 1990</a>)</span><a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>pp.376-403 がBayesの論文の本論の内容であり pp.399-403 で計算法を３つのルールにまとめているが，その導出部は一部「長すぎるから掲載を省略する」とされている．<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>一方で，Bayesの逆確率の問題への言及自体は，Laplaceの後年の1781年の著作<em>Mémoire sur les probabilités</em>へのCondorcetによる序文で初めて登場する <span class="citation" data-cites="Martin+2023-history">(<a href="#ref-Martin+2023-history" role="doc-biblioref"><strong>Martin+2023-history?</strong></a>)</span>．<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p><a href="https://golem.ph.utexas.edu/category/2021/10/stirlings_formula.html">nCatLab</a> 参照．<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p><span class="citation" data-cites="安藤洋美-OLS">(<a href="#ref-安藤洋美-OLS" role="doc-biblioref">安藤洋美, 1995</a>)</span> も参照．<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>1970年にインテルが世界初の DRAMである Intel 1103 を発売した．<a href="https://ja.wikipedia.org/wiki/%E6%83%85%E5%A0%B1%E9%9D%A9%E5%91%BD">Wikipediaページ</a>参照．<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>物理学では Heat Bath 法と呼ばれ古くから同様のアルゴリズムが存在したが，統計学界隈では現在でも Gibbs サンプラーと呼ばれる．<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>統計的画像処理など，<a href="../../../posts/2024/Computation/PGM1.html#sec-separation-in-markov-network">Markov 確率場</a> によってモデリングされる対象においてはよくある状況である．<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>この性質を指して，approximateの対義語としてexactという形容詞で表現される．<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>functional Bayes <span class="citation" data-cites="Sun2018functional">(<a href="#ref-Sun2018functional" role="doc-biblioref">Sun et al., 2019</a>)</span> という手法では，希望する入力と出力の組を事前に用意するのみで，適切な事前分布を提案してくれる枠組みである．<a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p><span class="citation" data-cites="Wilson-Izmailov2020">(<a href="#ref-Wilson-Izmailov2020" role="doc-biblioref">Wilson and Izmailov, 2020</a>)</span> によると，二重降下現象も見られない．<a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p>推定結果に自信がないときはそう表明してくれる機械は親しみやすい．<a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/162348\.github\.io\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
        for (let i=0; i<annoteTargets.length; i++) {
          const annoteTarget = annoteTargets[i];
          const targetCell = annoteTarget.getAttribute("data-target-cell");
          const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
          const contentFn = () => {
            const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
            if (content) {
              const tipContent = content.cloneNode(true);
              tipContent.classList.add("code-annotation-tip-content");
              return tipContent.outerHTML;
            }
          }
          const config = {
            allowHTML: true,
            content: contentFn,
            onShow: (instance) => {
              selectCodeLines(instance.reference);
              instance.reference.classList.add('code-annotation-active');
              window.tippy.hideAll();
            },
            onHide: (instance) => {
              unselectCodeLines();
              instance.reference.classList.remove('code-annotation-active');
            },
            maxWidth: 300,
            delay: [50, 0],
            duration: [200, 0],
            offset: [5, 10],
            arrow: true,
            trigger: 'click',
            appendTo: function(el) {
              return el.parentElement.parentElement.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'quarto',
            placement: 'right',
            positionFixed: true,
            popperOptions: {
              modifiers: [
              {
                name: 'flip',
                options: {
                  flipVariations: false, // true by default
                  allowedAutoPlacements: ['right'],
                  fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
                },
              },
              {
                name: 'preventOverflow',
                options: {
                  mainAxis: false,
                  altAxis: false
                }
              }
              ]        
            }      
          };
          window.tippy(annoteTarget, config); 
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "162348/162348.github.io";
    script.dataset.repoId = "R_kgDOKlfKYQ";
    script.dataset.category = "Announcements";
    script.dataset.categoryId = "DIC_kwDOKlfKYc4CgDmb";
    script.dataset.mapping = "pathname";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://162348.github.io/">
<p>Hirofumi Shiba</p>
</a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/162348/162348.github.io/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/ano2math5">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:shiba.hirofumi@ism.ac.jp">
      <i class="bi bi-envelope" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="../../../blog.xml">
      <i class="bi bi-rss" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>