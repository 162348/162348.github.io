---
title: "法律家のための統計数理（4）第3章第1-4節"
author: "司馬博文"
date: "1/11/2024"
categories: [草野数理法務]
toc: true
toc-expand: true
number-sections: true
twitter-card: true
bibliography: ../../../mathematics.bib
csl: ../../../apa.csl
code-block-bg: true
code-block-border-left: "#31BAE9"
code-overflow: wrap
code-fold: true
abstract-title: 概要
abstract: 教科書第３章第５節から第８節 (pp. 96-126) を通じ，統計学検定への入門も兼ねて，推測統計学のうち統計的仮説検定の基礎を学ぶ．
crossref:
    sec-prefix: 節
    eq-prefix: 式
---

統計的検定の考え方と，その科学的な態度については，[@大塚2020 p.97-106] が大変含蓄が深い．

{{< include ../../../_preamble.qmd >}}

## 仮設検定

### 二項モデルでの検定

:::{.callout-tip icon="false"}
## 問題

冠動脈バイパス手術を受けた20歳の青年が３日後に死亡した．

* 同病院では過去３年の30件のうち10人が術後１週間以内に死亡している．
* 一般に術後１週間以内に死亡する確率は0.2である．

不審だと言えるだろうか？言えるとしたらどのような意味で？
:::

「正常な範囲内の事象である」とする帰無仮説の下で，当該事象が起こる確率を計算する．これが5%以下だったら「不審だと思うに足る」と言えるだろう．

本問題は死亡率 $p\in[0,1]$ という母数に関する検定問題と捉えることができ，すると帰無仮説は
$$
H_0:p=0.2
$$
というシンプルな表示を得る．

この下で，$n=30$ として，確率変数 $X$ を「術後１週間以内に死亡する人数」とすると，$X$ は二項分布 $\Bin(30,0.2)$ に従う（二項分布の定義は @sec-binomial ）．

```{python}
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import binom

# Parameters for the binomial distribution
n = 30  # number of trials
p = 0.2 # probability of success in each trial

# Generating data for the binomial distribution
x = np.arange(0, n+1)
y = binom.pmf(x, n, p)

# Plotting the binomial distribution
plt.figure(figsize=(3.5, 3))
plt.plot(x, y, 'bo', markersize=5)
plt.vlines(x, 0, y, colors='b', lw=5)
plt.title('Binomial Distribution - n=30, p=0.2')
plt.xlabel('Number of Deaths')
plt.ylabel('Mass')
plt.grid(False)
plt.show()
```

この図からも，10人以上になる確率は極めて小さいことが判るだろう．実際に計算してみると，

```{python}
prob_10_or_more = 1 - binom.cdf(9, n, p) - binom.pmf(10, n, p)/2
print(f"p-value is {prob_10_or_more:.4f}")
```

となる．この「帰無仮説 $H_0$ （今回は「１週間死亡率は20%」）を仮定した下で，実際に観測した事象（今回は「30人のうち10人が一週間死亡」）が起こる条件付き確率」を **$p$-値** と呼ぶ．^[[@大塚2020 p.105]，[@草野2016 p.100]]

:::{.callout-caution icon="false" collapse="true"}
## 注（検定統計量の選び方）

上で叙述したのは，「死亡者数」という離散確率変数を検定統計量に用いた場合である．しかし，本書 [@草野2016 p.99] では，別の離散検定統計量に対して，正規近似を通じて計算している．これは $z$-検定と呼ばれるものである（ [Wikipedia](https://ja.wikipedia.org/wiki/%E4%BA%8C%E9%A0%85%E6%A4%9C%E5%AE%9A) も参照）．

計算機が得意ならば，直接計算で出した方が近似誤差がないため，好ましいだろう．実際，書籍で得られた値は $p=0.0344$ であり，過小評価している．その論拠は「$pn,(1-p)n$ のいずれも $5$ 以上であれば正規分布と同一視して良いことが知られている」という点である．

一方で，上の議論では $p=0.0611$ と5%の水準を超えている．一方で，[@Lancaster61-MidPValue] の mid-$P$ value と呼ばれる補正法を用いると $p=0.0434$ となり，再び有意になる．

このことをどう評価するべきか……．技術的・専門的すぎてとても人口に膾炙するものではないと思うと同時に，非常に本来的ではない議論になっていると感ずる（ @sec-Bayes ）．
:::

### 誤り

帰無仮説を間違えて棄却してしまうことを，[**第一種の過誤**](https://ja.wikipedia.org/wiki/%E7%AC%AC%E4%B8%80%E7%A8%AE%E9%81%8E%E8%AA%A4%E3%81%A8%E7%AC%AC%E4%BA%8C%E7%A8%AE%E9%81%8E%E8%AA%A4) という．これは有意水準 $\al$ の値に一致する．

統計的仮説検定の理論は，初めは [Neyman](https://ja.wikipedia.org/wiki/%E3%82%A4%E3%82%A7%E3%82%B8%E3%83%BB%E3%83%8D%E3%82%A4%E3%83%9E%E3%83%B3) と [Pearson](https://ja.wikipedia.org/wiki/%E3%82%A8%E3%82%B4%E3%83%B3%E3%83%BB%E3%83%94%E3%82%A2%E3%82%BD%E3%83%B3) によって科学的発見の文脈で考えられたものであるため，帰無仮説の棄却は「科学的発見の萌芽」と同義と解すことが多い（[@大塚2020 p.97-106] も参照）．その場合，第一種の誤りとは「本当はなんでもないのに大発見だと思い上がりってしまう確率」である．これを犯す確率を最も制限したい，という志向を持つ．

次に，第一種の誤りの可能性 $\al$ を制限した上で，本当は帰無仮説が誤りなのに棄却できないリスク＝発見を検出できないリスクをなるべく下げることを二次的目標として考える．これを **第二種の過誤** という．その確率 $1-\beta$ に対して，$\beta$ を **検出力 (power)** と呼ぶ．

これは [第二回で扱った検察官の誤謬](%E6%B3%95%E5%BE%8B%E5%AE%B6%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E7%B5%B1%E8%A8%88%E6%95%B0%E7%90%862.qmd#sec-Bayes-problem) に通じる語用法である．

### 独立性の検定

:::{.callout-tip icon="false"}
## 問題

次の条件を持つ学習教材が「必ず英語の成績が上がる」と言えるだろうか？

* 全国共通模試で，英語の全国平均点は58点であった．
* 当該教材を用いて勉強した者80名の平均は70点であり，標準偏差は15であった．
:::

これは，当該教材を用いた群と用いていない群という「２つの標本」の間に差がないこと，今回では「平均が同じであること」を帰無仮説として，目下の証拠からこれを棄却出来るかを検定する問題として捉えることができる．

### 区間推定

### ベイズ統計学 {#sec-Bayes}

> 伝統的統計学は客観確率を用いているので，母数の確からしさを１つの数値として示すことができない．伝統的統計学が示しうるものは，「母数がある範囲内にあればこの証拠が現れる確率はいくらであるか」でしかないのである．この矛盾をいかに克服するかは法律家と統計学者が共同して取り組むべき今後の課題であるが，**１つの可能性として考えうることは伝統的統計学に代えてベイズ統計学の手法を用いることである**．[@草野2016 p.119]

## 定義集

$$
[a,b]:=\Brace{x\in\R\mid a\le x\le b}
$$
は実数の区間を表す．
$$
\N^+:=\Brace{1,2,3,\cdots}
$$
は正の整数全体の集合を表す．詳しくは [本サイトの数学記法一覧](../../Surveys/Notations.qmd#sec-numbers) を参照．

### 二項分布 {#sec-binomial}

[@草野2016 p.92] も参照．

:::{.callout-note icon="false"}
## 定義（二項分布，Bernoulli分布）

1. パラメータ $n\in\N^+$ と $p\in[0,1]$ に関する **二項分布** $\Bin(n,p)$ とは，集合 $\{0,1,\cdots,n\}$ 上の離散確率分布で，
確率質量関数
$$
b(x;n,p):=\comb{n}{x}p^x(1-p)^{n-x},
$$
$$
x=0,1,\cdots,n,
$$
が定めるものをいう．

2. パラメータ $p\in[0,1]$ に関する **Bernoulli分布** $\Ber(p)$ とは，$n=1$ の場合の二項分布
$$
\Ber(p):=\Bin(1,p)
$$
をいう．
:::

ただし，二項係数 $\comb{n}{x}$ は高校数学では ${}_nC_x$ と表す場合が多い．前者の記法の美点は，関係式
$$
\begin{align*}
    \comb{n}{x}&=\frac{n!}{x!(n-x)!}\\
    &=\frac{n}{x}\frac{(n-1)!}{(x-1)!(n-x)!}\\
    &=\frac{n}{x}\comb{n-1}{x-1}
\end{align*}
$$
が直感的に表せる点にある．