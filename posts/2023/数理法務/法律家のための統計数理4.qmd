---
title: "法律家のための統計数理（4）第3章第1-4節"
author: "司馬博文"
date: "1/11/2024"
categories: [草野数理法務]
toc: true
toc-expand: true
number-sections: true
twitter-card: true
bibliography: ../../../mathematics.bib
csl: ../../../apa.csl
abstract-title: 概要
abstract: 教科書第3章第1-4節(pp.73-96)を通じ，統計学検定への入門も兼ねて，推測統計学の基礎を学ぶ．
crossref:
    sec-prefix: 節
    eq-prefix: 式
---

{{< include ../../../_preamble.qmd >}}

## 今回の内容

### 母集団と標本 (pp.73-75)

#### 母集団

標本調査が行われるとき，調査対象となる全体集団を **母集団** (population) という．全人口を精査することは困難であるため，ここから無作為に一部分を選ぶことになる．これを [**標本調査**](https://www.stat.go.jp/teacher/survey.html) (survey sampling) といい，得られたデータを **標本** (sample) という．

「無作為」と言ってもどのように選べば良いか？を考える分野を **標本調査法** (sampling theory) という．^[[@Wu-Thompson2020] など．] 大統領選挙を通じての標本抽出法の発展の例は @sec-Gallup に付した．

#### 統計量の例

標本の関数を [**統計量**](https://ja.wikipedia.org/wiki/%E7%B5%B1%E8%A8%88%E9%87%8F) (statistic) という．

::: {.callout-tip icon="false"}
## 定義（３つの標本統計量）
$x_1,\cdots,x_n$ を標本とする．

1. 次を **標本平均** という：
$$
\ov{x}:=\frac{x_1+\cdots+x_n}{n}.
$$
2. 次を **標本分散** という：
$$
s^2:=\frac{1}{n}\sum_{i=1}^n(x_i-\ov{x})^2.
$$
3. 標本分散の非負の平方根 $s:=\sqrt{s^2}$ を **標本標準偏差** という．
4. 次を **不偏分散** という：
$$
u^2:=\frac{1}{n-1}\sum_{i=1}^n(x_i-\ov{x})^2.
$$
:::

::: {.callout-tip icon="false"}
## 命題（分散公式）
標本分散 $s^2$ と標本平均 $\ov{x}^2$ の間には次の関係が成り立つ：
$$
s^2=\frac{1}{n}\sum_{i=1}^nx_i^2-\ov{x}^2.
$$
$\frac{1}{n}\sum_{i=1}^nx_i^2$ という量を **標本の２次の絶対積率** という．
:::
::: {.callout-note icon="false" title="証明" collapse="true"}
$$
\begin{align*}
    s^2&=\frac{1}{n}\sum_{i=1}^n(x_i-\ov{x})^2\\
    &=\frac{1}{n}\sum_{i=1}^n(x_i^2-2x_i\ov{x}+\ov{x}^2)\\
    &=\frac{1}{n}\sum_{i=1}^nx_i^2-2\ov{x}\frac{1}{n}\sum_{i=1}^nx_i+\ov{x}^2\\
    &=\frac{1}{n}\sum_{i=1}^nx_i^2-\ov{x}^2.
\end{align*}
$$
:::

#### 母数とは何か？

本書 [@草野2016 p.75] に

> 標本に統計量があるように母集団にもその特性を表す数値が備わっているはずであり，そのような数値のことを **母数** という．

とあるが，この文脈では母数ではなく **特性値** という [@竹村彰道2020]．特性値を母数と設定することが多いが，それはあくまで統計解析者の裁量である．

母数とは次に示すように，**推定対象として解析者が設定する母集団の特性値** である．標本統計量は実際に計算できるが，特性値と母数は未知である．

よって，ほとんどの場合，**推測統計の問題とは母数推定の問題に他ならない**．

::: {.callout-tip icon="false"}
## 定義（統計モデル，母数）

* 母集団上の確率分布の族 $\{P_\theta\}_{\theta\in\Theta}$ を **統計モデル** という．
* 統計モデルを添字付ける「番号」 $\theta\in\Theta$ を **母数** という．
:::

### 統計推測の技法(1) (pp.75-85)

本書 [@草野2016 pp.75-85] の重大な特徴に，確率変数と確率分布を区別していないという問題がある．

確率分布とは [第１回講義](%E6%B3%95%E5%BE%8B%E5%AE%B6%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E7%B5%B1%E8%A8%88%E6%95%B0%E7%90%861.qmd#sec-axiom) で導入した，３つの公理を満たす集合関数 $\P:P(\Om)\to[0,1]$ である．このとき，ペア $(\Om,\P)$ を，確率が定義された集合という意味で **確率空間** という．

**確率変数** とは，確率空間 $(\Om,\P)$ 上に定義された関数 $X:\Om\to\R$ のことである．特に，値域が $\bN\subset\R$ に限る場合を **離散変数** という．

#### 離散の場合

確率変数 $X$ の取り得る値が $\bN=\{0,1,2,\cdots\}$ に限る場合が離散の場合である．

::: {.callout-tip icon="false"}
## 定義（期待値）
1. 非負値の関数 $f:\bN\to[0,1]$ であって次を満たすものを **確率（質量）関数** という：
$$
f(n)=\P[X=n]
$$
2. 確率関数 $f:\bN\to[0,1]$ に従う確率変数 $X:\Om\to\bN$ に対して，次の量 $\E[X]$ を **期待値** という：
$$
\E[X]:=\sum_{n=1}^\infty nf(n)=\sum_{n=1}^\infty n\P[X=n].
$$
3. 次の量 $\V[X]$ を $X$ の **分散** という：
$$
\V[X]:=\E\SQuare{(X-\E[X])^2}.
$$
:::

#### 連続の場合

::: {.callout-tip icon="false"}
## 定義（期待値）
$(\Om,\P)$ を確率空間，$X:\Om\to\R$ をその上の確率変数とする．

1. 非負値の関数 $F:\R\to[0,1]$ であって次を満たすものを，$X$ の **（累積）分布関数** という：
$$
F(x):=\P[X\le x].
$$
2. 非負値の関数 $p:\R\to\R_+$ であって次を満たすものが存在するならば，これを $X$ の **（確率）密度関数** という：
$$
\P[X\in A]=\int_Ap(x)\,dx.
$$
3. 確率密度 $p$ に従う確率変数 $X:\Om\to\R$ に対して，次の量 $\E[X]$ が存在するならば，これを $X$ の **期待値** という：
$$
\E[X]:=\int_\R xp(x)\,dx.
$$
4. 次の量 $\V[X]$ が存在するならば，これを $X$ の **分散** という：
$$
\V[X]:=\E\SQuare{(X-\E[X])^2}.
$$
:::

#### 期待値の性質

::: {.callout-tip icon="false"}
## 命題（期待値の性質）
$X,Y:\Om\to\R$ を確率変数とする．

1. （期待値の線型性）任意の $a,b\in\R$ について，
$$
\E[aX+bY]=a\E[X]+b\E[Y].
$$
2. （分散の斉次性）任意の $a,b\in\R$ について，
$$
\V[aX+b]=a^2\V[X].
$$
:::

#### 独立性と共分散

::: {.callout-tip icon="false"}
## 定義（確率変数の独立性）
$X,Y:\Om\to\R$ を確率変数とする．

1. $X,Y$ が互いに **独立** であるとは，任意の事象 $A,B\subset\Om$ について，
$$
\P[X\in A,Y\in B]=\P[X\in A]\P[Y\in B]
$$
を満たすことをいう．
2. $X,Y$ の **共分散** とは，
$$
\Cov[X,Y]:=\E\SQuare{(X-\E[X])(Y-\E[Y])}
$$
をいう．
:::

::: {.callout-tip icon="false"}
## 命題（独立確率変数の性質）
$X,Y:\Om\to\R$ を確率変数とする．

1. $X,Y$ が独立ならば，次が成り立つ：
$$
\E[XY]=\E[X]\E[Y].
$$
2. 次が成り立つ：
$$
\V[X+Y]=\V[X]+2\Cov[X,Y]+\V[Y].
$$
3. （独立ならば無相関）$X,Y$ が独立ならば，
$$
\Cov[X,Y]=0.
$$
特に，$X,Y$ が独立ならば，$\V$ は加法を保存する．
:::

### 統計推測の技法(2) (pp.85-94)

#### 正規分布

```{python}
import numpy as np
import matplotlib.pyplot as plt
from ipywidgets import interact, FloatSlider
import seaborn as sns

# 正規分布のグラフを描画する関数
def plot_normal_distribution(variance):
    mean = 0  # 平均値
    sigma = np.sqrt(variance)  # 標準偏差（分散の平方根）
    
    # 正規分布のデータを生成
    x = np.linspace(-10, 10, 1000)
    y = (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(- (x - mean)**2 / (2 * sigma**2))
    
    # グラフを描画
    plt.figure(figsize=(10, 6))
    sns.lineplot(x=x, y=y)
    plt.title(f'Normal Distribution with Variance {variance}')
    plt.xlabel('Value')
    plt.ylabel('Probability Density')
    plt.show()

# インタラクティブなウィジェットを作成
interact(plot_normal_distribution, variance=FloatSlider(value=1, min=0.1, max=5, step=0.1))
```

#### Bernoulli分布と二項分布

```{python}
from matplotlib.widgets import Button
 
fig, ax = plt.subplots()
scatter = ax.scatter(np.random.rand(10), np.random.rand(10))
 
button_ax = plt.axes([0.7, 0.05, 0.1, 0.075])
button = Button(button_ax, 'Add')
 
def add_point(event):
    new_point = np.random.rand(2)
    scatter.set_offsets(np.concatenate([scatter.get_offsets(), [new_point]]))
    plt.draw()
 
button.on_clicked(add_point)
 
plt.show()
```

#### Poisson分布

### 統計推測の技法(3) (pp.94-97)

ここで重要なトピックは不偏分散である．

## 補足

### 第1節：母集団と標本

#### 「推測統計学」とは何か？

本書 [@草野2016 p.73] でも次のような注がなされている：

> 推測統計学に対して，証拠から得られた情報をいかに効率的かつ明確に表現するかを研究する統計学の分野を記述統計学という [@草野2016 p.73]．

現代では「統計学」と言った際にほとんど推測統計学を指すと言っても過言ではない．^[なお，[@増山1950] の序によると，**推測統計学** という語は北川敏男によるものであり，増山は **推計学 (stochastics)** と呼んでいる．] つまり，現代では殆ど形骸化した区別である．**この名称の本当の意味を理解するためには，歴史的な情緒を持った文脈が必要である**．

一言で言えば，推測統計学は [Ronald A. Fisher](https://ja.wikipedia.org/wiki/%E3%83%AD%E3%83%8A%E3%83%AB%E3%83%89%E3%83%BB%E3%83%95%E3%82%A3%E3%83%83%E3%82%B7%E3%83%A3%E3%83%BC) の理論が出て来た際に，それ以前の [Quetelet](https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%89%E3%83%AB%E3%83%95%E3%83%BB%E3%82%B1%E3%83%88%E3%83%AC%E3%83%BC) からの統計学との断絶を強調するために用いられた語であった．

> 推計学 stochastic は推計と計画のための科学であり，その建設は主として英国の農学者 R. A. Fisher （現在 Cambridge 大学教授）の構想に懸る．--[@増山1950 p.3]

その態度の違いは，次の例が鮮明に示している．

> 例えば算術平均 mean という概念について：旧来の考え方に従えば平均 average は集団の ‘代表’ 値であると定義されている．^[$\phi(y,y,\cdots)=\phi(x_1,x_2,\cdots)$ なる関係が成り立つとき，$y$ を $x_1,x_2,\cdots$ の平均という．参照：[@Jevons1879 p.391]] 従って，算術平均が該集団をよく ‘代表’ しうると考えられる場合にはこれを採用し，しからざる場合には度数分布の形を眺めた上で，その他の平均値，例えば並数 mode なり幾何平均 geometrical mean なりをもって，これに代えるのである．だから ‘代表値’ として如何なる平均値を選ぶかは，この際，全く個々人の常識に委ねられてしまう．これに反して推計学が算術平均を採用するのは，それが分布関数として表現せられた母集団の或る常数（即ち母数）の適切な平均値となりうる場合のみに限られる．従来統計学を定義して ‘平均の学である’ となす立場があるけれども（例えば A. L. Bowley）このような考え方こそ統計学の記述的性格を遺憾なく露呈するものであろう．統計学がこのような原理に立つ限り，それは爾後の行動に関し，形式以上に何ら指針を与える力をもちうるものではない．行動の正しい指針を与えないような学問は実は科学の名に値しないものというべきであろう．これにも拘らず推計学は吾国では最近に到るまで，科学・技術の分野でさえ仲々受け入れられず政治・経済の領域では殆ど問題にもされなかったのである．これに反し，米国などでは，推計学が社会・自然のあらゆる分野に進出し，第２次大戦の遂行にあたっても大きな貢献をなしたのであった．--[@増山1950 p.4]

前者の記述統計学的な動機は，現代では「データサイエンス」のような分野に引き継がれている [@Hoaglin+2006]．

### Gallup事件 {#sec-Gallup}

#### 1936年大統領選挙とクオータ抽出の重要性

::: {.callout-tip title="Roosevelt v.s. Landon (1936)"}
* 背景には1929年10月24日の「暗黒の木曜日」に端を発した世界大恐慌があった．
  * 民主党 Franklin D. Roosevelt は再選を目指し，共和党の Alfred Landon が立ち向かった．
  * Roosevelt の保守的な姿勢は大恐慌を食い止めるには力不足と思われ，再選の見込みは低いという意見も強く，_The Literary Digest_ は237万人^[[@中山健夫2003]] を対象に回収した調査結果から，57% の得票で Landon が勝つだろうと予測した．
* 一方で Gallup 率いる the American Institute of Public Opinion は3000人の標本から Roosevelt が 55.7% の得票を得て当選するだろう，と予測した．^[[@鈴木督久2021] によると，実際はこれは史実の誤解であるようだ．Gallup が「Digest は Landon が 56% だとして予測を誤るだろう」というコラムを新聞社に送付するのに用いた標本が3000なのであって，Gallup 自身の選挙予測調査の標本サイズは30万人であったという．なお，その際の抽出法については歴史的な文献が欠けており，知る由がないという．とは言え，それでも，「標本は量より質」という教訓になる，という意味では，象徴的なエピソードであることは間違いない．]

結果，Roosevelt が 60% の得票を得て，48州中46州を手にした．

なぜ _The Literary Digest_ は予測を誤ったのか？その原因は不適切な標本抽出法にあった．

* _The Literary Digest_ は自誌の購読者（大恐慌の最中でも購読した層）を対象に，そして自動車保有者と電話利用者の名簿を使って約1000万人に郵送し，回収された237万人の回答を用いた．
* 過去5回の大統領選挙で的中させていたのは，経済的な状況があまり投票結果に影響しない時勢だったためと思われる．
* 一方，Gallup は母集団を層別してサンプルサイズを割り当て，そのクオータに沿って標本を集める非確率的抽出法を用いていた．なお，Gallup は4ヶ月前から，_The Literary Digest_ の予測は外れるだろうと新聞のコラム上で予言していた．
:::

このエピソードは **不適切なデザイン下で収集された大量データよりも良いデザイン下で収集された少量のデータのほうがずっと役に立つ** ということの好例として強調されることとなった．

しかし，話はここでは終わらない．その Gallup も，後の大統領選挙で予測を大きく外している．

#### 1948年大統領選挙と無作為抽出の重要性

::: {.callout-tip title="Truman v.s. Dewwey (1948)"}
* 1948年の選挙では，民主党は在任中に斃れた Roosevelt の後を継いでいた Harry Truman，共和党は4年前に Roosevelt に負けた Thomas Dewey が戦った．
* この年の背景には公民権問題があり，共和党が20年ぶりに政権を奪還すると予想されており，Gallup もその例にもれなかった．

結果，Truman が僅差で Dewey を破って当選した．

なぜクオータ法を用いたサンプリングで実績を出した Gallup は，今回は予測を大きく誤ったのか？

* 今回 Gallup も予想に失敗して世論調査そのものに懐疑の目が向けられたことを重く見て，検討委員会が設置された．
* そこで論点となったのが，当時 Gallup が用いていた割当法では，層内の個々の対象者の決定が調査員の個人的判断に委ねられていたことが多きなバイアスの原因となっていると予想された．
* その結果，今日では **無作為抽出** が大原則として一層強調されるエピソードとなっている [@なるほど統計学園]．
* だがこれ自体が原因だとは言えない．事実，調査担当員もそのことは自覚しており，予測を修正する調整技術を独自に開発して用いていたという [@佐藤2020]．どんな標本調査法にも偏りがあり，これを修正するための予測モデルと併用するという営みは現在の無作為抽出法でも同様であり，これ自体が問題ではない．
* 当時（現在も）広く用いられている電話調査という手法が，1948年代当時では裕福な有権者（電話を購入することができ，また不変の住所を維持していた）に偏ったサンプル抽出に導いたという議論もある．^[[Wikipedia](https://ja.wikipedia.org/wiki/1948年アメリカ合衆国大統領選挙#結果) の記述．]
:::

![[@佐藤2020 p.15] より](gallup.png)

1947年時点での GHQ による日本への統計指導でも，すでに無作為抽出法（当時は「任意見本法」）による調査が指導されている [@佐藤2020]．よって，当時からクオータ法の問題は認識されており，これに必要な対策を打つ形で運用されていたと解すのが妥当であろう．

なお，日本側のエピソードとして，統計数理研究所第７代所長も務めた [林知己夫](https://ja.wikipedia.org/wiki/林知己夫) のオーラルヒストリーに次のような一節がある：

> そんな時に，CIEの担当官は，日本の新聞社を集めて，「アメリカではクォータサンプルでやっているけれど，そんなのはサンプリングじゃない」と，トルーマン，デューイの大統領選挙の予測を持ち出してきてですね，「これはクォータサンプリングでやったから間違えたんだ．こんなもの夢夢やるんじゃないぞ」と．そうしてみんな肝に銘じたんですよね．サンプリングは厳正にやらなきゃいけないって教わったわけです [@林知己夫氏公開インタビュー]．