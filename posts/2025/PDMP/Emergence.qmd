---
title: "動き出す PDMP"
subtitle: "`PDMPFlux.jl` のアニメーションで見る MCMC の最近の発展"
author: "司馬博文"
date: "12/24/2025"
categories: [PDMP, MCMC, Process]
bibliography: 
    - ../../../assets/2023.bib
    - ../../../assets/2024.bib
    - ../../../assets/2025.bib
csl: ../../../assets/apalike.csl
---

## はじめに

PDMP (Piecewise Deterministic Markov Process) とは近年さかんに研究されている全く新しい MCMC の総称である．

収束が速い，大規模データに特に強い，密度が非正則だったりアトムを持っていても良いなど，理論的な期待は大きいが，その動いている様子を見たことのある者は，まだまだ一部の研究者に限られる．

HMC が Stan や PyMC に高度な実装があり，日々の統計と機械学習の実践を支えているのとは対照的である．

ここでは筆者が開発している Julia パッケージ [`PDMPFlux.jl`](https://github.com/162348/PDMPFlux.jl) を紹介する．

その最大の特徴は柔軟なアニメーション機能を提供する関数 `anim_traj` である．これにより種々の PDMP サンプラーの動きをアニメーションで見ることができる．本稿ではこの関数をフルに活用して，PDMP を「図解」してみたい．

PDMP はシミュレーション方法も未だ定まっておらず，実用上も理論上もまだまだ発展途上である．実は本パッケージは [@Andral-Kamatani2024] の実装という点が特徴であるが，PDMP のアルゴリズムの側面には深入りしすぎず，本稿の終わりには PDMP の理論的な側面を少し紹介したい．

突然だが，クイズである．次クイズに答えるつもりで本稿を読んでみてほしい．

以下に，本パッケージが提供する PDMP サンプラー６つのうち３つを示す．このうち，**最も高次元空間に強い手法はどれだろうか？**

:::: {layout-ncol="3"}

![[@Bouchard-Cote+2018]](../../2024/Slides/PDMPs/BPS_SlantedGauss2D.gif)

![[@Bierkens+2019]](../../2024/Slides/PDMPs/ZigZag_SlantedGauss2D.gif)

![[@Michel+2020]](../../2024/Slides/PDMPs/ForwardECMC_StandardGauss2D.gif)

::::

{{< include ../../../assets/_preamble.qmd >}}

* ただし，簡単のため，目標分布は標準 Gauss 分布 $N_d(0,I_d)$ とする：
  $$
  \pi^d(x)\,\propto\,e^{-U^d(x)},\qquad U^d(x)=\frac{\norm{x}^2}{2}.
  $$
* 「高次元に強い」とは，次のように決めるものとする：
  * 計算複雑性（例えば１つの独立サンプルを出力するのに要する $U(x),\nabla U(x)$ 評価の回数）のスケール $O(d^{\alpha})$ の $\alpha$ が小さいと「強い」とする．
  * 同じスケールにおいては，同一回数の $U(x),\nabla U(x)$ 評価（近似的に CPU 時間と比例するものとする）^[シミュレーション法が定まっていないのでうまく言えないが，理想的なアルゴリズムではほとんどその通りになる．]で，より多くの独立サンプルを生み出す方が「強い」とする．

正解は本記事の最後に触れる．

それまでは，上の４つの gif が表す確率過程が，どのように生成されているか解説する．

`PDMPFlux.jl` の実装について詳しくなってもらうと同時に，６つの PDMP 手法を通じて，「より速い手法を作るにはどういうアイデアがあり得るか？」を一緒に考えて欲しい．実際，マジのアイデア不足である．

最後に，現状での理論が与える示唆を少し紹介する．

## PDMP の基本：Poisson 点過程を打つ

基本的に，全ての PDMP アルゴリズムは点を打っている（＝特定の Poisson 点過程をシミュレーションしている）だけである．この時点で，既存の MCMC アルゴリズムとは全く違う．^[だが，最終的に最もうまくいく MCMC アルゴリズムと，最もうまくいく PDMP アルゴリズムは，確率過程としてはとても似通ってくる．シミュレーション方法が違うのみである．]

![PDMP アルゴリズム＝緑の点がどこに来るかをシミュレーションする．緑の点で「どのように方向転換をするか」は，手法ごとに違う．](Emergence/ZZS_demo.gif){fig-align="center" width="50%"}

打った点の間を直線で（または他の規定の規則で）補間するだけで最終的な output が完成する（次のコードの `sample_from_skeleton` の部分）．

```{.julia filename="PDMPFlux.jl/src/sample.jl"}
function sample(
    sampler::AbstractPDMP,  # PDMP サンプラーの種類を指定
    N_sk::Int,  # シミュレーションするイベントの数
    N_samples::Int,  # 最終的に出力するサンプルの数
    xinit::Vector{Float64},  # 初期値（位置）
    vinit::Vector{Float64};  # 初期値（速度）
    seed::Int=nothing,  # 乱数のシード（必要ならば）
    verbose::Bool = true  # 進捗バーを表示するかどうか
)::Matrix{Float64}

    history = sample_skeleton(sampler, N_sk, xinit, vinit, seed=seed, verbose=verbose)
    return sample_from_skeleton(sampler, N_samples, history)

end
```

この `sample_skeleton` が PDMP シミュレーションの本質であり，中では「次のイベント時刻の特定」の繰り返しである．

仮に１つ前のイベント時刻 $T_{i-1}$ で $(X_{T_{i-1}},V_{T_{i-1}})=(x,v)\in\R^{2d}$ まで来ているとしよう．すると，次のイベント時刻 $T_i$ が来るまでの時間 $T_i-T_{i-1}$ は，強度関数
$$
\lambda(t)=\max(0,\brac{V_t|\nabla U(X_t)})
$$ {#eq-lambda}
で定まる．

強度関数 (intensity function) とは Poisson 点過程の双対可予測射影を指す語であるが，生存解析におけるハザード関数と捉えても良い．

結局，次のイベント時刻 $T_i$ は
$$
\P[T_i-T_{i-1}\ge t|T_{i-1}]=\exp\paren{-\int^t_0\lambda(s)\,ds}
$$
に従って定まる．

$\lambda$ が定数ならば，到着時間 $T_i-T_{i-1}$ は指数分布である．しかし，式 ([-@eq-lambda]) は「速度 $V_t$ の，確率密度が下がっていく方向 $\nabla U(X_t)$ の成分が大きければ大きいほどイベントが起きやすい」ことを意味する．

これにより，式 ([-@eq-lambda]) に従ってイベント時刻を決定し，そこでうまく高密度領域に戻るような「方向転換」をデザインすれば，サンプラーを $U(x)$ の値が大きい領域に誘導することができる．

これが，確率分布 $\pi(x)\propto e^{-U(x)}$ に収束する PDMP の作り方である．

"PDMP" という名前についてであるが，直線部分が "piecewise deterministic" と呼ばれるゆえんであり，"Markov process" の部分は主に，方向転換が Markov 点過程に従うことと，方向転換の仕方がランダムである（場合がある）ことを指す．

## PDMP サンプラー戦国時代：方向転換のデザイン

最も代表的な手法は BPS (Bouncy Particle Sampler) 群である．

これは Snell の反射の法則の通りに方向転換をする．つまり，イベントが起こった場合，ポテンシャル $U(x)=-\log\pi(x)$ の等高線の接線を鏡に見立てて，反射する．式で表すと：
$$
V_t^{\text{new}}\gets V_t-2\frac{\brac{V_t|\nabla U(X_t)}}{\norm{\nabla U(X_t)}^2}\nabla U(X_t).
$$

これにより速度 $V_t$ のうち $\nabla U(X_t)$ に平行だった成分は反射され，垂直な成分はそのまま残る．

:::: {layout-ncol="2"}

![[@Bouchard-Cote+2018]](../../2024/Slides/PDMPs/BPS_SlantedGauss2D.gif){width=50%}

![[@Bierkens+2020]](../../2024/Slides/PDMPs/Boomerang_SlantedGauss2D.gif){width=50%}

::::

右側の Boomerang Sampler では参照測度が違う．BPS と同じメカニズムだが，$\R^n$ 上の Lebesgue 測度に対して設計する代わりに，標準 Gauss 測度に対して設計されている．このため，$\R^{\infty}$ 上でも定義可能な手法になっている．^[$\R^{\infty}$ または一般の可分 Hilbert 空間上では Lebesgue 測度は存在しないが，Gauss 測度は存在し続ける．] このような手法は function space MCMC とも呼ばれる [@Cotter+2013]．

この BPS 群の最大の欠点は refreshment という追加の動作が必要な点である．定期的に速度 $V_t$ を平衡分布にリセットする必要がある．

さもなくば，ダイナミクスのランダムネスが不足し，エルゴード性が失われたり，すごく遅くなったりする：

```{julia}
#| eval: false
#| code-fold: true

using PDMPFlux, Plots

@inline function ∇U(x::AbstractVector)
  return x
end

dim = 2
sampler = BPS(dim, ∇U; refresh_rate=0.0)

N_sk, xinit, vinit = 1_000, randn(dim), randn(dim)
vinit = vinit ./ sqrt(sum(vinit.^2))

output_BPS = sample_skeleton(sampler, N_sk, xinit, vinit, seed=20250428)
x_BPS = output_BPS.X
v_BPS = output_BPS.V
t_BPS = output_BPS.t

anim_traj(output_BPS, 100; plot_start=50, filename="BPS.gif", color="#E95420", scatter_color="#78C2AD", background="#F0F1EB", title="BPS without Refreshment", xlabel="", ylabel="", axis=false)
```

![](Emergence/BPS.gif){fig-align="center" width="50%"}

この問題を迂回する１つの方法は，そもそも進行方向を $\{\pm1\}^d$ に制限することである．

![[@Bierkens+2019]](../../2024/Slides/PDMPs/ZigZag_SlantedGauss2D.gif){width=30%}

これは trajectory の形状から Zig-Zag sampler と呼ばれるが，異方性に弱いという欠点がある．

つまり，分布の形状が $\{\pm1\}^d$ にうまく沿っていない場合，大変非効率的な移動を強いられるという欠点がある．

```{julia}
#| eval: false
#| code-fold: true

using PDMPFlux, LinearAlgebra

const γ = 10

@inline function ∇U(x::AbstractVector)
  return [γ,1/γ] ⋅ x
end

dim = 2
sampler = ZigZag(dim, ∇U; refresh_rate=0.0)

N_sk, xinit, vinit = 1_000, zeros(dim), ones(dim)

output_ZZ = sample_skeleton(sampler, N_sk, xinit, vinit, seed=20250428)
x_ZZ = output_ZZ.X
v_ZZ = output_ZZ.V
t_ZZ = output_ZZ.t

anim_traj(output_ZZ, 100; plot_start=50, filename="ZZS.gif", color="#E95420", scatter_color="#78C2AD", background="#F0F1EB", title="Zig-Zag on an Anisotropic Target", xlims=(-5, 5), ylims=(-5, 5))

```

![](Emergence/ZZS.gif){fig-align="center" width="50%"}

## PDMP の最近の発展

以上，今まで見てきたどの手法も得手・不得手というものがあった．

### FECMC：確率的反射，部分的リフレッシュ

今までの手法は全て，方向転換の仕方がシンプルで，ランダムネスは（実は）ない．

Forward Event-Chain Monte Carlo 法 [@Michel+2020] は，「ランダムな反射」を設計することで，「リフレッシュ動作が欠かせない」という先述の BPS の欠点を克服した．

特に「絶対に今来た道を戻らない "Forward"」という設計が凝らされており，次のようにくるくる回る軌道を描く：

![[@Michel+2020]](../../2024/Slides/PDMPs/ForwardECMC_StandardGauss2D.gif){fig-align="center" width=30%}

名前についてであるが，ECMC (Event-Chain Monte Carlo) 法とは，実は PDMP という名前がついて統計に輸入される前の，物理学で用いられていた手法である [@Bernard+2009], [@Michel+2014], [@Nishikawa+2015], [@Krauth2021]．

そもそも PDMP とは ECMC などの名前で，はじめて氷の融解の過程の全原子シミュレーションに成功（！）して [@Bernard-Krauth2011]，満を持して統計分野に輸入されたのであった．^[他にも直接の祖先は ECMC 以外にも辿れる [@Peters-deWith2012]．]

### Sticky PDMP：アトムを含む分布への解決策

PDMP はなんといっても連続時間の軌道を出力するという点に，過去の Monte Carlo 法にない特徴がある．

この特徴が極めて不思議な応用をもたらしてくれることを，コミュニティは近年自覚しつつある．

まず，目標の確率分布は絶対連続じゃなく，アトムが有限個含まれていても良い．

例えば，変数選択のことを考えて，事後分布が $\alpha\pi(x)+(1-\alpha)\delta_0(dx)$ という形で表せたとしよう．

この $\alpha$ の値（回帰で言えば，当該変数の事後包含確率）の値と，モデルに含まれた場合の事後分布を同時にサンプリングしたい場合，Sticky Zig-Zag sampler [@Bierkens+2023] が使える：

![[@Bierkens+2023]](../../2024/Slides/PDMPs/StickyZigZag.gif){fig-align="center" width=30%}

### Speed-Up PDMP：加速による重点サンプリング

連続時間のアルゴリズムになったため，「加速」という概念が生まれる．

単に加速するのではなく，位置に応じてサンプラーの速さを変えることで，分布の「どこを重視して欲しいか」を指定する使い方ができる．

これにより，裾が重い分布における尾部領域や，多峰性分布における谷の部分など，従来の MCMC では探索が困難であった領域に，違った重みを与えることができる．

![[@Vasdekis-Roberts2023]](../../2024/Slides/PDMPs/SUZZ_SlantedGauss2D.gif){fig-align="center" width=30%}

[@Bertazzi-Vasdekis2025] では，なんと 13 成分の混合 Gauss 分布から，ひとつもモードを潰さない正確なサンプリングを達成していることを報告している：

![[@Bertazzi-Vasdekis2025 p.19 Figure 4]](Emergence/Bertazzi_Vasdekis.png){fig-align="center" width=50%}

## クイズの答え

正解は Forward Event-Chain Monte Carlo である．

だが正確には，正解は２つあると言うべきである：

:::: {layout-ncol="2"}

![[@Bierkens+2019]](../../2024/Slides/PDMPs/ZigZag_SlantedGauss2D.gif)

![[@Michel+2020]](../../2024/Slides/PDMPs/ForwardECMC_StandardGauss2D.gif)

::::

というのも，Zig-Zag サンプラーには，ターゲット分布が積の形 $\pi(x)=\prod_{i=1}^d\pi^i(x_i)$ で書ける場合にだけ使える効率的な実装法があり，これを採用した場合のスケーリングは BPS や FECMC をしのぐ．

実はこの局所性を活かした実装が，ECMC という名前で，氷などの凝縮系の Monte Carlo シミュレーションで圧倒的な性能を見せつけてきた理由である．この点は [@Tartero-Krauth2023] などが良い入門になる．

しかし，一般的のターゲットに通用する実装で比較すると，FECMC の方が効率が良い：

```{julia}
#| eval: false
#| code-fold: true

using PDMPFlux, Plots, ProgressBars, LinearAlgebra, StatsPlots

const dim = 100

@inline function ∇U(x::AbstractVector)
  return x
end

@inline function ∇U_Boomerang(x::AbstractVector)
  return ones(dim)
end

function h_estimate_online(
  sampler::PDMPFlux.AbstractPDMP,
  T_end::Float64,
  xinit::Vector{Float64},
  vinit::Vector{Float64};
  seed::Union{Int, Nothing}=nothing,
)::Float64
  if !(isfinite(T_end)) || T_end < 0
    throw(ArgumentError("T_end must be finite and non-negative. Current value: $T_end"))
  end
  d = length(xinit)
  if d == 0
    throw(ArgumentError("xinit must be non-empty"))
  end
  if T_end == 0.0
    return 0.0
  end

  state = PDMPFlux.init_state(sampler, xinit, vinit, seed)

  estimate = 0.0

  # 現在のイベント点（post-jump）を保持し、次イベントまでの区間寄与を足す
  t_prev = state.t
  x_prev = copy(state.x)
  v_prev = copy(state.v)

  while t_prev < T_end
    PDMPFlux.get_event_state!(state, sampler)  # mutates state in-place; advances state.t to next accepted event
    t_next = state.t

    if t_next <= T_end
      Δt = t_next - t_prev
      # 区間 [t_prev, t_next] は (x_prev, v_prev) からの flow
      nx = dot(x_prev, x_prev)
      xv = dot(x_prev, v_prev)
      estimate += nx * Δt + (Δt^3) / 3 + (Δt^2) * xv

      t_prev = t_next
      copyto!(x_prev, state.x)
      copyto!(v_prev, state.v)
    else
      # overshoot: 最後は flow で t=T_end の点を作ってそこで打ち切る
      Δt = T_end - t_prev
      nx = dot(x_prev, x_prev)
      xv = dot(x_prev, v_prev)
      estimate += nx * Δt + (Δt^3) / 3 + (Δt^2) * xv
      break
    end
  end

  return (estimate - d * T_end) / sqrt(d) / T_end  # CAUTION: inprecise denominator (intentionally)
end

function Experiment_once()
  ZZS = ZigZag(dim, ∇U; refresh_rate=0.0)
  T, xinit, vinit = Float64(1000), randn(dim), ones(dim)
  t_ZZ = @elapsed output_ZZ = h_estimate_online(ZZS, T, xinit, vinit)

  BPS_sampler = BPS(dim, ∇U; refresh_rate=1.4)
  vinit = randn(dim)
  vinit = vinit ./ norm(vinit)
  t_BPS = @elapsed output_BPS = h_estimate_online(BPS_sampler, T, xinit, vinit)

  vinit = randn(dim)
  vinit = vinit ./ norm(vinit)
  FECMC = ForwardECMC(dim, ∇U)
  t_ForwardECMC = @elapsed output_ForwardECMC = h_estimate_online(FECMC, T, xinit, vinit)
  return [abs2(output_ZZ) * t_ZZ, abs2(output_BPS) * t_BPS, abs2(output_ForwardECMC) * t_ForwardECMC]
end

function Experiment(iter::Int=100)
  results = Matrix{Float64}(undef, iter, 3)
  for i in ProgressBar(1:iter)
    results[i,:] = Experiment_once()
  end
  return results
end

results = Experiment(100)

iter  = size(results, 1)
labels = ["ZZS", "BPS", "FECMC"]
groups = repeat(labels, inner=iter)
groups = categorical(groups; ordered=true, levels=labels)
boxplot(groups, vec(results);
    group = groups,
    bar_width = 0.7,
    legend = :bottomleft,
    xlabel = "Sampler",
    ylabel = "Squared Error × Computational Time",
    yscale = :log10)
```

![](Emergence/Comparison.png){fig-align="center" width="50%"}

縦軸は実行時間によって調節した平均自乗誤差 (MSE) であり，小さいほど性能が良い．

この性能差はスケーリング極限／拡散近似の数学によって理論的に説明することができる．

## 参考文献