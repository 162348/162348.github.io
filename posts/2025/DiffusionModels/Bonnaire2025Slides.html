<!DOCTYPE html>
<html lang="en"><head>
<link href="../../../assets/Shiba2.png" rel="icon" type="image/png">
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.27">

  <meta name="author" content="司馬博文">
  <title>Hirofumi Shiba – 拡散モデルでの動的暗黙正則化</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/theme/quarto-fef162f4c625999bce714cddb536258a.css">
  <link rel="stylesheet" href="../../../assets/slides.css">
  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">
  <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-36GX2G6GLL"></script>

  <script type="text/javascript">

  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-36GX2G6GLL', { 'anonymize_ip': true});
  </script>
  <link href="../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-pointer/pointer.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
  <link href="https://fonts.googleapis.com/css2?family=Zen+Kurenaido&amp;display=swap" rel="stylesheet">

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
  <link href="https://fonts.googleapis.com/css2?family=BIZ+UDPGothic&amp;display=swap" rel="stylesheet">

  <style>
    .navbar-title, .menu-text {
        font-family: "BIZ UDPGothic", sans-serif !important;
    }
    h1, .title, .description, .subtitle, .quarto-title-author-name, .quarto-title-affiliation, .date {
      font-family: "BIZ UDPGothic", sans-serif !important;
    }
    .quarto-title-author-name {
      font-size: 1.4em !important;
    }
    .date {
      font-size: 0.8em !important;
    }
    .callout.callout-titled .callout-body > .callout-content > :last-child {
      padding-bottom: 0.0em !important;
      margin-bottom: 0.5em !important;
    }
    .callout-body {
    color: #062e4b;
    font-size: 1.4em !important;
    }
    .katex-display {
      margin-top: 0.3em !important;
      margin-bottom: 0.3em !important;
    }
  </style>

  <!-- <style>
    .menu-text {
        font-family: "Gill Sans", sans-serif !important;
        font-weight: 400;
        font-style: normal;
    }
    .navbar-title {
        font-family: "Gill Sans", sans-serif !important;
        font-weight: 400;
        font-style: normal;
    }
  </style> -->
<meta property="og:title" content="拡散モデルでの動的暗黙正則化 – Hirofumi Shiba">
<meta property="og:description" content="スライド版はこちら．">
<meta property="og:image" content="https://162348.github.io/posts/2025/DiffusionModels/.Bonnaire2025/Summary1.png">
<meta property="og:site_name" content="Hirofumi Shiba">
<meta name="twitter:title" content="拡散モデルでの動的暗黙正則化 – Hirofumi Shiba">
<meta name="twitter:description" content="スライド版はこちら．">
<meta name="twitter:image" content="https://162348.github.io/posts/2025/DiffusionModels/.Bonnaire2025/Summary1.png">
<meta name="twitter:creator" content="@ano2math5">
<meta name="twitter:card" content="summary_large_image">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">拡散モデルでの動的暗黙正則化</h1>
  <p class="subtitle">Bonnaire, Urfin, Biroli &amp; Mézard (2025, NeurIPS)<br>Why Diffusion Models Don’t Memorize: The Role of Implicit Dynamical Regularization in Training</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
司馬博文 
</div>
</div>
</div>

  <p class="date">1/26/2026</p>
</section><section id="TOC">
<nav role="doc-toc"> 
<h2 id="toc-title">目次</h2>
<ul>
<li><a href="#/はじめに" id="/toc-はじめに"><span class="header-section-number">1</span> はじめに</a></li>
<li><a href="#/実験パート-section-2" id="/toc-実験パート-section-2"><span class="header-section-number">2</span> 実験パート (Section 2)</a></li>
<li><a href="#/理論パート-section-3" id="/toc-理論パート-section-3"><span class="header-section-number">3</span> 理論パート (Section 3)</a></li>
<li><a href="#/まとめ" id="/toc-まとめ"><span class="header-section-number">4</span> まとめ</a></li>
</ul>
</nav>
</section>
<section>
<section id="はじめに" class="title-slide slide level1 center" data-number="1">
<h1><span class="header-section-number">1</span> はじめに</h1>
<p><a href="#/sec-DMs" class="quarto-xref">1.1</a>. Diffusion Model とは？</p>
<p><a href="#/sec-Biroli" class="quarto-xref">1.2</a>. 先行研究 <span class="citation" data-cites="Biroli+2024">(<a href="#/参考文献" role="doc-biblioref" onclick="">Biroli et al., 2024</a>)</span></p>
<p><a href="#/sec-summary" class="quarto-xref">1.3</a>. 本論文の要旨</p>
<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
</section>
<section id="sec-DMs" class="slide level2" data-number="1.1">
<h2><span class="header-section-number">1.1</span> Score-based Diffusion Models</h2>
<p><span class="math display">
\text{Forward}\quad dX_t=-X_t\,dt+dB_t,\quad X_0\sim P_x,
</span> <span class="math display">
\text{Reverse}\quad dX'_t=-\biggr(X_t'+2s_t'(X_t')\biggl)\,dt+dB'_t.
</span></p>
<p>ただし <span class="math inline">s_t'(x):=\nabla_x\log p_t'(x)</span> は <span class="math inline">(X_t')</span> の周辺密度 <span class="math inline">p_t'</span> の Hyvärinen スコア．</p>
<div title="[Tweedie's Formula @Efron2011] の系">
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong><span class="citation" data-cites="Efron2011">(Tweedie’s Formula <a href="#/参考文献" role="doc-biblioref" onclick="">Efron, 2011</a>)</span> の系</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">
\operatorname{E}\left[\frac{e^{-t}X_x-X_{s+t}}{\Delta_t}\,\middle|\,X_{s+t}=x\right]=\nabla_x\log p_{s+t}(x).
</span></p>
</div>
</div>
</div>
</div>
<p><span class="math inline">\Delta_t:=\sqrt{1-e^{-2t}}</span> とすると <span class="math inline">\xi:=\frac{X_{s+t}-e^{-t}X_s}{\sqrt{\Delta_t}}\sim\operatorname{N}(0,1)</span>．</p>
<p><span class="math inline">s\to\infty</span> を考えて，次の損失関数が発想される： <span class="math display">
\mathcal{L}_t(\theta;\{x^\nu\}_{\nu=1}^n)=\frac{1}{n}\sum_{\nu=1}^n\operatorname{E}_\xi\left[\|\sqrt{\Delta_t}s_\theta(x_t^\nu(\xi))+\xi\|^2\right].
</span></p>

<aside><div>
<p>ただし，<span class="math inline">x_t^\nu(\xi):=e^{-t}x^\nu+\sqrt{\Delta_t}\xi</span>．</p>
</div></aside></section>
<section id="sec-Biroli" class="slide level2" data-number="1.2">
<h2><span class="header-section-number">1.2</span> Generation from the Empirical Score</h2>
<div title="Memorization Regime = 過学習 [@Biroli+2024]">
<div class="callout callout-important no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Memorization Regime = 過学習 <span class="citation" data-cites="Biroli+2024">(<a href="#/参考文献" role="doc-biblioref" onclick="">Biroli et al., 2024</a>)</span></strong></p>
</div>
<div class="callout-content">
<p>経験リスク最小化問題</p>
<p><span class="math display">
\mathcal{L}_t(\theta;\{x^\nu\}_{\nu=1}^n)=\frac{1}{n}\sum_{\nu=1}^n\operatorname{E}_\xi\left[\|\sqrt{\Delta_t}s_\theta(x_t^\nu(\xi))+\xi\|^2\right].
</span></p>
<p>を解き切ったらうまくいかない．理論的には <span class="math inline">\mathbb{P}_n</span> からのサンプルを再現してしまう．</p>
<p>→ 実際には経験リスク最小化を解き切っていないはず．</p>
</div>
</div>
</div>
</div>
<ul>
<li><p>Early stopping により汎化を達成しているのでは？</p></li>
<li><p>不完全なスコア学習＋サンプリングでの数値誤差で汎化している？？？</p></li>
</ul>

<aside><div>
<p><span class="math inline">n=O(e^d)</span> で大きくすると memorization が起こる時刻は <span class="math inline">\tau_C\to0</span> に近づく <span class="citation" data-cites="Biroli+2024">(<a href="#/参考文献" role="doc-biblioref" onclick="">Biroli et al., 2024</a>)</span>： <span class="math display">
\tau_C=\frac{1}{2}\log\left(1+\frac{\sigma^2}{n^{\frac{2}{d}}-1}\right)
</span></p>
</div></aside></section>
<section id="sec-summary" class="slide level2" data-number="1.3">
<h2><span class="header-section-number">1.3</span> 本論文の要旨：Implicit Dynamical Regularization</h2>
<div class="columns" style="text-align: center;">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Bonnaire2025/Summary1.png" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Bonnaire2025/Summary_diagram_tau_mem.png" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div></div>
<ul>
<li>たしかに解き切っていない．汎化のためには early stopping が必須．</li>
<li><span class="math inline">n&lt;p</span> じゃないと implicit dynamical regularization は起きない．</li>
<li><span class="math inline">p&lt;n</span> のとき，訓練ダイナミクスにスケール分離が見られる
<ul>
<li><p>汎化が始まる時間は <span class="math inline">\tau_{\text{gen}}=O(1)</span> だが，過学習が始まる時間は <span class="math inline">\tau_{\text{mem}}=O(n)</span></p>
<p>→ <span class="math inline">n</span> が大きいほど early stopping の sweet spot が広い．</p></li>
</ul></li>
</ul>
</section></section>
<section>
<section id="実験パート-section-2" class="title-slide slide level1 center" data-number="2">
<h1><span class="header-section-number">2</span> 実験パート (Section 2)</h1>
<p>理論パートではスコア学習に特化して解析するので，</p>
<p><span class="math display">
\text{スコア学習での汎化}\,\approx\,\text{Generative Model としての汎化}
</span></p>
<p>を確認する必要がある (<a href="#/sec-experiment-n" class="quarto-xref">2.2</a>)．</p>
<p>＋スケーリングの検証 (<a href="#/sec-experiment-p" class="quarto-xref">2.3</a>) ＋相図の検証 (<a href="#/sec-experiment-p-n" class="quarto-xref">2.4</a>)</p>
</section>
<section id="設定" class="slide level2" data-number="2.1">
<h2><span class="header-section-number">2.1</span> 設定</h2>
<ul>
<li><strong>データ</strong>：cropped, grayscaled, &amp; downsampled CelebA, <span class="math inline">d=32^2</span></li>
</ul>

<img data-src="Bonnaire2025/SM_Images_CelebA.jpeg" class="quarto-figure quarto-figure-center r-stretch" width="10"><ul>
<li><strong>スコア学習に使う NN</strong>：U-Net, 時刻 <span class="math inline">t</span> は sinusoidal position embedding</li>
<li><strong>損失関数</strong>：DDPM loss．ここまで全て <span class="citation" data-cites="Ho+2020">(<a href="#/参考文献" role="doc-biblioref" onclick="">Ho et al., 2020</a>)</span> の設定に従う．</li>
<li><strong>訓練</strong>：SGD, momentum <span class="math inline">\beta=0.95</span>, <span class="math inline">\eta=0.01</span>, <span class="math inline">B=n\land512</span></li>
</ul>
<p><span class="math inline">n\in\{128,\cdots,32768\}</span>, <span class="math inline">p\in\{1/4,1,2,4,9,16\}\times10^6</span> を順に動かしていく</p>
</section>
<section id="sec-experiment-n" class="slide level2" data-number="2.2">
<h2><span class="header-section-number">2.2</span> データサイズ <span class="math inline">n</span> を変える</h2>
<div class="columns" style="text-align: center;">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Bonnaire2025/N1.png" style="width:70.0%"></p>
<figcaption>横軸：訓練 step 数 <span class="math inline">\tau</span>，縦軸：Fréchet Inception Distance（実線），記憶データ点割合 %（点線）．</figcaption>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Bonnaire2025/N2.png" style="width:70.0%"></p>
<figcaption>スコア学習誤差のプロット<br>訓練誤差（実線），テスト誤差（点線）．全て <span class="math inline">t=0.01</span>．</figcaption>
</figure>
</div>
</div><ul>
<li><span class="math inline">n</span> が増えるほど汎化ギャップ <span class="math inline">\mathcal{L}_{\text{gen}}=\mathcal{L}_{\text{test}}-\mathcal{L}_{\text{train}}</span> が小さくなる．</li>
<li><span class="math inline">\mathcal{L}_{\text{gen}}&gt;0</span> が始まって，少し遅れて <span class="math inline">f_{\text{mem}}&gt;0</span> が始まる．が，スケーリングは同じ．</li>
</ul>
</div>
</section>
<section id="データサイズ-n-を変える" class="slide level2 unnumbered unlisted" data-visibility="uncounted">
<h2>2.2 データサイズ <span class="math inline">n</span> を変える</h2>
<div class="columns" style="text-align: center;">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Bonnaire2025/CelebA_B=n.png" style="width:70.0%"></p>
<figcaption>フルバッチ <span class="math inline">B=n</span> を取った場合</figcaption>
</figure>
</div>
<p><span class="small-letter">それでも同じスケーリングが見られる</span></p>
<p><span class="tiny-letter">→ 「モデルにサンプルを見せた回数」に依らない現象</span></p>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Bonnaire2025/CelebA_Adam.png" style="width:70.0%"></p>
<figcaption>SGD with momentum ではなく Adam を使った場合</figcaption>
</figure>
</div>
<p><span class="small-letter"><span class="math inline">\tau_{\text{gen}},\tau_{\text{mem}}</span> が全体的に小さい方向へスライド</span></p>
<p><span class="small-letter">主要なスケーリングは変わらない</span></p>
</div><!-- [横軸：訓練 step 数 $\tau$，縦軸：Fréchet Inception Distance（実線），記憶データ点割合 %（点線）．]{.small-letter} -->
</div>
</section>
<section id="sec-experiment-p" class="slide level2" data-number="2.3">
<h2><span class="header-section-number">2.3</span> モデルサイズ <span class="math inline">p</span> を変える</h2>
<div class="columns" data-layout-valign="middle">
<div class="column" data-layout-valign="middle" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Bonnaire2025/p1.png" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div title="U-Net チャンネル数を増やす">
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>U-Net チャンネル数を増やす</strong></p>
</div>
<div class="callout-content">
<ul>
<li><p>Base channel width <span class="math inline">W</span></p>
<p><span class="math inline">W\in\{8,16,32,48,64\}</span></p>
<p>→ <span class="math inline">p\in\{1/4,1,2,4,9,16\}\times10^6</span></p></li>
</ul>
</div>
</div>
</div>
</div>
<p>FID が下がり始める時刻： <span class="math display">
\tau_{\text{gen}}W=O(1)
</span></p>
<p>訓練データに酷似した生成が始まる時刻： <span class="math display">
\tau_{\text{mem}}W=O(n)
</span></p>
</div></div>
</section>
<section id="sec-experiment-p-n" class="slide level2" data-number="2.4">
<h2><span class="header-section-number">2.4</span> <span class="math inline">(p,n)</span> 相図</h2>
<div class="columns" style="text-align: center;">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Bonnaire2025/p2.png" style="width:100.0%"></p>
<figcaption>間に挟まれた相では，訓練時間に２つのスケールが現れる．</figcaption>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div title="Memorization Regime">
<div class="callout callout-important no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Memorization Regime</strong></p>
</div>
<div class="callout-content">
<p><span class="math inline">n</span> が小さすぎると，FID が下がり始める瞬間 <span class="math inline">\tau_{\text{gen}}</span> に memorization も起こる <span class="math display">
\tau_{\text{gen}}\approx\tau_{\text{mem}}\quad \textcolor{#EEC1C0}{p\gg n}
</span></p>
</div>
</div>
</div>
</div>
<div title="Architectural Regularization">
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Architectural Regularization</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">
n&gt;n^*(p)\approx p\qquad(n,p\to\infty)
</span> を超えると，<span class="math inline">\tau\to\infty</span> でも memorization は起こらない．</p>
</div>
</div>
</div>
</div>
</div></div>
</section></section>
<section>
<section id="理論パート-section-3" class="title-slide slide level1 center" data-number="3">
<h1><span class="header-section-number">3</span> 理論パート (Section 3)</h1>
<p>ランダム行列の経験スペクトル分布の極限に対するスケーリング解析</p>
<ul>
<li>ランダム行列のスペクトル分布解析への帰着 (<a href="#/sec-reduction" class="quarto-xref">3.3</a>)</li>
<li>ランダム行列の Stieltjes Transform Method (<a href="#/sec-Stieltjes" class="quarto-xref">3.4</a>)</li>
<li><strong>主定理</strong>：平均レゾルベントの満たす自己無撞着方程式 (<a href="#/sec-main-theorem" class="quarto-xref">3.6</a>)</li>
<li><strong>主補題</strong>：Gaussian Equivalence Principle (<a href="#/sec-GEP" class="quarto-xref">3.7</a>)</li>
<li>証明方針２つ：Replica Method v. Free Probability (<a href="#/sec-proof" class="quarto-xref">3.8</a>)</li>
<li><strong>主な系</strong>：Two-Bulk 構造 (<a href="#/sec-two-bulk" class="quarto-xref">3.9</a>)</li>
<li>結論・ダイナミクスへの示唆：Separation of Timescales (<a href="#/sec-dynamics" class="quarto-xref">3.10</a>)</li>
</ul>
</section>
<section id="設定-1" class="slide level2" data-number="3.1">
<h2><span class="header-section-number">3.1</span> 設定</h2>
<ul>
<li><strong>データ</strong>: <span class="math inline">\mathbb{R}^d\ni x^\nu\overset{\text{i.i.d.}}{\sim}P_x\;(\nu=1,\cdots,n)</span>. あとで <span class="math inline">d\to\infty</span> の極限を考える．</li>
<li><strong>スコア学習に使うNN</strong>：Random Feature <span class="math inline">W\in\mathbb{R}^{p\times d}</span> with i.i.d. Gaussian <span class="math display">
s_A(x):=\frac{A}{\sqrt{p}}\sigma^{\otimes p}\left(\frac{Wx}{\sqrt{d}}\right)\qquad A\in\mathbb{R}^{d\times p},
</span></li>
<li><strong>損失関数</strong>: 固定した時刻 <span class="math inline">t&gt;0</span> での DSM loss <span class="math display">
\mathcal{L}_t(A;\{x^\nu\}_{\nu=1}^n):=\frac{1}{dn}\sum_{\nu=1}^n\operatorname{E}\left[\|\sqrt{\Delta_t s_A(x_t^\nu(\xi))}+\xi\|^2\right].
</span></li>
<li><strong>訓練</strong>: GD の連続時間極限 <span class="math display">
\dot{A}_\tau=-d^2\nabla_A\mathcal{L}_t(A_\tau)=-2\Delta_t\frac{d}{p}AU_\tau-\frac{2d\sqrt{\Delta_t}}{\sqrt{p}}V_\tau^\top,\qquad\tau\ge0.
</span></li>
</ul>
</section>
<section id="gd-の連続時間極限" class="slide level2" data-number="3.2">
<h2><span class="header-section-number">3.2</span> GD の連続時間極限</h2>
<p>DSM loss での勾配降下法： <!-- $$\mathcal{L}_t(\theta,\{x^\nu\}^n_{\nu=1})=\frac{1}{d}\frac{1}{n}\sum_{\nu=1}^n\operatorname{E}_\xi\SQuare{\|\sqrt{\Delta_t}s_\theta(X^\nu_t)+\xi\|^2\,\bigg|\,X^\nu_0=\xi}$$ --> <span class="math display">
A^{(k+1)}\gets A^{(k)}-\eta\nabla_A\mathcal{L}_t(A^{(k)}),\qquad k=0,1,2,\cdots
</span> <span class="math display">
\mathcal{L}_t(A)=\frac{1}{d}\left(\frac{\Delta_t}{p}\operatorname{Tr}(A^\top AU)+\frac{2\sqrt{\Delta_t}}{\sqrt{p}}\operatorname{Tr}(AV)+d\right)
</span></p>
<p>時間変換 <span class="math inline">\tau(k):=k\eta/d^2</span> を施して，<span class="math inline">\eta\to0</span> の極限を取ると <span class="math display">
\dot{A}_\tau=-d^2\nabla_A\mathcal{L}_t(A_\tau)=-2\Delta_t\frac{d}{p}A_\tau U-\frac{2d\sqrt{\Delta_t}}{\sqrt{p}}V^\top,\qquad\tau\ge0,
</span> <span class="math display">%:=\frac{1}{n}\sum_{\nu=1}^n\E[y^\nu (y^\nu)^\top]
U:=\frac{1}{n}\sum_{\nu=1}^n\operatorname{E}_\xi\left[\sigma^{\otimes p}\left(\frac{Wx^\nu_t(\xi)}{\sqrt{d}}\right)\sigma^{\otimes p}\left(\frac{Wx^\nu_t(\xi)}{\sqrt{d}}\right)^\top\right],
</span> <span class="math display">
V:=\frac{1}{n}\sum_{\nu=1}^n\operatorname{E}_\xi\left[\sigma^{\otimes p}\left(\frac{Wx^\nu_t(\xi)}{\sqrt{d}}\right)\xi^\top\right].
</span></p>
</section>
<section id="sec-reduction" class="slide level2" data-number="3.3">
<h2><span class="header-section-number">3.3</span> <span class="math inline">U</span> のスペクトルの分布への帰着</h2>
<div class="callout callout-important no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>訓練ダイナミクス <span class="math inline">(A_\tau)_{\tau\ge0}</span> のスケール分離は，<span class="math inline">U</span> のスペクトルの分布のスケール分離からくる． 特に，典型的な緩和時間は <span class="math inline">\Delta_tU/\psi_p</span> の固有値の逆数が与える．</p>
</div>
</div>
</div>
<p><span class="math display">
\dot{\textcolor{#E95420}{A}}_{\textcolor{#E95420}{\tau}}=-d^2\nabla_A\mathcal{L}_t(\textcolor{#E95420}{A_\tau})=-2\Delta_t\frac{d}{p}\textcolor{#E95420}{A_\tau} U-\frac{2d\sqrt{\Delta_t}}{\sqrt{p}}V^\top,\qquad\tau\ge0,
</span> は行列 <span class="math inline">A\in\mathbb{R}^{d\times p}</span> に関する線型 ODE．<span class="math inline">U\in\mathrm{GL}_p(\mathbb{R})</span> なら Duhamel の公式から <span class="math display">
\frac{\textcolor{#E95420}{A_\tau}}{\sqrt{p}}=-\frac{1}{\sqrt{\Delta_t}}V^\top U^{-1}+\left(\frac{1}{\sqrt{\Delta_t}}V^\top U^{-1}+\frac{A_0}{\sqrt{p}}\right)\exp\left(-\frac{2\Delta_t}{\psi_p}U\textcolor{#E95420}{\tau}\right),
</span> <span class="math display">
\psi_p:=\frac{p}{d},\qquad\psi_n:=\frac{n}{d}.
</span></p>

<aside><div>
<p><span class="math inline">A_0=0</span> と仮定する．</p>
<p><span class="citation" data-cites="George+2025">(<a href="#/参考文献" role="doc-biblioref" onclick="">George et al., 2025</a>)</span> は解 <span class="math inline">-V^\top U^{-1}/\sqrt{\Delta_t}</span> に注目して，別の道具を通じてスペクトル分布を調べる．</p>
</div></aside></section>
<section id="sec-Stieltjes" class="slide level2" data-number="3.4">
<h2><span class="header-section-number">3.4</span> Stieltjes Transform Method (1/2)</h2>
<p><span class="math inline">U</span> の経験スペクトル分布 <span class="math inline">\mu_U</span> の Stieltjes transform は，resolvent <span class="math inline">R(z):=(U-zI_p)^{-1}</span> の平均固有値が与える： <span class="math display">
q(z):=\frac{\operatorname{Tr}(R(z))}{p}=\frac{1}{p}\sum_{i=1}^pR(z)_{ii}=\int_{-\infty}^\infty\frac{1}{\lambda-z}\mu_U(d\lambda)\quad(z\in\mathbb{C}\setminus\mathbb{R}).
</span></p>
<div title="[IX.2.2 The Spectral Theorem @Conway2007]">
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong><span class="citation" data-cites="Conway2007">(IX.2.2 The Spectral Theorem <a href="#/参考文献" role="doc-biblioref" onclick="">Conway, 2007</a>)</span></strong></p>
</div>
<div class="callout-content">
<p><span class="math inline">U</span> を Hilbert 空間 <span class="math inline">H</span> 上の正規作用素とする．このとき，ただ一つのスペクトル測度 <span class="math inline">E:\mathrm{Sp}(U)\to B(H)</span> が存在して， <span class="math display">
U=\int_{\mathrm{Sp}(U)} \lambda E(d\lambda).
</span></p>
</div>
</div>
</div>
</div>

<aside><div>
<p>Resolvent <span class="math inline">R(z)</span> は <span class="math inline">\mathrm{Sp}(U)</span> 上の有界 Borel 関数 <span class="math inline">f(\lambda)=(z-\lambda)^{-1}</span> の <span class="math inline">E</span> に関する積分．</p>
</div></aside></section>
<section id="stieltjes-transform-method-12" class="slide level2 unnumbered unlisted" data-visibility="uncounted">
<h2>3.4 Stieltjes Transform Method (1/2)</h2>
<p><span class="math inline">U</span> の経験スペクトル分布 <span class="math inline">\mu_U</span> の Stieltjes transform は，resolvent <span class="math inline">R(z):=(U-zI_p)^{-1}</span> の平均固有値が与える： <span class="math display">
q(z):=\frac{\operatorname{Tr}(R(z))}{p}=\frac{1}{p}\sum_{i=1}^pR(z)_{ii}=\int_{-\infty}^\infty\frac{1}{\lambda-z}\mu_U(d\lambda)\quad(z\in\mathbb{C}\setminus\mathbb{R}).
</span></p>
<p>Resolvent <span class="math inline">R(z)</span> は <span class="math inline">f(\lambda)=(z-\lambda)^{-1}</span> の <span class="math inline">E</span> に関する積分： <span class="math display">
R(z)=\frac{1}{U-z}=\int_{\mathrm{Sp}(U)}\frac{1}{\lambda-z}E(d\lambda).
</span> <span class="math display">
\therefore\qquad R(z)_{ii}=(e_i|R(z)e_i)=\int_{-\infty}^\infty\frac{1}{\lambda-z}\mu_{e_i}(d\lambda).
</span> <span class="math display">
\mu_U=\frac{1}{p}\sum_{i=1}^p\mu_{e_i},\qquad \mu_{e_i}(A):=(e_i|E(A)e_i)\quad(A\in \mathcal{B}(\mathbb{R})).
</span></p>
</section>
<section id="stieltjes-transform-method-22" class="slide level2" data-number="3.5">
<h2><span class="header-section-number">3.5</span> Stieltjes Transform Method (2/2)</h2>
<p><span class="math inline">q(z)=\operatorname{Tr}(R(z))/p</span> を求めれば，<span class="math inline">\mu_U</span> が復元できる：</p>
<div title="[定理2.4.3 @Anderson+2011]">
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong><span class="citation" data-cites="Anderson+2011">(定理2.4.3 <a href="#/参考文献" role="doc-biblioref" onclick="">Anderson et al., 2011</a>)</span></strong></p>
</div>
<div class="callout-content">
<p><span class="math inline">\mu</span> を <span class="math inline">\mathbb{R}</span> 上の確率測度， <span class="math display">
S_\mu(z):=\int_{-\infty}^\infty\frac{\mu(dx)}{x-z},\qquad z\in\mathbb{C}\setminus\mathbb{R}
</span> をStieltjes transform とする．任意の開区間 <span class="math inline">I\subset\mathbb{R}</span> について，<span class="math inline">\mu</span> が <span class="math inline">\partial I</span> 上に atom を持たないならば <span class="math display">
\mu(I)=\lim_{\epsilon\to0}\int_I\frac{\mathrm{Im}\,S_\mu(\lambda+i\epsilon)}{\pi}\,d\lambda.
</span></p>
</div>
</div>
</div>
</div>
</section>
<section id="stieltjes-transform-method-22-1" class="slide level2 unnumbered unlisted" data-visibility="uncounted">
<h2>3.5 Stieltjes Transform Method (2/2)</h2>
<p>【証明】 任意の <span class="math inline">\lambda\in\mathbb{R}</span> について，</p>
<p><span class="math display">\begin{align*}
    \mathrm{Im}\,\left(\frac{S_\mu(\lambda+i\epsilon)}{\pi}\right)&amp;=\frac{S_\mu(\lambda+i\epsilon)-S_\mu(\lambda-i\epsilon)}{2\pi i}\\
    &amp;=\frac{1}{2\pi i}\int_\mathbb{R}\left(\frac{1}{x-(\lambda+i\epsilon)}-\frac{1}{x-(\lambda-i\epsilon)}\right)\,\mu(dx)\\
    &amp;=\frac{1}{2\pi i}\int_\mathbb{R}\frac{2i\epsilon}{x^2-2\lambda x+(\lambda^2+\epsilon^2)}\mu(dx)\\
    &amp;=\int_\mathbb{R}\frac{1}{\pi}\frac{\epsilon}{(x-\lambda)^2+\epsilon^2}\mu(dx),\qquad\lambda\in\mathbb{R}.
  \end{align*}</span></p>
<p>この右辺は実は <span class="math inline">X\sim\mu,C_\epsilon\sim\operatorname{Cauchy}(0,\epsilon)</span> について <span class="math inline">X+C_\epsilon</span> の分布の <span class="math inline">\lambda</span> での確率密度である．<span class="math inline">X+C_\epsilon\Rightarrow X</span> から結論が従う．</p>

<aside><div>
<p>複素解析の <a href="https://en.wikipedia.org/wiki/Sokhotski%E2%80%93Plemelj_theorem">Sokhotski-Plemelj の公式</a> の系ともみれる．</p>
</div></aside></section>
<section id="sec-main-theorem" class="slide level2" data-number="3.6">
<h2><span class="header-section-number">3.6</span> 主定理：平均レゾルベント <span class="math inline">q(z)</span> の極限の特徴付け</h2>
<p><span class="math inline">q</span> を記述するための補助的な量（<span class="math inline">R(z)</span> と <span class="math inline">W,\Sigma^{-1}W</span> との overlap）を導入：</p>
<p><span class="math display">
\scriptstyle
r(z):=\frac{1}{p}\operatorname{Tr}(\Sigma^{1/2}W^\top(U-zI_p)^{-1}W\Sigma^{1/2}),\quad
s(z):=\frac{1}{p}\operatorname{Tr}(W^\top(U-zI_p)^{-1}W),\quad z\in\mathbb{C}
</span></p>
<div title="[定理3.1 @Bonnaire+2025]">
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong><span class="citation" data-cites="Bonnaire+2025">(定理3.1 <a href="#/参考文献" role="doc-biblioref" onclick="">Bonnaire et al., 2025</a>)</span></strong></p>
</div>
<div class="callout-content">
<p><span class="math inline">q(z)=\operatorname{Tr}(R(z))/p</span> はランダム行列極限 <span class="math inline">d,p,n\to\infty</span> で大数の法則が性質するとする．このとき，後述の仮定の下で，<span class="math inline">q</span> は次の鞍点方程式の解が与える：</p>
<p><span class="math display">
\begin{align*}
\scriptstyle
\widehat{s}(q)&amp;\scriptstyle=b^2_t\psi_p+\frac{1}{q},\quad\hat{r}(r,q)=\frac{\psi_pa_t^2e^{-2t}}{1+\frac{a_t^2e^{-2t}\psi_p}{\psi_n}r+\frac{\psi_pv_t^2}{\psi_n}q},\quad
s(z)=\int\frac{1}{\hat{s}(q)+\lambda\hat{r}(r,q)}\rho_\Sigma(d\lambda),\\
\scriptstyle r(z)&amp;\scriptstyle=\int\frac{\lambda}{\hat{s}(q)+\lambda\hat{r}(r,q)}\,\rho_\Sigma(d\lambda),\quad\psi_p(s_t^2-z)+\frac{\psi_pv_t^2}{\scriptscriptstyle 1+\frac{a_t^2e^{-2t}\psi_p}{\psi_n}r+\frac{\psi_pv_t^2}{\psi_n}q}+\frac{1-\psi_p}{q}-\frac{s}{q^2}=0.
\end{align*}
</span></p>
</div>
</div>
</div>
</div>

<aside><div>
<p><span class="math inline">\sigma=\mathrm{id}_{\mathbb{R}},P_x=N_d(0,I_d)</span> のとき，<span class="math inline">r=s</span> で <span class="math inline">s,\hat{s}</span> を消去すると <span class="citation" data-cites="Marčenko-Pastur1967">(<a href="#/参考文献" role="doc-biblioref" onclick="">Marčenko and Pastur, 1967</a>)</span> の自己無撞着方程式を得る： <span class="math display">
q(z)=\frac{1}{-z+\frac{\psi_p}{1+q(z)}}.
</span></p>
</div></aside></section>
<section id="sec-GEP" class="slide level2" data-number="3.7">
<h2><span class="header-section-number">3.7</span> Gaussian Equivalence Principle</h2>
<div title="経験スペクトル極限の構造定理 [定理1.4 @Peche2019]">
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>経験スペクトル極限の構造定理 <span class="citation" data-cites="Peche2019">(定理1.4 <a href="#/参考文献" role="doc-biblioref" onclick="">Péché, 2019</a>)</span></strong></p>
</div>
<div class="callout-content">
<p>ランダム行列 <span class="math inline">X\in\mathbb{R}^{d\times n},W\in\mathbb{R}^{p\times d}</span> の成分はそれぞれ i.i.d. で，指数より軽い裾を持ち，<span class="math inline">(0,1)</span> に正規化されているとする． <span class="math inline">f:\mathbb{R}\to\mathbb{R}</span> が Schwartz 急減少関数ならば， 次の２つの行列 <span class="math inline">M,M'</span> の経験スペクトル分布は漸近同等： <span class="math display">
M:=\frac{1}{d}f^{\otimes(p\times n)}\left(\frac{WX}{\sqrt{d}}\right)f^{\otimes(p\times n)}\left(\frac{WX}{\sqrt{d}}\right)^\top
</span> <span class="math display">
\scriptstyle
M':=\frac{1}{n}\left(\sqrt{\theta_2(f)}\frac{WX}{\sqrt{d}}+\sqrt{\theta_1(f)-\theta_2(f)}Z\right)\left(\sqrt{\theta_2(f)}\frac{WX}{\sqrt{d}}+\sqrt{\theta_1(f)-\theta_2(f)}Z\right)^\top
</span> ただし，<span class="math inline">Z\in\mathbb{R}^{p\times n}</span> は Gaussian random matrix で， <span class="math display">
\theta_1(f)=\operatorname{E}[f(Z_{11})^2],\quad\theta_2(f)=\operatorname{E}[f'(Z_{11})]^2=\operatorname{E}[Z_{11}f(Z_{11})]^2.
</span></p>
</div>
</div>
</div>
</div>

<aside><div>
<p><span class="math inline">\sqrt{\theta_2(f)}</span> は <span class="math inline">f(Z_{11})</span> を <span class="math inline">Z_{11}</span> で線型回帰した際の係数の絶対値，<span class="math inline">\theta_1(f)-\theta_2(f)</span> は残差と見れる．</p>
</div></aside></section>
<section id="gaussian-equivalence-principle" class="slide level2 unnumbered unlisted scrollable" data-visibility="uncounted">
<h2>3.7 Gaussian Equivalence Principle</h2>
<div title="[補題C.1 @Bonnaire+2025]">
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong><span class="citation" data-cites="Bonnaire+2025">(補題C.1 <a href="#/参考文献" role="doc-biblioref" onclick="">Bonnaire et al., 2025</a>)</span></strong></p>
</div>
<div class="callout-content">
<ol type="1">
<li><span class="math inline">\sigma\in L^2_0(\gamma),\;\gamma:=N_1(0,1)</span> である．</li>
<li>データ分布 <span class="math inline">P_x</span> は sub-Gaussian．</li>
<li><span class="math inline">P_x</span> の共分散行列 <span class="math inline">\Sigma^d:=\operatorname{E}[XX^\top]</span> は <span class="math inline">d\to\infty</span> の極限で有界な固有値を持ち，経験スペクトル分布の極限は密度 <span class="math inline">\rho_\Sigma</span> を持つ絶対連続分布になる．</li>
</ol>
<p>上の３条件の下で，次の２つの行列 <span class="math inline">U,U'</span> の経験スペクトル分布は漸近同等：</p>
<p><span class="math display">
\begin{align*}
  \scriptstyle
  U&amp;\scriptstyle:=\frac{1}{n}\sum_{\nu=1}^n\operatorname{E}_\xi\left[\sigma^{\otimes p}\left(\frac{Wx^\nu_t(\xi)}{\sqrt{d}}\right)\sigma^{\otimes p}\left(\frac{Wx^\nu_t(\xi)}{\sqrt{d}}\right)^\top\right]\\
  \scriptstyle U'&amp;\scriptstyle:=\frac{GG^\top}{n}+b_t^2\frac{WW^\top}{d}+s_t^2I_p,\qquad G:=e^{-t}a_t\frac{W}{\sqrt{d}}X'+v_t\Omega
\end{align*}
</span></p>
<p><span class="math inline">X'</span> は <span class="math inline">X</span> の独立 copy，<span class="math inline">\Omega</span> は独立な Gaussian random matrix．</p>
</div>
</div>
</div>
</div>
</section>
<section id="gaussian-equivalence-principle-1" class="slide level2 unnumbered unlisted" data-visibility="uncounted">
<h2>3.7 Gaussian Equivalence Principle</h2>
<p><span class="math display">
\begin{align*}
  U&amp;:=\frac{1}{n}\sum_{\nu=1}^n\operatorname{E}_\xi\left[\sigma^{\otimes p}\left(\frac{Wx^\nu_t(\xi)}{\sqrt{d}}\right)\sigma^{\otimes p}\left(\frac{Wx^\nu_t(\xi)}{\sqrt{d}}\right)^\top\right]\\
  U'&amp;:=\frac{GG^\top}{n}+b_t^2\frac{WW^\top}{d}+s_t^2I_p,\qquad G:=e^{-t}a_t\frac{W}{\sqrt{d}}X'+v_t\Omega
\end{align*}
</span></p>
<p><span class="math inline">\sigma^2_x:=\operatorname{Tr}(\Sigma)/d,\;f_t(\xi,\eta):=\sigma(e^{-t}\sigma_x\eta+\sqrt{\Delta_t}\xi)\;\xi,\eta,\zeta\sim\operatorname{N}_1(0,1)</span> とすると <span class="math display">
\begin{align*}
  b_t&amp;:=\operatorname{E}[\xi f_t(\xi,\eta)],\qquad a_t:=\operatorname{E}\left[\frac{\eta}{e^{-t}\sigma_x} f_t(\xi,\eta)\right],\\
  v_t^2&amp;:=\operatorname{E}[f_t(\xi,\eta)f_t(\xi,\zeta)]-a_t^2e^{-2t}\sigma^2_x,\\
  s^2_t&amp;:=\operatorname{E}[\sigma(\Gamma_t\eta)^2]-a_t^2e^{-2t}\sigma^2_x-v_t^2-b_t^2,\qquad\Gamma_t:=e^{-2t}\sigma^2_x+\Delta_t.
\end{align*}
</span></p>
</section>
<section id="sec-proof" class="slide level2 scrollable" data-number="3.8">
<h2><span class="header-section-number">3.8</span> <span class="math inline">q(z)=\operatorname{Tr}(R(z))/p</span> の極限の計算</h2>
<div class="columns" style="text-align: center;">
<div class="column" style="width:50%;">
<div style="text-align: left;" title="Replica Trick [[@Bonnaire+2025]]{.tiny-letter}">
<div class="callout callout-important no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Replica Trick <span class="tiny-letter"><span class="citation" data-cites="Bonnaire+2025">(<a href="#/参考文献" role="doc-biblioref" onclick="">Bonnaire et al., 2025</a>)</span></span></strong></p>
</div>
<div class="callout-content">
<p><span class="math inline">\frac{d\det(X)}{dX}\scriptstyle=\operatorname{Tr}(X^{-1})\det(X)</span> より，<sup>1</sup> <span class="math display">
\begin{align*}
  q(z)%&amp;=-\frac{1}{p}\pp{}{z}\log\det(U-zI_p)\\
  &amp;=\frac{2}{p}\frac{\partial }{\partial z}\log\left(\det(U-zI_p)\right)^{-\frac{1}{2}}\\
  &amp;=2\frac{\partial }{\partial z}\lim_{p\to\infty}\frac{\operatorname{E}[\log Z(z)]}{p}\\
  Z(z)&amp;:=\frac{1}{(2\pi)^{\frac{p}{2}}}\int_{\mathbb{R}^p}e^{-\frac{\phi^\top(U-zI_p)\phi}{2}}\,d\phi
\end{align*}
</span> 次の関係を用いて計算する： <span class="math display">
\log Z=\lim_{n\to\infty}\frac{Z^n-1}{n}.
</span></p>
</div>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div style="text-align: left;" title="Linearization [[@George+2025]]{.tiny-letter}">
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Linearization <span class="tiny-letter"><span class="citation" data-cites="George+2025">(<a href="#/参考文献" role="doc-biblioref" onclick="">George et al., 2025</a>)</span></span></strong></p>
</div>
<div class="callout-content">
<p><span class="math inline">U=FF^\top/n</span> と表せたとき， <span class="math display">
\begin{align*}
  L(z)&amp;:=\begin{pmatrix}
   -z_pI&amp;F^\top/\sqrt{n}\\
   F/\sqrt{n}&amp;I_n
   \end{pmatrix}\\
   &amp;\scriptstyle=B_0\otimes I+E_{12}\otimes X+E_{21}\otimes X^*
\end{align*}
</span> という大きい行列 <span class="math inline">L(z)^{-1}</span> の一部 <span class="math display">
(L(z)^{-1})_{11}=-(U+zI_p)^{-1}
</span> に <span class="math inline">R(z)</span> が入る．この<strong>直線束 (linear pencil) 表現</strong>の <span class="math inline">\operatorname{Tr}(L(z)^{-1})</span> の計算が自由確率論 (free CLT) で出来る．</p>
</div>
</div>
</div>
</div>
</div></div>
<!--
### 証明

::: {.callout-tip title="[定理3.1 @Bonnaire+2025]" icon="false" style="margin-bottom: 0em; !important"}

$q(z)=\Tr(R(z))/p$ の極限は，次の鞍点方程式の解が与える：

$$
\begin{align*}
\scriptstyle
\wh{s}(q)&\scriptstyle=b^2_t\psi_p+\frac{1}{q},\quad\hat{r}(r,q)=\frac{\psi_pa_t^2e^{-2t}}{1+\frac{a_t^2e^{-2t}\psi_p}{\psi_n}r+\frac{\psi_pv_t^2}{\psi_n}q},\quad
s(z)=\int\frac{1}{\hat{s}(q)+\lambda\hat{r}(r,q)}\rho_\Sigma(d\lambda),\\
\scriptstyle r(z)&\scriptstyle=\int\frac{\lambda}{\hat{s}(q)+\lambda\hat{r}(r,q)}\,\rho_\Sigma(d\lambda),\quad\psi_p(s_t^2-z)+\frac{\psi_pv_t^2}{\scriptscriptstyle 1+\frac{a_t^2e^{-2t}\psi_p}{\psi_n}r+\frac{\psi_pv_t^2}{\psi_n}q}+\frac{1-\psi_p}{q}-\frac{s}{q^2}=0.
\end{align*}
$$

:::

行列微分則 $\frac{d\det(X)}{dX}=\Tr(X^{-1})\det(X)$ [@Magnus-Neudecker2019 p.201] から，
$$
q(z)=-\frac{1}{p}\pp{}{z}\log\det(U-zI_p)=\frac{2}{p}\pp{}{z}\log\paren{\det(U-zI_p)}^{-\frac{1}{2}}
$$
-->
<aside><ol class="aside-footnotes"><li id="fn1"><p><span class="citation" data-cites="Magnus-Neudecker2019">(<a href="#/参考文献" role="doc-biblioref" onclick="">Magnus and Neudecker, 2019, p. 201</a>)</span></p></li></ol></aside></section>
<section id="sec-two-bulk" class="slide level2 scrollable" data-number="3.9">
<h2><span class="header-section-number">3.9</span> 主な系：スペクトルの two-bulk 構造</h2>
<div title="[定理3.2 @Bonnaire+2025]" style="margin-bottom: 0em; !important">
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong><span class="citation" data-cites="Bonnaire+2025">(定理3.2 <a href="#/参考文献" role="doc-biblioref" onclick="">Bonnaire et al., 2025</a>)</span></strong></p>
</div>
<div class="callout-content">
<p><span class="math inline">U</span> のランダム行列極限での極限固有値分布 <span class="math inline">\rho</span> は次の表示を持つ：<sup>1</sup></p>
<ol type="1">
<li>過剰パラメータ領域：<span class="math inline">\psi_p&gt;\psi_n\gg1</span> のとき</li>
</ol>
<p><span class="math display">
  \rho(\lambda)=\left(1-\frac{1+\psi_n}{\psi_p}\right)\delta_{\{s_t^2\}}(\lambda)+\frac{\psi_n}{\psi_p}\rho_1(\lambda)+\frac{1}{\psi_p}\mu_{\widetilde{U}}(\lambda).
  </span></p>
<ol start="2" type="1">
<li>不足パラメータ領域：<span class="math inline">\psi_n&gt;\psi_p\gg1</span> のとき</li>
</ol>
<p><span class="math display">
  \rho(\lambda)=\left(1-\frac{1}{\psi_p}\right)\rho_1(\lambda)+\frac{1}{\psi_p}\mu_{\widetilde{U}}(\lambda).
  </span></p>
<p>ただし，<span class="math inline">\rho_1</span> とは……（続く）</p>
</div>
</div>
</div>
</div>
<p>証明は <span class="math inline">\psi_n,\psi_p\to\infty</span> の近似の下で固定点方程式を解くことによる．</p>
<aside><ol class="aside-footnotes"><li id="fn2"><p>平均 <span class="math inline">\widetilde{U}:=\operatorname{E}[U]</span> の経験スペクトル分布の極限を <span class="math inline">\mu_{\widetilde{U}}</span> とした．</p></li></ol></aside></section>
<section id="主な系スペクトルの-two-bulk-構造" class="slide level2 unnumbered unlisted" data-visibility="uncounted">
<h2>3.9 主な系：スペクトルの two-bulk 構造</h2>
<div title="過剰パラメータ領域：$\psi_p>\psi_n\gg1$ のとき" style="margin-bottom: 0em; !important">
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>過剰パラメータ領域：<span class="math inline">\psi_p&gt;\psi_n\gg1</span> のとき</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">
\rho(\lambda)=\left(1-\frac{1+\psi_n}{\psi_p}\right)\delta_{\{s_t^2\}}(\lambda)+\frac{\psi_n}{\psi_p}\rho_1(\lambda)+\frac{1}{\psi_p}\mu_{\widetilde{U}}(\lambda).
</span></p>
<ul>
<li><span class="math inline">s_t^2</span> に属する固有ベクトルは <span class="math inline">\mathrm{Ker}\;(A_\tau)</span> に入り，訓練／テスト誤差の値を変えない．</li>
<li><span class="math inline">\rho_1</span> は atom を持たず， <span class="math display">
\mathrm{supp}\;(\rho_1)=\left[s_t^2+v_t^2\left(1-\sqrt{\psi_p/\psi_n}\right)^2,s_t^2+v_t^2\left(1+\sqrt{\psi_p/\psi_n}\right)^2\right]
</span></li>
<li><span class="math inline">\mu_{\widetilde{U}}</span> は atom を持つかもしれないが，絶対連続部分は <span class="math display">
\inf\mathrm{supp}\;(\mu_{\widetilde{U}})=O(\psi_p)\qquad(\psi_n,\psi_p\to\infty).
</span></li>
</ul>
</div>
</div>
</div>
</div>
<p>特に，<span class="math inline">\psi_p/\psi_n\to\infty</span> も仮定すると，<span class="math inline">\sup\mathrm{supp}\;(\rho_1)=O(\psi_p/\psi_n)</span>．</p>
</section>
<section id="主な系スペクトルの-two-bulk-構造-1" class="slide level2 unnumbered unlisted" data-visibility="uncounted">
<h2>3.9 主な系：スペクトルの two-bulk 構造</h2>
<div title="過剰パラメータ領域：$\psi_n,\psi_p/\psi_n\to\infty$ のとき" style="margin-bottom: 0em; !important">
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>過剰パラメータ領域：<span class="math inline">\psi_n,\psi_p/\psi_n\to\infty</span> のとき</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">
\rho(\lambda)=\left(1-\frac{1+\psi_n}{\psi_p}\right)\delta_{\{s_t^2\}}(\lambda)+\frac{\psi_n}{\psi_p}\rho_1(\lambda)+\frac{1}{\psi_p}\mu_{\widetilde{U}}(\lambda).
</span> <span class="math display">
\sup\mathrm{supp}\;(\textcolor{#928EC3}{\rho_1})=O(\psi_p/\psi_n),\qquad\inf\mathrm{supp}\;(\textcolor{#E69252}{\mu_{\widetilde{U}}})=O(\psi_p/\psi_n\cdot\psi_n).
</span></p>
</div>
</div>
</div>
</div>
<div class="columns" style="text-align: center;">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Bonnaire2025/Spectrum.png" style="width:70.0%"></p>
<figcaption><span class="math inline">d=10^2,\psi_p=64,\psi_n=8,t=0.01,\rho_\Sigma=\delta_1</span> の場合．</figcaption>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Bonnaire2025/Spectrum2.png" style="width:70.0%"></p>
<figcaption><span class="math inline">\rho_\Sigma=(\delta_{1/2}+\delta_{3/2})/2</span> の場合．</figcaption>
</figure>
</div>
</div></div>
<p><span class="math inline">\rho_1</span> は <span class="math inline">\sigma^2_x:=\operatorname{Tr}(\Sigma)/d</span> を通じてしかデータに依存しないので，２つの図で変わらない．</p>
</section>
<section id="sec-dynamics" class="slide level2" data-number="3.10">
<h2><span class="header-section-number">3.10</span> 過剰パラメータ領域での訓練ダイナミクス</h2>
<p><span class="math display">
\tau_{\text{gen}}:=\frac{\psi_p}{\Delta_t}\inf\mathrm{supp}\;(\textcolor{#E69252}{\mu_{\widetilde{U}}})=O(1/\Delta_t).
</span> <span class="math display">
\tau_{\text{mem}}:=\frac{\psi_p}{\Delta_t}\inf\mathrm{supp}\;(\textcolor{#928EC3}{\rho_1})=O(\psi_n/\Delta_t).
</span> <span class="math inline">t&gt;0</span> が大きく，<span class="math inline">n</span> が大きいほど <span class="math inline">\tau_{\text{mem}}</span> が大きい．</p>
<div class="columns" style="text-align: center;">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Bonnaire2025/Error_score_draft.png" style="width:70.0%"></p>
<figcaption>スコア誤差 <span class="math inline">\psi_n=4,8,16,32,t=0.1</span>．</figcaption>
</figure>
</div>
<p><span class="math display">
\mathcal{E}_{\text{score}}:=\frac{1}{d}\operatorname{E}_x\biggl[\|s_A(x)-\nabla\log P_x\|^2\biggr]
</span></p>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Bonnaire2025/test_train_inset_draft.png" style="width:70.0%"></p>
<figcaption>訓練誤差（実線）とテスト誤差（点線）</figcaption>
</figure>
</div>
<p><span class="math inline">\tau_{\text{gen}}</span> までの速いスケールでは，汎化ギャプ <span class="math inline">\mathcal{L}_{\text{gen}}=\mathcal{L}_{\text{test}}-\mathcal{L}_{\text{train}}</span> が消える．</p>
</div></div>
</section>
<section id="補足経験誤差最小化解-tautoinfty-の汎化誤差" class="slide level2" data-number="3.11">
<h2><span class="header-section-number">3.11</span> 補足：経験誤差最小化解 <span class="math inline">\tau\to\infty</span> の汎化誤差</h2>
<p>実は収束先も <span class="math inline">n</span> が大きいほど汎化ギャップ <span class="math inline">\mathcal{L}_{\text{gen}}=\mathcal{L}_{\text{test}}-\mathcal{L}_{\text{train}}</span> は低くなる <span class="citation" data-cites="George+2025">(<a href="#/参考文献" role="doc-biblioref" onclick="">George et al., 2025</a>)</span>．</p>
<p>ただし，パラメータ不足領域 <span class="math inline">\psi_p&lt;\psi_n</span> に侵入した場合は，時間スケールの分離は見られず，architectural regularization により <span class="math inline">\mathcal{L}_{\text{gen}}=\mathcal{L}_{\text{test}}-\mathcal{L}_{\text{train}}</span> はさらに下がる．</p>

<img data-src="Bonnaire2025/George.png" class="r-stretch quarto-figure-center"><p class="caption"><span class="math inline">t=0.01</span>．縦の点線は <span class="math inline">\psi_n=\psi_p</span> <span class="citation" data-cites="George+2025">(Figure 5 <a href="#/参考文献" role="doc-biblioref" onclick="">George et al., 2025</a>)</span>．<span class="math inline">\tau\to\infty</span> の場合に対応．</p></section></section>
<section>
<section id="まとめ" class="title-slide slide level1 center" data-number="4">
<h1><span class="header-section-number">4</span> まとめ</h1>

</section>
<section id="学習ダイナミクスのスケール分離" class="slide level2 scrollable" data-number="4.1">
<h2><span class="header-section-number">4.1</span> 学習ダイナミクスのスケール分離</h2>
<ol type="1">
<li>学習ダイナミクスのスケール分離を，勾配流の緩和時間 <span class="math display">
  \tau^{-1}=\psi_p\lambda_{\text{min}}/\Delta_t
  </span> の解析から示した．</li>
<li><span class="math inline">U</span> の固有値分布 <span class="math inline">\rho(d\lambda)</span> が次を満たす <span class="math inline">d\to\infty</span> 極限でスケール分離する： <span class="math display">
  \psi_p:=\frac{p}{d}\to\infty,\quad\psi_n:=\frac{n}{d}\to\infty,\quad\frac{\psi_p}{\psi_n}\to\infty.
  </span></li>
<li>速いスケールは真のデータ分布のみに依存し，<span class="math inline">\mathcal{L}_{\text{gen}}=\mathcal{L}_{\text{test}}-\mathcal{L}_{\text{train}}</span> が消える</li>
<li>遅いスケールは <span class="math inline">\tau_{\text{mem}}=O(n)</span> のオーダーで，データ分布の <span class="math inline">\sigma_x^2:=\operatorname{Tr}(\Sigma)/d</span> のみに依存する．</li>
<li><span class="math inline">n</span> も同時に大きくしていくと，経験リスク最小解 <span class="math inline">\tau\to\infty</span> での <span class="math inline">\mathcal{L}_{\text{gen}}</span> は下がる</li>
</ol>
</section>
<section id="なぜ学習ダイナミクスにスケール分離が見られるのか" class="slide level2 scrollable" data-number="4.2">
<h2><span class="header-section-number">4.2</span> なぜ学習ダイナミクスにスケール分離が見られるのか？</h2>
<div title="なぜスケール分離が起こるのか？">
<div class="callout callout-important no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>なぜスケール分離が起こるのか？</strong></p>
</div>
<div class="callout-content">
<p><span class="math inline">\tau_{\text{mem}}=O(n)</span> というのは，NN が経験スコアの高周波成分を学習するのにかかる時間が <span class="math inline">O(n)</span> でスケールするのが見えている？</p>
</div>
</div>
</div>
</div>
<ul>
<li>NN の spectral bias <span class="citation" data-cites="Rahaman+2019">(<a href="#/参考文献" role="doc-biblioref" onclick="">Rahaman et al., 2019</a>)</span>：NN が関数を学習する際，低周波成分 → 高周波成分の順に学んでいく
<ul>
<li>→ early stopping と併せると「低周波成分だけを学んでいることが汎化の主な理由である」という仮説がたつ．</li>
</ul></li>
<li>拡散モデルは訓練データに依らず，高周波成分を縮小して学習する <span class="citation" data-cites="Kadkhodaie+2024">(<a href="#/参考文献" role="doc-biblioref" onclick="">Kadkhodaie et al., 2024</a>)</span><sup>1</sup></li>
</ul>
<aside><ol class="aside-footnotes"><li id="fn3"><p><span class="citation" data-cites="Kadkhodaie+2024">(<a href="#/参考文献" role="doc-biblioref" onclick="">Kadkhodaie et al., 2024</a>)</span> は denoiser を直接 MSE で学習していることに注意．</p></li></ol></aside></section>
<section id="附言" class="slide level2" data-number="4.3">
<h2><span class="header-section-number">4.3</span> 附言</h2>
<ul>
<li>GD ダイナミクスだけ？ SGD, Adam でも普遍的に観察されるし，説明したい．</li>
<li>conditional generation でも成り立つように思われ，その場合 <span class="math inline">n,p,d</span> 以外の変数が出てくる？</li>
<li><span class="math inline">P_x</span> の裾が重い場合はどうなる？部分多様体上に台を持つ場合は？</li>
</ul>
</section></section>
<section id="参考文献" class="title-slide slide level1 unnumbered unlisted smaller scrollable" data-visibility="uncounted">
<h1>参考文献</h1>


<div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-Anderson+2011" class="csl-entry" role="listitem">
Anderson, G. W., Guionnet, A., and Zeitouni, O. (2011). <em><a href="https://doi.org/10.1017/CBO9780511801334">An introduction to random matrices</a></em>,Vol. 118. Cambridge University Press.
</div>
<div id="ref-Biroli+2024" class="csl-entry" role="listitem">
Biroli, G., Bonnaire, T., Bortoli, V. de, and Mézard, M. (2024). <a href="https://doi.org/10.1038/s41467-024-54281-3">Dynamical regimes of diffusion models</a>. <em>Nature Communications</em>, <em>15</em>(1), 9957.
</div>
<div id="ref-Bonnaire+2025" class="csl-entry" role="listitem">
Bonnaire, T., Urfin, R., Biroli, G., and Mezard, M. (2025). <a href="https://openreview.net/forum?id=BSZqpqgqM0">Why diffusion models don<span>’</span>t memorize: The role of implicit dynamical regularization in training</a>. In <em>The thirty-ninth annual conference on neural information processing systems</em>.
</div>
<div id="ref-Conway2007" class="csl-entry" role="listitem">
Conway, J. B. (2007). <em>A course in functional analysis</em>. Springer New York.
</div>
<div id="ref-Efron2011" class="csl-entry" role="listitem">
Efron, B. (2011). <a href="https://doi.org/10.1198/jasa.2011.tm11181">Tweedie’s formula and selection bias</a>. <em>Journal of the American Statistical Association</em>, <em>106</em>(496), 1602–1614.
</div>
<div id="ref-George+2025" class="csl-entry" role="listitem">
George, A. J., Veiga, R., and Macris, N. (2025). <a href="https://arxiv.org/abs/2502.00336">Denoising score matching with random features: Insights on diffusion models from precise learning curves</a>.
</div>
<div id="ref-Ho+2020" class="csl-entry" role="listitem">
Ho, J., Jain, A., and Abbeel, P. (2020). <a href="https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html"><span>Denoising Diffusion Probabilistic Models</span></a>. In <em>Advances in neural information processing systems</em>,Vol. 33.
</div>
<div id="ref-Kadkhodaie+2024" class="csl-entry" role="listitem">
Kadkhodaie, Z., Guth, F., Simoncelli, E. P., and Mallat, S. (2024). <a href="https://openreview.net/forum?id=ANvmVS2Yr0">Generalization in diffusion models arises from geometry-adaptive harmonic representations</a>. In <em>The twelfth international conference on learning representations</em>.
</div>
<div id="ref-Magnus-Neudecker2019" class="csl-entry" role="listitem">
Magnus, J. R., and Neudecker, H. (2019). <em><a href="https://doi.org/10.1002/9781119541219">Matrix differential calculus with applications in statistics and econometrics</a></em>. John Wiley &amp; Sons.
</div>
<div id="ref-Marčenko-Pastur1967" class="csl-entry" role="listitem">
Marčenko, V. A., and Pastur, L. A. (1967). <a href="https://doi.org/10.1070/SM1967v001n04ABEH001994">DISTRIBUTION OF EIGENVALUES FOR SOME SETS OF RANDOM MATRICES</a>. <em>Mathematics of the USSR-Sbornik</em>, <em>1</em>(4), 457.
</div>
<div id="ref-Peche2019" class="csl-entry" role="listitem">
Péché, S. (2019). <a href="https://doi.org/10.1214/19-ECP262"><span class="nocase">A note on the Pennington-Worah distribution</span></a>. <em>Electronic Communications in Probability</em>, <em>24</em>(none), 1–7.
</div>
<div id="ref-Rahaman+2019" class="csl-entry" role="listitem">
Rahaman, N., Baratin, A., Arpit, D., Draxler, F., Lin, M., Hamprecht, F., … Courville, A. (2019). <a href="https://proceedings.mlr.press/v97/rahaman19a.html">On the spectral bias of neural networks</a>. In K. Chaudhuri and R. Salakhutdinov, editors, <em>Proceedings of the 36th international conference on machine learning</em>,Vol. 97, pages 5301–5310. PMLR.
</div>
</div>
</section>


    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="../../../../../../assets/profile.jpg" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="../../../posts/2025/DiffusionModels/Bonnaire2025Slides.html">Why Diffusion Models Don’t Memorize</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-pointer/pointer.js"></script>
  <script src="../../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":false},
'pointer': {"key":"q","color":"red","pointerSize":16,"alwaysVisible":false},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 5.0e-2,

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, RevealPointer, QuartoSupport,

          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/162348\.github\.io\/");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>