<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.34">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="司馬博文">

<title>統計的学習理論１ – Hirofumi Shiba</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../assets/Shiba2.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-5082c1b048a9243e4e9bba654cb201bf.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-0f5af7d47a5002a4b3beacd379d1e7cd.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "?",
    "H"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-36GX2G6GLL"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-36GX2G6GLL', { 'anonymize_ip': true});
</script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Zen+Kurenaido&amp;display=swap" rel="stylesheet">

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=BIZ+UDPGothic&amp;display=swap" rel="stylesheet">

<style>
  h1, .title, .description, .subtitle {
    font-family: "Zen Kurenaido", sans-serif !important;
  }
</style>

<!-- <style>
  .menu-text {
      font-family: "Gill Sans", sans-serif !important;
      font-weight: 400;
      font-style: normal;
  }
  .navbar-title {
      font-family: "Gill Sans", sans-serif !important;
      font-weight: 400;
      font-style: normal;
  }
</style> -->

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../assets/styles.css">
<meta property="og:title" content="統計的学習理論１ – Hirofumi Shiba">
<meta property="og:description" content="統計的機械学習には，「汎化」に価値を置く独特の決定理論的な枠組みが存在する．特に，第一義的には経験リスクを最小化すること，より正確には経験リスク最小化と正則化とをバランスよく目指す「構造的リスク最小化」が広く機械学習のモデリング指針として採用されている．">
<meta property="og:image" content="https://162348.github.io/posts/2024/AI/Theory.png">
<meta property="og:site_name" content="Hirofumi Shiba">
<meta property="og:image:height" content="162">
<meta property="og:image:width" content="857">
<meta name="twitter:title" content="統計的学習理論１ – Hirofumi Shiba">
<meta name="twitter:description" content="統計的機械学習には，「汎化」に価値を置く独特の決定理論的な枠組みが存在する．特に，第一義的には経験リスクを最小化すること，より正確には経験リスク最小化と正則化とをバランスよく目指す「構造的リスク最小化」が広く機械学習のモデリング指針として採用されている．">
<meta name="twitter:image" content="https://162348.github.io/posts/2024/AI/Theory.png">
<meta name="twitter:creator" content="@ano2math5">
<meta name="twitter:image-height" content="162">
<meta name="twitter:image-width" content="857">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Hirofumi Shiba</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-notes" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Notes</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-notes">    
        <li>
    <a class="dropdown-item" href="../../../static/English.html">
 <span class="dropdown-text">English Notes</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../blog.html">
 <span class="dropdown-text">ノート (Japanese)</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Materials.html"> 
<span class="menu-text">Materials</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Slides.html"> 
<span class="menu-text">Slides</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Software.html"> 
<span class="menu-text">Software</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
    <a href="https://github.com/162348/162348.github.io/" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">統計的学習理論１</h1>
            <p class="subtitle lead">PAC 学習</p>
                                <div class="quarto-categories">
                <div class="quarto-category">Foundation</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>司馬博文 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">1/10/2024</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">3/03/2024</p>
      </div>
    </div>
      
    </div>
    
  <div>
    <div class="abstract">
      <div class="block-title">概要</div>
      統計的機械学習には，「汎化」に価値を置く独特の決定理論的な枠組みが存在する．特に，第一義的には経験リスクを最小化すること，より正確には経験リスク最小化と正則化とをバランスよく目指す「構造的リスク最小化」が広く機械学習のモデリング指針として採用されている．
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">目次</h2>
   
  <ul>
  <li><a href="#機械学習の形式化" id="toc-機械学習の形式化" class="nav-link active" data-scroll-target="#機械学習の形式化"><span class="header-section-number">1</span> 機械学習の形式化</a>
  <ul class="collapse">
  <li><a href="#記法と用語" id="toc-記法と用語" class="nav-link" data-scroll-target="#記法と用語"><span class="header-section-number">1.1</span> 記法と用語</a></li>
  <li><a href="#汎化ギャップ" id="toc-汎化ギャップ" class="nav-link" data-scroll-target="#汎化ギャップ"><span class="header-section-number">1.2</span> 汎化ギャップ</a></li>
  <li><a href="#経験リスク最小化の問題" id="toc-経験リスク最小化の問題" class="nav-link" data-scroll-target="#経験リスク最小化の問題"><span class="header-section-number">1.3</span> 経験リスク最小化の問題</a></li>
  <li><a href="#pac-学習" id="toc-pac-学習" class="nav-link" data-scroll-target="#pac-学習"><span class="header-section-number">1.4</span> PAC 学習</a></li>
  <li><a href="#thm-pac-learnable-の証明" id="toc-thm-pac-learnable-の証明" class="nav-link" data-scroll-target="#thm-pac-learnable-の証明"><span class="header-section-number">1.5</span> 定理&nbsp;1 の証明</a></li>
  <li><a href="#pac-学習の基本定理" id="toc-pac-学習の基本定理" class="nav-link" data-scroll-target="#pac-学習の基本定理"><span class="header-section-number">1.6</span> PAC 学習の基本定理</a></li>
  <li><a href="#bayes-ルール" id="toc-bayes-ルール" class="nav-link" data-scroll-target="#bayes-ルール"><span class="header-section-number">1.7</span> Bayes ルール</a></li>
  </ul></li>
  <li><a href="#統計的決定理論" id="toc-統計的決定理論" class="nav-link" data-scroll-target="#統計的決定理論"><span class="header-section-number">2</span> 統計的決定理論</a>
  <ul class="collapse">
  <li><a href="#枠組み" id="toc-枠組み" class="nav-link" data-scroll-target="#枠組み"><span class="header-section-number">2.1</span> 枠組み</a></li>
  <li><a href="#一様最強力検定" id="toc-一様最強力検定" class="nav-link" data-scroll-target="#一様最強力検定"><span class="header-section-number">2.2</span> 一様最強力検定</a></li>
  </ul></li>
  <li><a href="#pac-bound" id="toc-pac-bound" class="nav-link" data-scroll-target="#pac-bound"><span class="header-section-number">3</span> PAC bound</a>
  <ul class="collapse">
  <li><a href="#定理" id="toc-定理" class="nav-link" data-scroll-target="#定理"><span class="header-section-number">3.1</span> 定理</a></li>
  <li><a href="#bigglwidehatr_nwidehath_n-rwidehath_nbiggr-の評価" id="toc-bigglwidehatr_nwidehath_n-rwidehath_nbiggr-の評価" class="nav-link" data-scroll-target="#bigglwidehatr_nwidehath_n-rwidehath_nbiggr-の評価"><span class="header-section-number">3.2</span> <span class="math inline">\(\biggl|\widehat{R}_n(\widehat{h}_n)-R(\widehat{h}_n)\biggr|\)</span> の評価</a></li>
  <li><a href="#bigglwidehatr_noverlineh-roverlinehbiggr-の評価" id="toc-bigglwidehatr_noverlineh-roverlinehbiggr-の評価" class="nav-link" data-scroll-target="#bigglwidehatr_noverlineh-roverlinehbiggr-の評価"><span class="header-section-number">3.3</span> <span class="math inline">\(\biggl|\widehat{R}_n(\overline{h})-R(\overline{h})\biggr|\)</span> の評価</a></li>
  <li><a href="#定理の一般化" id="toc-定理の一般化" class="nav-link" data-scroll-target="#定理の一般化"><span class="header-section-number">3.4</span> 定理の一般化</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<p>機械学習と統計学に別を設けるならば，いずれもデータから構造を発見することを目標とするとしても，前者は明示的なプログラムを伴わない「自動化」を念頭におくものであると言える．この人間による介入をなるべく少なくしたいという志向が「学習」の名前に表れている．</p>
<p>それ故，機械学習の理論としては，通常の統計的決定理論の枠組みよりも，汎化性能に力点を置いたものとなっている．これを，径数模型の教師あり学習の場合に関して述べる．</p>
<section id="機械学習の形式化" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="機械学習の形式化"><span class="header-section-number">1</span> 機械学習の形式化</h2>
<section id="記法と用語" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="記法と用語"><span class="header-section-number">1.1</span> 記法と用語<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></h3>
<ul>
<li><p>データサイズを <span class="math inline">\(n\in\mathbb{N}^+\)</span> で表す．</p></li>
<li><p>訓練データ (sample) の全体を <span class="math inline">\(S_n=\{z_i\}_{i=1}^n\subset\mathcal{X}\times\mathcal{Y}\)</span> と表す．<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> <span class="math inline">\(\mathcal{X}\)</span> を入力空間，<span class="math inline">\(\mathcal{Y}\)</span> を出力空間と呼ぶ．<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p></li>
<li><p><span class="math inline">\(\mathcal{X},\mathcal{Y}\)</span> はいずれも可測空間とし，可測関数 <span class="math inline">\(h\in\mathcal{L}(\mathcal{X},\mathcal{Y})\)</span> を <strong>推定量</strong>，部分集合 <span class="math inline">\(\mathcal{H}\subset\mathcal{L}(\mathcal{X};\mathcal{Y})\)</span> を <strong>仮説集合</strong> (hypothesis set) という．<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p></li>
<li><p><span class="math inline">\(l(\Delta_\mathcal{Y})=\{0\}\)</span> を満たす関数 <span class="math inline">\(l:\mathcal{Y}^2\to\mathbb{R}_+\)</span> を <strong>損失関数</strong> という．<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p></li>
<li><p>写像 <span class="math inline">\(A:(\mathcal{X}\times\mathcal{Y})^n\to\mathcal{H}\)</span> を（機械学習） <strong>アルゴリズム</strong> または学習者という．</p></li>
</ul>
<p>以降，データはある真の分布 <span class="math inline">\(\mathbb{P}\in\mathcal{P}(\mathcal{X}\times\mathcal{Y})\)</span> に従うものとし，<span class="math inline">\((X,Y)\sim\mathbb{P}\)</span> と表す．サンプル <span class="math inline">\(S_n=\{z_i\}_{i=1}^n\)</span> は <span class="math inline">\((X,Y)\sim\mathbb{P}\)</span> の独立同分布な複製と仮定する．<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="損失関数の例">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
損失関数の例
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><p><span class="math inline">\(l:=1_{\Delta_\mathcal{Y}^\complement}\)</span> は <strong>0-1損失</strong> と呼ばれ，主に分類問題で使われる．これについて，汎化誤差とは，<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> <span class="math display">\[
R(h)=\mathbb{E}[l(h(X),Y)]=\mathbb{P}[h(X)\ne Y]
\]</span></p></li>
<li><p><span class="math inline">\(\mathcal{Y}=\mathbb{R}^d\)</span> とし，<span class="math inline">\(l(y_1,y_2)=\|y_1-y_2\|^2_2\)</span> とした場合を <strong>二乗損失</strong> といい，主に回帰問題の最小二乗法などで用いられる．</p></li>
</ul>
</div>
</div>
</div>
</section>
<section id="汎化ギャップ" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="汎化ギャップ"><span class="header-section-number">1.2</span> 汎化ギャップ</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="(generalization) error, training error^[[@Alquier2024 p.4], [@Mohri+2018 p.10]，[@金森敬文2015 p.7] を参考にした．[@Shalev-Shwartz-Ben-David2014 p.14] でも，generalization error, risk, error，さらには loss のいずれの名前でも呼ぶし，training error と empirical error /risk とも交換可能に使う，としている．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
(generalization) error, training error<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>
</div>
</div>
<div class="callout-body-container callout-body">
<div id="def-loss" class="theorem definition">
<p><span class="theorem-title"><strong>定義 1</strong></span> <span class="math inline">\(l:\mathcal{Y}^2\to\mathbb{R}_+\)</span> を損失関数とする．</p>
<ol type="1">
<li><p>仮説 <span class="math inline">\(h\in\mathcal{H}\)</span> の <strong>（汎化）誤差</strong> または <strong>危険</strong> または <strong>予測損失</strong> とは， <span class="math display">\[
R(h):=\mathbb{E}[l(h(X),Y)]
\]</span> をいう．</p></li>
<li><p>仮説 <span class="math inline">\(h\in\mathcal{H}\)</span> のサンプル <span class="math inline">\(S_n=\{(x_i,y_i)\}_{i=1}^n\)</span> に関する <strong>訓練誤差</strong> または <strong>経験損失</strong> とは， <span class="math display">\[
\widehat{R}_n(h):=\frac{1}{n}\sum_{i=1}^n l(h(x_i),y_i)
\]</span> をいう．</p></li>
<li><p>差 <span class="math inline">\(\widehat{R}_n(h)-R(h)\)</span> を <strong>汎化ギャップ</strong> という．</p></li>
</ol>
</div>
</div>
</div>
<p>アルゴリズム <span class="math inline">\(A\)</span> にとって，汎化誤差は不可知であるが，訓練誤差は計算可能である．データが独立同分布に従うとする場合，経験損失は予測損失の不偏推定量であり，<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> <span class="math inline">\(n\to\infty\)</span> の漸近論もすでに準備が出来ている．</p>
<p>従って，不可知である予測損失の最小化の代わりに，経験損失を最小化する予測器 <span class="math display">\[
\operatorname{ERM}_\mathcal{H}(S_n)\in\operatorname*{argmin}_{h\in\mathcal{H}}R_n(h)
\]</span> を構成すれば良い，という指針があり得る．この枠組みを <strong>経験リスク最小化 (Empirical Risk Minimization)</strong> といい，PAC 学習は，この ERM の枠組みがどれほどの意味で正しいかの定量的な検証になっている．</p>
</section>
<section id="経験リスク最小化の問題" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="経験リスク最小化の問題"><span class="header-section-number">1.3</span> 経験リスク最小化の問題</h3>
<p>ERM は一見，過学習の問題を孕んでいるように思える．</p>
<p>そこで，あらかじめ学習者 <span class="math inline">\(A\)</span> の値域 <span class="math inline">\(\mathcal{H}\subset\mathcal{L}(\mathcal{X};\mathcal{Y})\)</span> を制限することを考える．これを <strong>帰納バイアス</strong> といい，正則化などの方法によって達成される．</p>
<p>しかし，この漸近論が提供してくれない消息は複数ある．</p>
<ol type="1">
<li>機械学習においては，仮説 <span class="math inline">\(h\)</span> 自体がデータから決まる確率変数 <span class="math inline">\(h_{S_n}:\Omega\to\mathcal{H}\)</span> である場合が多い．これを考慮した収束が欲しい．</li>
<li><span class="math inline">\(n\)</span> が有限の場合に非漸近論的消息が欲しい．</li>
</ol>
<p>そこで以降は，アルゴリズム <span class="math inline">\(A:(\mathcal{X}\times\mathcal{Y})^n\to\mathcal{H}\)</span> を通じて，<span class="math inline">\(h_{S_n}:=A(S_n)\)</span> と定まるとし，<span class="math inline">\(h_{S_n}\)</span> を単に <span class="math inline">\(h\)</span> ともかき，これをデータの関数とする．</p>
<p>この下で，<span class="math inline">\(\widehat{R}(h_{S_n})\)</span> と <span class="math inline">\(R(h_{S_n})\)</span> の関係を考える．</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="損失と誤差の区別">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
損失と誤差の区別
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><span class="citation" data-cites="金森敬文2015">(<a href="#ref-金森敬文2015" role="doc-biblioref">金森敬文, 2015, p. 13</a>)</span> では，（決定論的な）仮説 <span class="math inline">\(h\in\mathcal{H}\)</span> に関して，<span class="math inline">\(R(h)\)</span> を損失，データから決まる仮説 <span class="math inline">\(h_{S_n}=A(S_n)\)</span> に関して，<span class="math inline">\(\operatorname{E}[R(h_{S_n})]\)</span> をリスクと呼び分けている．</p>
<p>損失のうち，特に <strong>0-1損失</strong> <span class="math display">\[
l=1_{\Delta_\mathcal{Y}^\complement}
\]</span></p>
<p>に関するものを誤差といい，この２語は殆ど交換可能な形で使う．その期待値をリスクと言う，という使い分けは一つ筋が通りそうである．</p>
<p>ただし，<span class="citation" data-cites="Alquier2024">(<a href="#ref-Alquier2024" role="doc-biblioref">Alquier, 2024</a>)</span>, <span class="citation" data-cites="Bousquet-Elisseeff2002">(<a href="#ref-Bousquet-Elisseeff2002" role="doc-biblioref">Bousquet and Elisseeff, 2002</a>)</span>, <span class="citation" data-cites="Shalev-Shwartz-Ben-David2014">(<a href="#ref-Shalev-Shwartz-Ben-David2014" role="doc-biblioref">Shalev-Shwartz and Ben-David, 2014</a>)</span> はいずれもリスクと誤差を交換可能な概念としている．</p>
</div>
</div>
</div>
</section>
<section id="pac-学習" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="pac-学習"><span class="header-section-number">1.4</span> PAC 学習</h3>
<p>機械学習を形式化する数理的枠組みのうち，<strong>PAC 学習</strong> とは，</p>
<blockquote class="blockquote">
<p><a href="https://en.wikipedia.org/wiki/Probably_approximately_correct_learning">Probably Approximately Correct Learning</a></p>
</blockquote>
<p>の略であり，<span class="citation" data-cites="Valiant1984">(<a href="#ref-Valiant1984" role="doc-biblioref">Valiant, 1984</a>)</span> によって提案されたものである．</p>
<p>機械学習における哲学的な問題として，「そもそも不可知なリスク <span class="math inline">\(R(h)\)</span> を最小化できるのか？」「できるとしたら，どのような場合においてか？」というものがあった．<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="agnostically PAC Learnable^[[@Shalev-Shwartz-Ben-David2014 p.25] 定義3.3，[@Mohri+2018 p.22] 定義2.14 など．元々の [@Valiant1984] の定義では，$m$ と計算時間の増加レートは $1/\ep,1/\delta$ の多項式以下であるという制限もあった．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
agnostically PAC Learnable<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>
</div>
</div>
<div class="callout-body-container callout-body">
<div id="def-PAC-learnable" class="theorem definition">
<p><span class="theorem-title"><strong>定義 2</strong></span> 集合 <span class="math inline">\(\mathcal{H}\subset\mathcal{L}(\mathcal{X};\mathcal{Y})\)</span> が（不可知論的な意味で） <strong>PAC 学習可能</strong> であるとは，ある関数 <span class="math display">\[
m_\mathcal{H}:(0,1)^2\to\mathbb{N}
\]</span> とアルゴリズム <span class="math display">\[
A:(\mathcal{X}\times\mathcal{Y})^{&lt;\omega}\to\mathcal{H}
\]</span> が存在して，任意の <span class="math inline">\(\epsilon,\delta\in(0,1)\)</span> と <span class="math inline">\(\mathbb{P}\in\mathcal{P}(\mathcal{X}\times\mathcal{Y})\)</span> に対して，<span class="math inline">\(m_\mathcal{H}(\epsilon,\delta)\)</span> よりも多くの i.i.d. サンプルが存在すれば，<span class="math inline">\(1-\delta\)</span> 以上の確率で， <span class="math display">\[
R(A(S_m))\le\min_{h\in\mathcal{H}}R(h)+\epsilon\quad(m\ge m_\mathcal{H}(\epsilon,\delta))
\]</span> が成り立つことをいう．</p>
</div>
</div>
</div>
<p>PAC 学習とは，分布 <span class="math inline">\(\mathbb{P}\in\mathcal{P}(\mathcal{X}\times\mathcal{Y})\)</span> に依らない真の誤差の評価を，確率論的に与えることを目的としており，Probably Approximately Correct の名前はその様子を端的に表現している．</p>
<p><span class="citation" data-cites="Valiant1984">(<a href="#ref-Valiant1984" role="doc-biblioref">Valiant, 1984</a>)</span> による PAC 学習可能性の定義には，計算量と計算時間の制約も入っていた．<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> <span class="citation" data-cites="Haussler-Warmuth1993">(<a href="#ref-Haussler-Warmuth1993" role="doc-biblioref">Haussler and Warmuth, 1993, p. 292</a>)</span> によれば，PAC 学習の枠組みにより，計算効率性の研究者が，機械学習のアルゴリズムにも目を向け，協業を始めるきっかけになったとしている．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="agnostically PAC Learnable^[[@Shalev-Shwartz-Ben-David2014 p.34] 系4.6 など．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
agnostically PAC Learnable<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>
</div>
</div>
<div class="callout-body-container callout-body">
<div id="thm-PAC-learnable" class="theorem">
<p><span class="theorem-title"><strong>定理 1</strong></span> 仮説集合 <span class="math inline">\(\mathcal{H}\subset\mathcal{L}(\mathcal{X};\mathcal{Y})\)</span> が有限ならば，（不可知論的な意味で）PAC 学習可能である．</p>
</div>
</div>
</div>
</section>
<section id="thm-pac-learnable-の証明" class="level3" data-number="1.5">
<h3 data-number="1.5" class="anchored" data-anchor-id="thm-pac-learnable-の証明"><span class="header-section-number">1.5</span> <a href="#thm-PAC-learnable" class="quarto-xref">定理&nbsp;1</a> の証明</h3>
<p>仮説集合 <span class="math inline">\(\mathcal{H}\)</span> が <strong>一様収束性</strong> を持つことを示せば良い，というように議論する．</p>
<p>PAC 学習可能性（ <a href="#def-PAC-learnable" class="quarto-xref">定義&nbsp;2</a> ）は純粋に真の誤差の議論であるが，訓練誤差との関係に注目して示すのである．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="$\epsilon$-representative, uniform convergence property^[[@Shalev-Shwartz-Ben-David2014 pp.31-32] 定義3.1 と 定義3.3．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="math inline">\(\epsilon\)</span>-representative, uniform convergence property<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>
</div>
</div>
<div class="callout-body-container callout-body">
<div id="def-uniform-convergence" class="theorem definition">
<p><span class="theorem-title"><strong>定義 3</strong></span> &nbsp;</p>
<ul>
<li>訓練データ <span class="math inline">\(S_n=\{x_i\}_{i=1}^n\)</span> が <strong><span class="math inline">\(\epsilon\)</span>-代表的</strong> であるとは，次を満たすことをいう： <span class="math display">\[
\lvert\widehat{R}_n(h)-R(h)\rvert\le\epsilon\quad(h\in\mathcal{H}).
\]</span></li>
<li>仮説集合 <span class="math inline">\(\mathcal{H}\)</span> が <strong>一様収束性</strong> を持つとは，任意の <span class="math inline">\(\epsilon,\delta\in(0,1)\)</span> と <span class="math inline">\(\mathbb{P}\in\mathcal{P}(\mathcal{X}\times\mathcal{Y})\)</span> について，十分大きな訓練データ <span class="math inline">\(S_m\)</span> を取れば，<span class="math inline">\(1-\delta\)</span> 以上の確率で <span class="math inline">\(S_m\)</span> は <span class="math inline">\(\epsilon\)</span>-代表的であることをいう．</li>
<li>このときのサンプル数の増加の速さを <span class="math inline">\(m_\mathcal{H}^{\mathrm{UC}}(\epsilon,\delta)\)</span> と書く．</li>
</ul>
</div>
<div id="lem-uniform-convergence" class="theorem lemma">
<p><span class="theorem-title"><strong>補題 1</strong></span> 訓練データ <span class="math inline">\(S_n\)</span> が <span class="math inline">\(\epsilon/2\)</span>-代表的ならば，任意の経験リスク最小化学習器 <span class="math display">\[
h_{S_n}\in\operatorname*{argmin}_{h\in\mathcal{H}}\widehat{R}_n(h)
\]</span> は <span class="math display">\[
R(h_{S_n})\le\min_{h\in\mathcal{H}}R(h)+\epsilon
\]</span> を満たす．</p>
<p>特に，<span class="math inline">\(m_\mathcal{H}^{\mathrm{UC}}(\epsilon,\delta)\)</span> に関して一様収束性を持つならば，<span class="math inline">\(m_\mathcal{H}(\epsilon/2,\delta)\le m_\mathcal{H}^{\mathrm{UC}}(\epsilon,\delta)\)</span> に関して（不可知論的な意味で）PAC 学習可能である．</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled" title="証明">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
証明
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(h_{S_n}\)</span> の最小性に注意して，</p>
<p><span class="math display">\[
\begin{align*}
    R(h_{S_n})&amp;\le\widehat{R}_n(h_{S_n})+\frac{\epsilon}{2}\\
    &amp;\le\widehat{R}_n(h)+\frac{\epsilon}{2}\\
    &amp;\le R(h)+\epsilon.
\end{align*}
\]</span></p>
</div>
</div>
</div>
<p>こうして，PAC 学習の枠組みは，（今回のケースでは）ERM の枠組みを肯定する結果を導いている．</p>
<p>これは，一様収束性が成り立つ仮説集合 <span class="math inline">\(\mathcal{H}\)</span> については，経験リスクは真のリスクに十分近いことを意味している．このような <span class="math inline">\(\mathcal{H}\)</span> を <strong>Glivenko-Cantelli クラス</strong> <span class="citation" data-cites="Glivenko1933">(<a href="#ref-Glivenko1933" role="doc-biblioref">Glivenko, 1933</a>)</span>, <span class="citation" data-cites="Cantelli1933">(<a href="#ref-Cantelli1933" role="doc-biblioref">Cantelli, 1933</a>)</span> ともいう．<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a></p>
<p>こうして，</p>
</section>
<section id="pac-学習の基本定理" class="level3" data-number="1.6">
<h3 data-number="1.6" class="anchored" data-anchor-id="pac-学習の基本定理"><span class="header-section-number">1.6</span> PAC 学習の基本定理</h3>
<p>実は，分類問題においては，一様収束性は，PAC 学習可能性を特徴付ける．</p>
<p>この証明は，VC 次元 <span class="citation" data-cites="Vapnik-Chervonenkis71">(<a href="#ref-Vapnik-Chervonenkis71" role="doc-biblioref">V. N. Vapnik and Chervonenkis, 1971</a>)</span> の概念による．</p>
<p>しかし，一般の学習問題においても同じ状況というわけではない <span class="citation" data-cites="Shalev-Shwartz2010">(<a href="#ref-Shalev-Shwartz2010" role="doc-biblioref">Shalev-Shwartz et al., 2010</a>)</span>．多クラス分類でさえ同値性は崩れる <span class="citation" data-cites="Daniely+2011">(<a href="#ref-Daniely+2011" role="doc-biblioref">Daniely et al., 2011</a>)</span>．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="Fundamental Theorem of Statistical Machine Learning^[[@Shalev-Shwartz-Ben-David2014 p.48] 定理6.7 など．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Fundamental Theorem of Statistical Machine Learning<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a>
</div>
</div>
<div class="callout-body-container callout-body">
<div id="thm-PAC" class="theorem">
<p><span class="theorem-title"><strong>定理 2</strong></span> 分類問題 <span class="math inline">\(\mathcal{Y}=2\)</span> を 0-1 損失 <span class="math inline">\(l=1_{\Delta_\mathcal{Y}^\complement}\)</span> で考えるとする．仮説集合 <span class="math inline">\(\mathcal{H}\subset\mathcal{L}(\mathcal{X};\mathcal{Y})\)</span> について，次は同値：</p>
<ol type="1">
<li><span class="math inline">\(\mathcal{H}\)</span> は一様収束性を持つ．</li>
<li><span class="math inline">\(\mathcal{H}\)</span> は（不可知論的な意味で）PAC 学習可能である．</li>
<li><span class="math inline">\(\mathcal{H}\)</span> は有限な VC 次元を持つ．</li>
</ol>
</div>
</div>
</div>
</section>
<section id="bayes-ルール" class="level3" data-number="1.7">
<h3 data-number="1.7" class="anchored" data-anchor-id="bayes-ルール"><span class="header-section-number">1.7</span> Bayes ルール</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="Bayes error, Bayes rule^[[@Mohri+2018 p.22] 定義2.15，[@金森敬文2015 p.9] を参考．], excess risk / regret">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Bayes error, Bayes rule<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a>, excess risk / regret
</div>
</div>
<div class="callout-body-container callout-body">
<div id="def-Bayes-loss" class="theorem definition">
<p><span class="theorem-title"><strong>定義 4</strong></span> 損失関数 <span class="math inline">\(l\)</span> に対して， <span class="math display">\[
\begin{align*}
    R^*&amp;:=\inf_{h\in\mathcal{L}(\mathcal{X};\mathcal{Y})}R(h)\\
    &amp;=\inf_{h\in\mathcal{L}(\mathcal{X};\mathcal{Y})}\mathbb{E}[l(h(X),Y)]
\end{align*}
\]</span> を <strong>Bayes 誤差</strong> という．仮に右辺の下限が達成される <span class="math inline">\(h^*\in\mathcal{L}(\mathcal{X};\mathcal{Y})\)</span> が存在するとき，これを <strong>Bayes 最適学習則</strong> またはベイズルール という． <span class="math display">\[
\mathcal{E}(h):=R(h)-R^*
\]</span> を <strong>超過損失</strong> という．</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="Bayes 規則の例^[[@Shalev-Shwartz-Ben-David2014 p.25] など．]">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Bayes 規則の例<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(\mathcal{Y}=2\)</span> の場合，任意の <span class="math inline">\(\mathbb{P}\in\mathcal{P}(\mathcal{X}\times\mathcal{Y})\)</span> に対して， <span class="math display">\[
h^*(x):=\begin{cases}
1&amp;\mathbb{P}[Y=1\,|\,X=x]\ge\frac{1}{2},\\
0&amp;\mathrm{otherwise}
\end{cases}
\]</span> は Bayes 最適学習則である．</p>
</div>
</div>
</div>
<p><span class="math display">\[
\begin{align*}
    \mathcal{E}(\widehat{h}_S)&amp;=R(\widehat{h}_S)-R(h^*)\\
    &amp;=\biggr(R(\widehat{h}_S)-\inf_{h\in\mathcal{H}}R(h)\biggl)+\biggr(\inf_{h\in\mathcal{H}}R(h)-R(h^*)\biggl).
\end{align*}
\]</span> 第一項を <strong>推定誤差</strong>，第二項を <strong>近似誤差</strong> という．<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a></p>
<p>ここから，<span class="math inline">\(\overline{h}\)</span> を <span class="math inline">\(\inf_{h\in\mathcal{H}}R(h)\)</span> を達成する <strong>oracle machine</strong> とすると，推定誤差はさらに２項に分解して評価できる： <span class="math display">\[
\begin{align*}
    &amp;R(\widehat{h}_n)-\inf_{h\in\mathcal{H}}R(H)\\
    &amp;=R(\widehat{h}_n)-R(\overline{h})\\
    &amp;=\underbrace{\widehat{R}_n(\widehat{h}_n)-\widehat{R}_n(\overline{h}_n)}_{\le0}+R(\widehat{h}_n)-\widehat{R}_n(\widehat{h}_n)+\widehat{R}_n(\overline{h})-R(\overline{h})\\
    &amp;\le\biggl|\widehat{R}_n(\widehat{h}_n)-R(\widehat{h}_n)\biggr|+\biggl|\widehat{R}_n(\overline{h})-R(\overline{h})\biggr|.
\end{align*}
\]</span></p>
</section>
</section>
<section id="統計的決定理論" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="統計的決定理論"><span class="header-section-number">2</span> 統計的決定理論</h2>
<p>PAC 学習の枠組みを相対的に理解するため，統計的決定理論の目線から，同じ形式を見直してみる．</p>
<section id="枠組み" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="枠組み"><span class="header-section-number">2.1</span> 枠組み</h3>
<p>最大の違いは，データ生成分布 <span class="math inline">\(\mathbb{P}\in\mathcal{P}(\mathcal{X}\times\mathcal{Y})\)</span> にパラメトリックな仮定をおく点である．このとき，組 <span class="math inline">\((\mathcal{X}\times\mathcal{Y},(\mathbb{P}_\theta)_{\theta\in\Theta})\)</span> を <strong>統計的実験</strong> ともいう．</p>
<p>損失関数 <span class="math inline">\(l:\mathcal{Y}\times\mathcal{Y}\to\mathbb{R}_+\)</span> は，より一般には，決定空間 <span class="math inline">\(\mathcal{Z}\)</span> に対して， <span class="math display">\[
l:\mathcal{Y}\times\mathcal{Z}\to\mathbb{R}_+
\]</span> と定まるものである．</p>
</section>
<section id="一様最強力検定" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="一様最強力検定"><span class="header-section-number">2.2</span> 一様最強力検定</h3>
<p>学習ではなく，検定の文脈では，PAC 同様全てのデータ生成分布 <span class="math inline">\(\mathbb{P}\in\mathcal{P}()\)</span> を考えるが，リスクが小さいことを要請する．</p>
</section>
</section>
<section id="pac-bound" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="pac-bound"><span class="header-section-number">3</span> PAC bound</h2>
<section id="定理" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="定理"><span class="header-section-number">3.1</span> 定理</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="PAC bound^[[@Alquier2024 p.7] 定理1.2 など．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
PAC bound<a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a>
</div>
</div>
<div class="callout-body-container callout-body">
<div id="thm-1" class="theorem">
<p><span class="theorem-title"><strong>定理 3</strong></span> 仮説集合 <span class="math inline">\(\mathcal{H}\)</span> が有限であるとする：<span class="math inline">\(\#\mathcal{H}=:M&lt;\infty\)</span>． このとき，任意の <span class="math inline">\(\epsilon\in(0,1)\)</span> について， <span class="math display">\[
\mathbb{P}\left[\forall_{h\in\mathcal{H}}\;R(h)-\widehat{R}(h)\le C\sqrt{\frac{\log\frac{M}{\epsilon}}{2n}}\right]\ge1-\epsilon.
\]</span></p>
</div>
</div>
</div>
<p>仮説 <span class="math inline">\(\mathcal{H}\)</span> の数 <span class="math inline">\(M\)</span> を増やすごとに，訓練データ数 <span class="math inline">\(n\)</span> は <span class="math inline">\(\log M\)</span> のオーダーで増やす必要がある，ということになる．</p>
</section>
<section id="bigglwidehatr_nwidehath_n-rwidehath_nbiggr-の評価" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="bigglwidehatr_nwidehath_n-rwidehath_nbiggr-の評価"><span class="header-section-number">3.2</span> <span class="math inline">\(\biggl|\widehat{R}_n(\widehat{h}_n)-R(\widehat{h}_n)\biggr|\)</span> の評価</h3>
</section>
<section id="bigglwidehatr_noverlineh-roverlinehbiggr-の評価" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="bigglwidehatr_noverlineh-roverlinehbiggr-の評価"><span class="header-section-number">3.3</span> <span class="math inline">\(\biggl|\widehat{R}_n(\overline{h})-R(\overline{h})\biggr|\)</span> の評価</h3>
</section>
<section id="定理の一般化" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="定理の一般化"><span class="header-section-number">3.4</span> 定理の一般化<a href="#fn21" class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a></h3>
<ul>
<li><p>一般の <span class="math inline">\(\mathcal{H}\subset\mathcal{L}(\mathcal{X};\mathcal{Y})\)</span> への拡張は，VC次元の理論を用いて行われる（ <a href="#thm-PAC" class="quarto-xref">定理&nbsp;2</a> など）．</p></li>
<li><p>バウンドの変形に，Rademacher 複雑性も使われる．</p></li>
<li><p>現実との乖離：現代の深層学習では <span class="math inline">\(M\)</span> が極めて大きくなり，PAC 不等式はほとんど意味をなさない．これを包括できる理論が試みられている．</p></li>
</ul>



</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-Alquier2024" class="csl-entry" role="listitem">
Alquier, P. (2024). <a href="https://doi.org/10.1561/2200000100">User-friendly introduction to PAC-bayes bounds</a>. <em>Foundations and Trends<span></span> in Machine Learning</em>, <em>17</em>(2), 174–303.
</div>
<div id="ref-Bousquet-Elisseeff2002" class="csl-entry" role="listitem">
Bousquet, O., and Elisseeff, A. (2002). <a href="https://jmlr.org/papers/v2/bousquet02a.html">Stability and generalization</a>. <em>Journal of Machine Learning Research</em>, <em>2</em>, 499–526.
</div>
<div id="ref-Cantelli1933" class="csl-entry" role="listitem">
Cantelli, F. P. (1933). <a href="">Sulla determinazione empirica della leggi di probabilità</a>. <em>Giornale Dell’Instituo Italiano Degli Attuari</em>, <em>4</em>(1), 421–424.
</div>
<div id="ref-Daniely+2011" class="csl-entry" role="listitem">
Daniely, A., Sabato, S., Ben-David, S., and Shalev-Shwartz, S. (2011). <a href="https://proceedings.mlr.press/v19/daniely11a.html">Multiclass learnability and the ERM principle</a>. In S. M. Kakade and U. von Luxburg, editors, <em>Proceedings of the 24th annual conference on learning theory</em>,Vol. 19, pages 207–232. Budapest, Hungary: PMLR.
</div>
<div id="ref-Devroye+1996" class="csl-entry" role="listitem">
Devroye, L., Györfi, L., and Lugosi, G. (1996). <em><a href="https://link.springer.com/book/10.1007/978-1-4612-0711-5">A probabilistic theory of pattern recognition</a></em>,Vol. 31. Springer New York.
</div>
<div id="ref-Glivenko1933" class="csl-entry" role="listitem">
Glivenko, V. I. (1933). <a href="">Sulla determinazione empirica della leggi di probabilità</a>. <em>Giornale Dell’Instituo Italiano Degli Attuari</em>, <em>4</em>(1), 92–99.
</div>
<div id="ref-Haussler-Warmuth1993" class="csl-entry" role="listitem">
Haussler, D., and Warmuth, M. (1993). <a href="https://link.springer.com/book/10.1007/b102257">Foundations of knowledge acquisition: Machine learning</a>. In A. L. Meyrowitz and S. Chipman, editors, pages 291–312. Springer New York.
</div>
<div id="ref-Mohri+2018" class="csl-entry" role="listitem">
Mohri, M., Rostamizadeh, A., and Talwalkar, A. (2018). <em><a href="https://cs.nyu.edu/~mohri/mlbook/">Foundations of machine learning</a></em>. MIT Press.
</div>
<div id="ref-Shalev-Shwartz-Ben-David2014" class="csl-entry" role="listitem">
Shalev-Shwartz, S., and Ben-David, S. (2014). <em><a href="https://doi.org/10.1017/CBO9781107298019">Understanding machine learning: From theory to algorithms</a></em>. Cambridge University Press.
</div>
<div id="ref-Shalev-Shwartz2010" class="csl-entry" role="listitem">
Shalev-Shwartz, S., Shamir, O., Srebro, N., and Sridharan, K. (2010). <a href="http://jmlr.org/papers/v11/shalev-shwartz10a.html">Learnability, stability and uniform convergence</a>. <em>Journal of Machine Learning Research</em>, <em>11</em>(90), 2635–2670.
</div>
<div id="ref-Valiant1984" class="csl-entry" role="listitem">
Valiant, L. G. (1984). <a href="https://dl.acm.org/doi/10.1145/1968.1972">A theory of the learnable</a>. <em>Communications of the ACM</em>, <em>27</em>(11), 1134–1142.
</div>
<div id="ref-Vapnik1998" class="csl-entry" role="listitem">
Vapnik, Vladimir N. (1998). <em><a href="https://www.wiley.com/en-us/Statistical+Learning+Theory-p-9780471030034">Statistical learning theory</a></em>. Wiley-Blackwell.
</div>
<div id="ref-Vapnik-Chervonenkis71" class="csl-entry" role="listitem">
Vapnik, V. N., and Chervonenkis, A. Ya. (1971). <a href="https://epubs.siam.org/doi/10.1137/1126059">Necessary and sufficient conditions for the uniform convergence of means to their expectations</a>. <em>Theory of Probability and Its Applications</em>, <em>16</em>(3), 264–280.
</div>
<div id="ref-金森敬文2015" class="csl-entry" role="listitem">
金森敬文. (2015). <em>統計的学習理論</em>. 講談社.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><span class="citation" data-cites="Mohri+2018">(<a href="#ref-Mohri+2018" role="doc-biblioref">Mohri et al., 2018, pp. 9–10</a>)</span> と <span class="citation" data-cites="Shalev-Shwartz-Ben-David2014">(<a href="#ref-Shalev-Shwartz-Ben-David2014" role="doc-biblioref">Shalev-Shwartz and Ben-David, 2014, pp. 13–14</a>)</span>, <span class="citation" data-cites="Alquier2024">(<a href="#ref-Alquier2024" role="doc-biblioref">Alquier, 2024</a>)</span> を参考にした．<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>これは訓練セット (training set) ともいう <span class="citation" data-cites="Shalev-Shwartz-Ben-David2014">(<a href="#ref-Shalev-Shwartz-Ben-David2014" role="doc-biblioref">Shalev-Shwartz and Ben-David, 2014, p. 14</a>)</span>．<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><span class="citation" data-cites="Bousquet-Elisseeff2002">(<a href="#ref-Bousquet-Elisseeff2002" role="doc-biblioref">Bousquet and Elisseeff, 2002</a>)</span> の用語に一致する．<span class="citation" data-cites="Alquier2024">(<a href="#ref-Alquier2024" role="doc-biblioref">Alquier, 2024, p. 2</a>)</span> では，<span class="math inline">\(\mathcal{X}\)</span> を object set，<span class="math inline">\(\mathcal{Y}\)</span> を label set と呼んでいる．<span class="citation" data-cites="Shalev-Shwartz-Ben-David2014">(<a href="#ref-Shalev-Shwartz-Ben-David2014" role="doc-biblioref">Shalev-Shwartz and Ben-David, 2014, pp. 13–14</a>)</span> は <span class="math inline">\(\mathcal{X}\)</span> を domain set，<span class="math inline">\(\mathcal{Y}\)</span> を label set と呼ぶ．<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><span class="citation" data-cites="Valiant1984">(<a href="#ref-Valiant1984" role="doc-biblioref">Valiant, 1984</a>)</span> では，<span class="math inline">\(\mathcal{Y}=2\)</span> の場合，元 <span class="math inline">\(h\in\mathcal{H}\)</span> を <strong>概念</strong> (concept) ともいう．その他の場合を predicate とも呼んでいる．<span class="citation" data-cites="Shalev-Shwartz-Ben-David2014">(<a href="#ref-Shalev-Shwartz-Ben-David2014" role="doc-biblioref">Shalev-Shwartz and Ben-David, 2014, p. 14</a>)</span> では <strong>predictor</strong>, predictino rule, classifier とも呼ぶとしている．<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p><span class="citation" data-cites="Alquier2024">(<a href="#ref-Alquier2024" role="doc-biblioref">Alquier, 2024, p. 177</a>)</span> を参考にした．<span class="math inline">\(\Delta_\mathcal{Y}:=\left\{(y',y)\in\mathcal{Y}^2\mid y=y'\right\}\)</span> を対角集合とした．<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p><span class="citation" data-cites="Alquier2024">(<a href="#ref-Alquier2024" role="doc-biblioref">Alquier, 2024</a>)</span> 第4章ではこの i.i.d. 仮定を外している．<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p><span class="citation" data-cites="Shalev-Shwartz-Ben-David2014">(<a href="#ref-Shalev-Shwartz-Ben-David2014" role="doc-biblioref">Shalev-Shwartz and Ben-David, 2014, p. 24</a>)</span> などでは，<span class="math inline">\(\mathcal{Y}=2\)</span> として分類問題を考えていることもあり，専らこの損失を考えている．<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p><span class="citation" data-cites="Alquier2024">(<a href="#ref-Alquier2024" role="doc-biblioref">Alquier, 2024, p. 4</a>)</span>, <span class="citation" data-cites="Mohri+2018">(<a href="#ref-Mohri+2018" role="doc-biblioref">Mohri et al., 2018, p. 10</a>)</span>，<span class="citation" data-cites="金森敬文2015">(<a href="#ref-金森敬文2015" role="doc-biblioref">金森敬文, 2015, p. 7</a>)</span> を参考にした．<span class="citation" data-cites="Shalev-Shwartz-Ben-David2014">(<a href="#ref-Shalev-Shwartz-Ben-David2014" role="doc-biblioref">Shalev-Shwartz and Ben-David, 2014, p. 14</a>)</span> でも，generalization error, risk, error，さらには loss のいずれの名前でも呼ぶし，training error と empirical error /risk とも交換可能に使う，としている．<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p><span class="citation" data-cites="Mohri+2018">(<a href="#ref-Mohri+2018" role="doc-biblioref">Mohri et al., 2018, pp. 10–11</a>)</span>, <span class="citation" data-cites="金森敬文2015">(<a href="#ref-金森敬文2015" role="doc-biblioref">金森敬文, 2015, p. 8</a>)</span> など．<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p><span class="citation" data-cites="Haussler-Warmuth1993">(<a href="#ref-Haussler-Warmuth1993" role="doc-biblioref">Haussler and Warmuth, 1993, p. 263</a>)</span> にある Valiant 本人による解説に，その哲学的なモチベーションがよく表れている．<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p><span class="citation" data-cites="Shalev-Shwartz-Ben-David2014">(<a href="#ref-Shalev-Shwartz-Ben-David2014" role="doc-biblioref">Shalev-Shwartz and Ben-David, 2014, p. 25</a>)</span> 定義3.3，<span class="citation" data-cites="Mohri+2018">(<a href="#ref-Mohri+2018" role="doc-biblioref">Mohri et al., 2018, p. 22</a>)</span> 定義2.14 など．元々の <span class="citation" data-cites="Valiant1984">(<a href="#ref-Valiant1984" role="doc-biblioref">Valiant, 1984</a>)</span> の定義では，<span class="math inline">\(m\)</span> と計算時間の増加レートは <span class="math inline">\(1/\ep,1/\delta\)</span> の多項式以下であるという制限もあった．<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p><span class="citation" data-cites="Shalev-Shwartz-Ben-David2014">(<a href="#ref-Shalev-Shwartz-Ben-David2014" role="doc-biblioref">Shalev-Shwartz and Ben-David, 2014, p. 28</a>)</span> も参照．<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p><span class="citation" data-cites="Shalev-Shwartz-Ben-David2014">(<a href="#ref-Shalev-Shwartz-Ben-David2014" role="doc-biblioref">Shalev-Shwartz and Ben-David, 2014, p. 34</a>)</span> 系4.6 など．<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p><span class="citation" data-cites="Shalev-Shwartz-Ben-David2014">(<a href="#ref-Shalev-Shwartz-Ben-David2014" role="doc-biblioref">Shalev-Shwartz and Ben-David, 2014, pp. 31–32</a>)</span> 定義3.1 と 定義3.3．<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p><span class="citation" data-cites="Shalev-Shwartz-Ben-David2014">(<a href="#ref-Shalev-Shwartz-Ben-David2014" role="doc-biblioref">Shalev-Shwartz and Ben-David, 2014, p. 35</a>)</span> など．<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p><span class="citation" data-cites="Shalev-Shwartz-Ben-David2014">(<a href="#ref-Shalev-Shwartz-Ben-David2014" role="doc-biblioref">Shalev-Shwartz and Ben-David, 2014, p. 48</a>)</span> 定理6.7 など．<a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p><span class="citation" data-cites="Mohri+2018">(<a href="#ref-Mohri+2018" role="doc-biblioref">Mohri et al., 2018, p. 22</a>)</span> 定義2.15，<span class="citation" data-cites="金森敬文2015">(<a href="#ref-金森敬文2015" role="doc-biblioref">金森敬文, 2015, p. 9</a>)</span> を参考．<a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p><span class="citation" data-cites="Shalev-Shwartz-Ben-David2014">(<a href="#ref-Shalev-Shwartz-Ben-David2014" role="doc-biblioref">Shalev-Shwartz and Ben-David, 2014, p. 25</a>)</span> など．<a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn19"><p><span class="citation" data-cites="金森敬文2015">(<a href="#ref-金森敬文2015" role="doc-biblioref">金森敬文, 2015, p. 17</a>)</span> を参考．<a href="#fnref19" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20"><p><span class="citation" data-cites="Alquier2024">(<a href="#ref-Alquier2024" role="doc-biblioref">Alquier, 2024, p. 7</a>)</span> 定理1.2 など．<a href="#fnref20" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn21"><p><span class="citation" data-cites="Devroye+1996">(<a href="#ref-Devroye+1996" role="doc-biblioref">Devroye et al., 1996</a>)</span> 第11, 12章 参照．<span class="citation" data-cites="Vapnik1998">(<a href="#ref-Vapnik1998" role="doc-biblioref">Vladimir N. Vapnik, 1998</a>)</span>．<a href="#fnref21" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/162348\.github\.io\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
        for (let i=0; i<annoteTargets.length; i++) {
          const annoteTarget = annoteTargets[i];
          const targetCell = annoteTarget.getAttribute("data-target-cell");
          const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
          const contentFn = () => {
            const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
            if (content) {
              const tipContent = content.cloneNode(true);
              tipContent.classList.add("code-annotation-tip-content");
              return tipContent.outerHTML;
            }
          }
          const config = {
            allowHTML: true,
            content: contentFn,
            onShow: (instance) => {
              selectCodeLines(instance.reference);
              instance.reference.classList.add('code-annotation-active');
              window.tippy.hideAll();
            },
            onHide: (instance) => {
              unselectCodeLines();
              instance.reference.classList.remove('code-annotation-active');
            },
            maxWidth: 300,
            delay: [50, 0],
            duration: [200, 0],
            offset: [5, 10],
            arrow: true,
            trigger: 'click',
            appendTo: function(el) {
              return el.parentElement.parentElement.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'quarto',
            placement: 'right',
            positionFixed: true,
            popperOptions: {
              modifiers: [
              {
                name: 'flip',
                options: {
                  flipVariations: false, // true by default
                  allowedAutoPlacements: ['right'],
                  fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
                },
              },
              {
                name: 'preventOverflow',
                options: {
                  mainAxis: false,
                  altAxis: false
                }
              }
              ]        
            }      
          };
          window.tippy(annoteTarget, config); 
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "162348/162348.github.io";
    script.dataset.repoId = "R_kgDOKlfKYQ";
    script.dataset.category = "Announcements";
    script.dataset.categoryId = "DIC_kwDOKlfKYc4CgDmb";
    script.dataset.mapping = "pathname";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://162348.github.io/">
<p>Hirofumi Shiba</p>
</a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/162348/162348.github.io/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/ano2math5">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:shiba.hirofumi@ism.ac.jp">
      <i class="bi bi-envelope" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="../../../blog.xml">
      <i class="bi bi-rss" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>