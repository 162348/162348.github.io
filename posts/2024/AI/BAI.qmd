---
title: "ベイズ機械学習"
subtitle: 概観
author: "司馬 博文"
date: 2/29/2024
categories: [Bayesian, Survey]
toc: true
number-sections: true
code-block-bg: true
code-block-border-left: "#5AB5BA"
code-overflow: wrap
code-fold: true
bibliography: 
    - ../../../mathematics.bib
    - ../../../bib.bib
csl: ../../../apa.csl
crossref:
    sec-prefix: 節
    eq-prefix: 式
    def-prefix: 定義
    def-title: 定義
    thm-prefix: 定理
    thm-title: 定理
    fig-prefix: 図
    fig-title: 図
abstract-title: 概要
abstract: ベイズ機械学習とは，不確実性を扱える機械学習手法をいう．これは従来の頻度論的手法と対照的に，推論手法よりもモデルベースで，最適化よりも積分ベースである．本記事ではその枠組みを概観する．
---

{{< include ../../../_preamble.qmd >}}

現在，産業界における "AI" というと専ら，いくつかの限られた巨大 IT 企業が主導して深層のニューラルネットワークを用いて最尤推定を行い，これを基盤モデルとして多くの下流タスクを安価に解くという営みのことを指す．

AI はこれにかぎるものではない．

## ベイズのすすめ

機械学習において，確率モデルをベースにしたアプローチを，**ベイズ機械学習** ともいう．

これは計算の困難さとスケーラブルでないという計算論的な側面と，設計者が確率モデルを設計しなければならない点で従来と異なった思考を必要とするユーザーフレンドリー性との２つの理由から，長らくマイノリティであった．

しかし，機械学習の性能と可能性を誰も伺わなくなった今こそ，新たな前身を産むためには，ベイズの視点が必要不可欠となっているのである．

### 不確実性の定量化の必要性

機械学習と統計学が単なる道具ではなく，人間のより大きな営みの一環を単独で担う場面が増えてきた．例えば，

* 金融・経営・政策決定などの分野で，意思決定に繋げるデータ解析をするとき
* 科学において，発見や仮説を検証するためのデータ解析をするとき
* ロボットや自動車などの自動化をし，社会に実装するとき
* 医療診断などの場面で，専門家を補助するシステムを作るとき

人間社会では信頼が重要であるように，いずれの場面でも，性能の高さと正確さだけでなく，モデル自身が「自分は何を言っているのか」を少しでもわかっていてくれている必要がある．

特に，データから高い確証度で言えることと，そうではないことでは全く違う意味を持つ．それぞれの場面での例には，次のようなものがあるだろう：

* 

### 信頼のおける AI システム

上述の点をまとめると，機械学習手法と人間社会がよりよく共生していくには AI の **信頼性** (trustworthyness) が必要とされているのである．

現状の手法の延長でこの問題は扱えず，新たな手法が必要とされている．

Bayesian approach や probabilistic approach と呼ばれている試みは，まさにこれに応えるものであり，近年急速に発展している．

### 不確実性を扱うには Bayes が必要である

（後述のように本質的には密接な関連があれど），たしかに Bayes の方法は従来の方法と大きく異なる．だからと言って慣習的に Bayes の方法を用いないで居ると，コミュニティの混乱をもたらす恐れがある場面も多い．

これを，科学における再現性の危機を例にとって確認したい．^[[@Gal-Ghahramani2016] も参照．]

#### 再現性の危機

多くの実験科学では不確実性の定量化が必要不可欠である [@Krzywinski-Altman2013]．

> It is necessary and true that all of the things we say in science, all of the conclusions, are uncertain ... [@Feynman1998]

[**再現性の危機** ](https://ja.wikipedia.org/wiki/%E5%86%8D%E7%8F%BE%E6%80%A7%E3%81%AE%E5%8D%B1%E6%A9%9F) (replication crisis) とは，多くの実験において報告されている統計的優位性が，再現実験において得られないことが多いという問題を指し，2010年代の初めから多くの科学分野において問題として取り上げられてきた．^[心理学においては「再現性問題が大きく注目される大きな契機となった「超能力論文」が出版されたのが 2011 年である」 [@平石-中村2022] ようである．計量経済学における **信頼性革命** [@Angrist-Pischke2010] は，再現性の危機の，もう一つの革新的な解決法である．]

その結果多くの科学分野では **Bayes 統計学による不確実性の定量化に移行しつつある** [@Herzog-Ostwald2013], [@Trafimow-Marks2015], [@Nuzzo2014]．特に，信頼区間と信用区間の違いにおいてその本質が顕著に表れている．

#### 信頼区間と信用区間

「95 % の信頼区間」と言ったとき，「95 % の確率で真の値がその範囲に含まれるような区間」だと思いがちであるが，これはどちらかというと信用区間の説明であり，**信頼区間は計算するごとに値が変わってしまう確率変数である** ことを見落としがちである．^[「それでは，信頼区間は不確実性の正しい定量化を与えないではないか！」ということになるが，その通りなのである．$P$-値を計算する過程とは，帰無仮説で条件付けているだけであり，データの関数でもある．$P$-値の確率変数としての分散が大きいほど，何回か同じ実験を繰り返せばすぐに小さな $P$-値が得られることになる．これは [**基準確率の誤謬**](../../2023/%E6%95%B0%E7%90%86%E6%B3%95%E5%8B%99/%E6%B3%95%E5%BE%8B%E5%AE%B6%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E7%B5%B1%E8%A8%88%E6%95%B0%E7%90%862.qmd#sec-Bayes-problem) と似ている．]

つまり，信頼区間は頻度論的な概念であり，「真の値」がまず存在し，区間自体が変動し，95 % の確率で被覆するというのである．今回見ている信頼区間が，別のデータセットで計算した場合にどう変わるかについては全く未知である．

このことは，信頼区間は「真のパラメータの値」で条件づけて得るものであるが，信用区間はデータによって条件づけて得るものであるという点で違う，とまとめられる．この２つの混同は「何で条件づけているか？」を意識することで回避することができる．^["Confidence intervals suffer from an inverse inference problem that is not very different from that suffered by the NHSTP. In the NHSTP, the problem is in traversing the distance from the probability of the finding, given the null hypothesis, to the probability of the null hypothesis, given the finding." [@Trafimow-Marks2015]]

誤解を恐れず言うならば，再現性の危機とは，信頼区間というサイコロの出目によって科学が踊らされていたということに他ならない [@Nuzzo2014]．^[[@Nuzzo2014] には，Fisher が最初に用いてから，Neyman-Pearson 理論がこれを排除したものの，コミュニティが $P$-値を誤解して都合の良いように利用するようになるまでに至った歴史が説明されている．]

## 初めに

現在，深層生成モデルは社会に大きな影響を与えており，今や AI が社会を変え得ることを疑う者は居ないだろう．

言語，画像，音声，さらには動画まで，マルチモーダルに活躍の幅を広げている．これらのモデルを相互接続することで，今後もさらに爆発的に機能と能力が発達していくことは間違いないだろう．

問題はその先である．

今の AI にはなく，しかし今後の AI にあってほしいもの，その筆頭は **不確実性** と **意思決定** である．

不確実性を定量的に使い，合理的な意思決定を下す手法を研究する機械学習の分野を，**Bayes 機械学習** (Bayesian machine learning) または **確率的機械学習** (probabilistic machine learning) と呼び [@Broderick+2023]，これらを要素技術としてその先に来るべきものを筆者は **Bayesian AI** と呼ぶ．



大きなデータも，属人化医療や推薦システムなど多くの文脈では小さなデータの寄せ集めであり，そうでなくともその構造を正しく捉え，全ての不確実性を取り入れた柔軟なモデリングをすることで，さらに密接な形で社会に取り入れることができる．^[[@Ghahramani2015 p.458] はこれを **モデルの属人化** (personalization of models) と呼んでいる．]

> Although considerable challenges remain, the c ing decade promises substantial advances in artificial intelligence and machine learning based on the probabilistic framework. [@Ghahramani2015]



## 数学者への勧め

Bayes の見方は，機械学習を底流する数理的枠組みになっている．仮に次の MacLane の言葉が数学者のあるべき態度の１つであるとするならば，数学者には Bayes 機械学習が特におすすめできる．

>  However, I persisted in the position that **as mathematicians we must know whereof we speak**, be it a homotopy group or an adjoint functor. [@MacLane1983 p.55]

任意のモデル $\cM$ の周辺尤度 $p(x|\cM)$ （**証拠** (model evidence) ともいう）は，全てのデータの空間 $x\in\cX$ 上に有限な測度を定めるはずである．

よって，**全てのモデルは，あるデータを得意とするならば他のデータについては不得意であることを免れない**．これは no free lunch 定理と呼ばれる定理の一群により推測されており，分類問題などの簡単なタスクを除いて完全な形式的表現は持たない知識である．

![A Probabilistic Perspective of Genelization [@Wilson-Izmailov2020]](Images/mackay.png)

例えば，[基盤モデル](../Kernels/Deep2.qmd#sec-fine-tuning) とは，インターネット上のデータから最大限人間の言語というものに関する帰納バイアスを取り込んだ，パラメータ上の初期設定である．

これは，あるパラメータ空間上の理想的な事前分布からのサンプリングであるかも知れない．それ故，種々の下流タスクに対して，小さなモデル変更のみにより適応することが出来る．

大規模言語モデルの能力創発現象は，帰納バイアスを十分取り込むことにより自然に解かれるタスクであったのかもしれない．

## 確率論の利用

### 不確実性の定量化

合理的な信念の度合い (degree of belief) は確率の公理を満たす必要があるということから，確率論は AI エージェントや動物の合理的な振る舞いの規範的な理論としても用いられる．その際，Bayes の定理は，帰納的推論の確率論的な拡張だと捉えられる．

機械学習や統計をこの立場から見て，観測による不確実性の減少だと理解した場合，これを Bayes 学習や Bayes 統計学と呼ぶ．「頻度論的」という言葉は，よく「Bayes ではない」ということを示すために接頭辞的に用いられる．

多くの頻度論的な統計手法が最適化に拠る一方で，Bayes 統計・Bayes 学習は専ら積分法に拠る．このように，その用いる手法も鮮やかに対照的に見えるが，積分は変分近似を通じて最適化問題としても解けるし，Lengevin 法や HMC などの最適化手法は積分問題を解ける．

また，頻度論的な議論は，事前分布を明示せずに行われる Bayes 学習の理論であるとみなせる．その意味で普遍的な議論であるが，不確実性を扱うためには Bayes の定理を通じた確率論的な扱いが必須であるから，これは適用範囲が限定的ということでもある．^[Philipp Hennig [_Probabilistic ML - Lecture 1 - Introduction_](https://youtu.be/TTo2kjrAuTo?si=QD_pqMkdLOl52OsR&t=3703)]

深層モデル，深層生成モデルと時流が来ており，この次は確率的モデリングの時代になることは間違いない．

## Bayes 機械学習の例

### Bayes 深層学習



### 確率的グラフィカルモデル

歴史的に，（確率的）モデリングは，主に（確率的）グラフィカルモデルを通じて機械学習の分野に導入された．

そのため，20世紀に入ったばかりの頃は，Bayes 機械学習の唯一の例は確率的グラフィカルモデルなのであった．^[[@Neal-Hinton1998] など．]

### 推論アルゴリズムのプログラミングから，モデルのプログラミングへ

シミュレーターがあれば推論ができるというのが Bayes 計算の強みである．

そこで，推論手法をこれで統一し，解析者はモデルの構築に集中すれば良い，という新たなパラダイムを **確率的プログラミング** (Probabilistic Programming) と呼ぶ．


### Bayes 最適化

### データ圧縮

### 階層モデルと統計モデルの自動発見

## 参考文献