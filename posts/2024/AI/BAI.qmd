---
title: "ベイズ機械学習"
subtitle: "所信表明"
author: "司馬 博文"
date: 3/19/2024
categories: [Bayesian, AI, Survey]
toc: true
number-sections: true
code-block-bg: true
code-block-border-left: "#5AB5BA"
code-overflow: wrap
code-fold: true
bibliography: 
    - ../../../mathematics.bib
    - ../../../bib.bib
csl: ../../../apa.csl
crossref:
    sec-prefix: 節
    eq-prefix: 式
    def-prefix: 定義
    def-title: 定義
    thm-prefix: 定理
    thm-title: 定理
    fig-prefix: 図
    fig-title: 図
---

現在，産業界における "AI" というと専ら，いくつかの限られた巨大 IT 企業が，巨大ニューラルネットワークを最尤推定で学習させ，これを基盤モデルとして公開し，我々一般庶民はそれを有効活用して下流タスクを安価に解くことだけ考えるという営みを指す．

その産業や生活への破壊的な影響を憂慮しながらも，雨乞いをする日々である．

![3月19日時点，GPT-5 にも Sora にもアクセス権を持たない我々 v.s. [Lex Fridman Podcast](https://youtu.be/jvqFAi7vkBc?si=hwF_LJAs7XE3bNTR&t=2695) に出演した Sam Altman](Images/SamAltman.mp4)

AI はそんなものではない．AI はこれにかぎるものではない．

AI が真に我々の友となり，我々の日常をほんとうに豊かにするは，AI の進歩だけが必要なのではなく，**人間との協業が得意になる必要がある**．

そのための第一歩はすでに明らかである．**不確実性の定量化** である．

つまり，「その AI には何が出来て何が出来ないか」「AI の出力がいつ信頼にたるもので，いつ人間の介入が必要であるのか」がわかりやすい形で伝わるコミュニケーション様式をそなえている必要があるのである．^[これは [Human-AI interaction におけるガイドライン](https://www.microsoft.com/en-us/research/project/guidelines-for-human-ai-interaction/) [@Amershi+2019], [@Bensal+2019] でも明確にされている点である．この方向への試みの代表がベイズ機械学習，というわけではないが，筆者はベイズ機械学習の興隆は信頼のおける AI システムの構築にための極めて盤石な土台になるだろうと論じる．]

---

筆者の知る限り，ここにある全てのナラティブは現時点では全く広く語られているものではなく，筆者も最初の１年の研究生活を通じて朧げながら見えて来たばかりのものである．

**不確実性の定量化は，機械学習モデルを民主化し，我々の民芸に取り込むための重要な一歩である**（のではないだろうか？）．

本稿はこの発見を共有するために書いた．筆者の反芻不足から，冗長な部分も多いだろうが，少しでも，琴線に触れるものがあれば幸いである．

{{< include ../../../_preamble.qmd >}}

## ベイズ機械学習のすすめ

我々が AI をより信頼するためには，何が必要だろうか？

筆者の考えでは，信頼への第一歩は **不確実性の定量化** が出来るようになることのはずである．

そしてそのためには **ベイズ機械学習** (Bayesian Machine Learning) の発展による本質的解決が必要不可欠である．本稿はこの点を説明するために執筆されたものである．

筆者に言わせれば，ベイズ機械学習が，今後数年間で AI が経験すべき進展の方向である．この山を越えれば，今まででさえ思っても見なかった未来がひらけてくるだろう．

### ベイズとは何か？

機械学習において，確率論的なモデリングに基づいたアプローチを **ベイズ機械学習** ともいう．典型的には，モデルの全変数上の結合分布をモデリングし，ベイズ規則によりパラメータのベイズ推定を行う，という手続きからなる．そのため，**確率論的アプローチ** や **モデルベースアプローチ** も同義語として用いられる．^[[@Broderick+2023 p.2] など．]

一方で，**頻度論的** という言葉は，よく非ベイズ的アプローチを示す接頭辞として用いられる．典型的には，損失関数を設定し，これを最小化するパラメータを探索することによって実行される．

この２つのアプローチは互いに対照的であり，統計学の始まりから基本的な二項対立の図式をなしてきた．

| | Bayesian | Frequentist |
|:-----:|:----:|:----:|
| Computational Idea^[多くの頻度論的な統計手法が最適化に拠る一方で，Bayes 統計・Bayes 学習は専ら積分法に拠る．このように，その用いる手法も鮮やかに対照的に見えるが，積分は変分近似を通じて最適化問題としても解けるし，Lengevin 法や HMC などの最適化手法は積分問題を解ける．] | Integration and Marginalization | Optimization and Approximation |
| Objective | Uncertainty Quantification | Approximation of True Value |
| Emphasis | Modelling | Inference |

: Contrast of the two main approachs to Machine Learning {.striped .hover tbl-colwidths="[20,20,10]"}

しかし，機械学習の時代においては，互いの弱みを補間し合う形で発展していくと筆者は考える．特に，現状の[**推論偏重でモデリング軽視の風潮が，重要な実世界応用の多くを阻んでしまっている**]{.underline}．機械学習の世界樹は実は２本あるのである．

### ベイズと頻度論との違い

ベイズと頻度論では，確率の解釈も異なるかも知れないが，数学的枠組みとしてはベイズの方が一般的な枠組みであり，また手続き上は，モデリングを重視するか，推論を重視するかの違いでしかない．

実際，殆どの場合，頻度論的手法はある特定の事前分布を持ったベイズ手法とみなせ，逆も然りである．

データから推論を行うには，何らかの仮定が必ず必要であり，それを明示的にモデルに組み込むのがベイズで，推論アルゴリズムにより自動化する精神を持つのが頻度論的手法である．

その結果，優秀な推論アルゴリズムが日夜驚異的なスピードで提案され，今や機械学習手法は教師あり学習・教師なし学習・強化学習の全てで目覚ましい発展を見た．

しかし，ベイズと頻度論の２つの柱のバランスを欠いた発展はここまでである．今や，頻度論的な手法を採用した際に，自分たちがどのような仮定を置いたのか全く明瞭な知識を欠いてしまっている．一方で，現実のビッグで複雑なデータを扱うためには，もはや確率的なモデリングを避けては通れない．^[[@Broderick+2023] が極めて説得的にこの点を指摘している．]

極めて本質的で強大な敵に対面しつつあるのである．

だが，現状の病理は明らかであり，頻度論とベイズの手法の間に対応をつけ，足並みを揃えることで次の前進が約束されてる．この意味で，２つの世界樹が必要なのである．

[**ベイズ流解釈により手法を理解し，最適化流解釈により手法を実装する**]{.underline}．これがあるべき機械学習の未来であると筆者は考える．

<!--

ベイズ推論は帰納的推論の確率論的拡張と見れるため，確率論的なモデリングは，合理的な意思決定の基礎でもある．^[合理的な信念の度合い (degree of belief) は確率の公理を満たす必要がある，という主張は [Cox の名前でも呼ばれる](https://en.wikipedia.org/wiki/Cox%27s_theorem)．この点から，Bayes の定理は，帰納的推論の確率論的な拡張だとも捉えられる．]

そのため意思決定解析などの分野では古くからベイズの手法が用いられていたが，その他の分野ではモデリングを伴わない手法が好まれることが多かった．^[計算の困難さ，古典的には事前分布の設定が恣意的であること，現代的には MCMC のパラメータチューニングが難しい点などが，ユーザーフレンドリーではないこと，などが理由としてよく挙げられる．]

-->

### ２つの世界樹

今こそ，この２つの手法は根底では繋がっていることをよく周知し，この２つの視座を往来しながら適材適所に使うことが大事だと筆者は考える．

しかしそのためには，ベイズ機械学習の発展が遅れている現状を鑑みて，ベイズの手法のより一層の発展と理解の深化が必要である．^[現状，日本にてベイズ機械学習を専業として研究を進めている人は [Emtiyaz Khan](https://emtiyaz.github.io/) に限ると思われる．]

本章「ベイズ機械学習のすすめ」は，ベイズの手法の特に肝心と思われる３つの側面を指摘して終わる．以下３章を通じて，

1. 第 [-@sec-uncertainty-quantification] 節  [**ベイズは不確実性を定量化する**]{.underline}

    Bayes の方が不確実性の定量化が得意であるため，そのような応用先では頻度論的な手法よりも，Bayes バージョンの手法を用いることが出来ると便利である．

2. 第 [-@sec-distributional-representation] 節  [**ベイズは分布という共通言語を与える**]{.underline}

    Bayes による統一的な扱いが理論的に有用である場面が増えている．その際に，Bayes による理論解析と最適化による実際の推論という適材適所の協業が未来の方向であるかも知れない．

3. 第 [-@sec-inductive-bias] 節  [**ベイズは理解を促進する**]{.underline}

    ベイズの手法が敬遠されていた理由も，換言すれば，「事前分布」という得体の知れないものを通じて，理論的深淵と直結するためである．ベイズ手法の研究が理論的な解明を要請する．だからこそ，数学者の魂を持った者がこの途を通ることは人類に大きく資すると筆者は考える．

## ベイズは不確実性を定量化する {#sec-uncertainty-quantification}

### 不確実性の定量化の必要性

機械学習と統計学が単なる道具ではなく，人間のより大きなシステムの一環を単独で担う場面が増えてきた．例えば，

* 金融・経営・政策決定などの分野で，意思決定に繋げるデータ解析をするとき
* 科学において，発見や仮説を検証するためのデータ解析をするとき
* ロボットや自動車などの自動化をし，社会に実装するとき
* 医療診断や裁判などの場面で，専門家を補助するシステムを作るとき

これらのいずれの例でも，[**システムの一部を担うにあたって，不確実性を定量化しておくことが欠かせない**]{.underline}．その出力を用いるのが人間である場合も勿論，別の機械学習モデルである場合は尚更である．

つまり，人間社会で優秀であるだけでなくホウレンソウと信頼獲得も重要であるように，機械学習モデルも性能の高さと正確さだけでなく，いつその結果を信頼して良いのかを「どの程度」という指標と共に知らせてくれることが信頼関係の基本となるだろう．

実際，殆どの場面で，データから高い確証度で言えることと，そうではないことでは全く違う意味を持つ．それぞれの場面での例には，次のようなものがあるだろう：

* データから高い確証度で言えることと，意思決定者による采配が必要な部分を分離できない限り，意思決定プロセスの一部として組み込むことが難しく，結局機械学習手法が全く採用されないということもあり得る．
* 結果の再現可能性が科学の基本的な要請である以上，その結果の不確実性を実験結果に付記することは基本的な科学的態度である．後述（第 [-@sec-replication-crisis] 節）するが，$p$-値や信頼区間などの統計量は[**これに応えるものではない**]{.underline}．
* ロボットや自動車の自動化 AI システムは，いくつかのモデルを組み合わせて作ることになるだろう．個々が十分な性能を持っていても，小さな誤差が累積してシステムとしての性能を著しく低下させることがある．これを防ぐために，統一した方法での不確実性の取り扱いが必要である．
* 個々人の権利と法益が衝突する場面にも AI が利用されより良い生活が実現されるには，法的な解釈可能性が担保される必要があることが，実は大きな難関として我々を待っている．その第一歩は，不確実性の可視化になるだろう．^[モデルの予測結果に不確実性の定量化が伴われていたならば，モデルを信用出来ない場面で意思決定者がこれを信用したため責任があるのか，使用者には非難可能性がないのか，モデル設計者に過失があったと言えるのかの議論に，足場を与えることが出来るだろう．]

以上の内容は，結果の **解釈可能性** でも全く同じことが言えるだろう．

### 信頼のおける AI システム

上述の点をまとめると，機械学習手法と人間社会がよりよく共生していくには AI の **信頼性** (trustworthyness) が必要とされているのである．不確実性の定量化と解釈可能性は，AI が人間社会で信頼を獲得するにあたって根本的な要素になるだろう．

現状の手法の延長でこの信頼性の問題は扱えず，新たな手法が必要とされている．Bayesian approach や probabilistic approach と呼ばれている試みは，まさにこれに応えるものであり，近年急速に発展している．

### 不確実性を扱うには Bayes が必要である {#sec-Bayes-for-uncertainty-quatification}

実装は頻度論的な手法の方が簡単で高速であることが多いが，不確実性の定量化には向かない．

このような場面では，頻度論的手法を頻度論的に改善する，という方向は筋が悪いと思われる．**このようなときこそ，もう一つの世界樹であるベイズの方法を用いるべきである**．

これを，科学における再現性の危機を例にとって確認したい．^[[@Gal-Ghahramani2016] も参照．]

#### 再現性の危機 {#sec-replication-crisis}

多くの実験科学では不確実性の定量化が必要不可欠である [@Krzywinski-Altman2013]．

> It is necessary and true that all of the things we say in science, all of the conclusions, are uncertain ... [@Feynman1998]

[**再現性の危機** ](https://ja.wikipedia.org/wiki/%E5%86%8D%E7%8F%BE%E6%80%A7%E3%81%AE%E5%8D%B1%E6%A9%9F) (replication crisis) とは，多くの実験において報告されている統計的有意性が，再現実験において得られないことが多いという問題を指し，2010年代の初めから多くの科学分野において問題として取り上げられてきた．^[心理学においては「再現性問題が大きく注目される大きな契機となった「超能力論文」が出版されたのが 2011 年である」 [@平石-中村2022] ようである．計量経済学における **信頼性革命** [@Angrist-Pischke2010] は，再現性の危機の，もう一つの革新的な解決法である．]

その理由は明白である．**信頼区間は集合値の推定量であるため，「分散」が十分大きいならば，データセットを変えて何回も計算することでいずれは非自明なものを得ることが出来るのである**．そのため，信頼区間や $P$-値を報告するだけでは，結果の信頼性については何も保証されないのである．

その結果多くの科学分野では **Bayes 統計学による不確実性の定量化に移行しつつある** [@Herzog-Ostwald2013], [@Trafimow-Marks2015], [@Nuzzo2014]．

信頼区間と信用区間の違いに注目して，その違いを解説する．

#### 信頼区間と信用区間

「95 % の信頼区間」と言ったとき，「95 % の確率で真の値がその範囲に含まれるような区間」だと思いがちであるが，これはどちらかというと信用区間の説明であり，**信頼区間は計算するごとに値が変わってしまう確率変数である** ことを見落としがちである．^[「それでは，信頼区間は不確実性の正しい定量化を与えないではないか！」ということになるが，その通りなのである．$P$-値を計算する過程とは，帰無仮説で条件付けているだけであり，データの関数でもある．$P$-値の確率変数としての分散が大きいほど，何回か同じ実験を繰り返せばすぐに小さな $P$-値が得られることになる．これは [**基準確率の誤謬**](../../2023/%E6%95%B0%E7%90%86%E6%B3%95%E5%8B%99/%E6%B3%95%E5%BE%8B%E5%AE%B6%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E7%B5%B1%E8%A8%88%E6%95%B0%E7%90%862.qmd#sec-Bayes-problem) と似ている．]

つまり，信頼区間は頻度論的な概念であり，「真の値」がまず存在し，区間自体が変動し，95 % の確率で被覆するというのである．今回見ている信頼区間が，別のデータセットで計算した場合にどう変わるかについては全く未知である．

このことは，信頼区間は「真のパラメータの値」で条件づけて得るものであるが，信用区間はデータによって条件づけて得るものであるという点で違う，とまとめられる．この２つの混同は「何で条件づけているか？」を意識することで回避することができる．^["Confidence intervals suffer from an inverse inference problem that is not very different from that suffered by the NHSTP. In the NHSTP, the problem is in traversing the distance from the probability of the finding, given the null hypothesis, to the probability of the null hypothesis, given the finding." [@Trafimow-Marks2015]]

誤解を恐れず言うならば，再現性の危機とは，信頼区間というサイコロの出目によって科学が踊らされていたということに他ならない [@Nuzzo2014]．^[[@Nuzzo2014] には，Fisher が最初に用いてから，Neyman-Pearson 理論がこれを排除したものの，コミュニティが $P$-値を誤解して都合の良いように利用するようになるまでに至った歴史が説明されている．]

#### なぜベイズを用いれば良いのか？

これは，信頼区間や $P$-値などの頻度論的な手法は，しばしば尤度原理に違反するためである．^[[@Murphy2022 p.201] の議論も参照．]

換言すれば，何らかのモデルと事前分布に関するベイズ手法と等価である，すなわち，Bayesianly justifiable [@Rubin1984] とみなせない手法は，何らかの意味でデータを十分に反映できていない可能性が高くなる．

従って，ベイズの手法が原理的に最も適切である場面が多い．一方でその計算の困難さや，全てのステップをモデリング段階に組み込む点を回避するために，種々の頻度論的な実装は考え得て，頻度論的な手法はそのような運用においては健全であるとの指標にもなる．^[[@Efron1986] も示唆深い．]

Bayes により手法を理解し，頻度論的に手法を実装することが，あるべき姿勢であると思われる．

> The applied statistician should be Bayesian in principle and calibrated to the real world in practice. [@Rubin1984]

### ベイズ深層学習という夢

深層モデルはその性能の高さから，最も実世界応用が期待されるモデルであるが，パラメータが極めて多いため，特にベイズ化することが難しいと言われている．

例えば，ハルシネーション (hallucination) として，LLM が「事実に基づかない」情報を生成してしまうことが問題とされているが，これも不確実性の定量化の問題に他ならない．^[[@Mohri-Hashimoto2024] なども指摘している．]

その他の場面でも，不確実性の定量化には conformal prediction などの事後的な手法が試みられている．^[[@Novello+2024] では out-of-distribution detection, [@Mohri-Hashimoto2024] は LLM の hallucination への応用．] これらはどのようなブラックボックスに対しても適用可能である一方で，対症療法というべきものであり，ベイズ流の解釈をすることで直接的に事後分布を求めるという根本的な解決にも，もっと注力されるべきである．

ベイズによる不確実性の定量化は，自然であるだけでなく，より有用な不確実性の定量化を与えるものだと予想している．

筆者は，conformal prediction などの post-hoc な手法は，便利かも知れないが，「信頼区間」や「$P$-値」のような側面（第 [-@sec-Bayes-for-uncertainty-quatification] 節）も併せ持つのではないかと危惧しながら見ている．

### 分野全体の動向

現状の機械学習モデルと実応用との乖離は，他の側面でも生じている．

まず，訓練データが実際の運用環境を十分に反映できていないということは極めて頻繁に起こるだろう．この現象を **分布シフト** といい，機械学種モデルの予測性能だけで無く，分布外汎化 (out-of-distribution generalization) 能力も重視するという潮流が生じている．

さらに，一度訓練したモデルを，分布シフト自体が移り変わっていく環境で，微調整のみによって繰り返し使い続けるという使用を想定した **継続学習** (continual learning) という考え方もある．^[[@Wamg+2024] が最新のサーベイであるようだ．]

章を変えて別の角度から議論を続けよう．

## ベイズは分布という共通言語を与える {#sec-distributional-representation}

### 継続学習という発想

継続学習は，機械学習モデルをより動的で実際的な環境でも使えるようにするための新たな枠組みである．そこまで，教師あり学習モデルがすでに実用的な性能を獲得したということでもある．

つまり，単に「教師あり」「教師なし」の１タスクを解く営みは爛熟しつつあり，機械学習の理論と応用の最先端は，より深い森に分け入りつつあるのである．

ここにおいて，ベイズ流の接近が統一的な取り扱いを与えるという美点が，さらに重要でもはや必要不可欠な役割を果たすものと思われる．

#### ベイズ推論が与える統一的枠組み

ベイズ推論とは，**事前分布** というものを設定して，これをデータによって更新するという営みである（その更新規則は Bayes の公式が与える）．

事前分布をどう設定すれば良いか？の問題は，ベイズ推論の初期からの問題であった．極めて自由度が高いことが，逆にベイズ推論が実際のデータ解析の場面において敬遠される一因ともなっていた．

#### ベイズと最適化との協業

しかし，継続学習が当たり前になった社会において，全てのパラメータ値を事前分布と事後分布とみなし，全ての学習過程をベイズの公式という統一的な方法で更新すると捉えられることは，極めて大きな利点になり得る．

というのも，継続学習においては，学習を繰り返すうちに過去に学んだ内容を忘れ去ってしまうという **壊滅的忘却** (catastrophically forgetting) が最大の困難である．

理論的には，分布のベイズ更新の繰り返しとして見る方が極めて見通しが良い．一方で，事後分布の近似が十分でない場合，実際にベイズ更新を行うことは性能に悪影響を与える．

そこで，理論解析や設計をベイズの観点から行い，実際の推論は最適化ベースで行うという適材適所により，壊滅的忘却を緩和できる可能性がある [@Farquhar-Gal2019]．

### モデルの属人化

大きなデータも，属人化医療や推薦システムなど多くの文脈では小さなデータの寄せ集めであり，そうでなくともその構造を正しく捉え，全ての不確実性を取り入れた柔軟なモデリングをすることで，さらに密接な形で社会に取り入れることができる．^[[@Ghahramani2015 p.458] はこれを **モデルの属人化** (personalization of models) と呼んでいる．]

> Although considerable challenges remain, the c ing decade promises substantial advances in artificial intelligence and machine learning based on the probabilistic framework. [@Ghahramani2015]

### 例：強化学習への分布によるアプローチ

> we believe the value distribution has a central role to play in reinforcement learning. [@Bellemare+2017]

## ベイズは理解を促進する {#sec-inductive-bias}

我々はもはや機械学習を通じて，自分たちが何をやっているのかわかっていない．この愚かさを AI に継がせてはならない．

### なぜベイズ法の発展が遅れたか？

ベイズ法の採用は，自分たちが何をやっているかへの理解と解釈可能性を刺激するという側面がある．

その理由は簡単である．ベイズ推論は，モデルとその上の事前分布を定めれば，あとはベイズ更新規則をどう計算するかの問題となり，近似手法は様々あれど，**もはや推論手法に選択の余地はない**．

換言すれば，その分解析者がモデルと事前分布の特定を全てこなす必要があるのであり，**解析者に確率モデリングへの理解を強要する**ところがある．

しかしこれは「面倒なことは全てアルゴリズムにやってほしい」という精神とは対立するため，ベイズの美点であると同時に，ベイズの発展を阻害してきた遠因の一つでもあった．

これを指して「事前分布の選択に恣意性が入る」という通り文句がよく使われるが，[実際は，頻度論的手法における「どのような目的関数をどのように最適化すれば良いか？」という恣意性に変換されているのみであり，問題を先送りにして，「ベイズ法 対 頻度論的手法」という虚構の対立を作り上げているのみである]{.underline}．

機械学習のポテンシャルが具現化したいまこそ，この困難に立ち向かう必要があるが，この問題は最適化や頻度論的な立場から見るより，ベイズの立場から見た方が，理論的な見通しが良いようである（第 [-@sec-Bayesian-rule] 節）．

### 帰納バイアスの明確化の必要性

機械学習の真の理解のためには，各モデルの帰納バイアスを明確化する必要がある．

#### 帰納バイアスとは何か？

現状の AI システムは大量のラベル付きデータが必要であり，多くの現実的に有用なタスクでこのような教師データが用意できるわけではない．

一方で，人間は遥かに少ないデータから効率的に学習することができる．

![Number of Training Tokens [BabyLM Challenge](https://babylm.github.io/)](../Kernels/Images/model_sizes.png)

その違いは，進化が我々生物に授けた **帰納バイアス** にあると考えられている．

我々には遺伝的に継がれている生まれ持った学習特性があり，より効率的に学習出来るのかも知れない．

事実，一度事前学習をした LLM は，極めて少ないデータにより新しいタスクを学習することができるがわかりつつある [@Zhou+2023]．[LLM の事後調整に関する稿](../Kernels/Deep2.qmd#sec-foundation-model) も参照．

#### 事前分布に向き合わずにやり過ごしてきた

現状，多くの機械学習手法は確率的な方法を取っていない．これは事前分布を明示せずに（ひょっとしたら明後日の方向に向かって）行われる Bayes 学習手法であるとみなせる．

現状の機械学習の成功は，事前分布に関する知識なしに到達されたものであり，それ故の限界がある．例えば，現状のままではモデルにどのような帰納バイアスが組み込まれているか不明瞭である．^[Philipp Hennig [_Probabilistic ML - Lecture 1 - Introduction_](https://youtu.be/TTo2kjrAuTo?si=QD_pqMkdLOl52OsR&t=3703) "Statistical Learning Theory is about Bayesian Reasoning when you don't say out aloud what the prior is."]

#### 帰納バイアスに対するベイズ的視点

データの空間 $\cX$ 上の任意のモデル $\cM$ の周辺尤度 $p(x|\cM)$ は，^[これを [**証拠**](https://en.wikipedia.org/wiki/Marginal_likelihood) (model evidence) ともいう．] ベイズ流には事後確率として捉えられ，全てのデータ $x\in\cX$ 上に有限な測度を定める．^[事前分布として非有限な測度を用いた場合など，例外もある．]

よって，**全てのモデルは，あるデータを得意とするならば他のデータについては不得意であることを免れない**．これは no free lunch 定理と呼ばれる定理の一群により推測されており，分類問題などの簡単なタスクを除いて完全な形式的表現はまだ持たない作業仮設である．

![A Probabilistic Perspective of Genelization [@Wilson-Izmailov2020]](Images/mackay.png)

例えば，[基盤モデル](../Kernels/Deep2.qmd#sec-fine-tuning) とは，インターネット上のデータから最大限人間の言語というものに関する帰納バイアスを取り込んだ，パラメータ上の初期設定であると見れる．

これは，あるパラメータ空間上の理想的な事前分布からのサンプリングであるかも知れない．それ故，種々の下流タスクに対して，小さなモデル変更のみにより適応することが出来る．

大規模言語モデルの能力創発現象は，帰納バイアスを十分取り込むことにより自然に解かれるタスクであったのかもしれない．

#### worst-case analysis からの脱皮

帰納バイアスを明確にせず，やり過ごしてきたつけが，特に学習理論においても現れている．

現状の統計的学習理論は全て，worst-case analysis であるが，実用上は全くそうではない．「動くモデル」には暗黙の帰納バイアスが入っており，これに明るくなる必要があるのである．

2024 年に生きる我々は，worst-case analysis からの脱皮を迫られている．

### 数学者の哲学

Bayes の見方は，機械学習モデルを底流する数理的枠組みになっている．仮に次の [Mac Lane](https://ja.wikipedia.org/wiki/%E3%82%BD%E3%83%BC%E3%83%B3%E3%83%80%E3%83%BC%E3%82%B9%E3%83%BB%E3%83%9E%E3%83%83%E3%82%AF%E3%83%AC%E3%83%BC%E3%83%B3) の言葉が数学者のあるべき態度の１つであるとするならば，数学者には Bayes の立場から機械学習を研究することを特におすすめできる．

>  However, I persisted in the position that **as mathematicians we must know whereof we speak**, be it a homotopy group or an adjoint functor. [@MacLane1983 p.55]

数理統計学に始まり，数学者の統計や機械学習分野への参入は，推論手法の解析が想像されるかも知れない．

しかし，真の数学的理解は，手法の数学的な機械仕掛けを紐解くだけでなく，それぞれの手法がモデルとしてどのような仮定の下で成り立っているかを，モデリングの観点から理解することにあると筆者には思われる．

個々の数学的な道具に捉われず，大局的な視点を持ちたい．

推論とモデリングという双対的な営みは，深い数理的な構造を持っていることが明らかになりつつあり，その解明と理論構築には，ベイズの観点から光を照らしてくれるような，Mac Lane の意味での数学者的な魂が必要とされているのである．

#### Bayes の数学

Bayes の観点から

#### Bayes に繋げる数学

通常の頻度論的手法は，うまくいくことが先であり，理論が後付けされる．そしてその理論もどこか ad-hoc というべきであり，worst-case で漸近論的である．

これらに Bayes 的な解釈を与えることで，暗黙のうちにどのような仮定を課しているモデリング手法に相等するのか明確にされる．特に，非漸近論的な知見を与えてくれる数少ないの道の一つである．

### ベイズ推論とみる美点 {#sec-Bayesian-rule}

ベイズ推論自体への理解だけでなく，種々の頻度論的手法を，特定の環境下でのベイズ推論の近似として理解することは，新たなアルゴリズムの開発に有用であるという合意が形成されつつあるようである．

最適化に基づく手法の計算効率性は，正確なベイズ推論に勝る場面も多い．ここで注意すべきは，ベイズ推論の実行が肝要であり，その実装は最適化に依ろうと，積分近似に依ろうと大した違いではないのである．

「ベイズ推論は多くの最尤法に基づく手法よりも，自然な正則化がなされるために過学習の問題がない．」と説明されるが[**本来は逆である**]{.underline}．多くの最適化に基づく手法は，目的関数の選択に恣意性があり，その選択を誤り続けているために過学習という問題が生じている，という方が，後世の教科書に載る表現なのではないかと筆者は考えている．

どのような目的関数をどのように最適化すれば良いか？

#### 例：強化学習

強化学習でも，学習と制御をベイズ推論と見ることが，アルゴリズムの設計において有用であることが提唱されつつある：

> Crucially, in the framework of PGMs, it is sufficient to write down the model and pose the question, and the objectives for learning and inference emerge automatically. [@Levine2018]










## Bayes 機械学習の例

### Bayes 深層学習

### 確率的グラフィカルモデル

歴史的に，（確率的）モデリングは，主に（確率的）グラフィカルモデルを通じて機械学習の分野に導入された．

そのため，20世紀に入ったばかりの頃は，Bayes 機械学習の唯一の例は確率的グラフィカルモデルなのであった．^[[@Neal-Hinton1998] など．]

### 推論アルゴリズムのプログラミングから，モデルのプログラミングへ

シミュレーターがあれば推論ができるというのが Bayes 計算の強みである．

そこで，推論手法をこれで統一し，解析者はモデルの構築に集中すれば良い，という新たなパラダイムを **確率的プログラミング** (Probabilistic Programming) と呼ぶ．


### Bayes 最適化

### データ圧縮

### 階層モデルと統計モデルの自動発見

