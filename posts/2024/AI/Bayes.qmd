---
title: "ベイズとは何か"
subtitle: "数学による統一的アプローチ"
author: "司馬博文"
date: "4/28/2024"
categories: [Slide]
format:
  html: default
  revealjs: 
    output-file: Bayes_slide.html
    slide-number: true
    show-slide-number: all
    chalkboard: 
      buttons: false
    preview-links: auto
    logo: ../../../assets/profile.jpg
    css: ../../../assets/slides.css
    footer: |
      [司馬博文](https://162348.github.io/posts/2024/AI/Bayes.html)
    scrollable: true
    smaller: true
    controls: true
    controls-layout: bottom-right
    self-contained-math: true
    toc: true
    toc-depth: 1
    toc-title: 目次
    number-sections: true
    theme: serif
  pptx:
    slide-number: true
format-links: [revealjs, pptx]
bibliography: 
    - ../../../assets/mathematics.bib
    - ../../../assets/bib.bib
csl: ../../../assets/apalike.csl
# description: |
#   井形研 RA 半導体読書会<br>
#   駒場IIキャンパス４号館
image: Images/Bayes.svg
comment: false
---


{{< include ../../../_preamble.qmd >}}

::: {.nonincremental}

- [トーマス・ベイズ 1701-1706](https://ja.wikipedia.org/wiki/%E3%83%88%E3%83%BC%E3%83%9E%E3%82%B9%E3%83%BB%E3%83%99%E3%82%A4%E3%82%BA)：イギリスの牧師・数学者
- ベイズの定理：確率論において，条件付き確率の計算手段を与える定理
- ベイズ○○：○○（分野名）におけるベイズの定理の応用
    - 例：ベイズ統計，ベイズ機械学習，ベイズ推論，……
    - 例外：ベイズ計算（ベイズの定理の通りに実際に計算をするための**計算手法の総称**）

:::

多くの応用を持つが，原理は同一である．

ベイズ深層学習，ベイズ最適化，……

# Who: ベイズとは誰か？

## 始まりは区間推定の問題であった

:::: {.columns}


::: {.column width="50%"}
::: {.callout-tip icon="false" title="ベイズが取り組んだ問題（現代語訳）^[[@Bayes1763]]"}
２値の確率変数は $Y_i\in\{0,1\}$ はある確率 $\theta\in(0,1)$ で $1$ になるとする：
$$
Y_i=\begin{cases}
1&\text{確率 }\theta\text{ で}\\
0&\text{残りの確率} 1-\theta\text{ で}
\end{cases}
$$
このような確率変数の独立な観測 $y_1,\cdots,y_n$ から，ある区間 $(a,b)\subset[0,1]$ に $\theta$ が入っているという確率を計算するにはどうすれば良いか？
:::
:::

::: {.column width="50%"}
* 決定的特徴：未知のパラメータ $\theta$ に対する確率分布を考えている．
* 与えられている観測のモデル $p(y|\theta)$ に対して，逆の条件付き確率 $p(\theta|y)$ を考えれば良い．
* そのための計算公式として「ベイズの定理」を導いた [@Bayes1763]．
:::

::::

# What: ベイズとは何か？

## ベイズの定理

::: {.callout-tip icon="false" title="ベイズの定理^[[@Shiryaev2016 p.272] (34) も参照．]"}
任意の可積分関数 $g$，確率変数 $\Theta\sim\P^\Theta$，部分 $\sigma$-代数 $\cG$ について，
$$
\E[g(\Theta)|\cG](\om)=\frac{\int_\R g(\theta)p(\om|\theta)\P^{\Theta}(d\theta)}{\int_\R p(\om|\theta)\P^\Theta(d\theta)}\;\as\,\om
$$
:::

一般には次の形で使う：
$$
p(\theta|x)=\frac{p(x|\theta)p(\theta)}{\int_\Theta p(x|\theta)p(\theta)\,d\theta}
$$

::: {.callout-note title="証明" icon="false" collapse="true"}
確率空間を $(\Om,\F,\P)$，確率変数 $\Theta$ は可測関数 $\Om\to\cX$，可積分関数は $g\in\L(\cX)$ とし，定理の式は確率測度 $\P$ に関して確率 $1$ で成り立つという意味であるとした．

可測空間 $(\Om,\cG)$ 上の測度 $\operatorname{Q}$ を
$$
\operatorname{Q}(B):=\int_B g(\theta(\om))\P(d\om),\qquad B\in\cG
$$
と定めると，
$$
\E[g(\Theta)|\cG]=\dd{\operatorname{Q}}{\P}.
$$
なお，この定理は暗黙に条件付き期待値 $\P[B|\Theta]$ は正則で，$(\Om,\cG)$ 上の $\sigma$-有限な参照測度 $\lambda$ に対して次の密度を持つことを仮定した：
$$
\P[B|\Theta=\theta]=\int_B p(\om|\theta)\lambda(d\om).
$$
この下では，Fubini の定理から
$$
\begin{align*}
  \P[B]&=\int_\R\P[B|\Theta=\theta]\P^\Theta(d\theta)\\
  &=\int_B\int_\R p(\om|\theta)\P^\Theta(d\theta)\lambda(d\om)
\end{align*}
$$
$$
\begin{align*}
  \operatorname{Q}[B]&=\E[g(\Theta)\E[1_B|\sigma[\Theta]]]\\
  &=\int_\R g(\theta)\P[B|\Theta=\theta]\P^\Theta(d\theta)\\
  &=\int_B\int_\R g(\theta)p(\om|\theta)\P^\Theta(d\theta)\lambda(d\om).
\end{align*}
$$
よってあとは
$$
\dd{\operatorname{Q}}{\P}=\dd{\operatorname{Q}/d\lambda}{\P/d\lambda}\;\P\das
$$
を示せば良い．これは [@Shiryaev2016 p.273] に譲る．
:::

## ベイズ推論のもう一つのピース「事前分布」

## 帰納的推論の確率的拡張としてのベイズ推論

## 生物の不確実性の下での推論のモデルとしてのベイズ推論

* 脳の平時の活動は経験的事前分布を表現していると解釈できる [@Berkes+2011]

* 脳の神経回路はベイズ推論（正確には，事後分布からのサンプリング）を行っている可能性がある [@Terada-Toyoizumi2024]

# How: ベイズはどう使うのか？

## 「ベイズ計算」という分野

$$
p(\theta|x)=\frac{p(x|\theta)p(\theta)}{\int_\Theta p(x|\theta)p(\theta)\,d\theta}
$$

* ベイズの定理で終わりじゃない．

    →「どう実際に計算するか？」（特に分母の積分が問題）

* ベイズ統計，ベイズ機械学習…… はすべてベイズの定理を使っている．

    →効率的で汎用的な計算方法を１つ見つければ，多くの応用分野に資する．

## 「ベイズ計算」の問題意識

* 受験問題で出題される積分問題は，解析的に解ける異例中の異例

* 加えて，「解析的に解ける」もののみを扱うのでは，モデリングの幅が狭すぎる

どんな関数 $p(x|\theta),p(\theta)$ に対しても積分
$$
\int_\Theta p(x|\theta)p(\theta)\,d\theta
$$
が計算できる方法が欲しい．

## 積分はどう計算すれば良いか？

* 数値積分（グリッド法）

    → Riemann 積分の定義を地で行く計算法

    → ３次元以上でもう現実的には計算量が爆発する

* モンテカルロ積分法

    → 確定的なグリッドを用いるのではなく，乱数を用いる

> It is evidently impractical to carry out a several hundred-dimensional integral by the usual numerical methods, so we resort to the Monte Carlo method. [@Metropolis+1953 p.1088]

# When: ベイズはいつ使えるか？

# Why: なぜベイズなのか？

# 参考文献 {.appendix}