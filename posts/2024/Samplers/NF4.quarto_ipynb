{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"ニューラル常微分方程式\"\n",
        "subtitle: \"`PyTorch` によるハンズオン\"\n",
        "author: \"司馬博文\"\n",
        "date: 8/20/2024\n",
        "image: Files/nonlinear/output.gif\n",
        "categories: [Deep, Sampling, Python]\n",
        "bibliography: \n",
        "    - ../../../assets/2023.bib\n",
        "    - ../../../assets/2024.bib\n",
        "    - ../../../assets/2025.bib\n",
        "csl: ../../../assets/apalike.csl\n",
        "abstract-title: 概要\n",
        "abstract: Gauss 分布からデータ分布までの変換を，可逆なニューラルネットワークでモデリングする正規化流は，ODE に基づいて設計することもできる．この方法は Neural ODE や連続な正規化流 (CNF) ともいう．今回は `PyTorch` を用いて，正規化流の実装の概要を見る．\n",
        "code-fold: false\n",
        "listing: \n",
        "    -   id: flow-listing\n",
        "        type: grid\n",
        "        sort: false\n",
        "        contents:\n",
        "            - \"NF.qmd\"\n",
        "            - \"NF1.qmd\"\n",
        "            - \"NF2.qmd\"\n",
        "        date-format: iso\n",
        "        fields: [title,image,date,subtitle]\n",
        "---\n",
        "\n",
        "::: {.hidden}\n",
        "\n",
        "::: {.content-visible when-format=\"html\"}\n",
        "\n",
        "A Blog Entry on Bayesian Computation by an Applied Mathematician\n",
        "\n",
        "$$\n",
        "\n",
        "\\renewcommand{\\P}{\\operatorname{P}}\\newcommand{\\E}{\\operatorname{E}}\n",
        "\\newcommand{\\R}{\\mathbb{R}}\\newcommand{\\F}{\\mathcal{F}}\n",
        "\\newcommand{\\abs}[1]{\\lvert#1\\rvert}\\newcommand{\\Abs}[1]{\\left|#1\\right|}\\newcommand{\\ABs}[1]{\\biggl|#1\\biggr|}\\newcommand{\\norm}[1]{\\|#1\\|}\\newcommand{\\Norm}[1]{\\left\\|#1\\right\\|}\\newcommand{\\NOrm}[1]{\\biggl\\|#1\\biggr\\|}\\newcommand{\\Brace}[1]{\\left\\{#1\\right\\}}\\newcommand{\\BRace}[1]{\\biggl\\{#1\\biggr\\}}\\newcommand{\\paren}[1]{\\left(#1\\right)}\\newcommand{\\Paren}[1]{\\biggr(#1\\biggl)}\\newcommand{\\brac}[1]{\\langle#1\\rangle}\\newcommand{\\Brac}[1]{\\left\\langle#1\\right\\rangle}\\newcommand{\\BRac}[1]{\\biggl\\langle#1\\biggr\\rangle}\\newcommand{\\bra}[1]{\\left\\langle#1\\right|}\\newcommand{\\ket}[1]{\\left|#1\\right\\rangle}\\newcommand{\\Square}[1]{\\left[#1\\right]}\\newcommand{\\SQuare}[1]{\\biggl[#1\\biggr]}\\newcommand{\\rN}{\\operatorname{N}}\\newcommand{\\ov}[1]{\\overline{#1}}\\newcommand{\\un}[1]{\\underline{#1}}\\newcommand{\\wt}[1]{\\widetilde{#1}}\\newcommand{\\wh}[1]{\\widehat{#1}}\\newcommand{\\pp}[2]{\\frac{\\partial #1}{\\partial #2}}\\newcommand{\\ppp}[3]{\\frac{\\partial #1}{\\partial #2\\partial #3}}\\newcommand{\\dd}[2]{\\frac{d #1}{d #2}}\\newcommand{\\floor}[1]{\\lfloor#1\\rfloor}\\newcommand{\\Floor}[1]{\\left\\lfloor#1\\right\\rfloor}\\newcommand{\\ceil}[1]{\\lceil#1\\rceil}\\newcommand{\\ocinterval}[1]{(#1]}\\newcommand{\\cointerval}[1]{[#1)}\\newcommand{\\COinterval}[1]{\\left[#1\\right)}\\newcommand{\\iso}{\\overset{\\sim}{\\to}}\n",
        "\n",
        "\n",
        "\n",
        "\\newcommand{\\y}{\\b{y}}\\newcommand{\\mi}{\\,|\\,}\\newcommand{\\Mark}{\\mathrm{Mark}}\n",
        "\\newcommand{\\argmax}{\\operatorname*{argmax}}\\newcommand{\\argmin}{\\operatorname*{argmin}}\n",
        "\n",
        "\\newcommand{\\pr}{\\mathrm{pr}}\\newcommand{\\Conv}{\\operatorname{Conv}}\\newcommand{\\cU}{\\mathcal{U}}\n",
        "\\newcommand{\\Map}{\\mathrm{Map}}\\newcommand{\\dom}{\\mathrm{Dom}\\;}\\newcommand{\\cod}{\\mathrm{Cod}\\;}\\newcommand{\\supp}{\\mathrm{supp}\\;}\n",
        "\\newcommand{\\grad}{\\operatorname{grad}}\\newcommand{\\rot}{\\operatorname{rot}}\\renewcommand{\\div}{\\operatorname{div}}\\newcommand{\\tr}{\\operatorname{tr}}\\newcommand{\\Tr}{\\operatorname{Tr}}\\newcommand{\\KL}{\\operatorname{KL}}\\newcommand{\\JS}{\\operatorname{JS}}\\newcommand{\\ESS}{\\operatorname{ESS}}\\newcommand{\\MSE}{\\operatorname{MSE}}\\newcommand{\\erf}{\\operatorname{erf}}\\newcommand{\\arctanh}{\\operatorname{arctanh}}\\newcommand{\\pl}{\\operatorname{pl}}\\newcommand{\\minimize}{\\operatorname{minimize}}\\newcommand{\\subjectto}{\\operatorname{subject to}}\\newcommand{\\sinc}{\\operatorname{sinc}}\\newcommand{\\Ent}{\\operatorname{Ent}}\\newcommand{\\Polya}{\\operatorname{Polya}}\\newcommand{\\Exp}{\\operatorname{Exp}}\\newcommand{\\codim}{\\operatorname{codim}}\\newcommand{\\sgn}{\\operatorname{sgn}}\\newcommand{\\rank}{\\operatorname{rank}}\n",
        "\n",
        "\\newcommand{\\vctr}[2]{\\begin{pmatrix}#1\\\\#2\\end{pmatrix}}\\newcommand{\\vctrr}[3]{\\begin{pmatrix}#1\\\\#2\\\\#3\\end{pmatrix}}\\newcommand{\\mtrx}[4]{\\begin{pmatrix}#1&#2\\\\#3&#4\\end{pmatrix}}\\newcommand{\\smtrx}[4]{\\paren{\\begin{smallmatrix}#1&#2\\\\#3&#4\\end{smallmatrix}}}\\newcommand{\\Ker}{\\mathrm{Ker}\\;}\\newcommand{\\Coker}{\\mathrm{Coker}\\;}\\newcommand{\\Coim}{\\mathrm{Coim}\\;}\\newcommand{\\lcm}{\\mathrm{lcm}}\\newcommand{\\GL}{\\mathrm{GL}}\\newcommand{\\SL}{\\mathrm{SL}}\\newcommand{\\alt}{\\mathrm{alt}}\n",
        "\n",
        "\\renewcommand{\\Re}{\\mathrm{Re}\\;}\\renewcommand{\\Im}{\\mathrm{Im}\\,}\\newcommand{\\Gal}{\\mathrm{Gal}}\\newcommand{\\PGL}{\\mathrm{PGL}}\\newcommand{\\PSL}{\\mathrm{PSL}}\\newcommand{\\Log}{\\mathrm{Log}\\,}\\newcommand{\\Res}{\\mathrm{Res}\\,}\\newcommand{\\on}{\\mathrm{on}\\;}\\newcommand{\\hatC}{\\widehat{\\C}}\\newcommand{\\hatR}{\\hat{\\R}}\\newcommand{\\PV}{\\mathrm{P.V.}}\\newcommand{\\diam}{\\mathrm{diam}}\\newcommand{\\Area}{\\mathrm{Area}}\\newcommand{\\Lap}{\\Laplace}\\newcommand{\\f}{\\mathbf{f}}\\newcommand{\\cR}{\\mathcal{R}}\\newcommand{\\const}{\\mathrm{const.}}\\newcommand{\\Om}{\\Omega}\\newcommand{\\Cinf}{C^\\infty}\\newcommand{\\ep}{\\epsilon}\\newcommand{\\dist}{\\mathrm{dist}}\\newcommand{\\opart}{\\o{\\partial}}\\newcommand{\\Length}{\\mathrm{Length}}\n",
        "\n",
        "\\newcommand{\\cA}{\\mathcal{A}}\\newcommand{\\cO}{\\mathcal{O}}\\newcommand{\\cW}{\\mathcal{W}}\\renewcommand{\\O}{\\mathcal{O}}\\renewcommand{\\S}{\\mathcal{S}}\\newcommand{\\U}{\\mathcal{U}}\\newcommand{\\V}{\\mathrm{V}}\\newcommand{\\N}{\\mathbb{N}}\\newcommand{\\bN}{\\mathbb{N}}\\newcommand{\\C}{\\mathrm{C}}\\newcommand{\\bC}{\\mathbb{C}}\\newcommand{\\Z}{\\mathcal{Z}}\\newcommand{\\Q}{\\mathbb{Q}}\\newcommand{\\bQ}{\\mathbb{Q}}\\newcommand{\\TV}{\\mathrm{TV}}\\newcommand{\\ORD}{\\mathrm{ORD}}\\newcommand{\\Card}{\\mathrm{Card}\\,}\\newcommand{\\Top}{\\mathrm{Top}}\\newcommand{\\Disc}{\\mathrm{Disc}}\\newcommand{\\Codisc}{\\mathrm{Codisc}}\\newcommand{\\CoDisc}{\\mathrm{CoDisc}}\\newcommand{\\Ult}{\\mathrm{Ult}}\\newcommand{\\ord}{\\mathrm{ord}}\\newcommand{\\bS}{\\mathbb{S}}\\newcommand{\\PConn}{\\mathrm{PConn}}\\newcommand{\\mult}{\\mathrm{mult}}\\newcommand{\\inv}{\\mathrm{inv}}\n",
        "\n",
        "\\newcommand{\\Der}{\\mathrm{Der}}\\newcommand{\\osub}{\\overset{\\mathrm{open}}{\\subset}}\\newcommand{\\osup}{\\overset{\\mathrm{open}}{\\supset}}\\newcommand{\\al}{\\alpha}\\newcommand{\\K}{\\mathbb{K}}\\newcommand{\\Sp}{\\mathrm{Sp}}\\newcommand{\\g}{\\mathfrak{g}}\\newcommand{\\h}{\\mathfrak{h}}\\newcommand{\\Imm}{\\mathrm{Imm}}\\newcommand{\\Imb}{\\mathrm{Imb}}\\newcommand{\\Gr}{\\mathrm{Gr}}\n",
        "\n",
        "\\newcommand{\\Ad}{\\mathrm{Ad}}\\newcommand{\\finsupp}{\\mathrm{fin\\;supp}}\\newcommand{\\SO}{\\mathrm{SO}}\\newcommand{\\SU}{\\mathrm{SU}}\\newcommand{\\acts}{\\curvearrowright}\\newcommand{\\mono}{\\hookrightarrow}\\newcommand{\\epi}{\\twoheadrightarrow}\\newcommand{\\Stab}{\\mathrm{Stab}}\\newcommand{\\nor}{\\mathrm{nor}}\\newcommand{\\T}{\\mathbb{T}}\\newcommand{\\Aff}{\\mathrm{Aff}}\\newcommand{\\rsup}{\\triangleright}\\newcommand{\\subgrp}{\\overset{\\mathrm{subgrp}}{\\subset}}\\newcommand{\\Ext}{\\mathrm{Ext}}\\newcommand{\\sbs}{\\subset}\\newcommand{\\sps}{\\supset}\\newcommand{\\In}{\\mathrm{in}\\;}\\newcommand{\\Tor}{\\mathrm{Tor}}\\newcommand{\\p}{\\b{p}}\\newcommand{\\q}{\\mathfrak{q}}\\newcommand{\\m}{\\mathfrak{m}}\\newcommand{\\cS}{\\mathcal{S}}\\newcommand{\\Frac}{\\mathrm{Frac}\\,}\\newcommand{\\Spec}{\\mathrm{Spec}\\,}\\newcommand{\\bA}{\\mathbb{A}}\\newcommand{\\Sym}{\\mathrm{Sym}}\\newcommand{\\Ann}{\\mathrm{Ann}}\\newcommand{\\Her}{\\mathrm{Her}}\\newcommand{\\Bil}{\\mathrm{Bil}}\\newcommand{\\Ses}{\\mathrm{Ses}}\\newcommand{\\FVS}{\\mathrm{FVS}}\n",
        "\n",
        "\\newcommand{\\Ho}{\\mathrm{Ho}}\\newcommand{\\CW}{\\mathrm{CW}}\\newcommand{\\lc}{\\mathrm{lc}}\\newcommand{\\cg}{\\mathrm{cg}}\\newcommand{\\Fib}{\\mathrm{Fib}}\\newcommand{\\Cyl}{\\mathrm{Cyl}}\\newcommand{\\Ch}{\\mathrm{Ch}}\n",
        "\\newcommand{\\rP}{\\mathrm{P}}\\newcommand{\\rE}{\\mathrm{E}}\\newcommand{\\e}{\\b{e}}\\renewcommand{\\k}{\\b{k}}\\newcommand{\\Christ}[2]{\\begin{Bmatrix}#1\\\\#2\\end{Bmatrix}}\\renewcommand{\\Vec}[1]{\\overrightarrow{\\mathrm{#1}}}\\newcommand{\\hen}[1]{\\mathrm{#1}}\\renewcommand{\\b}[1]{\\boldsymbol{#1}}\n",
        "\n",
        "\\newcommand{\\Inc}{\\mathrm{Inc}}\\newcommand{\\aInc}{\\mathrm{aInc}}\\newcommand{\\HS}{\\mathrm{HS}}\\newcommand{\\loc}{\\mathrm{loc}}\\newcommand{\\Lh}{\\mathrm{L.h.}}\\newcommand{\\Epi}{\\mathrm{Epi}}\\newcommand{\\slim}{\\mathrm{slim}}\\newcommand{\\Ban}{\\mathrm{Ban}}\\newcommand{\\Hilb}{\\mathrm{Hilb}}\\newcommand{\\Ex}{\\mathrm{Ex}}\\newcommand{\\Co}{\\mathrm{Co}}\\newcommand{\\sa}{\\mathrm{sa}}\\newcommand{\\nnorm}[1]{{\\left\\vert\\kern-0.25ex\\left\\vert\\kern-0.25ex\\left\\vert #1 \\right\\vert\\kern-0.25ex\\right\\vert\\kern-0.25ex\\right\\vert}}\\newcommand{\\dvol}{\\mathrm{dvol}}\\newcommand{\\Sconv}{\\mathrm{Sconv}}\\newcommand{\\I}{\\mathcal{I}}\\newcommand{\\nonunital}{\\mathrm{nu}}\\newcommand{\\cpt}{\\mathrm{cpt}}\\newcommand{\\lcpt}{\\mathrm{lcpt}}\\newcommand{\\com}{\\mathrm{com}}\\newcommand{\\Haus}{\\mathrm{Haus}}\\newcommand{\\proper}{\\mathrm{proper}}\\newcommand{\\infinity}{\\mathrm{inf}}\\newcommand{\\TVS}{\\mathrm{TVS}}\\newcommand{\\ess}{\\mathrm{ess}}\\newcommand{\\ext}{\\mathrm{ext}}\\newcommand{\\Index}{\\mathrm{Index}\\;}\\newcommand{\\SSR}{\\mathrm{SSR}}\\newcommand{\\vs}{\\mathrm{vs.}}\\newcommand{\\fM}{\\mathfrak{M}}\\newcommand{\\EDM}{\\mathrm{EDM}}\\newcommand{\\Tw}{\\mathrm{Tw}}\\newcommand{\\fC}{\\mathfrak{C}}\\newcommand{\\bn}{\\boldsymbol{n}}\\newcommand{\\br}{\\boldsymbol{r}}\\newcommand{\\Lam}{\\Lambda}\\newcommand{\\lam}{\\lambda}\\newcommand{\\one}{\\mathbf{1}}\\newcommand{\\dae}{\\text{-a.e.}}\\newcommand{\\das}{\\text{-a.s.}}\\newcommand{\\td}{\\text{-}}\\newcommand{\\RM}{\\mathrm{RM}}\\newcommand{\\BV}{\\mathrm{BV}}\\newcommand{\\normal}{\\mathrm{normal}}\\newcommand{\\lub}{\\mathrm{lub}\\;}\\newcommand{\\Graph}{\\mathrm{Graph}}\\newcommand{\\Ascent}{\\mathrm{Ascent}}\\newcommand{\\Descent}{\\mathrm{Descent}}\\newcommand{\\BIL}{\\mathrm{BIL}}\\newcommand{\\fL}{\\mathfrak{L}}\\newcommand{\\De}{\\Delta}\n",
        "\n",
        "\\newcommand{\\calA}{\\mathcal{A}}\\newcommand{\\calB}{\\mathcal{B}}\\newcommand{\\D}{\\mathcal{D}}\\newcommand{\\Y}{\\mathcal{Y}}\\newcommand{\\calC}{\\mathcal{C}}\\renewcommand{\\ae}{\\mathrm{a.e.}\\;}\\newcommand{\\cZ}{\\mathcal{Z}}\\newcommand{\\fF}{\\mathfrak{F}}\\newcommand{\\fI}{\\mathfrak{I}}\\newcommand{\\rV}{\\mathrm{V}}\\newcommand{\\cE}{\\mathcal{E}}\\newcommand{\\sMap}{\\sigma\\textrm{-}\\mathrm{Map}}\\newcommand{\\cC}{\\mathcal{C}}\\newcommand{\\comp}{\\complement}\\newcommand{\\J}{\\mathcal{J}}\\newcommand{\\sumN}[1]{\\sum_{#1\\in\\N}}\\newcommand{\\cupN}[1]{\\cup_{#1\\in\\N}}\\newcommand{\\capN}[1]{\\cap_{#1\\in\\N}}\\newcommand{\\Sum}[1]{\\sum_{#1=1}^\\infty}\\newcommand{\\sumn}{\\sum_{n=1}^\\infty}\\newcommand{\\summ}{\\sum_{m=1}^\\infty}\\newcommand{\\sumk}{\\sum_{k=1}^\\infty}\\newcommand{\\sumi}{\\sum_{i=1}^\\infty}\\newcommand{\\sumj}{\\sum_{j=1}^\\infty}\\newcommand{\\cupn}{\\cup_{n=1}^\\infty}\\newcommand{\\capn}{\\cap_{n=1}^\\infty}\\newcommand{\\cupk}{\\cup_{k=1}^\\infty}\\newcommand{\\cupi}{\\cup_{i=1}^\\infty}\\newcommand{\\cupj}{\\cup_{j=1}^\\infty}\\newcommand{\\limn}{\\lim_{n\\to\\infty}}\\renewcommand{\\L}{\\mathcal{L}}\\newcommand{\\cL}{\\mathcal{L}}\\newcommand{\\Cl}{\\mathrm{Cl}}\\newcommand{\\cN}{\\mathcal{N}}\\newcommand{\\Ae}{\\textrm{-a.e.}\\;}\\renewcommand{\\csub}{\\overset{\\textrm{closed}}{\\subset}}\\renewcommand{\\csup}{\\overset{\\textrm{closed}}{\\supset}}\\newcommand{\\wB}{\\wt{B}}\\newcommand{\\cG}{\\mathcal{G}}\\newcommand{\\Lip}{\\mathrm{Lip}}\\newcommand{\\AC}{\\mathrm{AC}}\\newcommand{\\Mol}{\\mathrm{Mol}}\n",
        "\n",
        "\\newcommand{\\Pe}{\\mathrm{Pe}}\\newcommand{\\wR}{\\wh{\\mathbb{\\R}}}\\newcommand*{\\Laplace}{\\mathop{}\\!\\mathbin\\bigtriangleup}\\newcommand*{\\DAlambert}{\\mathop{}\\!\\mathbin\\Box}\\newcommand{\\bT}{\\mathbb{T}}\\newcommand{\\dx}{\\dslash x}\\newcommand{\\dt}{\\dslash t}\\newcommand{\\ds}{\\dslash s}\n",
        "\n",
        "\\newcommand{\\round}{\\mathrm{round}}\\newcommand{\\cond}{\\mathrm{cond}}\\newcommand{\\diag}{\\mathrm{diag}}\n",
        "\\newcommand{\\Adj}{\\mathrm{Adj}}\\newcommand{\\Pf}{\\mathrm{Pf}}\\newcommand{\\Sg}{\\mathrm{Sg}}\n",
        "\n",
        "\n",
        "\\newcommand{\\aseq}{\\overset{\\text{a.s.}}{=}}\\newcommand{\\deq}{\\overset{\\text{d}}{=}}\\newcommand{\\cV}{\\mathcal{V}}\\newcommand{\\FM}{\\mathrm{FM}}\\newcommand{\\KR}{\\mathrm{KR}}\\newcommand{\\rba}{\\mathrm{rba}}\\newcommand{\\rca}{\\mathrm{rca}}\\newcommand{\\Prob}{\\mathrm{Prob}}\\newcommand{\\X}{\\mathcal{X}}\\newcommand{\\Meas}{\\mathrm{Meas}}\\newcommand{\\as}{\\;\\text{a.s.}}\\newcommand{\\io}{\\;\\mathrm{i.o.}}\\newcommand{\\fe}{\\;\\text{f.e.}}\\newcommand{\\bF}{\\mathbb{F}}\\newcommand{\\W}{\\mathcal{W}}\\newcommand{\\Pois}{\\mathrm{Pois}}\\newcommand{\\iid}{\\text{i.i.d.}}\\newcommand{\\wconv}{\\rightsquigarrow}\\newcommand{\\Var}{\\mathrm{Var}}\\newcommand{\\xrightarrown}{\\xrightarrow{n\\to\\infty}}\\newcommand{\\au}{\\mathrm{au}}\\newcommand{\\cT}{\\mathcal{T}}\\newcommand{\\wto}{\\overset{\\text{w}}{\\to}}\\newcommand{\\dto}{\\overset{\\text{d}}{\\to}}\\newcommand{\\sto}{\\overset{\\text{s}}{\\to}}\\newcommand{\\pto}{\\overset{\\text{p}}{\\to}}\\newcommand{\\mto}{\\overset{\\text{m}}{\\to}}\\newcommand{\\vto}{\\overset{v}{\\to}}\\newcommand{\\Cont}{\\mathrm{Cont}}\\newcommand{\\stably}{\\mathrm{stably}}\\newcommand{\\Np}{\\mathbb{N}^+}\\newcommand{\\oM}{\\overline{\\mathcal{M}}}\\newcommand{\\fP}{\\mathfrak{P}}\\newcommand{\\sign}{\\mathrm{sign}}\n",
        "\\newcommand{\\Borel}{\\mathrm{Borel}}\\newcommand{\\Mid}{\\,|\\,}\\newcommand{\\middleMid}{\\;\\middle|\\;}\\newcommand{\\CP}{\\mathrm{CP}}\\newcommand{\\bD}{\\mathbb{D}}\\newcommand{\\bL}{\\mathbb{L}}\\newcommand{\\fW}{\\mathfrak{W}}\\newcommand{\\DL}{\\mathcal{D}\\mathcal{L}}\\renewcommand{\\r}[1]{\\mathrm{#1}}\\newcommand{\\rC}{\\mathrm{C}}\\newcommand{\\qqquad}{\\qquad\\quad}\n",
        "\n",
        "\\newcommand{\\bit}{\\mathrm{bit}}\n",
        "\n",
        "\\newcommand{\\err}{\\mathrm{err}}\n",
        "\n",
        "\\newcommand{\\varparallel}{\\mathbin{\\!/\\mkern-5mu/\\!}}\\newcommand{\\Ri}{\\mathrm{Ri}}\\newcommand{\\Cone}{\\mathrm{Cone}}\\newcommand{\\Int}{\\mathrm{Int}}\n",
        "\n",
        "\\newcommand{\\pre}{\\mathrm{pre}}\\newcommand{\\om}{\\omega}\n",
        "\n",
        "\n",
        "\\newcommand{\\del}{\\partial}\n",
        "\\newcommand{\\LHS}{\\mathrm{LHS}}\\newcommand{\\RHS}{\\mathrm{RHS}}\\newcommand{\\bnu}{\\boldsymbol{\\nu}}\\newcommand{\\interior}{\\mathrm{in}\\;}\\newcommand{\\SH}{\\mathrm{SH}}\\renewcommand{\\v}{\\boldsymbol{\\nu}}\\newcommand{\\n}{\\mathbf{n}}\\newcommand{\\ssub}{\\Subset}\\newcommand{\\curl}{\\mathrm{curl}}\n",
        "\n",
        "\\newcommand{\\Ei}{\\mathrm{Ei}}\\newcommand{\\sn}{\\mathrm{sn}}\\newcommand{\\wgamma}{\\widetilde{\\gamma}}\n",
        "\n",
        "\\newcommand{\\Ens}{\\mathrm{Ens}}\n",
        "\n",
        "\\newcommand{\\cl}{\\mathrm{cl}}\\newcommand{\\x}{\\boldsymbol{x}}\n",
        "\n",
        "\\newcommand{\\Do}{\\mathrm{Do}}\\newcommand{\\IV}{\\mathrm{IV}}\n",
        "\n",
        "\\newcommand{\\AIC}{\\mathrm{AIC}}\\newcommand{\\mrl}{\\mathrm{mrl}}\\newcommand{\\dotx}{\\dot{x}}\\newcommand{\\UMV}{\\mathrm{UMV}}\\newcommand{\\BLU}{\\mathrm{BLU}}\n",
        "\n",
        "\\newcommand{\\comb}[2]{\\begin{pmatrix}#1\\\\#2\\end{pmatrix}}\\newcommand{\\bP}{\\mathbb{P}}\\newcommand{\\compsub}{\\overset{\\textrm{cpt}}{\\subset}}\\newcommand{\\lip}{\\textrm{lip}}\\newcommand{\\BL}{\\mathrm{BL}}\\newcommand{\\G}{\\mathbb{G}}\\newcommand{\\NB}{\\mathrm{NB}}\\newcommand{\\oR}{\\ov{\\R}}\\newcommand{\\liminfn}{\\liminf_{n\\to\\infty}}\\newcommand{\\limsupn}{\\limsup_{n\\to\\infty}}\\newcommand{\\esssup}{\\mathrm{ess.sup}}\\newcommand{\\asto}{\\xrightarrow{\\as}}\\newcommand{\\Cov}{\\mathrm{Cov}}\\newcommand{\\cQ}{\\mathcal{Q}}\\newcommand{\\VC}{\\mathrm{VC}}\\newcommand{\\mb}{\\mathrm{mb}}\\newcommand{\\Avar}{\\mathrm{Avar}}\\newcommand{\\bB}{\\mathbb{B}}\\newcommand{\\bW}{\\mathbb{W}}\\newcommand{\\sd}{\\mathrm{sd}}\\newcommand{\\w}[1]{\\widehat{#1}}\\newcommand{\\bZ}{\\mathbb{Z}}\\newcommand{\\Bernoulli}{\\mathrm{Ber}}\\newcommand{\\Ber}{\\mathrm{Ber}}\\newcommand{\\Mult}{\\mathrm{Mult}}\\newcommand{\\BPois}{\\mathrm{BPois}}\\newcommand{\\fraks}{\\mathfrak{s}}\\newcommand{\\frakk}{\\mathfrak{k}}\\newcommand{\\IF}{\\mathrm{IF}}\\newcommand{\\bX}{\\boldsymbol{X}}\\newcommand{\\bx}{\\boldsymbol{x}}\\newcommand{\\indep}{\\perp\\!\\!\\!\\perp}\\newcommand{\\IG}{\\mathrm{IG}}\\newcommand{\\Levy}{\\mathrm{Levy}}\\newcommand{\\MP}{\\mathrm{MP}}\\newcommand{\\Hermite}{\\mathrm{Hermite}}\\newcommand{\\Skellam}{\\mathrm{Skellam}}\\newcommand{\\Dirichlet}{\\mathrm{Dirichlet}}\\renewcommand{\\Beta}{\\operatorname{Beta}}\\newcommand{\\bE}{\\mathbb{E}}\\newcommand{\\bG}{\\mathbb{G}}\\newcommand{\\MISE}{\\mathrm{MISE}}\\newcommand{\\logit}{\\mathtt{logit}}\\newcommand{\\expit}{\\mathtt{expit}}\\newcommand{\\cK}{\\mathcal{K}}\\newcommand{\\dl}{\\dot{l}}\\newcommand{\\dotp}{\\dot{p}}\\newcommand{\\wl}{\\wt{l}}\\newcommand{\\Gauss}{\\mathrm{Gauss}}\\newcommand{\\fA}{\\mathfrak{A}}\\newcommand{\\under}{\\mathrm{under}\\;}\\newcommand{\\whtheta}{\\wh{\\theta}}\\newcommand{\\Em}{\\mathrm{Em}}\\newcommand{\\ztheta}{{\\theta_0}}\n",
        "\\newcommand{\\rO}{\\mathrm{O}}\\newcommand{\\Bin}{\\mathrm{Bin}}\\newcommand{\\rW}{\\mathrm{W}}\\newcommand{\\rG}{\\mathrm{G}}\\newcommand{\\rB}{\\mathrm{B}}\\newcommand{\\rU}{\\mathrm{U}}\\newcommand{\\HG}{\\mathrm{HG}}\\newcommand{\\GAMMA}{\\mathrm{Gamma}}\\newcommand{\\Cauchy}{\\mathrm{Cauchy}}\\newcommand{\\rt}{\\mathrm{t}}\\newcommand{\\rF}{\\mathrm{F}}\n",
        "\\newcommand{\\FE}{\\mathrm{FE}}\\newcommand{\\bV}{\\boldsymbol{V}}\\newcommand{\\GLS}{\\mathrm{GLS}}\\newcommand{\\be}{\\boldsymbol{e}}\\newcommand{\\POOL}{\\mathrm{POOL}}\\newcommand{\\GMM}{\\mathrm{GMM}}\\newcommand{\\MM}{\\mathrm{MM}}\\newcommand{\\SSIV}{\\mathrm{SSIV}}\\newcommand{\\JIV}{\\mathrm{JIV}}\\newcommand{\\AR}{\\mathrm{AR}}\\newcommand{\\ILS}{\\mathrm{ILS}}\\newcommand{\\SLS}{\\mathrm{SLS}}\\newcommand{\\LIML}{\\mathrm{LIML}}\n",
        "\n",
        "\\newcommand{\\Rad}{\\mathrm{Rad}}\\newcommand{\\bY}{\\boldsymbol{Y}}\\newcommand{\\pone}{{(1)}}\\newcommand{\\ptwo}{{(2)}}\\newcommand{\\ps}[1]{{(#1)}}\\newcommand{\\fsub}{\\overset{\\text{finite}}{\\subset}}\n",
        "\n",
        "\n",
        "\\newcommand{\\varlim}{\\varprojlim}\\newcommand{\\Hom}{\\mathrm{Hom}}\\newcommand{\\Iso}{\\mathrm{Iso}}\\newcommand{\\Mor}{\\mathrm{Mor}}\\newcommand{\\Isom}{\\mathrm{Isom}}\\newcommand{\\Aut}{\\mathrm{Aut}}\\newcommand{\\End}{\\mathrm{End}}\\newcommand{\\op}{\\mathrm{op}}\\newcommand{\\ev}{\\mathrm{ev}}\\newcommand{\\Ob}{\\mathrm{Ob}}\\newcommand{\\Ar}{\\mathrm{Ar}}\\newcommand{\\Arr}{\\mathrm{Arr}}\\newcommand{\\Set}{\\mathrm{Set}}\\newcommand{\\Grp}{\\mathrm{Grp}}\\newcommand{\\Cat}{\\mathrm{Cat}}\\newcommand{\\Mon}{\\mathrm{Mon}}\\newcommand{\\Ring}{\\mathrm{Ring}}\\newcommand{\\CRing}{\\mathrm{CRing}}\\newcommand{\\Ab}{\\mathrm{Ab}}\\newcommand{\\Pos}{\\mathrm{Pos}}\\newcommand{\\Vect}{\\mathrm{Vect}}\\newcommand{\\FinVect}{\\mathrm{FinVect}}\\newcommand{\\FinSet}{\\mathrm{FinSet}}\\newcommand{\\FinMeas}{\\mathrm{FinMeas}}\\newcommand{\\OmegaAlg}{\\Omega\\text{-}\\mathrm{Alg}}\\newcommand{\\OmegaEAlg}{(\\Omega,E)\\text{-}\\mathrm{Alg}}\\newcommand{\\Fun}{\\mathrm{Fun}}\\newcommand{\\Func}{\\mathrm{Func}}\n",
        "\n",
        "\\newcommand{\\Stoch}{\\mathrm{Stoch}}\\newcommand{\\FinStoch}{\\mathrm{FinStoch}}\\newcommand{\\Copy}{\\mathrm{copy}}\\newcommand{\\Delete}{\\mathrm{delete}}\n",
        "\\newcommand{\\Bool}{\\mathrm{Bool}}\\newcommand{\\CABool}{\\mathrm{CABool}}\\newcommand{\\CompBoolAlg}{\\mathrm{CompBoolAlg}}\\newcommand{\\BoolAlg}{\\mathrm{BoolAlg}}\\newcommand{\\BoolRng}{\\mathrm{BoolRng}}\\newcommand{\\HeytAlg}{\\mathrm{HeytAlg}}\\newcommand{\\CompHeytAlg}{\\mathrm{CompHeytAlg}}\\newcommand{\\Lat}{\\mathrm{Lat}}\\newcommand{\\CompLat}{\\mathrm{CompLat}}\\newcommand{\\SemiLat}{\\mathrm{SemiLat}}\\newcommand{\\Stone}{\\mathrm{Stone}}\\newcommand{\\Mfd}{\\mathrm{Mfd}}\\newcommand{\\LieAlg}{\\mathrm{LieAlg}}\n",
        "\\newcommand{\\Op}{\\mathrm{Op}}\n",
        "\\newcommand{\\Sh}{\\mathrm{Sh}}\n",
        "\\newcommand{\\Diff}{\\mathrm{Diff}}\n",
        "\\newcommand{\\B}{\\mathcal{B}}\\newcommand{\\cB}{\\mathcal{B}}\\newcommand{\\Span}{\\mathrm{Span}}\\newcommand{\\Corr}{\\mathrm{Corr}}\\newcommand{\\Decat}{\\mathrm{Decat}}\\newcommand{\\Rep}{\\mathrm{Rep}}\\newcommand{\\Grpd}{\\mathrm{Grpd}}\\newcommand{\\sSet}{\\mathrm{sSet}}\\newcommand{\\Mod}{\\mathrm{Mod}}\\newcommand{\\SmoothMnf}{\\mathrm{SmoothMnf}}\\newcommand{\\coker}{\\mathrm{coker}}\\newcommand{\\Ord}{\\mathrm{Ord}}\\newcommand{\\eq}{\\mathrm{eq}}\\newcommand{\\coeq}{\\mathrm{coeq}}\\newcommand{\\act}{\\mathrm{act}}\n",
        "\n",
        "\\newcommand{\\apf}{\\mathrm{apf}}\\newcommand{\\opt}{\\mathrm{opt}}\\newcommand{\\IS}{\\mathrm{IS}}\\newcommand{\\IR}{\\mathrm{IR}}\\newcommand{\\iidsim}{\\overset{\\text{i.i.d.}}{\\sim}}\\newcommand{\\propt}{\\,\\propto\\,}\\newcommand{\\bM}{\\mathbb{M}}\\newcommand{\\cX}{\\mathcal{X}}\\newcommand{\\cY}{\\mathcal{Y}}\\newcommand{\\cP}{\\mathcal{P}}\\newcommand{\\ola}[1]{\\overleftarrow{#1}}\n",
        "\n",
        "\\renewcommand{\\iff}{\\;\\mathrm{iff}\\;}\n",
        "\\newcommand{\\False}{\\mathrm{False}}\\newcommand{\\True}{\\mathrm{True}}\n",
        "\\newcommand{\\otherwise}{\\mathrm{otherwise}}\n",
        "\\newcommand{\\suchthat}{\\;\\mathrm{s.t.}\\;}\n",
        "\n",
        "\\newcommand{\\cM}{\\mathcal{M}}\\newcommand{\\M}{\\mathbb{M}}\\newcommand{\\cF}{\\mathcal{F}}\\newcommand{\\cD}{\\mathcal{D}}\\newcommand{\\fX}{\\mathfrak{X}}\\newcommand{\\fY}{\\mathfrak{Y}}\\newcommand{\\fZ}{\\mathfrak{Z}}\\renewcommand{\\H}{\\mathcal{H}}\\newcommand{\\cH}{\\mathcal{H}}\\newcommand{\\fH}{\\mathfrak{H}}\\newcommand{\\bH}{\\mathbb{H}}\\newcommand{\\id}{\\mathrm{id}}\\newcommand{\\A}{\\mathcal{A}}\n",
        "\\newcommand{\\lmd}{\\lambda}\n",
        "\\newcommand{\\Lmd}{\\Lambda}\n",
        "\\newcommand{\\cI}{\\mathcal{I}}\n",
        "\n",
        "\\newcommand{\\Lrarrow}{\\;\\;\\Leftrightarrow\\;\\;}\n",
        "\\DeclareMathOperator{\\des}{des}\n",
        "\\DeclareMathOperator{\\nd}{nd}\n",
        "\\DeclareMathOperator{\\dsep}{d-sep}\n",
        "\\DeclareMathOperator{\\sep}{sep}\n",
        "\\newcommand{\\rLL}{\\mathrm{LL}}\\newcommand{\\HT}{\\mathrm{HT}}\\newcommand{\\PS}{\\mathrm{PS}}\\newcommand{\\rI}{\\mathrm{I}}\n",
        "$$\n",
        "\n",
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "### 関連ページ {.unnumbered .unlisted}\n",
        "\n",
        "::: {#flow-listing}\n",
        ":::\n",
        "\n",
        "## 事前準備\n"
      ],
      "id": "d1b96d98"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "import math\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.color_palette(\"bright\")\n",
        "import matplotlib as mpl\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch import nn\n",
        "from torch.nn  import functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "use_cuda = torch.cuda.is_available()"
      ],
      "id": "98e6af47",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "まずは ODE ソルバーを用意する．これはどのようなものでも NODE のサブルーチンとして使うことができる．\n"
      ],
      "id": "a88df3b4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def ode_solve(z0, t0, t1, f):\n",
        "    \"\"\"\n",
        "    Simplest Euler ODE initial value solver\n",
        "    \"\"\"\n",
        "    h_max = 0.05\n",
        "    n_steps = math.ceil((abs(t1 - t0)/h_max).max().item())\n",
        "\n",
        "    h = (t1 - t0)/n_steps\n",
        "    t = t0\n",
        "    z = z0\n",
        "\n",
        "    for i_step in range(n_steps):\n",
        "        z = z + h * f(z, t)\n",
        "        t = t + h\n",
        "    return z"
      ],
      "id": "4a05efc6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NODE では，$D_{x}L_t$ と $D_\\theta L_t$ とは随伴状態 $a(t)$ に関する ODE で得られる．\n",
        "\n",
        "この ODE の係数を事前に自動微分を通じて計算しておくための親クラスを定義する：\n"
      ],
      "id": "2ffd8ac0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class ODEF(nn.Module):\n",
        "    def forward_with_grad(self, z, t, grad_outputs):\n",
        "        \"\"\"Compute f and a df/dz, a df/dp, a df/dt\"\"\"\n",
        "        batch_size = z.shape[0]\n",
        "\n",
        "        out = self.forward(z, t)\n",
        "\n",
        "        a = grad_outputs\n",
        "        adfdz, adfdt, *adfdp = torch.autograd.grad(\n",
        "            (out,), (z, t) + tuple(self.parameters()), grad_outputs=(a),\n",
        "            allow_unused=True, retain_graph=True\n",
        "        )\n",
        "        # grad method automatically sums gradients for batch items, we have to expand them back\n",
        "        if adfdp is not None:\n",
        "            adfdp = torch.cat([p_grad.flatten() for p_grad in adfdp]).unsqueeze(0)\n",
        "            adfdp = adfdp.expand(batch_size, -1) / batch_size\n",
        "        if adfdt is not None:\n",
        "            adfdt = adfdt.expand(batch_size, 1) / batch_size\n",
        "        return out, adfdz, adfdt, adfdp\n",
        "\n",
        "    def flatten_parameters(self):\n",
        "        p_shapes = []\n",
        "        flat_parameters = []\n",
        "        for p in self.parameters():\n",
        "            p_shapes.append(p.size())\n",
        "            flat_parameters.append(p.flatten())\n",
        "        return torch.cat(flat_parameters)"
      ],
      "id": "ee1a2fa0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neural ODE の実装\n",
        "\n",
        "Neural ODE では誤差逆伝播の代わりに随伴感度法を用いる．\n",
        "\n",
        "これは `torch.nn.Module` を継承したクラスとしては定義できないため，`torch.autograd.Function` を継承したクラスとして定義する：\n"
      ],
      "id": "08c3ce08"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class ODEAdjoint(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, z0, t, flat_parameters, func):\n",
        "        assert isinstance(func, ODEF)\n",
        "        bs, *z_shape = z0.size()\n",
        "        time_len = t.size(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            z = torch.zeros(time_len, bs, *z_shape).to(z0)\n",
        "            z[0] = z0\n",
        "            for i_t in range(time_len - 1):\n",
        "                z0 = ode_solve(z0, t[i_t], t[i_t+1], func)\n",
        "                z[i_t+1] = z0\n",
        "\n",
        "        ctx.func = func\n",
        "        ctx.save_for_backward(t, z.clone(), flat_parameters)\n",
        "        return z\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, dLdz):\n",
        "        \"\"\"\n",
        "        dLdz shape: time_len, batch_size, *z_shape\n",
        "        \"\"\"\n",
        "        func = ctx.func\n",
        "        t, z, flat_parameters = ctx.saved_tensors\n",
        "        time_len, bs, *z_shape = z.size()\n",
        "        n_dim = np.prod(z_shape)\n",
        "        n_params = flat_parameters.size(0)\n",
        "\n",
        "        # Dynamics of augmented system to be calculated backwards in time\n",
        "        def augmented_dynamics(aug_z_i, t_i):\n",
        "            \"\"\"\n",
        "            tensors here are temporal slices\n",
        "            t_i - is tensor with size: bs, 1\n",
        "            aug_z_i - is tensor with size: bs, n_dim*2 + n_params + 1\n",
        "            \"\"\"\n",
        "            z_i, a = aug_z_i[:, :n_dim], aug_z_i[:, n_dim:2*n_dim]  # ignore parameters and time\n",
        "\n",
        "            # Unflatten z and a\n",
        "            z_i = z_i.view(bs, *z_shape)\n",
        "            a = a.view(bs, *z_shape)\n",
        "            with torch.set_grad_enabled(True):\n",
        "                t_i = t_i.detach().requires_grad_(True)\n",
        "                z_i = z_i.detach().requires_grad_(True)\n",
        "                func_eval, adfdz, adfdt, adfdp = func.forward_with_grad(z_i, t_i, grad_outputs=a)  # bs, *z_shape\n",
        "                adfdz = adfdz.to(z_i) if adfdz is not None else torch.zeros(bs, *z_shape).to(z_i)\n",
        "                adfdp = adfdp.to(z_i) if adfdp is not None else torch.zeros(bs, n_params).to(z_i)\n",
        "                adfdt = adfdt.to(z_i) if adfdt is not None else torch.zeros(bs, 1).to(z_i)\n",
        "\n",
        "            # Flatten f and adfdz\n",
        "            func_eval = func_eval.view(bs, n_dim)\n",
        "            adfdz = adfdz.view(bs, n_dim)\n",
        "            return torch.cat((func_eval, -adfdz, -adfdp, -adfdt), dim=1)\n",
        "\n",
        "        dLdz = dLdz.view(time_len, bs, n_dim)  # flatten dLdz for convenience\n",
        "        with torch.no_grad():\n",
        "            ## Create placeholders for output gradients\n",
        "            # Prev computed backwards adjoints to be adjusted by direct gradients\n",
        "            adj_z = torch.zeros(bs, n_dim).to(dLdz)\n",
        "            adj_p = torch.zeros(bs, n_params).to(dLdz)\n",
        "            # In contrast to z and p we need to return gradients for all times\n",
        "            adj_t = torch.zeros(time_len, bs, 1).to(dLdz)\n",
        "\n",
        "            for i_t in range(time_len-1, 0, -1):\n",
        "                z_i = z[i_t]\n",
        "                t_i = t[i_t]\n",
        "                f_i = func(z_i, t_i).view(bs, n_dim)\n",
        "\n",
        "                # Compute direct gradients\n",
        "                dLdz_i = dLdz[i_t]\n",
        "                dLdt_i = torch.bmm(torch.transpose(dLdz_i.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1))[:, 0]\n",
        "\n",
        "                # Adjusting adjoints with direct gradients\n",
        "                adj_z += dLdz_i\n",
        "                adj_t[i_t] = adj_t[i_t] - dLdt_i\n",
        "\n",
        "                # Pack augmented variable\n",
        "                aug_z = torch.cat((z_i.view(bs, n_dim), adj_z, torch.zeros(bs, n_params).to(z), adj_t[i_t]), dim=-1)\n",
        "\n",
        "                # Solve augmented system backwards\n",
        "                aug_ans = ode_solve(aug_z, t_i, t[i_t-1], augmented_dynamics)\n",
        "\n",
        "                # Unpack solved backwards augmented system\n",
        "                adj_z[:] = aug_ans[:, n_dim:2*n_dim]\n",
        "                adj_p[:] += aug_ans[:, 2*n_dim:2*n_dim + n_params]\n",
        "                adj_t[i_t-1] = aug_ans[:, 2*n_dim + n_params:]\n",
        "\n",
        "                del aug_z, aug_ans\n",
        "\n",
        "            ## Adjust 0 time adjoint with direct gradients\n",
        "            # Compute direct gradients\n",
        "            dLdz_0 = dLdz[0]\n",
        "            dLdt_0 = torch.bmm(torch.transpose(dLdz_0.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1))[:, 0]\n",
        "\n",
        "            # Adjust adjoints\n",
        "            adj_z += dLdz_0\n",
        "            adj_t[0] = adj_t[0] - dLdt_0\n",
        "        return adj_z.view(bs, *z_shape), adj_t, adj_p, None"
      ],
      "id": "ad68b71b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "これを `nn.Module` クラスとしてラップすることで，準備完了である：\n"
      ],
      "id": "4a239a18"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class NeuralODE(nn.Module):\n",
        "    def __init__(self, func):\n",
        "        super(NeuralODE, self).__init__()\n",
        "        assert isinstance(func, ODEF)\n",
        "        self.func = func\n",
        "\n",
        "    def forward(self, z0, t=Tensor([0., 1.]), return_whole_sequence=False):\n",
        "        t = t.to(z0)\n",
        "        z = ODEAdjoint.apply(z0, t, self.func.flatten_parameters(), self.func)\n",
        "        if return_whole_sequence:\n",
        "            return z\n",
        "        else:\n",
        "            return z[-1]"
      ],
      "id": "28a6c968",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ダイナミクスの再現\n",
        "\n",
        "### 線型ダイナミクス\n",
        "\n",
        "簡単な線型ダイナミクスを，線型なダイナミクスで学習する．\n"
      ],
      "id": "ca5fba40"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class LinearODEF(ODEF):\n",
        "    def __init__(self, W):\n",
        "        super(LinearODEF, self).__init__()\n",
        "        self.lin = nn.Linear(2, 2, bias=False)\n",
        "        self.lin.weight = nn.Parameter(W)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        return self.lin(x)\n",
        "\n",
        "class SpiralFunctionExample(LinearODEF):\n",
        "    def __init__(self):\n",
        "        super(SpiralFunctionExample, self).__init__(Tensor([[-0.1, -1.], [1., -0.1]]))\n",
        "\n",
        "class RandomLinearODEF(LinearODEF):\n",
        "    def __init__(self):\n",
        "        # super(RandomLinearODEF, self).__init__(torch.randn(2, 2)/2.)\n",
        "        super(RandomLinearODEF, self).__init__(Tensor([[0.1, -0.1], [0.1, -0.1]]))\n",
        "\n",
        "def to_np(x):\n",
        "    return x.detach().cpu().numpy()"
      ],
      "id": "70a76d74",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_trajectories(obs=None, times=None, trajs=None, save=None, figsize=(16, 8)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    if obs is not None:\n",
        "        if times is None:\n",
        "            times = [None] * len(obs)\n",
        "        for o, t in zip(obs, times):\n",
        "            o, t = to_np(o), to_np(t)\n",
        "            for b_i in range(o.shape[1]):\n",
        "                plt.scatter(o[:, b_i, 0], o[:, b_i, 1], c=t[:, b_i, 0], cmap=cm.plasma)\n",
        "\n",
        "    if trajs is not None:\n",
        "        for z in trajs:\n",
        "            z = to_np(z)\n",
        "            plt.plot(z[:, 0, 0], z[:, 0, 1], lw=1.5)\n",
        "        if save is not None:\n",
        "            plt.savefig(save)\n",
        "    plt.show()\n",
        "\n",
        "def conduct_experiment(ode_true, ode_trained, n_steps, name, plot_freq=10, lr=0.01):\n",
        "    # Create data\n",
        "    z0 = Variable(torch.Tensor([[0.6, 0.3]]))\n",
        "\n",
        "    t_max = 6.29*5\n",
        "    n_points = 200\n",
        "\n",
        "    index_np = np.arange(0, n_points, 1, dtype=np.int64)\n",
        "    index_np = np.hstack([index_np[:, None]])\n",
        "    times_np = np.linspace(0, t_max, num=n_points)\n",
        "    times_np = np.hstack([times_np[:, None]])\n",
        "\n",
        "    times = torch.from_numpy(times_np[:, :, None]).to(z0)\n",
        "    obs = ode_true(z0, times, return_whole_sequence=True).detach()\n",
        "    obs = obs + torch.randn_like(obs) * 0.01\n",
        "\n",
        "    # Get trajectory of random timespan\n",
        "    min_delta_time = 1.0\n",
        "    max_delta_time = 5.0\n",
        "    max_points_num = 32\n",
        "    def create_batch():\n",
        "        t0 = np.random.uniform(0, t_max - max_delta_time)\n",
        "        t1 = t0 + np.random.uniform(min_delta_time, max_delta_time)\n",
        "\n",
        "        idx = sorted(np.random.permutation(index_np[(times_np > t0) & (times_np < t1)])[:max_points_num])\n",
        "\n",
        "        obs_ = obs[idx]\n",
        "        ts_ = times[idx]\n",
        "        return obs_, ts_\n",
        "\n",
        "    # Train Neural ODE\n",
        "    optimizer = torch.optim.Adam(ode_trained.parameters(), lr=lr)\n",
        "    for i in range(n_steps):\n",
        "        obs_, ts_ = create_batch()\n",
        "\n",
        "        z_ = ode_trained(obs_[0], ts_, return_whole_sequence=True)\n",
        "        loss = F.mse_loss(z_, obs_.detach())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % plot_freq == 0:\n",
        "            z_p = ode_trained(z0, times, return_whole_sequence=True)\n",
        "\n",
        "            plot_trajectories(obs=[obs], times=[times], trajs=[z_p], save=f\"Files/{name}/{i//plot_freq}.png\")\n",
        "            clear_output(wait=True)"
      ],
      "id": "94524bf6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "ode_true = NeuralODE(SpiralFunctionExample())\n",
        "ode_trained = NeuralODE(RandomLinearODEF())\n",
        "conduct_experiment(ode_true, ode_trained, 500, \"linear\")"
      ],
      "id": "ed79c969",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ImageMagick により gif 生成した結果は次の通り：\n",
        "```zsh\n",
        "convert -delay 10 -loop 0 $(for i in {0..49}; do echo $i.png; done) output.gif\n",
        "```\n",
        "\n",
        "![](Files/linear/output.gif)\n",
        "\n",
        "### 非線型ダイナミクス\n",
        "\n",
        "今回は非線型のダイナミクスを，[ELU](https://pytorch.org/docs/stable/generated/torch.nn.ELU.html) を備えた一層のニューラルネットワークで学習する：\n"
      ],
      "id": "934e81fc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class TestODEF(ODEF):\n",
        "    def __init__(self, A, B, x0):\n",
        "        super(TestODEF, self).__init__()\n",
        "        self.A = nn.Linear(2, 2, bias=False)\n",
        "        self.A.weight = nn.Parameter(A)\n",
        "        self.B = nn.Linear(2, 2, bias=False)\n",
        "        self.B.weight = nn.Parameter(B)\n",
        "        self.x0 = nn.Parameter(x0)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        xTx0 = torch.sum(x*self.x0, dim=1)\n",
        "        dxdt = torch.sigmoid(xTx0) * self.A(x - self.x0) + torch.sigmoid(-xTx0) * self.B(x + self.x0)\n",
        "        return dxdt\n",
        "\n",
        "class NNODEF(ODEF):\n",
        "    def __init__(self, in_dim, hid_dim, time_invariant=False):\n",
        "        super(NNODEF, self).__init__()\n",
        "        self.time_invariant = time_invariant\n",
        "\n",
        "        if time_invariant:\n",
        "            self.lin1 = nn.Linear(in_dim, hid_dim)\n",
        "        else:\n",
        "            self.lin1 = nn.Linear(in_dim+1, hid_dim)\n",
        "        self.lin2 = nn.Linear(hid_dim, hid_dim)\n",
        "        self.lin3 = nn.Linear(hid_dim, in_dim)\n",
        "        self.elu = nn.ELU(inplace=True)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        if not self.time_invariant:\n",
        "            x = torch.cat((x, t), dim=-1)\n",
        "\n",
        "        h = self.elu(self.lin1(x))\n",
        "        h = self.elu(self.lin2(h))\n",
        "        out = self.lin3(h)\n",
        "        return out"
      ],
      "id": "7bc74787",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "func = TestODEF(Tensor([[-0.1, -0.5], [0.5, -0.1]]), Tensor([[0.2, 1.], [-1, 0.2]]), Tensor([[-1., 0.]]))\n",
        "ode_true = NeuralODE(func)\n",
        "\n",
        "func = NNODEF(2, 16, time_invariant=True)\n",
        "ode_trained = NeuralODE(func)\n",
        "\n",
        "conduct_experiment(ode_true, ode_trained, 3000, \"nonlinear\", plot_freq=30, lr=0.001)"
      ],
      "id": "a997d72b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "逡巡を繰り返して学習する様子がよく伺える．学習率を `lr=0.001` としているが，`lr=0.01` でも `lr=0.005` でも，学習が非常に良い線まで行ってもすぐに初期値よりもカオスなダイナミクスに戻ってしまう挙動がよく見られた．\n",
        "\n",
        "![](Files/nonlinear/output.gif)\n",
        "\n",
        "## 文献紹介 {.appendix}\n",
        "\n",
        "[Mikhail Surtsukov 氏](https://msurtsukov.github.io/Neural-ODE/)によるチュートリアルが，[このレポジトリ](https://github.com/msurtsukov/neural-ode?tab=readme-ov-file)で公開されている．\n",
        "\n",
        "FFJORD [@Grathwohl+2019] の実装は，[このレポジトリ](https://github.com/rtqichen/ffjord)で公開されている．"
      ],
      "id": "881cda04"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/hirofumi48/Library/Jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}