{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00b49b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "import json\n",
    "\n",
    "# figure size/format\n",
    "fig_width = 6\n",
    "fig_height = 4\n",
    "fig_format = 'retina'\n",
    "fig_dpi = 96\n",
    "interactivity = ''\n",
    "is_shiny = False\n",
    "is_dashboard = False\n",
    "plotly_connected = True\n",
    "\n",
    "# matplotlib defaults / format\n",
    "try:\n",
    "  import matplotlib.pyplot as plt\n",
    "  plt.rcParams['figure.figsize'] = (fig_width, fig_height)\n",
    "  plt.rcParams['figure.dpi'] = fig_dpi\n",
    "  plt.rcParams['savefig.dpi'] = fig_dpi\n",
    "  from IPython.display import set_matplotlib_formats\n",
    "  set_matplotlib_formats(fig_format)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# plotly use connected mode\n",
    "try:\n",
    "  import plotly.io as pio\n",
    "  if plotly_connected:\n",
    "    pio.renderers.default = \"notebook_connected\"\n",
    "  else:\n",
    "    pio.renderers.default = \"notebook\"\n",
    "  for template in pio.templates.keys():\n",
    "    pio.templates[template].layout.margin = dict(t=30,r=0,b=0,l=0)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# disable itables paging for dashboards\n",
    "if is_dashboard:\n",
    "  try:\n",
    "    from itables import options\n",
    "    options.dom = 'fiBrtlp'\n",
    "    options.maxBytes = 1024 * 1024\n",
    "    options.language = dict(info = \"Showing _TOTAL_ entries\")\n",
    "    options.classes = \"display nowrap compact\"\n",
    "    options.paging = False\n",
    "    options.searching = True\n",
    "    options.ordering = True\n",
    "    options.info = True\n",
    "    options.lengthChange = False\n",
    "    options.autoWidth = False\n",
    "    options.responsive = True\n",
    "    options.keys = True\n",
    "    options.buttons = []\n",
    "  except Exception:\n",
    "    pass\n",
    "  \n",
    "  try:\n",
    "    import altair as alt\n",
    "    # By default, dashboards will have container sized\n",
    "    # vega visualizations which allows them to flow reasonably\n",
    "    theme_sentinel = '_quarto-dashboard-internal'\n",
    "    def make_theme(name):\n",
    "        nonTheme = alt.themes._plugins[name]    \n",
    "        def patch_theme(*args, **kwargs):\n",
    "            existingTheme = nonTheme()\n",
    "            if 'height' not in existingTheme:\n",
    "              existingTheme['height'] = 'container'\n",
    "            if 'width' not in existingTheme:\n",
    "              existingTheme['width'] = 'container'\n",
    "\n",
    "            if 'config' not in existingTheme:\n",
    "              existingTheme['config'] = dict()\n",
    "            \n",
    "            # Configure the default font sizes\n",
    "            title_font_size = 15\n",
    "            header_font_size = 13\n",
    "            axis_font_size = 12\n",
    "            legend_font_size = 12\n",
    "            mark_font_size = 12\n",
    "            tooltip = False\n",
    "\n",
    "            config = existingTheme['config']\n",
    "\n",
    "            # The Axis\n",
    "            if 'axis' not in config:\n",
    "              config['axis'] = dict()\n",
    "            axis = config['axis']\n",
    "            if 'labelFontSize' not in axis:\n",
    "              axis['labelFontSize'] = axis_font_size\n",
    "            if 'titleFontSize' not in axis:\n",
    "              axis['titleFontSize'] = axis_font_size  \n",
    "\n",
    "            # The legend\n",
    "            if 'legend' not in config:\n",
    "              config['legend'] = dict()\n",
    "            legend = config['legend']\n",
    "            if 'labelFontSize' not in legend:\n",
    "              legend['labelFontSize'] = legend_font_size\n",
    "            if 'titleFontSize' not in legend:\n",
    "              legend['titleFontSize'] = legend_font_size  \n",
    "\n",
    "            # The header\n",
    "            if 'header' not in config:\n",
    "              config['header'] = dict()\n",
    "            header = config['header']\n",
    "            if 'labelFontSize' not in header:\n",
    "              header['labelFontSize'] = header_font_size\n",
    "            if 'titleFontSize' not in header:\n",
    "              header['titleFontSize'] = header_font_size    \n",
    "\n",
    "            # Title\n",
    "            if 'title' not in config:\n",
    "              config['title'] = dict()\n",
    "            title = config['title']\n",
    "            if 'fontSize' not in title:\n",
    "              title['fontSize'] = title_font_size\n",
    "\n",
    "            # Marks\n",
    "            if 'mark' not in config:\n",
    "              config['mark'] = dict()\n",
    "            mark = config['mark']\n",
    "            if 'fontSize' not in mark:\n",
    "              mark['fontSize'] = mark_font_size\n",
    "\n",
    "            # Mark tooltips\n",
    "            if tooltip and 'tooltip' not in mark:\n",
    "              mark['tooltip'] = dict(content=\"encoding\")\n",
    "\n",
    "            return existingTheme\n",
    "            \n",
    "        return patch_theme\n",
    "\n",
    "    # We can only do this once per session\n",
    "    if theme_sentinel not in alt.themes.names():\n",
    "      for name in alt.themes.names():\n",
    "        alt.themes.register(name, make_theme(name))\n",
    "      \n",
    "      # register a sentinel theme so we only do this once\n",
    "      alt.themes.register(theme_sentinel, make_theme('default'))\n",
    "      alt.themes.enable('default')\n",
    "\n",
    "  except Exception:\n",
    "    pass\n",
    "\n",
    "# enable pandas latex repr when targeting pdfs\n",
    "try:\n",
    "  import pandas as pd\n",
    "  if fig_format == 'pdf':\n",
    "    pd.set_option('display.latex.repr', True)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# interactivity\n",
    "if interactivity:\n",
    "  from IPython.core.interactiveshell import InteractiveShell\n",
    "  InteractiveShell.ast_node_interactivity = interactivity\n",
    "\n",
    "# NOTE: the kernel_deps code is repeated in the cleanup.py file\n",
    "# (we can't easily share this code b/c of the way it is run).\n",
    "# If you edit this code also edit the same code in cleanup.py!\n",
    "\n",
    "# output kernel dependencies\n",
    "kernel_deps = dict()\n",
    "for module in list(sys.modules.values()):\n",
    "  # Some modules play games with sys.modules (e.g. email/__init__.py\n",
    "  # in the standard library), and occasionally this can cause strange\n",
    "  # failures in getattr.  Just ignore anything that's not an ordinary\n",
    "  # module.\n",
    "  if not isinstance(module, types.ModuleType):\n",
    "    continue\n",
    "  path = getattr(module, \"__file__\", None)\n",
    "  if not path:\n",
    "    continue\n",
    "  if path.endswith(\".pyc\") or path.endswith(\".pyo\"):\n",
    "    path = path[:-1]\n",
    "  if not os.path.exists(path):\n",
    "    continue\n",
    "  kernel_deps[path] = os.stat(path).st_mtime\n",
    "print(json.dumps(kernel_deps))\n",
    "\n",
    "# set run_path if requested\n",
    "if r'/Users/hirofumi48/162348.github.io/posts/2024/Samplers':\n",
    "  os.chdir(r'/Users/hirofumi48/162348.github.io/posts/2024/Samplers')\n",
    "\n",
    "# reset state\n",
    "%reset\n",
    "\n",
    "# shiny\n",
    "# Checking for shiny by using False directly because we're after the %reset. We don't want\n",
    "# to set a variable that stays in global scope.\n",
    "if False:\n",
    "  try:\n",
    "    import htmltools as _htmltools\n",
    "    import ast as _ast\n",
    "\n",
    "    _htmltools.html_dependency_render_mode = \"json\"\n",
    "\n",
    "    # This decorator will be added to all function definitions\n",
    "    def _display_if_has_repr_html(x):\n",
    "      try:\n",
    "        # IPython 7.14 preferred import\n",
    "        from IPython.display import display, HTML\n",
    "      except:\n",
    "        from IPython.core.display import display, HTML\n",
    "\n",
    "      if hasattr(x, '_repr_html_'):\n",
    "        display(HTML(x._repr_html_()))\n",
    "      return x\n",
    "\n",
    "    # ideally we would undo the call to ast_transformers.append\n",
    "    # at the end of this block whenver an error occurs, we do \n",
    "    # this for now as it will only be a problem if the user \n",
    "    # switches from shiny to not-shiny mode (and even then likely\n",
    "    # won't matter)\n",
    "    import builtins\n",
    "    builtins._display_if_has_repr_html = _display_if_has_repr_html\n",
    "\n",
    "    class _FunctionDefReprHtml(_ast.NodeTransformer):\n",
    "      def visit_FunctionDef(self, node):\n",
    "        node.decorator_list.insert(\n",
    "          0,\n",
    "          _ast.Name(id=\"_display_if_has_repr_html\", ctx=_ast.Load())\n",
    "        )\n",
    "        return node\n",
    "\n",
    "      def visit_AsyncFunctionDef(self, node):\n",
    "        node.decorator_list.insert(\n",
    "          0,\n",
    "          _ast.Name(id=\"_display_if_has_repr_html\", ctx=_ast.Load())\n",
    "        )\n",
    "        return node\n",
    "\n",
    "    ip = get_ipython()\n",
    "    ip.ast_transformers.append(_FunctionDefReprHtml())\n",
    "\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "def ojs_define(**kwargs):\n",
    "  import json\n",
    "  try:\n",
    "    # IPython 7.14 preferred import\n",
    "    from IPython.display import display, HTML\n",
    "  except:\n",
    "    from IPython.core.display import display, HTML\n",
    "\n",
    "  # do some minor magic for convenience when handling pandas\n",
    "  # dataframes\n",
    "  def convert(v):\n",
    "    try:\n",
    "      import pandas as pd\n",
    "    except ModuleNotFoundError: # don't do the magic when pandas is not available\n",
    "      return v\n",
    "    if type(v) == pd.Series:\n",
    "      v = pd.DataFrame(v)\n",
    "    if type(v) == pd.DataFrame:\n",
    "      j = json.loads(v.T.to_json(orient='split'))\n",
    "      return dict((k,v) for (k,v) in zip(j[\"index\"], j[\"data\"]))\n",
    "    else:\n",
    "      return v\n",
    "\n",
    "  v = dict(contents=list(dict(name=key, value=convert(value)) for (key, value) in kwargs.items()))\n",
    "  display(HTML('<script type=\"ojs-define\">' + json.dumps(v) + '</script>'), metadata=dict(ojs_define = True))\n",
    "globals()[\"ojs_define\"] = ojs_define\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42adf36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "DEVICE = torch.device(\"mps\")\n",
    "train_batch_size = 128\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a3cbe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "\n",
    "import math\n",
    "\n",
    "dataset_path = '~/hirofumi/datasets'\n",
    "\n",
    "kwargs = {'num_workers': 0, 'pin_memory': True}\n",
    "\n",
    "dataset = 'MNIST'\n",
    "img_size = (32, 32, 3)   if dataset == \"CIFAR10\" else (28, 28, 1) # (width, height, channels)\n",
    "\n",
    "timestep_embedding_dim = 256\n",
    "n_layers = 8\n",
    "hidden_dim = 256\n",
    "n_timesteps = 1000\n",
    "beta_minmax=[1e-4, 2e-2]\n",
    "\n",
    "inference_batch_size = 64\n",
    "lr = 5e-5\n",
    "\n",
    "seed = 2024\n",
    "\n",
    "hidden_dims = [hidden_dim for _ in range(n_layers)]\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    multiprocessing.set_start_method('spawn')\n",
    "\n",
    "    if dataset == 'CIFAR10':\n",
    "        train_dataset = CIFAR10(dataset_path, transform=transform, train=True, download=True)\n",
    "        test_dataset  = CIFAR10(dataset_path, transform=transform, train=False, download=True)\n",
    "    else:\n",
    "        train_dataset = MNIST(dataset_path, transform=transform, train=True, download=True)\n",
    "        test_dataset  = MNIST(dataset_path, transform=transform, train=False, download=True)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=train_batch_size, shuffle=True, **kwargs)\n",
    "    test_loader  = DataLoader(dataset=test_dataset,  batch_size=inference_batch_size, shuffle=False,  **kwargs)\n",
    "    \n",
    "    class SinusoidalPosEmb(nn.Module):\n",
    "        def __init__(self, dim):\n",
    "            super().__init__()\n",
    "            self.dim = dim\n",
    "\n",
    "        def forward(self, x):\n",
    "            device = x.device\n",
    "            half_dim = self.dim // 2\n",
    "            emb = math.log(10000) / (half_dim - 1)\n",
    "            emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "            emb = x[:, None] * emb[None, :]\n",
    "            emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "            return emb\n",
    "\n",
    "    class ConvBlock(nn.Conv2d):\n",
    "        \"\"\"\n",
    "            Conv2D Block\n",
    "                Args:\n",
    "                    x: (N, C_in, H, W)\n",
    "                Returns:\n",
    "                    y: (N, C_out, H, W)\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, in_channels, out_channels, kernel_size, activation_fn=None, drop_rate=0.,\n",
    "                        stride=1, padding='same', dilation=1, groups=1, bias=True, gn=False, gn_groups=8):\n",
    "            \n",
    "            if padding == 'same':\n",
    "                padding = kernel_size // 2 * dilation\n",
    "\n",
    "            super(ConvBlock, self).__init__(in_channels, out_channels, kernel_size,\n",
    "                                                stride=stride, padding=padding, dilation=dilation,\n",
    "                                                groups=groups, bias=bias)\n",
    "\n",
    "            self.activation_fn = nn.SiLU() if activation_fn else None\n",
    "            self.group_norm = nn.GroupNorm(gn_groups, out_channels) if gn else None\n",
    "            \n",
    "        def forward(self, x, time_embedding=None, residual=False):\n",
    "            \n",
    "            if residual:\n",
    "                # in the paper, diffusion timestep embedding was only applied to residual blocks of U-Net\n",
    "                x = x + time_embedding\n",
    "                y = x\n",
    "                x = super(ConvBlock, self).forward(x)\n",
    "                y = y + x\n",
    "            else:\n",
    "                y = super(ConvBlock, self).forward(x)\n",
    "            y = self.group_norm(y) if self.group_norm is not None else y\n",
    "            y = self.activation_fn(y) if self.activation_fn is not None else y\n",
    "            \n",
    "            return y\n",
    "        \n",
    "    class Denoiser(nn.Module):\n",
    "        \n",
    "        def __init__(self, image_resolution, hidden_dims=[256, 256], diffusion_time_embedding_dim = 256, n_times=1000):\n",
    "            super(Denoiser, self).__init__()\n",
    "            \n",
    "            _, _, img_C = image_resolution\n",
    "            \n",
    "            self.time_embedding = SinusoidalPosEmb(diffusion_time_embedding_dim)\n",
    "            \n",
    "            self.in_project = ConvBlock(img_C, hidden_dims[0], kernel_size=7)\n",
    "            \n",
    "            self.time_project = nn.Sequential(\n",
    "                                    ConvBlock(diffusion_time_embedding_dim, hidden_dims[0], kernel_size=1, activation_fn=True),\n",
    "                                    ConvBlock(hidden_dims[0], hidden_dims[0], kernel_size=1))\n",
    "            \n",
    "            self.convs = nn.ModuleList([ConvBlock(in_channels=hidden_dims[0], out_channels=hidden_dims[0], kernel_size=3)])\n",
    "            \n",
    "            for idx in range(1, len(hidden_dims)):\n",
    "                self.convs.append(ConvBlock(hidden_dims[idx-1], hidden_dims[idx], kernel_size=3, dilation=3**((idx-1)//2),\n",
    "                                                        activation_fn=True, gn=True, gn_groups=8))                                \n",
    "                                \n",
    "            self.out_project = ConvBlock(hidden_dims[-1], out_channels=img_C, kernel_size=3)\n",
    "            \n",
    "            \n",
    "        def forward(self, perturbed_x, diffusion_timestep):\n",
    "            y = perturbed_x\n",
    "            \n",
    "            diffusion_embedding = self.time_embedding(diffusion_timestep)\n",
    "            diffusion_embedding = self.time_project(diffusion_embedding.unsqueeze(-1).unsqueeze(-2))\n",
    "            \n",
    "            y = self.in_project(y)\n",
    "            \n",
    "            for i in range(len(self.convs)):\n",
    "                y = self.convs[i](y, diffusion_embedding, residual = True)\n",
    "                \n",
    "            y = self.out_project(y)\n",
    "                \n",
    "            return y\n",
    "        \n",
    "    model = Denoiser(image_resolution=img_size,\n",
    "                    hidden_dims=hidden_dims, \n",
    "                    diffusion_time_embedding_dim=timestep_embedding_dim, \n",
    "                    n_times=n_timesteps).to(DEVICE)\n",
    "\n",
    "    class Diffusion(nn.Module):\n",
    "        def __init__(self, model, image_resolution=[32, 32, 3], n_times=1000, beta_minmax=[1e-4, 2e-2], device='cuda'):\n",
    "        \n",
    "            super(Diffusion, self).__init__()\n",
    "        \n",
    "            self.n_times = n_times\n",
    "            self.img_H, self.img_W, self.img_C = image_resolution\n",
    "\n",
    "            self.model = model\n",
    "            \n",
    "            # define linear variance schedule(betas)\n",
    "            beta_1, beta_T = beta_minmax\n",
    "            betas = torch.linspace(start=beta_1, end=beta_T, steps=n_times).to(device) # follows DDPM paper\n",
    "            self.sqrt_betas = torch.sqrt(betas)\n",
    "                                        \n",
    "            # define alpha for forward diffusion kernel\n",
    "            self.alphas = 1 - betas\n",
    "            self.sqrt_alphas = torch.sqrt(self.alphas)\n",
    "            alpha_bars = torch.cumprod(self.alphas, dim=0)\n",
    "            self.sqrt_one_minus_alpha_bars = torch.sqrt(1-alpha_bars)\n",
    "            self.sqrt_alpha_bars = torch.sqrt(alpha_bars)\n",
    "            \n",
    "            self.device = device\n",
    "        \n",
    "        def extract(self, a, t, x_shape):\n",
    "            \"\"\"\n",
    "                from lucidrains' implementation\n",
    "                    https://github.com/lucidrains/denoising-diffusion-pytorch/blob/beb2f2d8dd9b4f2bd5be4719f37082fe061ee450/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py#L376\n",
    "            \"\"\"\n",
    "            b, *_ = t.shape\n",
    "            out = a.gather(-1, t)\n",
    "            return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
    "        \n",
    "        def scale_to_minus_one_to_one(self, x):\n",
    "            # according to the DDPMs paper, normalization seems to be crucial to train reverse process network\n",
    "            return x * 2 - 1\n",
    "        \n",
    "        def reverse_scale_to_zero_to_one(self, x):\n",
    "            return (x + 1) * 0.5\n",
    "        \n",
    "        def make_noisy(self, x_zeros, t): \n",
    "            # perturb x_0 into x_t (i.e., take x_0 samples into forward diffusion kernels)\n",
    "            epsilon = torch.randn_like(x_zeros).to(self.device)\n",
    "            \n",
    "            sqrt_alpha_bar = self.extract(self.sqrt_alpha_bars, t, x_zeros.shape)\n",
    "            sqrt_one_minus_alpha_bar = self.extract(self.sqrt_one_minus_alpha_bars, t, x_zeros.shape)\n",
    "            \n",
    "            # Let's make noisy sample!: i.e., Forward process with fixed variance schedule\n",
    "            #      i.e., sqrt(alpha_bar_t) * x_zero + sqrt(1-alpha_bar_t) * epsilon\n",
    "            noisy_sample = x_zeros * sqrt_alpha_bar + epsilon * sqrt_one_minus_alpha_bar\n",
    "        \n",
    "            return noisy_sample.detach(), epsilon\n",
    "        \n",
    "        \n",
    "        def forward(self, x_zeros):\n",
    "            x_zeros = self.scale_to_minus_one_to_one(x_zeros)\n",
    "            \n",
    "            B, _, _, _ = x_zeros.shape\n",
    "            \n",
    "            # (1) randomly choose diffusion time-step\n",
    "            t = torch.randint(low=0, high=self.n_times, size=(B,)).long().to(self.device)\n",
    "            \n",
    "            # (2) forward diffusion process: perturb x_zeros with fixed variance schedule\n",
    "            perturbed_images, epsilon = self.make_noisy(x_zeros, t)\n",
    "            \n",
    "            # (3) predict epsilon(noise) given perturbed data at diffusion-timestep t.\n",
    "            pred_epsilon = self.model(perturbed_images, t)\n",
    "            \n",
    "            return perturbed_images, epsilon, pred_epsilon\n",
    "        \n",
    "        \n",
    "        def denoise_at_t(self, x_t, timestep, t):\n",
    "            B, _, _, _ = x_t.shape\n",
    "            if t > 1:\n",
    "                z = torch.randn_like(x_t).to(self.device)\n",
    "            else:\n",
    "                z = torch.zeros_like(x_t).to(self.device)\n",
    "            \n",
    "            # at inference, we use predicted noise(epsilon) to restore perturbed data sample.\n",
    "            epsilon_pred = self.model(x_t, timestep)\n",
    "            \n",
    "            alpha = self.extract(self.alphas, timestep, x_t.shape)\n",
    "            sqrt_alpha = self.extract(self.sqrt_alphas, timestep, x_t.shape)\n",
    "            sqrt_one_minus_alpha_bar = self.extract(self.sqrt_one_minus_alpha_bars, timestep, x_t.shape)\n",
    "            sqrt_beta = self.extract(self.sqrt_betas, timestep, x_t.shape)\n",
    "            \n",
    "            # denoise at time t, utilizing predicted noise\n",
    "            x_t_minus_1 = 1 / sqrt_alpha * (x_t - (1-alpha)/sqrt_one_minus_alpha_bar*epsilon_pred) + sqrt_beta*z\n",
    "            \n",
    "            return x_t_minus_1.clamp(-1., 1)\n",
    "                    \n",
    "        def sample(self, N):\n",
    "            # start from random noise vector, x_0 (for simplicity, x_T declared as x_t instead of x_T)\n",
    "            x_t = torch.randn((N, self.img_C, self.img_H, self.img_W)).to(self.device)\n",
    "            \n",
    "            # autoregressively denoise from x_T to x_0\n",
    "            #     i.e., generate image from noise, x_T\n",
    "            for t in range(self.n_times-1, -1, -1):\n",
    "                timestep = torch.tensor([t]).repeat_interleave(N, dim=0).long().to(self.device)\n",
    "                x_t = self.denoise_at_t(x_t, timestep, t)\n",
    "            \n",
    "            # denormalize x_0 into 0 ~ 1 ranged values.\n",
    "            x_0 = self.reverse_scale_to_zero_to_one(x_t)\n",
    "            \n",
    "            return x_0\n",
    "        \n",
    "        \n",
    "    diffusion = Diffusion(model, image_resolution=img_size, n_times=n_timesteps, \n",
    "                        beta_minmax=beta_minmax, device=DEVICE).to(DEVICE)\n",
    "\n",
    "    optimizer = Adam(diffusion.parameters(), lr=lr)\n",
    "    denoising_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f74797",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start training DDPMs...\")\n",
    "model.train()\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    noise_prediction_loss = 0\n",
    "    for batch_idx, (x, _) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(DEVICE)\n",
    "        \n",
    "        noisy_input, epsilon, pred_epsilon = diffusion(x)\n",
    "        loss = denoising_loss(pred_epsilon, epsilon)\n",
    "        \n",
    "        noise_prediction_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"\\tEpoch\", epoch + 1, \"complete!\", \"\\tDenoising Loss: \", noise_prediction_loss / batch_idx)\n",
    "    \n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(\"Finish!! Total time: \", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0cce554",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\")\n",
    "model = Denoiser(image_resolution=img_size,\n",
    "                    hidden_dims=hidden_dims, \n",
    "                    diffusion_time_embedding_dim=timestep_embedding_dim, \n",
    "                    n_times=n_timesteps).to(DEVICE)\n",
    "diffusion = Diffusion(model, image_resolution=img_size, n_times=n_timesteps, beta_minmax=beta_minmax, device=DEVICE).to(DEVICE)\n",
    "\n",
    "print(\"Start training DDPMs...\")\n",
    "model.train()\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    noise_prediction_loss = 0\n",
    "    for batch_idx, (x, _) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(DEVICE)\n",
    "        \n",
    "        noisy_input, epsilon, pred_epsilon = diffusion(x)\n",
    "        loss = denoising_loss(pred_epsilon, epsilon)\n",
    "        \n",
    "        noise_prediction_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"\\tEpoch\", epoch + 1, \"complete!\", \"\\tDenoising Loss: \", noise_prediction_loss / batch_idx)\n",
    "    \n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(\"Finish!! Total time: \", total_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}