---
title: "フローベース模型による条件付き生成"
subtitle: "誘導からフローマッチングへ"
author: "司馬 博文"
date: 8/10/2024
date-modified: 8/22/2024
categories: [Deep, Sampling]
image: Files/RFDiff.gif
bibliography: 
    - ../../../assets/mathematics.bib
    - ../../../assets/bib.bib
    - ../../../assets/bib1.bib
csl: ../../../assets/apalike.csl
abstract-title: 概要
abstract: 拡散模型は拡張性にも優れており，条件付けが容易である．現状は誘導付き拡散によってこれが実現されるが，連続的な条件付き生成のために，フローマッチングなる方法も提案された．
listing: 
    -   id: diffusion-listing
        type: grid
        sort: false
        contents:
            - "Diffusion.qmd"
            - "NF1.qmd"
            - "EBM.qmd"
        date-format: iso
        fields: [title,image,date,subtitle]
---

{{< include ../../../assets/_preamble.qmd >}}

### 関連ページ {.unnumbered .unlisted}

::: {#diffusion-listing}
:::

## 誘導

拡散模型の美点には，条件付けが可能で拡張性に優れているという点もある．

実際，拡散模型の出現後，Conditional VAE [@Kingma+2014] などの従来手法を凌駕する条件付き生成が可能であることが直ちに理解された．

$C$ がクラスラベルなどの離散変数である場合，「誘導」による条件付き生成が初めに考えられた．

### はじめに

「誘導」ではまず，DDPM [@Ho+2020] でタイムステップ $t$ を positional encoding したようにして，プロンプト $c$ をデータに埋め込む．^[$c$ が $x_t$ と同じ画像である場合は，[@Ho+2022] のように $x_t$ にそのまま連結することも考えられる．]

そしてデータ $X$ とそのラベル $C$ に対して，条件付き分布 $\L[X|C]$ をモデリングする．

しかしこのアプローチの問題は，ラベル $C$ が不確実な場合などは，この情報を無視して普通の $X$ が生成されてしまいがちであることである．

そこで目的関数に，条件付き分布 $X|C$ の正確性を期すような追加のデザインをする．これが「誘導」である．

### 条件付きスコア場

条件付き分布 $p(x|c)$ を学習することを考える．

このとき $p(x|c)$ のスコアは，Bayes の定理から次のように表せる：
$$
\log p(x|c)=\log p(c|x)+\log p(x)-\log p(c),
$$
$$
\therefore\qquad\nabla_x\log p(x|c)=\nabla_x\log p(x)+\nabla_x\log p(c|x).
$$ {#eq-conditioned-score}

すなわち，条件付き確率 $p(x|c)$ のスコア場は，条件なしのスコア場 $\nabla_x\log p(x)$ と，分類器のスコア場 $\nabla_x\log p(c|x)$ の重ね合わせになる．

### 分類器による誘導 (CG) {#sec-CG}

式 ([-@eq-conditioned-score]) から，$\nabla_x\log p(x|c)$ が計算できる分類器 $p(c|x)$ を新たに訓練すれば，既存のモデル $\nabla_x\log p(x)$ から，サンプリング方法を変えるだけで条件付き生成ができる．

これを **CG: Classifier Guidance** [@Dhariwal-Nichol2021] といい，サンプリング中に各ステップで少しずつ $x_t$ が $p(x_t|c)$ に近づくように「誘導」されていく．

さらに，$c$ が無視されがちな場合も見越して，誘導スケール (guidance scale) という新たなハイパーパラメータ $\lambda\ge0$ を導入し，次のスコア
$$
\nabla_x\log p(x)+\lambda\nabla_x\log p(c|x).
$$ {#eq-CG-score}
からサンプリングすることも考えられる．

$\lambda>1$ としどんどん大きくしていくと，クラスラベル $c$ に「典型的な」サンプルが生成される傾向にある．

### 分類器なしの誘導

CG はいわばアドホックな方法であり，外部の分類器 $p(c|x)$ に頼らない方法を考えたい．

そのためには，式 ([-@eq-CG-score]) から $p(c|x)$ を消去して
$$
\lambda\nabla_x\log p(x|c)+(1-\lambda)\nabla_x\log p(x)
$$ {#eq-CFG-score}
とみて，$p(x|c),p(x)$ のいずれもデータから学ぶ．

このアプローチを **Classifier-Free Diffusion Guidance** [@Ho-Salimans2021] という．

その際は，新たなクラスラベル $\emptyset$ を導入して
$$
p(x)=p(x|\emptyset)
$$
とみなすことで，$p(x|c),p(x)$ を同一の [スコアネットワーク](Diffusion.qmd#sec-score-network) でモデリングする．

データセット内にランダムに1から2割の画像をクラスラベル $\emptyset$ と設定することで，これを実現する．

この方法は，追加の分類器の訓練が必要ないだけでなく，サンプリングのクオリティも向上する [@Nichol+2022], [@Saharia+2022SIGGRAPH]．これは分類タスクで訓練されたスコア $\log p(c|x)$ はどう訓練してもスコアネットワークで学習したスコア ([-@eq-CFG-score]) に匹敵する「良い」勾配が得られないためである．

### 高解像度画像生成への応用

#### Cascaded Generation {#sec-CascadedGeneration}

条件付き生成の技術はそのままで，最終的なクオリティを向上させるためには，Cascading [@Ho+2022] が使用可能である．

これは，画像生成は $x$ の解像度が低い状態で行い，この低解像度画像を次の条件付き拡散モデルの条件付け $c$ として，条件付き生成を **高解像度化** (super-resolution) に用いるものである [@Saharia+2023]．

この方法の美点は，条件付き生成器をたくさんスタックしたのちに，拡散模型間の段階でも Gauss ノイズや blur を印加することで，さらに最終的なクオリティが上げられるという [@Ho+2022]．これを **conditioning augmentation** と呼んでいる．

この方法は最初から高解像度での生成を目指して大規模な単一の拡散模型を設計するよりも大きく計算コストを削減できる．

Google も [Imagen](https://imagen.research.google/) [@Saharia+2022] でこのアーキテクチャを用いている．

#### Self-Conditioning [@Chen+2023]

拡散モデルを自己再帰的に用い，自身の前回の出力を今回の入力として逐次的にサンプリングを繰り返すことで，サンプリングのクオリティをさらに向上する自己条件づけが [@Chen+2023] で提案された．

この方法は RoseTTAFold Diffusion [@Watson+2023] によるたんぱく質構造生成でも用いられている：

![RFdiffusion generating a novel protein that binds to the insulin receptor. Taken from [Baker Lab HP](https://www.bakerlab.org/2023/07/11/diffusion-model-for-protein-design/)](Files/RFDiff.gif)

## フローマッチングによる連続な条件付け

### はじめに

連続な変数に対する条件付き確率からの生成は CcGAN [@Ding+2021] などでも試みられていた．

AlphaFold 3 [@Abramson+2024] や RoseTTAFold Diffusion [@Watson+2023], [@Krishna+2024] など，たんぱく質構造生成模型において拡散モデルが用いられている理由も，高精度な条件付き生成が可能であることが大きいという．

### 条件付きフローマッチング

２つの確率分布 $P_0,P_1\in\cP(\R^d)$ を結ぶ変換 $\phi_1:\R^d\to\R^d$ を学習することを考える．

## 文献紹介 {.appendix}

メンダコ氏によるブログ記事 [AlphaFold の進化史](https://horomary.hatenablog.com/entry/2024/06/30/211033) は AlphaFold3 が丁寧に解説されている．当該ブログは丁寧に書かれており，大変おすすめできる．

> Alphafold3とは長大な条件付けネットワークを備えた全原子拡散生成モデルであると前述したとおり、Alphafold3では必須入力としてタンパク質配列を、任意入力として核酸配列、SMILES形式で表現された低分子リガンド、金属イオンなどを長大な条件付けネットワークに入力することで、拡散モデルへの条件付けベクトルを作成します。

> DeepLearningで大規模分子の構造分布を予測するなんて数年前には考えられませんでしたが、拡散モデルによってすでに現実になりつつあります。一例として Distributional GraphormerというMicrosoft Researchの研究 [@Zheng+2024] を紹介します。

続きはぜひ，[メンダコ氏のブログ](https://horomary.hatenablog.com/entry/2024/06/30/211033#AlphaFold3-2024)でお読みください．