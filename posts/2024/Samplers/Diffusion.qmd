---
title: "拡散模型"
subtitle: "深層生成モデル６"
author: "司馬 博文"
date: 2/14/2024
date-modified: 8/2/2024
categories: [Deep, Process, Sampling]
bibliography: 
    - ../../../assets/mathematics.bib
    - ../../../assets/bib.bib
    - ../../../assets/bib1.bib
csl: ../../../assets/apalike.csl
abstract-title: 概要
abstract: 拡散模型はノイズからデータ分布まで到達するフローを生成する拡散過程を，データをノイズにする拡散過程の時間反転として学習する方法である．大規模なニューラルネットワークを用いて学習した場合，画像と動画に関しては 2024 年時点で最良の性能を誇る．
---

{{< include ../../../assets/_preamble.qmd >}}

## 導入

### アイデア

拡散モデルによる画像生成は，初め [@Dickstein+2015] で提案され，[@Ho+2020] で DDPM (Denoising Diffusion Probabilistic Model) として拡張された．^[VideoGPT の論文 [@Yan+2021] や，DALL-E2 の論文 [@Ramesh+2022]，GLIDE の論文 [@Nichol+2022] でも引用されている．]

[VAE](../Kernels/Deep4.qmd), [EBM](EBM.qmd), [正則化流](NF.qmd) はいずれもノイズからデータの分布までの変換を学ぼうとするが，拡散模型のアイデアは，**データをノイズにする方向の方が圧倒的に簡単である**ことを利用する．

まず訓練データを，完全な Gauss 分布になるような変換を拡散過程によって行う．これを複数段階に分けて実行し，エンコーダー
$$
q(x_0,x_T)dx_T=\int\cdots\int q(x_0,x_1)dx_1\cdots q(x_{T-1},x_T)dx_{T-1}
$$
を得る．

続いて，この逆過程 $p_\theta(x_t,x_{t-1})$ を VAE 様の方法で学習しようというのである．

この際，[スコアマッチング](EBM.qmd#sec-SM) を使うこともでき，NCSN (Noise Conditioned Score Network) [@Song+2021NeurIPS] などの方法が提案されている．

この２つの手法は，ノイズスケジュールが異なるのみで本質的に同じ枠組みであるとみなせる [@Huang+2021]．

### 拡散モデルの例

#### ADM [@Dhariwal-Nichol2021]

ADM (Ablated Diffusion Model) [@Dhariwal-Nichol2021] は ImageNet データの判別において当時の最先端であった BigGAN [@Brock+2019] の性能を凌駕した．

そのアーキテクチャには [U-Net](../Kernels/Deep.qmd#sec-U-net) [@Ronneberger+2015] が用いられた．

#### GLIDE [@Nichol+2022]

OpenAI の [GLIDE](https://github.com/openai/glide-text2im) (Guided Language to Image Diffusion for Generation and Editing) [@Nichol+2022] は，[CLIP](https://openai.com/research/clip) (Contrastive Language-Image Pre-training) というトランスフォーマーベースの画像符号化器と組み合わされた，テキスト誘導付き拡散モデルである．

#### Imagen [@Saharia+2022]

Google も [Imagen](https://imagen.research.google/) [@Saharia+2022] というCascaded Generation [-@sec-CascadedGeneration] に基づいた誘導付き拡散モデルを開発している．

T5-XXL [@Raffel+2020] に基づく言語モデルを通じて言語と画像を同等の潜在空間にのせ，U-Net アーキテクチャを持った VDM [-@sec-VDM] でモデリングすることで，高精度な text-to-image を実現している．

Palette [@Saharia+2022SIGGRAPH] は同様の仕組みで image-to-image を実現している．

<!-- [@Yang+2023-Diff] は動画生成に応用している． -->

#### 潜在拡散模型

[VAE](../Kernels/Deep4.qmd) や [GAN](../Kernels/Deep3.qmd) と違い，１つのニューラルネットワークしか用いないため，学習が安定しやすい．

一方で，生成時には逆変換を何度も繰り返す必要があるため，計算量が大きい．これを回避するために，生成を VAE 内の潜在空間で行うものを **潜在拡散モデル** (latent diffusion model) [@Rombach+2022] という．これが [Stable Diffusion](https://ja.stability.ai/stable-diffusion) の元となっている．

#### トランスフォーマーとの邂逅

並列化が容易であり，スケーラブルな手法であるため，トランスフォーマーと組み合わせて画像と動画の生成に使われる．

潜在拡散モデルで [U-Net](../Kernels/Deep.qmd#sec-U-net) [@Ronneberger+2015] を用いていたところをトランスフォーマーに置換した **拡散トランスフォーマー** (DiT: Diffusion Transformer) [@Peebles-Xie2023] が発表された．

その後，確率的補間 によって DiT を改良した SiT (Scalable Interpolant Transformer) [@Ma+2024] が発表された．

#### Discrete Denoising Diffusion Probabilistic Models (D3PM) [@Austin+2021]

Imagen にように言語を連続な潜在空間に埋め込む他に，直接離散空間上にも拡散模型を用いる事ができる．

実はこのように設計された拡散模型は，BERT [@Lewis+2020-BART] などのマスク付き言語モデルと等価になる．^[[@Murphy2023 p.880] 25.7.5 節も参照．]

MaskGIT (Masked Generative Image Transformer) [@Chang+2022] はこの枠組みに，画像をベクトル量子化して載せる．

## デノイジング拡散模型 (DDPM) {#sec-DDPM}

### 導入

DDPM はエンコーダー $q$ とデコーダー $p_\theta$ がそれぞれ複数層からなるような，階層的 VAE ともみなせる．

加えて，隠れ層は全て入力 $x_0$ と同じ次元 $d$ で作る点は，正則化流にも似ている（可逆とは限らないが）．

また，エンコーダー $q$ は
$$
q(x_0,x_T)\,dx_T=\rN_d(0,I_d)
$$
を満たすように，ノイズスケジュール $\{\beta_t\}$ の自由度のみを残して
$$
q(x_{t-1},x_t)\,dx_t:=\rN_d\paren{\sqrt{1-\beta_t}x_{t-1},\beta_tI_d},\qquad\beta_t\in(0,1),
$$
で固定し，学習すべきパラメータは入れない．


### デコーダーの設計

次の分布は解析的に求まる：
$$
q((x_t,x_0),x_{t-1})\,dx_{t-1}:=\rN_d\paren{\wt{\mu}_t(x_t,x_0),\wt{\beta}_tI_d}.
$$

このことに基づいて，
$$
p_\theta(x_t,x_{t-1})=\rN_d\Paren{\mu_\theta(x_t,t),\Sigma_\theta(x_t,t)},\qquad\Sigma_\theta(x_t,t):=\sigma_t^2I_d,
$$ {#eq-decoder-model}
とモデリングする．さらに $\sigma^2_t\in\{\beta_t,\wt{\beta}_t\}$ としてしまうことも多い．

総じて，データ分布を
$$
p_\theta(x_0):=\int_{\R^{d(T-1)}}p(x_T)p_\theta(x_T,x_{T-1})\cdots p_\theta(x_1,x_0)dx_{T-1}\cdots dx_1
$$
としてモデリングする．ただし，$p(x_T)\,dx_T=\rN_d(0,I_d)$．

### 変分推論

このモデルの対数尤度は，次のように下から評価できる：
\begin{align*}
    \log p_\theta(x_0)&=\log\int_{\R^{d(T-1)}}p_\theta(x_{0:T})\,dx_{1:T}\\
    &=\log\paren{\int_{\R^{d(T-1)}}\frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)}q(x_{1:T}|x_0)\,dx_{1:T}}\\
    &\ge\int_{\R^{d(T-1)}}\log\paren{p(x_T)\prod_{t=1}^T\frac{p_\theta(x_{t-1}|x_t)}{q(x_t|x_{t-1})}}q(x_{1:T}|x_0)\,dx_{1:T}=:-\L(x_0)
\end{align*}

このとき，
$$
\L(x_0)=\KL\Paren{q(x_T|x_0),p(x_T)}+\sum_{t=2}^T\int_{\R^d}\KL\Paren{q(x_{t-1}|x_t,x_0),p_\theta(x_{t-1}|x_t)}q(x_t|x_0)\,dx_t-\int_{\R^d}\log p_\theta(x_0|x_1)q(x_1|x_0)\,dx_1
$$
と展開できるが，登場する密度は全て正規密度であるため，全て計算できる．

だが [@Ho+2020] では，実際の訓練は正確な変分推論を実行するのではなく，この $\L(x_0)$ を簡略化したもの
$$
L'=\norm{\ep-\ep_0(X_t,t)}^2,\qquad t\sim\rU([T]),x_t\sim q_0(X_t),
$$
を用いた．[@Choi+2022] この議論をさらに進めている．

### Variational Diffusion Model (VDM) [@Kingma+2021] {#sec-VDM}

VDM では正確に $\L(x_0)$ を最小化し，真の変分推論を実行することを試みる．

エンコーダーの平均と分散
$$
q(x_t|x_0)=\rN_d\Paren{\wh{\al}_tx_0,\wh{\sigma}_t^2I_d}
$$
に関して $\L(x_0)$ を最適化する．これは SNR (Signal-to-Noise Ratio)
$$
R(t)=\frac{\wh{\al}_t^2}{\wh{\sigma}_t^2}=:e^{-\gamma_\phi(t)}
$$
をモデリングすることに等しく，$\gamma_\phi$ のモデリングにニューラルネットワークを用いることを考える．

[@Kingma+2021] はこのようにして正確な目的関数を定義し直し，さらにこれを推定する際に QMC によるより分散の小さい Monte Carlo 推定量を用いることを提案した．



## スコアベースの生成模型 (SGM) {#sec-SGM}

### 導入

スコアマッチングとはエネルギーベースモデルの文脈で生まれた手法であるが，そもそもスコア
$$
\nabla_x\log p(x)
$$
自体を学習することを生成モデリングの中心に据えることが SGM (Score-based Generative Model) [@Song-Ermon2019] で考えられた．エネルギー関数とスコア関数，どっちを学習の中心に据えるかについては [@Salimans-Ho2021] も参照．

しかしスコアを学習するにあたって最も致命的な点は，$\nabla_x\log p(x)$ の値は $p$ を一意的に定めないということである．特に，
$$
p=\pi p_0+(1-\pi)p_1,\qquad\pi\in(0,1)
$$
という関係があり，$p_0,p_1$ の台が互いに素であったとき，$\nabla_x\log p$ からは $\pi\in(0,1)$ を定めるための情報が完全に消えてしまう．

![[データが青，学習されたスコアが緑．](SM.qmd)](../../../docs/posts/2024/Samplers/SM_files/figure-html/fig-learned-score-output-1.png)

### デノイジングによる解決

[@Song-Ermon2019], [@Song-Ermon2020], [@Song+2021ICLR] はデータにノイズを印加し，これを除去する方向に学習することで，スコアマッチングの問題点を克服することを考えた．

ノイズを印加するとは，Gauss 核との畳み込みにより分布を軟化していくことに相当し，アニーリングと同じ効果を持つ．その結果，多峰性が消失してスコアマッチングが正確になる．加えて MCMC によるサンプリングも容易になる．

あとは，ノイズを失くしていく極限を取ると，限りなく正しくデータ分布を学ぶことができるようになっていく．

### Noise Conditional Score Network (NCSN) [@Song+2021NeurIPS]

この「データにノイズを印加して学びやすくし，徐々にノイズを除去していく」というアイデアは拡散模型のそれに他ならず，スコアマッチングと拡散模型が邂逅するのは時間の問題だったと言えるだろう．

スコアのスケール $\sigma$ の Gauss ノイズによる軟化列を $s_\theta(x,\sigma)$ と表すと，[デノイジングスコアマッチング](EBM.qmd##sec-DSM) (DNS) の目的関数の軟化列を得る：
$$
\L(\theta;\sigma)=\frac{1}{2}\E\Square{\Norm{s_\theta(\wt{X},\sigma)+\frac{\wt{X}-X}{\sigma^2}}^2_2}.
$$
これを組み合わせた目的関数
$$
\L(\theta;\sigma_{1:T})=\sum_{t=1}^T\lambda_t\L(\theta;\sigma_t),\qquad\lambda_t>0,
$$
を最終的な目的関数とする．

### DDPM との対応

以上，完全にスコアマッチングの観点から述べたが，NCSN は，ノイズスケジュールが異なるのみで本質的に DDPM [-@sec-DDPM] と同じ枠組みであるとみなせる [@Huang+2021]．

実際，
$$
\L(\theta;\sigma_t^2)=\L_{\text{simple}}
$$
が成り立つ．^[[@Murphy2023 p.867] 25.3.3 節も参照．]

## 連続時間極限

### 導入

ここまで，タイムステップ $t$ の取り方の議論をしていなかった．これはサンプリングに用いている拡散過程を離散化しているわけだから，その数学を借りることで更なる知見が得られる [@Tzen-Raginsky2019], [@Song+2021ICLR]．

加えて，データ分布をノイズ分布に還元するフローは，何も拡散過程だけが与えるわけではない．確定的なものも含め，ほとんどあらゆるダイナミクスを代わりに用いることができる．

特に，[MCMC がベクトル場に関する決定論的なフローで効率化させられる](../Slides/ZigZagSampler.qmd)ように，SDE の代わりに ODE を使うことで拡散模型のサンプリングを効率化する事ができる．

### 前向き拡散過程

データ分布を正規分布に還元する際に DDPM [-@sec-DDPM] で用いた拡散過程は，パラメータ $\beta(t)$ を持った $0$ に回帰的な拡散過程である：
$$
dX_t=-\frac{\beta(t)}{2}X_tdt+\sqrt{\beta(t)}dB_t,\qquad\beta\paren{\frac{t}{T}}=T\beta_t.
$$

このことは [@Song+2021ICLR] ですでに自覚されている．

一方で，SGM [-@sec-SGM] では
$$
dX_t=\sqrt{\dd{}{t}\sigma(t)^2}dB_t
$$
で定まる拡散過程を用いる．

### 後ろ向き拡散

[@Anderson1982], [@Haussmann-Pardoux1986] によると，一般に
$$
dX_t=f_t(X_t)\,dt+\sigma_t\,dB_t
$$
という SDE の時間反転は，
$$
dY_t=\Paren{f_t(Y_t)-\sigma_t^2\nabla_x\log q_t(Y_t)}\,dt+\sigma_t\,dB_{-t}
$$
が定める．Hyvärinen スコア関数が出てくるのである．^[Stein のスコア関数ともいう．]

特に，DDPM では
$$
dY_t=\Paren{-\frac{\beta_t}{2}Y_t-\beta_t\nabla_{x}\log q_t(Y_t)}\,dt+\sqrt{\beta_t}\,dB_{-t}
$$
と表せる．

このスコア関数 $\nabla_x\log q_t(X_t)$ を DSM によって推定した
$$
dY_t=-\frac{\beta_t}{2}\Paren{Y_t+2s_\theta(Y_t,t)}\,dt+\sqrt{\beta_t}\,dB_{-t}
$$
でデータ分布からサンプリングすることができるのである．なお，拡散過程のサンプリングは難しい問題であり，最も直接的には Euler-Maruyama 離散化を通じれば良い．

### 等価な分布フローを定める確定的ダイナミクス

代わりに ODE（[@Song+2021ICLR Sec D.3] が probability flow ODE と呼ぶ式）
$$
\dd{x_t}{t}=f(x,t)-\frac{g(t)^2}{2}\nabla_x\log p_t(x)
$$
で定まる確定的ダイナミクス $\{x_t\}$ を用いても，同様にデータ分布は $\rN_d(0,I_d)$ に還元される．

### 後ろ向き ODE

この ODE を推定した
$$
\dd{y_t}{t}=f(y,t)-\frac{g(t)^2}{2}s_\theta(y_t,t)
$$
を Euler 法，またはより高次な Heun 法などによって逆から解くことができる [@Karras+2022]．

これは[連続時間正規化流](NF.qmd#sec-CNF)，特に Neural ODE と等価なモデリングをすることになる．

実は SDE は
$$
dY_t=\Paren{f(y,t)-\frac{g(t)^2}{2}s_\theta(y_t,t)}-\frac{\beta_t}{2}s_\theta(y_t,t)dt+\sqrt{\beta_t}\,dB_t
$$
と，上記の確率的フロー ODE に Langevin 拡散の項を加えた形になっており，ODE によるアプローチはこの追加の Langevin 拡散項を消去することに等しい．

### サンプリング加速法 {#sec-acceleration}

ODE を用いることで拡散模型のサンプリング速度が向上する．[@Nichol-Dhariwal2021] も参照．

#### Denoising Diffusion Implicit Model (DDIM) [@JiamingSong+2021]

モデリングに用いる拡散過程の Markov 性を崩すことで，DDPM [-@sec-DDPM] より 10 倍から 50 倍速いサンプリングを実現したもの．

#### 逐次サンプリング問題としての解決

デコーダーに用いるモデル ([-@eq-decoder-model]) の表現力を上げることで，ステップサイズを大きくしてもサンプリングの性能を悪化させないようにすることを試みる．

例えば [@Gao+2021] は，ノイズ分布からデータ分布までのアニーリング列を，EBM の列として捉えてフィッティングをしている．同様のスキームで，[@Xiao+2021] は GAN を用いている．

#### 蒸留

[@Salimans-Ho2022] は Progressive Distillation と呼ばれる拡散過程の蒸留手法を提案している．

学習済みの拡散モデル（[@Salimans-Ho2022] では DDIM）から，徐々にステップ数を減らした蒸留モデルを作成していく．

#### 潜在拡散模型 (LDM) [@Rombach+2022]

まず画像データを VAE などで学習した潜在空間に変換し，その上で拡散模型でモデリングをする．

Latent Score-based Generative Model (LSGM) [@Vahdat+2021] では，VAE と拡散模型を同時に訓練することを考えている．

この手法は，潜在表現さえ適切に見つければ，複数のドメインのデータを同時に扱えるという美点がある．

また，[@Pandey+2022] では，まず VAE による生成モデルと作成し，その精度が足りない最終的な出力を高画質にするステップにのみ拡散模型を用いるスキームを提案している．

## 誘導付き拡散模型

拡散模型の更なる美点には，条件付けが可能で拡張性に優れているという点もある．

### Classifier Guidance (CG) [@Dhariwal-Nichol2021]

### Classifier-Free Diffusion Guidance [@Ho-Salimans2021]

### Cascaded Generation [@Ho+2022] {#sec-CascadedGeneration}


## 参考文献 {.appendix}

[`Awesome-Diffusion-Models`](https://github.com/diff-usion/Awesome-Diffusion-Models)，[What's the score?](https://scorebasedgenerativemodeling.github.io/)．

良いサーベイには次がある：[@Luo2022]，[@McAllester2023]．

古くからあり，すでに出版されているものには，[@Yang+2023], [@Cao+2024]．CVPR のチュートリアルが [@Kreis+2022], [@Song+2023]．

拡散モデルのサンプリングを加速する手法に関するサーベイは [@Nichol-Dhariwal2021], [@Croitoru+2023] など．