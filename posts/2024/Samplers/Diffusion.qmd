---
title: "拡散模型"
subtitle: "深層生成モデル６"
author: "司馬博文"
date: 2/14/2024
date-modified: 8/23/2024
image: Files/DDPM_outputs.png
categories: [Deep, Process, Sampling]
bibliography: 
    - ../../../assets/mathematics.bib
    - ../../../assets/bib.bib
    - ../../../assets/bib1.bib
csl: ../../../assets/apalike.csl
abstract-title: 概要
abstract: 拡散模型はノイズからデータ分布まで到達するフローを生成する拡散過程を，データをノイズにする拡散過程の時間反転として学習する方法である．大規模なニューラルネットワークを用いて学習した場合，画像と動画に関しては 2024 年時点で最良の性能を誇る．
listing: 
    -   id: diffusion-listing
        type: grid
        sort: false
        contents:
            - "NF1.qmd"
            - "NF3.qmd"
            - "DDPM.qmd"
            - "DD1.qmd"
            - "DD2.qmd"
            - "DiscreteDiffusion.qmd"
        date-format: iso
        fields: [title,image,date,subtitle]
---

{{< include ../../../assets/_preamble.qmd >}}

### 関連ページ {.unnumbered .unlisted}

::: {#diffusion-listing}
:::

## デノイジング拡散模型 (DDPM) {#sec-DDPM}

### はじめに

拡散モデルによる画像生成は，初め [@Dickstein+2015] で提案され，[@Ho+2020] で DDPM (Denoising Diffusion Probabilistic Model) として拡張された．

<!-- ^[VideoGPT の論文 [@Yan+2021] や，DALL-E2 の論文 [@Ramesh+2022]，GLIDE の論文 [@Nichol+2022] でも引用されている．] -->

<!-- [VAE](../Kernels/Deep4.qmd), [EBM](EBM.qmd), [正規化流](NF.qmd) はいずれもノイズからデータの分布までの変換を学ぼうとするが，拡散模型のアイデアは，**データをノイズにする方向の方が圧倒的に簡単である**ことを利用する． -->

DDPM では訓練データを，完全な Gauss 分布になるような変換を拡散過程によって行う．これを複数段階に分けて実行し，エンコーダー
$$
Q(x_0,-)=\int\cdots\int Q^1(x_0,dx_1)\cdots Q^T(x_{T-1},-)=\rN_d(0,I_d)
$$
を得る．

続いて，この逆過程 $p_\theta(x_t,x_{t-1})$ を VAE 様の方法で変分推論により学習しようというのである．

この方法は，Langevin サンプラーをデータ分布に誘導するスコア場を，種々のノイズレベル $\sigma_t>0$ で [スコアマッチング](EBM.qmd#sec-SM) により学習し，アニーリングをした Langevin サンプラーによりサンプリングをしていることに等価になる．

この SGM (Score-based Generative Model) としての見方（第 [-@sec-SGM] 節）からは，サンプリングに特化した [EBM](EBM.qmd) ともみなせる．

この２つの見方はノイズスケジュールの違いを除いて等価な目的関数を定める [@Huang+2021]．また，違う SDE が定める異なる拡散課程を用いて，ノイズ分布をデータ分布に輸送しているともみれる [@Song+2021ICLR]．現状２つの定式化は完全に等価とみなされ，単に **拡散模型** と言った場合 DDPM と SGM の双方を指す．

拡散模型は現在，連続時間ベースのフローベースモデルとして，[連続時間正規化流 (CNF)](NF1.qmd) と同一の枠組みで捉えられる [@Albergo+2023]．

### エンコーダーの設定 {#sec-DDPM-encoder}

前述の通り，DDPM はエンコーダー $q$ とデコーダー $p_\theta$ がそれぞれ複数層からなるような，階層的 VAE ともみなせる．

<!-- 加えて，隠れ層は全て入力 $x_0$ と同じ次元 $d$ で作る点は，正規化流にも似ている（可逆とは限らないが）． -->

ただし潜在空間上の事前分布は $\rN_d(0,I_d)$ で固定し，エンコーダー $q$ は
$$
Q(x_0,dx_T)=q(x_0,x_T)\,dx_T=\rN_d(0,I_d)
$$
を満たすように，ノイズスケジュール $\{\beta_t\}$ の自由度のみをハイパーパラメータとして残して
$$
Q^t(x_{t-1},dx_t):=\rN_d\paren{\sqrt{1-\beta_t}x_{t-1},\beta_tI_d},\qquad\beta_t\in(0,1),
$$
で固定し，学習すべきパラメータは入れない．

このとき
$$
Q^{1:t}(x_0,dx_t)=\rN_d\paren{\sqrt{\al_t}x_0,(1-\al_t)I_d},\qquad\al_t:=\prod_{s=1}^t(1-\beta_s),
$$
であり，後述の通り，これは OU 過程をシミュレーションしていることにあたる（第 [-@sec-forward-diffusion] 節）．

### デコーダーの設定

核 $Q^t(x_{t-1},dx_t)$ の逆
$$
q(x_{t-1}|x_t)\,dx_{t-1}dx_t=Q^t(x_{t-1},dx_t)\,dx_{t-1}
$$
を考えたい．この際，$x_0$ で条件づけると，次のような表示を得る：

::: {.callout-tip title="命題" icon="false"}

$$
q(x_{t-1}|x_t,x_0)\,dx_{t-1}=\rN_d\paren{\wt{\mu}_t(x_t,x_0),\wt{\beta}_tI_d}.
$$
ただし，$\wt{\mu}_t,\wt{\beta}_t$ は次のように定めた：
$$
\wt{\mu}_t(x_t,x_0):=\frac{(1-\al_{t-1})\sqrt{1-\beta_t}x_t+\sqrt{\al_{t-1}}\beta_tx_0}{1-\al_t},\qquad\wt{\beta}_t:=\frac{1-\al_{t-1}}{1-\al_t}\beta_t.
$$

:::
::: {.callout-note title="証明" icon="false" collapse="true"}

Bayes の定理から，
\begin{align*}
    q\Paren{x_{t-1},(x_t,x_0)}&=\frac{q(x_t|x_{t-1},x_0)q(x_{t-1}|x_0)}{q(x_t|x_0)}\\
    &=\frac{q(x_t|x_{t-1})q(x_{t-1}|x_0)}{q(x_t|x_0)}.
\end{align*}

いま，
$$
q(x_t|x_{t-1})=\frac{1}{(2\pi\beta_t)^{d/2}}\exp\paren{-\frac{\abs{x_t-\sqrt{1-\beta_t}x_{t-1}}^2}{2\beta_t}}
$$
$$
q(x_{t-1}|x_0)=\frac{1}{(2\pi(1-\al_{t-1}))^{d/2}}\exp\paren{-\frac{\abs{x_{t-1}-\sqrt{\al_{t-1}}x_0}^2}{2(1-\al_{t-1})}}
$$
$$
q(x_t|x_0)=\frac{1}{(2\pi(1-\al_t))^{d/2}}\exp\paren{-\frac{\abs{x_t-\sqrt{\al_t}x_0}^2}{2(1-\al_t)}}
$$
であるから，これを代入して結論を得る．


:::

このことに基づいて，
$$
P^t_\theta(x_t,dx_{t-1})=\rN_d\Paren{\mu_\theta(x_t,t),\Sigma_\theta(x_t,t)},\qquad\Sigma_\theta(x_t,t):=\sigma_t^2I_d,
$$ {#eq-decoder-model}
とモデリングする．

総じて，データ分布を
$$
p_\theta(x_0)\,dx_0:=\int_{\R^{dT}}p(x_T)P^T_\theta(x_T,dx_{T-1})\cdots P^1_\theta(x_1,dx_0)dx_T
$$ {#eq-decoder-model}
としてモデリングすることになる．ただし，$p(x_T)\,dx_T=\rN_d(0,I_d)$．

### DDPM の実装 {#sec-DDPM-implementation}

DDPM [@Ho+2020] では，平均のモデリングにのみパラメータを入れて，分散は
$$
\Sigma_\theta(x_t,t):=\sigma_t^2I_d,\qquad\sigma^2_t\in\{\beta_t,\wt{\beta}_t\}
$$
としてしまう．

$\beta_t$ の選択は Taylor 展開を通じた一次近似として正当化されるが，これにもニューラルネットワークを導入してより高次な近似をし，精度を上げる方法が [@Nichol-Dhariwal2021] で議論されている（第 [-@sec-acceleration-sequential] 節）．

加えて，$x_t,x_0$ で条件付けた $x_{t-1}$ の平均 $\wt{\mu}_t(x_t,x_0)$ は，
$$
x_t=\sqrt{\al_t}x_0+\sqrt{1-\al_t}\ep_t\quad\Leftrightarrow\quad x_0=\frac{1}{\sqrt{\al_t}}x_t-\frac{\sqrt{1-\al_t}}{\sqrt{\al_t}}\ep_t,\qquad\ep_t\sim\rN_d(0,I_d)
$$
を通じてパラメータ変換を施スト
\begin{align*}
    \wt{\mu}_t(x_t,\ep_t)&=\frac{1}{\sqrt{1-\beta_t}}\paren{\frac{1-\al_{t-1}}{1-\al_t}(1-\beta_t)x_t+\frac{\beta_t}{1-\al_t}x_t-\frac{\beta_t}{\sqrt{1-\al_t}}\ep_t}\\
    &=\frac{1}{\sqrt{1-\beta_t}}\paren{x_t-\frac{\beta_t}{\sqrt{1-\al_t}}\ep_t}
\end{align*}
を得る．

従って，$x_t$ から $x_{t-1}$ を予測する代わりに，$x_t$ から「どれくらいデノイジングするか？」を代わりに予測することもできる．すなわち，
$$
\wt{\mu}_\theta(x_t,t)=\frac{1}{\sqrt{1-\beta_t}}\paren{x_t-\frac{\beta_t}{\sqrt{1-\al_t}}\wt{\ep}_\theta(x_t,t)}
$$
というパラメータ変換により，$\wt{\mu}_t(x_t,t)$ の代わりに $\wt{\ep}_\theta(x_t,t)$ を予測する．

また $x_t$ は常に $d$ 次元で一定であるため，アーキテクチャは $U$-net や ConvNet などが用いられる．

![DDPM の出力の例．画像をタップしてコードを見る](Files/DDPM_outputs.png)

### 訓練

このモデルの対数尤度 ([-@eq-decoder-model]) は $\R^{dT}$ 上の積分を含む．そこで VAE 同様，最初の選択が変分推論となる．

次のように $\L(\theta,q)$ によって下から評価できる：

\begin{align*}
    \log p_\theta(x_0)&=\log\int_{\R^{dT}}p_\theta(x_{0:T})\,dx_{1:T}\\
    &=\log\paren{\int_{\R^{dT}}\frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)}q(x_{1:T}|x_0)\,dx_{1:T}}\\
    &\ge\int_{\R^{dT}}\log\paren{p(x_T)\prod_{t=1}^T\frac{p_\theta(x_{t-1}|x_t)}{q(x_t|x_{t-1})}}q(x_{1:T}|x_0)\,dx_{1:T}\\
    &=:\L(\theta,q).
\end{align*}

ただし，$\L(\theta,q)$ は次のように変形できる：

\begin{align*}
    \L(\theta,q)&=-\KL\Paren{q(x_T|x_0),p(x_T)}\\
    &\qquad-\sum_{t=2}^T\int_{\R^d}\KL\Paren{q(x_{t-1}|x_t,x_0),p_\theta(x_{t-1}|x_t)}q(x_t|x_0)\,dx_t\\
    &\qquad+\int_{\R^d}\log p_\theta(x_0|x_1)q(x_1|x_0)\,dx_1\\
    &=:\L_1(q)+\L_2(\theta,q)+\L_3(\theta,q).
\end{align*}

この式は [VAE の変分下界](../Kernels/Deep4.qmd#sec-ELBO) から，KL 乖離度の項が $T-1$ 個増えた形になっている．

この変分下界 $\L(\theta,q)$ の無限次元変数 $q$ の方は，$x$ からスタートするエンコーダー過程 [-@sec-DDPM-encoder] の確率核に固定してしまう．

すると，第二項 $\L_2(\theta)$ に登場する密度は全て正規密度であるため，解析的に計算できる：
$$
\KL\Paren{q(x_{t-1}|x_t,x_0),p_\theta(x_{t-1}|x_t)}=\frac{\abs{\wt{\mu}_t(x_t,x_0)-\mu_\theta(x_t,t)}^2}{2\beta_t}.
$$
第三項 $\L_3(\theta)$ は $q(x_1|x_0)\,dx_1=\rN_d(\sqrt{1-\beta_1}x_0,\beta_1I_d)$ からのサンプルにより Monte Carlo 近似できる．

### 代理目標 {#sec-DDPM-proxy-objective}

DDPM [@Ho+2020] では，$\wt{\mu}_\theta(x_t,t)$ の代わりに，$\wt{\ep}_\theta(x_t,t)$ を予測するのであった（第 [-@sec-DDPM-implementation] 節）．

この際，第三項は次の変更を受ける：
$$
\KL\Paren{q(x_{t-1}|x_t,x_0),p_\theta(x_{t-1}|x_t)}=\frac{\beta_t}{2(1-\al_t)(1-\beta_t)}\ABs{\wt{\ep}_\theta\Paren{\sqrt{\al_t}x_0+\sqrt{1-\al_t}\ep_t,t}-\ep_t}^2+\const
$$
第二項も全く同じ表記になり，$t=1$ の場合に当たるから，総じて
$$
\L(\theta)=-\sum_{t=1}^T\frac{\beta_t}{2(1-\al_t)(1-\beta_t)}\ABs{\wt{\ep}_\theta\Paren{\sqrt{\al_t}x_0+\sqrt{1-\al_t}\ep_t,t}-\ep_t}^2+\const
$$

しかし，DDPM [@Ho+2020] では，正確な変分推論を実行するのではなく，この係数を全て $1$ にした
$$
\L'=\abs{\ep_\tau-\wt{\ep}_\theta(X_\tau,\tau)}^2,\qquad X_\tau=\sqrt{\al_\tau}X_0+\sqrt{1-\al_\tau}\ep_\tau,\tau\sim\rU([T]),X_0\sim p(x_0)\,dx_0,\ep_\tau\sim\rN_d(0,I_d),
$$
を代理目標として用いた．ただし，$p(x_0)\,dx_0$ はデータ分布である．

これは純粋に，時刻 $t$ までに実際に印加されるノイズ $\ep_t$ とモデルが予測するノイズ $\wt{\ep}_\theta$ の二乗差を最小化することに等しい．

この目的関数の変更は，$t$ が小さい場合の誤差を小さく評価し，$t$ が大きい場合の誤差を大きく評価するため，大きい $t$ でのデノイジングというより難しいタスクを強調して学習する効果を持つという [@Ho+2020]．

[@Choi+2022] この代理目標の議論をさらに進めている．またこのような代理目標は，データ拡張の下では真の ELBO と一致する [@Kingma-Gao2023] ため，全く無根拠な変更というわけではない．

### 最尤推定 {#sec-VDM}

VDM (Variational Diffusion Model) [@Kingma+2021] では正確に $\L(\theta)$ を最小化することで最尤推定を実行する．

この方法では DDPM では固定されていたノイズスケジュール $\wt{\beta}_t$ の真の変分推論が実行できる．

$$
Q^{1:t}(x_0,dx_t)=\rN_d\Paren{\sqrt{\al_t}x_0,(1-\al_t)I_d}
$$
の変数 $\al_t$ をパラメータ変換した SNR (Signal-to-Noise Ratio)
$$
R(t)=\frac{\al_t}{1-\al_t}=:e^{-\gamma_\phi(t)}
$$
に注目し，$\gamma_\phi$ をニューラルネットワークでモデリングする．

この $R(t)$ を用いれば，正確な目的関数 $\L(\theta)$ はより簡単な表示を持つことを発見した [@Kingma+2021] は，さらにこれを訓練する際に QMC によるより分散の小さい Monte Carlo 推定量を用いることで，DDPM と同じくらい効率的に最尤推定が実行できることを示した．

[@Kingma+2021], [@Huang+2021] は無限層の VAE という DDPM の観点からの貢献であるが，SDE の観点からの最尤推定法を [@Song+2021NeurIPS], [@Vahdat+2021] が提案している（第 [-@sec-MLE-in-SGM] 節）．

## スコアベースの生成模型 (SGM) {#sec-SGM}

### はじめに

スコアマッチングはもともと，[エネルギーベースモデル (EBM)](EBM.qmd#sec-SM) の学習手法として [@Hyvarinen2005] により提案された．

そもそも EBM も優秀な生成モデルとして知られている [@Du-Mordatch2019], [@Gao+2020] が，スコアマッチングによるスコアの学習はもっと直接的に生成モデルを定める：

::: {.callout-tip appearance="simple" icon="false"}

スコア（または Stein [@Liu+2016] / [@Hyvarinen2005] スコア）と呼ばれるベクトル場
$$
\nabla_x\log p(x)
$$
自体を学習できれば，これが駆動する OU 過程を用いて $p(x)$ からサンプリングを行うことが出来る．

:::

これが **SGM (Score-based Generative Model)** [@Song-Ermon2019] のアイデアであった．^[エネルギー関数とスコア関数，どっちを学習の中心に据えるかについては [@Salimans-Ho2021] も参照．]

このアイデアは既存の [DSM (Denoising Score Matching)](EBM.qmd#sec-DSM) の改良とも見れる．

DSM はデータに印加するノイズ $\sigma>0$ が強いほど推定が安定するが，推定対象であるノイズが印加されたスコアは元のデータ分布から乖離してしまうというトレードオフがあった．これをアニーリングによって解決する方法とも見れる．

### SGM の課題

しかしこのスキームの課題は，$\nabla_x\log p(x)$ の値は $p$ を一意的に定めないということである．

例えば，
$$
p=\pi p_0+(1-\pi)p_1,\qquad\pi\in(0,1)
$$
という関係があり，$p_0,p_1$ の台が互いに素であったとき，$\nabla_x\log p$ からは $\pi\in(0,1)$ を定めるための情報が完全に消えてしまう．

すなわち，データが下図のように部分多様体上にのみ台を持つ場合は，モデルが識別可能でない．

![[スコアマッチングの例：データが青，学習されたスコア場が緑．](EBM1.qmd)](../../../docs/posts/2024/Samplers/SM_files/figure-html/fig-learned-score-output-1.png)

これにより間違ったスコアが学習され，多峰性を持ってしまった場合，OU 過程によるサンプリングが失敗する [@Song-Ermon2019]．

従って，各ノイズレベル $\sigma$ に対応したスコア場を学習し，Langevin サンプラーをノイズが大きく分布が単純な領域からスタートさせ，徐々にデータ分布に近づけて収束を促す（アニーリング）．

すると SGM は，最初の発想は全く違えど，最終的に得られるモデルは，DDPM と等価になる．

### デノイジングによる解決 {#sec-score-network}

SGM [@Song-Ermon2019], [@Song-Ermon2020] ではデータにさまざまな強度 $\sigma$ の Gauss ノイズを印加したもののスコア場を，スコアマッチングで学習することを考える．

ノイズレベル $\sigma$ も入力に含めることで，単一のニューラルネットワーク $s_\theta(x,\sigma)$ で学習をする．このアーキテクチャを **NCSN (Noise Conditional Score Network)** [@Song-Ermon2019] または単に **スコアネットワーク** [@Song-Ermon2020] という．

ノイズを印加することは，Gauss 核との畳み込みにより分布を軟化していくことに相当し，アニーリングと同じ効果を持つ．

その結果，$\sigma$ が十分大きい際は多峰性が消失してスコアマッチングが正確になる．加えて MCMC によるサンプリングも容易になる．

はじめ，OU 過程を十分に大きい $\sigma>0$ に対応するスコアで駆動させ，徐々に $\sigma\to0$ としていくことで，データ分布からサンプリングすることを目指す．^["Our sampling strategy is inspired by simulated annealing [@Kirkpartick+1983], [@Neal2001] which heuristically improves optimization for multimodal landscapes." [@Song-Ermon2019 p.2] より．]

### 目的関数

<!-- この「データにノイズを印加して学びやすくし，徐々にノイズを除去していく」というアイデアは拡散模型のそれに他ならず，スコアマッチングと拡散模型が邂逅するのは時間の問題だったと言えるだろう． -->

スコアのスケール $\sigma$ の Gauss ノイズにより軟化したデータのスコア場を $s_\theta(x,\sigma)$ と表し，[デノイジングスコアマッチング](EBM.qmd##sec-DSM) (DNS) の目的関数の列を考える：^[DNS も SSM も使用可能であるが，ここでは Langevin サンプラーのアニーリングのために，ノイズが印加されたベクトル場 $s_\theta(x,\sigma)$ の学習が必要であるため，DNS の選択が自然である [@Song-Ermon2019]．]
$$
\L(\theta;\sigma)=\frac{1}{2}\E\Square{\Norm{s_\theta(\wt{X},\sigma)+\frac{\wt{X}-X}{\sigma^2}}^2_2}.
$$

この DNS 目的関数の，ある等比数列 $\sigma_1>\cdots>\sigma_T>0$ に関する線型和
$$
\L(\theta;\sigma_{1:T})=\sum_{t=1}^T\lambda_t\L(\theta;\sigma_t),\qquad\lambda_t>0,
$$ {#eq-SGM-objective}
を最終的な目的関数とする．

数列 $(\sigma_i)$ の設定の仕方，$\sigma_1$ をどこまで大きくすれば良いか，などは [@Song-Ermon2020] の理論解析を参照．ステップ数 $T$ は大きければ大きいほどよい．

### DDPM との対応

この SGM の目的関数 ([-@eq-SGM-objective]) は，ノイズスケジュール $\lambda_t$ が異なるのみで DDPM [-@sec-DDPM] と同じ目的関数となっている [@Ho+2020], [@Huang+2021]．

実際，
$$
\L(\theta;\sigma_t^2)=\E\Square{\frac{\lambda_\tau}{\sigma_\tau^2}\abs{\ep_\tau-\wt{\ep}_\theta(X_\tau,\tau)}^2}
$$
と表せるから，ハイパーパラメータ $\lambda_t$ を $\lambda_t=\sigma_t^2$ と取ることで，DDPM の代理目的関数 [-@sec-DDPM-proxy-objective] に一致する．

### 最尤推定 {#sec-MLE-in-SGM}

近似が入っている DDPM の訓練目標と対応していることから判るように，スコアマッチングは正確な最尤推定を実行していない．

かといって，正確な変分推論 [-@sec-VDM] を実行するのは高くつく．

[@Song+2021NeurIPS] はスコアマッチングと同じくらい効率的な最尤推定法が，目的関数 ([-@eq-SGM-objective]) の重みづけ $(\lambda_t)$ を特定の値 **likelihood weighting** にとることで得られることを示している．^[これが可能であることは [@Ho+2020 p.8] でも触れられている．]

![[@Song+2021NeurIPS p.5]](Files/Song+(2021).png)

## 連続時間極限

### はじめに

DDPM [-@sec-DDPM] と SGM [-@sec-SGM] は，いずれも OU 過程とその時間反転の離散化として統一的に理解できる．

この連続時間極限に関する知見が，モデルのデザインに関して示唆を与えてくれる [@Tzen-Raginsky2019], [@Song+2021ICLR]．

タイムステップ $t$ の取り方は適応的にできるし，^[ちょうど，[Neural ODE](NF1.qmd) がタイムステップの取り方を適応的にしてくれたように．] SDE ([-@eq-OU]) と等価な輸送を定める ODE を考え，サンプリングを加速することも考えられる．^[ちょうど，[MCMC がベクトル場に関する決定論的なフローで効率化させられる](../Slides/ZigZagSampler.qmd)ように．]

### 前向き拡散過程 {#sec-forward-diffusion}

データ分布を正規分布に還元する際に DDPM [-@sec-DDPM] で用いた拡散過程は，パラメータ $\beta(t)$ を持った $0$ に回帰的な OU 過程である [@Song+2021ICLR p.5]：
$$
dX_t=-\frac{\beta(t)}{2}X_tdt+\sqrt{\beta(t)}dB_t,\qquad\beta\paren{\frac{t}{T}}=T\beta_t.
$$ {#eq-OU}

これを [@Song+2021ICLR] では **分散保存過程** (variance-preserving process) と呼んでいる．

一方で，SGM [-@sec-SGM] では
$$
dX_t=\sqrt{\dd{}{t}\sigma(t)^2}dB_t
$$
で定まる拡散過程を用いる．これを [@Song+2021ICLR] では **分散爆発過程** (variance-exploding process) と呼んでいる．

### 後ろ向き拡散

[@Anderson1982] によると，一般に
$$
dX_t=f_t(X_t)\,dt+\sigma_t\,dB_t
$$
という [SDE の時間反転](../Process/TimeReversalDiffusion.qmd) は，
$$
dY_t=\Paren{f_t(Y_t)-\sigma_t^2\nabla_x\log q_t(Y_t)}\,dt+\sigma_t\,dB_{-t}
$$
が定める．ここにスコア場 $\nabla_x\log q_t$ が出てくるのである．

特に，OU 過程 ([-@eq-OU]) の時間反転は
$$
dY_t=\Paren{-\frac{\beta_t}{2}Y_t-\beta_t\nabla_{x}\log q_t(Y_t)}\,dt+\sqrt{\beta_t}\,dB_{-t}
$$
と表せる．

このスコア関数 $\nabla_x\log q_t(X_t)$ を DSM によって推定した
$$
dY_t=-\frac{\beta_t}{2}\Paren{Y_t+2s_\theta(Y_t,t)}\,dt+\sqrt{\beta_t}\,dB_{-t}
$$
でデータ分布からサンプリングすることができるのである．なお，拡散過程のサンプリングは難しい問題であり，最も直接的には Euler-Maruyama 離散化を通じれば良い．

### 等価な輸送を定める確定的ダイナミクス

代わりに ODE
$$
\dd{x_t}{t}=f(x,t)-\frac{g(t)^2}{2}\nabla_x\log p_t(x)
$$
で定まる確定的ダイナミクス $\{x_t\}$ を用いても，同様にデータ分布は $\rN_d(0,I_d)$ に還元される．

これを [@Song+2021ICLR Sec D.3] は probability flow ODE と呼ぶ．

### 後ろ向き ODE {#sec-probability-flow-ODE}

この ODE を推定した
$$
\dd{y_t}{t}=f(y,t)-\frac{g(t)^2}{2}s_\theta(y_t,t)
$$
を Euler 法，またはより高次な Heun 法などによって逆から解くことができる [@Karras+2022]．

これは[連続時間正規化流](NF.qmd#sec-CNF)，特に Neural ODE と等価なモデリングをすることになる．

実は SDE は
$$
dY_t=\Paren{f(y,t)-\frac{g(t)^2}{2}s_\theta(y_t,t)}-\frac{\beta_t}{2}s_\theta(y_t,t)dt+\sqrt{\beta_t}\,dB_t
$$
と，上記の確率的フロー ODE に OU 過程の項を加えた形になっており，ODE によるアプローチはこの追加の OU 過程項を消去することに等しい．

## 応用

### サンプリング加速法 {#sec-acceleration}

ODE を用いることで拡散模型のサンプリング速度が向上する．[@Nichol-Dhariwal2021] も参照．

#### Denoising Diffusion Implicit Model (DDIM) [@JiamingSong+2021] {#sec-DDIM}

DDIM [@JiamingSong+2021] は，スタート地点 $x_0$ に条件付けられた確率核
$$
q_\sigma(x_{t-1}|x_t,x_0)\,dx_{t-1}=\rN\Paren{\sqrt{\al_{t-1}}x_0+\sqrt{1-\al_{t-1}-\sigma_t^2}\frac{x_t-\sqrt{\al_t}x_0}{\sqrt{1-\al_t}},\sigma_t^2I_d}
$$ {#eq-DDIM}
を考える．^[[@JiamingSong+2021] 内では $q_\sigma(x_t|x_{t-1},x_0)$ の形を与えていないが，Bayes の定理を通じてわかる：$$q_\sigma(x_t|x_{t-1},x_0)=\frac{q_\sigma(x_{t-1}|x_t,x_0)q_\sigma(x_t|x_0)}{q_\sigma(x_{t-1}|x_0)}.$$] これを $x_0$ に関して積分すると元の確率核 $q_\sigma(x_{t-1}|x_t)$ を得る．

$\sigma_t$ は任意としており，
$$
\sigma_t=\sqrt{\frac{1-\al_{t-1}}{1-\al_t}}\sqrt{1-\frac{\al_t}{\al_{t-1}}}
$$
と取った場合，$q_\sigma(x_{t-1}|x_t,x_0)$ は $x_0$ にもはや依らず，DDPM の設定を回復する．

$q_\sigma(x_{t-1}|x_t,x_0)$ の時間反転は次のように与えられる：
$$
p_\theta(x_{t-1}|x_t)\,dx_{t-1}=\rN\Paren{\sqrt{\al_{t-1}}\wh{x}_0+\sqrt{1-\al_{t-1}-\sigma_t^2}\frac{x_t-\sqrt{\al_t}\wh{x}_0}{\sqrt{1-\al_t}},\sigma_t^2I_d}.
$$

ただし，$x_0$ は事前にはわからないから，これをニューラルネットワークによりモデリングするとする：
$$
\wh{x}_0=\frac{x_t-\sqrt{1-\al_t}\ep_\theta(x_t,t)}{\sqrt{\al_t}}.
$$

すると，この際の目的関数は DDPM と全く変わらない．すなわち，既存の DDPM の訓練は特別な $\sigma_t$ に関する DDIM ([-@eq-DDIM]) の訓練とみなせるのである．

$\sigma_t$ が自由となると，$\sigma_t\equiv0$ と取っても良いはずである．この場合，サンプリングの過程は確定的になる．

総じて，すでに訓練された DDPM の $\ep_\theta(x_t,t)$ があれば，この $\sigma_t\equiv0$ の場合のサンプリング過程を採用すれば，DDPM [-@sec-DDPM] より 10 倍から 50 倍速いサンプリングが実現できる．

#### 逐次サンプリング問題としての解決 {#sec-acceleration-sequential}

デコーダーに用いるモデル ([-@eq-decoder-model]) の表現力を上げることで，ステップサイズを大きくしてもサンプリングの性能を悪化させないようにできる．

[@Nichol-Dhariwal2021] は $\Sigma_\theta(x_t,t)$ もニューラルネットワークで学習することで，サンプリングのステップサイズを大きくしてもサンプルの質を保つことができると報告している．

[@Kingma+2021] も，ノイズスケジュールも学習しようとしている点で似ている．

[@Gao+2021] は，ノイズ分布からデータ分布までのアニーリング列を，EBM の列として捉えてフィッティングをしている．同様のスキームで，[@Xiao+2021] は GAN を用いている．

#### 蒸留

[@Salimans-Ho2022] は Progressive Distillation と呼ばれる拡散過程の蒸留手法を提案している．

学習済みの拡散モデル（[@Salimans-Ho2022] では DDIM）から，徐々にステップ数を減らした蒸留モデルを作成していく．

#### 潜在拡散模型 (LDM) [@Rombach+2022]

まず画像データを VAE などで学習した潜在空間に変換し，その上で拡散模型でモデリングをする．

Latent Score-based Generative Model (LSGM) [@Vahdat+2021] では，VAE と拡散模型を同時に訓練することを考えている．

この手法は，潜在表現さえ適切に見つければ，複数のドメインのデータを同時に扱えるという美点がある．

また，[@Pandey+2022] では，まず VAE による生成モデルと作成し，その精度が足りない最終的な出力を高画質にするステップにのみ拡散模型を用いるスキームを提案している．

#### SDE から ODE へ (DEIS)

DEIS (Diffusion Exponential Integrator Sampler) [@Zhang-Chen2023] では，付随する ODE [-@sec-probability-flow-ODE] を Euler 法ではなく指数積分法で解くことで，離散化誤差を低減しつつサンプリングを加速する．

### 拡散モデルの例

#### ADM [@Dhariwal-Nichol2021]

ADM (Ablated Diffusion Model) [@Dhariwal-Nichol2021] と [分類器による誘導](NF3.qmd#sec-CG) は ImageNet データの判別において当時の最先端であった BigGAN [@Brock+2019] の性能を凌駕した．

そのアーキテクチャには [U-Net](../Kernels/Deep.qmd#sec-U-net) [@Ronneberger+2015] が用いられた．

#### GLIDE [@Nichol+2022]

OpenAI の [GLIDE](https://github.com/openai/glide-text2im) (Guided Language to Image Diffusion for Generation and Editing) [@Nichol+2022] は，[CLIP](https://openai.com/research/clip) (Contrastive Language-Image Pre-training) というトランスフォーマーベースの対照学習による画像テキスト同時表現学習器と組み合わされた，テキスト誘導付き拡散モデルである．

#### Imagen [@Saharia+2022]

Google も [Imagen](https://imagen.research.google/) [@Saharia+2022] という [Cascaded Generation](NF3.qmd#sec-CascadedGeneration) [@Ho+2022] に基づいた誘導付き拡散モデルを開発している．

T5-XXL [@Raffel+2020] に基づく言語モデルを通じて言語と画像を同等の潜在空間にのせ，U-Net アーキテクチャを持った VDM [-@sec-VDM] でモデリングすることで，高精度な text-to-image を実現している．

Palette [@Saharia+2022SIGGRAPH] は同様の仕組みで image-to-image を実現している．

<!-- [@Yang+2023-Diff] は動画生成に応用している． -->

#### 潜在拡散模型

[VAE](../Kernels/Deep4.qmd) や [GAN](../Kernels/Deep3.qmd) と違い，１つのニューラルネットワークしか用いないため，学習が安定しやすい．

一方で，生成時には逆変換を何度も繰り返す必要があるため，計算量が大きい．これを回避するために，生成を VAE 内の潜在空間で行うものを **潜在拡散モデル** (latent diffusion model) [@Rombach+2022] という．これが [Stable Diffusion](https://ja.stability.ai/stable-diffusion) の元となっている．

#### トランスフォーマーとの邂逅

並列化が容易であり，スケーラブルな手法であるため，トランスフォーマーと組み合わせて画像と動画の生成に使われる．

潜在拡散モデルで [U-Net](../Kernels/Deep.qmd#sec-U-net) [@Ronneberger+2015] を用いていたところをトランスフォーマーに置換した **拡散トランスフォーマー** (DiT: Diffusion Transformer) [@Peebles-Xie2023] が発表された．

その後，確率的補間 によって DiT を改良した SiT (Scalable Interpolant Transformer) [@Ma+2024] が発表された．

#### [Discrete Denoising Diffusion Probabilistic Models (D3PM)](DiscreteDiffusion.qmd#sec-D3PM) [@Austin+2021]

Imagen にように言語を連続な潜在空間に埋め込む他に，直接離散空間上にも拡散模型を用いる事ができる．

実はこのように設計された拡散模型は，BERT [@Lewis+2020-BART] などのマスク付き言語モデルと等価になる．

MaskGIT (Masked Generative Image Transformer) [@Chang+2022] はこの枠組みに，画像をベクトル量子化して載せる．

## 参考文献 {.appendix}

[`Awesome-Diffusion-Models`](https://github.com/diff-usion/Awesome-Diffusion-Models)，[What's the score?](https://scorebasedgenerativemodeling.github.io/)．

良いサーベイには次がある：[@Luo2022]，[@McAllester2023]．古くからあり，すでに出版されているものには，[@Yang+2023], [@Cao+2024]．

CVPR のチュートリアルが [@Kreis+2022], [@Song+2023Tutorial]．Web サイトには [@Dieleman2023]，[@Yuan2024]，[@Duan2023]，[@Das2024]．

また，入門的な内容が [@Nakkiran+2024] で扱われている．

拡散モデルのサンプリングを加速する手法に関する論文には [@Nichol-Dhariwal2021], [@Croitoru+2023] など．