---
title: "雑音除去拡散過程"
subtitle: "Denoising Diffusion によるサンプリング"
author: "司馬 博文"
date: 8/3/2024
date-modified: 8/5/2024
categories: [Process, Sampling]
bibliography: 
    - ../../../assets/mathematics.bib
    - ../../../assets/bib.bib
    - ../../../assets/bib1.bib
csl: ../../../assets/apalike.csl
abstract-title: 概要
abstract: 拡散模型はノイズからデータ分布まで到達するフローを生成する拡散過程を，データをノイズにする拡散過程の時間反転として学習する方法である．大規模なニューラルネットワークを用いて学習した場合，画像と動画に関しては 2024 年時点で最良の性能を誇る．
listing: 
    -   id: diffusion-listing
        type: grid
        sort: false
        contents:
            - "Diffusion.qmd"
            - "DD2.qmd"
            - "DiscreteDiffusion.qmd"
        date-format: iso
        fields: [title,image,date,subtitle]
---

{{< include ../../../assets/_preamble.qmd >}}

### 関連ページ {.unnumbered .unlisted}

::: {#diffusion-listing}
:::

<!-- ::: {layout-ncol=2 layout-valign="bottom"}

[![拡散模型（深層生成モデル６）](../../../docs/posts/2024/Samplers/SM_files/figure-html/fig-learned-score-output-1.png)](Diffusion.qmd)

[![雑音除去拡散サンプラー](Files/unnormalized_target.svg)](DD2.qmd)

::: -->


## 雑音除去拡散 {#sec-DDPS}

潜在空間 $\cX$ 上の事前分布 $\mu$ と，尤度が確率核 $\cX\to\cY$
$$
x\mapsto g(y|x)\,dy
$$
の形で与えられているとする．

### 雑音除去拡散 (DD)

[拡散模型](Diffusion.qmd) は，次で定まる OU 過程によってデータ分布を $\rN_d(0,I_d)$ にまで破壊しているとみなせる [@Song+2021ICLR]：
$$
dX_t=-\frac{1}{2}X_t\,dt+dB_t,\qquad X_0\sim p(x|y).
$$

ただし，この過程は指数エルゴード性を持つと言っても，完全に $\rN_d(0,I_d)$ に従うようになるのは $t\to\infty$ の極限においてである．この極限においては，$p(x|y)$ はもやは $y$ に依らなくなる．

この $(X_t)$ の有限時区間 $[0,T]$ における時間反転は，$(X_t)$ の密度を $p_t(x_t|y)$ で表すと，
$$
dZ_t=\frac{1}{2}Z_t\,dt+\nabla_z\log p_{T-t}(Z_t|y)\,dt+dW_t,\qquad Z_0\sim p_T(x_T|y),
$$ {#eq-denoising-diffusion}
の弱解になる [@Anderson1982], [@Haussmann-Pardoux1986]．この $(Z_t)_{t\in[0,T]}$ を **雑音除去拡散** (Denoising Diffusion) という．

### $(Z_t)$ からのサンプリング {#sec-DDPS-sampling}

すると残りの問題は，拡散過程 $(Z_t)_{t\in[0,T]}$ からのサンプリングになるが，これは $\log p_{T-t}(Z_t|y)$ という項の評価と $p_T(x_T|y)$ からのサンプリングが必要である．

$(Z_t)$ を
$$
dZ_t=\frac{1}{2}Z_t\,dt+s_{T-t}^\theta(Z_t,y)\,dt+dW_t,\qquad Z_0\sim\rN_d(0,I_d),
$$
で近似することが [@Song+2021ICLR] の方法である．思い切って $\rN_d(0,I_d)\approx p_T(x_T|y)$ としてしまい，$s_t^\theta(x_t,y)$ のモデリングに特化するのである．

この過程 $(Z_t)$ が定める測度を $\bQ_y^\theta\in\cP(C([0,T];\cX))$ と表すと，訓練目標は KL 乖離度の期待値
\begin{align*}
    \L(\theta)&:=2\E\SQuare{\KL\Paren{\bP_Y,\bQ_Y^\theta}}\\
    &=\int^T_0\E\SQuare{\Norm{s^\theta_t(X_t,Y)-\nabla_x\log p_{t|0}(X_t|X_0)}^2}\,dt+\const
\end{align*}
が考えられる．ただし，$\bP_Y$ は $(X_t)$ の分布，$p_{t|0}$ は $(X_t)$ の遷移密度を表す．この損失は [DSM](EBM.qmd#sec-DSM) [@Vincent2011] で与えられたものに等しい．

$$
(X_0,Y)\sim p(x,y)=g(y|x)\mu(x)
$$
からのシミュレーションが可能であるならば，この目的関数は確率的最適化アルゴリズムによって最適化できる．

こうして，雑音除去拡散サンプラー (DDPS: Denoising Diffusion Posterior Sampler) を得る．

### 近似ベイズ計算への応用

事前分布と尤度 $g(y|x)$ からのサンプリングが可能な状況は，生成モデリングの他に Simulation-based Inference などの近似推論でもあり得る．

実際，この DDPS は従来の ABC (Approximate Bayesian Computation) 法の代替になり得る．

さらに，[拡散模型の加速法](Diffusion.qmd#sec-acceleration) （Progressive Distillation [@Salimans-Ho2022] など）が DDPS にも応用可能である．

### 逆問題への応用

サンプルが画像だとしても，画像修復 (inpainting) や高解像度化 (super-resolution) などの逆問題応用が豊富に存在する．

このような，単一の $Y=y$ を固定した状況で潜在変数 $X_T$ からサンプリングをしたい場合では，$\log p_t(x_t|y)$ を一緒くたに $s^\theta_{t}(x_t,y)$ に取り替えてしまうのではなく，次の事前分布と尤度への分解に基づいて扱うこともできる：

$$
\nabla_x\log p_t(x_t|y)=\nabla_x\log\mu_t(x_t)+\nabla_x\log g_t(y|x_t),
$$
$$
\mu_t(x_t):=\int_\cX\mu(x_0)p_{t|0}(x_t|x_0)\,dx_0,\qquad g_t(y|x_t):=\int_\cX g(y|x_0)p_{0|t}(x_0,x_t)\,dx_0.
$$

この第一項は $s_t^\theta(x_t)$ により統一的にモデリングでき，同様に $X_0\sim\mu(x)$ から始まる雑音化過程 $(X_t)$ の分布を $\bP$ として $\KL(\bP,\bQ^\theta)$ 最小化問題として処理できる．

$g_t(y|x_t)$ の項も近似可能である．[@Chung+2023] では条件付き誘導が，[@Song+2023] では Monte Carlo 法が用いられている．

## Schrödinger 橋による事後分布サンプリング (DSB-PS) {#sec-DSB-PS}

### はじめに

$p_T(x_T|y)\approx\rN_d(0,I_d)$ の近似を成り立たせるために $T$ を十分大きく取る必要がある問題は，OU 過程の代わりに Schrödinger 橋を用いることで解決できることが [@Shi+2022] で提案された．

Schrödinger 橋自体は，[@DeBortoli+2021] などから拡散模型への応用は議論されていた．

### 定義

**Schrödinger 橋 (SB)** とは，
$$
\Pi^*:=\argmin_{\Pi\in\cP_0}\KL(\Pi,\bP),
$$
$$
\cP_0:=\BRace{\Pi\in\cP(C([0,T];\cX\times\cY))\,\bigg|\,\Pi_0(x_0,y_0)=p(x_0,y_0),\Pi_T(x_T,y_T)=\rN_d(0,I_d)p(y_T)},
$$
によって定まる確率分布に従う確率過程をいう．ただし，$\bP:=\bP_{y_0}\otimes\delta_{p(y)}$ とした．$\delta_{p(y)}$ は次で定まる確率分布である：
$$
dY_t=0,\qquad Y_0\sim p(y).
$$

これは表示
$$
\Pi^*=\bP^*_{y_0}\otimes\delta_{p(y)}
$$
を持つから，$Z_0\sim\rN_d(0,I_d)$ に従う過程 $(Z_t)$ をシミュレーションすることで，
$$
Z_T\sim\Pi^*_0(x|y)=p(x_0|y)\qquad p(y)\das
$$
が成り立つ．

### SB のシミュレーション

SB 問題の解 $\Pi$ は **逐次的比例フィッティング** (IPF: Iterative Proportional Fitting) により得られる．

#### IPF とは

IPF アルゴリズムは離散的な形で [@Deming-Stephan1940] が分割表データ解析の研究で提案している．その手続きを [@Ireland-Kullback1968] が距離の最小化として特徴付け，[@Kullback1968] が確率密度に対しても一般化した．ただし，この確率密度に対するアルゴリズムは [@Fortet1940] が Schrödinger 方程式の研究ですでに提案しているものである．

IPF は元々，指定した２つの確率ベクトル $r\in(0,\infty)^{d_r},c\in(0,\infty)^{d_c}$ を周辺分布に持つ結合分布（カップリング）のうち，指定の行列 $W\in M_{d_rd_c}(\R_+)$ に最も近い KL 乖離度を持つカップリングを見つけるための逐次アルゴリズムである [@Kurras2015]．

種々の分野で再発見され，複数の名前を持っているようである．例：Sheleikhovskii 法，Kruithof アルゴリズム，Furness 法，Sinkhorn-Knopp アルゴリズム，RAS 法など [@Kurras2015]．^[また，行列スケーリングを通じた最小情報コピュラとの関連を [@Bedford+2016], [@清智也2021] が指摘している．]

$W$ の成分が正である場合は，[@Sinkhorn1967] がアルゴリズムの収束と解の一意性を示している．^[ただし，[@Deming-Stephan1940] にも [@Fortet1940] にも言及しておらず，Markov 連鎖の遷移確率の推定という文脈で研究している．]

しかし，$W$ の成分が零を含む場合，零成分の位置に依存してアルゴリズムは収束しないことがあり得ることを，[@Sinkhorn-Knopp1967] が $d_r=d_c=1$ の場合について示している．

#### アルゴリズム

IPF アルゴリズムは，観念的には，２つの周辺分布のうち片方を制約に課しながら，KL 距離を最小にする射影を返していく：

$$
\Pi^{2n+1}:=\argmin_{\Pi\in\cP(C([0,T];\cX\times\cY))}\BRace{\KL(\Pi,\Pi^{2n})\,\bigg|\,\Pi_T=\rN_d(0,I_d)\otimes p(y_T)dy_T},
$$
$$
\Pi^{2n+2}:=\argmin_{\Pi\in\cP(C([0,T];\cX\times\cY))}\BRace{\KL(\Pi,\Pi^{2n+1})\,\bigg|\,\Pi_0(x_0,y_0)=p(x_0,y_0)}.
$$

今回の場合，
$$
\Pi^{2n+1}=\bP_{y_T}^{2n+1}\otimes\delta_{p(y)},\qquad\Pi^{2n+2}=\bP^{2n+2}_{y_0}\otimes\delta_{p(y)},
$$
と分解される．ただし，$\bP_{y_T}^{2n+1}$ は次で定まる $(Z_t)$ の時間反転
$$
dZ_t=f_{T-t}^{2n+1}(Z_t,y_T)\,dt+dW_t,\qquad Z_0\sim\rN_d(0,I_d),f_t^{2n+1}(x_t,y):=-f_t^{2n}(x_t,y)+\nabla_{x}\log\Pi^{2n}_t(x_t|y),
$$
$\bP_{y_0}^{2n+2}$ は次で定まる $(X_t)$ の経路測度となる：
$$
dX_t=f^{2n+2}_t(X_t,y_0)\,dt+dB_t,\qquad X_0\sim p(x|y_0)\,dx,f_t^{2n+2}(x_t,y):=-f_t^{2n+1}(x_t,y)+\nabla_x\log\Pi_t^{2n+1}(x_t|y).
$$
ただし，$f^0_t(x_t)=-x_t/2$．

#### DDPS との関係

最初のイテレーション $n=0$ における $\bP^1_y$ が雑音除去拡散 ([-@eq-denoising-diffusion]) に対応する．

しかし，IPF アルゴリズムのイテレーションを繰り返していくごとに，$T>0$ が十分に大きくない場合でも正確に $\rN_d(0,I_d)$ にデータ分布を還元する SB が得られるようになっていく．

#### DSB-PS

この際，スコア $\nabla_z\log p_{T-t}(Z_t|y)$ から始まり，$f^{n}_t\;(n\ge2)$ の推定も逐次的に行なわなければならない点については，**mean-matching** [@DeBortoli+2021], [@Shi+2022] という方法が考えられている．

この方法を用いて，IPF アルゴリズムが収束するまで実行して最終的に得るサンプラーを **Schrödinger 橋サンプラー** (DSB-PS: Diffusion Schrödinger Bridge Posterior Sampling) という．