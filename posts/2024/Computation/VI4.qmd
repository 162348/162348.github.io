---
title: "変分推論４"
subtitle: "主成分分析"
author: "司馬 博文"
date: 3/1/2024
categories: [Computation, Python]
toc: true
number-sections: true
code-block-bg: true
code-overflow: wrap
code-fold: true
code-annotations: select
bibliography: 
    - ../../../mathematics.bib
    - ../../../bib.bib
csl: ../../../apalike.csl
crossref:
    sec-prefix: 節
    eq-prefix: 式
    def-prefix: 定義
    def-title: 定義
    thm-prefix: 定理
    thm-title: 定理
    fig-prefix: 図
    fig-title: 図
abstract-title: 概要
abstract: $K$-平均法は混合モデルの最尤推定アルゴリズムとみなせたように，主成分分析が一般の線型 Gauss 潜在変数モデルにおける最尤推定とみなせる．
---

{{< include ../../../_preamble.qmd >}}

## 導入

**主成分分析** (PCA: Principal Component Analysis) も，$K$-平均法と同様に，次元削減，（非可逆）データ圧縮，特徴抽出，データ可視化の用途に用いられる．^[Kosambi-Karhunen-Loéve 変換ともいう [@Bishop-Bishop2024 p.497]．]

主成分分析は，値の分散が最大となるような線型射影を求める問題 [@Hotelling33-PCA] とも，また（おろした垂線の足の二乗距離和の意味で）コストが最小になるような線型射影を求める問題 [@Pearson01-PCA] とも見ることができ，歴史的には広い分野で研究されてきた．

また，複数のデータに対して，同時に主成分分析を行う場合，これを **正準相関分析** (canonical correlation analysis) [@Hotelling36] ともいう．

一方で潜在変数を導入し，「データ＝共通因子部＋独立因子部＋誤差」という分解を得ることを目標とする場合，これを **因子分析** (factor analysis) という [@足立浩平23-因子分析]．^[すなわち，主成分分析が低階数近似で，因子分析が高階数近似になっている，という説明が１つありえる．]

いずれも確率的モデリングとは無縁に見えるが，これらはいずれも線型 Gauss な潜在変数モデルの特殊化と見れる [@Tipping-Bishop1999]．^[[@Bishop-Bishop2024] 第16章．] 従って，EM アルゴリズムによる効率的な推定を初めとした，Bayes 学習，ニューラルネットワークなど，グラフィカルモデルとして様々な拡張が可能である．



