---
title: "新時代の MCMC を迎えるために"
subtitle: "連続時間アルゴリズムへの進化"
author: 
    - name: "司馬博文"
      orcid: 0009-0007-8251-1224
      affiliation:
        - name: 総合研究大学院大学先端学術院（統計科学コース）
          url: https://www.ism.ac.jp/senkou/
          group: ５年一貫博士課程
date: 5/24/2024
keywords:
    - マルコフ連鎖モンテカルロ法（MCMC）
    - 連続時間 MCMC
    - ハミルトニアンモンテカルロ法（HMC）
    - "区分的確定的マルコフ過程（PDMP: piecewise deterministic Markov process）"
categories: [MCMC, Simulation, Poster]
bibliography: 
    - ../../../mathematics.bib
    - ../../../bib.bib
csl: ../../../apa.csl
abstract-title: 概要
abstract: 物質科学を震源地とする MCMC のイノベーションが，統計力学と統計学の分野に波及して来ています．その結果，ここ 10 年で急激に MCMC 手法の革新が起こりました．従来 MCMC が離散時間ベースだったところが，イベントベースかつ連続時間ベースなものにとって替わられようとしているのです．これら連続時間 MCMC はどのような手法なのか？従来法を超えるのか？どのような場面で使えるのか？……等々疑問は尽きません．この新たな手法を正しく受け止めるために，現状の MCMC への理解から，新手法がどのように生まれたかの軌跡を辿り，現状の理解を確かめます．
copyright: "Copyright Hirofumi Shiba 2024. All Rights Reserved"
toc-location: right-body
toc-title: 目次
---

{{< include ../../../_preamble.qmd >}}

[![「新時代の MCMC を迎えるために」統数研オープンハウス（タップで PDF 閲覧）](../../../static/Posters/ISM-OH2024.jpg){width=50%}](../../../static/Posters/ISM-OH2024.pdf)

::: {.callout-tip appearance="minimal"}
以下は，5月24日 10:30~12:30 （コアタイム：10:30~11:10）に行われた [2024年度統数研オープンハウス](../../../static/Sessions.qmd#sec-ISM-openhouse2024) ポスターセッション（掲載 No. E1）に於て発表されたポスターに関する解説記事です．
:::

## 導入

### MCMC 小史

現状，HMC (Hamiltonian Monte Carlo) という約 40 年前に提案された MCMC 手法が，Stan などの確率的プログラミング言語のデフォルト MCMC 手法として採用されています．^[Hamiltonian Monte Carlo の名称は [@Neal2011-HMC] からで，元々は Hybrid Monte Carlo と呼ばれていました．分子動力学法 (Molecular Dynamics) と MCMC のハイブリッド，という意味でした．Stan で実装されている MCMC アルゴリズムについては [こちら](https://mc-stan.org/docs/reference-manual/mcmc.html) を参照．]

この手法はもともと [@Duane+1987] が場の量子論に特化した Monte Carlo 法として提案したものであったところを，[@Neal1994] が一般の統計モデルに適用可能な形式に翻訳する形で提案されたものでした．

ということで，HMC は，オリジナルの MCMC が物理学者 [@Metropolis+1953] に由るように，物理学において着想された MCMC 手法であったのです．

**そのHMC が，提案から 40 年目を迎える前に，更なる効率的な手法によって代替されようとしています**．

そのきっかけ [@Peters-deWith2012] も，やはり，物理学（正確には物質科学）からの着想でした．

### MCMC とは何か？

MCMC とは，確率変数をシミュレーションする際に用いられる汎用的アルゴリズムです．

一様分布や正規分布などの名前がついた分布ではない場合，どのようにすればその分布に従う確率変数をシミュレーションできるのか？は，古くからの問題でした．

実際，「MCMC では空間を探索するマルコフ連鎖を構成し，その足跡を辿るとちょうど確率変数のシミュレーションになっている」と種明かしを聞いても，「なぜそのような回りくどい方法を使うのか？」「もっと良い方法はないのか？」と思っても当然でしょう．

ですが，MCMC を，発明された経緯を辿り，物理学の問題意識から見てみると，実は極めて自然な発想に思えてくるかもしれません．

以降，MCMC の起源である物理系のシミュレーション（第 [-@sec-origin] 節）を例に取り，分子動力学法（第 [-@sec-MD] 節），Metropolis 法（第 [-@sec-MH] 節）を復習します．

::: {layout-ncol=2}
![分子動力学法の出力（第 [-@sec-MD] 節）^[特に収束が遅く，他の手法と比べてイテレーション数を 10　倍にしています．]](../../../docs/posts/2024/Computation/MCMC_files/figure-html/fig-md-output-1.png)

![Metropolis 法の出力（第 [-@sec-MH] 節）](../../../docs/posts/2024/Computation/MCMC_files/figure-html/fig-mh-output-1.png)
:::

これを基礎として，近年提案された非対称な MCMC 手法（第 [-@sec-LMH] 章），そして最新の連続時間 MCMC 手法（第 [-@sec-PDMP] 章）を紹介します．

::: {layout-ncol=2}
![非対称 MCMC 法（Lifted Metropolis 法）の出力（第 [-@sec-LMH] 章）](../../../docs/posts/2024/Computation/MCMC_files/figure-html/fig-lmh-output-1.png)

![連続時間 MCMC 法（Zig-Zag サンプラー）の出力（第 [-@sec-PDMP] 章）](../../../docs/posts/2024/Computation/MCMC_files/figure-html/fig-pdmp-output-1.png)
:::

### 自己相関・軌跡の一覧

::: {layout-ncol=3}
![Metropolis 法の自己相関関数（第 [-@sec-MH] 節）](../../../docs/posts/2024/Computation/MCMC_files/figure-html/fig-mh-auto-output-1.png)

![非対称 MCMC 法（Lifted Metropolis 法）の自己相関関数（第 [-@sec-LMH] 章）](../../../docs/posts/2024/Computation/MCMC_files/figure-html/fig-lmh-auto-output-1.png)

![連続時間 MCMC 法（Zig-Zag サンプラー）の自己相関関数（第 [-@sec-PDMP] 章）](../../../docs/posts/2024/Computation/MCMC_files/figure-html/fig-pdmp-auto-output-1.png)
:::

::: {layout-ncol=3}
![Metropolis 法の軌跡（第 [-@sec-MH] 節）](../../../docs/posts/2024/Computation/MCMC_files/figure-html/fig-1-output-1.png)

![非対称 MCMC 法（Lifted Metropolis 法）の軌跡（第 [-@sec-LMH] 章）](../../../docs/posts/2024/Computation/MCMC_files/figure-html/fig-4-output-1.png)

![連続時間 MCMC 法（Zig-Zag サンプラー）の軌跡（第 [-@sec-PDMP] 章）](../../../docs/posts/2024/Computation/MCMC_files/figure-html/fig-pdmp-traj-output-1.png)
:::

## MCMC の起源 {#sec-origin}

::: {.callout-caution title="よりみち：どうして MCMC が必要だったのか？" collapse="true"}

[@Metropolis+1953] では，温度 $T$ 一定の条件下で $N$ 粒子系をシミュレートし，任意の物理量 $F$ に対してその相空間上の平均
$$
\brac{F}=\frac{\int Fe^{-\frac{E}{kT}}dp}{\int e^{-\frac{E}{kT}}dp}
$$
を効率的に計算する汎用アルゴリズムが提案された．これが現在では Metropolis 法と呼ばれている．^[統計学界隈では [@Hastings1970] を入れて，Metropolis-Hastings 法とも呼ばれる．]

[@Metropolis+1953] では $N$ が数百になる場合を考えており（時代を感じるスケール感），当然愚直な数値積分は現代の計算機でも実行可能ではない．そこで Monte Carlo 法を考えることになるが，当時 Monte Carlo 法といえば，一様乱数を用いた計算法の全般を指し，具体的には $\brac{F}$ を重点サンプリング推定量
$$
\wh{F}=\frac{\sum_{n=1}^NF(\om)e^{-\frac{E(\om)}{kT}}}{\sum_{n=1}^Ne^{-\frac{E(\om)}{kT}}}
$$
で推定することを指した．^[ただし，配置 $\om\in\Om$ は空間内にランダム（一様）に粒子 $N$ 個を配置することで生成することとする．]

しかしこれでは，高エネルギーな状態・低エネルギーな状態を全く区別せず，状態 $\om\in\Om$ を完全に一様に生成するため，その分だけ非効率である．

これを低減することが出来れば Monte Carlo 法の更なる効率改善に繋がる．こうして，Gibbs 分布 $\frac{1}{Z}e^{-\frac{E}{kT}}$ から直接的サンプリングする方法が模索されたのである．

:::

[@Metropolis+1953] では，エネルギー $E$ を持つ系の Boltzmann-Gibbs 分布 $\frac{1}{Z}e^{-\frac{E}{kT}}$ から直接サンプリングする方法が探求されました．

ここでは簡単のため，１粒子が次のようなポテンシャル
$$
U(x)=\frac{x^2}{2}+\frac{x^4}{4}
$$
に従って運動する場合を考えましょう：

![ポテンシャル $U$ のプロット](Files/potential.svg){width=50% #fig-2}

このポテンシャルに関する Boltzmann-Gibbs 分布 $\pi\propt e^{-\beta U}$ は次のような形になります：^[１粒子系なので相互作用はなく，$E=U$．]

![ポテンシャル $U$ が定める Botlzmann-Gibbs 分布のプロット](Files/Gibbs.svg){width=50% #fig-3}

<!--
```
\begin{tikzpicture}
\begin{axis}[
    axis lines = middle,
    axis line style={->},
    xlabel = $x$,
    ylabel = {$e^{-\beta U(x)}$},
    xlabel style={at={(ticklabel* cs:1)}, anchor=north west},
    ylabel style={at={(ticklabel* cs:1)}, anchor=south west},
    xmin=-1.2, xmax=1.2,
    ymin=0, ymax=1,
    xtick distance=1,
    ytick=\empty,
    grid=both,
    grid style={gray!30, dashed},
    minor tick num=1,
    width=10cm,
    height=8cm,
    legend pos=north east,
    legend cell align=left,
    legend style={fill=white, fill opacity=0.8, draw opacity=1, text opacity=1, font=\small},
]
\addplot[domain=-2:2, samples=100, smooth, thick, minty] {exp(-x^2 - x^4)};
\addlegendentry{$y = e^{-\frac{U(x)}{kT}}$}
\end{axis}
\end{tikzpicture}
```
-->

２つのプロットを見比べると，低エネルギー状態ほど出現確率が高く，エネルギーが上がるにつれて急激に出現確率が下がることがわかります．以降，$\beta=1$ としましょう．^[$\beta=1$ と約束することは，系の温度を $T=k_B^{-1}$ に固定することにあたります．]

### 分子動力学法 {#sec-MD}

統計力学によれば，$\beta=1$ で定まる温度とポテンシャル $U$ を持つ Boltzmann-Gibbs 分布 $e^{-U}$ は，温度 $T=\frac{1}{k_B\beta}$ を持つ熱浴に接している力学系を，長時間シミュレーションして時間平均を取ることでサンプリングできるはずです．

このように，力学に基づいて物理過程を数値シミュレーションをすることを通じてサンプリングを達成する方法を [**分子動力学法**](https://ja.wikipedia.org/wiki/%E5%88%86%E5%AD%90%E5%8B%95%E5%8A%9B%E5%AD%A6%E6%B3%95) といいます．

これを実際にやってみます．図 [-@fig-2] で定めたポテンシャルを持つ粒子を考えます．^[図 [-@fig-2] で定めたポテンシャルを持つ力学系には，代表的なものは（非調和）振動子や，あるいは $U$ の形をした谷を行ったり来たりするボールを考えても構いません．]

続いてこれを温度 $T=\frac{1}{k_B\beta}$ を持つ熱浴と相互作用させます．例えば，ポテンシャル [-@fig-2] の $x=0$ の位置に半透性の壁を置き，確率 $1/2$ でこの温度 $T$ の壁の粒子と弾性衝突するとします．（残りの確率 $1/2$ では衝突せずに通過する）．

壁の粒子の速度は Maxwell の境界条件から与えられるものとすれば，次のようにして粒子の位置 $x$ がシミュレートできます：^[詳しい議論は [@Tartero-Krauth2023] をご参照ください．大変教育的な入門です．]

```{python}
import numpy as np

np.random.seed(2024)

def U(x):
    return x**2/2 + x**4/4

def pi(x):
    return np.exp(-U(x))

def md(num_samples, initial_state, initial_velocity, timestep=0.1):
    samples = [initial_state]
    current_state = initial_state
    current_velocity = initial_velocity
    current_time = 0

    for _ in range(num_samples - 1):
        proposed_state = current_state + current_velocity * timestep
        current_time += timestep
        if current_state * proposed_state < 0 and np.random.rand() < 1/2:
            current_velocity = (-1) * np.sign(current_velocity) * np.sqrt(-2 * np.log(np.random.rand() + 1e-7))
        else:
            current_velocity = current_velocity - ( current_state + current_state ** 3 ) * timestep
            current_state = proposed_state
        samples.append(current_state)

    return np.array(samples)

# サンプル数と初期条件を固定
num_samples = 10000
initial_state = 0.0
initial_velocity = 1.0

samples_MD = md(num_samples * 10, initial_state, initial_velocity, timestep=0.01)
```

```{python}
#| echo: false
ISMblue = "#2f579c"
SaddleBrown = "#8b4513"
minty = "#80c4ac"
```

```{python}
#| echo: false
#| fig-cap: 分子動力学法からのサンプル
#| label: fig-MD
import matplotlib.pyplot as plt

plt.figure(figsize=(3.5, 3))
plt.hist(samples_MD, bins=50, density=True, alpha=0.7, color=minty)
plt.show()
```

この方法は極めて収束が遅く，イテレーション数を 100000 以上に取らないと目標分布 $e^{-U}$ の良い近似とならないことを思い知りました．なお，以降の MCMC 法ではいずれもイテレーション数は一桁少ない 10000 としています．

### Metropolis 法 {#sec-MH}

もちろん，分布 $e^{-U}$ をサンプリングするために，必ずしも背景にある物理過程まで戻ってシミュレーションをする必要はありません．

そこで，シミュレーションは簡単なランダムウォークで行い，その結果を適切に修正することで目標分布に収束させる方法が [@Metropolis+1953] で考えられました．

[@Metropolis+1953] の手法は，現在では random walk Metropolis-Hastings 法と呼ばれます．

この背後の物理現象から離陸する一歩が，分子動力学法と MCMC 法とを分けるものでした．

```{python}
def metropolis(num_samples, initial_state, verbose=False):
    samples = [initial_state]
    current_state = initial_state

    accept = []

    for _ in range(num_samples - 1):
        proposed_state = current_state + np.random.uniform(-2,2)
        acceptance_ratio = pi(proposed_state) / pi(current_state)
        if np.random.rand() < acceptance_ratio:
            current_state = proposed_state
            accept.append(True)
        samples.append(current_state)

    if verbose:
        rate = len(accept) / num_samples
        print(f'acceptance rate : {rate}')

    return np.array(samples)
```

```{python}
#| echo: false
#| fig-cap: Metropolis 法からのサンプル
#| label: fig-MH
samples_MH = metropolis(num_samples, initial_state, verbose=False)
plt.figure(figsize=(3.5, 3))
plt.hist(samples_MH, bins=50, density=True, alpha=0.7, color=minty)
plt.show()
```

サンプル数は分子動力学法の $1/10$ であるにも拘らず，目標分布 $e^{-U}$ の良い近似を得ています．

一般に，MCMC からのサンプルの質の良さは，[自己相関関数](https://ja.wikipedia.org/wiki/%E8%87%AA%E5%B7%B1%E7%9B%B8%E9%96%A2) を見ることで評価できます．^[自己相関関数がどのような意味を持つか，筆者はわかりやすい説明をできかねますが，例えば自己相関関数の裾が重すぎると，中心極限定理が成り立たなくなります．]

Metropolis 法の自己相関関数を計算してみると，横軸の Lag が大きくなればなるほど Autocorrelation の値は小さくなっています．

```{python}
#| echo: false
#| fig-cap: Metropolis 法の自己相関関数
#| label: fig-MH-auto
plt.figure(figsize=(3.5, 3))
plt.acorr(samples_MH - np.mean(samples_MH), maxlags=10, color=minty)
plt.xlim(-0.5, 10.5)
#plt.ylim(-0.5,0.85)
# グラフの装飾
plt.title('Metropolis', color=minty)
plt.tick_params(axis='x', colors=ISMblue)
plt.tick_params(axis='y', colors=ISMblue)
plt.xlabel('Lag', color=ISMblue)
plt.ylabel('Autocorrelation', color=ISMblue)
#plt.savefig('MH_auto.svg', format='svg')
plt.show()
```

```{python}
#| echo: false
#| fig-cap: Metropolis 法の軌跡
#| label: fig-1
plt.figure(figsize=(3.5, 3))
plt.plot(samples_MH[0:50], range(50), color=minty)
plt.ylim(-0.5, 49.5)
#plt.xlim(-1.2,1.2)
# グラフの装飾
plt.title('Metropolis', color=minty)
plt.tick_params(axis='x', colors=ISMblue)
plt.tick_params(axis='y', colors=ISMblue)
plt.xlabel('X-axis', color=ISMblue)
plt.ylabel('Step', color=ISMblue)
#plt.savefig('MH_traj.svg', format='svg')
plt.show()
```

上図は Metropolis 法で構成される Markov 連鎖の軌跡を表しています．行ったり来たりしているのがわかります．棄却率は５割弱です．^[一般には，採択率を 0.2 から 0.4 に抑えるのが良いとされています．[@Chopin-Papaspiliopoulos20-SMC p.282] など．]

### 統計学への応用

こうして MCMC が発明されれば，すぐにイノベーションとして理解されたかというとそうではありませんでした．

この Metropolis の手法が極めて賢いシミュレーション手法であることは一目瞭然でも，一般の確率分布からのサンプリングに使える汎用アルゴリズムになっているという抽象的な観点が得られるまでには時間を要しました．これを成し遂げたのが [@Hastings1970] でした．^["While [@Metropolis+1953] proposed the use of MCMC sampling to compute particular integrals in statistical mechanics, **it was the Hastings paper that elevated the concept to a general one, and introduced it to the broader statistics community**." [@Martin+2023-history p.7] 3.5節．]

さらに，Hastings のこの結果も見過ごされたと言って良いでしょう．真にMCMC を統計学界隈に広め，現代におけるベイズ統計学の興隆の契機となったのは階層モデリングにおける Gibbs サンプリングの有用性を強調した [@Gelfand-Smith1990] だと言われます．^[[@Martin+2023-history p.8] 4節，[@Robert-Casella2011 p.102] など．]

当時，代替手法としては複雑な数値アルゴリズムしかなかったベイズ統計学において，MCMC は汎用的で実装も容易であることが周知され，ベイズ統計学が普及するきっかけとなりました．

## 非対称化への試み {#sec-LMH}

### 対称性という制約

ここでもう一度 Metropolis 法の軌跡 @fig-1 を見てみましょう．

![@fig-1 Metropolis 法の軌跡](../../../docs/posts/2024/Computation/MCMC_files/figure-html/fig-1-output-1.png){width=230pt}

最初の 50 サンプルしか表示していませんから，運が悪いとうまく見つからないかもしれませんが，「一度歩んだルートを，その後すぐに逆に戻ってしまう」という事象が発生しやすいことが観察できますでしょうか？

これを **対称性** (reversibility) または **可逆性** と言います．

Metropolis 法は構成上，この対称性を持つことが必要ですが，対称であるが故に一箇所に長時間とどまってしまうことが多く，対称分布が複雑である場合はもっといろんなモード（峰）からもサンプリングをしてほしいのに，なかなかそうなってくれないことがあります．

コーヒーに砂糖を溶かすことを考えてみましょう．砂糖の粒が拡散するのに任せておくと，最終的には均一に溶けるでしょうが，莫大な時間がかかります．スプーンで混ぜるなどして，砂糖が元の場所にとどまらずに移動し続けるようにすれば，はるかに速く平衡状態に到達できるでしょう．

これが **非対称化** のアイデアです．数ある Metropolis 法の改良の方向の中でも，この対称性を破るという試みは特に注目されてきました．

### リフティング

Metropolis 法を非対称化するアプローチに，**リフティング** [@Chen+1999] と呼ばれる方法があります．

これは，元々の状態空間を２つの「モード」$+1$ と $-1$ に分裂させ，$+1$ のモードではひたすら右側に，$-1$ のモードではひたすら左側に移動するようする方法です．

２つのモード $+1,-1$ の間を遷移する確率を調整することで，最終的な不変分布は変わらないようにすることができます．

こうすることで，対称性を破り，一度「この方向に行く！」と決めたら行き続けるようにしながら，収束先は変わらないように変更することが出来るのです．

実際に Metropolis 法に適用した Lifted Metropolis-Hastings 法 [@Turitsyn+2011] を実装してみましょう：

```{python}
def lifted_metropolis(num_samples, initial_state, verbose=False):
    samples = [initial_state]
    current_state = initial_state
    lifting_variable = 1
    accept = []

    for _ in range(num_samples - 1):
        delta = np.random.uniform(0,2)
        proposed_state = current_state + lifting_variable * delta
        acceptance_ratio = pi(proposed_state) / pi(current_state)

        if np.random.rand() < acceptance_ratio:
            current_state = proposed_state
            accept.append(True)
        else:
            lifting_variable = (-1) * lifting_variable

        samples.append(current_state)
    
    if verbose:
      rate = len(accept) / num_samples
      print(f'acceptance rate : {rate}')

    return np.array(samples)
```

```{python}
#| echo: false
#| fig-cap: 非対称 Metropolis 法からのサンプル
#| label: fig-LMH
samples_LMH = lifted_metropolis(num_samples, initial_state)
plt.figure(figsize=(3.5, 3))
plt.hist(samples_LMH, bins=50, density=True, alpha=0.7, color=minty)
plt.show()
```
```{python}
#| echo: false
#| fig-cap: 非対称 Metropolis 法の自己相関関数
#| label: fig-LMH-auto
plt.figure(figsize=(3.5, 3))
plt.acorr(samples_LMH - np.mean(samples_LMH), maxlags=10, color=minty)
plt.xlim(-0.5, 10.5)
#plt.ylim(-0.5,0.85)
# グラフの装飾
plt.title('Lifted Metropolis-Hastings', color=minty)
plt.tick_params(axis='x', colors=ISMblue)
plt.tick_params(axis='y', colors=ISMblue)
plt.xlabel('Lag', color=ISMblue)
plt.ylabel('Autocorrelation', color=ISMblue)
#plt.savefig('LMH_auto.svg', format='svg')
plt.show()
```

自己相関関数を見ると，Metropolis 法よりも急速に減衰していることがわかります．むしろ，過減衰のように自己相関関数が負になっていることもあります．

これは，一度「この方向に行く！」と決めたら行き続けるように設計したために，正の値が出たしばらくあとは負の値が，負の値が出たしばらくあとは正の値が出やすいようになってしまっているためです．

したがってこれは１次元の分布を考えていることに起因するため，殊更問題とすべきではないでしょう．

```{python}
#| echo: false
#| fig-cap: 非対称 Metropolis 法の軌跡
#| label: fig-4
plt.figure(figsize=(3.5, 3))
plt.plot(samples_LMH[0:50], range(50), color=minty)
plt.ylim(-0.5, 49.5)
#plt.xlim(-1.2,1.2)
# グラフの装飾
plt.title('Lifted Metropolis-Hastings', color=minty)
plt.tick_params(axis='x', colors=ISMblue)
plt.tick_params(axis='y', colors=ISMblue)
plt.xlabel('X-axis', color=ISMblue)
plt.ylabel('Step', color=ISMblue)
#plt.savefig('LMH_traj.svg', format='svg')
plt.show()
```

### リフティングの有用性

Curie-Weiss モデルに対する Lifted Metropolis-Hastings 方の適用が，モデルのパラメータ数 $n$ に対して，緩和時間を $\sqrt{n}$ のオーダーだけ改善することが，[@Turitsyn+2011] では数値実験で，[@Bierkens-Roberts2017] では理論的に検証されている．

<!--

### HMC

Hamiltonian Monte Carlo 法も一種のリフティングと見ることができ，

-->

## 新たな MCMC {#sec-PDMP}

<!--

こうして MCMC は物理学者から物質科学者，そして統計学者から機械学習家まで，多くの人が幅広く用いる手法になりました．

その結果，多くの同一の手法が違う名前で呼ばれていることも多く，現状の最先端ではどのようなことが起こっているのか見極めるのが困難です．

ここでは，上述のすべての分野に渡って共通して起こりつつある大きな地殻変動を紹介します．キーワードは **連続時間 MCMC** です．^[[@Fearnhead+2018-PDMC] から取った用語です．コンピュータシミュレーションである以上，結局は離散化するのですが，粒子の動きは（従来の Metropolis-Hastings 法のような）Markov 連鎖であるというより，連続時間確率過程のような動きをする手法群であることには間違いありません．]

-->

### 背後の物理現象からの更なる離陸

第 [-@sec-origin] 章で，分子動力学法（第 [-@sec-MD] 節）から，提案分布を背後の物理現象とは全く関係ないランダムウォークとすることで，Metropolis 法（第 [-@sec-MH] 節）は一気に効率的なサンプリング法となったことを見ました．

しかし，Metropolis 法はまだ思考が物理に引っ張られているのかも知れません．平衡統計力学において，ミクロの状態は等価で，ミクロなダイナミクスは可逆と考えられます．その前提が，知らず知らずのうちにまだ埋め込まれたままだと言えるでしょう．

そこで，スプーンでかき混ぜるように，遷移を非対称にすることで，より効率的なサンプリング法となることを前章 [-@sec-LMH] で見ました．

ここでは，さらに暗黙の思い込みから解き放たれようとします．それは，**シミュレーションするにあたって，必ずしも離散時間ステップに囚われる必要はない** ということです．

もう一度，Lifted Metropolis-Hastings 法の軌跡を見てみましょう：

![@fig-4 非対称 Metropolis 法の軌跡](../../../docs/posts/2024/Computation/MCMC_files/figure-html/fig-4-output-1.png){width=230pt}

この軌跡から得られる情報のほとんどは，「どこで折り返したか？」です．

ですから，この軌跡をシミュレーションするにあたって，一歩一歩採択-棄却のステップを繰り返す必要はなく，「どこで折り返すか？」を先に計算できてしまえば，あとは好きなステップサイズで切り出してサンプルとすれば良いのです．

実は，「折り返す地点だけを効率的に計算する」ことが可能であり，それが **連続時間 MCMC** のアイデアです．

### 連続時間 MCMC

Lifted Metropolis-Hastings の適切な連続時間極限 $\Delta t\to0$ を考えることで，「折り返す」という事象（が起こった回数）は Poisson 過程に従うことが導けます．

すると，「折り返す」事象が起こるまでの待ち時間 (interarrival time) は指数分布に従うことがわかります．これに基づいて，「折り返す」事象が起こる時刻を計算し，そこまでの軌跡を直線で補間すれば，Lifted Metropolis-Hastings 法（の連続時間極限）の軌跡が模倣できることになります．

最終的に得られる過程は，ランダムな時刻に「折り返す」事象が起こり，その間は確定的な動き（等速直線運動）をするというもので，このような過程を **区分確定的 Markov 過程** (PDMP: Piecewise Deterministic Markov Process) と呼びます．

このような PDMP は，Lifted Metropolis-Hastings 以外にも種々の MCMC 法の極限から見つかっており，その中でも特に有名なのが次の **Zig-Zag sampler** です：

```{python}
#| output: false
import math

def zigzag(num_samples, initial_state):
    samples = [initial_state]
    current_state = initial_state
    lifting_variable = 1
    t = 0

    while t < num_samples:
        state_event = lifting_variable * np.sqrt(-1 + np.sqrt( 1 - 4 * np.log(np.random.rand()) ))
        t_event = t + np.abs(state_event - current_state)
        for _ in range(math.ceil(t), math.ceil(t_event)):
        #for _ in np.linspace(t, t_event, 4):
            samples.append(current_state + lifting_variable * (_ - t))
        current_state = state_event
        lifting_variable = (-1) * lifting_variable
        t = t_event

    return np.array(samples)
```

<!--
自己相関関数こんなに spiky になるっけ？
いや，多分この設定だと zig-zag は普通に悪いんだろうな．
棄却率が高くて７割くらいある LMH に負けるのが「正しい」のかも知れない．

そして１次元なのに等間隔でサンプリングしているから，自己相関関数は sine curve に（むしろ）なるべきなのか！
-->

```{python}
#| echo: false
#| fig-cap: Zig-Zag サンプラーからのサンプル
#| label: fig-PDMP
samples_zigzag = zigzag(num_samples, initial_state)
plt.figure(figsize=(3.5, 3))
plt.hist(samples_zigzag, bins=50, density=True, alpha=0.7, color=minty)
plt.show()
```

```{python}
#| echo: false
#| fig-cap: Zig-Zag サンプラーの自己相関関数
#| label: fig-PDMP-auto
plt.figure(figsize=(3.5, 3))
plt.acorr(samples_zigzag - np.mean(samples_zigzag), maxlags=10, color=minty)
plt.xlim(-0.5, 10.5)
#plt.ylim(-0.5,0.85)
# グラフの装飾
plt.title('Zig-Zag sampler', color=minty)
plt.tick_params(axis='x', colors=ISMblue)
plt.tick_params(axis='y', colors=ISMblue)
plt.xlabel('Lag', color=ISMblue)
plt.ylabel('Autocorrelation', color=ISMblue)
#plt.savefig('zigzag_auto.svg', format='svg')
plt.show()
```

自己相関関数は，Lifted Metropolis-Hastings 法と同様に急激に下がって負の値に突き抜けたあとは，少し振動が残っているのがわかります．

次の軌跡を見て分かる通り，激しく多服するので，少し距離のあるサンプル間でも相関が出やすいようです．

```{python}
#| echo: false
#| fig-cap: Zig-Zag サンプラーの軌跡
#| label: fig-PDMP-traj
plt.figure(figsize=(3.5, 3))
plt.plot(samples_zigzag[0:50], range(50), color=minty)
plt.ylim(-0.5, 49.5)
#plt.xlim(-1.2,1.2)
# グラフの装飾
plt.title('Zig-Zag sampler', color=minty)
plt.tick_params(axis='x', colors=ISMblue)
plt.tick_params(axis='y', colors=ISMblue)
plt.xlabel('X-axis', color=ISMblue)
plt.ylabel('Step', color=ISMblue)
#plt.savefig('zigzag_traj.svg', format='svg')
plt.show()
```

連続時間極限 $\Delta t\to0$ をとっているということは，「極めて小さいステップサイズでの random walk Metropolis 法（第 [-@sec-MH] 節）」に相当します．従って，一度折り返したら，原点 $x=0$ を超えるまでは絶対に棄却されません．

そのため，このように往復するような軌跡が得られます．

### 連続時間 MCMC の美点

前節では，必ずしも PDMP 法である Zig-Zag sampler が，Lifted Metropolis-Hastings 法より，自己相関関数の観点で良いとは言い切れないことを見ました．

しかし，今回の設定は１次元という特殊な条件下であることを考慮に入れる必要があります．

１次元なので Zig-Zag サンプラーは行き来することしか出来ていませんが，２次元以上，特に高次元の場合は，Zig-Zag サンプラーは極めて効率的に状態空間を探索できることが期待されます．

例えば，標準正規分布に対する２次元での軌跡は次の通りです：

![Zig-Zag Sampler in $\R^2$](./Files/ZigZag_2d.png)

<!-- 

### 筆者の目標：新時代のサンプラーの開発

情報通信機器の発達によりデータが複雑で大規模化する現代では，モデルも同様に大規模で複雑化していく必要があります．OpenAI の ChatGPT や Sora，Anthropic の Claude-3 などの **基盤モデル** はその象徴と言えるでしょう．

筆者は，その中で **新時代の MCMC** の開発を目標としています．

高次元空間上の複雑な分布からも効率的にサンプリングできる MCMC 手法が開発された際には，多くの人が自分のノートパソコンで気軽にできるベイズ統計分析の幅が大きく広がることでしょう．

それこそ，ニューラルネットワークの表現力をフルに活用するだけでなく，ベイズ手法の強みも併せて，小規模データでも鮮やかな分析が簡単に出来るようになるかもしれません．

そのような世界線こそ，AI 技術の民主化と呼ぶにふさわしい，来るべき未来だと筆者は信じています．

また，基盤モデルの Bayes 的な理解を進めることも，実は壮大ながらも，筆者の最終的な目標の一つであります．

-->

## 終わりに {.appendix}

こうみると，MCMC は物理学の問題意識から生まれた手法でありながら，背後の物理現象を模倣することから離れていくことで，計算手法としての効率を高めていく一途を辿っていることがわかります．

そう見ると，次の目的地は連続時間 MCMC で間違いないような気がしてくるのですが……．まだ筆者には見えてきません．

また本稿では１つの流れしか取り上げておらず，例えば HMC とその非対称化がどのような位置づけにあるかもまだ考慮中です．

統計力学，統計学，機械学習が交差するなんとも面白いテーマです．

本ポスター執筆のきっかけは，[MLSS でのポスター発表](../Particles/PF.qmd) で連続時間 MCMC のことが機械学習の界隈では全く知られていないことを知ったことと，情報統計力学の研究集会に出席したことでした．

統計界隈では（本稿で解説しました通り） PDMP や連続時間 MCMC と呼ばれる手法は，物理学界隈では event-based simulation，rejection-free と呼ばれる手法群の１つとして活発に研究されていました．

全く同じ問題を解こうとしているのに，用語法が全く異なることに驚かされました．

２つの分野の相互理解と知見の交換が進むことを目指し，これからも研究していきたいと考えます．

## 参考文献 {.appendix}

本稿では，用いたコードの導出を一切触れませんでした．これについては，文献 [@Tartero-Krauth2023] をご参照ください．非調和振動子を系にとり，正準集団とみなすことで，分子動力学法，メトロポリス法からそのリフティングまで，種々のサンプラーを同じ題材で比較するアイデアをもらいました．こんなにわかりやすい解析ができるのかと心底驚きました．

続いて，Metropolis-Hastings 法 → 非対称 MCMC → 連続時間 MCMC という発展の過程を，背後の物理過程の模倣からの離陸という視点で統一的に捉えることが出来るということは，[@Turitsyn+2011] の魅力的なイントロダクションで気付かされました．本文献はリフティングによる MCMC の非可逆化を抽象的に定式化して数値実験で検証したものであり，「ねじれ詳細釣り合い条件」を導入した点で，アイデアの宝庫といえます．


