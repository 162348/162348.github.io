---
title: "新時代の MCMC を迎えるために"
subtitle: "連続時間アルゴリズムへの進化"
author: 
    - name: "司馬 博文"
      orcid: 0009-0007-8251-1224
      affiliation:
        - name: 総合研究大学院大学先端学術院（統計科学コース）
          url: https://www.ism.ac.jp/senkou/
          group: ５年一貫博士課程
date: 5/24/2024
keywords:
    - マルコフ連鎖モンテカルロ法（MCMC）
    - 連続時間 MCMC
    - ハミルトニアンモンテカルロ法（HMC）
    - "区分的確定的マルコフ過程（PDMP: piecewise deterministic Markov process）"
categories: [MCMC, Simulation, Poster]
bibliography: 
    - ../../../mathematics.bib
    - ../../../bib.bib
csl: ../../../apa.csl
abstract-title: 概要
abstract: 物質科学を震源地とする MCMC のイノベーションが，統計力学と統計学の分野に波及して来ています．その結果，ここ 10 年で急激に MCMC 手法の革新が起こりました．従来 MCMC が離散時間ベースだったところが，イベントベースかつ連続時間ベースなものにとって替わられようとしているのです．これら連続時間 MCMC はどのような手法なのか？従来法を超えるのか？どのような場面で使えるのか？……等々疑問は尽きません．この新たな手法を正しく受け止めるために，現状の MCMC への理解から，新手法がどのように生まれたかの軌跡を辿り，現状の理解を確かめます．
copyright: "Copyright Hirofumi Shiba 2024. All Rights Reserved"
toc-location: right-body
toc-title: 目次
---

{{< include ../../../_preamble.qmd >}}

[![「新時代の MCMC を迎えるために」統数研オープンハウス（タップで PDF 閲覧）](../../../static/Posters/ISM-OH2024.jpg){width=50%}](../../../static/Posters/ISM-OH2024.pdf)

::: {.callout-tip appearance="minimal"}
以下は，5月24日 10:30~12:30 （コアタイム：10:30~11:10）に行われた [2024年度統数研オープンハウス](../../../static/Sessions.qmd#sec-ISM-openhouse2024) ポスターセッション（掲載 No. E1）に於て発表されたポスターに関する解説記事です．
:::

## 導入

### MCMC 小史

現状，HMC (Hamiltonian Monte Carlo) という約 40 年前に提案された MCMC 手法が，Stan などの確率的プログラミング言語のデフォルト MCMC 手法として採用されています．^[Hamiltonian Monte Carlo の名称は [@Neal2011-HMC] からで，元々は Hybrid Monte Carlo と呼ばれていました．分子動力学法 (Molecular Dynamics) と MCMC のハイブリッド，という意味でした．Stan で実装されている MCMC アルゴリズムについては [こちら](https://mc-stan.org/docs/reference-manual/mcmc.html) を参照．]

この手法はもともと [@Duane+1987] が場の量子論に特化した Monte Carlo 法として提案したものであったところを，[@Neal1994] が一般の統計モデルに適用可能な形式に翻訳する形で提案されたものでした．

ということで，HMC は，オリジナルの MCMC が物理学者 [@Metropolis+1953] に由るように，物理学において着想された MCMC 手法であったのです．

**そのHMC が，提案から 40 年目を迎える前に，更なる効率的な手法によって代替されようとしています**．

そのきっかけ [@Peters-deWith2012] も，やはり，物理学（正確には物質科学）からの着想でした．

### MCMC とは何か？

MCMC とは，確率変数をシミュレーションする際に用いられる汎用的アルゴリズムです．

一様分布や正規分布などの名前がついた分布ではない場合，どのようにすればその分布に従う確率変数をシミュレーションできるのか？は，古くからの問題でした．

実際，「MCMC では空間を探索するマルコフ連鎖を構成し，その足跡を辿るとちょうど確率変数のシミュレーションになっている」と種明かしを聞いても，「なぜそのような回りくどい方法を使うのか？」「もっと良い方法はないのか？」と思っても当然でしょう．

ですが，MCMC を，発明された経緯を辿り，物理学の問題意識から見てみると，実は極めて自然な発想に思えてくるかもしれません．

以降，MCMC の起源である物理系のシミュレーション（第 [-@sec-origin] 節）を例に取り，分子動力学法（第 [-@sec-MD] 節），Metropolis 法（第 [-@sec-MH] 節）を復習します．

::: {layout-ncol=2}
![分子動力学法の出力](./MCMC_files/figure-ipynb/fig-md-output-1.png)

![Metropolis 法の出力](./MCMC_files/figure-ipynb/fig-mh-output-1.png)
:::

これを基礎として，近年提案された非対称な MCMC 手法（第 [-@sec-LMH] 章），そして最新の連続時間 MCMC 手法（第 [-@sec-PDMP] 章）を紹介します．

::: {layout-ncol=2}
![非対称 MCMC 法（Lifted Metropolis 法）の出力](./MCMC_files/figure-ipynb/fig-lmh-output-1.png)

![連続時間 MCMC 法（Zig-Zag サンプラー）の出力](./MCMC_files/figure-ipynb/fig-pdmp-output-1.png)
:::

## MCMC の起源 {#sec-origin}

::: {.callout-caution title="よりみち：どうして MCMC が必要だったのか？" collapse="true"}

[@Metropolis+1953] では，温度 $T$ 一定の条件下で $N$ 粒子系をシミュレートし，任意の物理量 $F$ に対してその相空間上の平均
$$
\brac{F}=\frac{\int Fe^{-\frac{E}{kT}}dp}{\int e^{-\frac{E}{kT}}dp}
$$
を効率的に計算する汎用アルゴリズムが提案された．これが現在では Metropolis 法と呼ばれている．^[統計学界隈では [@Hastings1970] を入れて，Metropolis-Hastings 法とも呼ばれる．]

[@Metropolis+1953] では $N$ が数百になる場合を考えており（時代を感じるスケール感），当然愚直な数値積分は現代の計算機でも実行可能ではない．そこで Monte Carlo 法を考えることになるが，当時 Monte Carlo 法といえば，一様乱数を用いた計算法の全般を指し，具体的には $\brac{F}$ を重点サンプリング推定量
$$
\wh{F}=\frac{\sum_{n=1}^NF(\om)e^{-\frac{E(\om)}{kT}}}{\sum_{n=1}^Ne^{-\frac{E(\om)}{kT}}}
$$
で推定することを指した．^[ただし，配置 $\om\in\Om$ は空間内にランダム（一様）に粒子 $N$ 個を配置することで生成することとする．]

しかしこれでは，高エネルギーな状態・低エネルギーな状態を全く区別せず，状態 $\om\in\Om$ を完全に一様に生成するため，その分だけ非効率である．

これを低減することが出来れば Monte Carlo 法の更なる効率改善に繋がる．こうして，Gibbs 分布 $\frac{1}{Z}e^{-\frac{E}{kT}}$ から直接的サンプリングする方法が模索されたのである．

:::

[@Metropolis+1953] では，エネルギー $E$ を持つ系の Boltzmann-Gibbs 分布 $\frac{1}{Z}e^{-\frac{E}{kT}}$ から直接サンプリングする方法が探求されました．

ここでは簡単のため，１粒子が次のようなポテンシャル
$$
U(x)=\frac{x^2}{2}+\frac{x^4}{4}
$$
に従って運動する場合を考えましょう：

![ポテンシャル $U$ のプロット](Files/potential.svg){width=50% #fig-2}

このポテンシャルに関する Boltzmann-Gibbs 分布 $\pi\propt e^{-\beta U}$ は次のような形になります：^[１粒子系なので相互作用はなく，$E=U$．]

![ポテンシャル $U$ が定める Botlzmann-Gibbs 分布のプロット](Files/Gibbs.svg){width=50%}

<!--
```
\begin{tikzpicture}
\begin{axis}[
    axis lines = middle,
    axis line style={->},
    xlabel = $x$,
    ylabel = {$e^{-\beta U(x)}$},
    xlabel style={at={(ticklabel* cs:1)}, anchor=north west},
    ylabel style={at={(ticklabel* cs:1)}, anchor=south west},
    xmin=-1.2, xmax=1.2,
    ymin=0, ymax=1,
    xtick distance=1,
    ytick=\empty,
    grid=both,
    grid style={gray!30, dashed},
    minor tick num=1,
    width=10cm,
    height=8cm,
    legend pos=north east,
    legend cell align=left,
    legend style={fill=white, fill opacity=0.8, draw opacity=1, text opacity=1, font=\small},
]
\addplot[domain=-2:2, samples=100, smooth, thick, minty] {exp(-x^2 - x^4)};
\addlegendentry{$y = e^{-\frac{U(x)}{kT}}$}
\end{axis}
\end{tikzpicture}
```
-->

２つのプロットを見比べると，低エネルギー状態ほど出現確率が高く，エネルギーが上がるにつれて急激に出現確率が下がることがわかります．以降，$\beta=1$ としましょう．^[$\beta=1$ と約束することは，系の温度を $T=k_B^{-1}$ に固定することにあたります．]

### 分子動力学法 {#sec-MD}

統計力学によれば，$\beta=1$ で定まる温度とポテンシャル $U$ を持つ Boltzmann-Gibbs 分布 $e^{-U}$ は，温度 $T=\frac{1}{k_B\beta}$ を持つ熱浴に接している力学系を，長時間シミュレーションして時間平均を取ることでサンプリングできるはずです．

このように，力学に基づいて物理過程を数値シミュレーションをすることを通じてサンプリングを達成する方法を [**分子動力学法**](https://ja.wikipedia.org/wiki/%E5%88%86%E5%AD%90%E5%8B%95%E5%8A%9B%E5%AD%A6%E6%B3%95) といいます．

これを実際にやってみます．図 [-@fig-2] で定めたポテンシャルを持つ粒子を考えます．^[図 [-@fig-2] で定めたポテンシャルを持つ力学系には，代表的なものは（非調和）振動子や，あるいは $U$ の形をした谷を行ったり来たりするボールを考えても構いません．]

続いてこれを温度 $T=\frac{1}{k_B\beta}$ を持つ熱浴と相互作用させます．例えば，ポテンシャル [-@fig-2] の $x=0$ の位置に半透性の壁を置き，確率 $1/2$ でこの温度 $T$ の壁の粒子と弾性衝突するとします．（残りの確率 $1/2$ では衝突せずに通過する）．

壁の粒子の速度は Maxwell の境界条件から与えられるものとすれば，次のようにして粒子の位置 $x$ がシミュレートできます：^[詳しい議論は [@Tartero-Krauth2023] をご参照ください．大変教育的な入門です．]

```{python}
import numpy as np

def U(x):
    return x**2/2 + x**4/4

def pi(x):
    return np.exp(-U(x))

def md(num_samples, initial_state, initial_velocity, timestep=0.1):
    samples = [initial_state]
    current_state = initial_state
    current_velocity = initial_velocity
    current_time = 0

    for _ in range(num_samples - 1):
        proposed_state = current_state + current_velocity * timestep
        current_time += timestep
        if current_state * proposed_state < 0 and np.random.rand() < 1/2:
            current_velocity = (-1) * np.sign(current_velocity) * np.sqrt(-2 * np.log(np.random.rand() + 1e-7))
        else:
            current_velocity = current_velocity - ( current_state + current_state ** 3 ) * timestep
            current_state = proposed_state
        samples.append(current_state)

    return np.array(samples)

# サンプル数と初期条件を固定
num_samples = 10000
initial_state = 0.0
initial_velocity = 1.0

samples_MD = md(num_samples * 10, initial_state, initial_velocity, timestep=0.01)
```

```{python}
#| echo: false
ISMblue = "#2f579c"
SaddleBrown = "#8b4513"
minty = "#80c4ac"
```

```{python}
#| echo: false
#| fig-cap: 分子動力学法からのサンプル
#| label: fig-MD
import matplotlib.pyplot as plt

plt.figure(figsize=(3.5, 3))
plt.hist(samples_MD, bins=50, density=True, alpha=0.7, color=minty)
plt.show()
```

この方法は極めて収束が遅く，イテレーション数を 100000 以上に取らないと目標分布 $e^{-U}$ の良い近似とならないことを思い知りました．なお，以降の MCMC 法ではいずれもイテレーション数は一桁少ない 10000 としています．

### Metropolis 法 {#sec-MH}

しかし，分布 $e^{-U}$ をサンプリングするために，必ずしも背景にある物理過程をシミュレーションする必要はありません．そこで，シミュレーションは簡単なランダムウォークで行い，その結果を適切に修正することで目標分布に収束させる方法が [@Metropolis+1953] で考えられました．

```{python}
def metropolis(num_samples, initial_state, verbose=False):
    samples = [initial_state]
    current_state = initial_state

    accept = []

    for _ in range(num_samples - 1):
        proposed_state = current_state + np.random.uniform(-1,1)
        acceptance_ratio = pi(proposed_state) / pi(current_state)
        if np.random.rand() < acceptance_ratio:
            current_state = proposed_state
            accept.append(True)
        samples.append(current_state)

    if verbose:
        rate = len(accept) / num_samples
        print(f'acceptance rate : {rate}')

    return np.array(samples)
```

```{python}
#| echo: false
#| fig-cap: Metropolis 法からのサンプル
#| label: fig-MH
samples_MH = metropolis(num_samples, initial_state)
plt.figure(figsize=(3.5, 3))
plt.hist(samples_MH, bins=50, density=True, alpha=0.7, color=minty)
plt.show()
```

サンプル数は $1/10$ であるにも拘らず，目標分布 $e^{-U}$ の良い近似を得ていると思われます．

一般に，MCMC からのサンプルの質の良さは，[自己相関関数](https://ja.wikipedia.org/wiki/%E8%87%AA%E5%B7%B1%E7%9B%B8%E9%96%A2) を見ることで評価されます．

横軸の Lag が大きくなればなるほど Autocorrelation の値は小さくなっています．一般に，離れたサンプル同士の相関が小さければ小さいほど，Markov 連鎖の平衡分布への収束は速い傾向にあります．

```{python}
#| echo: false
#| fig-cap: Metropolis 法の自己相関関数
#| label: fig-MH-auto
plt.figure(figsize=(3.5, 3))
plt.acorr(samples_MH - np.mean(samples_MH), maxlags=10, color=minty)
plt.xlim(-0.5, 10.5)
#plt.ylim(-0.5,0.85)
# グラフの装飾
plt.title('Metropolis', color=minty)
plt.tick_params(axis='x', colors=ISMblue)
plt.tick_params(axis='y', colors=ISMblue)
plt.xlabel('Lag', color=ISMblue)
plt.ylabel('Autocorrelation', color=ISMblue)
#plt.savefig('MH_auto.svg', format='svg')
plt.show()
```

```{python}
#| echo: false
#| label: fig-MH-traj
#| fig-cap: Metropolis 法の軌跡
plt.figure(figsize=(3.5, 3))
plt.plot(samples_MH[0:50], range(50), color=minty)
plt.ylim(-0.5, 49.5)
#plt.xlim(-1.2,1.2)
# グラフの装飾
plt.title('Metropolis', color=minty)
plt.tick_params(axis='x', colors=ISMblue)
plt.tick_params(axis='y', colors=ISMblue)
plt.xlabel('X-axis', color=ISMblue)
plt.ylabel('Step', color=ISMblue)
#plt.savefig('MH_traj.svg', format='svg')
plt.show()
```

### 統計学への応用

こうして MCMC が発明されれば，すぐにイノベーションとして理解されたかというとそうではありませんでした．

この Metropolis の手法が極めて賢いシミュレーション手法であることは一目瞭然でも，一般の確率分布からのサンプリングに使える汎用アルゴリズムになっているという抽象的な観点が得られるまでには時間を要しました．これを成し遂げたのが [@Hastings1970] でした．^["While [@Metropolis+1953] proposed the use of MCMC sampling to compute particular integrals in statistical mechanics, **it was the Hastings paper that elevated the concept to a general one, and introduced it to the broader statistics community**." [@Martin+2023-history p.7] 3.5節．]

さらにこの結果も見過ごされました．真にMCMC 法一般を統計学界隈に広め，ベイズ統計学の興隆につながったのは Gibbs サンプリングの有用性も強調した [@Gelfand-Smith1990] だと言われます．^[[@Martin+2023-history p.8] 4節，[@Robert-Casella2011 p.102] など．]

当時代替手法としては複雑な数値アルゴリズムしかなかったベイズ統計学において，MCMC は汎用的で実装も容易であることが周知され，ベイズ統計学が普及する大きな潤滑剤となりました．

## 非対称化への試み {#sec-LMH}

ここでもう一度 Metropolis 法の軌跡 @fig-MH-traj を見てみましょう．

![Metropolis 法の軌跡](./MCMC_files/figure-ipynb/fig-mh-traj-output-1.png)

### リフティング

```{python}
def lifted_metropolis(num_samples, initial_state, verbose=False):
    samples = [initial_state]
    current_state = initial_state
    lifting_variable = 1
    accept = []

    for _ in range(num_samples - 1):
        delta = np.random.uniform(0,1)
        proposed_state = current_state + lifting_variable * delta
        acceptance_ratio = pi(proposed_state) / pi(current_state)

        if np.random.rand() < acceptance_ratio:
            current_state = proposed_state
            accept.append(True)
        else:
            lifting_variable = (-1) * lifting_variable

        samples.append(current_state)
    
    if verbose:
      rate = len(accept) / num_samples
      print(f'acceptance rate : {rate}')

    return np.array(samples)
```

```{python}
#| echo: false
#| fig-cap: 非対称 Metropolis 法からのサンプル
#| label: fig-LMH
samples_LMH = lifted_metropolis(num_samples, initial_state)
plt.figure(figsize=(3.5, 3))
plt.hist(samples_LMH, bins=50, density=True, alpha=0.7, color=minty)
plt.show()
```
```{python}
#| echo: false
#| fig-cap: 非対称 Metropolis 法の自己相関関数
#| label: fig-LMH-auto
plt.figure(figsize=(3.5, 3))
plt.acorr(samples_LMH - np.mean(samples_LMH), maxlags=10, color=minty)
plt.xlim(-0.5, 10.5)
#plt.ylim(-0.5,0.85)
# グラフの装飾
plt.title('Lifted Metropolis-Hastings', color=minty)
plt.tick_params(axis='x', colors=ISMblue)
plt.tick_params(axis='y', colors=ISMblue)
plt.xlabel('Lag', color=ISMblue)
plt.ylabel('Autocorrelation', color=ISMblue)
#plt.savefig('LMH_auto.svg', format='svg')
plt.show()
```

```{python}
#| echo: false
#| fig-cap: 非対称 Metropolis 法の軌跡
#| label: fig-LMH-traj
plt.figure(figsize=(3.5, 3))
plt.plot(samples_LMH[0:50], range(50), color=minty)
plt.ylim(-0.5, 49.5)
#plt.xlim(-1.2,1.2)
# グラフの装飾
plt.title('Lifted Metropolis-Hastings', color=minty)
plt.tick_params(axis='x', colors=ISMblue)
plt.tick_params(axis='y', colors=ISMblue)
plt.xlabel('X-axis', color=ISMblue)
plt.ylabel('Step', color=ISMblue)
#plt.savefig('LMH_traj.svg', format='svg')
plt.show()
```

## 新たな MCMC {#sec-PDMP}

こうして MCMC は物理学者から物質科学者，そして統計学者から機械学習家まで，多くの人が幅広く用いる手法になりました．

その結果，多くの同一の手法が違う名前で呼ばれていることも多く，現状の最先端ではどのようなことが起こっているのか見極めるのが困難です．

ここでは，上述のすべての分野に渡って共通して起こりつつある大きな地殻変動を紹介します．キーワードは **連続時間 MCMC** です．^[[@Fearnhead+2018-PDMC] から取った用語です．コンピュータシミュレーションである以上，結局は離散化するのですが，粒子の動きは（従来の Metropolis-Hastings 法のような）Markov 連鎖であるというより，連続時間確率過程のような動きをする手法群であることには間違いありません．]

### 連続時間 MCMC

```{python}
import math

def zigzag(num_samples, initial_state):
    samples = [initial_state]
    current_state = initial_state
    lifting_variable = 1
    t = 0

    while t < num_samples:
        state_event = lifting_variable * np.sqrt(-1 + np.sqrt( 1 - 4 * np.log(np.random.rand()) ))
        t_event = t + np.abs(state_event - current_state)
        for _ in range(math.ceil(t),math.ceil(t_event)):
            samples.append(current_state + lifting_variable * (t_event - t))
        current_state = state_event
        lifting_variable = (-1) * lifting_variable
        t = t_event

    return np.array(samples)
```

```{python}
#| echo: false
#| fig-cap: Zig-Zag サンプラーからのサンプル
#| label: fig-PDMP
samples_zigzag = zigzag(num_samples, initial_state)
plt.figure(figsize=(3.5, 3))
plt.hist(samples_zigzag, bins=50, density=True, alpha=0.7, color=minty)
plt.show()
```
```{python}
#| echo: false
#| fig-cap: Zig-Zag サンプラーの自己相関関数
#| label: fig-PDMP-auto
plt.figure(figsize=(3.5, 3))
plt.acorr(samples_zigzag - np.mean(samples_zigzag), maxlags=10, color=minty)
plt.xlim(-0.5, 10.5)
#plt.ylim(-0.5,0.85)
# グラフの装飾
plt.title('Zig-Zag sampler', color=minty)
plt.tick_params(axis='x', colors=ISMblue)
plt.tick_params(axis='y', colors=ISMblue)
plt.xlabel('Lag', color=ISMblue)
plt.ylabel('Autocorrelation', color=ISMblue)
#plt.savefig('zigzag_auto.svg', format='svg')
plt.show()
```

```{python}
#| echo: false
#| fig-cap: Zig-Zag サンプラーの軌跡
#| label: fig-PDMP-traj
plt.figure(figsize=(3.5, 3))
plt.plot(samples_zigzag[0:50], range(50), color=minty)
plt.ylim(-0.5, 49.5)
#plt.xlim(-1.2,1.2)
# グラフの装飾
plt.title('Zig-Zag sampler', color=minty)
plt.tick_params(axis='x', colors=ISMblue)
plt.tick_params(axis='y', colors=ISMblue)
plt.xlabel('X-axis', color=ISMblue)
plt.ylabel('Step', color=ISMblue)
#plt.savefig('zigzag_traj.svg', format='svg')
plt.show()
```

### 連続時間 MCMC の美点

<!-- 

### 筆者の目標：新時代のサンプラーの開発

情報通信機器の発達によりデータが複雑で大規模化する現代では，モデルも同様に大規模で複雑化していく必要があります．OpenAI の ChatGPT や Sora，Anthropic の Claude-3 などの **基盤モデル** はその象徴と言えるでしょう．

筆者は，その中で **新時代の MCMC** の開発を目標としています．

高次元空間上の複雑な分布からも効率的にサンプリングできる MCMC 手法が開発された際には，多くの人が自分のノートパソコンで気軽にできるベイズ統計分析の幅が大きく広がることでしょう．

それこそ，ニューラルネットワークの表現力をフルに活用するだけでなく，ベイズ手法の強みも併せて，小規模データでも鮮やかな分析が簡単に出来るようになるかもしれません．

そのような世界線こそ，AI 技術の民主化と呼ぶにふさわしい，来るべき未来だと筆者は信じています．

また，基盤モデルの Bayes 的な理解を進めることも，実は壮大ながらも，筆者の最終的な目標の一つであります．

-->

## 終わりに {.appendix}

本ポスター執筆のきっかけは，[MLSS でのポスター発表](../Particles/PF.qmd) で連続時間 MCMC のことが機械学習の界隈では全く知られていないことを知ったことと，情報統計力学の研究集会に出席したことでした．

統計界隈では PDMP や連続時間 MCMC と呼ばれる手法は，物理学界隈では lifting や event-based simulation，rejection-free と呼ばれる手法群の１つとして活発に研究されていました．

全く同じ問題を解こうとしているのに，用語法が全く異なるのです！

２つの分野の相互理解と知見の交換が進むことを目指し，これからも研究していきたいと考えます．

## 参考文献 {.appendix}

* [@Tartero-Krauth2023] 非調和振動子を系にとり，正準集団とみなすことで，分子動力学法，メトロポリス法からそのリフティングまで，種々のサンプラーを同じ題材で比較するアイデアをもらいました．大変にわかりやすい解説です．
* 