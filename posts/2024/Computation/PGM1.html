<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="司馬博文">
<meta name="dcterms.date" content="2023-12-20">

<title>数学者のための確率的グラフィカルモデル１ – Hirofumi Shiba</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../assets/Shiba2.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-69a118ed5aa843c5d3f13e92a12ee77e.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-f8de076aeb9658a6c96d343f1d6c5546.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-69a118ed5aa843c5d3f13e92a12ee77e.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-4c09742be2272f701a3e51422777528f.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-4c09742be2272f701a3e51422777528f.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-4c09742be2272f701a3e51422777528f.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "?",
    "H"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-36GX2G6GLL"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-36GX2G6GLL', { 'anonymize_ip': true});
</script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Zen+Kurenaido&amp;display=swap" rel="stylesheet">

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=BIZ+UDPGothic&amp;display=swap" rel="stylesheet">

<style>
  h1, .title, .description, .subtitle {
    font-family: "Zen Kurenaido", sans-serif !important;
  }
</style>

<!-- <style>
  .menu-text {
      font-family: "Gill Sans", sans-serif !important;
      font-weight: 400;
      font-style: normal;
  }
  .navbar-title {
      font-family: "Gill Sans", sans-serif !important;
      font-weight: 400;
      font-style: normal;
  }
</style> -->

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../assets/styles.css">
<meta property="og:title" content="数学者のための確率的グラフィカルモデル１ – Hirofumi Shiba">
<meta property="og:description" content="PGM (Probabilistic Graphical Modelling) で用いられる代表的なモデル３つ（ベイジアンネットワーク，マルコフネットワーク，ファクターグラフ）を定義し，その性質を抽象的に説明する．これらは，複雑な高次元分布の分解を，計算機に理解可能な形で与える技法である．マルコフネットワークの形で与えられる分布に対しては，たとえ高次元であろうとも，MCMC によって効率的なサンプリングが可能である．">
<meta property="og:image" content="https://162348.github.io/posts/2024/Computation/PGM1.png">
<meta property="og:site_name" content="Hirofumi Shiba">
<meta property="og:image:height" content="134">
<meta property="og:image:width" content="393">
<meta name="twitter:title" content="数学者のための確率的グラフィカルモデル１ – Hirofumi Shiba">
<meta name="twitter:description" content="PGM (Probabilistic Graphical Modelling) で用いられる代表的なモデル３つ（ベイジアンネットワーク，マルコフネットワーク，ファクターグラフ）を定義し，その性質を抽象的に説明する．これらは，複雑な高次元分布の分解を，計算機に理解可能な形で与える技法である．マルコフネットワークの形で与えられる分布に対しては，たとえ高次元であろうとも，MCMC によって効率的なサンプリングが可能である．">
<meta name="twitter:image" content="https://162348.github.io/posts/2024/Computation/PGM1.png">
<meta name="twitter:creator" content="@ano2math5">
<meta name="twitter:image-height" content="134">
<meta name="twitter:image-width" content="393">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Hirofumi Shiba</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-notes" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Notes</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-notes">    
        <li>
    <a class="dropdown-item" href="../../../static/English.html">
 <span class="dropdown-text">English Notes</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../blog.html">
 <span class="dropdown-text">ノート (Japanese)</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Materials.html"> 
<span class="menu-text">Materials</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Slides.html"> 
<span class="menu-text">Slides</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Software.html"> 
<span class="menu-text">Software</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
    <a href="https://github.com/162348/162348.github.io/" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">数学者のための確率的グラフィカルモデル１</h1>
            <p class="subtitle lead">ベイジアンネットワークとマルコフネットワーク</p>
                                <div class="quarto-categories">
                <div class="quarto-category">Bayesian</div>
                <div class="quarto-category">Computation</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>司馬博文 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">12/20/2023</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">6/27/2024</p>
      </div>
    </div>
      
    </div>
    
  <div>
    <div class="abstract">
      <div class="block-title">概要</div>
      PGM (Probabilistic Graphical Modelling) で用いられる代表的なモデル３つ（ベイジアンネットワーク，マルコフネットワーク，ファクターグラフ）を定義し，その性質を抽象的に説明する．これらは，複雑な高次元分布の分解を，計算機に理解可能な形で与える技法である．マルコフネットワークの形で与えられる分布に対しては，たとえ高次元であろうとも，MCMC によって効率的なサンプリングが可能である．
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">目次</h2>
   
  <ul>
  <li><a href="#歴史と導入" id="toc-歴史と導入" class="nav-link active" data-scroll-target="#歴史と導入"><span class="header-section-number">1</span> 歴史と導入</a>
  <ul class="collapse">
  <li><a href="#例" id="toc-例" class="nav-link" data-scroll-target="#例"><span class="header-section-number">1.1</span> 例</a></li>
  <li><a href="#はじめに" id="toc-はじめに" class="nav-link" data-scroll-target="#はじめに"><span class="header-section-number">1.2</span> はじめに</a></li>
  <li><a href="#諸科学での知識表現の歴史" id="toc-諸科学での知識表現の歴史" class="nav-link" data-scroll-target="#諸科学での知識表現の歴史"><span class="header-section-number">1.3</span> 諸科学での知識表現の歴史</a></li>
  <li><a href="#sec-probabilistic-methods" id="toc-sec-probabilistic-methods" class="nav-link" data-scroll-target="#sec-probabilistic-methods"><span class="header-section-number">1.4</span> 人工知能分野での確率的モデリングの採用</a></li>
  <li><a href="#bayesian-network-と確率的モデリングの登場" id="toc-bayesian-network-と確率的モデリングの登場" class="nav-link" data-scroll-target="#bayesian-network-と確率的モデリングの登場"><span class="header-section-number">1.5</span> Bayesian Network と確率的モデリングの登場</a></li>
  <li><a href="#markov-network-の登場と-mcmc-の普及" id="toc-markov-network-の登場と-mcmc-の普及" class="nav-link" data-scroll-target="#markov-network-の登場と-mcmc-の普及"><span class="header-section-number">1.6</span> Markov Network の登場と MCMC の普及</a></li>
  </ul></li>
  <li><a href="#sec-BN" id="toc-sec-BN" class="nav-link" data-scroll-target="#sec-BN"><span class="header-section-number">2</span> Bayesian Network</a>
  <ul class="collapse">
  <li><a href="#sec-naive-Bayes" id="toc-sec-naive-Bayes" class="nav-link" data-scroll-target="#sec-naive-Bayes"><span class="header-section-number">2.1</span> 例：ナイーブ Bayes モデル</a></li>
  <li><a href="#sec-DAG" id="toc-sec-DAG" class="nav-link" data-scroll-target="#sec-DAG"><span class="header-section-number">2.2</span> DAG</a></li>
  <li><a href="#dag-が表現する局所独立構造" id="toc-dag-が表現する局所独立構造" class="nav-link" data-scroll-target="#dag-が表現する局所独立構造"><span class="header-section-number">2.3</span> DAG が表現する局所独立構造</a></li>
  <li><a href="#bayesian-network-の特徴付け" id="toc-bayesian-network-の特徴付け" class="nav-link" data-scroll-target="#bayesian-network-の特徴付け"><span class="header-section-number">2.4</span> Bayesian Network の特徴付け</a></li>
  <li><a href="#節グラフの分離性" id="toc-節グラフの分離性" class="nav-link" data-scroll-target="#節グラフの分離性"><span class="header-section-number">2.5</span> ３節グラフの分離性</a></li>
  <li><a href="#一般の-dag-の分離性" id="toc-一般の-dag-の分離性" class="nav-link" data-scroll-target="#一般の-dag-の分離性"><span class="header-section-number">2.6</span> 一般の DAG の分離性</a></li>
  <li><a href="#例-1" id="toc-例-1" class="nav-link" data-scroll-target="#例-1"><span class="header-section-number">2.7</span> 例</a></li>
  <li><a href="#sec-characterization-of-d-separation" id="toc-sec-characterization-of-d-separation" class="nav-link" data-scroll-target="#sec-characterization-of-d-separation"><span class="header-section-number">2.8</span> 分離性の特徴付け</a></li>
  <li><a href="#i-同値性" id="toc-i-同値性" class="nav-link" data-scroll-target="#i-同値性"><span class="header-section-number">2.9</span> <span class="math inline">\(I\)</span>-同値性</a></li>
  </ul></li>
  <li><a href="#markov-network" id="toc-markov-network" class="nav-link" data-scroll-target="#markov-network"><span class="header-section-number">3</span> Markov Network</a>
  <ul class="collapse">
  <li><a href="#グラフ理論の準備" id="toc-グラフ理論の準備" class="nav-link" data-scroll-target="#グラフ理論の準備"><span class="header-section-number">3.1</span> グラフ理論の準備</a></li>
  <li><a href="#markov-network-と-markov-random-field" id="toc-markov-network-と-markov-random-field" class="nav-link" data-scroll-target="#markov-network-と-markov-random-field"><span class="header-section-number">3.2</span> Markov Network と Markov Random Field</a></li>
  <li><a href="#はじめに-1" id="toc-はじめに-1" class="nav-link" data-scroll-target="#はじめに-1"><span class="header-section-number">3.3</span> はじめに</a></li>
  <li><a href="#ファクター" id="toc-ファクター" class="nav-link" data-scroll-target="#ファクター"><span class="header-section-number">3.4</span> ファクター</a></li>
  <li><a href="#sec-separation-in-markov-network" id="toc-sec-separation-in-markov-network" class="nav-link" data-scroll-target="#sec-separation-in-markov-network"><span class="header-section-number">3.5</span> Markov Network の分離性</a></li>
  <li><a href="#局所依存性" id="toc-局所依存性" class="nav-link" data-scroll-target="#局所依存性"><span class="header-section-number">3.6</span> 局所依存性</a></li>
  </ul></li>
  <li><a href="#sec-Factor-Graph" id="toc-sec-Factor-Graph" class="nav-link" data-scroll-target="#sec-Factor-Graph"><span class="header-section-number">4</span> Factor Graph</a>
  <ul class="collapse">
  <li><a href="#定義" id="toc-定義" class="nav-link" data-scroll-target="#定義"><span class="header-section-number">4.1</span> 定義</a></li>
  </ul></li>
  
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="歴史と導入" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="歴史と導入"><span class="header-section-number">1</span> 歴史と導入</h2>
<section id="例" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="例"><span class="header-section-number">1.1</span> 例</h3>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="ベイジアンネットワークの例^[[@Taroni+2014 p.35]，[@Sucar2021 p.x], [@Clark2018] [Graphical Models](https://m-clark.github.io/sem/graphical-models.html)．[@Jordan+1999 p.191] は 3.2節で Neural Networks as Graphical Models を扱っている．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>ベイジアンネットワークの例<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><a href="../../../posts/2024/Kernels/HierarchicalModel.html">階層モデル</a> や構造方程式モデル，<a href="../../../posts/2023/Surveys/SSM.html">状態空間モデル</a></li>
<li>ニューラルネットワーク <span class="citation" data-cites="Rumelhart+1987">(<a href="#ref-Rumelhart+1987" role="doc-biblioref">Rumelhart et al., 1987</a>)</span></li>
<li><a href="../../../posts/2023/数理法務/法律家のための統計数理3.html">決定木</a> や influence diagram <span class="citation" data-cites="Howard-Matheson1981">(<a href="#ref-Howard-Matheson1981" role="doc-biblioref">R. A. Howard and Matheson, 1981</a>)</span></li>
<li>システム工学におけるブロック線図</li>
<li>構造的因果モデル <span class="citation" data-cites="Pearl16-Primer">(<a href="#ref-Pearl16-Primer" role="doc-biblioref">Pearl et al., 2016</a>)</span><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></li>
</ul>
</div>
</div>
<p>また，ベイジアンネットワークは，<a href="../../../posts/2023/Probability/MarkovCategory.html">Markov 圏</a> 上の図式のうち，特定のグラフ理論的な条件 <a href="#sec-DAG" class="quarto-xref">2.2</a> を満たすものと見れる．</p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="マルコフネットワークの例^[[@Mezard-Montanari2009 p.177] 9.1.2 節に，ファクターグラフの例が挙げられている．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>マルコフネットワークの例<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>（２次元以下の）<a href="../../../posts/2024/Computation/PGM2.html#sec-Ising-model">Ising 模型</a> や <a href="../../../posts/2024/Nature/StatisticalMechanics1.html#sec-Potts">Potts 模型</a> はマルコフネットワークの例である．</li>
<li>画像データはマルコフネットワークとみなされ，デノイジングなどに用いられる．</li>
</ul>
</div>
</div>
<p>ファクターグラフは，マルコフネットワークと，その上に局所的に定義されたポテンシャルに関する情報との組である．</p>
<p>以上，グラフを利用したモデリング法は全て，確率的グラフィカルモデルとも呼ばれる．</p>
</section>
<section id="はじめに" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="はじめに"><span class="header-section-number">1.2</span> はじめに</h3>
<p>モデルに変数が多く含まれるほど，モデリングの作業は難しくなっていく．</p>
<p>その中でも，最も基本的な事前知識は「どの変数の間に関係があり，どの変数は互いに独立か」というタイプのものであり，変数間のグラフを描くことで特にわかりやすくなる．</p>
<p><strong>グラフィカルモデル</strong> とは，このような変数間の依存性・独立性を表現したグラフに，特定の分布族を対応させる数学的枠組みである．<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
</section>
<section id="諸科学での知識表現の歴史" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="諸科学での知識表現の歴史"><span class="header-section-number">1.3</span> 諸科学での知識表現の歴史</h3>
<p>多くの科学分野において，「知識表現」の「知識」とは，特に因果関係に関する知識のことを指すようである．これを捉えるために，グラフを用いることは自然な発想であり，計算機の登場以前にも，純粋に人間が理解を深めるための用途に，歴史上極めて早い時期から用いられていた．</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="グラフ表現の歴史^[[@Koller-Friedman2009 pp.12-14] 1.4節 など．]">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Caution</span>グラフ表現の歴史<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>高次元分布において，成分間の独立性をグラフを用いて表現しようという発想は，その計算機との親和性が見つかる前に，種々の科学分野で試みられていた．</p>
<ul>
<li><span class="citation" data-cites="Gibbs1902">(<a href="#ref-Gibbs1902" role="doc-biblioref">Gibbs, 1902</a>)</span> が統計力学の文脈で，相関粒子系の分布をグラフで表現した．</li>
<li><span class="citation" data-cites="Wright1918">(<a href="#ref-Wright1918" role="doc-biblioref">Wright, 1918</a>)</span> は骨格測定のデータを用いた因子分析で，（遺伝的な意味での）依存関係を，パス図と呼ばれる有向グラフを用いて表した．</li>
<li><span class="citation" data-cites="Wold1954">(<a href="#ref-Wold1954" role="doc-biblioref">Herman Wold, 1954</a>)</span> とその教え子との <span class="citation" data-cites="Joreskog-Wold1981">(<a href="#ref-Joreskog-Wold1981" role="doc-biblioref">K. G. Jöreskog and Wold, 1982</a>)</span>，さらに <span class="citation" data-cites="Blalock1971">(<a href="#ref-Blalock1971" role="doc-biblioref">Blalock&nbsp;Jr., 1971</a>)</span> が社会学において，因果をグラフを用いて表す因子分析法を <strong>構造方程式モデル</strong> (SEM: Structural Equation Model) の名前の下に普及させた．<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></li>
<li>経済学では特に <strong>操作変数法</strong> として独自の発展を遂げている．</li>
<li>その後 <span class="citation" data-cites="Wold-Strotz60">(<a href="#ref-Wold-Strotz60" role="doc-biblioref">H. Wold and Strotz, 1960</a>)</span> は <span class="citation" data-cites="Pearl09-Causality">(<a href="#ref-Pearl09-Causality" role="doc-biblioref">Pearl, 2009</a>)</span> などの do-calculus に繋がっている．これはパス解析や構造方程式モデルのノンパラメトリックな拡張とも見れる．<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></li>
<li>統計学でも <span class="citation" data-cites="Bartlett1935">(<a href="#ref-Bartlett1935" role="doc-biblioref">Bartlett, 1935</a>)</span> が分割表分析において変数同士の相関の研究をしたが，界隈が本格的に受け入れたのはやっと 1960 年代以降である．</li>
</ul>
</div>
</div>
</div>
</section>
<section id="sec-probabilistic-methods" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="sec-probabilistic-methods"><span class="header-section-number">1.4</span> 人工知能分野での確率的モデリングの採用</h3>
<p>人工知能分野が確率的手法を採用したのは，エキスパートシステムの構築が志向された 1960 年代であった．<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<p>医療診断や油源探索における専門家に匹敵する判断力を持つアルゴリズムを構築する途上で，不確実性の度合いの定量化が必要となり，naive Bayes model （第 <a href="#sec-naive-Bayes" class="quarto-xref">2.1</a> 節）と呼ばれる確率的モデルが採用された．特に <span class="citation" data-cites="Dombal+1972">(<a href="#ref-Dombal+1972" role="doc-biblioref">de&nbsp;Dombal et al., 1972</a>)</span> は限られた分野であるが人間を凌駕する診断正答率を示した．</p>
<p>だがこの確率的アプローチは，主にその計算複雑性から 1970 年代では冬の時代を経験することとなり，エキスパートシステムも production rule framework や <a href="https://ja.wikipedia.org/wiki/%E3%83%95%E3%82%A1%E3%82%B8%E3%82%A3%E8%AB%96%E7%90%86">ファジー論理</a> <span class="citation" data-cites="Zadeh1989">(<a href="#ref-Zadeh1989" role="doc-biblioref">Zadeh, 1989</a>)</span> など，確率論に代わって他のアーキテクチャが試みられるようになっていった．</p>
<div class="callout callout-style-default callout-important no-icon callout-titled" title="Bayesian network とエキスパートシステム">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Bayesian network とエキスパートシステム
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>グラフィカルモデリングは初め，自立して推論・意思決定を行うエキスパート・システムの構築のために人工知能分野で用いられ始めた．<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<p>ベイズ流のアプローチでは，事前分布を定める上で，系に対する客観的な事前知識と主観的な事前知識とを分けることが重要であるが，グラフィカルモデルや階層モデリングはこの分離を自然に行うことができる <span class="citation" data-cites="Robert2007">(<a href="#ref-Robert2007" role="doc-biblioref">C. P. Robert, 2007, pp. 457–458</a>)</span>．</p>
<p>世界に対する知識には不確実性がつきものであり，実世界応用ではこの「不確実性」を反映したモデリング手法が有効であることが多い．そこで，近年の機械学習へのベイズ流アプローチでも，グラフィカルモデルは盛んに応用されている（第 <a href="#sec-probabilistic-methods" class="quarto-xref">1.4</a> 節）．<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<blockquote class="blockquote">
<p>I have approximate answers and possible beliefs with different degrees of uncertainty about different things, but I am not absolutely sure of anything. – <a href="https://www.youtube.com/watch?v=P-Qdl6Gbx0k">Richard Feynman</a></p>
</blockquote>
<p>加えてグラフという表現方法は，人間にとって視覚的にわかりやすいだけでなく，周辺化，極値計算，条件付き確率の計算を高速化するという点で計算機的にも利点がある．<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a></p>
</div>
</div>
</div>
</section>
<section id="bayesian-network-と確率的モデリングの登場" class="level3" data-number="1.5">
<h3 data-number="1.5" class="anchored" data-anchor-id="bayesian-network-と確率的モデリングの登場"><span class="header-section-number">1.5</span> Bayesian Network と確率的モデリングの登場</h3>
<p>これを打開したのが</p>
<div class="callout callout-style-simple callout-important no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<ol type="1">
<li><span class="citation" data-cites="Pearl88-IntelligentSystem">(<a href="#ref-Pearl88-IntelligentSystem" role="doc-biblioref">Pearl, 1988</a>)</span> による Bayesian network framework と，<span class="citation" data-cites="Lauritzen-Spiegelhalter1988">(<a href="#ref-Lauritzen-Spiegelhalter1988" role="doc-biblioref">Lauritzen and Spiegelhalter, 1988</a>)</span> による効率的な推論手法という理論的発展．</li>
<li><span class="citation" data-cites="Heckerman+1992">(<a href="#ref-Heckerman+1992" role="doc-biblioref">Heckerman et al., 1992</a>)</span>, <span class="citation" data-cites="Heckerman-Nathwani1992">(<a href="#ref-Heckerman-Nathwani1992" role="doc-biblioref">Heckerman and Nathwani, 1992</a>)</span> が Bayesian network を病理学標本に応用して大きな成功を挙げたこと．</li>
</ol>
</div>
</div>
</div>
<p>の２つである．</p>
<p>これにより，確率的グラフィカルモデル，また一般に確率的アプローチが広く受け入れられるようになった．</p>
</section>
<section id="markov-network-の登場と-mcmc-の普及" class="level3" data-number="1.6">
<h3 data-number="1.6" class="anchored" data-anchor-id="markov-network-の登場と-mcmc-の普及"><span class="header-section-number">1.6</span> Markov Network の登場と MCMC の普及</h3>
<p>MCMC が真に統計界隈に輸入されるきっかけとなった <span class="citation" data-cites="Gelfand-Smith1990">(<a href="#ref-Gelfand-Smith1990" role="doc-biblioref">Gelfand and Smith, 1990</a>)</span> は Gibbs サンプラーに関するものであった．<span class="citation" data-cites="Geman-Geman1984">(<a href="#ref-Geman-Geman1984" role="doc-biblioref">Geman and Geman, 1984</a>)</span> による Gibbs サンプラーの提案も，画像分析，広く空間統計学においてなされたものであった．</p>
<p>統計物理学における Ising モデルが，空間統計学において Markov random field として広く受け入れられ <span class="citation" data-cites="Besag1974">(<a href="#ref-Besag1974" role="doc-biblioref">Besag, 1974</a>)</span>，これにより統計界隈に階層モデルと Gibbs サンプラーが広く受け入れられるようになったのである．</p>
<p>特に，Markov random field が，Gibbs 分布の局所的な条件付き分布からの特徴付けを与える（Hammersley-Clifford の定理<a href="#sec-separation-in-markov-network" class="quarto-xref">3.5</a>）という認識を導き，このことが MCMC を一般の Bayes 計算手法たらしめたと強調している <span class="citation" data-cites="Besag-Green1993">(<a href="#ref-Besag-Green1993" role="doc-biblioref">Besag and Green, 1993</a>)</span>．<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a></p>
<blockquote class="blockquote">
<p>it is no coincidence that the original concept and the early development of MCMC in Bayesian inference should take place exclusivelyin the spatial statistics literature. <span class="citation" data-cites="Besag-Green1993">(<a href="#ref-Besag-Green1993" role="doc-biblioref">Besag and Green, 1993, p. 26</a>)</span></p>
</blockquote>
<!-- ### 確率的グラフィカルモデリングの美点

確率的グラフィカルモデリングの美点は，人間（エキスパート）と計算機の協業を促進する共通言語としての働きが出来る点である．

1. 人間と計算機の双方にとって解釈しやすい **表現** である．
2. 確率的グラフィカルモデルで表現できる分布のクラスと，効率的に Bayes **推論** が可能な分布のクラスとが一致する．^[[@Koller-Friedman2009 pp.5-6] 1.2.2節．高次元分布が成分間に依存を持つことと，その依存を用いてコンパクトに低次元で表現可能であることとは殆ど等価な事実である．]
3. 人間と計算機の双方がモデリングに参加できる．後者によるモデリングは，**学習** とも呼ばれることになる．^[[@Koller-Friedman2009 p.6] 1.2.2節．"Probabilistic graphical models support a data-driven approach to model construction that is very eﬀective in practice."]

さらに，高次元分布 $P$ の成分間の依存関係を効率よく捉える手法であるため，その背後にあるグラフが判れば，グラフの分離性（ @sec-separation-in-markov-network ）を判定するだけで，$P$ の独立性の情報を得ることが出来る．

他にも，グラフの構造を用いて，$P$ を効率的に表現し，本質的な次元を大幅に落として計算を効率化することもできる． -->
</section>
</section>
<section id="sec-BN" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="sec-BN"><span class="header-section-number">2</span> Bayesian Network</h2>
<section id="sec-naive-Bayes" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="sec-naive-Bayes"><span class="header-section-number">2.1</span> 例：ナイーブ Bayes モデル</h3>
<p><a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">naive Bayes model</a> は Idiot Bayes model とも呼ばれる Bayesian Network の簡単な例である．</p>
<p>これは <strong>クラス</strong> と呼ばれる離散潜在変数 <span class="math inline">\(C\in\{c^1,\cdots,c^k\}\)</span> を持つ次のようなモデルである．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="naiveBayes.svg" class="img-fluid figure-img"></p>
<figcaption>naive Bayes model</figcaption>
</figure>
</div>
<p>この際，グラフィカルモデルに共通する用語を確認する．</p>
<ul>
<li>クラスの実現値 <span class="math inline">\(c^i\)</span> を <strong>インスタンス</strong> と呼ぶ．</li>
<li>潜在変数の実現値が確定することを，<strong>観測</strong> の他に <strong>インスタンス化</strong> ともいう．</li>
<li>インスタンス化されたときに取る値は <strong>エビデンス</strong> とも呼ばれる．</li>
</ul>
<p>観測値 <span class="math inline">\(X_1,\cdots,X_n\)</span> は <strong>特徴</strong> (features) と呼ばれ，これは互いに辺で結ばれていないため，クラスを与えた下で互いに条件付き独立であるとする： <span class="math display">\[
(X_i\perp\!\!\!\perp\boldsymbol{X}_{-i}\mid C)\;(i\in[n]),
\]</span> <span class="math display">\[
\boldsymbol{X}_{-i}:=(X_{1:i-1},X_{i+1:n}).
\]</span></p>
<p>こうして得る階層モデルを <strong>naive Bayes model</strong> という．<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a> その結合密度は <span class="math display">\[
p(c,x_1,\cdots,x_n)=p(c)\prod_{i=1}^np(x_i|c)
\]</span> と表せる．</p>
</section>
<section id="sec-DAG" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="sec-DAG"><span class="header-section-number">2.2</span> DAG</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 p.57]，[@Mezard-Montanari2009 p.269]．] （Bayesian Network structure）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>定義<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> （Bayesian Network structure）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>確率変数 <span class="math inline">\(\boldsymbol{X}:=(X_1,\cdots,X_n)\)</span> に関して，成分の全体 <span class="math inline">\(\mathcal{X}:=\{\mathcal{X}_1,\cdots,\mathcal{X}_n\}\)</span> を節集合とした <a href="https://ja.wikipedia.org/wiki/%E6%9C%89%E5%90%91%E9%9D%9E%E5%B7%A1%E5%9B%9E%E3%82%B0%E3%83%A9%E3%83%95"><strong>有向非循環グラフ</strong></a> (directed acyclic graph, DAG) <span class="math inline">\(\mathcal{G}=(\mathcal{X},\mathcal{E})\)</span> を <strong>Bayesian Network 構造</strong> といい，これが親ノードから子ノードへの確率核 <span class="math inline">\(P_i:\pi(\mathcal{X}_i)\to\mathcal{X}_i\)</span> を通じて定める <span class="math display">\[
\prod_{\mathcal{X}_i\in\mathcal{X}}P_i
\]</span> という形の分布の全体を <strong>Bayesian Network</strong> または <strong>有向グラフィカルモデル</strong> という．</p>
</div>
</div>
</div>
<p>Bayesian network は belief network とも呼ばれる．<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a> 決定分析で用いられる <a href="https://en.wikipedia.org/wiki/Influence_diagram">influence diagram</a> / decision network はその一般化である．</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="記法（親ノード，子孫ノード，非子孫ノード）">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Caution</span>記法（親ノード，子孫ノード，非子孫ノード）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>DAG <span class="math inline">\(\mathcal{G}\)</span> において，</p>
<ul>
<li>節 <span class="math inline">\(\mathcal{X}_i\)</span> からその親節の全体への対応を <span class="math display">\[
\mathcal{X}_i\mapsto\pi(\mathcal{X}_i)
\]</span> で表す．</li>
<li>節 <span class="math inline">\(\mathcal{X}_i\)</span> からその子節の全体への対応を添字について表現したものを <span class="math display">\[
\mathcal{X}_i\mapsto\mathop{\mathrm{des}}(\mathcal{X}_i)
\]</span> で表す．</li>
<li>次の対応を <strong>非子孫ノード</strong> という： <span class="math display">\[
\mathop{\mathrm{nd}}(\mathcal{X}_i):=\mathcal{X}\setminus(\{\mathcal{X}_i\}\cup\mathop{\mathrm{des}}(\mathcal{X}_i)).
\]</span></li>
</ul>
<p>「子孫ノードである」という関係は DAG 上に順序を定める．</p>
</div>
</div>
</div>
</section>
<section id="dag-が表現する局所独立構造" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="dag-が表現する局所独立構造"><span class="header-section-number">2.3</span> DAG が表現する局所独立構造</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 p.57]] （Directed Local Markov Independence）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>定義<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a> （Directed Local Markov Independence）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>DAG <span class="math inline">\(\mathcal{G}\)</span> が表現する条件付き独立性の全体を <span class="math inline">\(\mathcal{I}(\mathcal{G})\)</span> で表す．そのうち，特に <span class="math display">\[
X_i\perp\!\!\!\perp(X_j)_{j\in\mathop{\mathrm{nd}}(i)}\mid (X_j)_{j\in\pi(i)}
\]</span> という形をしたものを <strong>局所独立性</strong> といい，その（論理式の）全体を <span class="math inline">\(\mathcal{I}_l(\mathcal{G})\)</span> で表す．</p>
</div>
</div>
</div>
<p>Bayesian Network が視覚的表現・記号論で，その表現する所の局所依存性が意味論であると言える．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 p.60]] （Independence Assertions）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>定義<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a> （Independence Assertions）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> をノードの集合 <span class="math inline">\(\mathcal{X}=\{X_1,\cdots,X_n\}\)</span> 上の確率分布とする．<span class="math inline">\((X_i)_{i=1}^n\sim P\)</span> に関して成立する条件付き独立性の主張 <span class="math display">\[
(X_i)_{i\in I}\perp\!\!\!\perp(X_j)_{j\in J}\mid (X_k)_{k\in K}
\]</span> <span class="math display">\[
I\sqcup J\sqcup K\subset[n]
\]</span> の（論理式の）全体を <strong><span class="math inline">\(P\)</span> が含意する条件付き独立性</strong> といい， <span class="math inline">\(\mathcal{I}(P)\)</span> で表す．</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 p.60]] （$I$-Map）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>定義<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a> （<span class="math inline">\(I\)</span>-Map）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(\mathcal{I}\)</span> を確率変数 <span class="math inline">\((X_1,\cdots,X_n)\)</span> の成分間の条件付き独立性に関する論理式の全体，<span class="math inline">\(\mathcal{K}\)</span> を DAG とする．<span class="math inline">\(\mathcal{K}\)</span> が <span class="math inline">\(\mathcal{I}\)</span> の <strong><span class="math inline">\(I\)</span>-map</strong> であるとは， <span class="math display">\[
\mathcal{I}_l(\mathcal{K})\subset\mathcal{I}
\]</span> を満たすことをいう．すなわち，DAG <span class="math inline">\(\mathcal{K}\)</span> が表す局所的な独立性関係が <span class="math inline">\(\mathcal{I}\)</span> に含まれていることをいう．</p>
</div>
</div>
</div>
</section>
<section id="bayesian-network-の特徴付け" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="bayesian-network-の特徴付け"><span class="header-section-number">2.4</span> Bayesian Network の特徴付け</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 p.62]] （factorize, chain rule, local probabilistic model, Bayesian Network）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>定義<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a> （factorize, chain rule, local probabilistic model, Bayesian Network）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(\mathcal{G}\)</span> を確率変数 <span class="math inline">\((X_1,\cdots,X_n)\)</span> に関する Bayesian Network 構造とする．</p>
<ol type="1">
<li>分布 <span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> が <span class="math inline">\(\mathcal{G}\)</span> に従って <strong>分解する</strong> とは，<span class="math inline">\((X_1,\cdots,X_n)\sim P\)</span> と仮定したとき，次が成り立つことをいう： <span class="math display">\[
\mathcal{L}[X_1,\cdots,X_n]=\bigotimes^n_{i=1}\mathcal{L}[X_i|(X_j)_{j\in\pi(i)}].
\]</span></li>
<li>この式を Bayesian Network <span class="math inline">\(\mathcal{G}\)</span> の <strong>連鎖律</strong> といい，右辺の因子 <span class="math inline">\(\mathcal{L}[X_i|(X_j)_{j\in\pi(i)}]\)</span> の全体を 条件付き確率分布族 または <strong>局所モデル</strong> という．</li>
<li>Bayesian Network 構造 <span class="math inline">\(\mathcal{G}\)</span> とこれに沿って分解する分布 <span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> との組 <span class="math inline">\((\mathcal{G},P)\)</span> を，<strong>Bayesian Network</strong> または <strong>有向確率モデル</strong> という．</li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題^[[@Koller-Friedman2009 p.62] 定理3.1，定理3.2 p.63．[@Howard-Matheson1984] による．] （Bayesian Network の特徴付け）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>命題<a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a> （Bayesian Network の特徴付け）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(\mathcal{G}\)</span> を確率変数 <span class="math inline">\((X_1,\cdots,X_n)\)</span> に関する Bayesian Network 構造，<span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> を確率分布とする．このとき，次は同値：</p>
<ol type="1">
<li><span class="math inline">\(\mathcal{G}\)</span> が <span class="math inline">\(\mathcal{I}(P)\)</span> の <span class="math inline">\(I\)</span>-map である．</li>
<li><span class="math inline">\(P\)</span> は <span class="math inline">\(\mathcal{G}\)</span> に従って分解する．</li>
</ol>
</div>
</div>
</div>
</section>
<section id="節グラフの分離性" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="節グラフの分離性"><span class="header-section-number">2.5</span> ３節グラフの分離性</h3>
<p>節が３つ <span class="math inline">\(X,Y,Z\)</span> の場合の DAG は大別して３通り存在する．この場合で「分離性」の概念を説明する．</p>
<p>３つの成分 <span class="math inline">\((X,Y,Z)\)</span> が依存関係にある状態で，<span class="math inline">\(Z\)</span> が観測された（インスタンス化された）とする．</p>
<p>その場合に，<span class="math inline">\(X,Y\)</span> 間の因果関係がどう変化するか？を考える．元々因果関係があったところから，<a href="#fn21" class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a> これが解消されるとき，<span class="math inline">\(X,Y\)</span> は <span class="math inline">\(Z\)</span> を介して <strong><span class="math inline">\(d\)</span>-分離</strong> であるという．<a href="#fn22" class="footnote-ref" id="fnref22" role="doc-noteref"><sup>22</sup></a></p>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="逐次結合の場合">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Caution</span>逐次結合の場合
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>次のような逐次結合の場合，節 <span class="math inline">\(X,Y\)</span> は，節 <span class="math inline">\(Z\)</span> がインスタンス化されたとき <strong><span class="math inline">\(d\)</span>-分離</strong> である，という．</p>
<div class="cell" data-fig-width="1" data-layout-align="default">
<div class="cell-output-display">
<div id="fig-CausalTrail" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-CausalTrail-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<svg width="96" height="480" viewbox="0.00 0.00 62.00 188.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 184)">
<title>CausalTrail</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-184 58,-184 58,4 -4,4"></polygon>
<!-- X -->
<g id="node1" class="node">
<title>X</title>
<ellipse fill="none" stroke="black" cx="27" cy="-162" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="27" y="-157.8" font-family="Times,serif" font-size="14.00">X</text>
</g>
<!-- Z -->
<g id="node2" class="node">
<title>Z</title>
<ellipse fill="none" stroke="black" cx="27" cy="-90" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="27" y="-85.8" font-family="Times,serif" font-size="14.00">Z</text>
</g>
<!-- X&#45;&gt;Z -->
<g id="edge1" class="edge">
<title>X-&gt;Z</title>
<path fill="none" stroke="black" d="M27,-143.7C27,-135.98 27,-126.71 27,-118.11"></path>
<polygon fill="black" stroke="black" points="30.5,-118.1 27,-108.1 23.5,-118.1 30.5,-118.1"></polygon>
</g>
<!-- Y -->
<g id="node3" class="node">
<title>Y</title>
<ellipse fill="none" stroke="black" cx="27" cy="-18" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="27" y="-13.8" font-family="Times,serif" font-size="14.00">Y</text>
</g>
<!-- Z&#45;&gt;Y -->
<g id="edge2" class="edge">
<title>Z-&gt;Y</title>
<path fill="none" stroke="black" d="M27,-71.7C27,-63.98 27,-54.71 27,-46.11"></path>
<polygon fill="black" stroke="black" points="30.5,-46.1 27,-36.1 23.5,-46.1 30.5,-46.1"></polygon>
</g>
</g>
</svg>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-CausalTrail-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
図&nbsp;1: 逐次結合 (Causal Trail)
</figcaption>
</figure>
</div>
</div>
</div>
<p><span class="math inline">\(X\)</span> を勉強量，<span class="math inline">\(Z\)</span> を素点，<span class="math inline">\(Y\)</span> を GPA とするとき，<span class="math inline">\(Z\)</span> が観測されたならば，もはや勉強量は GPA に影響を与えない．ただし，相関は存在するだろうが．</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="分岐結合の場合">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Caution</span>分岐結合の場合
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>次のような分岐結合の場合，節 <span class="math inline">\(X,Y\)</span> は，節 <span class="math inline">\(Z\)</span> がインスタンス化されたとき <strong><span class="math inline">\(d\)</span>-分離</strong> である，という．</p>
<div class="cell" data-fig-width="3" data-layout-align="default">
<div class="cell-output-display">
<div id="fig-CommonCause" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-CommonCause-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<svg width="288" height="480" viewbox="0.00 0.00 134.00 116.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 112)">
<title>CausalTrail</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-112 130,-112 130,4 -4,4"></polygon>
<!-- Z -->
<g id="node1" class="node">
<title>Z</title>
<ellipse fill="none" stroke="black" cx="63" cy="-90" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="63" y="-85.8" font-family="Times,serif" font-size="14.00">Z</text>
</g>
<!-- X -->
<g id="node2" class="node">
<title>X</title>
<ellipse fill="none" stroke="black" cx="27" cy="-18" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="27" y="-13.8" font-family="Times,serif" font-size="14.00">X</text>
</g>
<!-- Z&#45;&gt;X -->
<g id="edge1" class="edge">
<title>Z-&gt;X</title>
<path fill="none" stroke="black" d="M54.65,-72.76C50.29,-64.28 44.85,-53.71 39.96,-44.2"></path>
<polygon fill="black" stroke="black" points="42.99,-42.44 35.3,-35.15 36.77,-45.64 42.99,-42.44"></polygon>
</g>
<!-- Y -->
<g id="node3" class="node">
<title>Y</title>
<ellipse fill="none" stroke="black" cx="99" cy="-18" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="99" y="-13.8" font-family="Times,serif" font-size="14.00">Y</text>
</g>
<!-- Z&#45;&gt;Y -->
<g id="edge2" class="edge">
<title>Z-&gt;Y</title>
<path fill="none" stroke="black" d="M71.35,-72.76C75.71,-64.28 81.15,-53.71 86.04,-44.2"></path>
<polygon fill="black" stroke="black" points="89.23,-45.64 90.7,-35.15 83.01,-42.44 89.23,-45.64"></polygon>
</g>
</g>
</svg>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-CommonCause-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
図&nbsp;2: 分岐結合 (Common Cause)
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="合流結合の場合">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Caution</span>合流結合の場合
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>次のような合流結合の場合，節 <span class="math inline">\(X,Y\)</span> は，節 <span class="math inline">\(Z\)</span> またはその子孫節がインスタンス化されなければ，節 <span class="math inline">\(Z\)</span> を介して <strong><span class="math inline">\(d\)</span>-分離</strong> である，という．</p>
<div class="cell" data-fig-width="3" data-layout-align="default">
<div class="cell-output-display">
<div id="fig-CommonEffect" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-CommonEffect-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<svg width="288" height="480" viewbox="0.00 0.00 134.00 116.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 112)">
<title>CausalTrail</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-112 130,-112 130,4 -4,4"></polygon>
<!-- X -->
<g id="node1" class="node">
<title>X</title>
<ellipse fill="none" stroke="black" cx="27" cy="-90" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="27" y="-85.8" font-family="Times,serif" font-size="14.00">X</text>
</g>
<!-- Z -->
<g id="node2" class="node">
<title>Z</title>
<ellipse fill="none" stroke="black" cx="63" cy="-18" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="63" y="-13.8" font-family="Times,serif" font-size="14.00">Z</text>
</g>
<!-- X&#45;&gt;Z -->
<g id="edge1" class="edge">
<title>X-&gt;Z</title>
<path fill="none" stroke="black" d="M35.35,-72.76C39.71,-64.28 45.15,-53.71 50.04,-44.2"></path>
<polygon fill="black" stroke="black" points="53.23,-45.64 54.7,-35.15 47.01,-42.44 53.23,-45.64"></polygon>
</g>
<!-- Y -->
<g id="node3" class="node">
<title>Y</title>
<ellipse fill="none" stroke="black" cx="99" cy="-90" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="99" y="-85.8" font-family="Times,serif" font-size="14.00">Y</text>
</g>
<!-- Y&#45;&gt;Z -->
<g id="edge2" class="edge">
<title>Y-&gt;Z</title>
<path fill="none" stroke="black" d="M90.65,-72.76C86.29,-64.28 80.85,-53.71 75.96,-44.2"></path>
<polygon fill="black" stroke="black" points="78.99,-42.44 71.3,-35.15 72.77,-45.64 78.99,-42.44"></polygon>
</g>
</g>
</svg>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-CommonEffect-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
図&nbsp;3: 合流結合 (Common Effect)
</figcaption>
</figure>
</div>
</div>
</div>
<p>この構造は <span class="math inline">\(v\)</span>-構造ともいう．<a href="#fn23" class="footnote-ref" id="fnref23" role="doc-noteref"><sup>23</sup></a> この場合，<span class="math inline">\(Z\)</span> が観測されたならば，<span class="math inline">\(X,Y\)</span> は因果関係を持つようになる．</p>
<p><span class="math inline">\(Z\)</span> が事象の有無で，<span class="math inline">\(X,Y\)</span> のいずれかが起こった時に <span class="math inline">\(Z\)</span> も起こるとしよう．いま <span class="math inline">\(Z\)</span> が起こったこと <span class="math inline">\(Z=1\)</span> が判明したとすると，<span class="math inline">\(X,Y\)</span> のいずれか一方も起こっている必要がある．従って，<span class="math inline">\(X=0\)</span> は <span class="math inline">\(Y=1\)</span> を要請するという因果関係が生じる．</p>
</div>
</div>
</div>
</section>
<section id="一般の-dag-の分離性" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="一般の-dag-の分離性"><span class="header-section-number">2.6</span> 一般の DAG の分離性</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 pp.71-72] 定義3.6, 3.7．] （active, $d$-Separated, Directed Global Markov Independencies）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-15-contents" aria-controls="callout-15" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>定義<a href="#fn24" class="footnote-ref" id="fnref24" role="doc-noteref"><sup>24</sup></a> （active, <span class="math inline">\(d\)</span>-Separated, Directed Global Markov Independencies）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-15" class="callout-15-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(\mathcal{G}\)</span> を Bayesian Network 構造，<span class="math inline">\(\boldsymbol{Z}\subset\mathcal{X}\)</span> を観測された節とする．</p>
<ol type="1">
<li>非有向道 <span class="math inline">\(X_1\rightleftharpoons\cdots\rightleftharpoons X_n\)</span> が <span class="math inline">\(\boldsymbol{Z}\)</span> の下でも <strong>active</strong> であるとは， 次の２条件を満たすことをいう：
<ol type="1">
<li><span class="math inline">\(\{X_i\}_{i=1}^n\cap\boldsymbol{Z}=\emptyset\)</span>．</li>
<li>任意の無向道内の合流結合 <span class="math inline">\(X_{i-1}\rightarrow X_i\leftarrow X_{i+1}\)</span> について，<span class="math inline">\(X_i\)</span> またはその子孫に <span class="math inline">\(\boldsymbol{Z}\)</span> の元が存在する．</li>
</ol></li>
<li><span class="math inline">\(\boldsymbol{X}\sqcup\boldsymbol{Y}\sqcup\boldsymbol{Z}\subset\mathcal{X}\)</span> を節の集合とする．<span class="math inline">\(\boldsymbol{X},\boldsymbol{Y}\)</span> が <span class="math inline">\(\boldsymbol{Z}\)</span> に関して <strong><span class="math inline">\(d\)</span>-分離</strong> であるとは，任意の <span class="math inline">\(X\in\boldsymbol{X}\)</span> と <span class="math inline">\(Y\in\boldsymbol{Y}\)</span> と，<span class="math inline">\(X,Y\)</span> を結ぶ無向道が，<span class="math inline">\(\boldsymbol{Z}\)</span> の下で active でないことをいう．このことを <span class="math inline">\(\mathop{\mathrm{d-sep}}_\mathcal{G}(\boldsymbol{X};\boldsymbol{Y}|\boldsymbol{Z})\)</span> と表す．<a href="#fn25" class="footnote-ref" id="fnref25" role="doc-noteref"><sup>25</sup></a></li>
<li><span class="math inline">\(\mathcal{G}\)</span> 内の <span class="math inline">\(d\)</span>-分離な組 <span class="math inline">\((\boldsymbol{X},\boldsymbol{Y},\boldsymbol{Z})\)</span> が表す条件付き独立性の条件式の全体を <span class="math display">\[
\mathcal{I}(\mathcal{G}):=\left\{(\boldsymbol{X}\perp\!\!\!\perp\boldsymbol{Y}|\boldsymbol{Z})\mid\mathop{\mathrm{d-sep}}_\mathcal{G}(\boldsymbol{X};\boldsymbol{Y}|\boldsymbol{Z})\right\}.
\]</span> この元を <strong>大域的独立性</strong> ともいう．</li>
</ol>
</div>
</div>
</div>
<p>局所依存性（ <a href="#sec-DAG" class="quarto-xref">Section&nbsp;2.2</a> ）は <span class="math inline">\(d\)</span>-分離性の特別な場合であり，<span class="math inline">\(\mathcal{I}_l(\mathcal{G})\subset\mathcal{I}(\mathcal{G})\)</span> である．</p>
</section>
<section id="例-1" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="例-1"><span class="header-section-number">2.7</span> 例</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Files/separation.svg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption><span class="math inline">\(d\)</span>-分離になるのはいつか？</figcaption>
</figure>
</div>
<p>この Bayesian Network 構造は，いつ <span class="math inline">\(d\)</span>-分離になり，いつ <span class="math inline">\(d\)</span>-分離ではないか？</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="答え">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-16-contents" aria-controls="callout-16" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Caution</span>答え
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-16-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>いずれも観測されない場合は <span class="math inline">\(d\)</span>-分離である．</li>
<li><span class="math inline">\(Z\)</span> が観測された場合，<span class="math inline">\(A,B\)</span> のいずれかも観測されていれば，やはり <span class="math inline">\(d\)</span>-分離である．</li>
</ul>
</div>
</div>
</div>
</section>
<section id="sec-characterization-of-d-separation" class="level3" data-number="2.8">
<h3 data-number="2.8" class="anchored" data-anchor-id="sec-characterization-of-d-separation"><span class="header-section-number">2.8</span> 分離性の特徴付け</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題^[[@Koller-Friedman2009 pp.72-73] 定理3.3, 3.5．] （$d$-分離性の特徴付け）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-17-contents" aria-controls="callout-17" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>命題<a href="#fn26" class="footnote-ref" id="fnref26" role="doc-noteref"><sup>26</sup></a> （<span class="math inline">\(d\)</span>-分離性の特徴付け）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-17" class="callout-17-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(\mathcal{G}\)</span> を Bayesian Network 構造，<span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> を確率分布とする．</p>
<ol type="1">
<li><span class="math inline">\(P\)</span> が <span class="math inline">\(\mathcal{G}\)</span> に沿って分解するならば，<span class="math inline">\(\mathcal{I}(\mathcal{G})\subset\mathcal{I}(P)\)</span>．</li>
<li><span class="math inline">\(\mathcal{H}\)</span> に沿って分解する殆ど全ての <span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> に関して，上の逆も成り立ち，特に等号が成立する．</li>
</ol>
</div>
</div>
</div>
<p><span class="math inline">\(\mathcal{G}\)</span> が定める分布族について，殆ど全ての分布が共通して持つ条件付き独立性の構造を，<span class="math inline">\(\mathcal{G}\)</span> から読み取れる <span class="math inline">\(d\)</span>-分離性によって発見できるということになる．</p>
<p>さらには，分布 <span class="math inline">\(P\)</span> の独立性の情報を知りたい場合，この背後にあるグラフ <span class="math inline">\(\mathcal{G}\)</span> を探し出して，<span class="math inline">\(d\)</span>-分離性を調べれば良い，ということでもであるのである．<a href="#fn27" class="footnote-ref" id="fnref27" role="doc-noteref"><sup>27</sup></a></p>
</section>
<section id="i-同値性" class="level3" data-number="2.9">
<h3 data-number="2.9" class="anchored" data-anchor-id="i-同値性"><span class="header-section-number">2.9</span> <span class="math inline">\(I\)</span>-同値性</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 p.76] 定義3.9．] （$I$-Equivalence）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>定義<a href="#fn28" class="footnote-ref" id="fnref28" role="doc-noteref"><sup>28</sup></a> （<span class="math inline">\(I\)</span>-Equivalence）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>２つの Bayesian Network 構造 <span class="math inline">\(\mathcal{G},\mathcal{G}'\)</span> が <strong><span class="math inline">\(I\)</span>-同値</strong> であるとは，<span class="math inline">\(\mathcal{I}(\mathcal{G})=\mathcal{I}(\mathcal{G}')\)</span> が成り立つことをいう．</p>
</div>
</div>
</div>
<p><span class="math inline">\(I\)</span> は写像であるから，この関係は確かに Bayesian Network 構造の全体（果てには有向グラフの全体）に同値関係を定める．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題^[[@Koller-Friedman2009 p.77] 定理3.7．] （$I$-同値性の十分条件）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-19-contents" aria-controls="callout-19" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>命題<a href="#fn29" class="footnote-ref" id="fnref29" role="doc-noteref"><sup>29</sup></a> （<span class="math inline">\(I\)</span>-同値性の十分条件）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-19" class="callout-19-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>２つの Bayesian Network 構造 <span class="math inline">\(\mathcal{G},\mathcal{G}'\)</span> が</p>
<ol type="1">
<li>同じスケルトンを持ち，<a href="#fn30" class="footnote-ref" id="fnref30" role="doc-noteref"><sup>30</sup></a></li>
<li>同じ <span class="math inline">\(v\)</span>-構造を持つ</li>
</ol>
<p>ならば，<span class="math inline">\(I\)</span>-同値である．</p>
</div>
</div>
</div>
<p>有向グラフ <span class="math inline">\(\mathcal{G}=(\mathcal{X},\mathcal{E})\)</span> の辺 <span class="math inline">\((X,Y)\in\mathcal{E}\)</span> が <strong>被覆されている</strong> とは， <span class="math display">\[
\pi(Y)=\pi(X)\cup\{X\}
\]</span> を満たすことをいう．</p>
<p>合流結合 <span class="math inline">\(X\rightarrow Z\leftarrow Y\)</span> において，辺 <span class="math inline">\(X\to Z\)</span> は被覆されていない．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題^[[@Koller-Friedman2009 p.77] 定理3.8．] （$I$-同値性の特徴付け）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-20-contents" aria-controls="callout-20" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>命題<a href="#fn31" class="footnote-ref" id="fnref31" role="doc-noteref"><sup>31</sup></a> （<span class="math inline">\(I\)</span>-同値性の特徴付け）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-20" class="callout-20-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>２つの Bayesian Network 構造 <span class="math inline">\(\mathcal{G},\mathcal{G}'\)</span> について，次は同値：</p>
<ol type="1">
<li><span class="math inline">\(\mathcal{G},\mathcal{G}'\)</span> は <span class="math inline">\(I\)</span>-同値である．</li>
<li><span class="math inline">\(\mathcal{G}\)</span> に <span class="math inline">\(I\)</span>-同値なグラフの列 <span class="math inline">\(\mathcal{G}=\mathcal{G}_0,\cdots,\mathcal{G}_m=\mathcal{G}'\)</span> であって，隣り合うグラフ <span class="math inline">\(\mathcal{G}_i,\mathcal{G}_{i+1}\;(i\in m)\)</span> 同士は，被覆されている辺の向きの反転しか違わないものが存在する．</li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="markov-network" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="markov-network"><span class="header-section-number">3</span> Markov Network</h2>
<section id="グラフ理論の準備" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="グラフ理論の準備"><span class="header-section-number">3.1</span> グラフ理論の準備</h3>
<p><span class="math inline">\(A\)</span> を集合とする． <span class="math display">\[
[A]^k:=\left\{B\in P(A)\mid\# B=k\right\}
\]</span> とする．無向グラフとは集合 <span class="math inline">\(V\)</span> と <span class="math inline">\(E\subset[V]^2\)</span> の組 <span class="math inline">\(G:=(V,E)\)</span> のことをいう．<a href="#fn32" class="footnote-ref" id="fnref32" role="doc-noteref"><sup>32</sup></a></p>
<p><strong>Markov Network 構造</strong> とは，任意の無向グラフをいう．</p>
<p>２つの節 <span class="math inline">\(x,y\in V\)</span> が <strong>隣接する</strong> (adjacent / neighbours) とは，<span class="math inline">\(\{x,y\}\in E\)</span> が成り立つことをいう．</p>
<p>無向グラフ <span class="math inline">\(G\)</span> が <strong>完備</strong> (complete) であるとは，任意の <span class="math inline">\(x,y\in V\)</span> について <span class="math inline">\(\{x,y\}\in E\)</span> が成り立つことをいう．このとき，頂点集合 <span class="math inline">\(V\)</span> は <strong>クリーク</strong> (clique) であるという．位数 <span class="math inline">\(n\)</span> の完備グラフは <span class="math inline">\(K^n\)</span> で表される．<a href="#fn33" class="footnote-ref" id="fnref33" role="doc-noteref"><sup>33</sup></a></p>
<p><span class="math inline">\(K^r\subset G\)</span> を満たす最大の数 <span class="math display">\[
\omega(G):=\left\{r\in\mathbb{N}\mid K^r\subset G\right\}
\]</span> を <strong>クリーク数</strong> といい，グラフの不変量となる．<a href="#fn34" class="footnote-ref" id="fnref34" role="doc-noteref"><sup>34</sup></a></p>
<p><a href="https://ja.wikipedia.org/wiki/%E5%BC%A6%E3%82%B0%E3%83%A9%E3%83%95"><strong>弦グラフ</strong></a> (chordal / triangulated graph) とは，任意の長さ４以上のサイクルが弦を持つグラフを言う．<a href="#fn35" class="footnote-ref" id="fnref35" role="doc-noteref"><sup>35</sup></a> 弦グラフが，Bayesian Network と Markov Network の双方により表現可能であるグラフのクラスに一致する．</p>
</section>
<section id="markov-network-と-markov-random-field" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="markov-network-と-markov-random-field"><span class="header-section-number">3.2</span> Markov Network と Markov Random Field</h3>
<p>マルコフネットワークは，２次元のマルコフ確率場に等価である．<a href="#fn36" class="footnote-ref" id="fnref36" role="doc-noteref"><sup>36</sup></a></p>
<p>後者は <a href="../../../posts/2024/Computation/PGM2.html#sec-Ising-model">Ising モデル</a> の一般化である．<a href="#fn37" class="footnote-ref" id="fnref37" role="doc-noteref"><sup>37</sup></a></p>
</section>
<section id="はじめに-1" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="はじめに-1"><span class="header-section-number">3.3</span> はじめに</h3>
<p>Markov Network は相互作用に自然な双方向性がない場合でもモデリングを可能とする．</p>
<p>例えば，集合 <span class="math inline">\(\{A,B,C,D\}\)</span> 上の条件付き独立関係 <span class="math display">\[
\mathcal{I}:=\left\{\substack{A\perp\!\!\!\perp C|(B,D),\\B\perp\!\!\!\perp D|(A,C)}\right\}
\]</span> に関して，<span class="math inline">\(\mathcal{I}(\mathcal{G})=\mathcal{I}\)</span> を満たす Bayesian Network 構造 <span class="math inline">\(\mathcal{G}\)</span> は存在しない．</p>
<p>一方で，分岐結合と合流結合とを区別できないため，因果性のような方向を持った依存関係は表現できない．</p>
<p>Markov Network では，節の間に自然な順序構造がないため，分布の表示が難しくなり，より純粋にグラフの分解に頼ることになる．それゆえ，データからの構造学習も遥かに難しくなる．<a href="#fn38" class="footnote-ref" id="fnref38" role="doc-noteref"><sup>38</sup></a></p>
<p>Bayesian Network では条件付き確率密度のみで十分だったところを，これを一般化する概念である factor と呼ばれる概念によって達成する．</p>
<p>条件付き確率密度 <span class="math inline">\(p(x_1,\cdots,x_m|y_1,\cdots,y_k)\)</span> とは，形式的には，積空間 <span class="math inline">\(\prod_{i=1}^m\mathrm{Im}\,(X_i)\times\prod_{j=1}^k\mathrm{Im}\,(Y_j)\)</span> 上の（正規化された）関数である．一般に，確率変数の値域の積上の（正規化されているとは限らない）関数を <strong>ファクター</strong> と言う．</p>
</section>
<section id="ファクター" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="ファクター"><span class="header-section-number">3.4</span> ファクター</h3>
<p>確率変数の組 <span class="math inline">\(\boldsymbol{X}=(X_1,\cdots,X_n)\)</span> 上の <strong>ファクター</strong> とは，ある部分集合 <span class="math inline">\(\{n_1,\cdots,n_D\}\subset[n]\)</span> に対して，関数 <span class="math inline">\((X_{n_1},\cdots,X_{n_D})\)</span> の値域上に定義された関数 <span class="math display">\[
\phi:\prod_{i=1}^D\mathrm{Im}\,(X_{n_i})\to\mathbb{R}
\]</span> を言う．この定義域を <strong>スコープ</strong> と言う．<a href="#fn39" class="footnote-ref" id="fnref39" role="doc-noteref"><sup>39</sup></a></p>
<p>定義域 <span class="math inline">\(a,b\subset[n]\)</span> がかぶる２つのファクター <span class="math inline">\(\phi_1,\phi_2,a\cap b\ne\emptyset\)</span> が存在する場合，これらを接続して，<span class="math inline">\(\prod_{i\in a\cup b}\mathrm{Im}\,(X_i)\)</span> 上に定義された新たなファクターを作ることが出来る：<a href="#fn40" class="footnote-ref" id="fnref40" role="doc-noteref"><sup>40</sup></a> <span class="math display">\[
\phi_1\times\phi_2(X_{a\cup b}):=\phi_1(X_a)\phi_2(X_b).
\]</span></p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 p.108] 定義4.3．] （Gibbs distribution, factorization）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-21-contents" aria-controls="callout-21" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>定義<a href="#fn41" class="footnote-ref" id="fnref41" role="doc-noteref"><sup>41</sup></a> （Gibbs distribution, factorization）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-21" class="callout-21-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ol type="1">
<li>離散確率変数の組 <span class="math inline">\(\boldsymbol{X}=(X_1,\cdots,X_n)\)</span> とその上のファクター <span class="math display">\[
\Phi:=(\phi_1(\boldsymbol{D}_1),\cdots,\phi_m(\boldsymbol{D}_m))
\]</span> <span class="math display">\[
\boldsymbol{D}_j\subset\{X_i\}_{i=1}^n\quad(j\in[m])
\]</span> とが定める <span class="math inline">\(\prod_{i=1}^n\mathrm{Im}\,(X_i)\)</span> 上の <a href="https://en.wikipedia.org/wiki/Gibbs_measure"><strong>Gibbs 分布</strong></a> とは，密度 <span class="math display">\[
p_\Phi(\boldsymbol{x})=\frac{1}{Z}\prod_{j=1}^m\phi_j(\boldsymbol{D}_j)
\]</span> が定める分布をいう．ここで <span class="math inline">\(Z\)</span> は正規化定数であり，歴史的には <strong>分配関数</strong> と言う．<a href="#fn42" class="footnote-ref" id="fnref42" role="doc-noteref"><sup>42</sup></a></li>
<li>Gibbs 分布 <span class="math inline">\(p_\Phi\)</span> が Markov network <span class="math inline">\(\mathcal{H}=(\{X_i\}_{i=1}^n,\mathcal{E})\)</span> 上で <strong>分解する</strong> とは，任意の <span class="math inline">\(\mathcal{D}_j\subset\{X_i\}_{i=1}^n\;(j\in[m])\)</span> が <span class="math inline">\(\mathcal{H}\)</span> のクリークであることをいう．このとき，各ファクター <span class="math inline">\(\phi_1,\cdots,\phi_m\)</span> を <strong>clique potential</strong> という．</li>
</ol>
</div>
</div>
</div>
</section>
<section id="sec-separation-in-markov-network" class="level3" data-number="3.5">
<h3 data-number="3.5" class="anchored" data-anchor-id="sec-separation-in-markov-network"><span class="header-section-number">3.5</span> Markov Network の分離性</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 pp.114-115] 定義4.8, 9．] （Global Markov Independence）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-22-contents" aria-controls="callout-22" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>定義<a href="#fn43" class="footnote-ref" id="fnref43" role="doc-noteref"><sup>43</sup></a> （Global Markov Independence）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-22" class="callout-22-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(\mathcal{H}\)</span> を Markov network 構造とする．</p>
<ol type="1">
<li>道 <span class="math inline">\(X_1\rightleftharpoons\cdots\rightleftharpoons X_n\)</span> が <span class="math inline">\(\boldsymbol{Z}\subset\{X_i\}_{i=1}^n\)</span> が観測された下でも <strong>active</strong> であるとは，<span class="math inline">\(\{X_i\}_{i=1}^n\cap\boldsymbol{Z}=\emptyset\)</span> を満たすことをいう．</li>
<li>節集合 <span class="math inline">\(\boldsymbol{X},\boldsymbol{Y},\boldsymbol{Z}\)</span> について，<span class="math inline">\(\boldsymbol{Z}\)</span> が <span class="math inline">\(\boldsymbol{X},\boldsymbol{Y}\)</span> を <strong>分離</strong> するとは，任意の <span class="math inline">\(X\in\boldsymbol{X}\)</span> と <span class="math inline">\(Y\in\boldsymbol{Y}\)</span> と，<span class="math inline">\(X,Y\)</span> を結ぶ道が，<span class="math inline">\(\boldsymbol{Z}\)</span> の下で active でないことをいう．このことを <span class="math inline">\(\mathop{\mathrm{sep}}_\mathcal{H}(\boldsymbol{X};\boldsymbol{Y}|\boldsymbol{Z})\)</span> と表す．</li>
</ol>
<ul>
<li><span class="math inline">\(\mathcal{H}\)</span> 内の分離的な組 <span class="math inline">\((\boldsymbol{X},\boldsymbol{Y},\boldsymbol{Z})\)</span> が表す条件付き独立性の条件式の全体を <span class="math display">\[
\mathcal{I}(\mathcal{H}):=\left\{(\boldsymbol{X}\perp\!\!\!\perp\boldsymbol{Y}|\boldsymbol{Z})\mid\mathop{\mathrm{sep}}_\mathcal{H}(\boldsymbol{X};\boldsymbol{Y}|\boldsymbol{Z})\right\}
\]</span> で表す．この元を <strong>大域的独立性</strong> ともいう．</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定理^[[@Koller-Friedman2009 pp.116-117] 定理4.1，定理4.2．] [@Hammersley-Clifford1971]">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-23-contents" aria-controls="callout-23" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>定理<a href="#fn44" class="footnote-ref" id="fnref44" role="doc-noteref"><sup>44</sup></a> <span class="citation" data-cites="Hammersley-Clifford1971">(<a href="#ref-Hammersley-Clifford1971" role="doc-biblioref">Hammersley and Clifford, 1971</a>)</span>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-23" class="callout-23-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> をノードの集合 <span class="math inline">\(\mathcal{X}=\{X_1,\cdots,X_n\}\)</span> 上の確率分布，<span class="math inline">\(\mathcal{H}\)</span> を <span class="math inline">\(\mathcal{X}\)</span> 上の Markov network 構造とする．このとき 1. <span class="math inline">\(\Rightarrow\)</span> 2. が成り立ち，<span class="math inline">\(P\)</span> が <span class="math inline">\(\mathcal{X}\)</span> 全域を台に持つとき次は同値：</p>
<ol type="1">
<li><span class="math inline">\(\mathcal{H}\)</span> は <span class="math inline">\(P\)</span> の <span class="math inline">\(I\)</span>-map である：<span class="math inline">\(\mathcal{I}(\mathcal{H})\subset\mathcal{I}(P)\)</span>．</li>
<li><span class="math inline">\(P\)</span> は <span class="math inline">\(\mathcal{H}\)</span> に従って分解する Gibbs 分布である．</li>
</ol>
</div>
</div>
</div>
<p><span class="citation" data-cites="Besag1974">(<a href="#ref-Besag1974" role="doc-biblioref">Besag, 1974</a>)</span> はこの定理に別証明を付し，植物生態学における空間統計モデルに応用している．<a href="#fn45" class="footnote-ref" id="fnref45" role="doc-noteref"><sup>45</sup></a></p>
<p>Markov 確率場の結合分布を，条件付き分布の系から得ることは困難であるが，結局結合分布も Gibbs 分布になることが <span class="citation" data-cites="Hammersley-Clifford1971">(<a href="#ref-Hammersley-Clifford1971" role="doc-biblioref">Hammersley and Clifford, 1971</a>)</span> の定理からわかるので，Gibbs 分布を通じて計算することができる．</p>
<p>この「条件付き分布から結合分布が復元できる」という知見が Gibbs sampling の基礎となった．<a href="#fn46" class="footnote-ref" id="fnref46" role="doc-noteref"><sup>46</sup></a> また統計的画像解析の基礎ともなった <span class="citation" data-cites="Grenander1983">(<a href="#ref-Grenander1983" role="doc-biblioref">Grenander, 1983</a>)</span>．</p>
<p>また <span class="citation" data-cites="Geman-Geman1984">(<a href="#ref-Geman-Geman1984" role="doc-biblioref">Geman and Geman, 1984</a>)</span> は，Markov 確率場でモデリングをし，その最大事後確率 MAP (Maximum a Posteriori) を目的関数として最適化を行う，という MAP-MRF アプローチを創始した <span class="citation" data-cites="Li2009">(<a href="#ref-Li2009" role="doc-biblioref">Stan Z. Li, 2009, p. 2</a>)</span>．</p>
<p>さらに統計計算法の進展により，画像の低レイヤーな特徴を表現する（画像修復，物体発見など）だけでなく，高レイヤーな特徴（物体認識やマッチングなど）をも扱えることがわかっている <span class="citation" data-cites="Gidas1989">(<a href="#ref-Gidas1989" role="doc-biblioref">Gidas, 1989</a>)</span>, <span class="citation" data-cites="Li1991">(<a href="#ref-Li1991" role="doc-biblioref">S. Ziqing Li, 1991</a>)</span>．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題^[[@Koller-Friedman2009 p.117] 定理4.3．] （分離性の特徴付け）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-24-contents" aria-controls="callout-24" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>命題<a href="#fn47" class="footnote-ref" id="fnref47" role="doc-noteref"><sup>47</sup></a> （分離性の特徴付け）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-24" class="callout-24-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(\mathcal{H}\)</span> を Markov network 構造，<span class="math inline">\(\{X\}\sqcup\{Y\}\sqcup\boldsymbol{Z}\subset\mathcal{X}\)</span> を節の集合とする．このとき，次が成り立つ：</p>
<ol type="1">
<li><span class="math inline">\(\mathcal{H}\)</span> 内で <span class="math inline">\(X,Y\)</span> は <span class="math inline">\(\boldsymbol{Z}\)</span> によって分離されないならば，ある <span class="math inline">\(\mathcal{H}\)</span> に沿って分解する分布 <span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> について，<span class="math inline">\(X\perp\!\!\!\perp Y|\boldsymbol{Z}\)</span> が成り立つ．</li>
<li><span class="math inline">\(\mathcal{H}\)</span> に沿って分解する殆ど全ての <span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> に関して，<span class="math inline">\(\mathcal{I}(\mathcal{H})=\mathcal{I}(P)\)</span> が成り立つ．</li>
</ol>
</div>
</div>
</div>
<p>Beysian Network （ <a href="#sec-characterization-of-d-separation" class="quarto-xref">Section&nbsp;2.8</a> ）の場合と違い，1. の主張が，<span class="math inline">\(\mathcal{H}\)</span> に沿って分解する全ての分布 <span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> に関して成り立つとは限らない．</p>
<p>しかし，殆ど全ての <span class="math inline">\(\mathcal{H}\)</span> に沿って分解する分布 <span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> に関して成り立つ条件付き独立性は，グラフの構造から読み取れる．</p>
</section>
<section id="局所依存性" class="level3" data-number="3.6">
<h3 data-number="3.6" class="anchored" data-anchor-id="局所依存性"><span class="header-section-number">3.6</span> 局所依存性</h3>
<p>Bayesian Network の <span class="math inline">\(d\)</span>-分離性に対応する分離性の概念を導入し，大域的独立性の概念を定義した．</p>
<p>しかし，Bayesian Network の場合では有向グラフとしての構造からすぐに読み取れた局所依存性の概念は，Markov Network の場合では，グラフの構造からは読み取れない．</p>
<p>そして２通りの定義が考え得る．局所依存性は，大域的依存性のサブセットであることに注意．そして，台を全体 <span class="math inline">\(\mathcal{X}\)</span> に持つ分布については，大域的依存性も含めて３つの定義は全て同値である．<a href="#fn48" class="footnote-ref" id="fnref48" role="doc-noteref"><sup>48</sup></a></p>
</section>
</section>
<section id="sec-Factor-Graph" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="sec-Factor-Graph"><span class="header-section-number">4</span> Factor Graph</h2>
<p>Markov network は Gibbs 分布の依存性を十分に表現できているわけではなかった（第 <a href="#sec-separation-in-markov-network" class="quarto-xref">3.5</a> 節）．これは特に，クリーク間の大小関係を把握できていないことに因る．</p>
<section id="定義" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="定義"><span class="header-section-number">4.1</span> 定義</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 p.123] 4.4.1.1，[@Mezard-Montanari2009 p.175] 9.1.1 節．] （Factor Graph）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-25-contents" aria-controls="callout-25" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>定義<a href="#fn49" class="footnote-ref" id="fnref49" role="doc-noteref"><sup>49</sup></a> （Factor Graph）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-25" class="callout-25-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Markov newtork から，ファクターを表す節を（四角形で囲うなどして区別した形で）追加し，ファクターをそのスコープに入る変数と隣接するようにし，一方で変数を表す（元々の）節とファクターを表す節とが隣接しないように修正した <a href="https://ja.wikipedia.org/wiki/2%E9%83%A8%E3%82%B0%E3%83%A9%E3%83%95">２部グラフ</a> <span class="math inline">\(\mathcal{F}\)</span> を <a href="https://en.wikipedia.org/wiki/Factor_graph"><strong>因子グラフ</strong></a> という．</p>
<p>分布 <span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> が <span class="math inline">\(\mathcal{F}\)</span> に関して <strong>分解する</strong> とは，<span class="math inline">\(\mathcal{F}\)</span> が定める確率変数の組とその上のファクターが定める Gibbs 分布であることをいう．</p>
</div>
</div>
</div>
</section>
</section>



<div id="quarto-appendix" class="default"><section id="終わりに" class="level2 appendix" data-number="5"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">5</span> 終わりに</h2><div class="quarto-appendix-contents">

<p>MCMC，特に Gibbs サンプラーは，Markov network の形で与えられる局所的な情報を利用したダイナミクスを持つ．</p>
<p>それ故，デザインから，大域的な探索が不得手であると言える．</p>



</div></section><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-Balgi+2024" class="csl-entry" role="listitem">
Balgi, S., Daoud, A., Peña, J. M., Wodtke, G. T., and Zhou, J. (2024). <em><a href="https://arxiv.org/abs/2401.06864">Deep learning with DAGs</a></em>.
</div>
<div id="ref-Bartlett1935" class="csl-entry" role="listitem">
Bartlett, M. S. (1935). <a href="https://www.jstor.org/stable/2983639">Contingency table interactions</a>. <em>Supplement to the Journal of the Royal Statistical Society</em>, <em>2</em>(2), 246–252.
</div>
<div id="ref-Besag1974" class="csl-entry" role="listitem">
Besag, J. (1974). <a href="https://www.jstor.org/stable/2984812">Spatial interaction and the statistical analysis of lattice systems</a>. <em>Journal of the Royal Statistical Society. Series B (Methodological)</em>, <em>36</em>(2), 192–236.
</div>
<div id="ref-Besag-Green1993" class="csl-entry" role="listitem">
Besag, J., and Green, P. J. (1993). <a href="https://doi.org/10.1111/j.2517-6161.1993.tb01467.x">Spatial statistics and bayesian computation</a>. <em>Journal of the Royal Statistical Society: Series B (Methodological)</em>, <em>55</em>(1), 25–37.
</div>
<div id="ref-Bishop2006" class="csl-entry" role="listitem">
Bishop, C. M. (2006). <em><a href="https://link.springer.com/book/9780387310732">Pattern recognition and machine learning</a></em>. Springer New York.
</div>
<div id="ref-Blalock1971" class="csl-entry" role="listitem">
Blalock&nbsp;Jr., H. (1971). <em><a href="">Causal models in the social sciences</a></em>. Chicago, Illinois: Aldine-Atheson.
</div>
<div id="ref-Clark2018" class="csl-entry" role="listitem">
Clark, M. (2018). <em><a href="https://m-clark.github.io/sem/">Graphical &amp; latent variable modeling</a></em>.
</div>
<div id="ref-Dombal+1972" class="csl-entry" role="listitem">
de&nbsp;Dombal, F. T., Leaper, D. J., Staniland, J. R., McCann, A. P., and Horrocks, J. C. (1972). <a href="https://www.jstor.org/stable/25418224">Computer-aided diagnosis of acute abdominal pain</a>. <em>The Britich Medical Journal</em>, <em>2</em>(5804), 9–13.
</div>
<div id="ref-Diestel2017" class="csl-entry" role="listitem">
Diestel, R. (2017). <em><a href="https://link.springer.com/book/10.1007/978-3-662-53622-3">Graph theory</a></em>,Vol. 173. Springer Berlin Heidelberg.
</div>
<div id="ref-Gelfand-Smith1990" class="csl-entry" role="listitem">
Gelfand, A. E., and Smith, A. F. M. (1990). <a href="https://doi.org/10.2307/2289776">Sampling-based approaches to calculating marginal densities</a>. <em>Journal of the American Statistical Association</em>, <em>85</em>(410), 398–409.
</div>
<div id="ref-Geman-Geman1984" class="csl-entry" role="listitem">
Geman, S., and Geman, D. (1984). <a href="https://doi.org/10.1109/TPAMI.1984.4767596"><span class="nocase">Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images</span></a>. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, <em>PAMI-6</em>(6), 721–741.
</div>
<div id="ref-Gibbs1902" class="csl-entry" role="listitem">
Gibbs, J. W. (1902). <em><a href="">Elementary principles in statistical mechanics: Developed with especial reference to the rational foundation of thermodynamics</a></em>. Charles Scribner’s Sons.
</div>
<div id="ref-Gidas1989" class="csl-entry" role="listitem">
Gidas, B. (1989). <a href="https://ieeexplore.ieee.org/document/16712">A renormalization group approach to image processing problems</a>. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, <em>11</em>(2), 164–180.
</div>
<div id="ref-Grenander1983" class="csl-entry" role="listitem">
Grenander, U. (1983). <em><a href="">Tutorial in pattern theory</a></em>. Brown University.
</div>
<div id="ref-Hammersley-Clifford1971" class="csl-entry" role="listitem">
Hammersley, J., and Clifford, P. (1971). <em><a href="https://ora.ox.ac.uk/objects/uuid:4ea849da-1511-4578-bb88-6a8d02f457a6">Markov fields on finite graphs and lattices</a></em>.
</div>
<div id="ref-Heckerman+1992" class="csl-entry" role="listitem">
Heckerman, D. E., Horvitz, E. J., and Nathwani, B. N. (1992). <a href="https://www.thieme-connect.com/products/ejournals/abstract/10.1055/s-0038-1634867">Toward normative expert systems: Part i. The pathfinder project</a>. <em>Methods of Information in Medicine</em>, <em>31</em>(2), 90–105.
</div>
<div id="ref-Heckerman-Nathwani1992" class="csl-entry" role="listitem">
Heckerman, D. E., and Nathwani, B. N. (1992). <a href="">Toward normative expert systems. II. Probability-based representations for eﬃcient knowledge acquisition and inference</a>. <em>Methods of Information in Medicine</em>, <em>31</em>(2), 106–116.
</div>
<div id="ref-Howard-Matheson1981" class="csl-entry" role="listitem">
Howard, R. A., and Matheson, J. E. (1981). Readings on the principles and applications of decision analysis. In R. A. Howard and J. E. Matheson, editors,. Strategic Decision Group.
</div>
<div id="ref-Howard-Matheson1984" class="csl-entry" role="listitem">
Howard, Ronald A., and Matheson, J. E. (1984). In, pages 721–762. SDG Decision Systems.
</div>
<div id="ref-Jordan+1999" class="csl-entry" role="listitem">
Jordan, M. I., Ghahramani, Z., Jaakkola, T. S., and Saul, L. K. (1999). <a href="https://link.springer.com/article/10.1023/A:1007665907178">An introduction to variational methods for graphical models</a>. <em>Machine Learning</em>, <em>37</em>, 183–233.
</div>
<div id="ref-Joreskog70" class="csl-entry" role="listitem">
Jöreskog, Karl Gustav. (1970). <a href="https://www.jstor.org/stable/2334833">A general method for analysis of covariance structures</a>. <em>Biometrika</em>, <em>57</em>(2), 239–251.
</div>
<div id="ref-Joreskog-Wold1981" class="csl-entry" role="listitem">
Jöreskog, K. G., and Wold, H. (1982). <em><a href="">Systems under indirect observation: Causality, structure, prediction</a></em>. Elsevier, Amsterdam.
</div>
<div id="ref-Kindermann-Snell1980" class="csl-entry" role="listitem">
Kindermann, R., and Snell, J. L. (1980). <em><a href="https://www.ams.org/books/conm/001/">Markov random fields and their applications</a></em>. American Mathematical Society.
</div>
<div id="ref-Koller-Friedman2009" class="csl-entry" role="listitem">
Koller, D., and Friedman, N. (2009). <em><a href="https://mitpress.mit.edu/9780262013192/probabilistic-graphical-models/">Probabilistic graphical models</a></em>. MIT Press.
</div>
<div id="ref-Lauritzen-Spiegelhalter1988" class="csl-entry" role="listitem">
Lauritzen, S. L., and Spiegelhalter, D. J. (1988). <a href="https://www.jstor.org/stable/2345762">Local computations with probabilites on graphical structures and their application to expert systems</a>. <em>Journal of the Royal Statistical Society. Series B (Methodological)</em>, <em>50</em>(2), 157–224.
</div>
<div id="ref-Li1991" class="csl-entry" role="listitem">
Li, S. Ziqing. (1991). <em>Towards 3D vision from range images: An optimisation framework and parallel distributed networks</em> (PhD thesis). University of Surrey, Guildford Surrey, UK. Retrieved from <a href="https://www.sciencedirect.com/science/article/pii/104996609290023V">https://www.sciencedirect.com/science/article/pii/104996609290023V</a>
</div>
<div id="ref-Li2009" class="csl-entry" role="listitem">
Li, Stan Z. (2009). <em><a href="https://link.springer.com/book/10.1007/978-1-84800-279-1">Markov random field modeling in image analysis</a></em>. Springer London.
</div>
<div id="ref-Mezard-Montanari2009" class="csl-entry" role="listitem">
Mézard, M., and Montanari, A. (2009). <em><a href="https://doi.org/10.1093/acprof:oso/9780198570837.001.0001">Information, physics, and computation</a></em>. Oxford University Press.
</div>
<div id="ref-Murphy2023" class="csl-entry" role="listitem">
Murphy, K. P. (2023). <em><a href="http://probml.github.io/book2">Probabilistic machine learning: Advanced topics</a></em>. MIT Press.
</div>
<div id="ref-Pearl88-IntelligentSystem" class="csl-entry" role="listitem">
Pearl, J. (1988). <em>Probabilistic reasoning in intelligent systems</em>. Morgan Kaufmann.
</div>
<div id="ref-Pearl09-Causality" class="csl-entry" role="listitem">
Pearl, J. (2009). <em>Causality: Models, reasoning and inference</em>. 和訳は黒木学による『統計的因果推論―モデル・推論・推測』（共立出版，2009）; Cambridge University Press.
</div>
<div id="ref-Pearl16-Primer" class="csl-entry" role="listitem">
Pearl, J., Glymour, M., and Jewell, N. P. (2016). <em>Causal inference in statistics: A primer</em>. 和訳は落海浩による『入門 統計的因果推論』（朝倉書店，2019）; Wiley.
</div>
<div id="ref-Robert2007" class="csl-entry" role="listitem">
Robert, C. P. (2007). <em><a href="https://link.springer.com/book/10.1007/0-387-71599-1">The bayesian choice: From decision-theoretic foundations to computational implementation</a></em>. Springer New York.
</div>
<div id="ref-Robert-Casella2011" class="csl-entry" role="listitem">
Robert, C., and Casella, G. (2011). <a href="http://www.jstor.org/stable/23059158">A short history of markov chain monte carlo: Subjective recollections from incomplete data</a>. <em>Statistical Science</em>, <em>26</em>(1), 102–115.
</div>
<div id="ref-Rumelhart+1987" class="csl-entry" role="listitem">
Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1987). <a href="https://mitpress.mit.edu/9780262680530/parallel-distributed-processing/">Parallel distributed processing: Explorations in the microstructure of cognition: foundations</a>. In D. E. Rumelhart and J. L. McClelland, editors, pages 318–362. MIT Press.
</div>
<div id="ref-Scholkopf2022" class="csl-entry" role="listitem">
Schölkopf, B. (2022). <a href="https://doi.org/10.1145/3501714.3501755">Causality for machine learning</a>. In <em>Probabilistic and causal inference</em>, pages 765–804. ACM.
</div>
<div id="ref-Sucar2021" class="csl-entry" role="listitem">
Sucar, L. E. (2021). <em><a href="https://link.springer.com/book/10.1007/978-1-4471-6699-3">Probabilistic graphical models: Principles and applications</a></em>. Springer London.
</div>
<div id="ref-Taroni+2014" class="csl-entry" role="listitem">
Taroni, F., Biedermann, A., Bozza, S., Garbolino, P., and Aitken, C. (2014). <em>Bayesian networks for probabilistic inference and decision analysis in forensic science</em>. John Wiley &amp; Sons.
</div>
<div id="ref-Theodoridis2020" class="csl-entry" role="listitem">
Theodoridis, S. (2020). <em><a href="https://doi.org/10.1016/C2019-0-03772-7">Machine learning: A bayesian and optimization perspective</a></em>. Academic Press.
</div>
<div id="ref-Wainwright-Jordan2008" class="csl-entry" role="listitem">
Wainwright, M. J., and Jordan, M. I. (2008). <a href="https://www.nowpublishers.com/article/Details/MAL-001">Graphical models, exponential families, and variational inference</a>. <em>Foundations and Trends in Machine Learning</em>, <em>1</em>(1-2), 1–305.
</div>
<div id="ref-Wold1954" class="csl-entry" role="listitem">
Wold, Herman. (1954). <a href="https://www.jstor.org/stable/1907540">Causality and econometrics</a>. <em>Econometrica</em>, <em>22</em>, 162–177.
</div>
<div id="ref-Wold-Strotz60" class="csl-entry" role="listitem">
Wold, H., and Strotz, R. H. (1960). <a href="https://www.jstor.org/stable/1907731">Recursive vs. Nonrecursive systems: An attempt at synthesis (part i of a triptych on causal chain systems)</a>. <em>Econometrica</em>, <em>28</em>(2), 417–427.
</div>
<div id="ref-Wright1918" class="csl-entry" role="listitem">
Wright, S. (1918). <a href="https://academic.oup.com/genetics/article/3/4/367/5934526">On the nature of size factors</a>. <em>Genetics</em>, <em>3</em>(4), 367.
</div>
<div id="ref-Zadeh1989" class="csl-entry" role="listitem">
Zadeh, L. A. (1989). <a href="https://ieeexplore.ieee.org/document/43406">Knowledge representation in fuzzy logic</a>. <em>IEEE Transactions on Knowledge and Data Engineering</em>, <em>1</em>(1), 89–100.
</div>
<div id="ref-須山敦志2019" class="csl-entry" role="listitem">
須山敦志. (2019). <em><a href="https://www.kspub.co.jp/book/detail/5168707.html">ベイズ深層学習</a></em>. 講談社サイエンティフィク.
</div>
<div id="ref-黒木学-小林史明2012" class="csl-entry" role="listitem">
黒木学, and 小林史明. (2012). <a href="https://www.jstage.jst.go.jp/article/jjb/32/2/32_119/_article/-char/ja/">構造的因果モデルについて</a>. <em>計量生物学</em>, <em>32</em>(2), 119–144.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><span class="citation" data-cites="Taroni+2014">(<a href="#ref-Taroni+2014" role="doc-biblioref">Taroni et al., 2014, p. 35</a>)</span>，<span class="citation" data-cites="Sucar2021">(<a href="#ref-Sucar2021" role="doc-biblioref">Sucar, 2021, p. x</a>)</span>, <span class="citation" data-cites="Clark2018">(<a href="#ref-Clark2018" role="doc-biblioref">Clark, 2018</a>)</span> <a href="https://m-clark.github.io/sem/graphical-models.html">Graphical Models</a>．<span class="citation" data-cites="Jordan+1999">(<a href="#ref-Jordan+1999" role="doc-biblioref">Jordan et al., 1999, p. 191</a>)</span> は 3.2節で Neural Networks as Graphical Models を扱っている．<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>この文脈では，ベイジアンネットワークのことは DAG とも，汎函数因果モデル <span class="citation" data-cites="Scholkopf2022">(<a href="#ref-Scholkopf2022" role="doc-biblioref">Schölkopf, 2022</a>)</span> とも呼ぶ．<span class="citation" data-cites="Murphy2023">(<a href="#ref-Murphy2023" role="doc-biblioref">Murphy, 2023, p. 211</a>)</span> 4.7節．例えば，医療診断では，複数の症状や検査結果，医学的指標との関連・相関・因果に関する知識を Bayesian Network （<a href="#sec-BN" class="quarto-xref">Section&nbsp;2</a>） で表現する．<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><span class="citation" data-cites="Mezard-Montanari2009">(<a href="#ref-Mezard-Montanari2009" role="doc-biblioref">Mézard and Montanari, 2009, p. 177</a>)</span> 9.1.2 節に，ファクターグラフの例が挙げられている．<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 3</a>)</span> 1.2.1，<span class="citation" data-cites="Murphy2023">(<a href="#ref-Murphy2023" role="doc-biblioref">Murphy, 2023, p. 143</a>)</span> 第4章．<span class="citation" data-cites="Balgi+2024">(<a href="#ref-Balgi+2024" role="doc-biblioref">Balgi et al., 2024</a>)</span> “As non-parametric causal models, DAGs require no assumptions about the functional form of the hypothesized relationships.”<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, pp. 12–14</a>)</span> 1.4節 など．<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>一般に，SEM は <span class="citation" data-cites="Joreskog70">(<a href="#ref-Joreskog70" role="doc-biblioref">Karl Gustav Jöreskog, 1970</a>)</span> が発祥と見られており，潜在変数モデルにもパス解析を拡張したもの，と説明される <span class="citation" data-cites="Clark2018">(<a href="#ref-Clark2018" role="doc-biblioref">Clark, 2018</a>)</span>．<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p><span class="citation" data-cites="黒木学-小林史明2012">(<a href="#ref-黒木学-小林史明2012" role="doc-biblioref">黒木学 and 小林史明, 2012</a>)</span> など．<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, pp. 12–14</a>)</span> 1.4節．<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 1</a>)</span> 1.1 Motivation．これはこの分野が不確実性を定量的に扱う必要があり，それ故確率的モデリングを必要としたためである．一般に，特定のタスクに特化しながら，汎用性も持つエキスパートシステムを構築するためには，<a href="https://ja.wikipedia.org/wiki/%E5%AE%A3%E8%A8%80%E5%9E%8B%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0">宣言型の知識表現</a> が良い接近として用いられる <span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 1</a>)</span> 1.1 Motivation．declarative representation の他に model-based approach ともいう．これは対象となるシステムの構造に関する知識を，計算機が理解可能な形で表現するモデルベースな接近であり，「知識」と「推論」という異なるタスクを分離する点に妙がある．<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 2</a>)</span> 1.1 Motivation．Probabilistic models allow us to make this fact (= many systems cannot be specified deterministically.) explicit, and therefore often provide a model which is more faithful to reality.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p><span class="citation" data-cites="Theodoridis2020">(<a href="#ref-Theodoridis2020" role="doc-biblioref">Theodoridis, 2020, p. 772</a>)</span> なども参照．用いるアルゴリズムの計算複雑性も，グラフ理論の言葉で記述できることが多い <span class="citation" data-cites="Wainwright-Jordan2008">(<a href="#ref-Wainwright-Jordan2008" role="doc-biblioref">Wainwright and Jordan, 2008, p. 4</a>)</span>．<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>その最重要文献として，<span class="citation" data-cites="Grenander1983">(<a href="#ref-Grenander1983" role="doc-biblioref">Grenander, 1983</a>)</span>，特に画像分析への Bayesian アプローチを取り扱った 4-6 章を挙げている．Gibbs サンプラーの語を導入したのは <span class="citation" data-cites="Geman-Geman1984">(<a href="#ref-Geman-Geman1984" role="doc-biblioref">Geman and Geman, 1984</a>)</span> であるが，すでに <span class="citation" data-cites="Grenander1983">(<a href="#ref-Grenander1983" role="doc-biblioref">Grenander, 1983</a>)</span> において極めて重要な Bayes 計算手法として扱われていた．<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p><span class="citation" data-cites="Bishop2006">(<a href="#ref-Bishop2006" role="doc-biblioref">Bishop, 2006, p. 46</a>)</span> などでも紹介されている．<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 57</a>)</span>，<span class="citation" data-cites="Mezard-Montanari2009">(<a href="#ref-Mezard-Montanari2009" role="doc-biblioref">Mézard and Montanari, 2009, p. 269</a>)</span>．<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p><span class="citation" data-cites="須山敦志2019">(<a href="#ref-須山敦志2019" role="doc-biblioref">須山敦志, 2019, p. 4</a>)</span>, <span class="citation" data-cites="Li2009">(<a href="#ref-Li2009" role="doc-biblioref">Stan Z. Li, 2009, p. 48</a>)</span>．<a href="https://en.wikipedia.org/wiki/Bayesian_network">Wikipedia</a> も参照．<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 57</a>)</span><a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 60</a>)</span><a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 60</a>)</span><a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn19"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 62</a>)</span><a href="#fnref19" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 62</a>)</span> 定理3.1，定理3.2 p.63．<span class="citation" data-cites="Howard-Matheson1984">(<a href="#ref-Howard-Matheson1984" role="doc-biblioref">Ronald A. Howard and Matheson, 1984</a>)</span> による．<a href="#fnref20" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn21"><p>これを trail が active である，ともいう．<span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 71</a>)</span>．<a href="#fnref21" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn22"><p>この語は directed separation の略であり <span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 71</a>)</span>，和語では <strong>有向分離</strong> ともいう．<a href="#fnref22" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn23"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 71</a>)</span><a href="#fnref23" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn24"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, pp. 71–72</a>)</span> 定義3.6, 3.7．<a href="#fnref24" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn25"><p><span class="math inline">\(I(\boldsymbol{X},\boldsymbol{Y}|\boldsymbol{Z})_\mathcal{G}\)</span> と表すこともある．<a href="#fnref25" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn26"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, pp. 72–73</a>)</span> 定理3.3, 3.5．<a href="#fnref26" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn27"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 78</a>)</span> 3.4節 の内容．<a href="#fnref27" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn28"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 76</a>)</span> 定義3.9．<a href="#fnref28" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn29"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 77</a>)</span> 定理3.7．<a href="#fnref29" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn30"><p>有向グラフの <strong>スケルトン</strong> とは，同じ辺を持つ無向グラフのことである．<a href="#fnref30" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn31"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 77</a>)</span> 定理3.8．<a href="#fnref31" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn32"><p><span class="citation" data-cites="Diestel2017">(<a href="#ref-Diestel2017" role="doc-biblioref">Diestel, 2017, pp. 1–2</a>)</span> 参照．<a href="#fnref32" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn33"><p><span class="citation" data-cites="Diestel2017">(<a href="#ref-Diestel2017" role="doc-biblioref">Diestel, 2017, p. 3</a>)</span> 参照．<a href="#fnref33" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn34"><p><span class="citation" data-cites="Diestel2017">(<a href="#ref-Diestel2017" role="doc-biblioref">Diestel, 2017, p. 135</a>)</span> 参照．<a href="#fnref34" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn35"><p>すなわち，三角形以外の <a href="https://ja.wikipedia.org/wiki/%E8%AA%98%E5%B0%8E%E9%83%A8%E5%88%86%E3%82%B0%E3%83%A9%E3%83%95">誘導部分グラフ</a> を部分グラフに持たないグラフをいう．<span class="citation" data-cites="Diestel2017">(<a href="#ref-Diestel2017" role="doc-biblioref">Diestel, 2017, p. 135</a>)</span> 参照．<a href="#fnref35" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn36"><p><span class="citation" data-cites="Sucar2021">(<a href="#ref-Sucar2021" role="doc-biblioref">Sucar, 2021, p. 94</a>)</span> も参照．<span class="citation" data-cites="Li2009">(<a href="#ref-Li2009" role="doc-biblioref">Stan Z. Li, 2009, p. 47</a>)</span> は，pairwise なマルコフ確率場もマルコフネットワークと見れることを指摘している．pairwise とは非零なポテンシャルを持つクリークが二点集合になるマルコフ確率場をいう．<a href="#fnref36" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn37"><p><span class="citation" data-cites="Kindermann-Snell1980">(<a href="#ref-Kindermann-Snell1980" role="doc-biblioref">Kindermann and Snell, 1980, p. 1</a>)</span><a href="#fnref37" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn38"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 106</a>)</span> 4.2節．<a href="#fnref38" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn39"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 104</a>)</span> 定義4.1．<a href="#fnref39" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn40"><p>ただし，<span class="math inline">\(\phi_1(X_a)\)</span> とは <span class="math inline">\(\phi_1((X_i)_{i\in a})\)</span> の略とした．<a href="#fnref40" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn41"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 108</a>)</span> 定義4.3．<a href="#fnref41" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn42"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 105</a>)</span> によると，当初統計物理学の分野の Markov 確率場の概念でこの用語が用いられたことが始まりとなっている．<a href="#fnref42" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn43"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, pp. 114–115</a>)</span> 定義4.8, 9．<a href="#fnref43" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn44"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, pp. 116–117</a>)</span> 定理4.1，定理4.2．<a href="#fnref44" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn45"><p><span class="citation" data-cites="Li2009">(<a href="#ref-Li2009" role="doc-biblioref">Stan Z. Li, 2009</a>)</span> の Rama Chellappa による foreword に “A big impetus to theoretical and practical considerations of 2D spatial interaction models, of which MRF’s form a subclass, was given by the seminal works of Julian Besag.” とある．“Labeling is also a natural representation for the study of MRF’s (Besag 1974).” は <span class="citation" data-cites="Li2009">(<a href="#ref-Li2009" role="doc-biblioref">Stan Z. Li, 2009, p. 3</a>)</span>．<a href="#fnref45" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn46"><p><span class="citation" data-cites="Robert-Casella2011">(<a href="#ref-Robert-Casella2011" role="doc-biblioref">C. Robert and Casella, 2011</a>)</span> <span class="citation" data-cites="Li2009">(<a href="#ref-Li2009" role="doc-biblioref">Stan Z. Li, 2009, p. 1</a>)</span> も参照．<a href="#fnref46" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn47"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 117</a>)</span> 定理4.3．<a href="#fnref47" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn48"><p>これは台が縮退している場合は，自明な（決定論的な）独立性が生じてしまうためである．<a href="#fnref48" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn49"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller and Friedman, 2009, p. 123</a>)</span> 4.4.1.1，<span class="citation" data-cites="Mezard-Montanari2009">(<a href="#ref-Mezard-Montanari2009" role="doc-biblioref">Mézard and Montanari, 2009, p. 175</a>)</span> 9.1.1 節．<a href="#fnref49" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/162348\.github\.io\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
        for (let i=0; i<annoteTargets.length; i++) {
          const annoteTarget = annoteTargets[i];
          const targetCell = annoteTarget.getAttribute("data-target-cell");
          const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
          const contentFn = () => {
            const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
            if (content) {
              const tipContent = content.cloneNode(true);
              tipContent.classList.add("code-annotation-tip-content");
              return tipContent.outerHTML;
            }
          }
          const config = {
            allowHTML: true,
            content: contentFn,
            onShow: (instance) => {
              selectCodeLines(instance.reference);
              instance.reference.classList.add('code-annotation-active');
              window.tippy.hideAll();
            },
            onHide: (instance) => {
              unselectCodeLines();
              instance.reference.classList.remove('code-annotation-active');
            },
            maxWidth: 300,
            delay: [50, 0],
            duration: [200, 0],
            offset: [5, 10],
            arrow: true,
            trigger: 'click',
            appendTo: function(el) {
              return el.parentElement.parentElement.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'quarto',
            placement: 'right',
            positionFixed: true,
            popperOptions: {
              modifiers: [
              {
                name: 'flip',
                options: {
                  flipVariations: false, // true by default
                  allowedAutoPlacements: ['right'],
                  fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
                },
              },
              {
                name: 'preventOverflow',
                options: {
                  mainAxis: false,
                  altAxis: false
                }
              }
              ]        
            }      
          };
          window.tippy(annoteTarget, config); 
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "162348/162348.github.io";
    script.dataset.repoId = "R_kgDOKlfKYQ";
    script.dataset.category = "Announcements";
    script.dataset.categoryId = "DIC_kwDOKlfKYc4CgDmb";
    script.dataset.mapping = "pathname";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://162348.github.io/">
<p>Hirofumi Shiba</p>
</a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/162348/162348.github.io/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/ano2math5">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:shiba.hirofumi@ism.ac.jp">
      <i class="bi bi-envelope" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="../../../blog.xml">
      <i class="bi bi-rss" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>