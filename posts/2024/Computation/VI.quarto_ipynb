{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"変分推論１\"\n",
        "subtitle: \"K-平均アルゴリズム\"\n",
        "author: \"司馬博文\"\n",
        "date: 2/3/2024\n",
        "date-modified: 8/12/2024\n",
        "categories: [Computation, Python]\n",
        "bibliography: \n",
        "    - ../../../assets/2023.bib\n",
        "    - ../../../assets/2024.bib\n",
        "    - ../../../assets/2025.bib\n",
        "csl: ../../../assets/apalike.csl\n",
        "abstract-title: 概要\n",
        "abstract: |\n",
        "    本稿では，[$K$-平均アルゴリズム](https://ja.wikipedia.org/wiki/K%E5%B9%B3%E5%9D%87%E6%B3%95) によるクラスタリングの考え方と問題点を，Python による実演を通じてみる．[次稿](VI2.qmd) で，$K$-平均アルゴリズムの model-aware な一般化として [EM アルゴリズム](https://ja.wikipedia.org/wiki/EM%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0) を説明し，その共通の問題点「初期値依存性」と「局所解へのトラップ」の数理的な理解を目指す．\n",
        "listing: \n",
        "    -   id: vi-listing\n",
        "        type: grid\n",
        "        sort: false\n",
        "        contents:\n",
        "            - VI2.qmd\n",
        "            - VI3.qmd\n",
        "            - ../Kernels/Kernel.qmd\n",
        "        date-format: iso\n",
        "        fields: [title,image,date,subtitle]\n",
        "---\n",
        "\n",
        "::: {.hidden}\n",
        "\n",
        "::: {.content-visible when-format=\"html\"}\n",
        "\n",
        "A Blog Entry on Bayesian Computation by an Applied Mathematician\n",
        "\n",
        "$$\n",
        "\n",
        "\\renewcommand{\\P}{\\operatorname{P}}\\newcommand{\\E}{\\operatorname{E}}\n",
        "\\newcommand{\\R}{\\mathbb{R}}\\newcommand{\\F}{\\mathcal{F}}\n",
        "\\newcommand{\\abs}[1]{\\lvert#1\\rvert}\\newcommand{\\Abs}[1]{\\left|#1\\right|}\\newcommand{\\ABs}[1]{\\biggl|#1\\biggr|}\\newcommand{\\norm}[1]{\\|#1\\|}\\newcommand{\\Norm}[1]{\\left\\|#1\\right\\|}\\newcommand{\\NOrm}[1]{\\biggl\\|#1\\biggr\\|}\\newcommand{\\Brace}[1]{\\left\\{#1\\right\\}}\\newcommand{\\BRace}[1]{\\biggl\\{#1\\biggr\\}}\\newcommand{\\paren}[1]{\\left(#1\\right)}\\newcommand{\\Paren}[1]{\\biggr(#1\\biggl)}\\newcommand{\\brac}[1]{\\langle#1\\rangle}\\newcommand{\\Brac}[1]{\\left\\langle#1\\right\\rangle}\\newcommand{\\BRac}[1]{\\biggl\\langle#1\\biggr\\rangle}\\newcommand{\\bra}[1]{\\left\\langle#1\\right|}\\newcommand{\\ket}[1]{\\left|#1\\right\\rangle}\\newcommand{\\Square}[1]{\\left[#1\\right]}\\newcommand{\\SQuare}[1]{\\biggl[#1\\biggr]}\\newcommand{\\rN}{\\operatorname{N}}\\newcommand{\\ov}[1]{\\overline{#1}}\\newcommand{\\un}[1]{\\underline{#1}}\\newcommand{\\wt}[1]{\\widetilde{#1}}\\newcommand{\\wh}[1]{\\widehat{#1}}\\newcommand{\\pp}[2]{\\frac{\\partial #1}{\\partial #2}}\\newcommand{\\ppp}[3]{\\frac{\\partial #1}{\\partial #2\\partial #3}}\\newcommand{\\dd}[2]{\\frac{d #1}{d #2}}\\newcommand{\\floor}[1]{\\lfloor#1\\rfloor}\\newcommand{\\Floor}[1]{\\left\\lfloor#1\\right\\rfloor}\\newcommand{\\ceil}[1]{\\lceil#1\\rceil}\\newcommand{\\ocinterval}[1]{(#1]}\\newcommand{\\cointerval}[1]{[#1)}\\newcommand{\\COinterval}[1]{\\left[#1\\right)}\\newcommand{\\iso}{\\overset{\\sim}{\\to}}\n",
        "\n",
        "\n",
        "\n",
        "\\newcommand{\\y}{\\b{y}}\\newcommand{\\mi}{\\,|\\,}\\newcommand{\\Mark}{\\mathrm{Mark}}\n",
        "\\newcommand{\\argmax}{\\operatorname*{argmax}}\\newcommand{\\argmin}{\\operatorname*{argmin}}\n",
        "\n",
        "\\newcommand{\\pr}{\\mathrm{pr}}\\newcommand{\\Conv}{\\operatorname{Conv}}\\newcommand{\\cU}{\\mathcal{U}}\n",
        "\\newcommand{\\Map}{\\mathrm{Map}}\\newcommand{\\dom}{\\mathrm{Dom}\\;}\\newcommand{\\cod}{\\mathrm{Cod}\\;}\\newcommand{\\supp}{\\mathrm{supp}\\;}\n",
        "\\newcommand{\\grad}{\\operatorname{grad}}\\newcommand{\\rot}{\\operatorname{rot}}\\renewcommand{\\div}{\\operatorname{div}}\\newcommand{\\tr}{\\operatorname{tr}}\\newcommand{\\Tr}{\\operatorname{Tr}}\\newcommand{\\KL}{\\operatorname{KL}}\\newcommand{\\JS}{\\operatorname{JS}}\\newcommand{\\ESS}{\\operatorname{ESS}}\\newcommand{\\MSE}{\\operatorname{MSE}}\\newcommand{\\erf}{\\operatorname{erf}}\\newcommand{\\arctanh}{\\operatorname{arctanh}}\\newcommand{\\pl}{\\operatorname{pl}}\\newcommand{\\minimize}{\\operatorname{minimize}}\\newcommand{\\subjectto}{\\operatorname{subject to}}\\newcommand{\\sinc}{\\operatorname{sinc}}\\newcommand{\\Ent}{\\operatorname{Ent}}\\newcommand{\\Polya}{\\operatorname{Polya}}\\newcommand{\\Exp}{\\operatorname{Exp}}\\newcommand{\\codim}{\\operatorname{codim}}\\newcommand{\\sgn}{\\operatorname{sgn}}\\newcommand{\\rank}{\\operatorname{rank}}\n",
        "\n",
        "\\newcommand{\\vctr}[2]{\\begin{pmatrix}#1\\\\#2\\end{pmatrix}}\\newcommand{\\vctrr}[3]{\\begin{pmatrix}#1\\\\#2\\\\#3\\end{pmatrix}}\\newcommand{\\mtrx}[4]{\\begin{pmatrix}#1&#2\\\\#3&#4\\end{pmatrix}}\\newcommand{\\smtrx}[4]{\\paren{\\begin{smallmatrix}#1&#2\\\\#3&#4\\end{smallmatrix}}}\\newcommand{\\Ker}{\\mathrm{Ker}\\;}\\newcommand{\\Coker}{\\mathrm{Coker}\\;}\\newcommand{\\Coim}{\\mathrm{Coim}\\;}\\newcommand{\\lcm}{\\mathrm{lcm}}\\newcommand{\\GL}{\\mathrm{GL}}\\newcommand{\\SL}{\\mathrm{SL}}\\newcommand{\\alt}{\\mathrm{alt}}\n",
        "\n",
        "\\renewcommand{\\Re}{\\mathrm{Re}\\;}\\renewcommand{\\Im}{\\mathrm{Im}\\,}\\newcommand{\\Gal}{\\mathrm{Gal}}\\newcommand{\\PGL}{\\mathrm{PGL}}\\newcommand{\\PSL}{\\mathrm{PSL}}\\newcommand{\\Log}{\\mathrm{Log}\\,}\\newcommand{\\Res}{\\mathrm{Res}\\,}\\newcommand{\\on}{\\mathrm{on}\\;}\\newcommand{\\hatC}{\\widehat{\\C}}\\newcommand{\\hatR}{\\hat{\\R}}\\newcommand{\\PV}{\\mathrm{P.V.}}\\newcommand{\\diam}{\\mathrm{diam}}\\newcommand{\\Area}{\\mathrm{Area}}\\newcommand{\\Lap}{\\Laplace}\\newcommand{\\f}{\\mathbf{f}}\\newcommand{\\cR}{\\mathcal{R}}\\newcommand{\\const}{\\mathrm{const.}}\\newcommand{\\Om}{\\Omega}\\newcommand{\\Cinf}{C^\\infty}\\newcommand{\\ep}{\\epsilon}\\newcommand{\\dist}{\\mathrm{dist}}\\newcommand{\\opart}{\\o{\\partial}}\\newcommand{\\Length}{\\mathrm{Length}}\n",
        "\n",
        "\\newcommand{\\cA}{\\mathcal{A}}\\newcommand{\\cO}{\\mathcal{O}}\\newcommand{\\cW}{\\mathcal{W}}\\renewcommand{\\O}{\\mathcal{O}}\\renewcommand{\\S}{\\mathcal{S}}\\newcommand{\\U}{\\mathcal{U}}\\newcommand{\\V}{\\mathrm{V}}\\newcommand{\\N}{\\mathbb{N}}\\newcommand{\\bN}{\\mathbb{N}}\\newcommand{\\C}{\\mathrm{C}}\\newcommand{\\bC}{\\mathbb{C}}\\newcommand{\\Z}{\\mathcal{Z}}\\newcommand{\\Q}{\\mathbb{Q}}\\newcommand{\\bQ}{\\mathbb{Q}}\\newcommand{\\TV}{\\mathrm{TV}}\\newcommand{\\ORD}{\\mathrm{ORD}}\\newcommand{\\Card}{\\mathrm{Card}\\,}\\newcommand{\\Top}{\\mathrm{Top}}\\newcommand{\\Disc}{\\mathrm{Disc}}\\newcommand{\\Codisc}{\\mathrm{Codisc}}\\newcommand{\\CoDisc}{\\mathrm{CoDisc}}\\newcommand{\\Ult}{\\mathrm{Ult}}\\newcommand{\\ord}{\\mathrm{ord}}\\newcommand{\\bS}{\\mathbb{S}}\\newcommand{\\PConn}{\\mathrm{PConn}}\\newcommand{\\mult}{\\mathrm{mult}}\\newcommand{\\inv}{\\mathrm{inv}}\n",
        "\n",
        "\\newcommand{\\Der}{\\mathrm{Der}}\\newcommand{\\osub}{\\overset{\\mathrm{open}}{\\subset}}\\newcommand{\\osup}{\\overset{\\mathrm{open}}{\\supset}}\\newcommand{\\al}{\\alpha}\\newcommand{\\K}{\\mathbb{K}}\\newcommand{\\Sp}{\\mathrm{Sp}}\\newcommand{\\g}{\\mathfrak{g}}\\newcommand{\\h}{\\mathfrak{h}}\\newcommand{\\Imm}{\\mathrm{Imm}}\\newcommand{\\Imb}{\\mathrm{Imb}}\\newcommand{\\Gr}{\\mathrm{Gr}}\n",
        "\n",
        "\\newcommand{\\Ad}{\\mathrm{Ad}}\\newcommand{\\finsupp}{\\mathrm{fin\\;supp}}\\newcommand{\\SO}{\\mathrm{SO}}\\newcommand{\\SU}{\\mathrm{SU}}\\newcommand{\\acts}{\\curvearrowright}\\newcommand{\\mono}{\\hookrightarrow}\\newcommand{\\epi}{\\twoheadrightarrow}\\newcommand{\\Stab}{\\mathrm{Stab}}\\newcommand{\\nor}{\\mathrm{nor}}\\newcommand{\\T}{\\mathbb{T}}\\newcommand{\\Aff}{\\mathrm{Aff}}\\newcommand{\\rsup}{\\triangleright}\\newcommand{\\subgrp}{\\overset{\\mathrm{subgrp}}{\\subset}}\\newcommand{\\Ext}{\\mathrm{Ext}}\\newcommand{\\sbs}{\\subset}\\newcommand{\\sps}{\\supset}\\newcommand{\\In}{\\mathrm{in}\\;}\\newcommand{\\Tor}{\\mathrm{Tor}}\\newcommand{\\p}{\\b{p}}\\newcommand{\\q}{\\mathfrak{q}}\\newcommand{\\m}{\\mathfrak{m}}\\newcommand{\\cS}{\\mathcal{S}}\\newcommand{\\Frac}{\\mathrm{Frac}\\,}\\newcommand{\\Spec}{\\mathrm{Spec}\\,}\\newcommand{\\bA}{\\mathbb{A}}\\newcommand{\\Sym}{\\mathrm{Sym}}\\newcommand{\\Ann}{\\mathrm{Ann}}\\newcommand{\\Her}{\\mathrm{Her}}\\newcommand{\\Bil}{\\mathrm{Bil}}\\newcommand{\\Ses}{\\mathrm{Ses}}\\newcommand{\\FVS}{\\mathrm{FVS}}\n",
        "\n",
        "\\newcommand{\\Ho}{\\mathrm{Ho}}\\newcommand{\\CW}{\\mathrm{CW}}\\newcommand{\\lc}{\\mathrm{lc}}\\newcommand{\\cg}{\\mathrm{cg}}\\newcommand{\\Fib}{\\mathrm{Fib}}\\newcommand{\\Cyl}{\\mathrm{Cyl}}\\newcommand{\\Ch}{\\mathrm{Ch}}\n",
        "\\newcommand{\\rP}{\\mathrm{P}}\\newcommand{\\rE}{\\mathrm{E}}\\newcommand{\\e}{\\b{e}}\\renewcommand{\\k}{\\b{k}}\\newcommand{\\Christ}[2]{\\begin{Bmatrix}#1\\\\#2\\end{Bmatrix}}\\renewcommand{\\Vec}[1]{\\overrightarrow{\\mathrm{#1}}}\\newcommand{\\hen}[1]{\\mathrm{#1}}\\renewcommand{\\b}[1]{\\boldsymbol{#1}}\n",
        "\n",
        "\\newcommand{\\Inc}{\\mathrm{Inc}}\\newcommand{\\aInc}{\\mathrm{aInc}}\\newcommand{\\HS}{\\mathrm{HS}}\\newcommand{\\loc}{\\mathrm{loc}}\\newcommand{\\Lh}{\\mathrm{L.h.}}\\newcommand{\\Epi}{\\mathrm{Epi}}\\newcommand{\\slim}{\\mathrm{slim}}\\newcommand{\\Ban}{\\mathrm{Ban}}\\newcommand{\\Hilb}{\\mathrm{Hilb}}\\newcommand{\\Ex}{\\mathrm{Ex}}\\newcommand{\\Co}{\\mathrm{Co}}\\newcommand{\\sa}{\\mathrm{sa}}\\newcommand{\\nnorm}[1]{{\\left\\vert\\kern-0.25ex\\left\\vert\\kern-0.25ex\\left\\vert #1 \\right\\vert\\kern-0.25ex\\right\\vert\\kern-0.25ex\\right\\vert}}\\newcommand{\\dvol}{\\mathrm{dvol}}\\newcommand{\\Sconv}{\\mathrm{Sconv}}\\newcommand{\\I}{\\mathcal{I}}\\newcommand{\\nonunital}{\\mathrm{nu}}\\newcommand{\\cpt}{\\mathrm{cpt}}\\newcommand{\\lcpt}{\\mathrm{lcpt}}\\newcommand{\\com}{\\mathrm{com}}\\newcommand{\\Haus}{\\mathrm{Haus}}\\newcommand{\\proper}{\\mathrm{proper}}\\newcommand{\\infinity}{\\mathrm{inf}}\\newcommand{\\TVS}{\\mathrm{TVS}}\\newcommand{\\ess}{\\mathrm{ess}}\\newcommand{\\ext}{\\mathrm{ext}}\\newcommand{\\Index}{\\mathrm{Index}\\;}\\newcommand{\\SSR}{\\mathrm{SSR}}\\newcommand{\\vs}{\\mathrm{vs.}}\\newcommand{\\fM}{\\mathfrak{M}}\\newcommand{\\EDM}{\\mathrm{EDM}}\\newcommand{\\Tw}{\\mathrm{Tw}}\\newcommand{\\fC}{\\mathfrak{C}}\\newcommand{\\bn}{\\boldsymbol{n}}\\newcommand{\\br}{\\boldsymbol{r}}\\newcommand{\\Lam}{\\Lambda}\\newcommand{\\lam}{\\lambda}\\newcommand{\\one}{\\mathbf{1}}\\newcommand{\\dae}{\\text{-a.e.}}\\newcommand{\\das}{\\text{-a.s.}}\\newcommand{\\td}{\\text{-}}\\newcommand{\\RM}{\\mathrm{RM}}\\newcommand{\\BV}{\\mathrm{BV}}\\newcommand{\\normal}{\\mathrm{normal}}\\newcommand{\\lub}{\\mathrm{lub}\\;}\\newcommand{\\Graph}{\\mathrm{Graph}}\\newcommand{\\Ascent}{\\mathrm{Ascent}}\\newcommand{\\Descent}{\\mathrm{Descent}}\\newcommand{\\BIL}{\\mathrm{BIL}}\\newcommand{\\fL}{\\mathfrak{L}}\\newcommand{\\De}{\\Delta}\n",
        "\n",
        "\\newcommand{\\calA}{\\mathcal{A}}\\newcommand{\\calB}{\\mathcal{B}}\\newcommand{\\D}{\\mathcal{D}}\\newcommand{\\Y}{\\mathcal{Y}}\\newcommand{\\calC}{\\mathcal{C}}\\renewcommand{\\ae}{\\mathrm{a.e.}\\;}\\newcommand{\\cZ}{\\mathcal{Z}}\\newcommand{\\fF}{\\mathfrak{F}}\\newcommand{\\fI}{\\mathfrak{I}}\\newcommand{\\rV}{\\mathrm{V}}\\newcommand{\\cE}{\\mathcal{E}}\\newcommand{\\sMap}{\\sigma\\textrm{-}\\mathrm{Map}}\\newcommand{\\cC}{\\mathcal{C}}\\newcommand{\\comp}{\\complement}\\newcommand{\\J}{\\mathcal{J}}\\newcommand{\\sumN}[1]{\\sum_{#1\\in\\N}}\\newcommand{\\cupN}[1]{\\cup_{#1\\in\\N}}\\newcommand{\\capN}[1]{\\cap_{#1\\in\\N}}\\newcommand{\\Sum}[1]{\\sum_{#1=1}^\\infty}\\newcommand{\\sumn}{\\sum_{n=1}^\\infty}\\newcommand{\\summ}{\\sum_{m=1}^\\infty}\\newcommand{\\sumk}{\\sum_{k=1}^\\infty}\\newcommand{\\sumi}{\\sum_{i=1}^\\infty}\\newcommand{\\sumj}{\\sum_{j=1}^\\infty}\\newcommand{\\cupn}{\\cup_{n=1}^\\infty}\\newcommand{\\capn}{\\cap_{n=1}^\\infty}\\newcommand{\\cupk}{\\cup_{k=1}^\\infty}\\newcommand{\\cupi}{\\cup_{i=1}^\\infty}\\newcommand{\\cupj}{\\cup_{j=1}^\\infty}\\newcommand{\\limn}{\\lim_{n\\to\\infty}}\\renewcommand{\\L}{\\mathcal{L}}\\newcommand{\\cL}{\\mathcal{L}}\\newcommand{\\Cl}{\\mathrm{Cl}}\\newcommand{\\cN}{\\mathcal{N}}\\newcommand{\\Ae}{\\textrm{-a.e.}\\;}\\renewcommand{\\csub}{\\overset{\\textrm{closed}}{\\subset}}\\renewcommand{\\csup}{\\overset{\\textrm{closed}}{\\supset}}\\newcommand{\\wB}{\\wt{B}}\\newcommand{\\cG}{\\mathcal{G}}\\newcommand{\\Lip}{\\mathrm{Lip}}\\newcommand{\\AC}{\\mathrm{AC}}\\newcommand{\\Mol}{\\mathrm{Mol}}\n",
        "\n",
        "\\newcommand{\\Pe}{\\mathrm{Pe}}\\newcommand{\\wR}{\\wh{\\mathbb{\\R}}}\\newcommand*{\\Laplace}{\\mathop{}\\!\\mathbin\\bigtriangleup}\\newcommand*{\\DAlambert}{\\mathop{}\\!\\mathbin\\Box}\\newcommand{\\bT}{\\mathbb{T}}\\newcommand{\\dx}{\\dslash x}\\newcommand{\\dt}{\\dslash t}\\newcommand{\\ds}{\\dslash s}\n",
        "\n",
        "\\newcommand{\\round}{\\mathrm{round}}\\newcommand{\\cond}{\\mathrm{cond}}\\newcommand{\\diag}{\\mathrm{diag}}\n",
        "\\newcommand{\\Adj}{\\mathrm{Adj}}\\newcommand{\\Pf}{\\mathrm{Pf}}\\newcommand{\\Sg}{\\mathrm{Sg}}\n",
        "\n",
        "\n",
        "\\newcommand{\\aseq}{\\overset{\\text{a.s.}}{=}}\\newcommand{\\deq}{\\overset{\\text{d}}{=}}\\newcommand{\\cV}{\\mathcal{V}}\\newcommand{\\FM}{\\mathrm{FM}}\\newcommand{\\KR}{\\mathrm{KR}}\\newcommand{\\rba}{\\mathrm{rba}}\\newcommand{\\rca}{\\mathrm{rca}}\\newcommand{\\Prob}{\\mathrm{Prob}}\\newcommand{\\X}{\\mathcal{X}}\\newcommand{\\Meas}{\\mathrm{Meas}}\\newcommand{\\as}{\\;\\text{a.s.}}\\newcommand{\\io}{\\;\\mathrm{i.o.}}\\newcommand{\\fe}{\\;\\text{f.e.}}\\newcommand{\\bF}{\\mathbb{F}}\\newcommand{\\W}{\\mathcal{W}}\\newcommand{\\Pois}{\\mathrm{Pois}}\\newcommand{\\iid}{\\text{i.i.d.}}\\newcommand{\\wconv}{\\rightsquigarrow}\\newcommand{\\Var}{\\mathrm{Var}}\\newcommand{\\xrightarrown}{\\xrightarrow{n\\to\\infty}}\\newcommand{\\au}{\\mathrm{au}}\\newcommand{\\cT}{\\mathcal{T}}\\newcommand{\\wto}{\\overset{\\text{w}}{\\to}}\\newcommand{\\dto}{\\overset{\\text{d}}{\\to}}\\newcommand{\\sto}{\\overset{\\text{s}}{\\to}}\\newcommand{\\pto}{\\overset{\\text{p}}{\\to}}\\newcommand{\\mto}{\\overset{\\text{m}}{\\to}}\\newcommand{\\vto}{\\overset{v}{\\to}}\\newcommand{\\Cont}{\\mathrm{Cont}}\\newcommand{\\stably}{\\mathrm{stably}}\\newcommand{\\Np}{\\mathbb{N}^+}\\newcommand{\\oM}{\\overline{\\mathcal{M}}}\\newcommand{\\fP}{\\mathfrak{P}}\\newcommand{\\sign}{\\mathrm{sign}}\n",
        "\\newcommand{\\Borel}{\\mathrm{Borel}}\\newcommand{\\Mid}{\\,|\\,}\\newcommand{\\middleMid}{\\;\\middle|\\;}\\newcommand{\\CP}{\\mathrm{CP}}\\newcommand{\\bD}{\\mathbb{D}}\\newcommand{\\bL}{\\mathbb{L}}\\newcommand{\\fW}{\\mathfrak{W}}\\newcommand{\\DL}{\\mathcal{D}\\mathcal{L}}\\renewcommand{\\r}[1]{\\mathrm{#1}}\\newcommand{\\rC}{\\mathrm{C}}\\newcommand{\\qqquad}{\\qquad\\quad}\n",
        "\n",
        "\\newcommand{\\bit}{\\mathrm{bit}}\n",
        "\n",
        "\\newcommand{\\err}{\\mathrm{err}}\n",
        "\n",
        "\\newcommand{\\varparallel}{\\mathbin{\\!/\\mkern-5mu/\\!}}\\newcommand{\\Ri}{\\mathrm{Ri}}\\newcommand{\\Cone}{\\mathrm{Cone}}\\newcommand{\\Int}{\\mathrm{Int}}\n",
        "\n",
        "\\newcommand{\\pre}{\\mathrm{pre}}\\newcommand{\\om}{\\omega}\n",
        "\n",
        "\n",
        "\\newcommand{\\del}{\\partial}\n",
        "\\newcommand{\\LHS}{\\mathrm{LHS}}\\newcommand{\\RHS}{\\mathrm{RHS}}\\newcommand{\\bnu}{\\boldsymbol{\\nu}}\\newcommand{\\interior}{\\mathrm{in}\\;}\\newcommand{\\SH}{\\mathrm{SH}}\\renewcommand{\\v}{\\boldsymbol{\\nu}}\\newcommand{\\n}{\\mathbf{n}}\\newcommand{\\ssub}{\\Subset}\\newcommand{\\curl}{\\mathrm{curl}}\n",
        "\n",
        "\\newcommand{\\Ei}{\\mathrm{Ei}}\\newcommand{\\sn}{\\mathrm{sn}}\\newcommand{\\wgamma}{\\widetilde{\\gamma}}\n",
        "\n",
        "\\newcommand{\\Ens}{\\mathrm{Ens}}\n",
        "\n",
        "\\newcommand{\\cl}{\\mathrm{cl}}\\newcommand{\\x}{\\boldsymbol{x}}\n",
        "\n",
        "\\newcommand{\\Do}{\\mathrm{Do}}\\newcommand{\\IV}{\\mathrm{IV}}\n",
        "\n",
        "\\newcommand{\\AIC}{\\mathrm{AIC}}\\newcommand{\\mrl}{\\mathrm{mrl}}\\newcommand{\\dotx}{\\dot{x}}\\newcommand{\\UMV}{\\mathrm{UMV}}\\newcommand{\\BLU}{\\mathrm{BLU}}\n",
        "\n",
        "\\newcommand{\\comb}[2]{\\begin{pmatrix}#1\\\\#2\\end{pmatrix}}\\newcommand{\\bP}{\\mathbb{P}}\\newcommand{\\compsub}{\\overset{\\textrm{cpt}}{\\subset}}\\newcommand{\\lip}{\\textrm{lip}}\\newcommand{\\BL}{\\mathrm{BL}}\\newcommand{\\G}{\\mathbb{G}}\\newcommand{\\NB}{\\mathrm{NB}}\\newcommand{\\oR}{\\ov{\\R}}\\newcommand{\\liminfn}{\\liminf_{n\\to\\infty}}\\newcommand{\\limsupn}{\\limsup_{n\\to\\infty}}\\newcommand{\\esssup}{\\mathrm{ess.sup}}\\newcommand{\\asto}{\\xrightarrow{\\as}}\\newcommand{\\Cov}{\\mathrm{Cov}}\\newcommand{\\cQ}{\\mathcal{Q}}\\newcommand{\\VC}{\\mathrm{VC}}\\newcommand{\\mb}{\\mathrm{mb}}\\newcommand{\\Avar}{\\mathrm{Avar}}\\newcommand{\\bB}{\\mathbb{B}}\\newcommand{\\bW}{\\mathbb{W}}\\newcommand{\\sd}{\\mathrm{sd}}\\newcommand{\\w}[1]{\\widehat{#1}}\\newcommand{\\bZ}{\\mathbb{Z}}\\newcommand{\\Bernoulli}{\\mathrm{Ber}}\\newcommand{\\Ber}{\\mathrm{Ber}}\\newcommand{\\Mult}{\\mathrm{Mult}}\\newcommand{\\BPois}{\\mathrm{BPois}}\\newcommand{\\fraks}{\\mathfrak{s}}\\newcommand{\\frakk}{\\mathfrak{k}}\\newcommand{\\IF}{\\mathrm{IF}}\\newcommand{\\bX}{\\boldsymbol{X}}\\newcommand{\\bx}{\\boldsymbol{x}}\\newcommand{\\indep}{\\perp\\!\\!\\!\\perp}\\newcommand{\\IG}{\\mathrm{IG}}\\newcommand{\\Levy}{\\mathrm{Levy}}\\newcommand{\\MP}{\\mathrm{MP}}\\newcommand{\\Hermite}{\\mathrm{Hermite}}\\newcommand{\\Skellam}{\\mathrm{Skellam}}\\newcommand{\\Dirichlet}{\\mathrm{Dirichlet}}\\renewcommand{\\Beta}{\\operatorname{Beta}}\\newcommand{\\bE}{\\mathbb{E}}\\newcommand{\\bG}{\\mathbb{G}}\\newcommand{\\MISE}{\\mathrm{MISE}}\\newcommand{\\logit}{\\mathtt{logit}}\\newcommand{\\expit}{\\mathtt{expit}}\\newcommand{\\cK}{\\mathcal{K}}\\newcommand{\\dl}{\\dot{l}}\\newcommand{\\dotp}{\\dot{p}}\\newcommand{\\wl}{\\wt{l}}\\newcommand{\\Gauss}{\\mathrm{Gauss}}\\newcommand{\\fA}{\\mathfrak{A}}\\newcommand{\\under}{\\mathrm{under}\\;}\\newcommand{\\whtheta}{\\wh{\\theta}}\\newcommand{\\Em}{\\mathrm{Em}}\\newcommand{\\ztheta}{{\\theta_0}}\n",
        "\\newcommand{\\rO}{\\mathrm{O}}\\newcommand{\\Bin}{\\mathrm{Bin}}\\newcommand{\\rW}{\\mathrm{W}}\\newcommand{\\rG}{\\mathrm{G}}\\newcommand{\\rB}{\\mathrm{B}}\\newcommand{\\rU}{\\mathrm{U}}\\newcommand{\\HG}{\\mathrm{HG}}\\newcommand{\\GAMMA}{\\mathrm{Gamma}}\\newcommand{\\Cauchy}{\\mathrm{Cauchy}}\\newcommand{\\rt}{\\mathrm{t}}\\newcommand{\\rF}{\\mathrm{F}}\n",
        "\\newcommand{\\FE}{\\mathrm{FE}}\\newcommand{\\bV}{\\boldsymbol{V}}\\newcommand{\\GLS}{\\mathrm{GLS}}\\newcommand{\\be}{\\boldsymbol{e}}\\newcommand{\\POOL}{\\mathrm{POOL}}\\newcommand{\\GMM}{\\mathrm{GMM}}\\newcommand{\\MM}{\\mathrm{MM}}\\newcommand{\\SSIV}{\\mathrm{SSIV}}\\newcommand{\\JIV}{\\mathrm{JIV}}\\newcommand{\\AR}{\\mathrm{AR}}\\newcommand{\\ILS}{\\mathrm{ILS}}\\newcommand{\\SLS}{\\mathrm{SLS}}\\newcommand{\\LIML}{\\mathrm{LIML}}\n",
        "\n",
        "\\newcommand{\\Rad}{\\mathrm{Rad}}\\newcommand{\\bY}{\\boldsymbol{Y}}\\newcommand{\\pone}{{(1)}}\\newcommand{\\ptwo}{{(2)}}\\newcommand{\\ps}[1]{{(#1)}}\\newcommand{\\fsub}{\\overset{\\text{finite}}{\\subset}}\n",
        "\n",
        "\n",
        "\\newcommand{\\varlim}{\\varprojlim}\\newcommand{\\Hom}{\\mathrm{Hom}}\\newcommand{\\Iso}{\\mathrm{Iso}}\\newcommand{\\Mor}{\\mathrm{Mor}}\\newcommand{\\Isom}{\\mathrm{Isom}}\\newcommand{\\Aut}{\\mathrm{Aut}}\\newcommand{\\End}{\\mathrm{End}}\\newcommand{\\op}{\\mathrm{op}}\\newcommand{\\ev}{\\mathrm{ev}}\\newcommand{\\Ob}{\\mathrm{Ob}}\\newcommand{\\Ar}{\\mathrm{Ar}}\\newcommand{\\Arr}{\\mathrm{Arr}}\\newcommand{\\Set}{\\mathrm{Set}}\\newcommand{\\Grp}{\\mathrm{Grp}}\\newcommand{\\Cat}{\\mathrm{Cat}}\\newcommand{\\Mon}{\\mathrm{Mon}}\\newcommand{\\Ring}{\\mathrm{Ring}}\\newcommand{\\CRing}{\\mathrm{CRing}}\\newcommand{\\Ab}{\\mathrm{Ab}}\\newcommand{\\Pos}{\\mathrm{Pos}}\\newcommand{\\Vect}{\\mathrm{Vect}}\\newcommand{\\FinVect}{\\mathrm{FinVect}}\\newcommand{\\FinSet}{\\mathrm{FinSet}}\\newcommand{\\FinMeas}{\\mathrm{FinMeas}}\\newcommand{\\OmegaAlg}{\\Omega\\text{-}\\mathrm{Alg}}\\newcommand{\\OmegaEAlg}{(\\Omega,E)\\text{-}\\mathrm{Alg}}\\newcommand{\\Fun}{\\mathrm{Fun}}\\newcommand{\\Func}{\\mathrm{Func}}\n",
        "\n",
        "\\newcommand{\\Stoch}{\\mathrm{Stoch}}\\newcommand{\\FinStoch}{\\mathrm{FinStoch}}\\newcommand{\\Copy}{\\mathrm{copy}}\\newcommand{\\Delete}{\\mathrm{delete}}\n",
        "\\newcommand{\\Bool}{\\mathrm{Bool}}\\newcommand{\\CABool}{\\mathrm{CABool}}\\newcommand{\\CompBoolAlg}{\\mathrm{CompBoolAlg}}\\newcommand{\\BoolAlg}{\\mathrm{BoolAlg}}\\newcommand{\\BoolRng}{\\mathrm{BoolRng}}\\newcommand{\\HeytAlg}{\\mathrm{HeytAlg}}\\newcommand{\\CompHeytAlg}{\\mathrm{CompHeytAlg}}\\newcommand{\\Lat}{\\mathrm{Lat}}\\newcommand{\\CompLat}{\\mathrm{CompLat}}\\newcommand{\\SemiLat}{\\mathrm{SemiLat}}\\newcommand{\\Stone}{\\mathrm{Stone}}\\newcommand{\\Mfd}{\\mathrm{Mfd}}\\newcommand{\\LieAlg}{\\mathrm{LieAlg}}\n",
        "\\newcommand{\\Op}{\\mathrm{Op}}\n",
        "\\newcommand{\\Sh}{\\mathrm{Sh}}\n",
        "\\newcommand{\\Diff}{\\mathrm{Diff}}\n",
        "\\newcommand{\\B}{\\mathcal{B}}\\newcommand{\\cB}{\\mathcal{B}}\\newcommand{\\Span}{\\mathrm{Span}}\\newcommand{\\Corr}{\\mathrm{Corr}}\\newcommand{\\Decat}{\\mathrm{Decat}}\\newcommand{\\Rep}{\\mathrm{Rep}}\\newcommand{\\Grpd}{\\mathrm{Grpd}}\\newcommand{\\sSet}{\\mathrm{sSet}}\\newcommand{\\Mod}{\\mathrm{Mod}}\\newcommand{\\SmoothMnf}{\\mathrm{SmoothMnf}}\\newcommand{\\coker}{\\mathrm{coker}}\\newcommand{\\Ord}{\\mathrm{Ord}}\\newcommand{\\eq}{\\mathrm{eq}}\\newcommand{\\coeq}{\\mathrm{coeq}}\\newcommand{\\act}{\\mathrm{act}}\n",
        "\n",
        "\\newcommand{\\apf}{\\mathrm{apf}}\\newcommand{\\opt}{\\mathrm{opt}}\\newcommand{\\IS}{\\mathrm{IS}}\\newcommand{\\IR}{\\mathrm{IR}}\\newcommand{\\iidsim}{\\overset{\\text{i.i.d.}}{\\sim}}\\newcommand{\\propt}{\\,\\propto\\,}\\newcommand{\\bM}{\\mathbb{M}}\\newcommand{\\cX}{\\mathcal{X}}\\newcommand{\\cY}{\\mathcal{Y}}\\newcommand{\\cP}{\\mathcal{P}}\\newcommand{\\ola}[1]{\\overleftarrow{#1}}\n",
        "\n",
        "\\renewcommand{\\iff}{\\;\\mathrm{iff}\\;}\n",
        "\\newcommand{\\False}{\\mathrm{False}}\\newcommand{\\True}{\\mathrm{True}}\n",
        "\\newcommand{\\otherwise}{\\mathrm{otherwise}}\n",
        "\\newcommand{\\suchthat}{\\;\\mathrm{s.t.}\\;}\n",
        "\n",
        "\\newcommand{\\cM}{\\mathcal{M}}\\newcommand{\\M}{\\mathbb{M}}\\newcommand{\\cF}{\\mathcal{F}}\\newcommand{\\cD}{\\mathcal{D}}\\newcommand{\\fX}{\\mathfrak{X}}\\newcommand{\\fY}{\\mathfrak{Y}}\\newcommand{\\fZ}{\\mathfrak{Z}}\\renewcommand{\\H}{\\mathcal{H}}\\newcommand{\\cH}{\\mathcal{H}}\\newcommand{\\fH}{\\mathfrak{H}}\\newcommand{\\bH}{\\mathbb{H}}\\newcommand{\\id}{\\mathrm{id}}\\newcommand{\\A}{\\mathcal{A}}\n",
        "\\newcommand{\\lmd}{\\lambda}\n",
        "\\newcommand{\\Lmd}{\\Lambda}\n",
        "\\newcommand{\\cI}{\\mathcal{I}}\n",
        "\n",
        "\\newcommand{\\Lrarrow}{\\;\\;\\Leftrightarrow\\;\\;}\n",
        "\\DeclareMathOperator{\\des}{des}\n",
        "\\DeclareMathOperator{\\nd}{nd}\n",
        "\\DeclareMathOperator{\\dsep}{d-sep}\n",
        "\\DeclareMathOperator{\\sep}{sep}\n",
        "\\newcommand{\\rLL}{\\mathrm{LL}}\\newcommand{\\HT}{\\mathrm{HT}}\\newcommand{\\PS}{\\mathrm{PS}}\\newcommand{\\rI}{\\mathrm{I}}\n",
        "$$\n",
        "\n",
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "より図が見やすい PDF 版は [こちら](report1.pdf)．\n",
        "\n",
        "### 関連ページ {.unnumbered .unlisted}\n",
        "\n",
        "::: {#vi-listing}\n",
        ":::\n",
        "\n",
        "\n",
        "## 導入\n",
        "\n",
        "### 歴史 {#sec-history}\n",
        "\n",
        "ハード $K$-平均法はモデルフリーのクラスタリングアルゴリズムである．Voronoi 分割による競争学習の一形態とも見れる．^[[@MacKay2003 p.285]．]\n",
        "\n",
        "一方で原論文 [@Lloyd1982] では，[パルス符号変調](https://ja.wikipedia.org/wiki/%E3%83%91%E3%83%AB%E3%82%B9%E7%AC%A6%E5%8F%B7%E5%A4%89%E8%AA%BF) の文脈で，アナログ信号の量子化の方法として提案している．^[Stuart P. Lloyd は 1957 年にメモランダムとして発表していたが，論文の形で出版されたのが 1982 である．$K$-means という名前の初出は [@MacQueen1967] とされている．]\n",
        "\n",
        "実際，$K$-平均法は（非可逆）データ圧縮にも用いられる．クラスター中心での画像の値と，それ以外では帰属先のクラスター番号のみを保存すれば良いというのである．このようなアプローチを **ベクトル量子化** (vector quantization) という．^[[@MacKay2003 p.284]，[@Bishop2006 p.429]，[@Murphy2022 p.722] 21.3.3節．クラスター中心は **符号表ベクトル** または 代表ベクトル (code-book vector) という．]\n",
        "\n",
        "ソフト $K$-平均法とは，このようなデータ点のクラスターへの一意な割り当てを，ソフトマックス関数を用いて軟化したアルゴリズムであり，多少アルゴリズムとしての振る舞いは改善するとされている．\n",
        "\n",
        "### 最適化アルゴリズムとしての見方\n",
        "\n",
        "$N$ 個のデータ $\\{x_n\\}_{n=1}^N$ の $K$ クラスへの $K$-平均クラスタリングアルゴリズムは，ハードとソフトの二種類存在するが，いずれも\n",
        "$$\n",
        "J:=\\sum_{n=1}^N\\sum_{k=1}^Kr_{nk}\\norm{x_n-\\mu_k}^2\n",
        "$$\n",
        "という損失関数の逐次最小化アルゴリズムとみなせる．\n",
        "\n",
        "この見方は，[EM アルゴリズム](VI2.qmd) への一般化の軸となる．\n",
        "\n",
        "しかしこの目的関数 $J$ が非凸関数であることが，第 [-@sec-result] 節で示す実験結果で見る通り，アルゴリズムに強い初期値依存性をもたらす．\n",
        "\n",
        "### $K$-平均法の変種\n",
        "\n",
        "#### $K$-means++\n",
        "\n",
        "$K$-平均法アルゴリズムの初期値依存性を，クラスタがより互いに離れるようにクラス割り当て法を修正することで対策した **最遠点クラスタリング** [@Gonzalez1985] が提案された．これは **$K$-means++** [@David-Sergei2007] とも呼ばれており，データ圧縮法として用いた場合は復元誤差が $O(\\log K)$ でバウンド出来ることも示されている．\n",
        "\n",
        "#### $K$-medoids\n",
        "\n",
        "[medoid](https://en.wikipedia.org/wiki/Medoid) とは，データの間に何らかの「類似度」が定義されている際に，クラスター内で他データ点との類似度が最大になる点を意味する．\n",
        "\n",
        "この medoid を mean の代わりに用いたアルゴリズムは，データ内の外れ値により強くなるとされる．\n",
        "\n",
        "$K$-medoids クラスタリングを行うアルゴリズムに Partitioning Around Medoids (PAM) [@Kaufmann-Rousseeuw1987] や Voronoi iteration [@Park-Jun2009] が知られている．\n",
        "\n",
        "### 用いるデータ {#sec-data}\n",
        "\n",
        "実際のコードとデータを用いて $K$-平均法を解説する．\n",
        "\n",
        "まずは，解説にために作られた，次のような３つのクラスタからなる２次元のデータを考え，これの正しいクラスタリングを目指す．\n"
      ],
      "id": "4b4d731c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import pandas as pd\n",
        "data1 = pd.read_csv('mixture1.dat', delimiter=\"\\t\" , header=None)\n",
        "data1_2d = data1.iloc[:, 1:3].to_numpy()"
      ],
      "id": "fe3ad95f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "markers1 = data1.iloc[:, 0]\n",
        "x1 = data1.iloc[:, 1]\n",
        "y1 = data1.iloc[:, 2]\n",
        "\n",
        "plt.figure(figsize=(3.5, 3))\n",
        "for marker in np.unique(markers1):\n",
        "    plt.scatter(x1[markers1 == marker], y1[markers1 == marker], label=f'Cluster {marker}', marker=f'${marker}$') \n",
        "\n",
        "plt.title('Scatter Plot of the Data')\n",
        "plt.show()"
      ],
      "id": "c2c3b950",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ハード $K$-平均法 {#sec-hard-k-means}\n",
        "\n",
        "### アルゴリズムの説明\n",
        "\n",
        "head $K$-means algorithm はデータ $\\{x^{(n)}\\}_{n=1}^N\\subset\\R^I$ とクラスタ数 $K\\in\\N^+$，そして初期クラスター中心 $(m^{(k)})_{k=1}^K\\in(\\R^I)^K$ の３組をパラメータに持つ．\n",
        "\n",
        "soft $K$-means algorithm [-@sec-soft-k-means] はさらに硬度パラメータ $\\beta\\in\\R_+$ を持つ．\n",
        "\n",
        "`numpy` の提供する行列積を利用して，これを Python により実装した例を以下に示す．ソフト $K$-平均法の実装と対比できるように，負担率を通じた実装を意識した例である．\n",
        "\n",
        "アノテーションを付してあるので，該当箇所（右端の丸囲み数字）をクリックすることで適宜解説が読めるようになっている．\n"
      ],
      "id": "e104efff"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import math\n",
        "from itertools import permutations\n",
        "\n",
        "def d(x,y):\n",
        "    \"\"\"\n",
        "    ２次元での Euclid 距離を計算する関数\n",
        "\n",
        "    Parameter:\n",
        "    - x,y: (2,)-numpy.ndarray\n",
        "    \"\"\"\n",
        "    return math.sqrt((x[0]-y[0])**2 + (x[1]-y[1])**2)\n",
        "\n",
        "def normalize(x):\n",
        "    \"\"\"\n",
        "    ラベル番号データを昇順にする関数\n",
        "\n",
        "    Parameter:\n",
        "    - x: (N,)-numpy.ndarray\n",
        "    \"\"\"\n",
        "    labels = [x[0]]\n",
        "    for i in x:\n",
        "        if i not in labels:\n",
        "            labels.append(i)\n",
        "\n",
        "    conditions = [x == labels[i] for i in range(len(labels))]\n",
        "    choices = [i + 1 for i in range(len(labels))]\n",
        "\n",
        "    return np.select(conditions, choices)\n",
        "\n",
        "def normalize_abnormal(x):\n",
        "    \"\"\"\n",
        "    ラベル番号データを昇順にする関数\n",
        "\n",
        "    Parameter:\n",
        "    - x: (N,)-numpy.ndarray\n",
        "    \"\"\"\n",
        "    labels = [x[0]]\n",
        "    for i in x:\n",
        "        if i not in labels:\n",
        "            labels.append(i)\n",
        "\n",
        "    conditions = [x == labels[i] for i in range(len(labels))]\n",
        "    choices = [1,3,2]\n",
        "\n",
        "    return np.select(conditions, choices)\n",
        "\n",
        "def accuracy(ans, pred):\n",
        "    \"\"\"\n",
        "    クラスタリング結果と正解値とを比べ，正答数と正解率を返す関数\n",
        "\n",
        "    Parameters:\n",
        "    - ans: (N,)-numpy.ndarray 正解値\n",
        "    - pred: (N,)-numpy.ndarray 予測値\n",
        "\n",
        "    ただし，成分は 1,2,3 のみとする．\n",
        "    \"\"\"\n",
        "    perms = permutations([1, 2, 3])\n",
        "    num_correct = []\n",
        "\n",
        "    for perm in perms:\n",
        "        mapping = {1: perm[0], 2: perm[1], 3: perm[2]}\n",
        "        permuted_pred = np.array([mapping[value] for value in pred])\n",
        "        num_correct.append(np.sum(ans == permuted_pred))\n",
        "\n",
        "    total_correct = max(num_correct)\n",
        "    accuracy = total_correct / len(ans)\n",
        "    return total_correct, accuracy\n",
        "\n",
        "def accuracy4(ans, pred):\n",
        "    \"\"\"\n",
        "    正解値と予測値を比べ，正答数と正解率を print する関数\n",
        "\n",
        "    Parameters:\n",
        "    - ans: (N,)-numpy.ndarray 正解値\n",
        "    - pred: (N,)-numpy.ndarray 予測値\n",
        "    \"\"\"\n",
        "    perms = permutations([1, 2, 3, 4])\n",
        "    num_correct = []\n",
        "\n",
        "    for perm in perms:\n",
        "        mapping = {1: perm[0], 2: perm[1], 3: perm[2], 4: perm[3]}\n",
        "        permuted_pred = np.array([mapping[value] for value in pred])\n",
        "        num_correct.append(np.sum(ans == permuted_pred))\n",
        "\n",
        "    total_correct = max(num_correct)\n",
        "    accuracy = total_correct / len(ans)\n",
        "    return total_correct, accuracy"
      ],
      "id": "14b8b7b3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{.python}\n",
        "def hkmeans_2d(data, K, init, max_iter=100):\n",
        "    \"\"\"\n",
        "    ２次元データに対するハード K-平均法の実装例．\n",
        "\n",
        "    Parameters:\n",
        "    - data: (N,2)-numpy.ndarray\n",
        "    - K: int クラスター数\n",
        "    - init: (2,K)-numpy.ndarray 初期値\n",
        "\n",
        "    Returns:\n",
        "    - clusters: (N,)-numpy.ndarray クラスター番号\n",
        "    \"\"\"\n",
        "\n",
        "    N = data.shape[0]  # <1>\n",
        "    I = data.shape[1]  # <2>\n",
        "    m = init  # <3>\n",
        "    r = np.zeros((K, N), dtype=float)  # <4>\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        # Assignment Step\n",
        "        for i in range(N):\n",
        "            distances = np.array([d(data[i], m[:,k]) for k in range(K)]) # <5>\n",
        "            k_hat = np.argmin(distances)  # <6>\n",
        "            r[:,i] = 0  # <7>\n",
        "            r[k_hat,i] = 1\n",
        "        \n",
        "        # Update Step\n",
        "        new_m = np.zeros_like(m, dtype=float) # <8>\n",
        "        numerator = np.dot(r, data)  # <9>\n",
        "        denominator = np.sum(r, axis=1) # <10>\n",
        "        for k in range(K): # <11>\n",
        "            if denominator[k] > 0:\n",
        "                new_m[:,k] = numerator[k] / denominator[k]\n",
        "            else:\n",
        "                new_m[:,k] = m[:,k]\n",
        "\n",
        "        if np.allclose(m, new_m): # <12>\n",
        "            break\n",
        "        m = new_m\n",
        "    \n",
        "    return np.argmax(r, axis=0)  # <13>\n",
        "```\n",
        "\n",
        "1. データ数を取得している．\n",
        "2. データの次元を取得している．今回はすべて２次元データを用いる．\n",
        "3. クラスター中心に引数として受け取った初期値を代入. $2×K$-行列であることに注意．\n",
        "4. 負担率を $K×N$-行列として格納している．その理由は後ほど行列積を通じた計算を行うためである．`dtype=float` の理由は後述．\n",
        "5. この `distances` 変数は `(K,)-numpy.ndarray` になる．すなわち，第 $k$ 成分が，第 $k$ クラスター中心との距離となっているようなベクトルである．ただし，`d` は Euclid 距離を計算する関数として定義済みとした．\n",
        "6. 距離が最小となるクラスター番号 $\\hat{k}:=[\\argmin_{k\\in[K]}d(m_k,x_i)]$ を，$i\\in[N]$ 番目のデータについて求める．\n",
        "7. $\\hat{k}$ に基づいて負担率を更新するが，ループ内で前回の結果をリセットする必要があることに注意．\n",
        "8. ここで `dtype=float` と指定しないと，初め引数 `init` が整数のみで構成されていた場合に，Python の自動型付機能が `int` 型だと判定し，クラスター中心 `m` の値が整数に限られてしまう．すると，アルゴリズムがすぐに手頃な格子点に収束してしまう．\n",
        "9. `numpy` の行列積を計算する関数 `np.dot` を使用している．更新式\n",
        "$$\n",
        "m^{(k)}\\gets\\frac{\\sum_{n=1}^Nr^{(n)}_kx^{(n)}}{\\sum_{n=1}^Nr^{(n)}_k}\n",
        "$$\n",
        "の分子を行列積と見たのである．\n",
        "10. 分母 (denominator) は $(K,N)$-行列 `r` の行和として得られる．\n",
        "11. ゼロによる除算が起こらないように場合わけをしている．\n",
        "12. クラスター中心がもはや変わらない場合はアルゴリズムを終了する．\n",
        "13. 負担率の最も大きいクラスター番号を返す．今回は `hat_k` の列をそのまま返せば良いが，soft $K$-means アルゴリズムにも通じる形で実装した．\n",
        "\n",
        "::: {.callout-caution icon=\"false\" title=\"注：実際に用いる実装\" collapse=\"true\"}\n",
        "\n",
        "ただし，本記事の背後では次の実装を用いる．\n",
        "\n",
        "クラスター中心の推移のヒストリーを保存して図示に利用したり，負担率 `r` の中身を見たりすることが出来るようにするため，assignment step と update step とに分けてクラスメソッドとして実装し，`run` メソッドでそれらを呼び出すようにしている．これに `fetch_cluster` と `fetch_history` メソッドを加えることで，クラスター番号とクラスター中心の推移を取得することが出来る．フィールド `.r` から（最終的な）負担率を見ることもできる．\n"
      ],
      "id": "f9f27c2d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "class kmeans_2d:\n",
        "    \"\"\"\n",
        "    ２次元データに対するソフト K-平均法の実装．\n",
        "\n",
        "    Usage:\n",
        "        kmeans = kmeans_2d(data, K, init, beta)\n",
        "        kmeans.run()\n",
        "\n",
        "    Parameters:\n",
        "    - data: (N,2)-numpy.ndarray\n",
        "    - K: int クラスター数\n",
        "    - init: (2,K)-numpy.ndarray 初期値\n",
        "    - beta: float 硬度パラメータ\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data, K, init, beta, max_iter=100):\n",
        "        self.data = np.array(data, dtype=float)\n",
        "        self.K = K\n",
        "        self.init = np.array(init, dtype=float)\n",
        "        self.beta = float(beta)\n",
        "        self.max_iter = max_iter\n",
        "        self.N = data.shape[0]  # データ数\n",
        "        self.I = data.shape[1]  # 次元数 今回は２\n",
        "        self.m = init  # クラスター中心の初期化．2×K行列．\n",
        "        self.r = np.zeros((K, self.N), dtype=float)  # 負担率．K×N行列．\n",
        "        self.history = [init.copy()] # クラスター中心の履歴．2×K行列．\n",
        "    \n",
        "    def soft_assigment(self):\n",
        "        \"\"\"soft K-means の場合の負担率の更新\"\"\"\n",
        "        for i in range(self.N):\n",
        "            distances = np.array([d(self.data[i], self.m[:,j]) ** 2 for j in range(self.K)]) # (N,)-numpy.ndarray\n",
        "            denominator_ = np.sum(np.exp(-self.beta * distances))  # 分母\n",
        "            self.r[:,i] = np.exp(- self.beta * distances) / denominator_\n",
        "\n",
        "    def hard_assigment(self):\n",
        "        \"\"\"hard K-means の場合の負担率の更新\"\"\"\n",
        "        for i in range(self.N):\n",
        "            distances = np.array([d(self.data[i], self.m[:,j]) for j in range(self.K)]) # (N,)-numpy.ndarray\n",
        "            k_hat = np.argmin(distances)  # 最小距離のクラスター番号\n",
        "            self.r[:,i] = 0  # 前のループの結果をリセット\n",
        "            self.r[k_hat,i] = 1\n",
        "    \n",
        "    def update(self):\n",
        "        \"\"\"クラスター中心の更新\"\"\"\n",
        "        new_m = np.zeros_like(self.m, dtype=float) # ここで float にしないと，クラスター中心が整数に限られてしまう．\n",
        "        numerator = np.dot(self.r, self.data)  # (K,2)-numpy.ndarray\n",
        "        denominator = np.sum(self.r, axis=1)  # 各クラスターの負担率の和\n",
        "        for k in range(self.K):\n",
        "            if denominator[k] > 0:\n",
        "                new_m[:,k] = numerator[k] / denominator[k]\n",
        "            else:\n",
        "                new_m[:,k] = self.m[:,k]\n",
        "        self.m = new_m\n",
        "\n",
        "    def fetch_cluster(self):\n",
        "        \"\"\"最終的なクラスター番号を格納した (N,)-array を返す\"\"\"\n",
        "        return np.argmax(self.r, axis=0)\n",
        "    \n",
        "    def fetch_history(self):\n",
        "        \"\"\"クラスター中心の履歴を格納したリストを，３次元の np.array に変換して返す\"\"\"\n",
        "        return np.stack(self.history, axis=0)\n",
        "\n",
        "    def run_soft(self):\n",
        "        \"\"\"soft K-means アルゴリズムの実行\"\"\"\n",
        "        for _ in range(self.max_iter):\n",
        "            self.soft_assigment()\n",
        "            self.update()\n",
        "            self.history.append(self.m.copy())\n",
        "            if np.allclose(self.history[-1], self.history[-2]):\n",
        "                break\n",
        "    \n",
        "    def run_hard(self):\n",
        "        \"\"\"hard K-means アルゴリズムの実行\"\"\"\n",
        "        for _ in range(self.max_iter):\n",
        "            self.hard_assigment()\n",
        "            self.update()\n",
        "            self.history.append(self.m.copy())\n",
        "            if np.allclose(self.history[-1], self.history[-2]):\n",
        "                break"
      ],
      "id": "5a08f071",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "なお，この実装は $\\beta\\ge500$ などの場合にオーバーフローが起こることに注意．これへの対処は `logsumexp` の使用などが考えられる．\n",
        "\n",
        ":::\n",
        "\n",
        "### 初期値依存性\n",
        "\n",
        "次の２つの初期値を与えてみる．\n",
        "$$\n",
        "m_1:=\\vctr{4}{0},\\quad m_2:=\\vctr{1}{4},\\quad m_3=\\vctr{-1}{1},\n",
        "$$\n",
        "と，$m_2,m_3$ は変えずに $m_1$ の $y$-座標を $1$ だけ下げたもの\n",
        "$$\n",
        "m_1':=\\vctr{4}{-1}\n",
        "$$\n",
        "とを初期値として与えてみる．\n"
      ],
      "id": "5cd903ed"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| label: fig-1\n",
        "#| fig-cap: ハード K-平均法によるクラスタリングの結果．初期値は $(m_1,m_2,m_3)=\\paren{\\vctr{4}{0},\\vctr{1}{4},\\vctr{-1}{1}}$．赤丸で囲まれている点がクラスター中心 (CoC / Center of Cluster) の初期値で，その後の移動が図示されている．\n",
        "initial_points = np.array([[-1,1],[1,4],[4,0]])\n",
        "\n",
        "result = kmeans_2d(data1_2d, 3, initial_points.T, 0.1)\n",
        "result.run_hard()\n",
        "pred = result.fetch_cluster()\n",
        "history = result.fetch_history()\n",
        "ans = data1.iloc[:, 0]\n",
        "\n",
        "markers_pred = normalize(pred)\n",
        "fig, axs = plt.subplots(1, 2, figsize=(7, 4))  # 1行2列のサブプロット\n",
        "\n",
        "# marker_predを使用したプロット\n",
        "for marker in np.unique(markers_pred):\n",
        "    axs[0].scatter(x1[markers_pred == marker], y1[markers_pred == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [2,1,0]\n",
        "default = [0,1,2]\n",
        "markerstyle = ['o', '^', 's']  # マーカーの形（丸、三角、正方形）\n",
        "for i,j in zip(rearrange, default):  # 点の数だけ繰り返し\n",
        "    x_coords = history[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[0].plot(x_coords, y_coords, linestyle='-', marker=markerstyle[j], label=f'CoC {j+1}', zorder=1)\n",
        "\n",
        "axs[0].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[0].set_title('Hard K-means')\n",
        "\n",
        "axs[0].legend()\n",
        "\n",
        "# markerを使用したプロット\n",
        "for marker in np.unique(markers1):\n",
        "    axs[1].scatter(x1[markers1 == marker], y1[markers1 == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "axs[1].set_title('Answer')\n",
        "\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "num_correct, accr = accuracy(ans, normalize(pred))\n",
        "iteration = history.shape[0]\n",
        "print(f'正解数: {num_correct}     正解率: {accr*100:.1f} %     反復数: {iteration} 回')"
      ],
      "id": "fig-1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "別の初期値を与えてみる（右下の点 $m_1$ を $1$ だけ下に下げただけ）：\n",
        "$$\n",
        "\\vctr{4}{0}=m_1\\mapsto m_1':=\\vctr{4}{-1}\n",
        "$$\n"
      ],
      "id": "0a45a24a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| label: fig-2\n",
        "#| fig-cap: ハード K-平均法によるクラスタリングの結果．初期値は $(m_1',m_2,m_3)=\\paren{\\vctr{4}{-1},\\vctr{1}{4},\\vctr{-1}{1}}$．\n",
        "\n",
        "initial_points = np.array([[-1,1],[1,4],[4,-1]])\n",
        "\n",
        "result = kmeans_2d(data1_2d, 3, initial_points.T, 0.1)\n",
        "result.run_hard()\n",
        "pred = result.fetch_cluster()\n",
        "history = result.fetch_history()\n",
        "ans = data1.iloc[:, 0]\n",
        "\n",
        "markers_pred = normalize(pred)\n",
        "fig, axs = plt.subplots(1, 2, figsize=(7, 4))  # 1行2列のサブプロット\n",
        "\n",
        "# marker_predを使用したプロット\n",
        "for marker in np.unique(markers_pred):\n",
        "    axs[0].scatter(x1[markers_pred == marker], y1[markers_pred == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [1,0,2]\n",
        "default = [0,1,2]\n",
        "markerstyle = ['o', '^', 's']  # マーカーの形（丸、三角、正方形）\n",
        "for i,j in zip(rearrange, default):  # 点の数だけ繰り返し\n",
        "    x_coords = history[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[0].plot(x_coords, y_coords, linestyle='-', marker=markerstyle[j], label=f'CoC {j+1}', zorder=1)\n",
        "\n",
        "axs[0].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[0].set_title('Hard K-means')\n",
        "\n",
        "axs[0].legend()\n",
        "\n",
        "# markerを使用したプロット\n",
        "for marker in np.unique(markers1):\n",
        "    axs[1].scatter(x1[markers1 == marker], y1[markers1 == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "axs[1].set_title('Answer')\n",
        "\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "center_2 = history[-1, :, :]\n",
        "\n",
        "num_correct, accr = accuracy(ans, normalize(pred))\n",
        "iteration = history.shape[0]\n",
        "print(f'正解数: {num_correct}     正解率: {accr*100:.1f} %     反復数: {iteration} 回')"
      ],
      "id": "fig-2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "結果が全く変わり，$(m_1',m_2,m_3)$ を与えた方が，大きく正解に近づいている．具体的には，右下の初期値 $m_1$ は右上の島に行くが，$m_1'$ は左下の島に行ってくれる．\n",
        "\n",
        "**ハード $K$-平均アルゴリズムは初期値に敏感である** ことがよく分かる．\n",
        "\n",
        "### 局所解への収束\n",
        "\n",
        "直前の結果[-@fig-2]ではクラスター２と３の境界線で４つのミスを犯しており，これを修正できないか試したい．\n",
        "\n",
        "そこで，答えに近いように，\n",
        "$$\n",
        "m_1\\gets\\vctr{2.5}{2},\\;\\; m_2\\gets\\vctr{-1}{-1},\\;\\; m_3\\gets\\vctr{1}{-2},\n",
        "$$\n",
        "を初期値として与えてみて，正答率の変化を観察する．\n"
      ],
      "id": "8fec4a2d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "initial_points = np.array([[-1,-1],[1,-2],[2.5,2]])\n",
        "result = kmeans_2d(data1_2d, 3, initial_points.T, 0.1)\n",
        "result.run_hard()\n",
        "pred = result.fetch_cluster()\n",
        "history = result.fetch_history()\n",
        "ans = data1.iloc[:, 0]\n",
        "\n",
        "markers_pred = normalize(pred)\n",
        "fig, axs = plt.subplots(1, 2, figsize=(7, 4))  # 1行2列のサブプロット\n",
        "\n",
        "# marker_predを使用したプロット\n",
        "for marker in np.unique(markers_pred):\n",
        "    axs[0].scatter(x1[markers_pred == marker], y1[markers_pred == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [2,0,1]\n",
        "default = [0,1,2]\n",
        "markerstyle = ['o', '^', 's']  # マーカーの形（丸、三角、正方形）\n",
        "for i,j in zip(rearrange, default):  # 点の数だけ繰り返し\n",
        "    x_coords = history[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[0].plot(x_coords, y_coords, linestyle='-', marker=markerstyle[j], label=f'CoC {j+1}', zorder=1)\n",
        "\n",
        "axs[0].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[0].set_title('Soft K-means with beta=1')\n",
        "\n",
        "axs[0].legend()\n",
        "\n",
        "# markerを使用したプロット\n",
        "for marker in np.unique(markers1):\n",
        "    axs[1].scatter(x1[markers1 == marker], y1[markers1 == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "axs[1].set_title('Answer')\n",
        "\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "num_correct, accr = accuracy(ans, normalize(pred))\n",
        "iteration = history.shape[0]\n",
        "print(f'正解数: {num_correct}     正解率: {accr*100:.1f} %     反復数: {iteration} 回')\n",
        "\n",
        "center1 = history[-1, :, :]"
      ],
      "id": "1ef7b9f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "もはや初期値から殆ど動いていないが，目標のクラスター３に分類された３つの点が，相変わらず３のままであり，加えてクラスター２の中心がこれらから逃げているようにも見えるので，クラスター２の初期値をよりクラスター３に近いように誘導し，クラスター３の中心をより右側から開始する：\n",
        "\n",
        "$$\n",
        "m_2:\\vctr{-1}{-1}\\mapsto\\vctr{0}{-2}\\;\\; m_3:\\vctr{1}{-2}\\mapsto\\vctr{2}{-2}\n",
        "$$\n"
      ],
      "id": "402b9f55"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "initial_points = np.array([[0,-2],[2,-2],[2.5,2]])\n",
        "result = kmeans_2d(data1_2d, 3, initial_points.T, 0.1)\n",
        "result.run_hard()\n",
        "pred = result.fetch_cluster()\n",
        "history = result.fetch_history()\n",
        "ans = data1.iloc[:, 0]\n",
        "\n",
        "markers_pred = normalize(pred)\n",
        "fig, axs = plt.subplots(1, 2, figsize=(7, 4))  # 1行2列のサブプロット\n",
        "\n",
        "# marker_predを使用したプロット\n",
        "for marker in np.unique(markers_pred):\n",
        "    axs[0].scatter(x1[markers_pred == marker], y1[markers_pred == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [2,0,1]\n",
        "default = [0,1,2]\n",
        "markerstyle = ['o', '^', 's']  # マーカーの形（丸、三角、正方形）\n",
        "for i,j in zip(rearrange, default):  # 点の数だけ繰り返し\n",
        "    x_coords = history[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[0].plot(x_coords, y_coords, linestyle='-', marker=markerstyle[j], label=f'CoC {j+1}', zorder=1)\n",
        "\n",
        "axs[0].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[0].set_title('Soft K-means with beta=1')\n",
        "\n",
        "axs[0].legend()\n",
        "\n",
        "# markerを使用したプロット\n",
        "for marker in np.unique(markers1):\n",
        "    axs[1].scatter(x1[markers1 == marker], y1[markers1 == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "axs[1].set_title('Answer')\n",
        "\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "num_correct, accr = accuracy(ans, normalize(pred))\n",
        "iteration = history.shape[0]\n",
        "print(f'正解数: {num_correct}     正解率: {accr*100:.1f} %     反復数: {iteration} 回')\n",
        "\n",
        "center2 = history[-1, :, :]"
      ],
      "id": "fc855d68",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "こんなに誘導をしても，正しく分類してくれない．\n",
        "\n",
        "実は，以上２つの初期値では，最終的に３つのクラスター中心は同じ値に収束している．よって，これ以上どのように初期値を変更しても，正答率は上がらないシナリオが考えられる．\n",
        "\n",
        "以上の観察から，ハード $K$-平均法はある種の **局所解に収束する** ようなアルゴリズムであると考えられる．\n",
        "\n",
        "## ソフト $K$-平均法\n",
        "\n",
        "### アルゴリズムの説明 {#sec-soft-k-means}\n",
        "\n",
        "ハード $K$-平均法[-@sec-hard-k-means]では，負担率\n",
        "$$\n",
        "r_{kn}\\gets\\delta_{k}(\\argmax_{i\\in[k]}d(m_i,x_n))\n",
        "$$\n",
        "は $0,1$ のいずれかの値しか取らなかった．この振る舞いを，\n",
        "$$\n",
        "\\sigma(z;e)_i:=\\frac{e^{z_i}}{\\sum_{j=1}^Ke^{e_j}}\\quad(i\\in[K])\n",
        "$$\n",
        "で定まる [**ソフトマックス関数**](https://ja.wikipedia.org/wiki/%E3%82%BD%E3%83%95%E3%83%88%E3%83%9E%E3%83%83%E3%82%AF%E3%82%B9%E9%96%A2%E6%95%B0) $\\sigma:\\R^K\\to(0,1)^K$ を用いて，「軟化」する．\n",
        "\n",
        "ここでは，$\\beta\\ge0$ として，\n",
        "$$\n",
        "\\sigma(z;e^{-\\beta})_i=\\frac{e^{-\\beta z_i}}{\\sum_{j=1}^Ke^{-\\beta e_j}}\n",
        "$$\n",
        "の形で用い，$\\argmax$ の代わりに\n",
        "$$\n",
        "\\begin{align*}\n",
        "    r_{kn}&\\gets\\sigma(d(-,x_n)^2\\circ m;e^{-\\beta})_k\\\\\n",
        "    &=\\frac{e^{-\\beta d(m_k,x_n)^2}}{\\sum_{j=1}^K e^{-\\beta d(m_j,x_n)^2}}\n",
        "\\end{align*}\n",
        "$$\n",
        "とする．ただし，$d$ は $\\R^2$ 上の Euclid 距離とした．\n",
        "\n",
        "#### 硬度パラメータ\n",
        "\n",
        "$\\beta$ は **硬度 (stiffness)** または逆温度と呼ぶ．^[stiffness の用語は [@MacKay2003 p.289] から．実は各クラスターに Gauss モデルを置いた場合の分散 $\\sigma^2$ に対して，$\\beta=\\frac{1}{2\\sigma^2}$ の関係がある．[次稿](VI2.qmd#sec-EM-and-K-means) 参照．] $\\sigma:=\\beta^{-1/2}$ は距離の次元を持つ．\n",
        "\n",
        "$\\beta=0$ のときは温度が無限大の場合にあたり，常に負担率は一様になる．絶対零度に当たる $\\beta\\to\\infty$ の極限が hard $K$-means アルゴリズムに相当する．\n",
        "\n",
        "逆温度 $\\beta$ を連続的に変化させることで，クラスタ数に分岐が起こる，ある種の相転移現象を見ることができる．^[[@MacKay2003 p.291]．]\n",
        "\n",
        "#### 実装\n",
        "\n",
        "実装は例えば hard $K$-means アルゴリズム[-@sec-hard-k-means]から，負担率計算の部分のみを変更すれば良い：\n",
        "\n",
        "```{.python}\n",
        "for i in range(N):\n",
        "        distances = np.array([d(data[i], m[:,k]) for k in range(K)]) # <1>\n",
        "        denominator_ = np.sum(np.exp(-beta * distances))  # <2>\n",
        "        r[:,i] = np.exp(-beta * distances) / denominator_ # <3>\n",
        "```\n",
        "1. データ $x_i$ とクラスター中心 $(m_k)_{k=1}^K$ との距離を計算し，ベクトル $(d(x_n,m_k))_{k=1}^K$ を `distances` に格納している．\n",
        "2. 負担率の計算\n",
        "$$\n",
        "r_{ik}=\\frac{\\exp(-\\beta d(m_k,x_i))}{\\sum_{j=1}^K\\exp(-\\beta d(m_j,x_i))}\n",
        "$$\n",
        "を２段階に分けて行なっており，分母を先に計算して変数 `denominator_` に格納している．\n",
        "3. すでに計算してある分母 `denominator_` を用いてデータ $x_i$ の負担率 $(r_{ki})_{k=1}^K$ を計算し，$(K,N)$-行列 `r` の各列に格納している．\n",
        "\n",
        "### 挙動の変化の観察\n",
        "\n",
        "逆温度をはじめに $\\beta=0.3$ としてみる．@fig-1 と全く同様な初期値\n",
        "$$\n",
        "m_1:=\\vctr{4}{0},\\quad m_2:=\\vctr{1}{4},\\quad m_3=\\vctr{-1}{1},\n",
        "$$\n",
        "を与えてみると，次の通りの結果を得る：\n"
      ],
      "id": "f5260428"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| label: fig-3\n",
        "#| fig-cap: 左がソフト K-平均法（$\\beta=1$），右がハード K-平均法によるクラスタリングの結果（図２の左と全く同じもの）．初期値は $(m_1,m_2,m_3)=\\paren{\\vctr{4}{0},\\vctr{1}{4},\\vctr{-1}{1}}$．赤丸で囲まれている点がクラスター中心 (CoC / Center of Cluster) の初期値で，その後の移動が図示されている．\n",
        "initial_points = np.array([[-1,1],[1,4],[4,0]])\n",
        "result = kmeans_2d(data1_2d, 3, initial_points.T, 0.3)\n",
        "result.run_soft()\n",
        "pred = result.fetch_cluster()\n",
        "history = result.fetch_history()\n",
        "ans = data1.iloc[:, 0]\n",
        "\n",
        "markers_pred = normalize(pred)\n",
        "\n",
        "result2 = kmeans_2d(data1_2d, 3, initial_points.T, 1)\n",
        "result2.run_hard()\n",
        "pred2 = result2.fetch_cluster()\n",
        "history2 = result2.fetch_history()\n",
        "\n",
        "markers_pred2 = normalize(pred2)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 4))  # 1行2列のサブプロット\n",
        "\n",
        "# marker_predを使用したプロット\n",
        "for marker in np.unique(markers_pred):\n",
        "    axs[0].scatter(x1[markers_pred == marker], y1[markers_pred == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [2,1,0]\n",
        "default = [0,1,2]\n",
        "markers = ['o', '^', 's']  # マーカーの形（丸、三角、正方形）\n",
        "for i,j in zip(rearrange, default):  # 点の数だけ繰り返し\n",
        "    x_coords = history[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[0].plot(x_coords, y_coords, linestyle='-', marker=markers[j], label=f'CoC {j+1}', zorder=1)\n",
        "\n",
        "axs[0].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[0].set_title('Soft K-means with beta=0.3')\n",
        "\n",
        "axs[0].legend()\n",
        "\n",
        "for marker in np.unique(markers_pred2):\n",
        "    axs[1].scatter(x1[markers_pred2 == marker], y1[markers_pred2 == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [2,1,0]\n",
        "default = [0,1,2]\n",
        "markers = ['o', '^', 's']  # マーカーの形（丸、三角、正方形）\n",
        "for i,j in zip(rearrange, default):  # 点の数だけ繰り返し\n",
        "    x_coords = history2[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history2[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[1].plot(x_coords, y_coords, linestyle='-', marker=markers[j], label=f'CoC {j+1}', zorder=1)\n",
        "\n",
        "axs[1].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[1].set_title('Hard K-means')\n",
        "\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "num_correct1, accr1 = accuracy(ans, normalize(pred))\n",
        "iteration = history.shape[0]\n",
        "num_correct2, accr2 = accuracy(ans, normalize(pred2))\n",
        "print(f'正解数: {num_correct1} vs. {num_correct2}     正解率: {accr1*100:.1f} % vs. {accr2*100:.1f} %     反復数: {history.shape[0]} 回 vs. {history2.shape[0]} 回')"
      ],
      "id": "fig-3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "クラスターの境界が変化しており，正解率は悪化している．さらに，反復数が９回であったところから，３倍に増えている（28回）．\n",
        "\n",
        "また，右上の２つのクラスター中心の収束先は，微妙にずれているが **ほとんど一致している** 点も注目に値する．\n",
        "\n",
        "::: {.callout-note icon=\"false\" title=\"参考：最終的なクラスター中心の座標\" collapse=\"true\"}\n",
        "```{.python}\n",
        "centers = history[-1, :, :]\n",
        "df = pd.DataFrame(centers, columns=['Cluster1', 'Cluster2', 'Cluster3'])\n",
        "print(df)\n",
        "```"
      ],
      "id": "e16976b5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "center3 = history[-1, :, :]\n",
        "df = pd.DataFrame(center3, columns=['Cluster1', 'Cluster2', 'Cluster3'])\n",
        "df = df[['Cluster3', 'Cluster2', 'Cluster1']]\n",
        "df.index = ['x', 'y']\n",
        "df.columns = ['Cluster1', 'Cluster2', 'Cluster3']\n",
        "print(df)"
      ],
      "id": "8cb93448",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "@fig-2 で与えた初期値 $(m_1',m_2,m_3)$ も与えてみる．\n"
      ],
      "id": "cf6d0529"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| label: fig-4\n",
        "#| fig-cap: ソフト K-平均法（$\\beta=1$）によるクラスタリングの結果，右がハード K-平均法によるクラスタリングの結果（図２の右と全く同じもの）．初期値は $(m_1',m_2,m_3)=\\paren{\\vctr{4}{-1},\\vctr{1}{4},\\vctr{-1}{1}}$．\n",
        "initial_points = np.array([[-1,1],[1,4],[4,-1]])\n",
        "result = kmeans_2d(data1_2d, 3, initial_points.T, 0.3)\n",
        "result.run_soft()\n",
        "pred = result.fetch_cluster()\n",
        "history = result.fetch_history()\n",
        "ans = data1.iloc[:, 0]\n",
        "\n",
        "markers_pred = normalize(pred)\n",
        "\n",
        "result2 = kmeans_2d(data1_2d, 3, initial_points.T, 1)\n",
        "result2.run_hard()\n",
        "pred2 = result2.fetch_cluster()\n",
        "history2 = result2.fetch_history()\n",
        "\n",
        "markers_pred2 = normalize(pred2)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(7, 4))  # 1行2列のサブプロット\n",
        "\n",
        "# marker_predを使用したプロット\n",
        "for marker in np.unique(markers_pred):\n",
        "    axs[0].scatter(x1[markers_pred == marker], y1[markers_pred == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [1,0,2]\n",
        "default = [0,1,2]\n",
        "markers = ['o', '^', 's']  # マーカーの形（丸、三角、正方形）\n",
        "for i,j in zip(rearrange, default):  # 点の数だけ繰り返し\n",
        "    x_coords = history[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[0].plot(x_coords, y_coords, linestyle='-', marker=markers[j], label=f'CoC {j+1}', zorder=1)\n",
        "\n",
        "axs[0].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[0].set_title('Soft K-means with beta=0.3')\n",
        "\n",
        "axs[0].legend()\n",
        "\n",
        "for marker in np.unique(markers_pred2):\n",
        "    axs[1].scatter(x1[markers_pred2 == marker], y1[markers_pred2 == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [1,0,2]\n",
        "default = [0,1,2]\n",
        "markers = ['o', '^', 's']  # マーカーの形（丸、三角、正方形）\n",
        "for i,j in zip(rearrange, default):  # 点の数だけ繰り返し\n",
        "    x_coords = history2[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history2[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[1].plot(x_coords, y_coords, linestyle='-', marker=markers[j], label=f'CoC {j+1}', zorder=1)\n",
        "\n",
        "axs[1].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[1].set_title(\"Hard K-means\")\n",
        "\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "num_correct1, accr1 = accuracy(ans, normalize_abnormal(pred))\n",
        "iteration = history.shape[0]\n",
        "num_correct2, accr2 = accuracy(ans, normalize(pred2))\n",
        "print(f'正解数: {num_correct1} vs. {num_correct2}     正解率: {accr1*100:.1f} % vs. {accr2*100:.1f} %     反復数: {history.shape[0]} 回 vs. {history2.shape[0]} 回')"
      ],
      "id": "fig-4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "クラスター境界と正答率は変わらないが，反復数がやはり７回から大きく増えている．\n",
        "\n",
        "結果はやはり @fig-3 とは大きく異なっており，ハード $K$-平均法で観察された初期値鋭敏性が，変わらず残っている．\n",
        "\n",
        "加えてこの場合も @fig-3 のクラスター１と２と同様に，クラスター２と３の中心がほぼ一致している．\n",
        "\n",
        "::: {.callout-note icon=\"false\" title=\"参考：最終的なクラスター中心の座標\" collapse=\"true\"}"
      ],
      "id": "bf9009ed"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "center4 = history[-1, :, :]\n",
        "df = pd.DataFrame(center4, columns=['Cluster1', 'Cluster2', 'Cluster3'])\n",
        "df = df[['Cluster2', 'Cluster1', 'Cluster3']]\n",
        "df.index = ['x', 'y']\n",
        "df.columns = ['Cluster1', 'Cluster2', 'Cluster3']\n",
        "print(df)"
      ],
      "id": "737b125b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "$\\beta=0.3$ の場合のソフト $K$-平均法は，この例では **クラスター中心が融合する傾向にある** ようである．\n",
        "\n",
        "一般に，$\\beta$ が小さく，温度が大きいほど，エネルギーランドスケープに極小点が少なくなり，クラスターは同じ場所へ収束しやすくなると予想される．\n",
        "\n",
        "### 高温になるほどクラスター数は減少する\n",
        "\n",
        "初期値を直前で用いた\n",
        "$$\n",
        "m_1\\gets\\vctr{4}{-1},\\quad m_2\\gets\\vctr{1}{4},\\quad m_3\\gets\\vctr{-1}{1},\n",
        "$$\n",
        "で固定とし，さらに温度を上げて，逆温度を $\\beta=0.1$ としてみる．\n"
      ],
      "id": "8d5311e8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| label: fig-5\n",
        "#| fig-cap: ソフト K-平均法（左$\\beta=0.1$，右$\\beta=1$）によるクラスタリングの結果．初期値は $(m_1',m_2,m_3)=\\paren{\\vctr{4}{-1},\\vctr{1}{4},\\vctr{-1}{1}}$．\n",
        "initial_points = np.array([[-1,1],[1,4],[4,-1]])\n",
        "result = kmeans_2d(data1_2d, 3, initial_points.T, 0.1)\n",
        "result.run_soft()\n",
        "pred = result.fetch_cluster()\n",
        "history = result.fetch_history()\n",
        "ans = data1.iloc[:, 0]\n",
        "\n",
        "markers_pred = normalize(pred)\n",
        "\n",
        "result2 = kmeans_2d(data1_2d, 3, initial_points.T, 0.3)\n",
        "result2.run_soft()\n",
        "pred2 = result2.fetch_cluster()\n",
        "history2 = result2.fetch_history()\n",
        "\n",
        "markers_pred2 = normalize(pred2)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(7, 4))  # 1行2列のサブプロット\n",
        "\n",
        "# marker_predを使用したプロット\n",
        "for marker in np.unique(markers_pred):\n",
        "    axs[0].scatter(x1[markers_pred == marker], y1[markers_pred == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [1,0,2]\n",
        "default = [0,1,2]\n",
        "markers = ['o', '^', 's']  # マーカーの形（丸、三角、正方形）\n",
        "for i,j in zip(rearrange, default):  # 点の数だけ繰り返し\n",
        "    x_coords = history[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[0].plot(x_coords, y_coords, linestyle='-', marker=markers[j], label=f'CoC {j+1}', zorder=1)\n",
        "\n",
        "axs[0].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[0].set_title('Soft K-means with beta=0.1')\n",
        "\n",
        "axs[0].legend()\n",
        "\n",
        "for marker in np.unique(markers_pred2):\n",
        "    axs[1].scatter(x1[markers_pred2 == marker], y1[markers_pred2 == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [1,0,2]\n",
        "default = [0,1,2]\n",
        "markers = ['o', '^', 's']  # マーカーの形（丸、三角、正方形）\n",
        "for i,j in zip(rearrange, default):  # 点の数だけ繰り返し\n",
        "    x_coords = history2[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history2[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[1].plot(x_coords, y_coords, linestyle='-', marker=markers[j], label=f'CoC {j+1}', zorder=1)\n",
        "\n",
        "axs[1].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[1].set_title('Soft K-means with beta=0.3')\n",
        "\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "num_correct1, accr1 = accuracy(ans, normalize(pred))\n",
        "iteration = history.shape[0]\n",
        "num_correct2, accr2 = accuracy(ans, normalize_abnormal(pred2))\n",
        "print(f'正解数: {num_correct1} vs. {num_correct2}     正解率: {accr1*100:.1f} % vs. {accr2*100:.1f} %     反復数: {history.shape[0]} 回 vs. {history2.shape[0]} 回')"
      ],
      "id": "fig-5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "反復数はさらに増加し，全てがほとんど同じクラスターに属する結果となってしまった．\n",
        "\n",
        "::: {.callout-note icon=\"false\" title=\"参考：最終的なクラスター中心の座標\" collapse=\"true\"}"
      ],
      "id": "3fee1414"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "center5 = history[-1, :, :]\n",
        "df = pd.DataFrame(center5, columns=['Cluster1', 'Cluster2', 'Cluster3'])\n",
        "df = df[['Cluster2', 'Cluster1', 'Cluster3']]\n",
        "df.index = ['x', 'y']\n",
        "df.columns = ['Cluster1', 'Cluster2', 'Cluster3']\n",
        "print(df)"
      ],
      "id": "5547fad1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "温度が大変に高い状態では，全てが乱雑で，３つのクラスターが一様・公平に負担率を持つようになった．そのため，第一歩からほとんど全体の中心へと移動し，反復数が減る．\n",
        "\n",
        "次に，温度を少し下げて，逆温度を $\\beta=2$ としてみる．\n"
      ],
      "id": "e822b34e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| label: fig-6\n",
        "#| fig-cap: ソフト K-平均法（左$\\beta=10$，右$\\beta=1$）によるクラスタリングの結果．初期値は $(m_1',m_2,m_3)=\\paren{\\vctr{4}{-1},\\vctr{1}{4},\\vctr{-1}{1}}$．\n",
        "initial_points = np.array([[-1,1],[1,4],[4,-1]])\n",
        "result = kmeans_2d(data1_2d, 3, initial_points.T, 2)\n",
        "result.run_soft()\n",
        "pred = result.fetch_cluster()\n",
        "history = result.fetch_history()\n",
        "ans = data1.iloc[:, 0]\n",
        "\n",
        "markers_pred = normalize(pred)\n",
        "\n",
        "result2 = kmeans_2d(data1_2d, 3, initial_points.T, 0.3)\n",
        "result2.run_soft()\n",
        "pred2 = result2.fetch_cluster()\n",
        "history2 = result2.fetch_history()\n",
        "\n",
        "markers_pred2 = normalize(pred2)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(7, 4))  # 1行2列のサブプロット\n",
        "\n",
        "# marker_predを使用したプロット\n",
        "for marker in np.unique(markers_pred):\n",
        "    axs[0].scatter(x1[markers_pred == marker], y1[markers_pred == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [1,0,2]\n",
        "default = [0,1,2]\n",
        "markers = ['o', '^', 's']  # マーカーの形（丸、三角、正方形）\n",
        "for i,j in zip(rearrange, default):  # 点の数だけ繰り返し\n",
        "    x_coords = history[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[0].plot(x_coords, y_coords, linestyle='-', marker=markers[j], label=f'CoC {j+1}', zorder=1)\n",
        "\n",
        "axs[0].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[0].set_title('Soft K-means with beta=2')\n",
        "\n",
        "axs[0].legend()\n",
        "\n",
        "for marker in np.unique(markers_pred2):\n",
        "    axs[1].scatter(x1[markers_pred2 == marker], y1[markers_pred2 == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [1,0,2]\n",
        "default = [0,1,2]\n",
        "markers = ['o', '^', 's']  # マーカーの形（丸、三角、正方形）\n",
        "for i,j in zip(rearrange, default):  # 点の数だけ繰り返し\n",
        "    x_coords = history2[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history2[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[1].plot(x_coords, y_coords, linestyle='-', marker=markers[j], label=f'CoC {j+1}', zorder=1)\n",
        "\n",
        "axs[1].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[1].set_title('Soft K-means with beta=0.3')\n",
        "\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "num_correct1, accr1 = accuracy(ans, normalize(pred))\n",
        "iteration = history.shape[0]\n",
        "num_correct2, accr2 = accuracy(ans, normalize_abnormal(pred2))\n",
        "print(f'正解数: {num_correct1} vs. {num_correct2}     正解率: {accr1*100:.1f} % vs. {accr2*100:.1f} %     反復数: {history.shape[0]} 回 vs. {history2.shape[0]} 回')"
      ],
      "id": "fig-6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "初めて soft $K$-means アルゴリズムを用いた場合で，３つのクラスター中心がはっきりと別れた．反復回数は，$\\beta=0.3$ の場合と比べればやはり落ち着いている．\n",
        "\n",
        "しかし，正解率は head $K$-means の場合（ @fig-2 など）と全く同じである．実は，最終的なクラスター中心も @fig-2 の最終的なクラスター中心とほとんど同じになっている．\n",
        "\n",
        "::: {.callout-note icon=\"false\" title=\"参考：最終的なクラスター中心の座標\" collapse=\"true\"}\n",
        "\n",
        "**今回のソフト $K$-平均法の最終的なクラスター中心**\n"
      ],
      "id": "8255095f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "center6 = history[-1, :, :]\n",
        "df1 = pd.DataFrame(center6, columns=['Cluster1', 'Cluster2', 'Cluster3'])\n",
        "df1 = df1[['Cluster2', 'Cluster3', 'Cluster1']]\n",
        "df1.index = ['x', 'y']\n",
        "df1.columns = ['Cluster1', 'Cluster2', 'Cluster3']\n",
        "print(df1)"
      ],
      "id": "df16b67f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "@fig-2 のハード $K$-平均法の最終的なクラスター中心\n"
      ],
      "id": "a8cb2de1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "df2 = pd.DataFrame(center_2, columns=['Cluster1', 'Cluster2', 'Cluster3'])\n",
        "df2 = df2[['Cluster2', 'Cluster3', 'Cluster1']]\n",
        "df2.index = ['x', 'y']\n",
        "df2.columns = ['Cluster1', 'Cluster2', 'Cluster3']\n",
        "print(df2)"
      ],
      "id": "5d7be49d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "以上より，ソフト $K$-平均法は温度を上げるほどクラスター数が少なくなり，温度を下げるほどクラスター数は上がり，**十分に温度を下げるとハード $K$-平均法に挙動が似通う**．\n",
        "\n",
        "### 最適な硬度の選択\n",
        "\n",
        "$\\beta=0.2$ ではクラスターが２つに縮退し，$\\beta=1$ では hard $K$-means アルゴリズムの結果とほとんど変わらなくなる．その中間では次のように挙動が変わる：\n"
      ],
      "id": "4d5a6f0b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| label: fig-7\n",
        "#| fig-cap: ソフト K-平均法によるクラスタリングの結果の比較（$\\beta=0.2$ vs. $\\beta=0.25$）．\n",
        "initial_points = np.array([[-1,1],[1,4],[4,-1]])\n",
        "result1 = kmeans_2d(data1_2d, 3, initial_points.T, 0.2)\n",
        "result2 = kmeans_2d(data1_2d, 3, initial_points.T, 0.25)\n",
        "result1.run_soft()\n",
        "result2.run_soft()\n",
        "pred1 = result1.fetch_cluster()\n",
        "pred2 = result2.fetch_cluster()\n",
        "history1 = result1.fetch_history()\n",
        "history2 = result2.fetch_history()\n",
        "ans = data1.iloc[:, 0]\n",
        "\n",
        "markers_pred1 = normalize(pred1)\n",
        "markers_pred2 = normalize(pred2)\n",
        "fig, axs = plt.subplots(1, 2, figsize=(7, 4))  # 1行2列のサブプロット\n",
        "\n",
        "# marker_predを使用したプロット\n",
        "for marker in np.unique(markers_pred1):\n",
        "    axs[0].scatter(x1[markers_pred1 == marker], y1[markers_pred1 == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [1,2,0]\n",
        "markers = ['o', '^', 's']  # マーカーの形（丸、三角、正方形）\n",
        "for i in rearrange:  # 点の数だけ繰り返し\n",
        "    x_coords = history1[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history1[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[0].plot(x_coords, y_coords, linestyle='-', marker=markers[2-i], label=f'CoC {3-i}', zorder=1)\n",
        "\n",
        "axs[0].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[0].set_title('Soft K-means with beta=0.2')\n",
        "\n",
        "axs[0].legend()\n",
        "\n",
        "\n",
        "# marker_predを使用したプロット\n",
        "for marker in np.unique(markers_pred2):\n",
        "    axs[1].scatter(x1[markers_pred2 == marker], y1[markers_pred2 == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [1,0,2]\n",
        "for i in rearrange:  # 点の数だけ繰り返し\n",
        "    x_coords = history2[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history2[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[1].plot(x_coords, y_coords, linestyle='-', marker=markers[2-i], label=f'CoC {3-i}', zorder=1)\n",
        "\n",
        "axs[1].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[1].set_title('Soft K-means with beta=0.25')\n",
        "\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "num_correct1, accr1 = accuracy(ans, normalize_abnormal(pred1))\n",
        "num_correct2, accr2 = accuracy(ans, normalize_abnormal(pred2))\n",
        "print(f'正解数: {num_correct1} vs. {num_correct2}')\n",
        "print(f'正解率: {accr1*100:.1f} % vs. {accr2*100:.1f} %')"
      ],
      "id": "fig-7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| label: fig-8\n",
        "#| fig-cap: ソフト K-平均法によるクラスタリングの結果の比較（$\\beta=0.3$ vs. $\\beta=0.5$）．\n",
        "initial_points = np.array([[-1,1],[1,4],[4,-1]])\n",
        "result1 = kmeans_2d(data1_2d, 3, initial_points.T, 0.3)\n",
        "result2 = kmeans_2d(data1_2d, 3, initial_points.T, 0.5)\n",
        "result1.run_soft()\n",
        "result2.run_soft()\n",
        "pred1 = result1.fetch_cluster()\n",
        "pred2 = result2.fetch_cluster()\n",
        "history1 = result1.fetch_history()\n",
        "history2 = result2.fetch_history()\n",
        "ans = data1.iloc[:, 0]\n",
        "\n",
        "markers_pred1 = normalize(pred1)\n",
        "markers_pred2 = normalize(pred2)\n",
        "fig, axs = plt.subplots(1, 2, figsize=(7, 4))  # 1行2列のサブプロット\n",
        "\n",
        "# marker_predを使用したプロット\n",
        "for marker in np.unique(markers_pred1):\n",
        "    axs[0].scatter(x1[markers_pred1 == marker], y1[markers_pred1 == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [1,0,2]\n",
        "default = [0,1,2]\n",
        "markers = ['o', '^', 's']  # マーカーの形（丸、三角、正方形）\n",
        "for i,j in zip(rearrange, default):  # 点の数だけ繰り返し\n",
        "    x_coords = history1[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history1[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[0].plot(x_coords, y_coords, linestyle='-', marker=markers[j], label=f'CoC {j+1}', zorder=1)\n",
        "\n",
        "axs[0].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[0].set_title('Soft K-means with beta=0.3')\n",
        "\n",
        "axs[0].legend()\n",
        "\n",
        "\n",
        "# marker_predを使用したプロット\n",
        "for marker in np.unique(markers_pred2):\n",
        "    axs[1].scatter(x1[markers_pred2 == marker], y1[markers_pred2 == marker], label=f'Cluster {marker}', marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [1,0,2]\n",
        "for i,j in zip(rearrange, default):  # 点の数だけ繰り返し\n",
        "    x_coords = history2[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history2[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[1].plot(x_coords, y_coords, linestyle='-', marker=markers[j], label=f'CoC {j+1}', zorder=1)\n",
        "\n",
        "axs[1].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[1].set_title('Soft K-means with beta=0.5')\n",
        "\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "num_correct1, accr1 = accuracy(ans, normalize_abnormal(pred1))\n",
        "num_correct2, accr2 = accuracy(ans, normalize(pred2))\n",
        "print(f'正解数: {num_correct1} vs. {num_correct2}')\n",
        "print(f'正解率: {accr1*100:.1f} % vs. {accr2*100:.1f} %')"
      ],
      "id": "fig-8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "やはり，温度が高い場合はクラスター中心が合流・融合してしまいやすいが，冷却することでクラスター数は大きい状態で安定する，と言えるだろう．\n",
        "\n",
        "## 本番データセットでの実験\n",
        "\n",
        "今まで使っていたデータ[-@sec-data]はクラスターのオーバーラップはなかったため，いわば優しいデータであった．ここからはよりデータ生成過程が複雑なデータを用いて，ソフト $K$-平均法の挙動を観察する．\n",
        "\n",
        "### データの概観 {#sec-data2}\n",
        "\n",
        "今度は，次の４クラスのデータを用いる．\n"
      ],
      "id": "c1378d61"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "data2_unsorted = pd.read_csv('mixture2.dat', delimiter=\"\\t\" , header=None)\n",
        "data2 = data2_unsorted.sort_values(by=0, ascending=True)\n",
        "data2_2d = data2.iloc[:, 1:3].to_numpy()\n",
        "\n",
        "markers2 = data2.iloc[:, 0]\n",
        "x2 = data2.iloc[:, 1]\n",
        "y2 = data2.iloc[:, 2]\n",
        "\n",
        "plt.figure(figsize=(3.5, 3))\n",
        "for marker in np.unique(markers2):\n",
        "    plt.scatter(x2[markers2 == marker], y2[markers2 == marker], label=f'Cluster {marker}', marker=f'${marker}$') \n",
        "\n",
        "plt.title('Scatter Plot of the Data')\n",
        "plt.show()"
      ],
      "id": "f1b7dada",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "実は，これは４つの Gauss 分布から生成されたデータである．\n",
        "\n",
        "### 最適な温度の選択\n"
      ],
      "id": "e6703d50"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "initial_points = np.array([[1,6],[6,-1],[1,-8],[-4,-1]])\n",
        "result1 = kmeans_2d(data2_2d, 4, initial_points.T, 0.1)\n",
        "result2 = kmeans_2d(data2_2d, 4, initial_points.T, 0.15)\n",
        "result1.run_soft()\n",
        "result2.run_soft()\n",
        "pred1 = result1.fetch_cluster()\n",
        "pred2 = result2.fetch_cluster()\n",
        "history1 = result1.fetch_history()\n",
        "history2 = result2.fetch_history()\n",
        "ans = data2.iloc[:, 0]\n",
        "\n",
        "markers_pred1 = normalize(pred1)\n",
        "markers_pred2 = normalize(pred2)\n",
        "fig, axs = plt.subplots(1, 2, figsize=(7, 4))  # 1行2列のサブプロット\n",
        "\n",
        "# marker_predを使用したプロット\n",
        "for marker in np.unique(markers_pred1):\n",
        "    axs[0].scatter(x2[markers_pred1 == marker], y2[markers_pred1 == marker], marker=f'${marker}$', alpha=0.3),  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [0,1,2,3]\n",
        "default = [0,1,2,3]\n",
        "labels = [2,1,3,2]\n",
        "markers = ['o', '^', 's', '*']\n",
        "colors = ['orange', 'blue', 'green', 'orange']\n",
        "for i,j,k in zip(rearrange, default, labels):  # 点の数だけ繰り返し\n",
        "    x_coords = history1[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history1[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[0].plot(x_coords, y_coords, color=colors[j], linestyle='-', marker=markers[j], label=f'CoC {k}', zorder=1)\n",
        "\n",
        "axs[0].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[0].set_title('Soft K-means with beta=0.1')\n",
        "axs[0].legend()\n",
        "\n",
        "\n",
        "# marker_predを使用したプロット\n",
        "for marker in np.unique(markers_pred2):\n",
        "    axs[1].scatter(x2[markers_pred2 == marker], y2[markers_pred2 == marker], marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [1,0,3,2]\n",
        "for i,j in zip(rearrange, default):  # 点の数だけ繰り返し\n",
        "    x_coords = history1[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history1[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[1].plot(x_coords, y_coords, linestyle='-', marker=markers[j], label=f'CoC {j+1}', zorder=1)\n",
        "\n",
        "axs[1].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[1].set_title('Soft K-means with beta=0.15')\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "num_correct1, accr1 = accuracy4(ans, normalize(pred1))\n",
        "num_correct2, accr2 = accuracy4(ans, normalize(pred2))\n",
        "iteration1 = history1.shape[0]\n",
        "iteration2 = history2.shape[0]"
      ],
      "id": "13bdf125",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "result1 = kmeans_2d(data2_2d, 4, initial_points.T, 0.2)\n",
        "result2 = kmeans_2d(data2_2d, 4, initial_points.T, 0.3)\n",
        "result1.run_soft()\n",
        "result2.run_soft()\n",
        "pred1 = result1.fetch_cluster()\n",
        "pred2 = result2.fetch_cluster()\n",
        "history1 = result1.fetch_history()\n",
        "history2 = result2.fetch_history()\n",
        "ans = data2.iloc[:, 0]\n",
        "\n",
        "markers_pred1 = normalize(pred1)\n",
        "markers_pred2 = normalize(pred2)\n",
        "fig, axs = plt.subplots(1, 2, figsize=(7, 4))  # 1行2列のサブプロット\n",
        "\n",
        "# marker_predを使用したプロット\n",
        "for marker in np.unique(markers_pred1):\n",
        "    axs[0].scatter(x2[markers_pred1 == marker], y2[markers_pred1 == marker], marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [1,0,3,2]\n",
        "default = [0,1,2,3]\n",
        "markers = ['o', '^', 's', '*']\n",
        "for i,j in zip(rearrange, default):  # 点の数だけ繰り返し\n",
        "    x_coords = history1[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history1[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[0].plot(x_coords, y_coords, linestyle='-', marker=markers[j], label=f'CoC {j+1}', zorder=1)\n",
        "\n",
        "axs[0].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[0].set_title('Soft K-means with beta=0.2')\n",
        "axs[0].legend()\n",
        "\n",
        "\n",
        "# marker_predを使用したプロット\n",
        "for marker in np.unique(markers_pred2):\n",
        "    axs[1].scatter(x2[markers_pred2 == marker], y2[markers_pred2 == marker], marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "for i,j in zip(rearrange, default):  # 点の数だけ繰り返し\n",
        "    x_coords = history2[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history2[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[1].plot(x_coords, y_coords, linestyle='-', marker=markers[j], label=f'CoC {j+1}', zorder=1)\n",
        "\n",
        "axs[1].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[1].set_title('Soft K-means with beta=0.3')\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "num_correct3, accr3 = accuracy4(ans, normalize(pred1))\n",
        "num_correct4, accr4 = accuracy4(ans, normalize(pred2))\n",
        "iteration3 = history1.shape[0]\n",
        "iteration4 = history2.shape[0]"
      ],
      "id": "31d611c4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "result1 = kmeans_2d(data2_2d, 4, initial_points.T, 0.5)\n",
        "result2 = kmeans_2d(data2_2d, 4, initial_points.T, 1)\n",
        "result1.run_soft()\n",
        "result2.run_hard()\n",
        "pred1 = result1.fetch_cluster()\n",
        "pred2 = result2.fetch_cluster()\n",
        "history1 = result1.fetch_history()\n",
        "history2 = result2.fetch_history()\n",
        "ans = data2.iloc[:, 0]\n",
        "\n",
        "markers_pred1 = normalize(pred1)\n",
        "markers_pred2 = normalize(pred2)\n",
        "fig, axs = plt.subplots(1, 2, figsize=(7, 4))  # 1行2列のサブプロット\n",
        "\n",
        "# marker_predを使用したプロット\n",
        "for marker in np.unique(markers_pred1):\n",
        "    axs[0].scatter(x2[markers_pred1 == marker], y2[markers_pred1 == marker], marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "rearrange = [1,0,3,2]\n",
        "default = [0,1,2,3]\n",
        "markers = ['o', '^', 's', '*']\n",
        "for i,j in zip(rearrange, default):  # 点の数だけ繰り返し\n",
        "    x_coords = history1[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history1[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[0].plot(x_coords, y_coords, linestyle='-', marker=markers[j], label=f'CoC {j+1}', zorder=1)\n",
        "\n",
        "axs[0].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[0].set_title('Soft K-means with beta=0.5')\n",
        "axs[0].legend()\n",
        "\n",
        "\n",
        "# marker_predを使用したプロット\n",
        "for marker in np.unique(markers_pred2):\n",
        "    axs[1].scatter(x2[markers_pred2 == marker], y2[markers_pred2 == marker], marker=f'${marker}$', alpha=0.3)  # markerパラメータによって形状を指定\n",
        "\n",
        "for i,j in zip(rearrange, default):  # 点の数だけ繰り返し\n",
        "    x_coords = history2[:, 0, i]  # i番目の点の全時点でのx座標\n",
        "    y_coords = history2[:, 1, i]  # i番目の点の全時点でのy座標\n",
        "    axs[1].plot(x_coords, y_coords, linestyle='-', marker=markers[j], label=f'CoC {j+1}', zorder=1)\n",
        "\n",
        "axs[1].scatter(initial_points[:, 0], initial_points[:, 1], facecolors='none', edgecolors='red', s=100, zorder=2)\n",
        "\n",
        "axs[1].set_title('Hard K-means')\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "num_correct5, accr5 = accuracy4(ans, normalize(pred1))\n",
        "num_correct6, accr6 = accuracy4(ans, normalize(pred2))\n",
        "iteration5 = history1.shape[0]\n",
        "iteration6 = history2.shape[0]"
      ],
      "id": "aa71b98a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "print(f'正解数: {num_correct1} vs. {num_correct2}     正解率: {accr1*100:.1f} % vs. {accr2*100:.1f} %     反復数: {iteration1} 回 vs. {iteration2} 回')\n",
        "print(f'正解数: {num_correct3} vs. {num_correct4}     正解率: {accr3*100:.1f} % vs. {accr4*100:.1f} %     反復数: {iteration3} 回 vs. {iteration4} 回')\n",
        "print(f'正解数: {num_correct5} vs. {num_correct6}     正解率: {accr5*100:.1f} % vs. {accr6*100:.1f} %     反復数: {iteration5} 回 vs. {iteration6} 回')"
      ],
      "id": "fca70af8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 実験結果まとめ {#sec-result}\n",
        "\n",
        "::: {.callout-note icon=\"false\" title=\"結論\"}\n",
        "* データ [-@sec-data] に対して，（初期値 $(m'_1,m_2,m_3)$ で）ソフト $K$-平均法を適用すると，\n",
        "  * $\\beta\\ge2$ の場合で結果はハード $K$-平均法と変わらなくなる．\n",
        "  * $\\beta=1$ の場合で結果はクラスターがほとんど２つになり，$\\beta\\le0.5$ では計算機上では実際に２つになってしまう．\n",
        "  * 正答率は $1\\le\\beta\\le1.1$ で最大であった．\n",
        "  * $\\beta$ を大きくするほど，反復回数は減少していった．\n",
        "* データ [-@sec-data2] に対しても，以上の４点について同様の傾向が確認できた．\n",
        ":::\n",
        "\n",
        "こうしてソフト $K$-平均法とハード $K$-平均法の性質は分かった．主に\n",
        "\n",
        "1. 初期値依存性\n",
        "2. クラスタ数 $K$ の選択法\n",
        "\n",
        "の問題が未解決であり，恣意性が残る．\n",
        "\n",
        "これを，ベイズ混合モデリングにより解決する方法を[次稿](VI2.qmd)で紹介する．"
      ],
      "id": "527707e1"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/hirofumi48/Library/Jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}