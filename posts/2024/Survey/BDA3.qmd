---
title: "ベイズデータ解析７"
subtitle: "ベイズ階層モデル"
author: "司馬博文"
date: 12/12/2024
date-modified: 12/13/2024
categories: [Bayesian, Statistics]
bibliography: 
    - ../../../assets/mathematics.bib
    - ../../../assets/bib.bib
    - ../../../assets/bib1.bib
csl: ../../../assets/apalike.csl
abstract-title: 概要
abstract: |
    データが自然な階層構造を持つ場合，これを取り入れた自然な事前分布を，一つ上の階層に回帰モデルを付け加えることで構成できる．
    このようなモデルをベイズ階層モデルという．
    本稿ではベイズ階層モデルの縮小効果を概観する．
    事前知識を構造に関する知識としてモデルに取り入れることでデータによりフィットする尤度構造を獲得することは，データ解析の一つの目標として，（線型）回帰モデルの自然な拡張と理解できる．
keywords: [変動係数モデル, Mixed-effects model, NER model, 分散成分モデル, Fay-Herriot model, Two-way (crossed) classification model, 項目応答モデル, Rasch model]
# image: Files/BayesianWorkflow.svg
listing: 
    -   id: lst-survey
        type: grid
        sort: false
        contents:
            - "BDA1.qmd"
            - "../Lifestyle/FixedRandom.qmd"
            - "../Kernels/HierarchicalModel.qmd"
        date-format: iso
        fields: [title,image,date,subtitle]
    -   id: lst-regression
        type: grid
        sort: false
        contents:
            - "BayesRegression.qmd"
            - "BDA1.qmd"
            - "BDA2.qmd"
        date-format: iso
        fields: [title,image,date,subtitle]
    -   id: lst-embed
        type: grid
        grid-columns: 1
        contents:
            - "../Computation/brms.qmd"
        date-format: iso
        fields: [title,image,date,subtitle]
---

{{< include ../../../assets/_preamble.qmd >}}

## 関連記事 {.unnumbered .unlisted}

::: {#lst-survey}
:::

## はじめに

### 階層モデル

データが自然な **階層構造** を持つとする．例えば標本がクラスター抽出された場合，パネルデータや経時的繰り返し観測による標本，共変量統制とマッチングなど，自然な階層構造を持つデータは多い．

このようなデータに対して，個々のサブグループに対して全く同じ回帰モデルを繰り返し適用し，結果のプロットを小窓に分割して並べることで，グループごとの効果の違いを比較することができる．

この方法はナイーブながらも有力で，[10.9 節 @Gelman-Hill-Vehtari2020 p.148] では "secret weapon" と呼んでいる．

この別々の回帰モデルはベイズ的に統合して推論することができる．このグループごとに変動する係数を許したモデルが（ベイズ）**階層モデル** である．

### いつ使うか？

線型回帰の枠組みで交差項を入れることで，グループごとに緩やかに異なる回帰係数を許すことができる．

さらには一般化線型モデルを用いることで，連続・離散データの簡単な非線型関係まで扱うことができる．

::: {#lst-regression}
:::

それでも階層モデルに進む動機として次のような点が挙げられる：

::: {.callout-important icon="false" title="階層モデルの美点^[[11.5 節 @Gelman-Hill2006 p.246] も参照．]"}

1. 説明変数が多すぎる場合は馬蹄事前分布などの構造を持った事前分布が使用可能である．しかしデータが階層構造を持つ場合は，その構造に関する事前知識を用いて，自然な事前分布を組織的に導入することができる．これが階層モデリングに他ならないとも見れる．その結果大量の説明変数がある場合でも，その関連度をモデルに知らせて適切に推定する方法にもなる^[一般に階層モデルは，全ての説明変数を組み込んだモデルから，特定の係数の部分集合を括り出し，その部分集合に super-population model を仮定したものと見れる．[13.6 節 @Gelman-Hill2006 p.296] の議論も参照．]．
2. 単一のグループではデータ数が小さい場合に，グループレベルの回帰係数 $\al_{j[i]}$ を安定して推定する手法とも理解できる．他のグループの回帰モデルと組み合わせた大きな階層モデルをベイズすることで，確度が低い（が関連する）モデルも捨てずに推定に利用するため (partial pooling)，より好ましい統計的推定を実行できる．これは **縮小推定** のキーワードの下でも追及されており，階層モデルは自然な縮小推定が実行される典型的な設定である．^[例えば小地域推定においては極めて自然なモデルである [@久保川達也2006], [@菅澤-久保川2023] も参照．]
3. グループ毎の回帰係数の違いに興味がある場合，グループレベルの変動の分散 $\sigma_j^2$ を推定する最も自然なモデルである．実際，一階層の回帰分析は $\sigma_j=0$ の場合，グループ毎に別々の回帰分析を実行する場合は $\sigma_j=\infty$ という（場合によっては非現実的な）仮定を置いた縮退した階層モデルと見れる．

:::

全体の係数のみに興味がある場合，グループレベルの変動やデータの階層構造は局外構造である．このような状況では，誤差が相関を持つ場合にも頑健な点推定手法として，一般化推定方程式法なども用いることができる．^[この点については [11.6 節 @Gelman-Hill2006 p.248]，[@Carlin+2001] などを参照．]

## 線型変動係数モデル

### 変量効果モデル

階層モデル
$$
y_i=\al_{j[i]}+\beta x_i+\ep_i,\qquad\ep_i\sim\rN(0,\sigma^2_y),
$$ {#eq-model-1}
$$
\al_j=\mu_\al+\eta_j,\qquad\eta_j\sim\rN(0,\sigma^2_\al),
$$ {#eq-model-2}
は２つの別の階層にある回帰モデルが，１つに統合された形をしている．^[この第二階層の構造を $\al_j\sim\rN(\mu_\al,\sigma^2_\al)$ という事前分布とみて，この未知パラメータの推定から始める点推定法を経験ベイズという [@菅澤-久保川2023 pp.11-12]．]

([-@eq-model-1]), ([-@eq-model-2]) は **変量効果モデル**，または NER (Nest Error Regression) model [@Battese+1988] と呼ばれる．^[[@菅澤-久保川2023] では，$\beta$ が $j[i]\in[J]$ 毎に異なるとき，これを変量係数モデルと呼んでいる．ここでは [@Gelman2005] などに倣って，全てまとめて変動係数 (varying coefficient) モデルと呼ぶことにする．]

### 中庸としての階層モデル

全く等価だが $D_i$ を $i$ 番目の成分のみが $1$ のベクトル，$\al=(\al_1,\cdots,\al_J)^\top$ として
$$
y_i=D_i\al+\beta x_i+\ep_i
$$
と表すことができる．

こうみると $J$ 個のクラスそれぞれに関する指示変数 $D_1,\cdots,D_J$ で定数項を置き換えた単一の回帰モデルと見ることもできる．仮に複数の変動係数が存在しても共線型性が問題にならないのは，$\al$ の事前分布に構造が入っているためである．

階層モデル ([-@eq-model-1]), ([-@eq-model-2]) において $\sigma^2_\al\to0$ の極限を考えると，グループ毎に変動がないという単一の線型回帰モデルに帰着する．

他方で実は $\sigma^2_\al\to\infty$ の極限を考えると，古典的な点推定の文脈では，$J$ グループのそれぞれに別々の線型回帰を実行するというモデルに帰着する．

これは「グループ毎に全く別々で互いに関係がない」というモデルであり，真実は２つの中庸にあると思われる．

グループ毎の変動と，その間の緩い関係性の双方を許し，１つのモデルに取り込んだものが **階層モデル** である．グループレベルの変動 $\sigma^2_\al$ を推定するための自然なモデルでもある．

### BLUE

線型最良不偏推定量 (BLUE) は [@Henderson1950] によって提案された，$\beta,\al_{j[i]}$ の推定量である．

$\beta$ の推定量は計量経済学の文脈で変量効果推定量と呼ばれる GLS 推定量に他ならない．^[[@菅澤-久保川2023 p.10] に GLS 推定量が BLUE であることの証明がある．変量効果推定量については [17.6 @Hansen2022 pp.601-603] を参照した．]

$\al_{j[i]}$ の BLUE は，モデル ([-@eq-model-1]), ([-@eq-model-2]) においては
$$
\wh{\al}_j=\frac{\frac{n_j}{\al_y^2}}{\frac{n_j}{\al_y^2}+\frac{1}{\sigma^2_\al}}(\ov{y}_j-\beta\ov{x}_j)+\frac{\frac{1}{\sigma^2_\al}}{\frac{n_j}{\al_y^2}+\frac{1}{\sigma^2_\al}}\mu_\al
$$
と表せる．^[正規性の仮定の下では一般に経験ベイズ推定量と一致することが [@菅澤-久保川2023 pp.11-12] で示されている．]

<!-- 
([-@eq-model-1]) のような線型モデルでは，$\al_{j[i]}$ の存在などの分布構造の要因に依らず平均が不偏推定できるのである．
-->

### 分散成分モデル

#### 一般的な定義

[@Henderson1950] に始まる分散成分モデルは，一般的には
$$
y_{ij}=\beta x_i+\al_{j_1[i]}+\cdots+\al_{j_k[i]}+\ep_{ij}
$$
$$
\al_{j_l}\iidsim\rN(0,\tau_l^2),
$$
と表されるモデルと理解される [@菅澤-久保川2023 p.73]．$k=1$ の場合は [@Fay-Herriot1979] モデルともいう．

変量効果モデルにおいて誤差には完全な階層関係があったが，分散成分モデルはその non-nested な場合への拡張とみなせる．

#### 分散成分モデルの例

この場合データ $y_{ij}$ の変動を成分ごとに分解しようという志向が，分散分析の発展と見れる．例えば
$$
y_{ijk}=\mu+\mu_{1i}+\mu_{2j}+\ep_{ijk}
$$
という形の場合は特に **二元分類モデル**，$\mu_{3ij}$ も加えた場合は二元交差モデルと呼ばれる．

さらにグループ階層のモデルに関して，分散成分モデルではグループレベル変数 $\al_{j_l}$ は互いに独立であるとしているが，空間モデルでは互いに相関を持つと仮定することもある．

さらにこの階層は潜在変数の階層とみるとコピュラモデルや理想点モデルに近くなる．項目反応モデルは，個人毎の変動と項目毎の変動の，non-nested な２つの変動を持ったロジスティック階層モデル [-@sec-multilevel-logistic] になる．

#### 分散成分の点推定法

変量効果モデルや分散成分モデルにも適用可能な，一般の階層モデルに適用可能な分散成分の推定法として，一般化推定方程式法がある．

その特別な荷重を取った場合に REML (Restricted Maximum Likelihood) 推定量がある [2.3 節 @菅澤-久保川2023 p.13]．

こうして得た分散成分，特に分散比 $\rho:=\sigma^2_v/\sigma^2_e$ の推定量を得たあと，これを BLUE $\wh{\beta}$ に代入して得る２段階推定量を **経験 BLUE** という [@久保川達也2006 p.143]．

その縮小効果については次稿も参照：

::: {#lst-embed}
:::

### ベイズ推定

ベイズ階層モデルの基礎は [@Lindley-Smith1972] が敷いたと言われる．

## 階層ロジスティックモデル {#sec-multilevel-logistic}

### 項目応答モデル

#### １母数ロジットモデル

$$
g(x):=\operatorname{logit}(x)=\log\frac{x}{1-x}
$$
$$
g(\mu_{i})=\al_{j[i]}-\beta_{k[i]},\qquad\mu_{i}=\P[Y_{ik}=1],
$$
というモデルを [**１母数応答モデル**](../TransDimensionalModels/IdealPoint.qmd#sec-binary-IRT) または [@Rasch1960] モデルという．

このモデルは $(\al_j,\beta_k)$ 上の平行移動に関して識別不可能であるため，点推定の文脈では追加の制約条件が導入される．しかしベイズの文脈では不適な事前分布を避けることで自然に回避される．

階層ベイズモデルでは，自然に関心が能力パラメータ $\al_j$ と難易度パラメータ $\beta_k$ の分散に向けられる：
$$
\al_j=\mu_\al+\gamma_\al X^\al_j+\ep_j,\qquad\ep_j\iidsim\rN(0,\sigma^2_\al),
$$
$$
\beta_k=\mu_\beta+X^\beta_k+\ep_k,\qquad\ep_k\iidsim\rN(0,\sigma^2_\beta).
$$

#### ２母数ロジットモデル

さらに項目毎の **識別力母数** (discrimination parameter) $\gamma_k$ を導入したモデル
$$
g(\mu_i)=\gamma_{k[i]}\Paren{\al_{j[i]}-\beta_{k[i]}},
$$
を [**２母数ロジットモデル**](../TransDimensionalModels/IdealPoint.qmd#sec-binary-IRT) という．

#### 多次元の潜在空間

読解力と数学力の別々の能力を要求するテストなどのデータに対して，多次元の潜在空間を持つモデルを考えたい．

両方が要求される AND の論理の場合は
$$
\mu_i=g^{-1}\Paren{\gamma^{(1)}_{k[i]}(\al_{j[i]}-\beta^{(1)}_{k[i]})}g^{-1}\Paren{\gamma^{(2)}_{k[i]}(\al_{j[i]}-\beta^{(2)}_{k[i]})}
$$
というモデルが考えられるかもしれない．OR の論理の各因数を $1-\mu_i, 1-g^{-1}(-)$ で置き換えれば良い．

一方で潜在空間からの関数を設定しても良いだろう．最も直感的には能力値の和で
$$
\mu_i=g^{-1}\Paren{\gamma^{(1)}_{k[i]}(\al_{j[i]}-\beta^{(1)}_{k[i]})+\gamma^{(2)}_{k[i]}(\al_{j[i]}-\beta^{(2)}_{k[i]})}
$$
と表すものである．

#### 応答曲線

リンク関数 $g$ の選択は，潜在変数 $\al_j,\beta_k,\gamma_k$ の変化が応答確率の変化にどう関係するかを規定する．

$g$ のプロットは ICC (Item Characteristic Curve) または trace line と呼ばれる [@Fox2010 p.6]．

これは $g(0.5)$ を中心に対称になっているが，この対称性が不適切な場合も多い．

[@Bafumi+2005] などは
$$
\mu_i=\pi_1+(1-\pi_0-\pi_1)g^{-1}\Paren{\gamma_k(\al_j-\beta_k)}
$$
として，最低限の $y_i=0,1$ への反応確率 $\pi_0,\pi_1$ をあらかじめ設定し，$[\pi_0,\pi_1]\subset[0,1]$ の範囲だけに応答曲線をフィッティングすることを考えた．

$\pi_0,\pi_1$ も推定すべきパラメータとする．

## 文献紹介 {.appendix}

[12 章 @Gelman-Hill2006] が筆者の知る限り最も丁寧な階層モデルへの導入である．

変動係数モデルに関して [@菅澤-久保川2023] が極めて見通しが良い．小地域推定を主なテーマとしている．

項目応答モデルと理想点モデルは [14.3 @Gelman-Hill2006] において一般化線型階層モデルの文脈で扱われている．