---
title: "ベイズデータ解析５"
subtitle: "回帰モデルの概観"
author: "司馬博文"
date: 12/5/2024
date-modified: 12/8/2024
categories: [Bayesian, Statistics]
bibliography: 
    - ../../../assets/mathematics.bib
    - ../../../assets/bib.bib
    - ../../../assets/bib1.bib
csl: ../../../assets/apalike.csl
abstract-title: 概要
abstract: |
    ベイズ回帰分析のワークフローを概観する．一つの悲願として，階層モデルを構築して，パラメータをもはや残さず，尤度の推定に成功することがあることを紹介する．
    分散分析はこの階層化の際の鍵を握る考え方として，現代でも重要な位置付けを得ることになる．
    また多くの回帰分析ではデータを変換して線型関係の推定に集中する場合が多く，これを扱う数理モデルとして一般化線型モデルを紹介する．
image: Files/BayesianWorkflow.svg
listing: 
    -   id: lst-survey
        type: grid
        sort: false
        contents:
            - "../Computation/brms.qmd"
            - "BDA2.qmd"
            - "Survey1.qmd"
            - "Survey2.qmd"
            - "Survey3.qmd"
            - "Survey4.qmd"
        date-format: iso
        fields: [title,image,date,subtitle]
    -   id: lst-ANOVA
        type: grid
        sort: false
        contents:
            - "BayesANOVA.qmd"
            - "Survey1.qmd"
            - "../Computation/brms.qmd"
        date-format: iso
        fields: [title,image,date,subtitle]
      
---

{{< include ../../../assets/_preamble.qmd >}}

## 関連記事 {.unnumbered .unlisted}

::: {#lst-survey}
:::

## 回帰分析の一般事項

### はじめに：正規線型回帰

回帰分析とは，２つの確率変数 $X,Y$ の実現と見られるデータが得られている際に，その条件付き期待値 $\E[Y|X]$ に対して，$x\in\cX$ に依存するモデル
$$
\cX\ni x\mapsto P_{\theta,x}\in\cP(\cY)
$$
を考えることをいう．例えば
$$
P_{\theta,x}=\rN(\beta^\top x,\sigma^2),\qquad\theta=(\beta,\sigma),
$$
とした場合を **正規線型回帰** (normal linear model) という．

### ベイズ回帰分析

しかしベイズ回帰分析では，条件付き期待値 $\E[Y|X]$ を推定するというより，本質的には結合変数 $(X,Y)$ の結合分布をモデリングしているとみなすべきである．

実際，ベイズ回帰分析では事前分布 $P_\varphi$ も併せて次の２つのモデルが想定される：
$$
Y|X\sim P_{\theta,x},\qquad X\sim P_\varphi.
$$

この結果，パラメータの空間 $(\theta,\varphi)$ 上からの確率核
$$
(\theta,\varphi)\mapsto P_{\theta,x}P_\varphi(dx)\in\cP(\cX\times\cY)
$$
が想定されることになる．これを **尤度** という．

尤度によりデータの空間 $\cX\times\cY$ 上の確率分布に関する問題を，パラメータの空間上に移送することが **（ベイズ）推論** である．

ベイズ回帰分析とは，尤度を $P_{\theta}(x,dy)P_\varphi(dx)$ と分解された形で与える場合のベイズモデリングに過ぎない．換言すれば，$Y|X$ の依存構造に焦点がある際に行うベイズ推論である．

$\Theta\indep\Phi$ の仮定を置いていることが特徴であるが，$(X,Y)$ の結合分布の想定が簡単になる点が，ここまで人口に膾炙している理由であると思われる．

### ベイズ回帰分析ワークフロー {#sec-Bayesian-workflow}

1. $(X,Y)$ の依存構造が単純（線型）になるような変数変換を行う（一般化線型モデルの利用を含む）．
2. $(\Theta,\Phi)$ の事前分布を設定する（初めは一様分布やデフォルトの無情報事前分布で良い）．
3. 事後分布を計算し，事後予測分布を見てデータが再現できているかを基にモデルを検証する．

その後，十分に階層化をして，パラメータの空間上の事前分布がほとんど情報を持たなくて良いようにする，完全ベイズ推論が一つの悲願とされる．^[従来は事前分布の経験ベイズ推定と呼ばれていた考え方である [@Gelman+2020 p.6]．]

モデルの挙動がもはや事前分布に依存しなくなった際，モデルの階層構造や尤度の構造が十分にデータを反映できていると思われるためである．^[一方で多くの頻度論的な手法は，無情報事前分布を仮定したベイズ推論とみなせる．そこでベイズの，有効な頻度論的モデルを探索するための方法としての美点が見えてくるのである．]

> 推定すべきものはモデルの尤度であってパラメターの値ではないというのが赤池氏の主張です．いいかえると，推定すべきは確率構造であってパラメターではないというのです．[@田邉國士2010]

::: {.callout-important appearance="simple" icon="false"}

この階層化と尤度の推定を探索的に実行できる点がベイズの真の美点だと筆者は考える．そして一度モデルの構造・尤度が明瞭化された際は，もはやベイズである必要はない場合が多い．^[この点については [@Gelman2014] も参照．大統領選における有権者の行動のモデリングを，ベイズ階層モデルに基づいて探索的に実行しており，"multilevel Bayesian modeling can be considered as an elaborate form of exploratory data analysis" と結論している．]

:::

### ベイズ線型回帰からの脱出

前節の立場にたてば，最初の解析は常に（弱い情報を持った事前分布による）ベイズ回帰分析であるべきである．^[もちろん重要な事前情報や予備解析が存在する場合は，これを事前分布としてどう更新されるかをみるのが良い．[1.6 節 @Gelman-Hill-Vehtari2020 p.16] に簡潔な概観的議論がある．]

これは若干の正則化を加えたロバスト最尤推定に，不確実性の定量化を加えたものと等価であるが，これを MCMC を回すことで一度に実行できる点が美点である．

さらに言えば posterior predictive check によるモデルの妥当性を即時に確認できる．

同時に解析の目標は，適切な関数関係や階層関係を持った階層モデルの発見と，これに適合する（ベイズだろうと点推定だろうと）パラメータ推定法の構成による，ナイーブなベイズ線型回帰からの脱出である．

This is the game we (should) play.

## 階層モデル

### はじめに

階層モデルは複雑なモデルを構築するための強力なツールであり，ベイズのワークフローにおいて基本的な要素になる．

層別抽出やクラスター抽出をはじめとして，多くの場合階層別に知識が存在し，これらを系統的に組み込んだ形でモデルを構築できる．

しかし同時に計算が困難になり，第一近似として正規性が仮定される場合が多い．

### 混合効果モデル

標本を $J$ 個のグループにわけ，これへの所属を表す２値変数 $x_i\in\R^J$ を説明変数に追加するとする．

このような所属変数 $x_i$ の回帰係数 $\beta\in\R^J$ に対して階層モデルが考えられる場合が多い．

例えば $\al\in\R,\sigma_\beta>0$ をスカラーとして
$$
\beta\sim\rN_J(\al\b{1},\sigma^2_\beta I_J),
$$
という正規モデルを想定した場合，$x_{ij}$ の係数 $\beta_j$ は各グループ $j\in[J]$ 固有の切片項であり，**変量効果** (random effect) と呼ばれる．

変量効果の追加は，同一グループ内の $y_i$ に相関を生じさせるが，グループが違う場合は相変わらず独立のままとする効果がある．

さらに $\beta_j$ の分散 $\sigma^2_{\beta_j}$ を $\infty$ とした場合，すなわち（もはや確率分布ではないが）一様分布を仮定した場合を **固定効果** (fixed effect) という．^[[@Bafumi-Gelman2007] では unmodeled varying intercept と呼んでいる．]

ベイズの立場からは，「変量」と「固定」の名称は歴史的なもので，実質的な違いは「次の階層で回帰モデルを仮定するか，モデルを持たない最終階層の変数と扱い一様事前分布に従うとするか」という仮定の違いにすぎない．

この２種の取り扱いをする回帰係数を混在させた場合は **混合モデル** (mixed model) という [@BDA p.383]．

### 階層モデルから見た分散分析

ベイズのワークフローにおいて，複数の説明変数間の階層関係の特定や「どのグループの回帰係数を共通とするか」の見極めが極めて重要である [-@sec-Bayesian-workflow]．

特に，膨大な説明変数の中から「因子」（性別・教育水準・出身地など）とその「水準」（女性・大学院生・山形県民など）とを峻別することが重要であり，どのクラスに独自の回帰係数 $\beta^{(m)}\sim\rN_{J_m}(\al_{m}\b{1}_{J_m},\sigma^2_{m}I_{J_m})$ を与えるかの決定が，モデルの尤度の改善において大きな効果を持つ [@Gelman2005]．

$M$ 元配置の分散分析において，各因子 $m\in[M]$ に対応する回帰係数は，$J_m$ 個の水準ごとに次のように決まるバラバラの変動係数を持つとする：
$$
\beta^{(m)}_j\sim\rN(0,\sigma^2_m),\qquad j\in[J_m].
$$
この変量効果としての解釈により，ANOVA は階層モデルの推定とみなせる [3.2節 @Gelman2005 p.9]．^[すると「自由度」とは変動係数の数に他ならない．]

この際の $\sigma^2_m$ に対する共役（超）事前分布は逆 $\chi^2$-分布である [@BDA p.396]
$$
\sigma^2_{m}\sim\chi^{-2}(\mu_m,\sigma^2_{0m})
$$
であり，$\nu_m=-1,\sigma^2_{0m}=0$ とすることで一様事前分布を得る．

> Analysis of variance (Anova) represents a key idea in statistical modeling of complex data structures. [@BDA p.395]

こうして設定された各因子の各水準ごとの係数 $\beta^{(m)}_j$ の事後分布を見ることで「分散分析」を実行することになる．これがベイズによる分散分析の再解釈である．

::: {#lst-ANOVA}
:::

### 水準ごとの分散

このように分散分析を階層モデルのベイズ推定と再解釈することで，膨大な数の水準の組み合わせに関して，その効果量を定量的に比較することができる．

ここからさらに，$M$ 個の因子ごとに全ての水準で共通した分散 $\sigma_1^2,\cdots,\sigma_M^2$ の $M$ 個のみを考えるのではなく，
$$
\beta^{(m)}\sim\rN_{J_m}(\al_m\b{1}_{J_m},\diag(\sigma^2_{m1},\cdots,\sigma^2_{mJ_m})),\qquad m\in[M],
$$
として，水準ごとにも異なる $\sum_{m=1}^M J_m$ 個の分散を考えることもできる [15.7 節 @BDA p.397]．

この際，
$$
\operatorname{Cauchy}(0,A),\qquad A\sim U(\R_+),
$$
という形の半 Cauchy 分布が $\sigma^2_{mj}$ の事前分布として用いられる [@BDA p.399]．これは一部の水準にのみ大きな分散を認め，その他の水準にはほとんど分散への寄与がないという仮定を表している．

### 強線型性 {#sec-collinearity}

仮に２つの説明変数に完全な線型関係がある場合，複数のパラメータ値が同一のモデルを表現するため，パラメータ推定が複数の解を持つ（＝識別不可能）．



## 一般化線型モデル

### 線型 Gauss 性からの乖離

正規線型モデルから，次の２つの自由度を追加したモデルを **一般化線型モデル** [@Nelder-Wedderburn72-GLM] という：

::: {.callout-tip appearance="simple" icon="false"}

1. リンク関数 $g$

  $$
  g\circ\E[Y|X]=\beta^\top X
  $$

2. （正規分布以外の）分布族 $P$

  $$
  Y|X\sim P(\E[Y|X],\phi)
  $$

:::

その結果質的データ解析にも応用可能な広いクラスのモデルを得る．

::: {.callout-caution title="カウントデータに対する Poisson モデル" icon="false"}

自然数値のデータに対して，$y_i\sim\Pois(\lambda_i)$ の $\lambda_i$ を，正準リンク関数 $g=\log$ を通じて
$$
\log\lambda_i=X_i^\top\beta
$$
とモデリングすることが考えられる．このモデルを **Poisson 回帰** ともいう．

:::

::: {.callout-caution title="成功回数データに対する二項モデル" icon="false"}

２値データや成功回数を表すデータの場合，$y_i\sim\Bin(n_i,\mu_i)$ の $\mu_i$ を $\P[Y_i=1|X_i]$ の形でモデリングすることを考えることができる．

この場合，正準リンク関数は
$$
g(\mu)=\log\frac{\mu}{1-\mu}
$$
という logit 変換で与えられる．より効率的な推論を促進するために probit リンクや，非対称性を導入する log-log リンク
$$
g(\mu)=\log(-\log\mu)
$$
が用いられることもある．

:::

### 指数分布族

なお正準リンクとは，Poisson 分布族や二項分布族を指数分布族とみなした際のリンク関数のことである．

例えば二項分布族 $\{\Bin(n,\mu)\}_{\mu\in(0,1)}$ は，計数測度 $\nu$ に対して，
$$
\dd{\Bin(n,\mu)}{\nu}(x)=\comb{n}{x}\exp\paren{x\log\frac{\mu}{1-\mu}+n\log(1-\mu)}
$$
と表せる．$g(\mu)$ を **自然な十分統計量** ともいう．

指数分布族と正準リンク関数を用いた一般化線型モデリングは，パラメトリック分布族の十分統計量を代理の応答変数として線型回帰を行なっているものとみなせる．

::: {.callout-important title="変換の意味" icon="false"}

このような数理統計学的な理由とは別に，$g(\mu)$ の意味を直接解釈することもできる．

* Poisson 回帰はオフセット $\log y_i$ を作ることで，
  $$
  \log\frac{\lambda_i}{y_i}=X_i^\top\beta
  $$
  と見ることもできる．$\lambda_i/y_i$ は観測カウント $y_i$ に対する平均 $\lambda_i$ の **率比** (rate ratio) と呼ばれ，$g(\lambda_i/y_i)$ は対数率比と解釈できる．
* $\frac{\mu}{1-\mu}$ という値は成功確率 $\mu$ に対するオッズ比と呼ばれ，$g(\mu)$ は **対数オッズ比** (log odds ratio) と呼ばれる．

:::

### 分散分析

線型モデルにおいて分散分析は，第一義的には帰無モデルの検定であった．後続の多重比較による解析は，説明変数ごとの効果量の比較を行う．

しかし線型モデルにおいてその方法は分散の分解に基づいており，この一般化線型モデルへの拡張は自明ではない．

一般化線型モデルにおいても残差を定義し，これに基づいてモデルの検証を行うことはできる [@Davison-Tsai1992]．



## 終わりに {.appendix}

[@BDA] 第14章で回帰分析，15章で階層モデルが議論されている．15.6, 15.7 章で Bayesian Anova が解説されている．

[@Gelman-Hill-Vehtari2020] が回帰に特化した本である．

`rstanarm` パッケージを通じて

```r
library(rstanarm)
fit <- stan_glm(y ~ x, data = mydata)
```

というコードでベイズ線型回帰を実行できる．[@Muth-Oravecz-Gabry2018] が最適なイントロダクションである．

`rstanarm` パッケージは特に `R` の built-in の関数

```r
fit <- lm(y ~ x, data = mydata)
```

や `lmer` との接続性を意識されているパッケージで，古典的な解析とベイズ分析との往復が容易にできる．

```r
fit <- stan_glm(y ~ x, data = mydata, algorithm = "optimizing")
```

により変分推論による高速な近似推定も可能である．ベイズ回帰は探索的な用途でも多く使われることを考えると大変有用な機能である．