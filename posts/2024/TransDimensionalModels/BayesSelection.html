<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="司馬博文">
<meta name="dcterms.date" content="2024-12-10">
<meta name="keywords" content="horseshoe prior, spike-and-slab prior, Stochastic Search Variable Selection, Add-Delete-Swap, Locally informed MCMC Sticky PDMP">

<title>ベイズ変数選択 – Hirofumi Shiba</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../assets/Shiba2.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-listing/list.min.js"></script>
<script src="../../../site_libs/quarto-listing/quarto-listing.js"></script>
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-90c2643ab6f776117e85fdd60cb25922.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-15aa87366f2f14a7a763690207757fed.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "?",
    "H"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>

  window.document.addEventListener("DOMContentLoaded", function (_event) {
    const listingTargetEl = window.document.querySelector('#listing-lst-survey .list');
    if (!listingTargetEl) {
      // No listing discovered, do not attach.
      return; 
    }

    const options = {
      valueNames: ['listing-title','listing-image','listing-date','listing-subtitle',{ data: ['index'] },{ data: ['categories'] },{ data: ['listing-date-sort'] },{ data: ['listing-file-modified-sort'] }],
      
      searchColumns: ["listing-title","listing-author","listing-date","listing-image","listing-description"],
    };

    window['quarto-listings'] = window['quarto-listings'] || {};
    window['quarto-listings']['listing-lst-survey'] = new List('listing-lst-survey', options);

    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  });

  window.addEventListener('hashchange',() => {
    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  })
  

  window.document.addEventListener("DOMContentLoaded", function (_event) {
    const listingTargetEl = window.document.querySelector('#listing-lst-embedding .list');
    if (!listingTargetEl) {
      // No listing discovered, do not attach.
      return; 
    }

    const options = {
      valueNames: ['listing-title','listing-image','listing-date','listing-subtitle',{ data: ['index'] },{ data: ['categories'] },{ data: ['listing-date-sort'] },{ data: ['listing-file-modified-sort'] }],
      
      searchColumns: ["listing-title","listing-author","listing-date","listing-image","listing-description"],
    };

    window['quarto-listings'] = window['quarto-listings'] || {};
    window['quarto-listings']['listing-lst-embedding'] = new List('listing-lst-embedding', options);

    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  });

  window.addEventListener('hashchange',() => {
    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  })
  

  window.document.addEventListener("DOMContentLoaded", function (_event) {
    const listingTargetEl = window.document.querySelector('#listing-lst-embedding1 .list');
    if (!listingTargetEl) {
      // No listing discovered, do not attach.
      return; 
    }

    const options = {
      valueNames: ['listing-title','listing-image','listing-date','listing-subtitle',{ data: ['index'] },{ data: ['categories'] },{ data: ['listing-date-sort'] },{ data: ['listing-file-modified-sort'] }],
      
      searchColumns: ["listing-title","listing-author","listing-date","listing-image","listing-description"],
    };

    window['quarto-listings'] = window['quarto-listings'] || {};
    window['quarto-listings']['listing-lst-embedding1'] = new List('listing-lst-embedding1', options);

    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  });

  window.addEventListener('hashchange',() => {
    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  })
  

  window.document.addEventListener("DOMContentLoaded", function (_event) {
    const listingTargetEl = window.document.querySelector('#listing-lst-embedding2 .list');
    if (!listingTargetEl) {
      // No listing discovered, do not attach.
      return; 
    }

    const options = {
      valueNames: ['listing-title','listing-image','listing-date','listing-subtitle',{ data: ['index'] },{ data: ['categories'] },{ data: ['listing-date-sort'] },{ data: ['listing-file-modified-sort'] }],
      
      searchColumns: ["listing-title","listing-author","listing-date","listing-image","listing-description"],
    };

    window['quarto-listings'] = window['quarto-listings'] || {};
    window['quarto-listings']['listing-lst-embedding2'] = new List('listing-lst-embedding2', options);

    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  });

  window.addEventListener('hashchange',() => {
    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  })
  </script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-36GX2G6GLL"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-36GX2G6GLL', { 'anonymize_ip': true});
</script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Zen+Kurenaido&amp;display=swap" rel="stylesheet">

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=BIZ+UDPGothic&amp;display=swap" rel="stylesheet">

<style>
  h1, .title, .description, .subtitle {
    font-family: "Zen Kurenaido", sans-serif !important;
  }
</style>

<!-- <style>
  .menu-text {
      font-family: "Gill Sans", sans-serif !important;
      font-weight: 400;
      font-style: normal;
  }
  .navbar-title {
      font-family: "Gill Sans", sans-serif !important;
      font-weight: 400;
      font-style: normal;
  }
</style> -->

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../assets/styles.css">
<meta property="og:title" content="ベイズ変数選択 – Hirofumi Shiba">
<meta property="og:description" content="点推定における変数選択法は，正則化項の追加によることが多い．
これはベイズ推論では $0$ 近傍に大きな確率を持った事前分布を仮定していることに等しい．
ベイズの観点から適切な縮小事前分布を用意することで，大きな効果を持つ回帰係数は変えずに，
効果の小さい変数を排除することができる．
一般に LASSO よりも絞って選択してくれることが多い．

またベイズ変数選択では，$0$…">
<meta property="og:image" content="https://162348.github.io/posts/2024/Survey/Files/elpd.svg">
<meta property="og:site_name" content="Hirofumi Shiba">
<meta name="twitter:title" content="ベイズ変数選択 – Hirofumi Shiba">
<meta name="twitter:description" content="点推定における変数選択法は，正則化項の追加によることが多い．
これはベイズ推論では $0$ 近傍に大きな確率を持った事前分布を仮定していることに等しい．
ベイズの観点から適切な縮小事前分布を用意することで，大きな効果を持つ回帰係数は変えずに，
効果の小さい変数を排除することができる．
一般に LASSO よりも絞って選択してくれることが多い．

またベイズ変数選択では，$0$…">
<meta name="twitter:image" content="https://162348.github.io/posts/2024/Survey/Files/elpd.svg">
<meta name="twitter:creator" content="@ano2math5">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Hirofumi Shiba</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-notes" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Notes</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-notes">    
        <li>
    <a class="dropdown-item" href="../../../static/English.html">
 <span class="dropdown-text">English Notes</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../blog.html">
 <span class="dropdown-text">ノート (Japanese)</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Materials.html"> 
<span class="menu-text">Materials</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Slides.html"> 
<span class="menu-text">Slides</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Software.html"> 
<span class="menu-text">Software</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
    <a href="https://github.com/162348/162348.github.io/" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">ベイズ変数選択</h1>
            <p class="subtitle lead">BMI データの重線型回帰を題材として</p>
                                <div class="quarto-categories">
                <div class="quarto-category">Bayesian</div>
                <div class="quarto-category">Statistics</div>
                <div class="quarto-category">R</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>司馬博文 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">12/10/2024</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">1/04/2025</p>
      </div>
    </div>
      
    </div>
    
  <div>
    <div class="abstract">
      <div class="block-title">概要</div>
      <p>点推定における変数選択法は，正則化項の追加によることが多い． これはベイズ推論では <span class="math inline">\(0\)</span> 近傍に大きな確率を持った事前分布を仮定していることに等しい． ベイズの観点から適切な縮小事前分布を用意することで，大きな効果を持つ回帰係数は変えずに， 効果の小さい変数を排除することができる． 一般に LASSO よりも絞って選択してくれることが多い．</p>
      <p>またベイズ変数選択では，<span class="math inline">\(0\)</span> にアトムを持つ事前分布を用いることで，当該の変数がモデルに含まれる事後確率 (PIP: Posterior Inclusion Probability) を算出することができる． この方法ではモデルの空間を効率的に探索するサンプラーの開発が重要であるが， 近年では効率的なサンプラーが複数提案されている．</p>
    </div>
  </div>

  <div>
    <div class="keywords">
      <div class="block-title">Keywords</div>
      <p>horseshoe prior, spike-and-slab prior, Stochastic Search Variable Selection, Add-Delete-Swap, Locally informed MCMC Sticky PDMP</p>
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">目次</h2>
   
  <ul>
  <li><a href="#はじめに" id="toc-はじめに" class="nav-link active" data-scroll-target="#はじめに"><span class="header-section-number">1</span> はじめに</a>
  <ul class="collapse">
  <li><a href="#復習ベイズデータ解析の第一歩" id="toc-復習ベイズデータ解析の第一歩" class="nav-link" data-scroll-target="#復習ベイズデータ解析の第一歩"><span class="header-section-number">1.1</span> （復習）ベイズデータ解析の第一歩</a></li>
  <li><a href="#ベイズから見た変数選択" id="toc-ベイズから見た変数選択" class="nav-link" data-scroll-target="#ベイズから見た変数選択"><span class="header-section-number">1.2</span> ベイズから見た変数選択</a></li>
  <li><a href="#ベイズモデル平均を見据えて" id="toc-ベイズモデル平均を見据えて" class="nav-link" data-scroll-target="#ベイズモデル平均を見据えて"><span class="header-section-number">1.3</span> ベイズモデル平均を見据えて</a></li>
  </ul></li>
  <li><a href="#sec-Bayesian-regularization" id="toc-sec-Bayesian-regularization" class="nav-link" data-scroll-target="#sec-Bayesian-regularization"><span class="header-section-number">2</span> 縮小事前分布による方法</a>
  <ul class="collapse">
  <li><a href="#多くの説明変数が存在する場合の事前分布" id="toc-多くの説明変数が存在する場合の事前分布" class="nav-link" data-scroll-target="#多くの説明変数が存在する場合の事前分布"><span class="header-section-number">2.1</span> 多くの説明変数が存在する場合の事前分布</a></li>
  <li><a href="#縮小事前分布" id="toc-縮小事前分布" class="nav-link" data-scroll-target="#縮小事前分布"><span class="header-section-number">2.2</span> 縮小事前分布</a></li>
  <li><a href="#local-scale-mixture" id="toc-local-scale-mixture" class="nav-link" data-scroll-target="#local-scale-mixture"><span class="header-section-number">2.3</span> Local Scale Mixture</a></li>
  <li><a href="#ベイズ縮小の効果" id="toc-ベイズ縮小の効果" class="nav-link" data-scroll-target="#ベイズ縮小の効果"><span class="header-section-number">2.4</span> ベイズ縮小の効果</a></li>
  <li><a href="#馬蹄事前分布" id="toc-馬蹄事前分布" class="nav-link" data-scroll-target="#馬蹄事前分布"><span class="header-section-number">2.5</span> 馬蹄事前分布</a></li>
  <li><a href="#正則化" id="toc-正則化" class="nav-link" data-scroll-target="#正則化"><span class="header-section-number">2.6</span> 正則化</a></li>
  <li><a href="#rstanarm-での利用" id="toc-rstanarm-での利用" class="nav-link" data-scroll-target="#rstanarm-での利用"><span class="header-section-number">2.7</span> <code>rstanarm</code> での利用</a></li>
  </ul></li>
  <li><a href="#sec-Bayesian-variable-selection" id="toc-sec-Bayesian-variable-selection" class="nav-link" data-scroll-target="#sec-Bayesian-variable-selection"><span class="header-section-number">3</span> ベイズ変数選択</a>
  <ul class="collapse">
  <li><a href="#sec-hierarchical-modeling" id="toc-sec-hierarchical-modeling" class="nav-link" data-scroll-target="#sec-hierarchical-modeling"><span class="header-section-number">3.1</span> はじめに：階層モデリング</a></li>
  <li><a href="#sec-SSVS" id="toc-sec-SSVS" class="nav-link" data-scroll-target="#sec-SSVS"><span class="header-section-number">3.2</span> 確率的探索法</a></li>
  <li><a href="#sec-Add-Delete-Swap" id="toc-sec-Add-Delete-Swap" class="nav-link" data-scroll-target="#sec-Add-Delete-Swap"><span class="header-section-number">3.3</span> Add-Delete-Swap による探索</a></li>
  <li><a href="#超次元-mcmc-による-pip-算出" id="toc-超次元-mcmc-による-pip-算出" class="nav-link" data-scroll-target="#超次元-mcmc-による-pip-算出"><span class="header-section-number">3.4</span> 超次元 MCMC による PIP 算出</a></li>
  <li><a href="#計算の問題" id="toc-計算の問題" class="nav-link" data-scroll-target="#計算の問題"><span class="header-section-number">3.5</span> 計算の問題</a></li>
  <li><a href="#tempered-gibbs-サンプラー" id="toc-tempered-gibbs-サンプラー" class="nav-link" data-scroll-target="#tempered-gibbs-サンプラー"><span class="header-section-number">3.6</span> Tempered Gibbs サンプラー</a></li>
  <li><a href="#sec-Locally-Informed-MH-Samplers" id="toc-sec-Locally-Informed-MH-Samplers" class="nav-link" data-scroll-target="#sec-Locally-Informed-MH-Samplers"><span class="header-section-number">3.7</span> Locally Informed MH Samplers</a></li>
  <li><a href="#適応的なサンプラー" id="toc-適応的なサンプラー" class="nav-link" data-scroll-target="#適応的なサンプラー"><span class="header-section-number">3.8</span> 適応的なサンプラー</a></li>
  <li><a href="#非可逆なサンプラー" id="toc-非可逆なサンプラー" class="nav-link" data-scroll-target="#非可逆なサンプラー"><span class="header-section-number">3.9</span> 非可逆なサンプラー</a></li>
  </ul></li>
  
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="はじめに" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="はじめに"><span class="header-section-number">1</span> はじめに</h2>
<section id="復習ベイズデータ解析の第一歩" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="復習ベイズデータ解析の第一歩"><span class="header-section-number">1.1</span> （復習）ベイズデータ解析の第一歩</h3>
<p>データの非線型変換も取り入れたベイズ線型重回帰分析は，多くの場合，データを理解するための最初の解析手法として選択される．</p>
<p>その方法を <code>brms</code> パッケージを用いて実践したのが次の記事である：</p>
<div id="listing-lst-embedding" class="listing quarto-float quarto-figure quarto-figure-left quarto-listing quarto-listing-container-grid anchored">
<div class="list grid quarto-listing-cols-1">
<div class="g-col-1" data-index="0" data-categories="QmF5ZXNpYW4lMkNTdGF0aXN0aWNzJTJDUg==" data-listing-date-sort="1733788800000" data-listing-file-modified-sort="1752119711328" data-listing-date-modified-sort="1733961600000" data-listing-reading-time-sort="5" data-listing-word-count-sort="945">
<a href="../../../posts/2024/Survey/BayesRegression.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="../../../posts/2024/Survey/Files/elpd.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
<code>brms</code> を用いたベイズ重回帰分析
</h5>
<div class="card-subtitle listing-subtitle">
BMI データを題材として
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-12-10
</div>
</div>
</div>
</div></a>
</div>
</div>
<div class="listing-no-matching d-none">No matching items</div>
</div>
<p>前稿では BMI を LAB と LDL から予測する問題を，線型回帰モデルから始めた．</p>
<p>交差項を追加することで，LDL が違う群に対して LAB がどう変わるかの層別の違いを見ることができる．</p>
<p>事後予測分布によるモデルのチェックは残差プロットと同様に，極めて手軽かつ有力なモデル検証の方法である．</p>
<p>これにより関数関係の非線型性が疑われたため，被説明変数 BMI に対して対数変換を施して線型回帰をすると，予測性能の改善が見られた．</p>
<p>事後予測分布のプロットだけでなく，その「よさ」の定量的な指標として交差検証による事後予測スコア elpd <span class="citation" data-cites="Vehtari+2017">(<a href="#ref-Vehtari+2017" role="doc-biblioref">Vehtari et al., 2017</a>)</span> があることを学んだ．</p>
</section>
<section id="ベイズから見た変数選択" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="ベイズから見た変数選択"><span class="header-section-number">1.2</span> ベイズから見た変数選択</h3>
<p>こうして予測力を基にモデル選択をする方法は得たわけであるが，純粋にベイズ的な観点から変数選択を行う方法が大きく分けて２つある．</p>
<section id="縮小事前分布による方法" class="level4" data-number="1.2.1">
<h4 data-number="1.2.1" class="anchored" data-anchor-id="縮小事前分布による方法"><span class="header-section-number">1.2.1</span> 縮小事前分布による方法</h4>
<p>１つ目が「モデルに含まれる変数は少ないはずである」という信念を表現した事前分布を用いる方法である（第 <a href="#sec-Bayesian-regularization" class="quarto-xref">2</a> 節）．</p>
<p>これは馬蹄事前分布 <span class="citation" data-cites="Carvalho+2009">(<a href="#ref-Carvalho+2009" role="doc-biblioref">Carvalho et al., 2009</a>)</span>, <span class="citation" data-cites="Carvalho+2010">(<a href="#ref-Carvalho+2010" role="doc-biblioref">Carvalho et al., 2010</a>)</span>，Laplace 事前分布 / Bayesian Lasso <span class="citation" data-cites="Park-Casella2008">(<a href="#ref-Park-Casella2008" role="doc-biblioref">Park and Casella, 2008</a>)</span> などの global-local shrinkage prior を用いる方法である．</p>
<p>この方法は点推定や頻度論的な方法ではほとんど唯一の変数選択の方法であり，正則化または<strong>スパース性</strong> のキーワードの下で盛んに研究されている <span class="citation" data-cites="Hastie+2015">(<a href="#ref-Hastie+2015" role="doc-biblioref">Hastie et al., 2015</a>)</span>．</p>
</section>
<section id="sec-spike-and-slab" class="level4" data-number="1.2.2">
<h4 data-number="1.2.2" class="anchored" data-anchor-id="sec-spike-and-slab"><span class="header-section-number">1.2.2</span> ベイズ変数選択</h4>
<p>２つ目が spike-and-slab 事前分布 <span class="citation" data-cites="Mitchell-Beauchamp1988">(<a href="#ref-Mitchell-Beauchamp1988" role="doc-biblioref">Mitchell and Beauchamp, 1988</a>)</span> という <span class="math inline">\(0\)</span> にマスを持つ事前分布を用いる方法である： <span id="eq-spike-and-slab"><span class="math display">\[
p(dx)=\prod_{i=1}^d\biggr(\omega_i\phi_i(x_i)\,dx_i+(1-\omega_i)\delta_0(dx_i)\biggl)
\tag{1}\]</span></span></p>
<p>この方法では当該変数の <strong>事後包含確率</strong> (PIP: Posterior Inclusion Probability) を導出することができる．実際 (<a href="#eq-spike-and-slab" class="quarto-xref">1</a>) は混合分布の形をしており，spike <span class="math inline">\(\delta_0\)</span> と slab <span class="math inline">\(\phi_i\)</span> のどちらからサンプリングされるかを表す潜在変数 <span class="math inline">\(\gamma_i\in\{0,1\}\)</span> を導入すれば，<span class="math inline">\(\operatorname{P}[\gamma=0|\mathcal{D}]\)</span> という事後確率こそが変数 <span class="math inline">\(x_i\)</span> がモデルに入る事後確率である．</p>
<p>PIP を用いることで「当該変数がモデルに含まれるか？」という問題に直接ベイズ的に答えることができる．これを <strong>ベイズ変数選択</strong> という <a href="#sec-Bayesian-variable-selection" class="quarto-xref">3</a>．</p>
<p>一方で前述の global-local shrinkage prior でも，post-processing を通じて同様に PIP を近似的に算出することができる <span class="citation" data-cites="Hahn-Carvalho2015">(<a href="#ref-Hahn-Carvalho2015" role="doc-biblioref">Hahn and Carvalho, 2015</a>)</span>．</p>
</section>
</section>
<section id="ベイズモデル平均を見据えて" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="ベイズモデル平均を見据えて"><span class="header-section-number">1.3</span> ベイズモデル平均を見据えて</h3>
<p>このようにベイズ変数選択 <a href="#sec-spike-and-slab" class="quarto-xref">1.2.2</a> では，変数選択も統計的推論の問題として解く．</p>
<p>この方法は最適なレートで縮小する効果を持ち <span class="citation" data-cites="Castillo+2015">(<a href="#ref-Castillo+2015" role="doc-biblioref">Castillo et al., 2015</a>)</span>，また予測力にも優れる <span class="citation" data-cites="Porwal-Raftery2022">(<a href="#ref-Porwal-Raftery2022" role="doc-biblioref">Porwal and Raftery, 2022</a>)</span>．</p>
<p>最終的には，適切に構造と事前分布が設定されたベイズモデルを用いて，ベイズ推論により変数の関連度を自動で判断して結果を出すことが理想である．その意味では全ての変数を（適切に）入れたモデルを用いることが好ましい．<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>ベイズ変数選択はこの最終目標に向かうまでの探索的な中途解析と見ることもできる．</p>
<p>実際，ベイズ変数選択により得た事後包含確率 PIP は，ベイズモデル平均 (BMA: Bayesian Model Averaging) <span class="citation" data-cites="Hoeting+1999">(<a href="#ref-Hoeting+1999" role="doc-biblioref">Hoeting et al., 1999</a>)</span> に用いることができる．</p>
<p>変数選択・モデル選択を実行し，選ばれた単一のモデルで推論・予測を実行するよりも，尤度が必ずしも最も高いわけではないモデルも捨てずに推論に用いることで精度を上げることができる．</p>
<p>これがベイズモデル平均の考え方であり，ベイズの美点をフルに発揮する枠組みであると言える．実際，<span class="citation" data-cites="Porwal-Raftery2022">(<a href="#ref-Porwal-Raftery2022" role="doc-biblioref">Porwal and Raftery, 2022</a>)</span> では線型回帰モデルの変数選択において，３つの適応的 BMA 手法が全てのタスクでベストな予測性能を示したことを報告している．</p>
</section>
</section>
<section id="sec-Bayesian-regularization" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="sec-Bayesian-regularization"><span class="header-section-number">2</span> 縮小事前分布による方法</h2>
<section id="多くの説明変数が存在する場合の事前分布" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="多くの説明変数が存在する場合の事前分布"><span class="header-section-number">2.1</span> 多くの説明変数が存在する場合の事前分布</h3>
<p><code>stan_glm</code> では回帰係数には適切な分散を持った独立な正規分布（<span class="math inline">\(g\)</span>-prior）をデフォルトの事前分布としている．</p>
<p><code>brms</code> では一様事前分布である．</p>
<p>仮に説明変数が極めて多い場合，このデフォルト事前分布を採用し続けることは適切ではない．</p>
<p>実際，独立な正規・一様分布に従う説明変数が大量にある場合，これは「ベイズ（事後平均）推定量の分散が大きい」という事前分布を採用していることに含意してしまう．</p>
<p>仮に <span class="math inline">\(\sigma\)</span> にも同様の分散の大きい事前分布をおいているのならば辻褄は合うが，そうでないならばベイズ決定係数 <span class="math inline">\(R^2\)</span> にほとんど <span class="math inline">\(1\)</span> 近くの事前分布をおいていることに等価である．</p>
<p>すなわち過学習されたモデルに強い事前分布をおいていることになる <span class="citation" data-cites="Gelman-Hill-Vehtari2020">(<a href="#ref-Gelman-Hill-Vehtari2020" role="doc-biblioref">Gelman et al., 2020, p. 208</a>)</span>．これは我々の信念と食い違うだろう．そもそも弱情報であるべきデフォルト事前分布としては相応しくない．</p>
</section>
<section id="縮小事前分布" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="縮小事前分布"><span class="header-section-number">2.2</span> 縮小事前分布</h3>
<p>まずは各変数の正規事前分布の分散を十分小さくして，誤差 <span class="math inline">\(\epsilon\)</span> の分散 <span class="math inline">\(\sigma^2\)</span> のスケールと同一にすることが考えられる．</p>
<p>この際 <span class="math inline">\(R^2\)</span> にはほとんど無情報な事前分布が仮定されるのと同一である．</p>
<p>さらに，仮に「多くの説明変数のうち，一部しか重要なものはなく，他の大部分はほとんど無関係である」と思っている，あるいは思いたいとする．変数選択を行いたい場合がこれにあたる．</p>
<p>この信念を正確に表現する事前分布の一つに馬蹄事前分布 (horseshoe prior) <span class="citation" data-cites="Carvalho+2009">(<a href="#ref-Carvalho+2009" role="doc-biblioref">Carvalho et al., 2009</a>)</span>, <span class="citation" data-cites="Carvalho+2010">(<a href="#ref-Carvalho+2010" role="doc-biblioref">Carvalho et al., 2010</a>)</span> とその正則化バージョン <span class="citation" data-cites="Piironen-Vehtari2017">(<a href="#ref-Piironen-Vehtari2017" role="doc-biblioref">Piironen and Vehtari, 2017b</a>)</span> がある．</p>
<p>これらの分布は global-local shrinkage prior と呼ばれ，<span class="math inline">\(R^2\)</span> 上の事前分布に，<span class="math inline">\(0\)</span> 上にスパイクを生じさせる．モデルに支持されない説明変数の係数を <span class="math inline">\(0\)</span> に向かって縮小する効果があり，結果としてシンプルなモデルを選好することになる．</p>
<p>Stan においては <code>prior=hs</code> によって指定できる <span class="citation" data-cites="Gelman-Hill-Vehtari2020">(<a href="#ref-Gelman-Hill-Vehtari2020" role="doc-biblioref">Gelman et al., 2020, p. 209</a>)</span>．</p>
</section>
<section id="local-scale-mixture" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="local-scale-mixture"><span class="header-section-number">2.3</span> Local Scale Mixture</h3>
<p>多くの正則化事前分布は次のような正規分布の local scale mixture <span class="citation" data-cites="West1987">(<a href="#ref-West1987" role="doc-biblioref">West, 1987</a>)</span> の形をしている：<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> <span class="math display">\[
\pi(\beta_j|\lambda)=\int_\mathbb{R}\phi(\beta_j|0,\lambda^2\lambda^2_j)\pi(\lambda_j^2)\,d\lambda_j.
\]</span></p>
<p><span class="math inline">\(\pi\)</span> が２点のみに台を持つ場合が spike-and-slab (<a href="#eq-spike-and-slab" class="quarto-xref">1</a>) であった <span class="citation" data-cites="Polson-Scott2011">(<a href="#ref-Polson-Scott2011" role="doc-biblioref">Polson and Scott, 2011</a>)</span>．SSVS （第 <a href="#sec-SSVS" class="quarto-xref">3.2</a> 節）も含む．<span class="math inline">\(\pi\)</span> が絶対連続である場合も次のような例を持つ <span class="citation" data-cites="Polson-Scott2012">(<a href="#ref-Polson-Scott2012" role="doc-biblioref">Polson and Scott, 2012</a>)</span>：</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li>二重指数分布 (double exponential) / Bayesian Lasso <span class="citation" data-cites="Park-Casella2008">(<a href="#ref-Park-Casella2008" role="doc-biblioref">Park and Casella, 2008</a>)</span>, <span class="citation" data-cites="Hans2009">(<a href="#ref-Hans2009" role="doc-biblioref">Hans, 2009</a>)</span></li>
<li>馬蹄事前分布 (horseshoe prior) <span class="citation" data-cites="Carvalho+2009">(<a href="#ref-Carvalho+2009" role="doc-biblioref">Carvalho et al., 2009</a>)</span>, <span class="citation" data-cites="Carvalho+2010">(<a href="#ref-Carvalho+2010" role="doc-biblioref">Carvalho et al., 2010</a>)</span></li>
<li>Bayesian elastic net <span class="citation" data-cites="Hans2011">(<a href="#ref-Hans2011" role="doc-biblioref">Hans, 2011</a>)</span></li>
</ul>
</div>
</div>
</div>
<p><span class="citation" data-cites="Ishwaran-Rao2005">(<a href="#ref-Ishwaran-Rao2005" role="doc-biblioref">Ishwaran and Rao, 2005</a>)</span> はこれらの研究より早い段階で，<span class="math inline">\(\pi\)</span> に <span class="math inline">\(0\)</span> の近くと <span class="math inline">\(0\)</span> から大きく離れた二峰を持つ分布を用意している．</p>
</section>
<section id="ベイズ縮小の効果" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="ベイズ縮小の効果"><span class="header-section-number">2.4</span> ベイズ縮小の効果</h3>
<p>スケールパラメータ <span class="math inline">\(\lambda\)</span> は，LASSO <span class="citation" data-cites="Tibshirani1996">(<a href="#ref-Tibshirani1996" role="doc-biblioref">Tibshirani, 1996</a>)</span> では CV などの基準により選択することになるが，<span class="math inline">\(\lambda\)</span> を推定してモデル平均を行うことでより高い推定精度を得ることができる <span class="citation" data-cites="Hans2009">(<a href="#ref-Hans2009" role="doc-biblioref">Hans, 2009</a>)</span>．</p>
<p>同様にして事後平均推定量により推定精度は改善されるが，ほとんど確実にこれはスパースではない．従って推定量のスパース性と推定精度はトレードオフの関係にあり，完全にベイジアンに Bayesian LASSO を実行すると本末転倒に陥るという一面もある．</p>
<p>このためベイズ縮小事前分布を用いた場合，自動的にスパース性に基づいたモデル選択ができるというわけではなく，事後モデル確率 (posterior model probability) を最大にするものを見つけるという post-processing が必要になる <span class="citation" data-cites="Hahn-Carvalho2015">(Section 1.5 <a href="#ref-Hahn-Carvalho2015" role="doc-biblioref">Hahn and Carvalho, 2015, p. 438</a>)</span>, <span class="citation" data-cites="Piironen+2020">(<a href="#ref-Piironen+2020" role="doc-biblioref">Piironen et al., 2020</a>)</span>, <span class="citation" data-cites="Griffin2024">(<a href="#ref-Griffin2024" role="doc-biblioref">Jim E. Griffin, 2024</a>)</span>．</p>
<p>しかし以上のベイズモデル選択の手続きを踏むことによって，事後モデル確率を最大にするものという統計的・決定理論的に根拠を持ったモデル選択を実行することができる．</p>
<p>LASSO はベイズモデル選択の結果よりも予測性能が必ずしも高いわけではないにも拘らず，より多くの変数をモデルに残しがちであることも報告されている <span class="citation" data-cites="Porwal-Raftery2022">(<a href="#ref-Porwal-Raftery2022" role="doc-biblioref">Porwal and Raftery, 2022, p. 3</a>)</span>．これは馬蹄事前分布などの最新の縮小事前分布は，回帰係数の効果量やモデルの大きさなどに応じて適応的に正則化の強さを加減しているためだとも言える <span class="citation" data-cites="Li-Dutta-Roy2023">(<a href="#ref-Li-Dutta-Roy2023" role="doc-biblioref">Li et al., 2023</a>)</span>．</p>
</section>
<section id="馬蹄事前分布" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="馬蹄事前分布"><span class="header-section-number">2.5</span> 馬蹄事前分布</h3>
<p>馬蹄事前分布 <span class="math display">\[
\beta_j|\lambda_j,\tau\sim\mathrm{N}(0,\lambda_j^2\tau^2),\qquad\lambda_j\sim\operatorname{half-Cauchy}(0,1),
\]</span> は global-local shrinkage prior の１つである．</p>
<p>というのも，hyperparameter <span class="math inline">\(\tau\)</span> で決まる大域的な縮小効果がある一方で，半 Cauchy 分布による混合の構造が局所的なスケールパラメータ <span class="math inline">\(\lambda_j\)</span> を調整し，縮小される変数とされない変数とにコントラストをつけてくれる．</p>
<p>つまり，馬蹄事前分布は「少数の変数のみが大きなスケールを持つ」という信念を，階層的な構造で表現したものと理解できる．</p>
<p>最後の問題はハイパーパラメータ <span class="math inline">\(\tau\)</span> の調整である．</p>
<p>交差検証法や周辺尤度の値，情報量規準により <span class="math inline">\(\tau\)</span> の値を選んで推定を実行することもできる（経験ベイズ）．<span class="citation" data-cites="Polson-Scott2011">(<a href="#ref-Polson-Scott2011" role="doc-biblioref">Polson and Scott, 2011</a>)</span> では <span class="math display">\[
\tau|\sigma\sim\operatorname{half-Cauchy}(0,\sigma^2)
\]</span> という hyperprior を推奨している．ただし <span class="math inline">\(\sigma^2\)</span> は誤差の分散と共通とする．一方で <span class="citation" data-cites="Piironen-Vehtari2017Choice">(<a href="#ref-Piironen-Vehtari2017Choice" role="doc-biblioref">Piironen and Vehtari, 2017a</a>)</span> は事前の信念から非零の係数を持つべき変数の数 <span class="math inline">\(p_0\)</span> に対して <span class="math display">\[
\tau|\sigma\sim\operatorname{half-Cauchy}(0,\tau^2_0),\qquad\tau_0:=\frac{p_0}{p-p_0}\frac{\sigma^2}{\sqrt{n}},
\]</span> により hyperprior を置くことを推奨している．</p>
</section>
<section id="正則化" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="正則化"><span class="header-section-number">2.6</span> 正則化</h3>
<p>馬蹄事前分布はモデルに支持される変数の係数はほとんど縮小させないように設計されている．これは美点である一方で，正則化の効果を弱めてしまい，縮小事前分布であるはずが推定の安定化が望めない場合がある．</p>
<p>例えばロジスティック回帰に馬蹄事前分布をおくと，<a href="../../../posts/2024/Survey/BDA2.html#sec-separation">分離</a> などが起こって識別性が弱い場合に Cauchy 分布と同様の裾を持つために事後平均推定量が存在しなくなってしまう <span class="citation" data-cites="Ghosh+2018">(<a href="#ref-Ghosh+2018" role="doc-biblioref">Ghosh et al., 2018</a>)</span>．</p>
<p>また従来の馬蹄事前分布では，ときに事後分布が漏斗型を持ってしまい，収束が劇的に遅くなるという現象も観測されていた <span class="citation" data-cites="Piironen-Vehtari2015">(<a href="#ref-Piironen-Vehtari2015" role="doc-biblioref">Piironen and Vehtari, 2015</a>)</span>．</p>
<p>これらの問題を解決するために spike-and-slab 事前分布の slab width と同様の正則化ハイパーパラメータ <span class="math inline">\(c&gt;0\)</span> を導入した <strong>正則化馬蹄事前分布</strong> (regularized horseshoe prior) <span class="citation" data-cites="Piironen-Vehtari2017">(<a href="#ref-Piironen-Vehtari2017" role="doc-biblioref">Piironen and Vehtari, 2017b</a>)</span> が提案されている： <span class="math display">\[
\beta_j|\lambda_j,\tau,c\sim\mathrm{N}(0,\tau^2\widetilde{\lambda}_j^2),\qquad\widetilde{\lambda}_j:=\frac{c^2\lambda_j^2}{c^2+\tau^2\lambda_j^2},\lambda_j\sim\operatorname{half-Cauchy}(0,1).
\]</span> <span class="math inline">\(c\to\infty\)</span> の極限では馬蹄事前分布に一致する．この <span class="math inline">\(c\)</span> には次の hyperprior を推奨している： <span class="math display">\[
c^2\sim\operatorname{Inv-Gamma}(\nu/2,\nu s^2/2).
\]</span> これにより最大の係数に対して <span class="math inline">\(t_\nu(0,s^2)\)</span> の事前分布を置くことに等価になる <span class="citation" data-cites="Piironen-Vehtari2017">((2.11) <a href="#ref-Piironen-Vehtari2017" role="doc-biblioref">Piironen and Vehtari, 2017b, p. 5025</a>)</span>．</p>
</section>
<section id="rstanarm-での利用" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="rstanarm-での利用"><span class="header-section-number">2.7</span> <code>rstanarm</code> での利用</h3>
<p><code>rstanarm</code> では <code>hs</code> (hierarchical shrinkage) 事前分布</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hs</span>(<span class="at">df =</span> <span class="dv">1</span>, <span class="at">global_df =</span> <span class="dv">1</span>, <span class="at">global_scale =</span> <span class="fl">0.01</span>, <span class="at">slab_df =</span> <span class="dv">4</span>, <span class="at">slab_scale =</span> <span class="fl">2.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>が利用可能である．これは <span class="math display">\[
\tau|\sigma\sim\operatorname{half-t}(\textcolor{purple}{\mathtt{global_df}}),\qquad\lambda_j\sim\operatorname{half-t}(\textcolor{purple}{\mathtt{df}})
\]</span> というものであるから，<code>df=1</code>, <code>global_df=1</code> が正則化馬蹄事前分布に対応する．</p>
<p><code>global_scale</code> が <span class="math inline">\(\tau_0\)</span> に，<code>slab_scale</code> が <span class="math inline">\(s\)</span>，<code>slab_df</code> が <span class="math inline">\(\nu\)</span> に対応する．</p>
</section>
</section>
<section id="sec-Bayesian-variable-selection" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="sec-Bayesian-variable-selection"><span class="header-section-number">3</span> ベイズ変数選択</h2>
<section id="sec-hierarchical-modeling" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="sec-hierarchical-modeling"><span class="header-section-number">3.1</span> はじめに：階層モデリング</h3>
<p><strong>ベイズ変数選択</strong> では，説明変数 <span class="math inline">\(\{x_i\}_{i=1}^p\)</span> のそれぞれがモデルに含まれるかを意味する潜在変数 <span class="math inline">\(\{\gamma_i\}_{i=1}^p\in\{0,1\}^p=:\Gamma\)</span> の事後分布を算出して，特定の変数がモデルに含まれる確率を算出する．</p>
<p>最終的にこの確率分布は，ベイズモデル平均 (BMA: Bayesian Model Averaging) と言って，それぞれのモデルの事後予測を平均するためのプライヤーとして用いることもできる．</p>
<p>この方法では <span class="math display">\[
p(\gamma)=\prod_{i=1}^p\omega_i^{\gamma_i}(1-\omega_i)^{1-\gamma_i},\qquad p(\sigma^2)\,\propto\,\sigma^{-2}
\]</span> <span class="math display">\[
p(\beta|\sigma,\gamma)\,d\beta=\mathrm{N}_p(0,\Sigma(\sigma,\gamma))
\]</span> という階層構造を通じて，回帰モデルに潜在変数 <span class="math inline">\(\gamma\)</span> を導入する．<span class="math inline">\(\Sigma\)</span> は <span class="citation" data-cites="Liang+2022">(<a href="#ref-Liang+2022" role="doc-biblioref">X. Liang et al., 2022</a>)</span> では独立，<span class="citation" data-cites="George-McCulloch1997">(<a href="#ref-George-McCulloch1997" role="doc-biblioref">George and McCulloch, 1997</a>)</span> では <span class="math inline">\(g\)</span>-prior とする： <span class="math display">\[
\Sigma(\sigma,\gamma):=g\sigma^2(X^\top_\gamma X_\gamma)^{-1}.
\]</span> <span class="math inline">\(g\)</span> は global scale parameter と呼ばれ，これにさらに hyperprior を設定することもある <span class="citation" data-cites="Liang+2008">(<a href="#ref-Liang+2008" role="doc-biblioref">F. Liang et al., 2008</a>)</span>, <span class="citation" data-cites="Lay-Steel2009">(<a href="#ref-Lay-Steel2009" role="doc-biblioref">Ley and Steel, 2009</a>)</span>．</p>
<p>このアプローチは <span class="citation" data-cites="George-McCulloch1997">(<a href="#ref-George-McCulloch1997" role="doc-biblioref">George and McCulloch, 1997</a>)</span> らによって創始された．（仮に <span class="math inline">\(p\)</span> が比例的に増えるとしても） <span class="math inline">\(n\to\infty\)</span> の極限で PIP は正しいモデル上の Delta 測度に収束する <span class="citation" data-cites="Shang-Clayton2011">(<a href="#ref-Shang-Clayton2011" role="doc-biblioref">Shang and Clayton, 2011</a>)</span>．</p>
</section>
<section id="sec-SSVS" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="sec-SSVS"><span class="header-section-number">3.2</span> 確率的探索法</h3>
<p>特に <span class="citation" data-cites="George-McCulloch1993">(<a href="#ref-George-McCulloch1993" role="doc-biblioref">George and McCulloch, 1993</a>)</span> では <span id="eq-SSVS"><span class="math display">\[
\beta_i|\gamma_i\sim(1-\gamma_i)\mathrm{N}(0,\sigma_i^2)+\gamma_i\mathrm{N}(0,c_i^2\sigma_i^2)
\tag{2}\]</span></span> という構造を設定し，データ拡張に基づく Gibbs サンプラーによって推定することを提案した．</p>
<p>この方法は <strong>確率的探索法</strong> (SSVS: Stochastic Search Variable Selection) と呼ばれる．<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p>しかし (<a href="#eq-SSVS" class="quarto-xref">2</a>) は spike-and-slab (<a href="#eq-spike-and-slab" class="quarto-xref">1</a>) の近似になっているため，<span class="math inline">\(\gamma_i=1\)</span> の事後確率は正確に PIP になっているわけではない．</p>
<p>この近似は Gibbs サンプラーを高速にするという利点はあったかもしれないが，現代では spike-and-slab (<a href="#eq-spike-and-slab" class="quarto-xref">1</a>) に直接適用できる高速なサンプラーが多数開発されている．</p>
</section>
<section id="sec-Add-Delete-Swap" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="sec-Add-Delete-Swap"><span class="header-section-number">3.3</span> Add-Delete-Swap による探索</h3>
<p>計量化学 (chemometrics) では <span class="math inline">\(p\)</span> が特に高次元になり得る．<span class="citation" data-cites="Brown+1998">(<a href="#ref-Brown+1998" role="doc-biblioref">Brown et al., 1998</a>)</span> は近赤外線分光法で得られたデータから，予測に有用な波長を選択する問題に対処するためにベイズ変数選択の方法を用いることを考えた．</p>
<p>そのためにまず第 <a href="#sec-hierarchical-modeling" class="quarto-xref">3.1</a> 節の階層モデルを多次元化し，推定には乱歩 MH 法を用いた．</p>
<p><span class="citation" data-cites="Brown+1998">(<a href="#ref-Brown+1998" role="doc-biblioref">Brown et al., 1998</a>)</span> の乱歩 MH 法の提案核は，Add-Delete-Swap の動きをするものであった：</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>次の２つの動きを，それぞれ確率 <span class="math inline">\(\phi,1-\phi\)</span> で行う；</p>
<ol type="1">
<li><p>Adding or Deleting</p>
<p>新たな変数 <span class="math inline">\(x_i\)</span> をランダムに選び，まだモデルに入っていない場合は入れ，すでにモデルに含まれている場合は取り除く．</p></li>
<li><p>Swapping</p>
<p>モデルに含まれていない変数 <span class="math inline">\(x_i\)</span> と含まれている変数 <span class="math inline">\(x_j\)</span> をそれぞれランダムに選び，入れ替える．</p></li>
</ol>
</div>
</div>
</div>
<p><span class="citation" data-cites="Yang+2016">(<a href="#ref-Yang+2016" role="doc-biblioref">Yang et al., 2016</a>)</span> は MH 法の計算複雑性を解析し，<span class="math inline">\(p\)</span> が大きい場合にも計算量が線型にしか増加しない乱歩 MH 法を提案した．</p>
</section>
<section id="超次元-mcmc-による-pip-算出" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="超次元-mcmc-による-pip-算出"><span class="header-section-number">3.4</span> 超次元 MCMC による PIP 算出</h3>
<p>事後包含確率を出すにあたって，Reversible-Jump MCMC <span class="citation" data-cites="Green1995">(<a href="#ref-Green1995" role="doc-biblioref">Green, 1995</a>)</span> などの超次元手法を用いることも考えられる．</p>
<p>超次元 MCMC とは，一般に複数のモデルから同時にサンプリングするための用いられ，ベイズ変数選択法は分解可能なグラフィカルモデルに対する超次元 MCMC 法の特別な場合と見れる <span class="citation" data-cites="Godsill2001">(<a href="#ref-Godsill2001" role="doc-biblioref">Godsill, 2001, p. 232</a>)</span>．</p>
<p>詳しくは別稿で取り上げるが，特に Sticky PDMP <span class="citation" data-cites="Bierkens+2023">(<a href="#ref-Bierkens+2023" role="doc-biblioref">Bierkens et al., 2023</a>)</span> は有力な PIP 算出法になる．</p>
<div id="listing-lst-survey" class="listing quarto-float quarto-figure quarto-figure-left quarto-listing quarto-listing-container-grid anchored">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="QmF5ZXNpYW4lMkNNQ01DJTJDU3RhdGlzdGljcw==" data-listing-date-sort="1726963200000" data-listing-file-modified-sort="1752119711578" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="2" data-listing-word-count-sort="349">
<a href="../../../posts/2024/TransDimensionalModels/BayesTrans.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="../../../posts/2024/TransDimensionalModels/Images/StickyComparison.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
超次元 MCMC
</h5>
<div class="card-subtitle listing-subtitle">
モデル選択のためのマルコフ連鎖モンテカルロ法
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-22
</div>
</div>
</div>
</div></a>
</div>
<div class="g-col-1" data-index="1" data-categories="QmF5ZXNpYW4lMkNTdGF0aXN0aWNzJTJDUERNUA==" data-listing-date-sort="1734739200000" data-listing-file-modified-sort="1752119711578" data-listing-date-modified-sort="1737849600000" data-listing-reading-time-sort="2" data-listing-word-count-sort="253">
<a href="../../../posts/2024/TransDimensionalModels/BayesSticky.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="Images/StickyComparison.png" style="height: 150px;"  class="thumbnail-image card-img"/></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Sticky PDMP によるベイズ変数選択
</h5>
<div class="card-subtitle listing-subtitle">
非絶対連続分布からの正確なサンプリング
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-12-21
</div>
</div>
</div>
</div></a>
</div>
<div class="g-col-1" data-index="2" data-categories="QmF5ZXNpYW4lMkNTdGF0aXN0aWNzJTJDTUNNQw==" data-listing-date-sort="1734739200000" data-listing-file-modified-sort="1752119711578" data-listing-date-modified-sort="1734739200000" data-listing-reading-time-sort="1" data-listing-word-count-sort="97">
<a href="../../../posts/2024/TransDimensionalModels/BayesTraverse.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="../Stat/MeanOfGaussian.svg" style="height: 150px;"  class="thumbnail-image card-img"/></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
連続・離散を往来する MCMC サンプラー
</h5>
<div class="card-subtitle listing-subtitle">
Zig-Zag within Gibbs という考え方
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-12-21
</div>
</div>
</div>
</div></a>
</div>
</div>
<div class="listing-no-matching d-none">No matching items</div>
</div>
</section>
<section id="計算の問題" class="level3" data-number="3.5">
<h3 data-number="3.5" class="anchored" data-anchor-id="計算の問題"><span class="header-section-number">3.5</span> 計算の問題</h3>
<p>ベイズ変数選択とはモデル空間 <span class="math inline">\(\Gamma=\{0,1\}^p\)</span> 上の事後分布を計算することであるが，これを効率的に行う MCMC を構成することが中心的な問題になる．</p>
<p>ここまで叙述してきた Gibbs サンプラー（例えば確率的探索法 <a href="#sec-SSVS" class="quarto-xref">3.2</a> など）は，<span class="math inline">\(p=2\)</span> の極めて簡単な設定で簡単に崩壊する．というのも，２つの同等な説明力を持つ確率変数が強い相関を持つ場合，<span class="math inline">\((\beta,\gamma)\)</span> の同時分布は強い二峰性を持つ．</p>
<p>その結果ただナイーブに Gibbs サンプラーを適用しただけでは片方の峰しか見つけることができず，PIP について偏った結果を出してしまう <span class="citation" data-cites="Zanella-Roberts2019">(Section 5.1 <a href="#ref-Zanella-Roberts2019" role="doc-biblioref">Zanella and Roberts, 2019</a>)</span>．</p>
<p>推定したいモデルが階層モデルである限り，多峰性の問題は常に付きものである．</p>
<div id="listing-lst-embedding1" class="listing quarto-float quarto-figure quarto-figure-left quarto-listing quarto-listing-container-grid anchored">
<div class="list grid quarto-listing-cols-1">
<div class="g-col-1" data-index="0" data-categories="QmF5ZXNpYW4lMkNTdGF0aXN0aWNzJTJDTUNNQyUyQ1I=" data-listing-date-sort="1734825600000" data-listing-file-modified-sort="1752119711577" data-listing-date-modified-sort="1734912000000" data-listing-reading-time-sort="5" data-listing-word-count-sort="954">
<a href="../../../posts/2024/TransDimensionalModels/Bafumi.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="Files/Bafumi_Model1.png" style="height: 150px;"  class="thumbnail-image card-img"/></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
On the Identifiability of the Bafumi et. al.&nbsp;Ideal Point Model
</h5>
<div class="card-subtitle listing-subtitle">
Rethinking of the Hierarchical Model of Bafumi et. al.&nbsp;(2005)
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-12-22
</div>
</div>
</div>
</div></a>
</div>
</div>
<div class="listing-no-matching d-none">No matching items</div>
</div>
<p><span class="math inline">\(p=2\)</span> の時でさえ深刻になり得る多峰性の問題に加えて，共変量の数 <span class="math inline">\(p\)</span> が大きい現代的な問題に対処する必要もあることを思えば，ベイズ変数選択の問題は，多峰性に強い効率的なベイズ計算法を開発するという普遍的な課題に回収されるのである．</p>
</section>
<section id="tempered-gibbs-サンプラー" class="level3" data-number="3.6">
<h3 data-number="3.6" class="anchored" data-anchor-id="tempered-gibbs-サンプラー"><span class="header-section-number">3.6</span> Tempered Gibbs サンプラー</h3>
<p>目標分布の条件付き分布 <span class="math inline">\(f(x_i|x_{-i})\)</span> が多峰性を持つ場合，何らかの軟化 <span class="math inline">\(g(x_i|x_{-i})\)</span> を考えることがあり得る．これに対して <span class="math display">\[
p_i(x):=\frac{g(x_i|x_{-i})}{f(x_i|x_{-i})}
\]</span> と定め，まず <span class="math inline">\((p_1(x),\cdots,p_p(x))\)</span> に従って <span class="math inline">\(i\in[p]\)</span> を選び，続いて <span class="math inline">\(x_i\sim g(x_i|x_{-i})\)</span> をサンプリングする random scan Gibbs サンプラーを考えると，これはやはり <span class="math inline">\(f\)</span> を不変分布にもつ．</p>
<p>この方法では <span class="math inline">\(p_i(x)\)</span> で各説明変数 <span class="math inline">\(x_i\)</span> に傾斜をつけているために，特に PIP の高い <span class="math inline">\(i\in[p]\)</span> から優先的にサンプリングすることができる．この方法は後述 <a href="#sec-Locally-Informed-MH-Samplers" class="quarto-xref">3.7</a> 節の informed MCMC の先駆けとなった．</p>
<!--
### SVEN

[@Hans+2007] では確率的探索法 [-@sec-SSVS] を，Add-Delete-Swap [-@sec-Add-Delete-Swap] の動きを取り入れることでさらに洗練させることを考えた．

１つの変数のみを Add-Delete-Swap して得る配置のみ

SVEN (Selection of Variables with Embedded screeNing) [@Li-Dutta-Roy2023]．
-->
</section>
<section id="sec-Locally-Informed-MH-Samplers" class="level3" data-number="3.7">
<h3 data-number="3.7" class="anchored" data-anchor-id="sec-Locally-Informed-MH-Samplers"><span class="header-section-number">3.7</span> Locally Informed MH Samplers</h3>
<p>Add-Delete-Swap による乱歩 MH 法 <a href="#sec-Add-Delete-Swap" class="quarto-xref">3.3</a> の設計は，見通しの良い素朴な構成であるが，効率的な動きである保証は全くない．さらには <span class="math inline">\(\phi\)</span> やそれぞれの候補を持ってくる確率など，ユーザーが調整する必要があるハイパーパラメータも多い．</p>
<p>対称かつ局所的なサンプラーの中では，採択率が高いほど効率が良い <span class="citation" data-cites="Peskun1973">(<a href="#ref-Peskun1973" role="doc-biblioref">Peskun, 1973</a>)</span>, <span class="citation" data-cites="Tierney1998">(<a href="#ref-Tierney1998" role="doc-biblioref">Tierney, 1998</a>)</span>．そこで離散空間上の乱歩 MH 法の採択率を上げるために，現在位置の周囲の点の情報を収集して次の動きを決めるサンプラーが <strong>Informed MCMC</strong> の名前の下で開発されている <span class="citation" data-cites="Liang+2022">(<a href="#ref-Liang+2022" role="doc-biblioref">X. Liang et al., 2022, p. 84</a>)</span>．</p>
<p>多くの locally informed MCMC <span class="citation" data-cites="Zanella2020">(<a href="#ref-Zanella2020" role="doc-biblioref">Zanella, 2020</a>)</span> では，通常の乱歩 MH 核 <span class="math inline">\(Q\)</span> を基底核 (base kernel) として，これを近傍での事後分布の様子を要約した <strong>釣り合い関数</strong> (balancing function) <span class="math inline">\(g\)</span> を用いて修正することで効率的な動きを達成する： <span class="math display">\[
q_g(\gamma,\gamma')\,\propto\,g\left(\frac{\pi(\gamma')}{\pi(\gamma)}\right)q(\gamma,\gamma').
\]</span></p>
<p>この中でも LIT (Locally Informed and Thresholded proposal) <span class="citation" data-cites="Zhou+2022">(<a href="#ref-Zhou+2022" role="doc-biblioref">Zhou et al., 2022</a>)</span> は釣り合い関数として閾値関数 (threshold function) <span class="math display">\[
g(t)=p^L\land(p^l\lor t),\qquad-\infty&lt;l&lt;L&lt;\infty.
\]</span> を用い，さらに提案核 <span class="math inline">\(Q\)</span> を単なる一様分布ではなく第 <a href="#sec-Add-Delete-Swap" class="quarto-xref">3.3</a> 節で考えられた Add-Delete-Swap 核 <span class="citation" data-cites="Brown+1998">(<a href="#ref-Brown+1998" role="doc-biblioref">Brown et al., 1998</a>)</span> にとることで，一定の条件の下で <strong>次元 <span class="math inline">\(p\)</span> に依存しない収束速度</strong> を達成することを示した．</p>
</section>
<section id="適応的なサンプラー" class="level3" data-number="3.8">
<h3 data-number="3.8" class="anchored" data-anchor-id="適応的なサンプラー"><span class="header-section-number">3.8</span> 適応的なサンプラー</h3>
<p>LIT は固定した基底核 <span class="math inline">\(Q\)</span> を取り，そこから <span class="math inline">\(g\)</span> で修正することを基本戦略としていた．一方でそもそも基底核 <span class="math inline">\(Q\)</span> を適応的に調整していくメカニズムを導入することができる．</p>
<p>ASI (Adaptively Scaled Individual adaptation) <span class="citation" data-cites="Griffin+2021">(<a href="#ref-Griffin+2021" role="doc-biblioref">J. E. Griffin et al., 2021</a>)</span> では，<span class="citation" data-cites="Brown+1998">(<a href="#ref-Brown+1998" role="doc-biblioref">Brown et al., 1998</a>)</span> の Add-Delete-Swap 核 <a href="#sec-Add-Delete-Swap" class="quarto-xref">3.3</a> <span class="math display">\[
q_\eta(\gamma,\gamma')=\prod_{j=1}^pq_{\eta,j}(\gamma_j,\gamma_j'),\qquad \eta=(A_1,\cdots,A_p,D_1,\cdots,D_p)\in(0,1)^{2p},
\]</span> <span class="math display">\[
q_{\eta,j}(0,1)=\eta_j=A_j,\qquad q_{\eta,j}(1,0)=\eta_{p+j}=D_j,
\]</span> を元にして，<span class="math inline">\(\eta=(A,D)\)</span> を適応的に更新していくことを考える．その際の目安は，<span class="math inline">\(x_j\)</span> の PIP <span class="math inline">\(\pi_j\)</span> から定まる <span class="math display">\[
A_j^\mathrm{opt}:=1\land\frac{\pi_j}{1-\pi_j},\qquad D_j^\mathrm{opt}:=1\land\frac{1-\pi_j}{\pi_j},
\]</span> である．これの推定量 <span class="math inline">\(\eta^{(i)}\)</span> を各段階で構成した上で，総じた採択率を調整する学習率のようなパラメータ <span class="math inline">\(\zeta^{(i)}\)</span> も導入し，<span class="citation" data-cites="Robbins-Monro1951">(<a href="#ref-Robbins-Monro1951" role="doc-biblioref">Robbins and Monro, 1951</a>)</span> の方法で更新していく．</p>
<p>実は ASI は <span class="citation" data-cites="Liang+2023">(<a href="#ref-Liang+2023" role="doc-biblioref">X. Liang et al., 2023</a>)</span> がいう <strong>確率近傍サンプラー</strong> (random neighbourhood sampler) の例になっている．これは Add-Delete-Swap <span class="citation" data-cites="Brown+1998">(<a href="#ref-Brown+1998" role="doc-biblioref">Brown et al., 1998</a>)</span> のように提案される近傍が，補助的な離散確率変数 <span class="math inline">\(k\in[K]\)</span> によって定まるような乱歩 MH 法をいう．</p>
<p><span class="citation" data-cites="Liang+2023">(<a href="#ref-Liang+2023" role="doc-biblioref">X. Liang et al., 2023</a>)</span> では ASI によって構成される確率的近傍の中から，さらに locally informed に次の動きを選ぶことを提案し， <strong>適応的確率近傍</strong> (ARNI: Adaptive Random Neighbourhood Informed) サンプラーと呼んでいる．これにより ASI で上がりきらなかった採択率を押し上げつつ，計算量を抑えつつも良い近傍を提案するメカニズムを取り入れることができる．</p>
<p>これにより <span class="math inline">\(p\)</span> に依らない収束だけでなく，計算複雑性も <span class="math inline">\(p\)</span> の次元に対してスケールするものが得られると期待される．</p>
</section>
<section id="非可逆なサンプラー" class="level3" data-number="3.9">
<h3 data-number="3.9" class="anchored" data-anchor-id="非可逆なサンプラー"><span class="header-section-number">3.9</span> 非可逆なサンプラー</h3>
<p>Informed MCMC とは，連続空間上で言えば，MALA などの勾配情報を利用したサンプラーである．このような乱歩 MH 法の修正として得られる効率的なサンプラーを <span class="citation" data-cites="Liang+2022">(<a href="#ref-Liang+2022" role="doc-biblioref">X. Liang et al., 2022</a>)</span> は <strong>近傍サンプラー</strong> (neighbourhood sampler) と呼んでいる．</p>
<p>MALA などの Langevin 拡散を元にした乱歩 MH 法は革新的であったが，現在最も効率的なサンプラーは，局所的な動きを廃した HMC 法と，非可逆な動きを達成する PDMP (Piecewise Deterministic Markov Process) / ECMC (Event-Chain Monte Carlo) である．</p>
<p>離散空間上でもこれらのサンプラーに対応するものは高い効率を示すだろうと思われる．</p>
<p>一般の離散空間上でも局所性の打開には <span class="citation" data-cites="Nishimura+2020">(<a href="#ref-Nishimura+2020" role="doc-biblioref">Nishimura et al., 2020</a>)</span>，可逆性の打開には <span class="citation" data-cites="Koskela2022">(<a href="#ref-Koskela2022" role="doc-biblioref">Koskela, 2022</a>)</span> などの試みがあるが，殊に変数選択に関しては Sticky PDMP <span class="citation" data-cites="Bierkens+2023">(<a href="#ref-Bierkens+2023" role="doc-biblioref">Bierkens et al., 2023</a>)</span> という画期的な手法が開発されている．</p>
<p>これに関しては次稿で詳しく取り上げる：</p>
<div id="listing-lst-embedding2" class="listing quarto-float quarto-figure quarto-figure-left quarto-listing quarto-listing-container-grid anchored">
<div class="list grid quarto-listing-cols-1">
<div class="g-col-1" data-index="0" data-categories="QmF5ZXNpYW4lMkNTdGF0aXN0aWNzJTJDUERNUA==" data-listing-date-sort="1734739200000" data-listing-file-modified-sort="1752119711578" data-listing-date-modified-sort="1737849600000" data-listing-reading-time-sort="2" data-listing-word-count-sort="253">
<a href="../../../posts/2024/TransDimensionalModels/BayesSticky.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="Images/StickyComparison.png" style="height: 150px;"  class="thumbnail-image card-img"/></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Sticky PDMP によるベイズ変数選択
</h5>
<div class="card-subtitle listing-subtitle">
非絶対連続分布からの正確なサンプリング
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-12-21
</div>
</div>
</div>
</div></a>
</div>
</div>
<div class="listing-no-matching d-none">No matching items</div>
</div>
</section>
</section>



<div id="quarto-appendix" class="default"><section id="文献紹介" class="level2 appendix" data-number="4"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">4</span> 文献紹介</h2><div class="quarto-appendix-contents">

<p>変数選択のための事前分布とその <span class="math inline">\(R^2\)</span> 上に定める事前分布については <span class="citation" data-cites="Gelman-Hill-Vehtari2020">(12.7 節 <a href="#ref-Gelman-Hill-Vehtari2020" role="doc-biblioref">Gelman et al., 2020</a>)</span> で丁寧に議論されている．</p>
<p>この第一のアプローチ・縮小事前分布については <span class="citation" data-cites="Bhadra+2019">(<a href="#ref-Bhadra+2019" role="doc-biblioref">Bhadra et al., 2019</a>)</span> のレビューがある．他には <span class="citation" data-cites="Griffin-Brown2021">(<a href="#ref-Griffin-Brown2021" role="doc-biblioref">Jim E. Griffin and Brown, 2021</a>)</span>, <span class="citation" data-cites="Griffin-Brown2017">(<a href="#ref-Griffin-Brown2017" role="doc-biblioref">Jim E. Griffin and Brown, 2017</a>)</span>, <span class="citation" data-cites="Hahn-Carvalho2015">(<a href="#ref-Hahn-Carvalho2015" role="doc-biblioref">Hahn and Carvalho, 2015</a>)</span> が詳しい．</p>
<p><span class="citation" data-cites="George-McCulloch1993">(<a href="#ref-George-McCulloch1993" role="doc-biblioref">George and McCulloch, 1993</a>)</span> による変数選択法が <span class="citation" data-cites="Hoff2009">(Chapter 9 <a href="#ref-Hoff2009" role="doc-biblioref">Hoff, 2009</a>)</span> で取り上げられている．</p>
<p>ベイズ変数選択手法の概観は <span class="citation" data-cites="Liang+2023">(<a href="#ref-Liang+2023" role="doc-biblioref">X. Liang et al., 2023</a>)</span> や <span class="citation" data-cites="Griffin2024">(<a href="#ref-Griffin2024" role="doc-biblioref">Jim E. Griffin, 2024</a>)</span> のイントロに圧倒されるほどまとまっている．<span class="citation" data-cites="Griffin2024">(<a href="#ref-Griffin2024" role="doc-biblioref">Jim E. Griffin, 2024</a>)</span> ではモデルの空間上に得られた事後分布の情報を効果的に表示するための「信用区間」の構成法を提案している．</p>




</div></section><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-Barr+2013" class="csl-entry" role="listitem">
Barr, D. J., Levy, R., Scheepers, C., and Tily, H. J. (2013). <a href="https://doi.org/10.1016/j.jml.2012.11.001">Random effects structure for confirmatory hypothesis testing: Keep it maximal</a>. <em>Journal of Memory and Language</em>, <em>68</em>(3), 255–278.
</div>
<div id="ref-Bhadra+2019" class="csl-entry" role="listitem">
Bhadra, A., Datta, J., Polson, N. G., and Willard, B. (2019). <a href="https://doi.org/10.1214/19-STS700"><span>Lasso Meets Horseshoe: A Survey</span></a>. <em>Statistical Science</em>, <em>34</em>(3), 405–427.
</div>
<div id="ref-Bierkens+2023" class="csl-entry" role="listitem">
Bierkens, J., Grazzi, S., Meulen, F. van der, and Schauer, M. (2023). <a href="https://doi.org/10.1007/s11222-022-10180-5"><span class="nocase">Sticky PDMP Samplers for Sparse and Local Inference Problems</span></a>. <em>Statistics and Computing</em>, <em>33</em>(1), 8.
</div>
<div id="ref-Brown+1998" class="csl-entry" role="listitem">
Brown, P. J., Vannucci, M., and Fearn, T. (1998). <a href="https://doi.org/10.1002/(SICI)1099-128X(199805/06)12:3<173::AID-CEM505>3.0.CO;2-0">Bayesian wavelength selection in multicomponent analysis</a>. <em>Journal of Chemometrics</em>, <em>12</em>(3), 173–182.
</div>
<div id="ref-Carvalho+2009" class="csl-entry" role="listitem">
Carvalho, C. M., Polson, N. G., and Scott, J. G. (2009). <a href="https://proceedings.mlr.press/v5/carvalho09a.html">Handling sparsity via the horseshoe</a>. In D. van Dyk and M. Welling, editors, <em>Proceedings of the twelfth international conference on artificial intelligence and statistics</em>,Vol. 5, pages 73–80. Hilton Clearwater Beach Resort, Clearwater Beach, Florida USA: PMLR.
</div>
<div id="ref-Carvalho+2010" class="csl-entry" role="listitem">
Carvalho, C. M., Polson, N. G., and Scott, J. G. (2010). <a href="https://doi.org/10.1093/biomet/asq017"><span class="nocase">The horseshoe estimator for sparse signals</span></a>. <em>Biometrika</em>, <em>97</em>(2), 465–480.
</div>
<div id="ref-Castillo+2015" class="csl-entry" role="listitem">
Castillo, I., Schmidt-Hieber, J., and Vaart, A. van der. (2015). <a href="https://doi.org/10.1214/15-AOS1334"><span class="nocase">Bayesian linear regression with sparse priors</span></a>. <em>The Annals of Statistics</em>, <em>43</em>(5), 1986–2018.
</div>
<div id="ref-Gelman-Hill-Vehtari2020" class="csl-entry" role="listitem">
Gelman, A., Hill, J., and Vehtari, A. (2020). <em><a href="https://avehtari.github.io/ROS-Examples/">Regression and other stories</a></em>. Cambridge University Press.
</div>
<div id="ref-George-McCulloch1993" class="csl-entry" role="listitem">
George, E. I., and McCulloch, R. E. (1993). <a href="http://www.jstor.org/stable/2290777">Variable selection via gibbs sampling</a>. <em>Journal of the American Statistical Association</em>, <em>88</em>(423), 881–889.
</div>
<div id="ref-George-McCulloch1997" class="csl-entry" role="listitem">
George, E. I., and McCulloch, R. E. (1997). <a href="http://www.jstor.org/stable/24306083">APPROACHES FOR BAYESIAN VARIABLE SELECTION</a>. <em>Statistica Sinica</em>, <em>7</em>(2), 339–373.
</div>
<div id="ref-Ghosh+2018" class="csl-entry" role="listitem">
Ghosh, J., Li, Y., and Mitra, R. (2018). <a href="https://doi.org/10.1214/17-BA1051"><span class="nocase">On the Use of Cauchy Prior Distributions for Bayesian Logistic Regression</span></a>. <em>Bayesian Analysis</em>, <em>13</em>(2), 359–383.
</div>
<div id="ref-Godsill2001" class="csl-entry" role="listitem">
Godsill, S. J. (2001). <a href="https://doi.org/10.1198/10618600152627924">On the relationship between markov chain monte carlo methods for model uncertainty</a>. <em>Journal of Computational and Graphical Statistics</em>, <em>10</em>(2), 230–248. doi: 10.1198/10618600152627924.
</div>
<div id="ref-Green1995" class="csl-entry" role="listitem">
Green, P. J. (1995). <a href="http://www.jstor.org/stable/2337340">Reversible jump markov chain monte carlo computation and bayesian model determination</a>. <em>Biometrika</em>, <em>82</em>(4), 711–732.
</div>
<div id="ref-Griffin2024" class="csl-entry" role="listitem">
Griffin, Jim E. (2024). <a href="https://arxiv.org/abs/2402.12323">Expressing and visualizing model uncertainty in bayesian variable selection using cartesian credible sets</a>.
</div>
<div id="ref-Griffin-Brown2017" class="csl-entry" role="listitem">
Griffin, Jim E., and Brown, P. (2017). <a href="https://doi.org/10.1214/15-BA990"><span class="nocase">Hierarchical Shrinkage Priors for Regression Models</span></a>. <em>Bayesian Analysis</em>, <em>12</em>(1), 135–159.
</div>
<div id="ref-Griffin-Brown2021" class="csl-entry" role="listitem">
Griffin, Jim E., and Brown, P. J. (2021). <a href="https://doi.org/10.1016/j.chemolab.2021.104255">Bayesian global-local shrinkage methods for regularisation in the high dimension linear model</a>. <em>Chemometrics and Intelligent Laboratory Systems</em>, <em>210</em>, 104255.
</div>
<div id="ref-Griffin+2021" class="csl-entry" role="listitem">
Griffin, J. E., Łatuszyński, K. G., and Steel, M. F. J. (2021). <a href="https://doi.org/10.1093/biomet/asaa055">In search of lost mixing time: Adaptive markov chain monte carlo schemes for bayesian variable selection with very large p</a>. <em>Biometrika</em>, <em>108</em>(1), 53–69.
</div>
<div id="ref-Hahn-Carvalho2015" class="csl-entry" role="listitem">
Hahn, P. R., and Carvalho, C. M. (2015). <a href="https://doi.org/10.1080/01621459.2014.993077">Decoupling shrinkage and selection in bayesian linear models: A posterior summary perspective</a>. <em>Journal of the American Statistical Association</em>, <em>110</em>(509), 435–448. doi: 10.1080/01621459.2014.993077.
</div>
<div id="ref-Hans2009" class="csl-entry" role="listitem">
Hans, C. (2009). <a href="http://www.jstor.org/stable/27798870">Bayesian lasso regression</a>. <em>Biometrika</em>, <em>96</em>(4), 835–845.
</div>
<div id="ref-Hans2011" class="csl-entry" role="listitem">
Hans, C. (2011). <a href="https://doi.org/10.1198/jasa.2011.tm09241">Elastic net regression modeling with the orthant normal prior</a>. <em>Journal of the American Statistical Association</em>, <em>106</em>(496), 1383–1393. doi: 10.1198/jasa.2011.tm09241.
</div>
<div id="ref-Hastie+2015" class="csl-entry" role="listitem">
Hastie, T., Tibshirani, R., and Wainwright, M. (2015). <em><a href="https://doi.org/10.1201/b18401">Statistical learning with sparsity: The lasso and generalizations</a></em>. Chapman; Hall/CRC.
</div>
<div id="ref-Hoeting+1999" class="csl-entry" role="listitem">
Hoeting, J. A., Madigan, D., Raftery, A. E., and Volinsky, C. T. (1999). <a href="https://doi.org/10.1214/ss/1009212519"><span class="nocase">Bayesian model averaging: a tutorial (with comments by M. Clyde, David Draper and E. I. George, and a rejoinder by the authors</span></a>. <em>Statistical Science</em>, <em>14</em>(4), 382–417.
</div>
<div id="ref-Hoff2009" class="csl-entry" role="listitem">
Hoff, P. D. (2009). <em><a href="https://doi.org/10.1007/978-0-387-92407-6">A first course in bayesian statistical methods</a></em>. Springer New York.
</div>
<div id="ref-Ishwaran-Rao2005" class="csl-entry" role="listitem">
Ishwaran, H., and Rao, J. S. (2005). <a href="https://doi.org/10.1214/009053604000001147"><span class="nocase">Spike and slab variable selection: Frequentist and Bayesian strategies</span></a>. <em>The Annals of Statistics</em>, <em>33</em>(2), 730–773.
</div>
<div id="ref-Koskela2022" class="csl-entry" role="listitem">
Koskela, J. (2022). <a href="https://doi.org/10.1080/10618600.2022.2032722">Zig-zag sampling for discrete structures and nonreversible phylogenetic MCMC</a>. <em>Journal of Computational and Graphical Statistics</em>, <em>31</em>(3), 684–694. doi: 10.1080/10618600.2022.2032722.
</div>
<div id="ref-Lay-Steel2009" class="csl-entry" role="listitem">
Ley, E., and Steel, M. F. J. (2009). <a href="https://doi.org/10.1002/jae.1057">On the effect of prior assumptions in bayesian model averaging with applications to growth regression</a>. <em>Journal of Applied Econometrics</em>, <em>24</em>(4), 651–674.
</div>
<div id="ref-Li-Dutta-Roy2023" class="csl-entry" role="listitem">
Li, D., Dutta, S., and Roy, V. (2023). <a href="https://doi.org/10.1080/10618600.2022.2074428">Model based screening embedded bayesian variable selection for ultra-high dimensional settings</a>. <em>Journal of Computational and Graphical Statistics</em>, <em>32</em>(1), 61–73.
</div>
<div id="ref-Liang+2008" class="csl-entry" role="listitem">
Liang, F., Paulo, R., Molina, G., Clyde, M. A., and Berger, J. O. (2008). <a href="https://doi.org/10.1198/016214507000001337">Mixtures of g priors for bayesian variable selection</a>. <em>Journal of the American Statistical Association</em>, <em>103</em>(481), 410–423. doi: 10.1198/016214507000001337.
</div>
<div id="ref-Liang+2022" class="csl-entry" role="listitem">
Liang, X., Livingstone, S., and Griffin, J. (2022). <a href="https://doi.org/10.1007/s11222-022-10137-8">Adaptive random neighbourhood informed markov chain monte carlo for high-dimensional bayesian variable selection</a>. <em>Statistics and Computing</em>, <em>32</em>(5), 84.
</div>
<div id="ref-Liang+2023" class="csl-entry" role="listitem">
Liang, X., Livingstone, S., and Griffin, J. (2023). <a href="https://doi.org/10.3390/e25091310">Adaptive MCMC for bayesian variable selection in generalised linear models and survival models</a>. <em>Entropy</em>, <em>25</em>(9).
</div>
<div id="ref-Mitchell-Beauchamp1988" class="csl-entry" role="listitem">
Mitchell, T. J., and Beauchamp, J. J. (1988). <a href="http://www.jstor.org/stable/2290129">Bayesian variable selection in linear regression</a>. <em>Journal of the American Statistical Association</em>, <em>83</em>(404), 1023–1032.
</div>
<div id="ref-Nishimura+2020" class="csl-entry" role="listitem">
Nishimura, A., Dunson, D. B., and Lu, J. (2020). <a href="https://doi.org/10.1093/biomet/asz083">Discontinuous hamiltonian monte carlo for discrete parameters and discontinuous likelihoods</a>. <em>Biometrika</em>, <em>107</em>(2), 365–380.
</div>
<div id="ref-Park-Casella2008" class="csl-entry" role="listitem">
Park, T., and Casella, G. (2008). <a href="https://doi.org/10.1198/016214508000000337">The bayesian lasso</a>. <em>Journal of the American Statistical Association</em>, <em>103</em>(482), 681–686. doi: 10.1198/016214508000000337.
</div>
<div id="ref-Peskun1973" class="csl-entry" role="listitem">
Peskun, P. H. (1973). <a href="https://doi.org/10.1093/biomet/60.3.607">Optimum monte-carlo sampling using markov chains</a>. <em>Biometrika</em>, <em>60</em>(3), 607–612.
</div>
<div id="ref-Piironen+2020" class="csl-entry" role="listitem">
Piironen, J., Paasiniemi, M., and Vehtari, A. (2020). <a href="https://doi.org/10.1214/20-EJS1711"><span class="nocase">Projective inference in high-dimensional problems: Prediction and feature selection</span></a>. <em>Electronic Journal of Statistics</em>, <em>14</em>(1), 2155–2197.
</div>
<div id="ref-Piironen-Vehtari2015" class="csl-entry" role="listitem">
Piironen, J., and Vehtari, A. (2015). <a href="https://arxiv.org/abs/1508.02502">Projection predictive variable selection using stan+r</a>.
</div>
<div id="ref-Piironen-Vehtari2017Choice" class="csl-entry" role="listitem">
Piironen, J., and Vehtari, A. (2017a). <a href="https://proceedings.mlr.press/v54/piironen17a.html"><span class="nocase">On the Hyperprior Choice for the Global Shrinkage Parameter in the Horseshoe Prior</span></a>. In A. Singh and J. Zhu, editors, <em>Proceedings of the 20th international conference on artificial intelligence and statistics</em>,Vol. 54, pages 905–913. PMLR.
</div>
<div id="ref-Piironen-Vehtari2017" class="csl-entry" role="listitem">
Piironen, J., and Vehtari, A. (2017b). <a href="https://doi.org/10.1214/17-EJS1337SI"><span class="nocase">Sparsity information and regularization in the horseshoe and other shrinkage priors</span></a>. <em>Electronic Journal of Statistics</em>, <em>11</em>(2), 5018–5051.
</div>
<div id="ref-Polson-Scott2011" class="csl-entry" role="listitem">
Polson, N. G., and Scott, J. G. (2011). <a href="https://doi.org/10.1093/acprof:oso/9780199694587.003.0017">501Shrink globally, act locally: Sparse bayesian regularization and prediction</a>. In <em>Bayesian statistics 9</em>. Oxford University Press.
</div>
<div id="ref-Polson-Scott2012" class="csl-entry" role="listitem">
Polson, N. G., and Scott, J. G. (2012). <a href="https://doi.org/10.1214/12-BA730"><span class="nocase">On the Half-Cauchy Prior for a Global Scale Parameter</span></a>. <em>Bayesian Analysis</em>, <em>7</em>(4), 887–902.
</div>
<div id="ref-Porwal-Raftery2022" class="csl-entry" role="listitem">
Porwal, A., and Raftery, A. E. (2022). <a href="https://doi.org/10.1073/pnas.2120737119">Comparing methods for statistical inference with model uncertainty</a>. <em>Proceedings of the National Academy of Sciences</em>, <em>119</em>(16), e2120737119.
</div>
<div id="ref-Robbins-Monro1951" class="csl-entry" role="listitem">
Robbins, H., and Monro, S. (1951). <a href="https://www.jstor.org/stable/2236626">A stochastic approximation method</a>. <em>The Annals of Mathematical Statistics</em>, <em>22</em>(3), 400–407.
</div>
<div id="ref-Shang-Clayton2011" class="csl-entry" role="listitem">
Shang, Z., and Clayton, M. K. (2011). <a href="https://doi.org/10.1016/j.jspi.2011.05.002">Consistency of bayesian linear model selection with a growing number of parameters</a>. <em>Journal of Statistical Planning and Inference</em>, <em>141</em>(11), 3463–3474.
</div>
<div id="ref-Tibshirani1996" class="csl-entry" role="listitem">
Tibshirani, R. (1996). <a href="https://doi.org/10.1111/j.2517-6161.1996.tb02080.x">Regression shrinkage and selection via the lasso</a>. <em>Journal of the Royal Statistical Society: Series B (Methodological)</em>, <em>58</em>(1), 267–288.
</div>
<div id="ref-Tierney1998" class="csl-entry" role="listitem">
Tierney, L. (1998). <a href="http://www.jstor.org/stable/2667233">A note on metropolis-hastings kernels for general state spaces</a>. <em>The Annals of Applied Probability</em>, <em>8</em>(1), 1–9.
</div>
<div id="ref-Vehtari+2017" class="csl-entry" role="listitem">
Vehtari, A., Gelman, A., and Gabry, J. (2017). <a href="https://doi.org/10.1007/s11222-016-9696-4">Practical bayesian model evaluation using leave-one-out cross-validation and WAIC</a>. <em>Statistics and Computing</em>, <em>27</em>(5), 1413–1432.
</div>
<div id="ref-West1987" class="csl-entry" role="listitem">
West, M. (1987). <a href="https://doi.org/10.1093/biomet/74.3.646">On scale mixtures of normal distributions</a>. <em>Biometrika</em>, <em>74</em>(3), 646–648.
</div>
<div id="ref-Yang+2016" class="csl-entry" role="listitem">
Yang, Y., Wainwright, M. J., and Jordan, M. I. (2016). <a href="https://doi.org/10.1214/15-AOS1417"><span class="nocase">On the computational complexity of high-dimensional Bayesian variable selection</span></a>. <em>The Annals of Statistics</em>, <em>44</em>(6), 2497–2532.
</div>
<div id="ref-Zanella2020" class="csl-entry" role="listitem">
Zanella, G. (2020). <a href="https://doi.org/10.1080/01621459.2019.1585255">Informed proposals for local MCMC in discrete spaces</a>. <em>Journal of the American Statistical Association</em>, <em>115</em>(530), 852–865.
</div>
<div id="ref-Zanella-Roberts2019" class="csl-entry" role="listitem">
Zanella, G., and Roberts, G. (2019). <a href="https://doi.org/10.1111/rssb.12316">Scalable importance tempering and bayesian variable selection</a>. <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em>, <em>81</em>(3), 489–517.
</div>
<div id="ref-Zhou+2022" class="csl-entry" role="listitem">
Zhou, Q., Yang, J., Vats, D., Roberts, G. O., and Rosenthal, J. S. (2022). <a href="https://doi.org/10.1111/rssb.12546">Dimension-free mixing for high-dimensional bayesian variable selection</a>. <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em>, <em>84</em>(5), 1751–1784.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>例えば <span class="citation" data-cites="Barr+2013">(<a href="#ref-Barr+2013" role="doc-biblioref">Barr et al., 2013</a>)</span> では検証的仮説検定の設定で，どこまでランダム効果をモデルに入れるかを議論しており，「全部入れるべき」という結論を一定の前提の下で導いている．<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><span class="citation" data-cites="Hahn-Carvalho2015">(<a href="#ref-Hahn-Carvalho2015" role="doc-biblioref">Hahn and Carvalho, 2015, p. 436</a>)</span> は local scale mixture と呼んでいる．他にこの観点は <span class="citation" data-cites="Griffin-Brown2017">(<a href="#ref-Griffin-Brown2017" role="doc-biblioref">Jim E. Griffin and Brown, 2017</a>)</span>, <span class="citation" data-cites="Polson-Scott2012">(<a href="#ref-Polson-Scott2012" role="doc-biblioref">Polson and Scott, 2012</a>)</span> でも議論されている．<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>変数減少法やステップワイズ法などのヒューリスティックな方法に対しての「確率的探索法」という名称だったのだと思われる．特に <span class="citation" data-cites="George-McCulloch1993">(<a href="#ref-George-McCulloch1993" role="doc-biblioref">George and McCulloch, 1993</a>)</span> ではデータ拡張に基づく Gibbs サンプラーを用いており，その様子が「確率的探索」に見えるのだと思われる．<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/162348\.github\.io\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
        for (let i=0; i<annoteTargets.length; i++) {
          const annoteTarget = annoteTargets[i];
          const targetCell = annoteTarget.getAttribute("data-target-cell");
          const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
          const contentFn = () => {
            const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
            if (content) {
              const tipContent = content.cloneNode(true);
              tipContent.classList.add("code-annotation-tip-content");
              return tipContent.outerHTML;
            }
          }
          const config = {
            allowHTML: true,
            content: contentFn,
            onShow: (instance) => {
              selectCodeLines(instance.reference);
              instance.reference.classList.add('code-annotation-active');
              window.tippy.hideAll();
            },
            onHide: (instance) => {
              unselectCodeLines();
              instance.reference.classList.remove('code-annotation-active');
            },
            maxWidth: 300,
            delay: [50, 0],
            duration: [200, 0],
            offset: [5, 10],
            arrow: true,
            trigger: 'click',
            appendTo: function(el) {
              return el.parentElement.parentElement.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'quarto',
            placement: 'right',
            positionFixed: true,
            popperOptions: {
              modifiers: [
              {
                name: 'flip',
                options: {
                  flipVariations: false, // true by default
                  allowedAutoPlacements: ['right'],
                  fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
                },
              },
              {
                name: 'preventOverflow',
                options: {
                  mainAxis: false,
                  altAxis: false
                }
              }
              ]        
            }      
          };
          window.tippy(annoteTarget, config); 
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "162348/162348.github.io";
    script.dataset.repoId = "R_kgDOKlfKYQ";
    script.dataset.category = "Announcements";
    script.dataset.categoryId = "DIC_kwDOKlfKYc4CgDmb";
    script.dataset.mapping = "pathname";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://162348.github.io/">
<p>Hirofumi Shiba</p>
</a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/162348/162348.github.io/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/ano2math5">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:shiba.hirofumi@ism.ac.jp">
      <i class="bi bi-envelope" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="../../../blog.xml">
      <i class="bi bi-rss" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>