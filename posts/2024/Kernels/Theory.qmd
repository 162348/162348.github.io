---
title: "統計的学習理論"
author: "司馬博文"
date: 1/10/2024
date-modified: 1/23/2024
categories: [Kernel, Math Notes]
toc: true
image: Theory.png
number-sections: true
code-block-bg: true
code-block-border-left: "#5AB5BA"
code-overflow: wrap
code-fold: true
bibliography: 
    - ../../../mathematics.bib
    - ../../../bib.bib
csl: ../../../apa.csl
abstract-title: 概要
abstract: 統計的学習理論の基礎を数学的に理解する
crossref:
    sec-prefix: 節
    eq-prefix: 式
    def-prefix: 定義
    def-title: 定義
    thm-prefix: 定理
    thm-title: 定理
---

{{< include ../../../_preamble.qmd >}}

「汎化」に価値を置く，独特の決定理論的な枠組みが存在する．
特に，現状では「経験リスク最小化」とその正則化が最もよく見られる．
この枠組みから，各手法の優越を評価することとなる．

[@Mohri+2018], [@Vapnik1999]

## 径数模型の教師あり学習の場合 {#sec-1}

### 記法と用語^[[@Mohri+2018 pp.9-10] を参考にした．]

* データサイズ $n\in\N^+$ を固定するのが特徴である．^[これを agnostical setting という．]

* データ (sample) の全体を $S_n=\{z_i\}_{i=1}^n\subset\cX\times\cY$ と表す．$\cX$ を入力空間，$\cY$ を出力空間と呼ぶ．^[[@Bousquet-Elisseeff2002] の用語に一致する．[@Alquier2021 p.2] では，$\cX$ を object set，$\cY$ を label set と呼んでいる．]

* $\cX,\cY$ はいずれも可測空間とし，可測関数 $f\in\L(\cX,\cY)$ を推定量，部分集合 $\H\subset\L(\cX;\cY)$ を **仮設集合** (hypothesis set) という．^[[@Valiant1984] では，$\cY=2$ の場合，元 $h\in\cH$ を **概念** (concept) ともいう．ここでは predicate とも呼んでいる．]

* 関数 $l:\cY^2\to\R_+$ を **損失関数** という．^[普通 $l(\Delta_\cY)=\{0\}$ を満たすように取る．]

* 写像 $A:(\cX\times\cY)^n\to\H$ を **アルゴリズム** という．

以降，データはある真の分布 $\P\in(\cX\times\cY)$ に従うものとし，$(X,Y)\sim\P$ と表す．サンプル $S_n=\{z_i\}_{i=1}^n$ は $(X,Y)$ の独立同分布な複製と仮定する．

### PAC学習

> [Probably Approximately Correct Learning](https://en.wikipedia.org/wiki/Probably_approximately_correct_learning)

の略であり，[@Valiant1984] によって提案された，機械学習を形式化する数理的枠組みである．^[[@Haussler-Warmuth1993 p.291] など．これにより，計算効率性の研究者が，機械学習のアルゴリズムにも目を向け，協業を始めるきっかけになったとしている．]

::: {.callout-tip icon="false"}
## 
::: {#def-loss}
## predictive loss / generalization error / risk, empirical risk /loss / error^[[@Alquier2021 p.4], [@Mohri+2018 p.10]，[@金森敬文2015 p.7] を参考にした．]
$l:\cY^2\to\R_+$ を損失関数とする．

1. 仮設 $h\in\cH$ の **危険** または **予測損失** または **汎化誤差** とは，
$$
R(h):=\E[l(h(X),Y)]
$$
をいう．

2. 仮設 $h\in\cH$ のサンプル $\{(x_i,y_i)\}_{i=1}^n$ に関する **経験損失** または経験誤差とは，
$$
\wh{R}(h):=\frac{1}{n}\sum_{i=1}^n l(h(x_i),y_i)
$$
をいう．
:::
:::

データが独立同分布に従うとする場合，経験損失は予測損失の不偏推定量であり，^[[@Mohri+2018 pp.10-11], [@金森敬文2015 p.8] など．] $n\to\infty$ の漸近論もすでに準備が出来ている．

予測損失の最小化の代わりに，経験損失の最小化を金科玉条とする枠組みを **経験リスク最小化 (Empirical Risk Minimization)** という．PAC 学習も，この金科玉条を（結果的にでも）正当化する枠組みであると言える．

しかし，この漸近論が提供してくれない消息は複数ある．

1. 機械学習においては，仮説 $h$ 自体がデータから決まる確率変数 $h_{S_n}:\Om\to\cH$ である場合が多い．これを考慮した収束が欲しい．
2. $n$ が有限の場合に非漸近論的消息が欲しい．

そこで以降は，アルゴリズム $A:(\cX\times\cY)^n\to\cH$ を通じて，$h_{S_n}:=A(S_n)$ と定まるとし，$h_{S_n}$ を単に $h$ ともかき，これをデータの関数とする．

この下で，$\wh{R}(h_{S_n})$ と $R(h_{S_n})$ の関係を考える．

::: {.callout-caution icon="false" collapse="true"}
## loss と error の区別

[@金森敬文2015 p.13] では，（決定論的な）仮説 $h\in\cH$ に関して，$R(h)$ を損失，データから決まる仮説 $h_{S_n}=A(S_n)$ に関して，$\E[R(h_{S_n})]$ をリスクと呼び分けている．

損失のうち，特に **0-1損失**
$$
l=1_{\Delta_\cY^\comp}
$$^[$\Delta_\cY:=\Brace{(y',y)\in\cY^2\mid y=y'}$ を対角集合とした．]
に関するものを誤差といい，この２語は殆ど交換可能な形で使う．その期待値をリスクと言う，という使い分けは一つ筋が通りそうである．

ただし，[@Alquier2021], [@Bousquet-Elisseeff2002] はいずれもリスクと誤差を並列している．
:::

### Bayes ルール

::: {.callout-tip icon="false"}
## 
::: {#def-Bayes-loss}
## Bayes error, Bayes rule^[[@金森敬文2015 p.9] を参考．], excess risk / regret

損失関数 $l$ に対して，
$$
\begin{align*}
    R^*&:=\inf_{h\in\L(\cX;\cY)}R(h)\\
    &=\inf_{h\in\L(\cX;\cY)}\E[l(h(X),Y)]
\end{align*}
$$
を **Bayes 誤差** という．仮に右辺の下限が達成される $h^*\in\L(\cX;\cY)$ が存在するとき，これを **Bayes 規則** という．
$$
\cE(h):=R(h)-R^*
$$
を **超過損失** という．
:::
:::

$$
\begin{align*}
    \cE(\wh{h}_S)&=R(\wh{h}_S)-R(h^*)\\
    &=\Paren{R(\wh{h}_S)-\inf_{h\in\cH}R(h)}+\Paren{\inf_{h\in\cH}R(h)-R(h^*)}.
\end{align*}
$$
第一項を **推定誤差**，第二項を **近似誤差** という．^[[@金森敬文2015 p.17] を参考．]

ここから，$\ov{h}$ を $\inf_{h\in\cH}R(h)$ を達成する **oracle machine** とすると，推定誤差はさらに２項に分解して評価できる：
$$
\begin{align*}
    &R(\wh{h}_n)-\inf_{h\in\cH}R(H)\\
    &=R(\wh{h}_n)-R(\ov{h})\\
    &=\underbrace{\wh{R}_n(\wh{h}_n)-\wh{R}_n(\ov{h}_n)}_{\le0}+R(\wh{h}_n)-\wh{R}_n(\wh{h}_n)+\wh{R}_n(\ov{h})-R(\ov{h})\\
    &\le\ABs{\wh{R}_n(\wh{h}_n)-R(\wh{h}_n)}+\ABs{\wh{R}_n(\ov{h})-R(\ov{h})}.
\end{align*}
$$

### 主結果

::: {.callout-tip icon="false"}
## 
::: {#thm-1}
## PAC bound^[[@Alquier2021 p.7] など．]

仮設集合 $\cH$ が有限であるとする：$\#\cH=:M<\infty$．
このとき，任意の $\ep\in(0,1)$ について，
$$
\P\Square{\forall_{h\in\cH}\;R(h)-\wh{R}(h)\le C\sqrt{\frac{\log\frac{M}{\ep}}{2n}}}\ge1-\ep.
$$
:::
:::

#### $\ABs{\wh{R}_n(\wh{h}_n)-R(\wh{h}_n)}$ の評価



#### $\ABs{\wh{R}_n(\ov{h})-R(\ov{h})}$ の評価

#### その後の発展^[[@Devroye+1996] 第11, 12章 参照．[@Vapnik1998]．]

* 一般の $\cH\subset\L(\cX;\cY)$ への拡張は，VC次元の理論を用いて行われた．

* バウンドの変形に，Rademacher 複雑性も使われる．

* 現実との乖離：現代の深層学習では $M$ が極めて大きくなり，PAC 不等式はほとんど意味をなさない．これを包括できる理論が試みられている．

## 正則化と汎化の関係

### 導入

定理 @thm-1 の証明からも判る通り，推定誤差と近似誤差のトレードオフが存在する．

これを踏まえて，機械学習モデルの根本的な設計思想として [構造リスク最小化](https://en.wikipedia.org/wiki/Structural_risk_minimization) が提案された [@Vapnik-Chervonenkis1974]．これは近似誤差をある一定以下に抑え，その中で仮設空間の複雑さをなるべく落とす，という設計方針である．

一方で，仮設集合 $\cH$ を小さくする代わりに，アルゴリズム $A:(\cX\times\cY)^n\to\cH$ が探索する範囲を小さいものにし，実質的な仮設空間のサイズを抑えることも考えられる．これを **正則化** という．

この方向の研究の源流は，[@Bousquet-Elisseeff2002] らの **安定性** の理論であった．

これは「実質的な仮設空間」という考え方を導入することで，@sec-1 の機械学習モデルの予測精度理論の精緻化も生んだ．

### 枠組み：アルゴリズムに目を向ける

リスクを
$$
R(A,S):=\E[l(A(S)(X),YT)]
$$
経験リスクと
$$
\wh{R}(A,S_n):=\frac{1}{n}\sum_{i=1}^nl(A(S_n)(x_i),y_i)
$$
として，アルゴリズム $A:(\cX\times\cY)^n\to\cH$ の関数とみる．^[[@Bousquet-Elisseeff2002 p.502]．]

この場合，仮設空間 $\cH$ 上の一様な評価は，そもそも目指さない．

### 安定性

::: {.callout-tip icon="false"}
## 
::: {#def-stability}
## 安定性^[[@Bousquet-Elisseeff2002 p.503]．]

アルゴリズム $A:(\cX\times\cY)^n\to\cH$ が，損失関数 $l$ に関して **$\beta\in(0,1)$-安定** であるとは，任意の $S\subset(\cX\times\cY)^n$ に対して，
$$
\begin{align*}
    &\max_{i\in[n]}\E\SQuare{\ABs{l(A(S)(x_i),y_i)\\
    &\qquad-l(A(S\setminus\{z_i\})(x_i),y_i)}}\le\beta
\end{align*}
$$
が成り立つことをいう．
:::
:::

すなわち，学習データを１つ減らしたときの損失の変化が，ある一定以下であることをいう．

これは感度分析的な考え方であるが，実は正則化により，アルゴリズムは安定的な挙動をするようになり，安定性が汎化誤差の上界を与える！

### 主結果

::: {.callout-tip icon="false"}
##
::: {#thm-2}
## 安定なアルゴリズムに対する汎化バウンド^[[@Bousquet-Elisseeff2002 p.507] Theorem 12．]

$A$ を $\beta_1$-安定で，損失関数 $l$ は上界 $M>0$ を持つとする．このとき，$1-\delta$ の確率で
$$
R(A,S)\le\wh{R}(A,S_n)+2\beta+(4n\beta+M)\sqrt{\frac{\log1/\delta}{2n}}.
$$
:::
:::

### アルゴリズムの安定性

一方で，アルゴリズムの安定性を示すことは難しく，通常 admissibility と Bregman divergence を通じて議論されるようである．^[[@Bousquet-Elisseeff2002] 第５節．]

## PAC-Bayes

通常の機械学習の枠組みでは，仮設集合 $\cH\subset\L(\cX;\cY)$ を固定し，この中で最適な推定量 $\ov{h}\in\cH$ を探すことに集中する．

一方で，PAC-Bayes では，仮設集合 $\cH$ 上の確率分布を学習し，最終的に 投票 (vote) などの確率的な操作によって決めることを考え，これにも対応する理論を構築する．^[[@Alquier2021] Introduction より．]

これは，従来の PAC 学習は最悪評価をしていたとして相対化するような試みであり，より実際の機械学習アルゴリズムへの応用可能性が意識されている．

これは [@Shawe-Taylor-Williamson1997] によって創始され， [@McAllester1999] によって最初の定理が示された．[@Seeger2002], [@Catoni2007] も金字塔であり，後者は情報統計力学との関連を推し進めている．

### 枠組み

データにより決まる確率測度
$$
\wh{\rho}:(\cX\times\cY)^n\to\cP(\cH)
$$
を考え，推定量をランダムに $\wt{h}\sim\wh{\rho}$ とサンプリングする．これを **ランダム推定量** (randomized estimator) という．

例えば $\cY=2$ においては，Gibbs 判別器と呼ばれる．^[[@Scholkopf-Smola2002 p.381] 定義12.23．]

また，最終的な推定量を
$$
h_{\wh{\rho}}:=\wh{\rho}(h)
$$
と決定しても良い．これを **集合推定量** (aggregated predictor) という．

これらのリスク $R(\wh{h}),R(h_{\wh{\rho}})$ を調べるのが PAC-Bayes である．

### KL-乖離度

すると，$\log M$ の項に KL-乖離度が現れる．

::: {.callout-tip icon="false"}
## 
::: {#def-KL-divergence}
## Kullback-Leibler divergence

$\mu,\nu\in\cP(\cH)$ の **Kullback-Leibler 乖離度** とは，
$$
\KL(\mu|\nu):=\begin{cases}
\int_\cH\log\paren{\dd{\mu}{\nu}(\theta)}\mu(d\theta)&\mu\ll\nu,\\
\infty&\otherwise.
\end{cases}
$$
をいう．
:::
:::