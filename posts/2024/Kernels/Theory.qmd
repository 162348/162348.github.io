---
title: "統計的学習理論１"
subtitle: "PAC 学習"
author: "司馬博文"
date: 1/10/2024
date-modified: 3/2/2024
categories: [Kernel, Math Notes]
toc: true
image: Theory.png
number-sections: true
code-block-bg: true
code-block-border-left: "#5AB5BA"
code-overflow: wrap
code-fold: true
bibliography: 
    - ../../../mathematics.bib
    - ../../../bib.bib
csl: ../../../apa.csl
abstract-title: 概要
abstract: 統計的機械学習には，「汎化」に価値を置く，独特の決定理論的な枠組みが存在する．特に，現状では経験リスク最小化と正則化とを組み合わせた「構造的リスク最小化」が最もよく見られる．この枠組みから，各手法の優越を評価することとなる．
crossref:
    sec-prefix: 節
    eq-prefix: 式
    def-prefix: 定義
    def-title: 定義
    thm-prefix: 定理
    thm-title: 定理
---

{{< include ../../../_preamble.qmd >}}

機械学習と統計学に別を設けるならば，いずれもデータから構造を発見することを目標とするとしても，前者は明示的なプログラムを伴わない「自動化」を念頭におくものであると言える．この人間による介入をなるべく少なくしたいという志向が「学習」の名前に表れている．

それ故，機械学習の理論としては，統計的決定理論の枠組みとは違った枠組みが存在する．これを，径数模型の教師あり学習の場合に関して述べる．

## 枠組み

### 記法と用語^[[@Mohri+2018 pp.9-10] と [@Shalev-Shwartz-Ben-David2014 pp.13-14] を参考にした．]

* データサイズ $n\in\N^+$ を固定するのが特徴である．^[これを **不可知論的** (agnostical) setting という．]

* データ (sample) の全体を $S_n=\{z_i\}_{i=1}^n\subset\cX\times\cY$ と表す．^[これは訓練セット (training set) ともいう [@Shalev-Shwartz-Ben-David2014 p.14]．] $\cX$ を入力空間，$\cY$ を出力空間と呼ぶ．^[[@Bousquet-Elisseeff2002] の用語に一致する．[@Alquier2021 p.2] では，$\cX$ を object set，$\cY$ を label set と呼んでいる．[@Shalev-Shwartz-Ben-David2014 pp.13-14] は $\cX$ を domain set，$\cY$ を label set と呼ぶ．]

* $\cX,\cY$ はいずれも可測空間とし，可測関数 $f\in\L(\cX,\cY)$ を推定量，部分集合 $\H\subset\L(\cX;\cY)$ を **仮設集合** (hypothesis set) という．^[[@Valiant1984] では，$\cY=2$ の場合，元 $h\in\cH$ を **概念** (concept) ともいう．その他の場合を predicate とも呼んでいる．[@Shalev-Shwartz-Ben-David2014 p.14] では **predictor**, predictino rule, classifier とも呼ぶとしている．]

* $l(\Delta_\cY)=\{0\}$ を満たす関数 $l:\cY^2\to\R_+$ を **損失関数** という．

* 写像 $A:(\cX\times\cY)^n\to\H$ を（機械学習） **アルゴリズム** または学習者という．

以降，データはある真の分布 $\bP\in\cP(\cX\times\cY)$ に従うものとし，$(X,Y)\sim\bP$ と表す．サンプル $S_n=\{z_i\}_{i=1}^n$ は $(X,Y)$ の独立同分布な複製と仮定する．

::: {.callout-caution icon="false" collapse="true" title="損失関数の例"}

* $l:=1_{\Delta_\cY^\comp}$ は **0-1損失** と呼ばれ，主に分類問題で使われる．これについて，汎化誤差とは，^[[@Shalev-Shwartz-Ben-David2014 p.24] などでは，$\cY=2$ として分類問題を考えていることもあり，専らこの損失を考えている．]
$$
R(h)=\bE[l(h(X),Y)]=\bP[h(X)\ne Y]
$$

* $\cY=\R^d$ とし，$l(y_1,y_2)=\norm{y_1-y_2}^2_2$ とした場合を **二乗損失** といい，主に回帰問題の最小二乗法などで用いられる．

:::

### 汎化ギャップ

::: {.callout-tip icon="false" title="(generalization) error, training error^[[@Alquier2021 p.4], [@Mohri+2018 p.10]，[@金森敬文2015 p.7] を参考にした．[@Shalev-Shwartz-Ben-David2014 p.14] でも，generalization error, risk, error，さらには loss のいずれの名前でも呼ぶし，training error と empirical error /risk とも交換可能に使う，としている．]"}
::: {#def-loss}

$l:\cY^2\to\R_+$ を損失関数とする．

1. 仮設 $h\in\cH$ の **（汎化）誤差** または **危険** または **予測損失** とは，
$$
R(h):=\bE[l(h(X),Y)]
$$
をいう．

2. 仮設 $h\in\cH$ のサンプル $S_n=\{(x_i,y_i)\}_{i=1}^n$ に関する **訓練誤差** または **経験損失** とは，
$$
\wh{R}_n(h):=\frac{1}{n}\sum_{i=1}^n l(h(x_i),y_i)
$$
をいう．

3. 差 $\wh{R}_n(h)-R(h)$ を **汎化ギャップ** という．

:::
:::

アルゴリズム $A$ にとって，汎化誤差は不可知であるが，訓練誤差は計算可能である．データが独立同分布に従うとする場合，経験損失は予測損失の不偏推定量であり，^[[@Mohri+2018 pp.10-11], [@金森敬文2015 p.8] など．] $n\to\infty$ の漸近論もすでに準備が出来ている．

不可知である予測損失の最小化の代わりに，経験損失を最小化する予測器
$$
\operatorname{ERM}_\cH(S_n)\in\argmin_{h\in\cH}R_n(h)
$$
を構成する枠組みを **経験リスク最小化 (Empirical Risk Minimization)** という．PAC 学習は，枠組みがどれほどの意味で正しいかの定量的な検証になっている．

一見，これでは過学習の問題が生じる．

そこで，あらかじめ学習者 $A$ の値域 $\cH\subset\L(\cX;\cY)$ を制限することを考える．これを **帰納バイアス** といい，正則化などの方法によって達成される．

しかし，この漸近論が提供してくれない消息は複数ある．

1. 機械学習においては，仮説 $h$ 自体がデータから決まる確率変数 $h_{S_n}:\Om\to\cH$ である場合が多い．これを考慮した収束が欲しい．
2. $n$ が有限の場合に非漸近論的消息が欲しい．

そこで以降は，アルゴリズム $A:(\cX\times\cY)^n\to\cH$ を通じて，$h_{S_n}:=A(S_n)$ と定まるとし，$h_{S_n}$ を単に $h$ ともかき，これをデータの関数とする．

この下で，$\wh{R}(h_{S_n})$ と $R(h_{S_n})$ の関係を考える．

::: {.callout-caution icon="false" collapse="true" title="loss と error の区別"}

[@金森敬文2015 p.13] では，（決定論的な）仮説 $h\in\cH$ に関して，$R(h)$ を損失，データから決まる仮説 $h_{S_n}=A(S_n)$ に関して，$\E[R(h_{S_n})]$ をリスクと呼び分けている．

損失のうち，特に **0-1損失**
$$
l=1_{\Delta_\cY^\comp}
$$

^[$\Delta_\cY:=\Brace{(y',y)\in\cY^2\mid y=y'}$ を対角集合とした．]
に関するものを誤差といい，この２語は殆ど交換可能な形で使う．その期待値をリスクと言う，という使い分けは一つ筋が通りそうである．

ただし，[@Alquier2021], [@Bousquet-Elisseeff2002] はいずれもリスクと誤差を並列している．
:::

### PAC学習

機械学習を形式化する数理的枠組みのうち，**PAC 学習** とは，

> [Probably Approximately Correct Learning](https://en.wikipedia.org/wiki/Probably_approximately_correct_learning)

の略であり，[@Valiant1984] によって提案されたものである．

PAC 学習とは，分布 $\bP\in\cP(\cX\times\cY)$ に依らない汎化ギャップの評価を，確率論的に与えることを目的としており，Probably Approximately Correct の名前はその様子を端的に表現している．

[@Haussler-Warmuth1993 p.292] によれば，PAC 学習の枠組みにより，計算効率性の研究者が，機械学習のアルゴリズムにも目を向け，協業を始めるきっかけになったとしている．

::: {.callout-tip icon="false" title="agnostically PAC Learnable^[[@Shalev-Shwartz-Ben-David2014 p.25] 定義3.3，[@Mohri+2018 p.22] 定義2.14 など．元々の [@Valiant1984] の定義では，$m$ と計算時間の増加レートは $1/\ep,1/\delta$ の多項式以下であるという制限もあった．]"}
::: {#def-PAC-learnable}

集合 $\cH\subset\L(\cX;\cY)$ が（不可知論的な意味で） **PAC 学習可能** であるとは，ある関数
$$
m_\cH:(0,1)^2\to\N
$$
とアルゴリズム
$$
A:(\cX\times\cY)^{<\om}\to\cH
$$
が存在して，任意の $\ep,\delta\in(0,1)$ と $\bP\in\cP(\cX\times\cY)$ に対して，$m_\cH(\ep,\delta)$ よりも多くの i.i.d. サンプルが存在すれば，$1-\delta$ 以上の確率で，
$$
R(A(S_m))\le\ep+\min_{h\in\cH}R(h)\quad(m\ge m_\cH(\ep,\delta))
$$
が成り立つことをいう．

:::
:::

### Bayes ルール

::: {.callout-tip icon="false" title="Bayes error, Bayes rule^[[@金森敬文2015 p.9] を参考．], excess risk / regret"}
::: {#def-Bayes-loss}

損失関数 $l$ に対して，
$$
\begin{align*}
    R^*&:=\inf_{h\in\L(\cX;\cY)}R(h)\\
    &=\inf_{h\in\L(\cX;\cY)}\bE[l(h(X),Y)]
\end{align*}
$$
を **Bayes 誤差** という．仮に右辺の下限が達成される $h^*\in\L(\cX;\cY)$ が存在するとき，これを **Bayes 最適学習則** またはベイズルール という．
$$
\cE(h):=R(h)-R^*
$$
を **超過損失** という．
:::
:::

::: {.callout-caution icon="false" collapse="true" title="Bayes 規則の例^[[@Shalev-Shwartz-Ben-David2014 p.25] など．]"}

$\cY=2$ の場合，任意の $\bP\in\cP(\cX\times\cY)$ に対して，
$$
h^*(x):=\begin{cases}
1&\bP[Y=1\mi X=x]\ge\frac{1}{2},\\
0&\otherwise
\end{cases}
$$
は Bayes 最適学習則である．

:::

$$
\begin{align*}
    \cE(\wh{h}_S)&=R(\wh{h}_S)-R(h^*)\\
    &=\Paren{R(\wh{h}_S)-\inf_{h\in\cH}R(h)}+\Paren{\inf_{h\in\cH}R(h)-R(h^*)}.
\end{align*}
$$
第一項を **推定誤差**，第二項を **近似誤差** という．^[[@金森敬文2015 p.17] を参考．]

ここから，$\ov{h}$ を $\inf_{h\in\cH}R(h)$ を達成する **oracle machine** とすると，推定誤差はさらに２項に分解して評価できる：
$$
\begin{align*}
    &R(\wh{h}_n)-\inf_{h\in\cH}R(H)\\
    &=R(\wh{h}_n)-R(\ov{h})\\
    &=\underbrace{\wh{R}_n(\wh{h}_n)-\wh{R}_n(\ov{h}_n)}_{\le0}+R(\wh{h}_n)-\wh{R}_n(\wh{h}_n)+\wh{R}_n(\ov{h})-R(\ov{h})\\
    &\le\ABs{\wh{R}_n(\wh{h}_n)-R(\wh{h}_n)}+\ABs{\wh{R}_n(\ov{h})-R(\ov{h})}.
\end{align*}
$$

## PAC bound

::: {.callout-tip icon="false" title="PAC bound^[[@Alquier2021 p.7] 定理1.2 など．]"}
::: {#thm-1}

仮設集合 $\cH$ が有限であるとする：$\#\cH=:M<\infty$．
このとき，任意の $\ep\in(0,1)$ について，
$$
\bP\Square{\forall_{h\in\cH}\;R(h)-\wh{R}(h)\le C\sqrt{\frac{\log\frac{M}{\ep}}{2n}}}\ge1-\ep.
$$
:::
:::

仮説 $\cH$ の数 $M$ を増やすごとに，訓練データ数 $n$ は $\log M$ のオーダーで増やす必要がある，ということになる．

### $\ABs{\wh{R}_n(\wh{h}_n)-R(\wh{h}_n)}$ の評価



### $\ABs{\wh{R}_n(\ov{h})-R(\ov{h})}$ の評価

### その後の発展^[[@Devroye+1996] 第11, 12章 参照．[@Vapnik1998]．]

* 一般の $\cH\subset\L(\cX;\cY)$ への拡張は，VC次元の理論を用いて行われた．

* バウンドの変形に，Rademacher 複雑性も使われる．

* 現実との乖離：現代の深層学習では $M$ が極めて大きくなり，PAC 不等式はほとんど意味をなさない．これを包括できる理論が試みられている．