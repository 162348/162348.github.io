---
title: "統計的学習理論"
author: "Draft Draft"
date: 1/10/2024
categories: [Kernels]
toc: true
number-sections: true
code-block-bg: true
code-block-border-left: "#31BAE9"
code-overflow: wrap
code-fold: true
bibliography: 
    - ../../../mathematics.bib
    - ../../../bib.bib
csl: ../../../apa.csl
abstract-title: 概要
abstract: 統計的学習理論の基礎を数学的に理解する
crossref:
    sec-prefix: 節
    eq-prefix: 式
    def-prefix: 定義
    def-title: 定義
    thm-prefix: 定理
    thm-title: 定理
---

{{< include ../../../_preamble.qmd >}}

「汎化」に価値を置く，独特の決定理論的な枠組みが存在する．
特に，現状では「経験リスク最小化」とその正則化が最もよく見られる．
この枠組みから，各手法の優越を評価することとなる．

[@Mohri+2018], [@Vapnik1999]

## 径数模型の教師あり学習の場合

### 記法と用語^[[@Mohri+2018 pp.9-10] を参考にした．]

* データサイズ $n\in\N^+$ を固定するのが特徴である．^[これを agnostical setting という．]

* データ (sample) の全体を $S_n=\{z_i\}_{i=1}^n\subset\cX\times\cY$ と表す．$\cX$ を入力空間，$\cY$ を出力空間と呼ぶ．^[[@Alquier2021 p.2] では，$\cX$ を object set，$\cY$ を label set と呼んでいる．]

* $\cX,\cY$ はいずれも可測空間とし，可測関数 $f\in\L(\cX,\cY)$ を推定量，部分集合 $\H\subset\L(\cX;\cY)$ を **仮設集合** (hypothesis set) という．^[[@Valiant1984] では，$\cY=2$ の場合，元 $h\in\cH$ を **概念** (concept) ともいう．ここでは predicate とも呼んでいる．]

* 関数 $l:\cY^2\to\R_+$ を **損失関数** という．^[普通 $l(\Delta_\cY)=\{0\}$ を満たすように取る．]

* 写像 $A:(\cX\times\cY)^n\to\H$ を **アルゴリズム** という．

以降，データはある真の分布 $\P\in(\cX\times\cY)$ に従うものとし，$(X,Y)\sim\P$ と表す．サンプル $S_n=\{z_i\}_{i=1}^n$ は $(X,Y)$ の独立同分布な複製と仮定する．

### PAC学習

> [Probably Approximately Correct Learning](https://en.wikipedia.org/wiki/Probably_approximately_correct_learning)

の略であり，[@Valiant1984] によって提案された，機械学習を形式化する数理的枠組みである．^[[@Haussler-Warmuth1993 p.291] など．これにより，計算効率性の研究者が，機械学習のアルゴリズムにも目を向け，協業を始めるきっかけになったとしている．]

::: {.callout-tip icon="false"}
## 
::: {#def-loss}
## predictive loss / generalization error / risk, empirical risk /loss / error^[[@Alquier2021 p.4], [@Mohri+2018 p.10]，[@金森敬文2015 p.7] を参考にした．]
$l:\cY^2\to\R_+$ を損失関数とする．

1. 仮設 $h\in\cH$ の **危険** または **予測損失** または **汎化誤差** とは，
$$
R(h):=\E[l(h(X),Y)]
$$
をいう．

2. 仮設 $h\in\cH$ のサンプル $\{(x_i,y_i)\}_{i=1}^n$ に関する **経験損失** または経験誤差とは，
$$
\wh{R}(h):=\frac{1}{n}\sum_{i=1}^n l(h(x_i),y_i)
$$
をいう．
:::
:::

データが独立同分布に従うとする場合，経験損失は予測損失の不偏推定量であり，^[[@Mohri+2018 pp.10-11], [@金森敬文2015 p.8] など．] $n\to\infty$ の漸近論もすでに準備が出来ている．

予測損失の最小化の代わりに，経験損失の最小化を金科玉条とする枠組みを **経験リスク最小化 (Empirical Risk Minimization)** という．PAC 学習も，この金科玉条を（結果的にでも）正当化する枠組みであると言える．

しかし，この漸近論が提供してくれない消息は複数ある．

1. 機械学習においては，仮説 $h$ 自体がデータから決まる確率変数 $h_S:\Om\to\cH$ である場合が多い．これを考慮した収束が欲しい．
2. $n$ が有限の場合に非漸近論的消息が欲しい．

そこで以降は，アルゴリズム $A:(\cX\times\cY)^n\to\cH$ を通じて，$h_S:=A(S_n)$ と定まるとし，$h_S$ を単に $h$ ともかき，これをデータの関数とする．

この下で，$\wh{R}(h_S)$ と $R(h_S)$ の関係を考える．

::: {.callout-caution icon="false" collapse="true"}
## loss と error の区別

[@金森敬文2015 p.13] では，（決定論的な）仮説 $h\in\cH$ に関して，$R(h)$ を損失，データから決まる仮説 $h_S=A(S_n)$ に関して，$\E[R(h_S)]$ をリスクと呼び分けている．

損失のうち，特に **0-1損失**
$$
l=1_{\Delta_\cY^\comp}
$$^[$\Delta_\cY:=\Brace{(y',y)\in\cY^2\mid y=y'}$ を対角集合とした．]
に関するものを誤差といい，この２語は殆ど交換可能な形で使う．その期待値をリスクと言う，という使い分けは一つ筋が通りそうである．
:::

### Bayes ルール

::: {.callout-tip icon="false"}
## 
::: {#def-Bayes-loss}
## Bayes error, Bayes rule^[[@金森敬文2015 p.9] を参考．], excess risk / regret

損失関数 $l$ に対して，
$$
\begin{align*}
    R^*&:=\inf_{h\in\L(\cX;\cY)}R(h)\\
    &=\inf_{h\in\L(\cX;\cY)}\E[l(h(X),Y)]
\end{align*}
$$
を **Bayes 誤差** という．仮に右辺の下限が達成される $h^*\in\L(\cX;\cY)$ が存在するとき，これを **Bayes 規則** という．
$$
\cE(h):=R(h)-R^*
$$
を **超過損失** という．
:::
:::

$$
\begin{align*}
    \cE(\wh{h}_S)&=R(\wh{h}_S)-R(h^*)\\
    &=\Paren{R(\wh{h}_S)-\inf_{h\in\cH}R(h)}+\Paren{\inf_{h\in\cH}R(h)-R(h^*)}.
\end{align*}
$$
第一項を **推定誤差**，第二項を **近似誤差** という．^[[@金森敬文2015 p.17] を参考．]

ここから，$\ov{h}$ を $\inf_{h\in\cH}R(h)$ を達成する **oracle machine** とすると，推定誤差はさらに２項に分解して評価できる：
$$
\begin{align*}
    &R(\wh{h}_n)-\inf_{h\in\cH}R(H)\\
    &=R(\wh{h}_n)-R(\ov{h})\\
    &=\underbrace{\wh{R}_n(\wh{h}_n)-\wh{R}_n(\ov{h}_n)}_{\le0}+R(\wh{h}_n)-\wh{R}_n(\wh{h}_n)+\wh{R}_n(\ov{h})-R(\ov{h})\\
    &\le\ABs{\wh{R}_n(\wh{h}_n)-R(\wh{h}_n)}+\ABs{\wh{R}_n(\ov{h})-R(\ov{h})}.
\end{align*}
$$

### 主結果

::: {.callout-tip icon="false"}
## 
::: {#thm-1}
## PAC bound^[[@Alquier2021 p.7] など．]

仮設集合 $\cH$ が有限であるとする：$\#\cH=:M<\infty$．
このとき，任意の $\ep\in(0,1)$ について，
$$
\P\Square{\forall_{h\in\cH}\;R(h)-\wh{R}(h)\le C\sqrt{\frac{\log\frac{M}{\ep}}{2n}}}\ge1-\ep.
$$
:::
:::

#### $\ABs{\wh{R}_n(\wh{h}_n)-R(\wh{h}_n)}$ の評価



#### $\ABs{\wh{R}_n(\ov{h})-R(\ov{h})}$ の評価

#### その後の発展^[[@Devroye+1996] 第11, 12章 参照．[@Vapnik1998]．]

* 一般の $\cH\subset\L(\cX;\cY)$ への拡張は，VC次元の理論を用いて行われた．

* バウンドの変形に，Rademacher 複雑性も使われる．

## 正則化と汎化の関係

定理 @thm-1 の証明からも判る通り，推定誤差と近似誤差のトレードオフが存在する．

[@Bousquet-Elisseeff2002] を参照．

## PAC-Bayes

通常の機械学習の枠組みでは，仮設集合 $\cH\subset\L(\cX;\cY)$ を固定し，この中で最適な推定量 $\ov{h}\in\cH$ を探すことに集中する．

一方で，PAC-Bayes では，仮設集合 $\cH$ 上の確率分布を学習し，最終的に 投票 (vote) などの確率的な操作によって決めることを考え，これにも対応する理論を構築する．^[[@Alquier2021] Introduction より．]

これは [@Shawe-Taylor-Williamson1997] と [@McAllester1999] によって創始された．