---
title: "統計的学習理論"
author: "Draft Draft"
date: 1/10/2024
categories: [Kernels]
toc: true
number-sections: true
code-block-bg: true
code-block-border-left: "#31BAE9"
code-overflow: wrap
code-fold: true
bibliography: ../../../mathematics.bib
csl: ../../../apa.csl
abstract-title: 概要
abstract: 統計的学習理論の基礎を数学的に理解する
crossref:
    sec-prefix: 節
    eq-prefix: 式
    def-prefix: 定義
    def-title: 定義
    thm-prefix: 定理
    thm-title: 定理
---

{{< include ../../../_preamble.qmd >}}

「汎化」に価値を置く，独特の決定理論的な枠組みが存在する．
特に，現状では「経験リスク最小化」とその正則化が最もよく見られる．
この枠組みから，手法の優越を評価することとなる．

[@Mohri+2018], [@Vapnik1999]

## 径数模型の教師あり学習の場合

### 記法

* データサイズ $n\in\N^+$ を固定するのが特徴である．^[これを agnostical setting という．]
* データの全体を $S_n=\{z_i\}_{i=1}^n\subset\cX\times\cY$ と表す．
* $\cX,\cY$ はいずれも可測空間とし，部分集合 $\H\subset\L(\cX;\cY)$ を **仮設集合** という．
* 関数 $l:\cY^2\to\R_+$ を **損失関数** という．
* 写像 $A:(\cX\times\cY)^n\to\H$ を **アルゴリズム** という．

### PAC学習

> Probably Approximately Correct Learning

の略である．

::: {#def-loss}
1. 
$$
R(h):=\E[l(h(X),Y)]
$$
を **予測損失** という．
2. 
$$
\wh{R}(h):=\frac{1}{n}\sum_{i=1}^n l(h(x_i),y_i)
$$
を **経験損失** という．
:::

データが独立同分布に従うとする場合，経験損失は予測損失の不偏推定量であり，$n\to\infty$ の漸近論はすでに準備が出来ている．この理論が提供してくれない消息は複数ある．

予測損失の最小化の代わりに，経験損失の最小化を金科玉条とする枠組みを **経験リスク最小化 (Empirical Risk Minimization)** という．

1. 仮設 $h:\Om\to\H$ 自体がデータから決まる $h_S$ である．これを考慮した収束が欲しい．
2. $n$ が有限の場合に非漸近論的消息が欲しい．

### Bayes ルール

::: {#def-Bayes-loss}
損失関数 $l$ に対して，
$$
R^*:=\inf_{h\in\L(\cX;\cY)}R(h)
$$
を **Bayes 誤差** という．仮に右辺の下限が達成される $h^*\in\L(\cX;\cY)$ が存在するとき，これを **Bayes 規則** という．
:::

::: {#def-regret}
$$
\cE(h):=R(h)-R^*
$$
を **超過損失** という．
:::

$$
\begin{align*}
    \cE(\wh{h}_S)&=R(\wh{h}_S)-R(h^*)\\
    &=\Paren{R(\wh{h}_S)-\inf_{h\in\cH}R(h)}+\Paren{\inf_{h\in\cH}R(h)-R(h^*)}.
\end{align*}
$$
第一項を **推定誤差**，第二項を **近似誤差** という．

ここから，$\ov{h}$ を $\inf_{h\in\cH}R(h)$ を達成する **oracle machine** とすると，
$$
\begin{align*}
    &R(\wh{h}_n)-\inf_{h\in\cH}R(H)\\
    &=R(\wh{h}_n)-R(\ov{h})\\
    &=\underbrace{\wh{R}_n(\wh{h}_n)-\wh{R}_n(\ov{h}_n)}_{\le0}+R(\wh{h}_n)-\wh{R}_n(\wh{h}_n)+\wh{R}_n(\ov{h})-R(\ov{h})\\
    &\le\ABs{\wh{R}_n(\wh{h}_n)-R(\wh{h}_n)}+\ABs{\wh{R}_n(\ov{h})-R(\ov{h})}.
\end{align*}
$$

### $\ABs{\wh{R}_n(\wh{h}_n)-R(\wh{h}_n)}$ の評価



### $\ABs{\wh{R}_n(\ov{h})-R(\ov{h})}$ の評価

## 正則化と汎化の関係

[@Bousquet-Elisseeff2002] を参照．

## PAC-Bayes

通常の機械学習の枠組みでは，仮設集合 $\cH\subset\L(\cX;\cY)$ を固定し，この中で最適な点 $\ov{h}\in\cH$ を探すことに集中する．

一方で，PAC-Bayes では，仮設集合 $\cH$ 上の確率分布を学習し，最終的に 投票 (vote) によって決めることを考え，これにも対応する理論を構築する．^[[@Alquier2021] Introduction より．]

