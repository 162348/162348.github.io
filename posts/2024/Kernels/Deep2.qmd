---
title: "数学者のための深層学習２"
subtitle: トランスフォーマー
author: "司馬 博文"
date: 2/11/2024
categories: [Kernel, Math Notes]
toc: true
number-sections: true
code-block-bg: true
code-block-border-left: "#5AB5BA"
code-overflow: wrap
code-fold: true
bibliography: 
    - ../../../mathematics.bib
    - ../../../bib.bib
csl: ../../../apa.csl
crossref:
    sec-prefix: 節
    eq-prefix: 式
    def-prefix: 定義
    def-title: 定義
    thm-prefix: 定理
    thm-title: 定理
    fig-prefix: 図
    fig-title: 図
abstract-title: 概要
abstract: 数学者のために，深層学習モデルの例として，トランスフォーマーを概説する．
---

{{< include ../../../_preamble.qmd >}}

## トランスフォーマー

### 名前の由来と背景

トランスフォーマーは，注意 (attension) [@Vaswani+2017] という機構を通じて，時系列データの効率的な内部表現を獲得することの出来るモデルである．これは，内部表現ベクトルを，次元を変えずにより良いものに「変換する」というところから名前が付けられている．

初めは自然言語処理（特に機械翻訳）の文脈で導入されたが，画像，動画でも抜群の性能を発揮する上に，これらを組み合わせることもできる（第 [-@sec-multimodal-transformer] 節）．

さらに，トランスフォーマーはアーキテクチャとしてシンプルであり，大規模なデータセットで大規模なモデルを訓練することが出来るスケーラビリティが魅力である．これより，一度訓練した大規模モデルを種々の下流タスクに応用することが可能になり，基盤モデルという新たな存在を生み出した（第 [-@sec-foundation-model] 節）．

このことが，理論的に優れているが複雑なモデルを開発することよりも，スケーラブルでシンプルなモデルの方が，これを大規模にすることで実用的に高い性能を達成しやすいという共通了解を生みつつある．

### 注意機構

注意機構は，元々機械翻訳に用いられていたエンコーダー・デコーダー型の RNN の性能を向上させる機構として提案された [@Bahdanau+2015]．その後，[@Vaswani+2017] の _Attention is All You Need_ とは，注意機構のみが重要で，RNN としての構造（や画像では畳み込みの構造）を排してシンプルにした方が更に性能が向上する，という報告である．

時系列データの解析では，そして自然言語処理ではとりわけ，文脈というものが重要であり，同じデータでも文脈が違えば全く違う意味を持つということがよくある．

#### 枠組み

トランスフォーマーに入力する系列を $\{x^n\}_{n=1}^N\subset\R^D$ で表す．各 $x^n$ を **トークン** (token) という．画像では **パッチ** (patch) ともいう．

$X:=(x^n)_{n=1}^N\in M_{ND}(\R)$ とも表す．

#### 自己注意機構のプロトタイプ

自己注意機構とは，$Y=AX$ によって定まる $M_{ND}(\R)$ 上の線型変換 $X\mapsto Y$ のことである：
$$
y^n=\sum_{m=1}^N a^n_mx^m,
$$ {#eq-1}
$$
a^n_m=\frac{e^{(x^n)^\top x^m}}{\sum_{k=1}^Ne^{(x^n)^\top x^k}}.
$$ {#eq-2}
ここで，$A=(a^n_m)_{n,m\in[N]}\in M_N(\R)$ は確率行列をなし，その成分を **注意荷重** (attention weight) という．

この変換において，同じ $x^m$ の値を，３回別々の意味で使われていることに注意する．

* @eq-1 における $x^m$ は，新たな表現 $y^n$ を作るためのプロトタイプにような働きをしている．これを **値** (value) という．
* @eq-2 において，内積が用いられており，$x^n$ と $x^m$ の類似度が測られている．
  * $x^m$ を，$x^m$ が提供出来る情報を要約した量としての働きをし，**鍵** (key) という．
  * $x^n$ は，$x^n$ と関連すべき情報を要求する役割を果たし，**クエリ** (query) という．
* 最終的に，鍵とクエリの類似度・マッチ度を，[ソフトマックス関数](https://ja.wikipedia.org/wiki/%E3%82%BD%E3%83%95%E3%83%88%E3%83%9E%E3%83%83%E3%82%AF%E3%82%B9%E9%96%A2%E6%95%B0) を通じて確率分布として表現し，バリューの空間 $\{x^m\}_{m=1}^N$ 上の確率質量関数 $\{a^n_m\}_{m=1}^N$ を得ている．これに関して積分することで，鍵 $y^n$ を得る．

#### 実際の自己注意機構

３つの別々の役割を果たしている以上，それぞれ固有の表現を持っていても良いはずである．そこで，値，鍵，クエリに，それぞれにニューラルネットワーク $W_{(\Lambda)}\in M_{DD_{(\Lambda)}}(\R)\;(\Lambda\in\{V,K,Q\})$ を与えて固有の表現
$$
x_{(\Lambda)}^n:=XW_{(\Lambda)}
$$
を持たせ，この $W_{(\Lambda)}$ を誤差逆伝播法により同時に学習することとする．

こうして得るのが，内積による自己注意機構 (dot-product self-attention mechanism) である．このとき，$D_{(K)}=D_{(Q)}$ は必要だが，$y^n\in\R^{D_{(V)}}$ は，元の次元 $D$ と異なっても良いことに注意．

最後に，ソフトマックス関数の適用において，勾配消失を回避するために，次元 $D_{(K)}$ に応じたスケーリングを介して
$$
a^n_m=\frac{e^{\frac{\paren{x^n_{(Q)}}^\top x^m_{(K)}}{\sqrt{D_K}}}}{\sum_{k=1}^Ne^{\frac{\paren{x^n_{(Q)}}^\top x^k_{(K)}}{\sqrt{D_K}}}}
$$
とする．これを最終的な **自己注意機構** (scaled dot-product self-attention mechanism) という．

#### 多頭注意

以上の自己注意機構を１単位として，これを複数独立に訓練し，最終的にはこれらの線型結合を採用する仕組みを **多頭注意** (multi-head attention) という．

これにより，種々の文脈をより頑健に読み取ることが出来るようである．

#### トランスフォーマーの全体

更に勾配消失を回避するために，[残差結合](Deep.qmd#sec-ResNet) を導入し，訓練の高速化のために正規化 [@Ba+2016] が導入される．

そして，モデルを大規模化していくには，この「多頭注意＋残差結合と正規化」のブロックを積み重ねる．

注意機構は線型性が高いため，多頭注意の層の間に，通常の多層パーセプトロンもスタックして，ネットワークの表現能力を保つ工夫もされる．

## 言語トランスフォーマー

言語モデルをニューラルネットワークによって作ることは早くから試みられていた [@Bengio+2000]．

トランスフォーマーの登場まで，これには RNN が主に用いられていた．



### 言語の取り扱い

#### 単語の埋め込み

言語をそのまま扱うのではなく，トークン $x^n\in\R^D$ の形に符号化する必要がある．

言語には他にも改行や数式，コンピューターコードがあるが，まずは単語の表現を考える．

単語を Euclid 空間内に埋め込んだものを **分散表現** (distributed representation) という．これを２層のニューラルネットワークで行う技術が `word2vec` である [@Mikolov2013]．

その訓練法には２つあり，窓の幅を $M=5$ などとすると，

* CBOW (Continuous Bag of Words)：前後 $M$ 語のみを見せて，中央の語を予測する．
* Continuous Skip-gram：中央の語を見せて，前後 $M$ 語を予測する．

という，いずれも教師なしの方法によって学習される．

#### トークン化

バイトペア符号化 (BPE: Byte Pair Encoding) [@Sennrich+2016] は，データ圧縮の手法であるが，単語に限らず種々のデータを含んだ文字列を符号化するのにも用いられる．

#### 位置情報符号化

トランスフォーマーはそのままではトークンの順番を考慮しないため，トークンの順番の情報も符号化時に含める必要がある．これを **位置情報符号化** (positional encoding) という [@Dufter+2021]．

このようにして，位置情報はトランスフォーマーのモデル構造を修正して組み込むのではなく，符号化の段階で組み込み，トランスフォーマーはそのまま使うのである．

これは，位置情報をトークンと同じ空間に埋め込んだ表現 $r^n$ を学習し，
$$
\wt{x}^n:=x^n+r^n
$$
を新たな符号とする．

### デコーダーのみの言語モデル

GPT などの生成モデルは，デコーダー部分のトランスフォーマーの機能を主に用いている．

これはまず，

1. トークン列 $(x^n)_{n=1}^{N-1}$ を入力し，条件付き分布 $p(x^N|x_1,\cdots,x^{N-1})$ を得る．
2. 分布 $p(x^N|x_1,\cdots,x^{N-1})$ からサンプリングをする．

の２段階で行われる．こうして $(x^n)_{n=1}^N$ を得たら，次は $x^{N+1}$ を生成し，文章が終わるまでこれを続けることで，最終的な生成を完遂する．

#### 条件付き分布の表現

大規模なデータセットの上で，文章を途中まで読み，次のトークンを推測する，という自己教師あり学習を行うことで，トークン上の条件付き分布を学習する．

### エンコーダーのみの言語モデル

BERT [@Devlin+2019] などの言語理解モデルは，エンコーダ部分のトランスフォーマーの機能を主に用いている．

## 大規模言語モデル

### 名前の由来と背景

自然言語処理にトランスフォーマーを応用した例は大きな成功を見ている．GPT-2 [@Radford+2019], GPT-3 [@Brown+2020], GPT-4 [@OpenAI2023] のシリーズはその代表であり，特に GPT-4 は AGI の実現に向けた重要な一歩とも評されている [@Bubeck+2023]．

その成功は，言語モデルとして優れているという点よりもむしろ，並列化が可能であり GPU などの計算資源を効率的に使えるという点にあり，モデルの改良よりも計算資源の増強が最終的に大きな進歩をもたらすという側面が大きい，という認識が優勢になっている [@Sutton2019]．これはスケーリング則として理論的にも理解が試みられている [@Kaplan+2020]．

この観点から，トランスフォーマーを用いた事前学習済みの言語モデルが，種々のタスクをほとんど例示なし (few-shot / zero-shot) で解ける能力を創発する程度に大きい場合，その規模が意味を持つことを強調して，**大規模言語モデル** (LLM: Large Language Model) とも呼ぶ [@Zhao+2023]．

### 「基盤モデル」と事後調整 {#sec-foundation-model}

GPT の P とは Pre-trained である．自己教師あり学習によって [事前学習](Deep.qmd#sec-pretraining-using-AE) をしたあと，さらに教師あり学習によって微調整を行う．

この微調整は **事後調整** (fine-tune) と呼ばれ，転移学習の一種ともみなせる．この意味でも，さらに使い方の意味でも，種々の応用や下流タスク (downstream task) の基礎となるモデルであることと，そのものでは未完成であることとを強調して，**基盤モデル** (foundation model) とも呼ばれる [@Bommasani+2021]．

事後調整では，モデルの全体では規模が大きすぎるため，出力層の後に新しいニューラルネットを付加したり，最後の数層のみを追加で教師あり学習をしたりする方法が一般的である．または，LoRA (Low-Rank Adaptation) [@Hu+2021] では，トランスフォーマーの各層に新たな層を挿入し，これを学習する．

これは，事後調整に有効な内的次元は実際には小さく [@Aghajanyan+2021]，これに有効にアクセスし，効率的な事後調整を行うことが出来るという．

事後調整には，他にも，ChatGPT のようなサービスを展開するために必要なユーザー体験の改善を目的としたものも含まれる．GPT-4 では [人間のフィードバックによる強化学習](https://ja.wikipedia.org/wiki/%E4%BA%BA%E9%96%93%E3%81%AE%E3%83%95%E3%82%A3%E3%83%BC%E3%83%89%E3%83%90%E3%83%83%E3%82%AF%E3%81%AB%E3%82%88%E3%82%8B%E5%BC%B7%E5%8C%96%E5%AD%A6%E7%BF%92) (RLHF: Reinforcement Learning through Human Feedback) [@Christiano+2017] が用いられている [@OpenAI2023 p.2]．

### プロンプトエンジニアリング

基盤モデルは使い方によって大きく性能が変わる．特に，prompt engineering [@Liu+2023] は，プロンプトの送り方によって性能がどう変わるかを調べる新たな分野である．

その結果，プロンプト内で新たなタスクを定義するだけで，これが解けてしまうこともわかっており，これを few-shot learning という．これも大規模言語モデルの大きな特徴である．


## 画像トランスフォーマー

## 多相トランスフォーマー {#sec-multimodal-transformer}