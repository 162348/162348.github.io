---
title: "数学者のための深層学習２"
subtitle: トランスフォーマー
author: "司馬 博文"
date: 2/11/2024
categories: [Kernel, Math Notes]
toc: true
number-sections: true
code-block-bg: true
code-block-border-left: "#5AB5BA"
code-overflow: wrap
code-fold: true
bibliography: 
    - ../../../mathematics.bib
    - ../../../bib.bib
csl: ../../../apa.csl
crossref:
    sec-prefix: 節
    eq-prefix: 式
    def-prefix: 定義
    def-title: 定義
    thm-prefix: 定理
    thm-title: 定理
    fig-prefix: 図
    fig-title: 図
abstract-title: 概要
abstract: 数学者のために，深層学習モデルの例として，トランスフォーマーを概説する．
---

{{< include ../../../_preamble.qmd >}}

## トランスフォーマー

### 名前の由来と背景

トランスフォーマーは，注意 (attension) [@Vaswani+2017] という機構を通じて，時系列データの効率的な内部表現を獲得することの出来るモデルである．これは，内部表現ベクトルを，次元を変えずにより良いものに「変換する」というところから名前が付けられている．

初めは自然言語処理（特に機械翻訳）の文脈で導入されたが，画像，動画でも抜群の性能を発揮する上に，これらを組み合わせることもできる（第 [-@sec-multimodal-transformer] 節）．

さらに，トランスフォーマーはアーキテクチャとしてシンプルであり，大規模なデータセットで大規模なモデルを訓練することが出来るスケーラビリティが魅力である．これより，一度訓練した大規模モデルを種々の下流タスクに応用することが可能になり，基盤モデルという新たな存在を生み出した（第 [-@sec-foundation-model] 節）．

このことが，理論的に優れているが複雑なモデルを開発することよりも，スケーラブルでシンプルなモデルの方が，これを大規模にすることで実用的に高い性能を達成しやすいという共通了解を生みつつある．

### 注意機構

注意機構は，元々機械翻訳に用いられていたエンコーダー・デコーダー型の RNN の性能を向上させる機構として提案された [@Bahdanau+2015]．その後，[@Vaswani+2017] の _Attention is All You Need_ とは，注意機構のみが重要で，RNN としての構造（や画像では畳み込みの構造）を排してシンプルにした方が更に性能が向上する，という報告である．

時系列データの解析では，そして自然言語処理ではとりわけ，文脈というものが重要であり，同じデータでも文脈が違えば全く違う意味を持つということがよくある．

#### 枠組み

トランスフォーマーに入力する系列を $\{x^n\}_{n=1}^N\subset\R^D$ で表す．各 $x^n$ を **トークン** (token) という．画像では **パッチ** (patch) ともいう．

$X:=(x^n)_{n=1}^N\in M_{ND}(\R)$ とも表す．

#### 自己注意機構のプロトタイプ

自己注意機構とは，$Y=AX$ によって定まる $M_{ND}(\R)$ 上の線型変換 $X\mapsto Y$ のことである：
$$
y^n=\sum_{m=1}^N a^n_mx^m,
$$ {#eq-1}
$$
a^n_m=\frac{e^{(x^n)^\top x^m}}{\sum_{k=1}^Ne^{(x^n)^\top x^k}}.
$$ {#eq-2}
ここで，$A=(a^n_m)_{n,m\in[N]}\in M_N(\R)$ は確率行列をなし，その成分を **注意荷重** (attention weight) という．

この変換において，同じ $x^m$ の値を，３回別々の意味で使われていることに注意する．

* @eq-1 における $x^m$ は，新たな表現 $y^n$ を作るためのプロトタイプにような働きをしている．これを **値** (value) という．
* @eq-2 において，内積が用いられており，$x^n$ と $x^m$ の類似度が測られている．
  * $x^m$ を，$x^m$ が提供出来る情報を要約した量としての働きをし，**鍵** (key) という．
  * $x^n$ は，$x^n$ と関連すべき情報を要求する役割を果たし，**クエリ** (query) という．
* 最終的に，鍵とクエリの類似度・マッチ度を，[ソフトマックス関数](https://ja.wikipedia.org/wiki/%E3%82%BD%E3%83%95%E3%83%88%E3%83%9E%E3%83%83%E3%82%AF%E3%82%B9%E9%96%A2%E6%95%B0) を通じて確率分布として表現し，バリューの空間 $\{x^m\}_{m=1}^N$ 上の確率質量関数 $\{a^n_m\}_{m=1}^N$ を得ている．これに関して積分することで，鍵 $y^n$ を得る．

#### 実際の自己注意機構

３つの別々の役割を果たしている以上，それぞれ固有の表現を持っていても良いはずである．そこで，値，鍵，クエリに，それぞれにニューラルネットワーク $W_{(\Lambda)}\in M_{DD_{(\Lambda)}}(\R)\;(\Lambda\in\{V,K,Q\})$ を与えて固有の表現
$$
x_{(\Lambda)}^n:=XW_{(\Lambda)}
$$
を持たせ，この $W_{(\Lambda)}$ を誤差逆伝播法により同時に学習することとする．

こうして得るのが，内積による自己注意機構 (dot-product self-attention mechanism) である．このとき，$D_{(K)}=D_{(Q)}$ は必要だが，$y^n\in\R^{D_{(V)}}$ は，元の次元 $D$ と異なっても良いことに注意．

最後に，ソフトマックス関数の適用において，勾配消失を回避するために，次元 $D_{(K)}$ に応じたスケーリングを介して
$$
a^n_m=\frac{e^{\frac{\paren{x^n_{(Q)}}^\top x^m_{(K)}}{\sqrt{D_K}}}}{\sum_{k=1}^Ne^{\frac{\paren{x^n_{(Q)}}^\top x^k_{(K)}}{\sqrt{D_K}}}}
$$
とする．これを最終的な **自己注意機構** (scaled dot-product self-attention mechanism) という．

### トランスフォーマーの全体

#### 多頭注意

以上の自己注意機構を１単位として，これを複数独立に訓練し，最終的にはこれらの線型結合を採用する仕組みを **多頭注意** (multi-head attention) という．

これにより，種々の文脈をより頑健に読み取ることが出来るようである．

#### 残差結合と正規化

更に勾配消失を回避するために，[残差結合](Deep.qmd#sec-ResNet) を導入し，訓練の高速化のために正規化 [@Ba+2016] が導入される．

そして，モデルを大規模化していくには，この「多頭注意＋残差結合と正規化」のブロックを積み重ねる．

注意機構は線型性が高いため，多頭注意の層の間に，通常の多層パーセプトロンもスタックして，ネットワークの表現能力を保つ工夫もされる．

#### 正規化

レイヤー正則化 (layer normalization) [@Ba+2016] は，バッチ正規化 (batch normalization) [@Ioffe-Szegedy2015] が RNN にも適するようにした修正として提案された．

バッチ正規化は，ニューラルネットワークの内部層の学習が，手前の層のパラメータが時事刻々と変化するために安定した学習が出来ないという **内部共変量シフト** (internal covariate shift) にあると突き止め，これをモデルアーキテクチャに正規化層を取り入れることで解決したものである．

正規化層は，ニューラルネットワークへの入力を，平均が零で分散が $1$ になるように変換する．元々，ニューラルネットワークの入力を正規化してから学習させることで学習が効率化されることは知られていた [@LeCun+2012] が，バッチ正規化は，これをバッチごとに，かつ，モデルの内部にも取り込んだものである．

バッチ正規化は精度の上昇と訓練の加速をもたらす．これはバッチ正規化により大きな学習率で訓練しても活性化が発散せず，これにより訓練時間の短縮と，局所解に囚われにくく汎化性能の向上がもたらされているようである [@Bjorck+2018]．

## 言語トランスフォーマー

言語モデルをニューラルネットワークによって作ることは早くから試みられていた [@Bengio+2000]．

トランスフォーマーの登場まで，これには RNN が主に用いられていた．しかし，RNN は長い系列に対しては勾配消失が起こりやすく，また，並列化が難しいという問題があった．

### 言語の取り扱い

#### 単語の分散表現

言語をそのまま扱うのではなく，トークン $x^n\in\R^D$ の形に符号化する必要がある．

言語には他にも改行や数式，コンピューターコードがあるが，まずは単語の表現を考える．

単語を Euclid 空間内に埋め込んだものを **分散表現** (distributed representation) という．これを２層のニューラルネットワークで行う技術が `word2vec` である [@Mikolov2013]．

その訓練法には２つあり，窓の幅を $M=5$ などとすると，

* CBOW (Continuous Bag of Words)：前後 $M$ 語のみを見せて，中央の語を予測する．
* Continuous Skip-gram：中央の語を見せて，前後 $M$ 語を予測する．

という，いずれも教師なしの方法によって学習される．

#### トークン化

バイトペア符号化 (BPE: Byte Pair Encoding) [@Sennrich+2016] は，データ圧縮の手法であるが，単語に限らず種々のデータを含んだ文字列を符号化するのにも用いられる．

#### 位置情報符号化

トランスフォーマーはそのままではトークンの順番を考慮しないため，トークンの順番の情報も符号化時に含める必要がある．これを **位置情報符号化** (positional encoding) という [@Dufter+2021]．

このようにして，位置情報はトランスフォーマーのモデル構造を修正して組み込むのではなく，符号化の段階で組み込み，トランスフォーマーはそのまま使うのである．

これは，位置情報をトークンと同じ空間に埋め込んだ表現 $r^n$ を学習し，
$$
\wt{x}^n:=x^n+r^n
$$
を新たな符号とする．

### 従来の言語モデル

文章をトークン列 $\{x^n\}_{n=1}^N\subset\R^D$ に置き換えたあとに，この上の結合分布 $p(x^1,\cdots,x^N)$ をモデリングすることが，**言語モデル** の目標である．

#### $n$-gram

$L\ge1$ とし，$x_n=0\;(n\le0)$ として，
$$
p(x_1,\cdots,x_N)=\prod_{n=1}^Np_{\theta_n}(x_n|x_{n-L},\cdots,x_{n-1})
$$
という形で $p$ をモデリングする，自己回帰性を加味したモデルは古くから使われる．

これは $L$-gram モデルと呼ばれるが，文章の長さ $N$ が大きくなると，必要なパラメータ $\theta_n$ の数が増加する．

これに対処する方法としては，[隠れ Markov モデル](../../2023/Surveys/SSM.qmd) を用いることが考えられる．

#### RNN

言語モデルをニューラルネットワークによって表現することが，[@Mikolov+2010] によって試みられた．

これは通常のニューラルネットワーク (FFN: Feed-Forward Network と呼ばれる) に出力の一部を次の入力に使うという回帰的な流れを追加することで，隠れ Markov モデルのように次に持ち越される内部状態を持つことを可能にしたモデルである．

しかしこれは学習が困難である．誤差の逆伝播を時間に対しても逆方向に繰り返す必要がある (Backpropagation through time) ので，長い系列に対しては逆伝播しなければいけない距離が長く，勾配消失・爆発が起こりやすい．これは長期的な依存関係を学習しにくいということももたらす．^[勾配の爆発に対しては gradient clipping などの対症療法が用いられる．] また，並列化も難しい．

これに対処するために，モデルの構造を変えて過去の情報を流用しやすくする方法も種々提案された．LSTM (Long short-term memory) [@Hochreiter-Schmidhuber1997] や GRU (Gated Recurrent Unit) [@Cho+2014] などがその例である．

### デコーダーのみの言語モデル

GPT などの生成モデルは，デコーダー部分のトランスフォーマーの機能を主に用いている．

これはまず，

1. トークン列 $(x^n)_{n=1}^{N-1}$ を入力し，条件付き分布 $p(x^N|x_1,\cdots,x^{N-1})$ を得る．
2. 分布 $p(x^N|x_1,\cdots,x^{N-1})$ からサンプリングをする．

の２段階で行われる．こうして $(x^n)_{n=1}^N$ を得たら，次は $x^{N+1}$ を生成し，文章が終わるまでこれを続けることで，最終的な生成を完遂する．

#### 条件付き分布の表現

大規模なデータセットの上で，文章を途中まで読み，次のトークンを推測する，という自己教師あり学習を行うことで，トークン上の条件付き分布を学習する．

この際に，先のトークンの情報は使わないように，注意機構を工夫 (masked / causal attention) して訓練する．

#### 条件付き分布からのサンプリング

仮に最も確率の高いトークンを毎回選択する場合，出力は決定論的であり，同じ表現を繰り返すことが多くみられる．

実は，より人間らしい表現は，確率の低いトークンもかなら頻繁に採用される [@Holtzman+2020]．

かと言って，純粋なサンプリングをしたのでは，文章全体から見て意味をなさない場合も多い．

これを解決したのが top-$p$ sampling / nucleus sampling [@Holtzman+2020] である．

[GPT-2 にも実装されている](https://github.com/openai/gpt-2-output-dataset/issues/5) ようである．

### エンコーダーのみの言語モデル

BERT (bidirectional encoder representations from transformers) [@Devlin+2019] などの言語理解モデルは，エンコーダ部分のトランスフォーマーの機能を主に用いている．その結果，生成は出来ない．

訓練は，データセットから単語を確率的に脱落させ，これを補完するように訓練する．結果として，文章の前後両方 (bidirectional) の文脈を考慮するようになるのである．

実際に使う際は，例えば感情の判別などでは，文章の冒頭に `[class]` などの特殊なトークンを置き，これをエンコーダーに通してトークンが何に置き換わるかを見ることで，判別を実行することができる．

### エンコーダー・デコーダーの言語モデル

トランスフォーマーは原論文 [@Vaswani+2017] では，エンコーダーとデコーダーがセットになったモデルとして提案された．

これは機械翻訳を念頭に置いていたため，RNN の構造を引き継いだ形で提案されたためである．この場合，次のようにしてモデルは使われる

1. 入力 $X$ をエンコーダーに通し，内部表現 $Z$ を得る．
2. この内部表現 $Z$ を元に，デコードした結果 $Y$ を出力する．
3. 唯一，$Z$ をデコーダーに渡す部分での注意機構層では，鍵と値としては $Z$ を使うが，クエリとしては $Y$ を使う．

３の機構を **エンコーダー・デコーダーの注意機構** (encoder-decoder / corss attention mechanism) といい，これによって $Z$ と $Y$ のトークンの間の類似度をモデルに取り入れる．

## 大規模言語モデル

### 名前の由来と背景

自然言語処理にトランスフォーマーを応用した例は大きな成功を見ている．GPT [@Radford+2018], GPT-2 [@Radford+2019], GPT-3 [@Brown+2020], GPT-4 [@OpenAI2023] のシリーズはその代表であり，特に GPT-4 は AGI の実現に向けた重要な一歩とも評されている [@Bubeck+2023]．^[他にも Google の [GShard](https://research.google/pubs/gshard-scaling-giant-models-with-conditional-computation-and-automatic-sharding/) [@Lepikhin+2021]，Google Brain の Switch Transformers [@Fedus+2022]，Google DeepMind の [Gopher](https://deepmind.google/discover/blog/language-modelling-at-scale-gopher-ethical-considerations-and-retrieval/) [@Rae+2021] などがある．]

その成功は，言語モデルとして優れているという点よりもむしろ，並列化が可能であり GPU などの計算資源を効率的に使えるという点にあり，モデルの改良よりも計算資源の増強が最終的に大きな進歩をもたらすという側面が大きい，という認識が優勢になっている [@Sutton2019]．これはスケーリング則として理論的にも理解が試みられている [@Kaplan+2020]．

この観点から，トランスフォーマーを用いた事前学習済みの言語モデルが，種々のタスクをほとんど例示なし (few-shot / zero-shot) で解ける能力を創発する程度に大きい場合，その規模が意味を持つことを強調して，**大規模言語モデル** (LLM: Large Language Model) とも呼ぶ [@Zhao+2023]．

### 「基盤モデル」と事後調整 {#sec-foundation-model}

GPT の P とは Pre-trained である．自己教師あり学習によって [事前学習](Deep.qmd#sec-pretraining-using-AE) をしたあと，さらに教師あり学習によって微調整を行う．

この微調整は **事後調整** (fine-tune) と呼ばれ，転移学習の一種ともみなせる．この意味でも，さらに使い方の意味でも，種々の応用や下流タスク (downstream task) の基礎となるモデルであることと，そのものでは未完成であることとを強調して，**基盤モデル** (foundation model) とも呼ばれる [@Bommasani+2021]．

事後調整では，モデルの全体では規模が大きすぎるため，出力層の後に新しいニューラルネットを付加したり，最後の数層のみを追加で教師あり学習をしたりする方法が一般的である．または，LoRA (Low-Rank Adaptation) [@Hu+2021] では，トランスフォーマーの各層に新たな層を挿入し，これを学習する．

これは，事後調整に有効な内的次元は実際には小さく [@Aghajanyan+2021]，これに有効にアクセスし，効率的な事後調整を行うことが出来るという．

事後調整には，他にも，ChatGPT のようなサービスを展開するために必要なユーザー体験の改善を目的としたものも含まれる．GPT-4 では [人間のフィードバックによる強化学習](https://ja.wikipedia.org/wiki/%E4%BA%BA%E9%96%93%E3%81%AE%E3%83%95%E3%82%A3%E3%83%BC%E3%83%89%E3%83%90%E3%83%83%E3%82%AF%E3%81%AB%E3%82%88%E3%82%8B%E5%BC%B7%E5%8C%96%E5%AD%A6%E7%BF%92) (RLHF: Reinforcement Learning through Human Feedback) [@Christiano+2017] が用いられている [@OpenAI2023 p.2]．

### プロンプトエンジニアリング

基盤モデルは使い方によって大きく性能が変わる．特に，prompt engineering [@Liu+2023] は，プロンプトの送り方によって性能がどう変わるかを調べる新たな分野である．

その結果，プロンプト内で新たなタスクを定義するだけで，これが解けてしまうこともわかっており，これを few-shot learning という．これも大規模言語モデルの大きな特徴である．

## 多相トランスフォーマー {#sec-multimodal-transformer}

トランスフォーマーは自然言語処理の文脈で開発されたが，画像や動画，音声 [@Radford+2023] にも適用されている．

動画はまだしも画像には，直感的には時系列構造がないように思えるが，トランスフォーマーはもはや汎用のニューラルネットワークアーキテクチャとして使用できることが解りつつある．

それぞれの応用分野で **モデルの構造は殆ど差異がなく**，トークン化の手法などに差異があるのみのように見受けられる．^[モデルの比較は [@Raffel+2020] などが行っている．]

### 画像トランスフォーマー (ViT)

画像の分類問題を解くためのエンコーダ・トランスフォーマーは ViT (Vision Transformer) [@Dosovitskiy+2021] と呼ばれており，ILSVRC (the ImageNet Large Scale Visual Recognition Challenge) では未だ [ResNet](Deep.qmd#sec-ResNet) 系のモデルが優勢であった 2021 年に，これを超える性能を示した．

実はモデルは殆どトランスフォーマーそのままであり，肝要であったのは画像をトークン化である．ピクセルをそのまま用いるのではなく，ある程度大きなピクセルの集合である **パッチ** (patch) を用いることで，計算量を下げる．[@Dosovitskiy+2021] では $16\times16$ サイズなどが採用された．

一方で，画像を恣意的に系列化しているため，幾何学的な構造は１から学ぶ必要があり，最初からモデルに組み込まれている [CNN](Deep.qmd#sec-CNN) よりは一般に多くの訓練データを必要とする．だが，これにより帰納バイアスが弱いということでもある．

トークン化に小規模な CNN を用いてデータ圧縮を行うこともある．

### 画像生成トランスフォーマー

一方でデコーダートランスフォーマーを用いて，画像の生成モデリングを行った最初の例は [@Chen+2020] である．

なお，自己回帰的な生成モデルを通じて画像の生成を試みることは，CNN [@vandenOord+2016b] や RNN [@vandenOord+2016] でも行われている．

この際に判明したことには，画像の分類タスクでは連続表現が役に立っても，生成タスクでは高い解像度を持った画像の生成が難しく，離散表現が有効であることが知られている．しかしこれではデータ量が増えてしまうため，画像の [ベクトル量子化](../Computation/VI.qmd#sec-history) が行われることが多い．

[@Chen+2020] でも $K$-平均法によるクラスタリングが行われており，さらに [VQ-VAE](Deep4.qmd#sec-VQ-VAE) を用いたデータ圧縮も行われている．

[@Chen+2020] では最終的に各ピクセルを one-hot 表現にまで落とし込み，これを GPT-2 モデル [@Radford+2019] につなげている．

Google の [BigGAN](https://arxiv.org/abs/1809.11096) は，トランスフォーマーを用いた生成モデルの例である．[MUSE](https://muse-model.github.io/) [@Krause+2023]

### 動画トランスフォーマー

動画を画像の連続と見てトランスフォーマーを応用するアプローチは Latte (Latent Diffusion Transformer) [@Rakhimov+2020] に始まる．

VideoGPT [@Yan+2021] では動画を 3D の CNN でデータ圧縮，VQ-VAE で量子化して離散的な潜在表現を得た後，GPT と殆ど似たトランスフォーマーに通して学習し，

### 世界モデルとしてのトランスフォーマー

トランスフォーマーを世界モデルとして用いて，シミュレーションを行い動画を生成し，これをモデルベースの強化学習 [@Sutton-Barto2018] の材料とすることが広く提案されている．これは learning in imagination [@Racaniere+2017] と呼ばれる．^[[@Ha-Schmidthuber2018] は RNN により世界モデルを構築している．[@Kaiser+2020] は動画から Atari を学習している．[@Hafner+2021] はさらに性能が良い．]

IRIS (Imagination with auto-Regression over an Inner Speech) [@Micheli+2023] はこれに初めてトランスフォーマーを用いた世界モデルから動画生成をした．

