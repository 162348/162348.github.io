---
title: "階層模型再論"
author: "司馬 博文"
date: 8/12/2024
date-modified: 8/12/2024
categories: [Statistics]
bibliography: 
    - ../../../assets/mathematics.bib
    - ../../../assets/bib.bib
    - ../../../assets/bib1.bib
csl: ../../../assets/apalike.csl
abstract-title: 概要
abstract: この手法は，表現学習，非線型独立成分分析など，「生成」以外の潜在変数模型の応用法を横断してレビューする．識別性を保った深層潜在モデルを学習しようとする方法は，因果的表現学習とも呼ばれている．
listing: 
    -   id: kernel-listing
        type: grid
        sort: false
        contents:
            - "NCL.qmd"
            - "Manifold.qmd"
            - "../Samplers/Sampling.qmd"
        date-format: iso
        fields: [title,image,date,subtitle]
# shift-heading-level-by: -1
---

### 関連ページ {.unnumbered .unlisted}

::: {#kernel-listing}
:::


{{< include ../../../assets/_preamble.qmd >}}

## はじめに

潜在変数模型とはどうやらとんでもなく広い射程を持った対象であるようである．

::: {.callout-tip appearance="simple" icon="false"}

1. 心理学，経済学をはじめとして多くの分野で中心的に扱われてきたモデルである（因子分析，構造方程式モデル，DAG，[Probabilistic Graphical Model](../Computation/PGM1.qmd) など）．
2. ベイズ統計学では **階層モデル** (hierarchical model) として極めて重要な役割を果たす．
3. 生成モデリングも，観測変数上の周辺分布がデータ分布に近づくように潜在変数模型を学習する方法である．
4. 表現学習や独立成分分析だけでなく，脳も潜在変数模型に基いてメンタルモデルを構成しているという仮説もある（[InfoMax に関する稿](NCL.qmd#sec-InfoMax)も参照）．

:::

このように種々の文脈で登場する潜在変数模型であるが，[それぞれの文脈において「潜在変数」の果たす役割は全く違う]{.underline}．

しかし，数学的には全く同じ枠組みで記述できる．従って，そのように扱うことは一定の価値を持つだろう．

本稿では問題とする潜在変数モデルを線型かつ１層に固定し，それぞれの文脈での「使い方の違い」に注目することを目指す．