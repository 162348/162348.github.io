---
title: "数学者のための深層学習５"
subtitle: 拡散モデル
author: "司馬 博文"
date: 2/14/2024
categories: [Kernel, Math Notes]
toc: true
number-sections: true
code-block-bg: true
code-block-border-left: "#5AB5BA"
code-overflow: wrap
code-fold: true
bibliography: 
    - ../../../mathematics.bib
    - ../../../bib.bib
csl: ../../../apa.csl
crossref:
    sec-prefix: 節
    eq-prefix: 式
    def-prefix: 定義
    def-title: 定義
    thm-prefix: 定理
    thm-title: 定理
    fig-prefix: 図
    fig-title: 図
abstract-title: 概要
abstract: 数学者のために，深層生成モデルの１つ VAE を概観する．
---

{{< include ../../../_preamble.qmd >}}

## 導入

[@Luo2022]

### 歴史

拡散モデルによる画像生成は，初め [@Dickstein+2015] で提案された．^[VideoGPT の論文 [@Yan+2021] や，DALL-E2 の論文 [@Ramesh+2022]，GLIDE の論文 [@Nichol+2022] でも引用されている．]

これをスコアマッチングの手法 [@Hyvarinen2005], [@Vincent2011] と組み合わせたのが NCSN (Noise Conditioned Score Network) [@Song-Ermon2020] や DDPM (Denoising Diffusion Probabilistic Model) [@Ho+2020] である．

この２つの手法は，ノイズスケジュールが異なるのみで本質的に同じ枠組みであるとみなせる [@Huang+2021]．

### 拡散モデルの例

ADM (Ablated Diffusion Model) [@Dhariwal-Nichol2021] は ImageNet データの判別において当時の最先端であった BigGAN [@Brock+2019] の性能を凌駕した．

OpenAI の [GLIDE](https://github.com/openai/glide-text2im) (Guided Language to Image Diffusion for Generation and Editing) [@Nichol+2022] は，[CLIP](https://openai.com/research/clip) という画像符号化器と組み合わされた，テキスト誘導付き拡散モデルである．

Google も [Imagen](https://imagen.research.google/) [@Saharia+2022] という拡散モデルを開発している．

[@Yang+2023] は動画生成に応用している．

### アイデア {#sec-idea}

[GAN](Deep3.qmd)，[VAE](Deep4.qmd)，[正規化流](Deep6.qmd) などの生成モデルでは，潜在空間 $\cZ$ からデータの空間 $\cX$ への確率核を深層ニューラルネットワークで学習するのであった．

ニューラルネットワークの表現力は十分高いので，$\cZ$ 上の事前分布は典型的には正規分布が用いられる．

拡散モデルも，全くこの枠組みから逸脱するものではない．

まず訓練データを，完全な Gauss 分布になるような変換を行う．これを複数段階に分けて提示し，この逆過程を学習する．画像においては，[U-Net](Deep.qmd#sec-U-net) [@Ronneberger+2015] が典型的に用いられる．

並列化が容易であり，スケーラブルな手法であるため，トランスフォーマーと組み合わせて画像と動画の生成に使われる．

[VAE](Deep4.qmd) や [GAN](Deep3.qmd) と違い，１つのニューラルネットワークしか用いないため，学習が安定しやすい．

一方で，生成時には逆変換を何度も繰り返す必要があるため，計算量が大きい．これを回避するために，生成を VAE 内の潜在空間で行うものを **潜在拡散モデル** (latent diffusion model) [@Rombach+2022] という．これが [Stable Diffusion](https://ja.stability.ai/stable-diffusion) の元となっている．

### トランスフォーマーとの邂逅

[潜在拡散モデル](Deep5.qmd#sec-idea) で [U-Net](Deep.qmd#sec-U-net) [@Ronneberger+2015] を用いていたところをトランスフォーマーに置換した **拡散トランスフォーマー** (DiT: Diffusion Transformer) [@Peebles-Xie2023] が発表された．

その後，確率的補間 によって DiT を改良した SiT (Scalable Interpolant Transformer) [@Ma+2024] が発表された．

## 前向き方向符号化器

## 後ろ向き復号化器

## スコアマッチング

[@Song+2021NeurIPS]

## 誘導付き拡散モデル

## 確率微分方程式との関係

連続時間極限を取ることで，拡散過程が現れる [@Tzen-Raginsky2019], [@Song+2021ICLR]．

