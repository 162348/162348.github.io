---
title: "共に数学の機械学習への応用を志す者へ"
subtitle: "推論と変分法の双対性という観点"
author: "司馬 博文"
date: 5/10/2024
categories: [Opinion, Life]
toc: true
bibliography: 
    - ../../../mathematics.bib
    - ../../../bib.bib
csl: ../../../apa.csl
abstract-title: 概要
abstract: 共に機械学習の数学的内容を探求する同志を求む．そのため，筆者が最近つかみつつある機械学習の「数学的内容」に関する私見を共有したい．機械学習は，多くの数学的な魂をも魅了する豊かなテーマであると信じている．
---

{{< include ../../../_preamble.qmd >}}

## 機械学習の数学的内容に関する私見

確率統計学の始まりを [@Kolmogorov1933] による公理化からとするならば，まだ 100 年の歴史も持たない新しい数学分野であると言える．

それでもその数学的な内容は驚異的に豊かになった．

しかし一方で，機械学習の数学的な内容はまだ見えて来ない部分も多い．

機械学習は統計の延長線上にあると言えるかもしれないが，その源流が計算機科学にある通り，「自動化」が中心的な要素となっている．

機械学習では，データを丁寧に観察し，解析の一部始終を見守る「統計学者」は想定されず，データの処理はアルゴリズムに完全に任されることとなる．

それ故に，従来の数理統計学では考えられなかった新たな確率的過程を考慮に入れる必要がある．それが「推論の過程」である．

頻度論的なアプローチでは種々の最適化アルゴリズムが，ペイジアンアプローチではサンプリングアルゴリズムが主な推論エンジンとして用いられ，「どのアルゴリズムがどのような場合にうまくいくか」「他のアルゴリズムと比べてどうか？」が中心問題の１つとなっている．

いずれのアルゴリズムも，確率過程として極めて豊かな構造を持つ．ということはすなわち，ある測度空間 $(E,\cE)$ 上の確率測度の空間 $\cP(E)$ 上の力学系を定める．

例えば変分推論では汎函数 $\KL:\cP(E)\times\cP(E)\to[0,\infty]$ を最小化するように設計された力学系，MCMC では事後分布に収束するように設計された Markov 連鎖が $\cP(E)$ 上に押し出す力学系，などである．

筆者はここで１つの大胆な見方を提示したい．それは，この「最適化」と「サンプリング」のアルゴリズムが，互いに双対的な形で $\cP(E)$ に関わっており，その $\cP(E)$ 上の様子を捉えることで統一的な理解が待っているのではないか？という見方である．

そして，これが機械学習の数学的内容だと言いたい．

## 物理学と機械学習の双対性

![物理学・機械学習と数学の関係](Images/AppliedMath.svg)

### 物理学は

いわば統計の **順問題** を解いてきたと言える．

（平衡）統計力学は系の統計的ふるまいを記述するために，正準集団を代表としていくつかの等価なモデルを用意しており，^[主な目標が熱力学極限にあり，この極限において等価な予測を与えるモデルとして等価である，という意味である [@田崎晴明2008II p.333] など．] 場合に応じて計算しやすいものを用いるというモデル選択の立場に立っていると言える．^[[@樺島祥介2002 pp.4-5]，[@戸田+2011 p.34] など．]

系の確率的なダイナミクスを予測するために [@Metropolis+1953] や [@Glauber1963] の方法など，現在 MCMC として知られる重要なシミュレーション法が開発された．

つまり，ベイズ統計学では事後分布からの推論手法として用いられる MCMC は，物理学においては実際の系よりも高速に平衡に至るように設計された Markov ダイナミクスとして発明されたものであり，平衡分布の統計的な性質を調べようとするサンプリング法として開発されたということである．

ここにも，順問題と逆問題の双対的な使い方が見られる．

MCMC の近年の発展はこちらの記事も参照：

```{=html}
<div class="article-card-container">
  <div class="article-card">
    <a href="https://162348.github.io/posts/2024/Computation/MCMC.html" target="_blank">
      <img src="https://162348.github.io/static/Posters/ISM-OH2024.jpg" alt="Article Image" class="article-image">
      <div class="article-content">
        <h3 class="article-title">新時代の MCMC を迎えるために</h3>
        <p class="article-description">連続時間アルゴリズムへの進化</p>
      </div>
    </a>
  </div>
</div>
```

<!--

Markov 連鎖のエルゴード性の研究は，統計力学の発展と両輪であった．Markov 性はなんといってもランダムな自然現象の基本的なモデルであり，これを通じて確率的なダイナミクスを調べるという方法は強力な計算科学の手法として受け入れられた．

統計力学は順問題的である側面があり，コレを逆問題に応用したのがベイズ統計学であると捉えられる．

加えて，SDE と拡散過程は熱方程式をはじめとする PDE の幾何学的な解釈を与える．

-->

### 機械学習では，

基本的には統計的な逆問題，すなわちデータから背後の確率分布を推定する問題を解くが，特に統計的な手続きを $\cP(E)$ 上の力学系を通じて自動化しようという志向が古典的な統計学と異なる．

加えて，多くの物理学的な原理が，何かしらの汎函数の最小化問題として変分法的に理解されるのと同様，^[幾何光学における Fermat の原理から懐胎されていたアイデアであり，解析力学の最小作用の原理に代表され，同様の原理は量子力学，電磁気学など多くの分野で通用する．] 機械学習の多くのアルゴリズムは $\cP(E)$ 上の汎函数（特に KL-乖離度）の最適化問題として理解される．

ここに，$\cP(E)$ への写像を考慮する物理学と，$\cP(E)$ からの写像を考慮する機械学習の間に，基本的な立場の違いを見るのである．

### 【背景】幾何学と解析学は双対である

[Mikhael Gromov](https://en.wikipedia.org/wiki/Mikhael_Gromov_(mathematician)) によると，空間 $X$ の解析学とは $X$ **上の** 関数の研究で，$X$ の幾何学とは $X$ **への** 関数の研究である [@深谷賢治1997 p.11]．^[同講義録 [@深谷賢治1997 p.12] にて，平面幾何とは，例えば円とは $S^1\mono\R^2$ なる写像を調べるもの，$\R^2$ 上の解析とは，$f(x,y)$ などの２変数関数を調べる，という例を挙げている．]

[![Gromov による幾何と解析の解釈](../Kernels/Images/Gromov.png)](https://www.math.kyoto-u.ac.jp/~fukaya/shzuok.pdf)

## 例

以上の抽象的な議論を表にまとめると次のとおり：

| | 物理 | 機械学習 |
|:-----:|:----:|:----:|
| 数学的内容 | $\cP(E)$ 上の幾何 | $\cP(E)$ 上の解析 |
| 統計的関心 | 順問題 | 逆問題 |

: これからの統計数学 {.striped .hover .responsive-sm tbl-colwidths="[10,20,20]"}

現時点で筆者が集めている例は次のとおりである：

### SMC テンパリング

例えば，MCMC よりも多峰性に強いサンプリング法として期待されている [テンパリング SMC 法](../../Surveys/SMCSamplers.qmd)^[[@Chopin-Papaspiliopoulos20-SMC p.28] など．] は，最適化の観点からは，KL ダイバージェンスを [鏡映降下法](https://en.wikipedia.org/wiki/Mirror_descent) によって最小化した際の離散力学系と等価になると報告されている [@Chopin+2023]．