---
title: "共に数学の機械学習への応用を志す者たちへ"
subtitle: "推論と変分法の双対性という観点"
author: "司馬 博文"
date: 5/10/2024
categories: [Opinion, Life]
toc: true
bibliography: 
    - ../../../mathematics.bib
    - ../../../bib.bib
csl: ../../../apa.csl
crossref:
    sec-prefix: 節
    eq-prefix: 式
    def-prefix: 定義
    def-title: 定義
    thm-prefix: 定理
    thm-title: 定理
    fig-prefix: 図
    fig-title: 図
abstract-title: 概要
abstract: 共に機械学習の数学的内容を探求する同志を求む．そのため，筆者が最近つかみつつある機械学習の「数学的内容」に関する私見を共有したい．機械学習は，多くの数学的な魂をも魅了する豊かなテーマであると信じている．
---

{{< include ../../../_preamble.qmd >}}

## 機械学習の数学的内容に関する私見

確率統計学の始まりを [@Kolmogorov1933] による公理化からとするならば，まだ 100 年の歴史も持たない新しい数学分野であると言える．

それでもその数学的な内容は驚異的に豊かになった．

しかし一方で，機械学習の数学的な内容はまだ見えて来ない部分も多い．

機械学習は統計の延長線上にあると言えるかもしれないが，その源流が計算機科学にある通り，「自動化」が中心的な要素となっている．

機械学習では，データを丁寧に観察し，解析の一部始終を見守る「統計学者」は想定されず，データの処理はアルゴリズムに完全に任されることとなる．

それ故に，従来の数理統計学では考えられなかった新たな確率的過程を考慮に入れる必要がある．それが「推論の過程」である．

頻度論的なアプローチでは種々の最適化アルゴリズムが，ペイジアンアプローチではサンプリングアルゴリズムが主な推論エンジンとして用いられ，「どのアルゴリズムがどのような場合にうまくいくか」「他のアルゴリズムと比べてどうか？」が中心問題の１つとなっている．

いずれのアルゴリズムも，確率過程として極めて豊かな構造を持つ．ということはすなわち，ある測度空間 $(E,\cE)$ 上の確率測度の空間 $\cP(E)$ 上の力学系を定める．

例えば変分推論では汎函数 $\KL:\cP(E)\times\cP(E)\to[0,\infty]$ を最小化するように設計された力学系，MCMC では事後分布に収束するように設計された Markov 連鎖が $\cP(E)$ 上に押し出す力学系，などである．

筆者はここで１つの大胆な見方を提示したい．それは，この「最適化」と「サンプリング」のアルゴリズムが，互いに双対的な形で $\cP(E)$ に関わっており，その $\cP(E)$ 上の様子を捉えることで統一的な理解が待っているのではないか？という見方である．

そして，これが機械学習の数学的内容だと言いたい．

## 説明

## 例

例えば，MCMC よりも多峰性に強いサンプリング法として期待されている [テンパリング SMC 法](../../Surveys/SMCSamplers.qmd)^[[@Chopin-Papaspiliopoulos20-SMC p.28] など．] は，最適化の観点からは，KL ダイバージェンスを [鏡映降下法](https://en.wikipedia.org/wiki/Mirror_descent) によって最小化した際の離散力学系と等価になると報告されている [@Chopin+2023]．