---
title: "Zig-Zag サンプラーのサブサンプリングによるスケーラビリティ"
subtitle: "大規模モデル・大規模データに対する MCMC を目指して"
author: "司馬博文"
date: 7/18/2024
date-modified: 7/23/2024
categories: [MCMC, Computation, Julia]
image: MeanOfGaussian.svg
bibliography:
    - ../../../mathematics.bib
    - ../../../bib.bib
csl: ../../../apalike.csl
abstract-title: 概要
abstract: Zig-Zag サンプラーは，その非対称なダイナミクスにより，収束が速くなることが期待されている MCMC 手法である．それだけでなく，対数尤度の勾配に対する不偏推定量をサブサンプリングにより構成することで，ベイズ推論においてサンプルサイズに依らない一定のコストで効率的な事後分布からのサンプリングが可能である．
code-fold: false
execute:
    cache: true
shift-heading-level-by: -1
---

{{< include ../../../_preamble.qmd >}}

```{=html}
<div class="article-card-container">
    <div class="article-card">
        <a href="https://162348.github.io/posts/2024/Process/ZigZag.html" target="_blank">
            <img src="https://162348.github.io/posts/2024/Process/ZigZag2D_Gaussian.svg" alt="Article Image" class="article-image">
            <div class="article-content">
                <h3 class="article-title">Zig-Zag 過程によるサンプリング</h3>
                <p class="article-description">ジャンプと確定的な動きによる新たな MCMC 手法</p>
            </div>
        </a>
    </div>
</div>
```

<!-- ## Subsampling Technology -->

MCMC の計算複雑性のボトルネックは，尤度の評価にある．各ステップで全てのデータを用いて尤度を計算する必要がある点が，MCMC を深層学習などの大規模データの設定への応用を難しくしている [@Murphy2023 p.647]．

サブサンプリングが可能であることと，複数の効率的なサブサンプリング法の提案により，Zig-Zag 過程は次世代のサンプラーとして圧倒的なスケーラビリティ（Super Efficient Bayesian Inference [@Bierkens+2019]）を示すのではないかと期待されている．^[この２点が両方肝心である．効率的なサブサンプリング推定量の開発が [@Fearnhead+2018-PDMC] 以来議論の焦点になっている．]

### 対数尤度の勾配を不変推定する

$p(x)$ を事前分布，$p(y|x)$ を観測のモデル（または尤度）とし，データ $y_1,\cdots,y_n$ は互いに独立であるとする．

このとき，事後分布 $\pi(x):=p(x|y)$ と Hamiltonian $U$ は次のように表せる：
$$
\pi(x)\propt\paren{\prod_{k=1}^n p(y_k|x)}p(x)
$$
\begin{align*}
   U(x)&=-\sum_{k=1}^n\log p(y_k|x)-\log p(x)\\
   &=\frac{1}{n}\sum_{k=1}^n\Paren{-n\log p(y_k|x)-\log p(x)}=:\frac{1}{n}\sum_{k=1}^nU^k(x).
\end{align*}

このとき，$U$ の導関数 $\partial_i U(x)$ は，独立な観測 $y_1,\cdots,y_n$ について項別微分をして平均をとったものに等しい：
$$
\partial_iU(x)=\frac{1}{n}\sum_{k=1}^nE^k_i(x),
$$ {#eq-decomposition-of-DU}
$$
E^k_i(x):=\partial_iU^k(x)=\pp{}{x_i}\Paren{-n\log p(y_k|x)-\log p(x)}.
$$

よって，精度は劣るかもしれないが，一様に選んだ $K\sim\rU([n])$ から定まる $E^K_i$ の値は $\partial_i U(x)$ の不偏推定量となっている．この発想により，ZZ-SS という新たなアルゴリズムを構成できる．

### サブサンプリングを取り入れた Zig-Zag サンプラー

この各 $E^K_i$ が定める強度関数
$$
m^K_i(t):=\Paren{\theta E^K_i(x+\theta t)}_+=\Paren{\theta\partial_iU^K(x+\theta t)}_+
$$
を用いた Zig-Zag サンプラーを [@Bierkens+2019] では **ZZ-SS** (Zig-Zag with Sub-Sampling) と呼んでいる．

$$
\max_{k\in[n]}m^k_i\le M_i
$$
を満たす連続関数 $M_i$ を用いて次のようにシミュレーションすることができる：

::: {.callout-tip appearance="simple" icon="false" title="[@Bierkens+2019 p.1303 アルゴリズム３]"}

1. 代理強度関数 $M_1,\cdots,M_d$ を持つ互いに独立な $\R_+$ 上の非一様 Poisson 点過程の到着時刻 $T_1,\cdots,T_d$ をシミュレーションする．
2. 最初に到着した座標番号 $j:=\argmin_{i\in[d]}T_i$ について，確率
    $$
    \frac{m^K_j(T_j)}{M_j(T_j)},\qquad K\sim\rU([n]),
    $$
    で時刻 $T_j$ に速度成分 $\theta_j$ の符号を反転させる．
3. １に $t=T_j$ として戻って，繰り返す．

:::

::: {.callout-note title="部分サンプリングにより不変分布が変わらないことの証明^[[@Vasdekis2021 p.25] や [@Bierkens+2019 p.1302 定理4.1] も参照．]" icon="false" collapse="true"}

ZZ-SS によってシミュレートされる過程は，レート関数
$$
\lambda_i(x,\theta)=\E[(\theta E^K_i(x))_+]=\frac{1}{n}\sum_{k=1}^n(\theta E^k_i(x))_+
$$
を持った Zig-Zag 過程に等しい

これは，元々のレート関数に対して，
$$
\gamma_i(x,\theta):=\frac{1}{n}\sum_{k=1}^n(\theta_iE^k_i(x))_+-\paren{\theta_i\frac{1}{n}\sum_{k=1}^nE^k_i(x)}_+
$$
という項を加えて得る Zig-Zag サンプラーともみなすことができる．非負性は関数 $(x)_+:=x\lor0$ の凸性から従う．最後に $\gamma_i(x,\theta)=\gamma_i(x,F_i(\theta))$ を確認すれば良い．

これは
\begin{align*}
  &\qquad\frac{1}{n}\sum_{k=1}^n\Paren{\theta_iE_i^k(x)}_+-\frac{1}{n}\sum_{k=1}^n\Paren{-\theta_iE_i^k(x)}_+\\
  &=\frac{1}{n}\sum_{k=1}^n\paren{(\theta_iE_i^k(x))_+-(-\theta_iE_i^k(x))_+}=\frac{1}{n}\sum_{k=1}^n\theta_iE_i^k(x)
\end{align*}
であることから従う．

こうして，サブサンプリングの実行による精度の劣化が，[@Andrieu-Livingstone2021] の枠組みで捉えられる，ということでもある（レート関数が増加したので，スイッチングイベントが増え，diffusive な動きが増加する）．

:::

例えば $p(y_k|x)$ が Cauchy 密度であるなど $\partial_iU$ が有界であるとき，$M_i:=\max_{x\in\R^d}\partial_iU(x)$ などと選ぶことができる．$M_i$ をより $\partial_iU$ に近く選ぶほど剪定の効率は上がるが，$M_i$ を複雑にしすぎると今度は $M_i$ を強度とする Poisson 点過程のシミュレーションが困難になる．

そのため，ZZ-SS では代理レート関数 $M_i$ は大きく取る必要があり，尤度関数の評価の回数が増える．そのため，アルゴリズムの計算複雑性は上がっていることに注意 [@Bierkens+2019 p.1302 第４節]．

### 制御変数による分散低減 {#sec-ZZ-CV}

$\partial_iU(x)$ が Lipschitz 連続であるとき，$E_i^k$ をある参照点 $\partial_iU(x_*)$ とそこからの乖離と取ることで $n\to\infty$ の極限で分散が抑えられる．

こうすることで，$M_i$ を１次関数としたまま，より小さく $E_i^k$ にフィットするように取ることができる．

::: {.callout-tip title="命題" icon="false"}

任意の $i\in[d]$ について，ある $C_i>0$ が存在して，
$$
\abs{\partial_iU(x)-\partial_iU(y)}\le C_i\abs{x-y},\quad(x,y)\in\R^{2d},
$$
が成り立つとする．このとき，
$$
M_i(t):=a_i+b_it
$$
$$
a_i:=(\theta_i\partial_iU(x_*))_++C_i\norm{x-x_*}_p,\quad b_i:=C_id^{1/p}
$$
と定めれば，
$$
m_i^k\le M_i
$$
が成り立つ．ただし，
$$
\partial_iU(x)=\frac{1}{n}\sum_{k=1}^nE^k_i(x),\tag{1}
$$
$$
E^k_i(x):=\partial_iU(x_*)+\partial_iU^k(x)-\partial_iU^k(x_*),
$$
$$
m^k_i(t):=\Paren{\theta E_i^k(x+\theta t)}_+,
$$
とした．

:::

この仮定は例えば $\partial_iU$ が有界な導関数を持つならば成り立つ．$p(y_k|x)$ が Gauss 密度であるやさらに裾が重いときは成り立つ．

次のようにして参照点 $x_*$ を選ぶ事前処理を行うことで，**データのサイズに依存しない計算複雑性で事後分布からの正確なサンプリングが可能**になる．

::: {.callout-tip appearance="simple" icon="false" title="preprocessing for ZZ-CV"}

1. $x_*:=\argmin_{x\in\R^d}U(x)$ を探索する．
2. $\partial_iU(x_*),\partial_iU^k(x_*)$ を計算する．

この２つはいずれも $O(n)$ の複雑性で実行できる．

:::

### ZZ-CV のスケーリング

このとき，$x_*$ を定める事前処理が，$\wh{x}$ を最尤推定量として，
$$
\norm{x_*-\wh{x}}_p=O(n^{-1/2})\quad(n\to\infty)
$$
程度の正確性があれば，事後分布の最尤推定量周りの漸近展開 [@Johnson1970] を通じて，
$$
\norm{x-x_*}_p=O_p(n^{-1/2})\quad(n\to\infty)
$$
$$
\partial_iU(x_*)=O_p(n^{1/2})\quad(n\to\infty)
$$
が成り立つ．

::: {.callout-important collapse="true" title="Zig-Zag 過程のスケーリング^[[@Bierkens+2019 pp.1306-] 第5.1節参照．]" icon="false"}

事後分布に対する Zig-Zag 過程は，$\sqrt{n}$ だけ時間を加速したものが $\rN_d(0,i(x_0))$ を標的にする Zig-Zag 過程に収束するから，$O(n^{-1/2})$ のタイムステップで区切ってサンプルとすることができる．

しかし
$$
\max_{k\in[n]}\Paren{\theta_i\partial_iU^k(x+\theta t)}_+\le M_i
$$
を満たす $M_i$ は $O(n^{\al})\;(\al\ge1/2)$ のスケールで増大していく．

各スイッチングイベントにおいて，全データにアクセスする $O(n)$ の計算複雑性が必要であるから，総じて $O(n^{\al+1/2})$ の計算複雑性となる． 

:::

ZZ-CV が平衡に至っている場合は $x$ はほとんど $x_*$ に集積するため，
$$
\abs{E^k_i(x)}=\ABs{\partial_iU(x_*)+\partial_iU^k(x)-\partial_iU^k(x_*)}=O(n^{1/2})
$$
が成り立つ．よってこれを抑える $M_i$ も $O(n^{1/2})$ で済み，必要以上に大きい代理レート関数を用意して剪定する必要がない．

全データにアクセスする $O(n)$ のステップもないために，事前処理 [-@sec-ZZ-CV] と十分平衡に至っているとみなせるまでの burn-in を除いて，$O(1)$ の計算複雑性でサンプリングが可能である．このことを [@Bierkens+2019] は super-efficiency と呼ぶ．

::: {.callout-important title="更なるスケーラブル手法の可能性（事後分布が集中する場合のみ？）" collapse="true" icon="false"}

他に，事後分布の集中領域でうまくスイッチング回数が抑えられる $\lambda_i$ が構成できたならば，低い計算複雑性を達成できるだろう．

ZZ-CV では，これに事後分布の Gauss 近似を用いたことになる．

また，$U$ の２階微分が有界でない場合，この枠組みが使えない．実際，[@Bierkens+2019 p.1315 第6.5節] ではこの場合での数値実験の結果が示されており，事後分布が集積しないために super-efficiency は得られていない．

参照点 $x_*$ を複数取る拡張なども [@Bierkens+2019 第7節] で考えられている．

:::

### 数値実験：MSE の比較

ある Gauss 分布に従うデータを生成する：
$$
Y^j\iidsim\rN(x_0,\sigma^2),\qquad j\in[n],
$$
分散 $\sigma^2$ は既知として，位置母数 $x\in\R$ を推定する問題を考える．

事前分布を $\rN(0,\rho^2)$ とすると，定数の違いを除いて
\begin{align*}
    U(x)&=\frac{x^2}{2\rho^2}+\frac{1}{2\sigma^2}\sum_{j=1}^n(x-y^j)^2\\
    &=\frac{1}{n}\sum_{j=1}^n\paren{\frac{x^2}{2\rho^2}+\frac{n}{2\sigma^2}(x-y^j)^2}=:\frac{1}{n}\sum_{j=1}^nU^j(x)
\end{align*}
であるから，
\begin{align*}
    U'(x)&=\frac{x}{\rho^2}+\frac{1}{\sigma^2}\sum_{j=1}^n(x-y^j)\\
    &=\frac{x}{\rho^2}+\frac{n}{\sigma^2}(x-\ov{y}),
\end{align*}
$$
U''(x)=\frac{1}{\rho^2}+\frac{n}{\sigma^2}.
$$

従って，Zig-Zag 過程のイベントの強度関数は
\begin{align*}
    m(t)&=\Paren{\theta U'(x+\theta t)}_+\\
    &=\paren{\frac{\theta(x+\theta t)}{\rho^2}+\frac{\theta}{\sigma^2}\sum_{j=1}^n(x+\theta t-y^j)}_+\\
    &=\paren{\frac{\theta x}{\rho^2}+\frac{\theta}{\sigma^2}\sum_{j=1}^n(x-y^j)+t\paren{\frac{1}{\rho^2}+\frac{n}{\sigma^2}}}_+
\end{align*}
と表せ，これは１次関数 $(a+bt)_+$ の形であるから直接のシミュレーションが可能である．^[実装は `ZigZagBoomerang` パッケージの [`zigzagboom1d.jl`](https://github.com/mschauer/ZigZagBoomerang.jl/blob/master/src/zigzagboom1d.jl) を参考にした．]

```{julia}
#| code-fold: true
#| output: false
#| code-summary: サブサンプリングなしの Zig-Zag 過程のシミュレーションをする関数 ZZ() を定義
using ZigZagBoomerang
using Distributions
using Random

λ(∇U, x, θ, F::ZigZag1d) = pos(θ*∇U(x)) # rate function on E
λ_bar(τ, a, b) = pos(a + b*τ)  # affine proxy

"""
`x`: current location, `θ`: current velocity, `t`: current time,
"""
function move_forward(τ, t, x, θ, ::ZigZag1d)
    τ + t, x + θ*τ , θ
end

"""
    `∇U`: gradient of the negative log-density
    `(x,θ)`: initial state
    `T`: Time Horizon    
    `a+bt`: computational bound for intensity m(t)

    `num`: ポアソン時刻に到着した回数
    `acc`: 受容回数．`acc/num` は acceptance rate
"""
function ZZ(∇U, x::Float64, θ::Float64, T::Float64, y, Flow::ZigZagBoomerang.ContinuousDynamics; rng=Random.GLOBAL_RNG, ab=ab_ZZ)
    t = zero(T)
    Ξ = [(t, x, θ)]
    num = acc = 0
    epoch_list = [num]
    a, b = ab(x, θ, Flow)
    t′ =  t + poisson_time(a, b, rand())  # イベントは a,b が定める affine proxy に従って生成する

    while t < T
        τ = t′ - t
        t, x, θ = move_forward(τ, t, x, θ, Flow)
        l, lb = λ(∇U, x, θ, Flow), λ_bar(τ, a, b)  # λ が真のレート, λ_bar が affine proxy
        num += 1
        if rand()*lb < l
            acc += 1
            if l > lb + 0.01
                println(l-lb)
            end
            θ = -θ
            push!(Ξ, (t, x, θ))
            push!(epoch_list, num)
        end
        a, b = ab(x, θ, Flow)
        t′ = t + poisson_time(a, b, rand())
    end

    return Ξ, epoch_list, acc/num
end
```

```{julia}
#| output: false
#| code-fold: true
#| code-summary: 今回の設定に応じたレート関数 (a+bt)+ を用意
pos(x) = max(zero(x), x)  # positive part
a(x, θ, ρ, σ, y) = θ * x / ρ^2 + (θ/σ^2) * sum(x .- y)
b(x, θ, ρ, σ, y) = ρ^(-2) + length(y)/σ^2

ρ, σ, x0, θ0 = 1.0, 1.0, 1.0, 1.0
n1, n2 = 100, 10^4
TrueDistribution = Normal(x0, σ)
y1 = rand(TrueDistribution, n1)
y2 = rand(TrueDistribution, n2)

# computational bounds for intensity m(t)
ab_ZZ_n1(x, θ, ::ZigZag1d) = (a(x, θ, ρ, σ, y1), b(x, θ, ρ, σ, y1))
ab_ZZ_n2(x, θ, ::ZigZag1d) = (a(x, θ, ρ, σ, y2), b(x, θ, ρ, σ, y2))

∇U1(x) = x/ρ^2 + (length(y1)/σ^2) * (x - mean(y1)) 
∇U2(x) = x/ρ^2 + (length(y2)/σ^2) * (x - mean(y2)) 

# T = 2500.0
# trace_ZZ1, epochs_ZZ1, acc_ZZ1 = ZZ(∇U1, x0, θ0, T, ZigZag1d(); ab=ab_ZZ_n1)
# trace_ZZ2, num_ZZ2, acc_ZZ2 = ZZ(∇U2, x0, θ0, T, ZigZag1d(); ab=ab_ZZ_n2)
# dt = 0.01
# traj_ZZ1 = discretize(trace_ZZ1, ZigZag1d(), dt)
# traj_ZZ2 = discretize(trace_ZZ2, ZigZag1d(), dt)
```

```{julia}
#| output: false
#| code-fold: true
#| code-summary: N 回 ZZ() を実行して，その事後平均の MSE を計算する関数 experiment() を定義
function SquaredError(sample::Vector{Float64}, y)
    True_Posterior_Mean = sum(y) / (length(y) + 1)
    return (mean(sample) - True_Posterior_Mean)^2
end

"""
    epoch_list: 注目するエポック数のリスト
    N: 実験回数
"""
function experiment(epoch_list, T, dt, N, ∇U, x0, θ0, y, Sampler; ab=ab_ZZ_n1)
    SE_sum = zero(epoch_list)
    acc_list = []
    for _ in 1:N
        trace_ZZ1, epochs_ZZ1, acc_ZZ1 = Sampler(∇U, x0, θ0, T, y, ZigZag1d(); ab=ab)
        push!(acc_list, acc_ZZ1)
        traj_ZZ1 = discretize(trace_ZZ1, ZigZag1d(), dt)
        SE_list = []
        for T in epoch_list
            epoch = findfirst(x -> x > T, epochs_ZZ1) - 1
            t = findfirst(x -> x > trace_ZZ1[epoch][1], traj_ZZ1.t) - 1
            SE = SquaredError(traj_ZZ1.x[1:t], y)
            push!(SE_list, SE)
        end
        SE_sum += SE_list
    end
    return SE_sum ./ N, mean(acc_list)
end
```

```{julia}
#| code-fold: true
#| code-summary: 実験の実行
using Plots

T = 3000.0
epoch_list = [10.0, 100.0, 1000.0, 10000.0]
dt = 0.01
N = 10

MSE_ZZ1, acc = experiment(epoch_list, T, dt, N, ∇U1, x0, θ0, y1, ZZ; ab=ab_ZZ_n1)
p = plot(#epoch_list, MSE_ZZ1,
    xscale=:log10,
    yscale=:log10,
    xlabel="epochs",
    ylabel="MSE"
    # ,background_color = "#F0F1EB"
    )
scatter!(p, epoch_list, MSE_ZZ1,
    marker=:circle,
    markersize=5,
    markeralpha=0.6,
    color="#78C2AD",
    label=nothing
    )

using GLM, DataFrames
df = DataFrame(X = log10.(epoch_list), Y = log10.(MSE_ZZ1))
model = lm(@formula(Y ~ X), df)
X_pred = range(minimum(df.X), maximum(df.X), length=100)
Y_pred = predict(model, DataFrame(X = X_pred))
plot!(p, 10 .^ X_pred, 10 .^ Y_pred,
    line=:solid,
    linewidth=2,
    color="#78C2AD",
    label="ZZ"
    )

# display(p)

println("Average acceptance rate: $acc")
```

より，たしかに剪定なしの正確なシミュレーションができている．

一方で，
$$
U^j(x):=\frac{x^2}{2\rho^2}+\frac{n}{2\sigma^2}(x-y^j)^2,
$$
$$
\lambda^j(x,\theta):=\Paren{\theta(U^j)'(x)}_+
$$
としてサブサンプリングを取り入れることを考えるが，これを同じ $(a+bt)_+$ ではバウンド出来ない：

```{julia}
#| code-fold: true
#| code-summary: ZZ-SS (ZigZag with Subsampling) の定義
#| output: false

λj(j,x,θ,y) = pos(θ * (x/ρ^2 + length(y)/σ^2 * (x - y[j])))

function ZZ_SS(∇U, x::Float64, θ::Float64, T::Float64, y, Flow::ZigZagBoomerang.ContinuousDynamics; rng=Random.GLOBAL_RNG, ab=ab_ZZ)
    t = zero(T)
    Ξ = [(t, x, θ)]
    num = acc = 0
    epoch_list = [num]
    a, b = ab(x, θ, Flow)
    t′ =  t + poisson_time(a, b, rand())  # イベントは a,b が定める affine proxy に従って生成する

    while t < T
        τ = t′ - t
        t, x, θ = move_forward(τ, t, x, θ, Flow)
        j = rand(1:length(y))
        l, lb = λj(j, x, θ, y), λ_bar(τ, a, b)  # λ が真のレート, λ_bar が affine proxy
        num += 1
        if rand()*lb < l
            if l > lb + 0.01
                # println(l-lb)
                acc += 1  #  overflow を数えるように変更済み！注意！
            end
            θ = -θ
            push!(Ξ, (t, x, θ))
            push!(epoch_list, num)
        end
        a, b = ab(x, θ, Flow)
        t′ = t + poisson_time(a, b, rand())
    end

    return Ξ, epoch_list, acc/num
end
```

```{julia}
#| code-fold: true
#| code-summary: 実験の実行
using LaTeXStrings

MSE_ZZ_SS, acc = experiment(epoch_list, T, dt, N, ∇U1, x0, θ0, y1, ZZ_SS; ab=ab_ZZ_n1)
println(L"上界 $(a+bt)_+$ を超えてしまう平均的割合: ", "$acc")
```

しかし，ZZ-CV アルゴリズムではこのようなことは起こらない．実際，次の等式が成り立つ：
$$
U'(x_*)+(U^j)'(x)-(U^j)'(x_*)=U'(x),\qquad x,x_*\in\R.
$$

このモデルにおける MAP 推定量は
$$
\wh{x}:=\frac{\ov{y}}{1+\frac{\sigma^2}{n\rho^2}}
$$
である．

```{julia}
#| code-fold: true
#| code-summary: ZZ-CV (ZigZag with Control Variates) の定義
#| output: false

x_star = mean(y1) / (1 + σ^2/(length(y1) * ρ^2))

C(ρ, σ, y) = ρ^(-2) + length(y)/σ^2
a(x, θ, ρ, σ, y) = pos(θ*∇U1(x_star)) + C(ρ, σ, y) * abs(x - x_star)
b(x, θ, ρ, σ, y) = C(ρ, σ, y)

# New Computational Bounds for ZZ-CV
ab_ZZ_CV(x, θ, ::ZigZag1d) = (a(x, θ, ρ, σ, y1), b(x, θ, ρ, σ, y1))

function ZZ_CV(∇U, x::Float64, θ::Float64, T::Float64, y, Flow::ZigZagBoomerang.ContinuousDynamics; rng=Random.GLOBAL_RNG, ab=ab_ZZ_CV)
    t = zero(T)
    Ξ = [(t, x, θ)]
    num = acc = 0
    epoch_list = [num]
    a, b = ab(x, θ, Flow)
    t′ =  t + poisson_time(a, b, rand())  # イベントは a,b が定める affine proxy に従って生成する

    while t < T
        τ = t′ - t
        t, x, θ = move_forward(τ, t, x, θ, Flow)
        # j = rand(1:length(y))  # 今回はたまたま要らない
        l, lb =λ(∇U, x, θ, Flow), λ_bar(τ, a, b)  # λ が真のレート, λ_bar が affine proxy
        num += 1
        if rand()*lb < l
            acc += 1
            if l > lb + 0.01
                println(l-lb)
            end
            θ = -θ
            push!(Ξ, (t, x, θ))
            push!(epoch_list, num)
        end
        a, b = ab(x, θ, Flow)
        t′ = t + poisson_time(a, b, rand())
    end

    return Ξ, epoch_list, acc/num
end
```

```{julia}
#| code-fold: true
#| code-summary: 実験の実行

MSE_ZZ_CV, acc = experiment(epoch_list, T, dt, N, ∇U1, x0, θ0, y1, ZZ_CV; ab=ab_ZZ_CV)

q = scatter(p, epoch_list, MSE_ZZ_CV,
    marker=:circle,
    markersize=5,
    markeralpha=0.6,
    color="#E95420",
    label=nothing
    )

df = DataFrame(X = log10.(epoch_list), Y = log10.(MSE_ZZ_CV))
model = lm(@formula(Y ~ X), df)
X_pred = range(minimum(df.X), maximum(df.X), length=100)
Y_pred = predict(model, DataFrame(X = X_pred))
plot!(q, 10 .^ X_pred, 10 .^ Y_pred,
    line=:dash,
    linewidth=2,
    color="#E95420",
    label="ZZ-CV (without amendment)"
    )

display(q)
```

```{julia}
#| output: false
#| echo: false
# savefig(q, "MeanOfGaussian_Erronous.svg")
```

一見すると ZZ-CV が負けているように見える．しかし，点線で描いているのは，横軸が epoch であることを正しく考慮していない間違ったプロットであるためである．

[@Bierkens+2019 p.1310] において epoch とは，計算量の１単位分としており，ZZ における１回の到着時刻のシミュレーションは，ZZ-CV の $n$ 回分に当たる．これを考慮に入れてプロットし直すと次の通りになる：

```{julia}
#| code-fold: true
#| code-summary: 実験の実行
T_SuperEfficient = 300000.0
epoch_list_SuperEfficient = [1000.0, 10000.0, 100000.0, 1000000.0]

@time MSE_ZZ_CV, acc = experiment(epoch_list_SuperEfficient, T_SuperEfficient, dt, N, ∇U1, x0, θ0, y1, ZZ_CV; ab=ab_ZZ_CV)

scatter!(p, epoch_list, MSE_ZZ_CV,
    marker=:circle,
    markersize=5,
    markeralpha=0.6,
    color="#E95420",
    label=nothing
    )

df = DataFrame(X = log10.(epoch_list), Y = log10.(MSE_ZZ_CV))
model = lm(@formula(Y ~ X), df)
X_pred = range(minimum(df.X), maximum(df.X), length=100)
Y_pred = predict(model, DataFrame(X = X_pred))
plot!(p, 10 .^ X_pred, 10 .^ Y_pred,
    line=:solid,
    linewidth=2,
    color="#E95420",
    label="ZZ-CV"
    )

display(p)
```

```{julia}
#| output: false
#| echo: false
# savefig(p, "MeanOfGaussian.svg")
```

これは換言すれば横軸が「ズルい」ということでもあるが，同時に $n\to\infty$ の極限では，圧倒的に ZZ-CV が効率的になるということでもある．^[ただし，例えば今回も計算時間で言えば長くなっていることに注意．]

### 非一様な部分サンプリング

当然，必ずしも一様な分解
$$
U(x)=\frac{1}{n}\sum_{j=1}^nU^j(x)
$$
に基づいた一様なサブサンプリング $K\sim\rU([n])$ を行う必要はない．

剪定の手続きを棄却法とみると，重点サンプリングのアイデアを導入することで制御変数に依らない分散低減が狙える [@Sen+2020 importance subsampling strategy]．

特に，比例的高次元極限や，不均衡データに対する[ロジスティック回帰](../Stat/Logistic.qmd)では，事後分布が十分な集中性を持たないために制御変数の方法 [-@sec-ZZ-CV] が十分な効率改善を示さないが，この重点サブサンプリングによれば効率の改善が見込める．

詳しくは，次稿参照：

```{=html}
<div class="article-card-container">
    <div class="article-card">
        <a href="https://162348.github.io/posts/2024/Stat/Logistic2.html" target="_blank">
            <img src="https://162348.github.io/posts/2024/Stat/Logistic2.svg" alt="Article Image" class="article-image">
            <div class="article-content">
                <h3 class="article-title">大規模な不均衡データに対するロジスティック回帰（後編）</h3>
                <p class="article-description">離散時間 MCMC から連続時間 MCMC へ</p>
            </div>
        </a>
    </div>
</div>
```