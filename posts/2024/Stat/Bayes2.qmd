---
title: "ベイズ統計学とスピングラス"
subtitle: "誤り訂正符号を題材にして"
author: "司馬 博文"
date: 6/23/2024
image: posterior.svg
categories: [Bayesian, Nature, Information]
bibliography: 
    - ../../../mathematics.bib
    - ../../../bib.bib
csl: ../../../apa.csl
abstract-title: 概要
abstract: 誤り訂正符号などの情報科学的設定の下では，ベイズ推定とスピングラス系の基底状態探索に対応が存在する．特に，ベイズ最適な推定とは，西森ライン上のスピングラス系の熱力学として捉えられる．
format:
    html:
        code-fold: false
execute:
    cache: true
---

{{< include ../../../_preamble.qmd >}}

```{=html}
<div class="article-card-container">
    <div class="article-card">
        <a href="https://162348.github.io/posts/2024/Stat/Bayes1.html" target="_blank">
            <img src="https://162348.github.io/posts/2024/Stat/posterior.svg" alt="Article Image" class="article-image">
            <div class="article-content">
                <h3 class="article-title">ベイズ統計学と統計物理学</h3>
                <p class="article-description">スパース符号の復元を題材として</p>
            </div>
        </a>
    </div>
</div>
```

上掲稿で扱ったスパース符号の復元の問題をさらに押し進め，より実用的な誤り訂正符号の設定を考える．

モデルにハイパーパラメータが増え，厳密に証明できる事項は大きく減る．（逆）温度パラメータ $\beta>0$ が特定の値を取る際，厳密解が計算可能であり，これを **西森温度** と呼ぶ．^[**西森ライン** ともいう．[@Iba1999]，[@西森秀稔1999 p.55]など参照．] これは，ハイパーパラメータ $\beta>0$ が指定する分布族が，真の事後分布を含む条件と等価になる．

## 誤り訂正符号

### 線型符号 {#sec-linear-code}

有限体 $\bF_p$ 上の固定符号長 $n$ を持つ **線型符号** とは，$\bZ$-部分加群 $C\subset\bF_p^n$ のことである：
$$
a(x+y)=ax+ay\quad(a\in\bZ,x,y\in C).
$$

このクラスの符号については，Hamming 距離 $d$ の最小値
$$
\min_{\substack{x,y\in C\\ x\ne y}}d(x,y)
$$
が線型時間で計算可能であるために，誤り訂正符号の例として重宝される．

::: {.callout-caution title="例（最も単純な線型パリティ検査符号）^[[@横尾英俊2004 pp.101-102]も参照．]" collapse="true" icon="false"}

$$
C:=\Brace{\mathtt{000},\mathtt{011},\mathtt{101},\mathtt{110}}
$$
とすると，$\bF_2^3$ 上の $\bZ$-部分加群となっている．

加えて，この線型符号は次の構造を持つ：任意の符号語 $x_1x_2x_3\in C$ について，
$$
x_1+x_2\equiv x_3\mod 2.
$$
すなわち，真の符号は前半２ビット（**情報ビット**）に含まれており，最後の符号は **パリティ検査ビット** と呼ばれる．

１ビットの誤りまでなら，$x_3$ の偶奇が変わるために，誤りを検出できる．このことを，$C$ は単一パリティ検査符号であるという．

:::

### パリティ検査

::: {.callout-tip title="定義（パリティ検査方程式）" icon="false"}
$n>k\in\N$ に対して，**$(n,k)$-線型符号** とは，ある行列 $H\in M_{n,n-k}(\bF_2)$ を用いて
$$
C=\Ker H
$$
と定義される符号 $C\subset\bF_2^n$ のことをいう．このとき，$H$ を **パリティ検査行列**，符号語 $x\in C$ が満たす性質
$$
Hx=0
$$
を **パリティ検査方程式** という．
:::

::: {.callout-caution title="例（組織符号）^[[@横尾英俊2004 p.106] も参照．]" collapse="true" icon="false"}

前掲の例（第 [-@sec-linear-code] 節）のように，情報ビットと組織ビットが完全に分離している符号を **組織符号** という．

これは，ある行列 $G\in M_{k,n-k}(\bF_2)$ が存在して，白文 $u\in\bF_2^k$ に対する符号が
$$
x=(I_k\;G)^\top u
$$
と表せる場合に当たる．

このとき，パリティ検査行列 $H\in M_{n,n-k}(\bF_2)$ を
$$
H:=(G\;I_{n-k})
$$
で定めると，パリティ検査方程式が成り立つ．

実際，
$$
Hx=(G\;I_{n-k})(I_k\;G)^\top u=Ou=0.
$$

こうして定まる $H$ はパリティ検査行列の標準形ともいう．

:::

パリティ検査行列における誤り訂正では，次の逆問題を考えることになる．

::: {.callout-important appearance="simple" icon="false" title="シンドローム復号"}

対称通信路が加法的ノイズを印加するならば，受信符号 $y$ はあるベクトル $e\in\bF_2^n$ に対して
$$
y=x+e
$$
の形で表される．

すると，パリティ検査方程式より，
$$
s:=Hy=He
$$
が必要である．この値 $s$ を **シンドローム** という．

シンドロームは誤りベクトル $e$ のみの関数であるから，良い設定下では誤り $e$ を推定することができる．

:::

::: {.callout-caution title="例（低密度パリティ検査）^[[@樺島-杉浦2008 p.28] も参照．]" collapse="true" icon="false"}

一般に，パリティ検査方程式
$$
s=He
$$
から $e$ を推定する問題は計算量的に困難になる．

しかし，例えばパリティ検査行列が
$$
H=(C_1\;C_2)
$$
$$
C_1\in M_{n-k,k}(\bF_2),\quad C_2\in M_{n-k,n-k}(\bF_2)
$$
と２つの疎行列の結合として表される場合（Gallager 符号 [@Gallager1960] という），Bethe 近似による効率的な復号アルゴリズムが存在する．

:::

### Hamming 符号



### スピングラスとの類似性 {#sec-Sourlas1989}

スピングラスとの類似性を最初に指摘したのは [@Sourlas1989] であった．

現在ではこの対応は誤り訂正符号に限らず，極めて広範な統計的推定問題に渡っていることが認識されている．

実際，スピングラス理論で開発されたレプリカ法，cavity method, 信念伝搬法は盛んに統計的推定問題に応用されている [@Zdeborova-Krzakala2016]．

> Perhaps the most important message we want to pass in this review is that **many calculations that physics uses to understand the world can be translated into algorithms that machine learning uses to understand data**. [@Zdeborova-Krzakala2016 p.457]

## スピングラスと西森温度

### 設定：２点相互作用のみを考えたモデル

配置空間を $x\in\{\pm1\}^N$ とし，$N$ 個の頂点を持ったグラフ $\cG=(\cV,\cE)$ が定めるスピングラスモデル
$$
E(x,y)=-\sum_{(i,j)\in\cE}y_{ij}x_ix_j
$$
を考える．このようなモデルを [@Edwards-Anderson1975] モデルともいう．

$y_{ij}>0$ の場合 $x_i,x_j$ は揃い，$y_{ij}<0$ の場合 $x_i,x_j$ は反対方向を向く方がエネルギーが下がる．

::: {.callout-caution title="フラストレーションについて" collapse="true" icon="false"}

この系を絶対零度まで冷却した際，$(y_{ij})$ に指定された通りのルールを満たす配置 $x\in\{\om1\}^N$ があるならばその配置が出現するはずである．この場合，系はフラストレーションを持たないという．

そうでない場合でも，ファクターグラフ $(\cV,\cE,(y_{ij}))$ が定めるフラストレーションを最小にした基底状態が見つかるはずである．

なお，あるファクターグラフがフラストレーションを持たないかどうかは，クラス P に属する問題である．すなわち，多項式時間で判定可能である．^[[充足可能性問題](https://ja.wikipedia.org/wiki/%E5%85%85%E8%B6%B3%E5%8F%AF%E8%83%BD%E6%80%A7%E5%95%8F%E9%A1%8C)と違い，３項以上の相互作用を考えてもクラス P のままである．[@Mezard-Montanari2009 p.246] や [@樺島-杉浦2008] も参照．]

:::

### スピングラス系のベイズからの解釈 {#sec-teacher-student-senario}

統計的な手続きは，スピングラス系を特殊な方法で生成し，その基底状態を探る逆問題として理解できる．^[特に，信号処理などの情報科学的な設定で，この対応がつけやすい．というのも，一般の統計的な問題では，「スピングラスを生成する」部分に相当するような，データ生成過程に対する事前知識を持っていることが稀であり，モデル選択も重要なトピックに入るためである．一方で，スピングラス系と対応づけるとき，モデル選択は一般に射程には入らない．[@Zdeborova-Krzakala2016 p.456] も参照．]

具体的には，[前稿](Bayes1.qmd) で扱った通信の問題を抽象化し，次の過程を考える：

::: {.callout-tip appearance="simple" icon="false" title="planted ensemble^[こうして生成されたスピングラス系を，planted ensemble と呼び，このシナリオを機械学習の訓練過程に準えて teacher-student scenario とも呼ぶのが [@Zdeborova-Krzakala2016 p.462] の用語である．]"}

1. 配置 $x\in\{\pm1\}^N$ をある（事前）分布 $p_\al(x)$ に従って選ぶ．
2. 相互作用項 $y$ を，この $x$ が定める Boltzmann 分布 $p_\beta(y|x)$ からサンプリングする：
$$
p_\beta(y|x):=\frac{e^{-\beta E(x)}}{\cZ_\beta}
$$
$$
\cZ_\beta:=\sum_{y\in\cE}e^{-\beta E(x,y)}
$$
3. 観測者は $y$ のみを見て，$x$ がなんだったかを考える．

ただし，$\al,\beta$ はパラメータとする．

:::

すなわち，Ising スピンの配置が信号であり，ノイズが加わった観測とは，coupling $y_{ij}$ のみを見ることに対応する．

そして信号推定とは，$y_{ij}$ が定める Hamiltonian $E(x,y)$ の基底状態を探索することに他ならない．

二元対称通信路における誤り訂正符号のスピングラス的解釈（第 [-@sec-Sourlas1989] 節）はこの例の１つに過ぎない．

さらに，$x$ を一般の潜在変数とし，事前分布 $p(x)$ と確率核 $p(y|x)$ が定める確率的グラフィカルモデルは，すべてこの枠組みに収まる．

::: {.callout-caution title="比例的高次元漸近理論" collapse="true" icon="false"}

$M:=\abs{\cE}$ が観測 $y$ のサイズとなる．

従来の統計学における漸近理論では，パラメータの次元 $N$ は固定とし，$M\to\infty$ の極限での理論が展開された．

現代では，モデルのサイズも大きくする $N\to\infty$ の極限を考える需要が高まっている．

しかしこの場合でも，統計力学のツールボックスはこれを可能にする．

特に，比 $\al:=\frac{M}{N}$ を保ったまま $N,M\to\infty$ の極限を考えるスキームは **比例的高次元** と呼ばれる．

一般に，$\al$ が十分大きい場合は，モデルの複雑性に対して観測も多いので，意味のある情報が引き出せるはずであり，$\al$ が小さいほど困難になっていくはずである．

実際に，比例的高次元極限では，前稿でみた閾値現象が普遍的に生じることが知られている．これが，スピングラスの相転移に対応するのである．

:::

### 西森ライン {#sec-Nishimori-line}

前節 [-@sec-teacher-student-senario] の解釈では，観測 $y$ を経たあとの信号 $x$ の事後分布は
\begin{align*}
    p_{\al,\beta}(x|y)&\propt p_\beta(y|x)p_\al(x)\\
    &=\frac{e^{-\beta E(x,y)}p_\al(x)}{\cZ_{\al,\beta}}
\end{align*}
$$
\cZ_{\al,\beta}:=\sum_{x\in\cE}e^{-\beta E(x,y)}p_\al(x)
$$
で与えられる．

ただし，ここで，観測者の立てたモデルにおいて，パラメータ $\al,\beta$ は真の値 $\al^*,\beta^*$ とは異なり得るとする．

仮に観測者の用いたパラメータが真のパラメータと一致していた $(\al,\beta)=(\al^*,\beta^*)$ の場合，次の [西森対称性](Bayes1.qmd#sec-Nishimori-symmetry) が成り立つ：
$$
\E[f(X_1,X_2)]=\E[f(X^*,X)]
$$
この関係性を通じて，自由エネルギー（＝ KL 乖離度）をはじめとした厳密解が求まるのである．

::: {.callout-caution title="西森対称性の含意" collapse="true" icon="false"}

西森対称性を用いた厳密解は，前稿で多く紹介している：

```{=html}
<div class="article-card-container">
    <div class="article-card">
        <a href="https://162348.github.io/posts/2024/Stat/Bayes1.html" target="_blank">
            <img src="https://162348.github.io/posts/2024/Stat/posterior.svg" alt="Article Image" class="article-image">
            <div class="article-content">
                <h3 class="article-title">ベイズ統計学と統計物理学</h3>
                <p class="article-description">スパース符号の復元を題材として</p>
            </div>
        </a>
    </div>
</div>
```

一般に，事後平均推定量 $\wh{X}_n$ が平均自乗誤差を最低にするのであった：

$$
\E[(\wh{X}_n-X^*)^2]=\min_{\wh{X}_n}\E[(\wh{X}_n-X^*)^2]
$$

一般にこの値は不可知であるが，西森ライン上では＝モデルの特定が成功している場合，$\wh{X}_n$ の分散に平均的に（＝$\E$ 内で）一致することになる．

これが [命題](Bayes1.qmd#sec-MMSE-via-Nishimori)
$$
\MMSE=\E[X^2]-\E\SQuare{\brac{X}^2}
$$
の意味であるとも見れる．

:::