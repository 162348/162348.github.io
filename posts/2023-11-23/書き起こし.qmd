---
title: "Whispter APIを通じて日本語音声を書き起こす方法"
author: "Hirofumi Shiba"
date: "11/23/2023"
categories: [Lifestyle, Python]
toc: true
number-sections: true
cover: img.png
twitter-card: true
code-block-bg: true
code-block-border-left: "#31BAE9"
code-overflow: wrap
abstract-title: 概要
abstract: Whispter APIは25MBまでの音声ファイルしか書き起こししてくれないので，長時間の音声ファイルを一度に書き起こしてもらうには工夫が必要．
---

![Whispter](img.png)

## Whispterのダウンロード

まずWhisperを[OpenAIのGitHub](https://github.com/openai/whisper)からダウンロードします．

```bash
!pip install git+https://github.com/openai/whisper.git
```

さらに，内部で `ffmpeg` が必要になるので，これもダウンロードしておく必要があります．MacOSの場合は次のコマンドでインストールできます．^[それ以外のOSの場合は[こちら](https://github.com/openai/whisper)の`README.md`にやり方が書いてあります．]
```bash
brew install ffmpeg
```

ローカル環境ではなくとも，[Google Colaboratory](https://colab.research.google.com/?hl=ja)を用いてブラウザ上で実行することもできます．その場合の詳しいやり方は，[こちらのサイト](https://aismiley.co.jp/ai_news/what-is-whisper/)が参考になります．

## ファイルの分割

Whispterはどんなに大きな音声ファイルを渡しても25MB時点までしか書き起こしてくれません．そのため，ファイルを分割してWhispterに渡すこととします．次のコードは大きなファイルを分割するための関数を定義しています． `duration=240` で，何秒間でファイルを区切るかを指定します．筆者の経験上240秒（4分）がうまくいきます．

```python
import wave

def split_wav_file(filename, duration=240):
    # WAVファイルを開く
    with wave.open(filename, 'rb') as wav:
        # パラメータの取得
        n_channels, sampwidth, framerate, n_frames, comptype, compname = wav.getparams()

        # 5分間のフレーム数を計算
        frames_per_split = framerate * duration * n_channels * sampwidth

        # 全フレームを読み込み
        frames = wav.readframes(n_frames)

        # 分割してファイルに書き込む
        for i in range(0, len(frames), frames_per_split):
            # 新しいファイル名
            new_file = f'split_{i // frames_per_split}.wav'

            # 新しいファイルを書き込む
            with wave.open(new_file, 'wb') as new_wav:
                new_wav.setparams((n_channels, sampwidth, framerate, frames_per_split // (n_channels * sampwidth), comptype, compname))
                new_wav.writeframes(frames[i:i+frames_per_split])
```

こうして定義した関数を次のように用いると， `split_n.wav` という名前で，複数のファイルに分割してくれます．
```python
split_wav_file('［あなたの手元のファイル名］.wav')
```

## 書き起こし

続いて，細かく分けたファイル `split_n.wav` たちを順にWhisperに渡して書き起こしてもらい，結果を1つのテキストファイル `書き起こし.txt` にまとめてもらいます．

```python
import whisper

# モデルのロード
model = whisper.load_model("large")  # やっぱ精度が違います

# ファイルのリスト
files = [f"split_{i}.wav" for i in range(27)]  # split_0.wav から split_26.wav まで

# 結果を格納するための空の文字列
transcription = ""

# 各ファイルを順番に処理
for file in files:
    # ファイルを書き起こし
    result = model.transcribe(file, language='ja')
    transcription += result["text"] + "\n\n"

# 書き起こし結果をテキストファイルに書き込む
with open("書き起こし.txt", "w", encoding="utf-8") as text_file:
    text_file.write(transcription)

```

ここでは最大のモデル `large` を用いています．その場合，結構な時間がかかります．