---
title: "ベイズ計算とは何か | About Bayesian Computation（執筆中）"
author: "Hirofumi Shiba"
date: "12/6/2023"
categories: [Survey]
toc: true
number-sections: true
twitter-card: true
code-block-bg: true
code-block-border-left: "#31BAE9"
code-overflow: wrap
code-fold: true
bibliography: ../../mathematics.bib
csl: ../../apa.csl
---

# 「ベイズ計算」の「ベイズ」とは何者か？

## ベイズのアイデア

[Thomas Bayes](https://ja.wikipedia.org/wiki/%E3%83%88%E3%83%BC%E3%83%9E%E3%82%B9%E3%83%BB%E3%83%99%E3%82%A4%E3%82%BA) 1701-1761 は英国の牧師である．

当時は統計的推定の問題が肝要であった．その中でも，次のような「区間推定」の問題を考えていた．

{{< include ../../_preamble.qmd >}}

::: {.callout-tip icon="false" title="問題"}
2値のデータ $Y_i\in\{0,1\}$ は，ある未知の「成功率」 $\theta\in(0,1)$ に従って，確率 $\theta$ で $Y_i=1$，確率 $1-\theta$ で $Y_i=0$ となるとする．^[これはBernoulli分布 $Y_i|\theta\iidsim\Ber(\theta)$ を仮定するということである．] 仮に，$Y_i$ は性別で，$\theta$ は男児が生まれる確率だと捉えることとしよう．^[Bayes自身は「テーブル上にボールを転がしていく」という表現をしたという [@Martin+2023-history]．] このようなデータが独立に観測されて，$Y_1,\cdots,Y_n$ と得られているとする．真の成功率 $\theta$ が区間 $(a,b)\subset(0,1)$ に入っているという確率をどう見積もれば良いか？
:::

彼の発想は極めてシンプルである．

1. まず**事前分布** $p(\theta)$ と呼ばれる，最初の $\theta$ に対する予想を自由に表現する．
2. これをデータを用いて修正して，**事後分布** $p(\theta|Y_1,\cdots,Y_n)$ を得る．これは「データ $Y_1,\cdots,Y_n$ が得られた，という条件の下で考えた条件付き分布」である．
3. この事後分布の形から区間推定を実行する．

::: {.callout-note icon="false" title="[@Bayes1763] のアイデア"}
事前分布として最初の予想をすると言っても，$\theta\in(0,1)$ は全く予想がつかないとして，ここでは「どんな $\theta$ もあり得る」という意味で，$p(\theta)$ を一様分布に設定しよう：
```{python}

import matplotlib.pyplot as plt
import numpy as np

# Define the range for x-axis
x = np.linspace(0, 1, 1000)

# Uniform distribution density function is constant
y = np.ones_like(x)

# Plot the graph
plt.figure(figsize=(6, 4)) # Size suitable for a smartphone screen
plt.plot(x, y, label='Uniform Distribution (0,1)', color=(0.35, 0.71, 0.73, 1))
plt.fill_between(x, y, color=(0.35, 0.71, 0.73, 0.3))
plt.xlabel('x')
plt.ylim(0, 1.5)
plt.ylabel('Density')
plt.title('Density Function of Uniform Distribution on (0,1)')
plt.legend()
plt.grid(True)
plt.show()
```

このように，一様分布とは「どのような $\theta$ の値も同様に確からしい」という予想の表現である．しかし，データ $Y_1,\cdots,Y_n$ が得られている今，どんな $\theta$ も等しく尤もらしいという訳ではない．そこで，「データ $Y_1,\cdots,Y_n$ に関する条件付き分布」を計算することとする．実は，簡単な確率の法則から，次の公式を得ることができる：^[各 $\theta$ の下で目の前のデータ $Y_1,\cdots,Y_n$ が生成される確率 $p(Y_1,\cdots,Y_n|\theta)$ が低いということは，「その $\theta$ から生成されたデータである確率は低い」という逆の発想ができる．そこで $p(Y_1,\cdots,Y_n|\theta)$ という条件付き確率を**尤度**ともいう．]
$$
p(\theta|Y_1,\cdots,Y_n)=\frac{p(Y_1,\cdots,Y_n|\theta)p(\theta)}{\int_\Theta p(Y_1,\cdots,Y_n|\theta)p(\theta)\,d\theta}
$$ {#eq-Bayes-formula}

これを用いて，条件付き分布 $p(\theta|Y_1,\cdots,Y_n)$ を計算する．例えば[日本の2021年の出生児性別のデータ](https://www.e-stat.go.jp/dbview?sid=0003411595)を用いると次のようになる．

```{python}
import matplotlib.pyplot as plt
from scipy.stats import beta

# パラメータの設定
n = 811622
male = 415903
female = n - male

# ベータ分布のPDFを計算
x = np.linspace(0, 1, 1000)
y = beta.pdf(x, 1+male, 1+female)

# プロット
plt.figure(figsize=(6, 4))
plt.plot(x, y, label=f'Beta({1+male}, {1+female})', color=(0.35, 0.71, 0.73, 1))
plt.fill_between(x, y, color=(0.35, 0.71, 0.73, 0.3))
plt.xlabel('p')
plt.xlim(0.4, 0.6)
plt.ylabel('Probability Density')
plt.title('Bayesian Posterior Distribution')
plt.legend()
plt.grid()
plt.show()
```

こうして極めて鋭い事後分布が出来た．では区間推定の例として，$(a,b)=(0.5,1.0)$ として，「男児の方が女児よりも多い確率」を推定しよう．これは次を計算することになる：
$$
\P\Square{\frac{1}{2}<\theta<1}=\int^1_{\frac{1}{2}}p(Y_1,\cdots,Y_n|\theta)\,d\theta.
$$
```{python}
print(sum(y[500:600])/1000)
```
もはや丸め誤差により $1$ を越してしまっている．ほとんど確実に「男児の方が生まれる確率が高い」と結論づけて良いだろう．
:::

この [@Bayes1763] が実行したように，**事後確率 $p(\theta|Y_1,\cdots,Y_n)$ をみて $\theta$ に関する推論をする**，という立場からの統計的営み全体を，**ベイズ統計学**という．

## ベイズ統計学の基本問題

事後確率を導く際に用いた公式 @eq-Bayes-formula は**Bayesの公式**と呼ばれており，従ってベイズ統計学の最も肝要なパーツである．今回の場合では，Pythonコードをご覧になった方はわかったかもしれないが，
$$
p(\theta|Y_1,\cdots,Y_n)\propt\int^1_0\theta^m(1-\theta)^{n-m}
$$
となっており，これは[Beta分布](../2023-11-24/Beta-Gamma.qmd)と呼ばれるものである．**こんな簡単な設定でも，この積分が殆ど計算できないことはBayes自身もよくわかっていた**．

さらに悪いことに，現代のBayes統計学の多くの統計量は，ある関数 $g:\Theta\to\R$ を用いて
$$
\E[g(\theta)|Y_1,\cdots,Y_n]=\int_{\Theta}g(\theta)p(\theta|Y_1,\cdots,Y_n)\,d\theta
$$
と表される．ここでも積分が登場するのである．先ほどのBayesの区間推定の例では $g=1_{(a,b)}$ と取った場合に当たる．$g(\theta)=\theta^p$ と取った場合，事後積率という統計量になる．等に $p=1$ の場合が事後平均である．

そこでBayesは，$g=1_{(a,b)}$ と取った場合の積分 $\E[g(\theta)|Y_1,\dots,Y_n]$ の値を，男児の数
$$m:=\#\Brace{i\in[n]\mid Y_i=1}$$
が非常に多いか，非常に少ない場合については，被積分関数を二項展開して項別積分により計算することを提案した．しかしこの手法は明らかに今回の例では使えず（我々は男女の出生率にそこまで偏りがないことを経験的に知っている），真に興味のある場合を包含していない．この場合について，Bayesは $\E[g(\theta)|Y_1,\dots,Y_n]$ の値を上下から評価するにとどまった．

そのこともあってか，文献 [@Bayes1763] は実はBayesの死後にRichard Priceによって投稿されたものであり，生前に自ら投稿・発表した訳ではなかった．当然，発表当時は全く注目を受けなかった．

まとめると，Bayesのアプローチは非常に自然で，特に確率分布を簡単にプロットできる現代では不確実性が明確に図示できるという美点がある．しかしながら，その肝心の「事後分布の公式（Bayesの公式）」がほとんどの場合で計算不可能なのである！そこでBayesは計算法の開発を余儀なくされた．このように，**Bayes統計学は当初からBayes計算の問題を懐胎していた**のである．

実際，Bayes統計学はそのポテンシャルが評価されているだけであった期間が長く，真に日の目を見たと言えるのはここ30年のことである．