---
title: "正規標本の標本平均と標本分散が独立であることの証明"
author: "Hirofumi Shiba"
date: "11/22/2023"
categories: [Math Notes]
toc: true
number-sections: true
twitter-card:
    image: "https://162348.github.io/posts/2023-11-22/formula.png"
bibliography: bib.bib
csl: apa.csl
---

次の命題の証明を与える．

![正規標本の標本平均と標本分散との独立性](formula.png)

{{< include _preamble.qmd >}}

::: {.callout-tip icon="false" title="命題"}
正規標本 $X_i\iidsim\rN_1(\mu,\sigma^2)\;(\mu\in\R,\sigma^2>0)$ に対して，統計量を
$$\ov{X}:=\frac{1}{N+1}\sum_{i=1}^{N+1}X_i,$$
$$U^2:=\frac{1}{N}\sum_{i=1}^{N+1}(X_i-\ov{X})^2,$$
と定める．^[$U^2$ は不偏分散と呼ばれる統計量である．代わりに標本分散 $S^2:=\frac{1}{N+1}\sum_{i=1}^{N+1}(X_i-\ov{X})^2$ を考えても同様の主張 $\ov{X}\perp\!\!\!\perp S^2$ を得る．]このとき， $\ov{X}$ と $U^2$ とは独立である．
:::

なお，この性質は正規分布を特徴付ける [@Kawata-Sakamoto49]．

## Helmert変換による証明 {#sec-1}

最も直接的で，示唆も深い．
[@竹村彰道2020] 第4.3節 pp.69-70 も参照．

::: {.callout-tip icon="false" title="定義"}
次のように定まる行列 $\bH\in M_{N+1}(\R)$ を **Helmert行列** という．^[[@DelMoral-Horton2023-EnKF] も参照．]
最初の行を
$$\bH_{1,j}:=\frac{1}{\sqrt{N+1}},\qquad 1\le j\le N+1,$$
とし，それ以下の行を
$$\bH_{i,j}:=\ov{\bH}_{i,j}:=\begin{cases}
\frac{1}{\sqrt{i(i-1)}}&1\le j<i,\\
-\frac{i-1}{\sqrt{i(i-1)}}&j=i,\\
0&i<j\le N+1.
\end{cases}$$
と定める．このとき，
$$\bH=\vctr{\frac{\b{1}_{N+1}^\top}{\sqrt{N+1}}}{\ov{\bH}}$$
と表せる．^[$\b{1}_{N+1}$ は $1$ のみを成分に持つ $\R^{N+1}$ の元， $\ov{\bH}$ は行列 $\ov{\bH}:=(\ov{\bH}_{i,j})_{2\le i\le N+1,1\le i\le N+1}$ とした．]
:::

::: {.callout-tip icon="false" title="補題"}
Helmert行列 $\bH\in M_{N+1}(\R)$ とその部分行列 $\ov{\bH}\in M_{N,N+1}(\R)$ について，

1. 直交行列である．
2. 次を満たす：$$\ov{\bH}^\top\ov{\bH}=I-\frac{1}{N+1}J=\ep.$$

ただし，次のように定めた：
$$
\ep:=I_{N+1}-\frac{J_{N+1}}{N+1},\qquad J_{N+1}:=\b{1}_{N+1}\b{1}_{N+1}^\top.
$$

3. $x,y\in\R^{N+1}$ に対して， $x^\top\ep y=(x-\ov{x}\b{1}_{N+1})^\top(y-\ov{y}\b{1}_{N+1})$
:::

::: {.callout-note icon="false"}

## 証明（補題）

$\bH$ を具体的に書けば，

$$
\bH:=\begin{pmatrix}\frac{1}{\sqrt{N+1}}&\frac{1}{\sqrt{N+1}}&\frac{1}{\sqrt{N+1}}&\frac{1}{\sqrt{N+1}}&\cdots&\cdots&\frac{1}{\sqrt{N+1}}\\
\frac{1}{\sqrt{2}}&-\frac{1}{\sqrt{2}}&0&0&\cdots&\cdots&0\\
\frac{1}{\sqrt{6}}&\frac{1}{\sqrt{6}}&-\frac{2}{\sqrt{6}}&0&\cdots&\cdots&0\\
\vdots&\vdots&\vdots&\vdots&\ddots&\ddots&\vdots\\
\frac{1}{\sqrt{k(k-1)}}&\cdots&\frac{1}{\sqrt{k(k-1)}}&\frac{1-k}{\sqrt{k(k-1)}}&0&\cdots&0\\
\vdots&\ddots&\vdots&\vdots&\ddots&\ddots&\vdots\\
\frac{1}{\sqrt{N(N+1)}}&\cdots&\cdots&\cdots&\cdots&\frac{1}{\sqrt{N(N+1)}}&\frac{N}{\sqrt{N(N+1)}}
\end{pmatrix}
$$

1. 
$\bH$ の任意の行は正規化されており，異なる行の間の内積は必ず零になることはすぐに判る．よって， $\bH\bH^\top=I$．列についても同様であることが，
$$
\frac{1}{N+1}+\sum_{k=1}^N\frac{1}{k(k+1)}=1
$$
に注意すれば同様に判る．よって，

$$
\bH\bH^\top=I=\bH^\top\bH=\frac{1}{N+1}J+\ov{\bH}^\top\ov{\bH}.
$$

2. 1.の最後の等式から従う．なお，1.の最後の等式は次のように判る：

$$
\paren{\frac{\b{1}_{N+1}}{\sqrt{N+1}}\;\ov{\bH}^\top}\vctr{\frac{\b{1}_{N+1}^\top}{\sqrt{N+1}}}{\ov{\bH}}=\frac{\b{1}_{N+1}\b{1}_{N+1}^\top}{N+1}+\ov{\bH}^\top\ov{\bH}.
$$

3. $\ep=I_{N+1}-\frac{\b{1}_{N+1}\b{1}_{N+1}^\top}{N+1}$ を具体的に書けば
$$
\ep=\begin{pmatrix}
\frac{N}{N+1}&-\frac{1}{N+1}&-\frac{1}{N+1}&\cdots&-\frac{1}{N+1}\\
-\frac{1}{N+1}&\frac{N}{N+1}&-\frac{1}{N+1}&\cdots&-\frac{1}{N+1}\\
\vdots&\ddots&\ddots&\ddots&\vdots\\
-\frac{1}{N+1}&\cdots&\cdots&-\frac{1}{N+1}&\frac{N}{N+1}
\end{pmatrix}
$$

となるから，
$$
\begin{align*}
x^\top\ep y&=\frac{1}{N+1}(x_1\;\cdots\;x_{N+1})\begin{pmatrix}(N+1)y_1-\sum_{i=1}^{N+1}y_i\\\vdots\\(N+1)y_{N+1}-\sum_{i=1}^{N+1}y_i\end{pmatrix}\\
&=\frac{1}{N+1}\paren{(N+1)\sum_{i=1}^{N+1}x_iy_i-\paren{\sum_{i=1}^{N+1}x_i}\paren{\sum_{i=1}^{N+1}y_i}}\\
&=\sum_{i=1}^{N+1}x_iy_i-(N+1)\ov{x}\cdot\ov{y}\\
&=\sum_{i=1}^{N+1}(x_iy_i-\ov{x}\ov{y})\\
&=\sum_{i=1}^{N+1}(x_i-\ov{x})(y_i-\ov{y})\\
&=(x-\b{1}_{N+1}\ov{x})^\top(y-\b{1}_{N+1}\ov{y}).
\end{align*}
$$

:::

::: {.callout-note icon="false"}

## 証明

$\mu=0,\sigma^2=1$ と仮定して示せば， 一般の $X_i$ に対しても $\frac{X_i-\mu}{\sigma}\sim\rN(0,1)$ に対して同様の議論をすることで一般の場合の結果も得る．

$$X_{1:N+1}:=\begin{pmatrix}X_1\\\vdots\\X_{N+1}\end{pmatrix}\sim\rN_{N+1}(0,I_{N+1})$$

に対して， $Y_{1:N+1}:=\bH X_{1:N+1}$ と定めると， $\bH$ は直交行列だからやはり $Y\sim\rN_{N+1}(0,I_{N+1})$．加えて，$\bH$ の構成から 
$$
Y_0=\frac{\b{1}_{N+1}^\top}{\sqrt{N+1}}X_{1:N+1}=\sqrt{N+1}\cdot\ov{X}
$$
が成り立っている．

補題の2.と3.から， $Y_{2:N+1}=\ov{\bH}X_{1:N+1}$ に注意して，
$$
\begin{align*}
\norm{Y_{2:N+1}}^2&=(\ov{\bH}X_{1:N+1})^\top(\ov{\bH}X_{1:N+1})\\
&=X_{1:N+1}^\top(\ov{\bH}^\top\ov{\bH})X_{1:N+1}\\
&=X_{1:N+1}^\top\ep X_{1:N+1}=\norm{X_{1:N+1}-\ov{X}\b{1}_{N+1}}^2\\
&=\sum_{i=1}^{N+1}(X_i^2-\ov{X}^2)\\
&=\sum_{i=1}^{N+1}(X_i-\ov{X})^2=NU^2.
\end{align*}
$$

以上より， $\ov{X}$ は $Y_1$ のみの関数で， $S^2,U^2$ は $Y_{2:N+1}$ のみの関数であるから，互いに独立である．

:::

## Basuの定理による証明

::: {.callout-tip icon="false" title="[@Basu55]"}
$\{P_\theta\}_{\theta\in\Theta}$ を分布族， $(\X,\A),(\cT,\B),(\V,\cC)$ を可測空間とする．
$T:\X\to\cT$ を $\{P_\theta\}_{\theta\in\Theta}$ の完備十分統計量，統計量 $V:\X\to\V$ の分布 $P^V_\theta$ は $\theta$ に依らないとする．^[このような性質を満たす統計量 $V$ を分布族 $\{P_\theta\}_{\theta\in\Theta}$ の補助統計量という．]
このとき，任意の $\theta\in\Theta$ に対して，$T$ と $V$ は独立である：
$$P_\theta[T\in A,V\in B]=P_\theta[T\in A]P_\theta[V\in B]\qquad(A\in\B,B\in\cC,\theta\in\Theta)$$
:::

::: {.callout-note icon="false"}

## 証明（Basuの定理）

仮定より，$p_B:=P_\theta[V\in B]\in\R,q_B(T):=P_\theta[V\in B|T]:\X\to\R$ は $\theta\in\Theta$ に依らない．
これに対して，条件付き期待値の性質から
$$p_B=E_\theta[1_B(V)]=E_\theta[E_\theta[1_B(V)|T]]=E_\theta[q_B(T)]$$
であるから，$E_\theta[p_B-q_B(T)]=0$ が従う．
完備性から，$P_\theta[p_B=q_B(T)]=1$．よって，任意の $\theta\in\Theta$ について，
\begin{align*}
    P_\theta[T\in A,V\in B]&=E_\theta[1_A(T)1_B(V)]\\
    &=E_\theta[1_A(T)E_\theta[1_B(V)|T]]\\
    &=E_\theta[1_A(T)q_B(T)]\\
    &=E_\theta[1_A(T)p_B]\\
    &=E_\theta[1_A(T)]p_B\\
    &=P_\theta[T\in A]P_\theta[V\in B].
\end{align*}

:::

これを用いて，次のように証明できる．

::: {.callout-note icon="false"}

## 証明

1. 標本平均は平均の完備十分統計量である
2. 標本分散は平均の補助統計量である

の2点を示せば，Basuの定理から，標本平均と標本分散は独立である：$\ov{X}\perp\!\!\!\perp S^2$．
同様にして，標本平均と不偏分散も独立である．

1. 分布族 $\{\rN(\mu,\sigma^2)^{\otimes n}\}_{\mu\in\R}$ は指数型であり，
統計量 $$T_1(x):=\sum_{i\in[n]}x_i=n\ov{X}$$ は $\mu$ の完備十分統計量である．
1. 標本分散の分布は
$$S^2:=\frac{1}{n}\sum_{i\in[n]}(X_i-\ov{X})^2\sim\chi^2(n-1)$$
より，パラメータ$\mu\in\R$に依らない．

:::

## Fisher-Cochranの定理の考え方

総合研究大学院大学統計科学コース2021年8月実施の[入試問題](https://www.ism.ac.jp/senkou/admission/kakomon.html)の第三問にて，本命題を背景とした問題が出題された．このアプローチは @sec-1 の証明法を別の角度から見れる．^[過去9年分の入試問題の解答は[こちら](https://anomath.com/essay/tinkering/3009/)から]

::: {.callout-tip icon="false" title="補題"}
$$X_{1:n}=\begin{pmatrix}X_1\\\vdots\\X_n\end{pmatrix},\qquad X_i\iidsim\rN(\mu,\sigma^2),$$
をGauss確率ベクトル，$B\in M_{mn}(\R),A\in M_n(\R)$ を対称行列とする．$BA=O_{m,n}$ のとき，2つの確率変数 $BX_{1:n}$ と $X^\top_{1:n} AX_{1:n}$ とは独立になる．
:::

::: {.callout-note icon="false"}

## 証明（補題）

$A$ は対称行列だから，ある直交行列 $U\in \r{O}_n(\R),U^\top U=I_n$ を用いて，$U^\top DU=A$ と対角化出来る．ただし， $D:=\diag(a_1,\cdots,a_r)\in M_n(\R),r:=\rank A$ は対角行列とした．
よって，$Y_{1:n}:=UX_{1:n}$ と定めると，これは再び成分が互いに独立な正規確率変数のベクトル $Y_{1:n}\sim\rN_n(\mu U1_n,\sigma^2I_n)$ で，
$$X_{1:n}^\top AX_{1:n}=(UX_{1:n})^\top D(UX_{1:n})=a_1Y_1^2+\cdots+a_rY_r^2,$$
と表せる．

次に，$BA=0$ より，$\Im A\subset\Ker B$，従って双方の直交補空間を考えると $\Im B\subset\Ker A$ でもあるから，$BX_{1:n}$ は $y_{r+1},\cdots,y_{n}$ のみによって表せる確率変数のベクトルである（使わないものも許す）．
よって，$BX_{1:n}$ と $X_{1:n}^\top AX_{1:n}$ は独立．

:::

::: {.callout-note icon="false"}

## 証明

$m=1,B:=\frac{1}{N+1}1_{N+1}^\top$ と
$$A:=N\ep=\frac{N}{N+1}\begin{pmatrix}
N&-1&-1&\cdots&-1\\
-1&N&-1&\cdots&-1\\
\vdots&\ddots&\ddots&\ddots&\vdots\\
-1&\cdots&\cdots&-1&N
\end{pmatrix}\in M_{N+1}(\R)$$
と定めると，$BA=O$ であり，同時に $\ov{X}=BX_{1:N+1}$ かつ $U^2=X^\top_{1:N} AX_{1:N}$ である．

:::