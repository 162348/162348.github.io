---
title: "書籍紹介 Del Moral (2004) Feynman-Kac Formulae"
author: "Hirofumi Shiba"
date: "11/8/2023"
categories: [Books, Particles]
abstract-title: 概要
abstract: 1.1節"On the Origins of Feynman-Kac and Particle Models"を翻訳
toc: true
number-sections: false
---

![book cover](img.png)

## 書籍紹介 Del Moral (2004) Feynman-Kac Formulae

前文と一部の内容が[著者のHP](https://people.bordeaux.inria.fr/pierre.delmoral/gips.html)からご覧になれます．

```{=html}
<a class="embedly-card" href="https://link.springer.com/book/10.1007/978-1-4684-9393-1">Feynman-Kac Formulae</a><script async src="//cdn.embedly.com/widgets/platform.js" charset="UTF-8"></script>
```

この本はFeynman-Kac道測度とその粒子法による解釈とその各種科学分野への応用を統一的に扱った初のモノグラフ．

## 内容

### Preface

本書はFeynman-Kac path distribution, 相関粒子系，系統木モデルを扱う．生物学，物理学，確率統計学，工学，信号処理に渡る共通の話題である．21世紀に入ってやっと理論の形が見えてきたので，ここに教科書を書く．粒子法とFeynman-Kacモデル自体は，統計物理学，とりわけ気体分子運動論に起源を持つが，この本はその知識がなくても読めるようになっている．確率過程の素養がある学部生，工学・統計学・生物学・物理学の大学院生が対象読者である．

また，Feynman-Kacモデルと粒子法の漸近理論の研究に必要な数学，経験過程論，大偏差解析，半群・マルチンゲール理論，カオスの伝播，測度値過程の集中，関数不等式，エルゴード係数，Markov作用素の引き戻し，非線形半群など，の参考書になるようにも用意した．

また本書には種々のFeynman-Kac distribution flow, 相関粒子モデルの例の宝庫になっている．制限Markov連鎖シミュレーション，吸収媒体内のランダム粒子，Schrödinger作用素とFeynman-Kac半群のスペクトル解析，稀事象解析，Dirichlet境界問題，非線型フィルタリング問題，相関Kalman-Bucyフィルタ，方向つきポリマーシミュレーション，相関Metropolisアルゴリズムなど，種々のモデルの粒子近似と収束解析の例が含まれている．

これほど物理学・工学・数学にまたがるトピックを書籍化できたことに感謝しかない．本書を書いた理由は，まず第一にFeynman-Kac path modelとその粒子近似を扱う書籍は皆無だったからである．しかし同時に，この理論は現代のBayes統計学，工学，物理学，生物学で用いられるモンテカルロ法の解析に共通の土台を提供する，極めて有用な理論である．さらに，オペレータ記法に対する恐怖心さえ払拭して貰えば，非線型問題や相関粒子近似の研究に，強力な道具となること間違いなしである．



第1と12章では連続なモデルも扱っているが，離散時間のFeynman-Kacモデルに集中した．その理由は第一に，離散時間ならばMarkov過程の前提知識をほとんど用いないためである．これは本書の「なるべくself-containedな教科書を書く」という目的に合致している．第二に，連続な場合の漸近解析は，ほとんど離散の場合と同じ道を辿るからである．一方で多くのopen problemも残るが．

### Sec1.1 On the Origins of Feynman-Kac and Particle Models

::: {.callout-tip title="ポイント"}
Wienerの道積分は，量子の運動を確率測度の言葉で書いた．FeynmanはSchrödinger方程式と繋げて，ポテンシャルを与えたモデルにおいて，当該ポテンシャルが定める「確率測度の変換則」を与えた．これがFeynman-Kacの公式である．
Feynman-Kac測度は，生きたり死んだりする粒子系の見本道の分布や，一般に淘汰圧や相互作用にさらされる粒子の分布のモデリングに広く有用であることが判りつつある．
尤度，淘汰圧，相互作用が「ポテンシャル」という一つの枠組みで捉えられるのである．ポテンシャルを尤度とすると，特定の粒子に淘汰圧をかけることで，効率的に探索することに使える．
:::

Feynman-Kac公式はFeynmanの1942年の博士論文に起源を持つ．これはSchrödinger方程式とWienerの道積分とをヒューリスティックに繋いだ．この研究は1950年代のMark Kacの研究に受け継がれることになる．ポテンシャルに従って運動する量子の半群を，汎函数の道積分の言葉で記述する，というアイデアである．直感的には，Feynman-Kac測度は粒子の経路の分布に，ポテンシャルの効果を組み込むということである．

これは「ポテンシャル関数が定める確率測度の変換」であるが，この発想が多くの数理物理，確率過程の分野の研究の方向性を決定づけた．そして今日，このモデルは多くの現象のモデリングに有用であることがわかっている．例えば物理学で，吸収的で非規則的な媒質内での単一粒子の見本道の分布を記述することが出来る．このモデルでは，ポテンシャル関数というのは，「死亡／生成率」を表している．

より一般的に，物理化学における有向ポリマーなどの物理・生物学的存在のBoltzmann-Gibbs分布ともみなせる．この例では，ポテンシャル関数というのは，ハミルトニアンや，ともかく相互作用のエネルギー関数や淘汰圧に相当するものになる．さらに工学や統計学者の文脈では，ポテンシャル関数は，特定の観察過程に対する変数の条件付き確率（＝尤度）を表すことになる．この見方はフィルタリング問題やBayes解析をはじめとし，信号処理の分野で広く使われている．ともかく，ポテンシャルとは，観測過程や，参照道に対する，状態変数の尤度と同一視されるのである．

確率的粒子算譜は，Monte Carlo法の一種である．その源は，確率を頻度として捉えたBernoulliの基礎づけから見られる．そこから現代の確率論の発展に至るまでの大きな一歩は，1920年代のMarkovによる「確率過程」という対象の創出である．Markov過程という概念は，種々の工学・自然科学的対象を，自然な形でモデリングするための最適な語彙を与えた．**さらに，粒子法の，他の数値解放にない美点は，工学や自然科学が与える発展方程式に対して，「微視的な粒子解釈を与える」という点である．他にも，モデルの係数に正則性の仮定を必要としないこと，大規模モデルにも使えることなど，美点は尽きない**．^[[Feynman Lecturesの第1章第2節](https://www.feynmanlectures.caltech.edu/I_01.html#Ch1-S2)で，「現代科学最大の発見を1つ挙げるとすると原子論だ」と言っている．粒子法によるモデリングは，人間が理解しやすいモデリングの究極形の1つであるかもしれない．]さらに現在発見されつつあるもう一つの魅力として，分布の空間上で非線型方程式が数値的に解ける，という方面での応用である．これらの分布モデルの非線型な構造は，その粒子近似版のモデルに，自然な相互作用と分岐のメカニズムを課す．この近年の応用は，1960年代の流体力学と統計物理の発展に源を発する．この方面については，McKeanの開拓的仕事を参照すると良い．

この相関粒子法を工学や，とりわけ信号処理の分野に使うという応用は，さらに最近になってのことである．この方面での最初の厳密な研究は，1996年の非線型推定問題への粒子法の応用であるように思われる．この研究は，1990年台に初めて提案された新たな種の相関粒子モデルに対して，初めて厳密な収束の結果を与えた．同様の研究が4つ追随し，この種の相関粒子モデルが，大規模かつ非線型な測度値過程を数値的に解く手法として優れていることが判明した．同時期に，別の粒子分岐過程が，連続時間のフィルタリング問題を解く手法として独立に提案された．このときの手法は，現在でも非線型平滑化や道推定問題に使われている系統木粒子モデルの漸近解析に，ほとんどそのまま使えることが判明した（Del Moral and Miclo (2001) Genealogies and Increasing Propagation of Chaos for Feynman-Kac and Genetics Model）．

本書の要点を掴むために，最初の例を与える．Singer modelと呼ばれており，レーダーのモデルである．3次元のMarkov過程 $X_n=(X_n^{(1)},X_n^{(2)},X_n^{(3)})$ を考え，それぞれ加速度，速度，位置を表し，次のように発展するとする：

$$
\begin{cases}X_n^{(1)}=X_{n-1}^{(1)}+\epsilon_nW_n\\X_n^{(2)}=(1-\alpha\Delta)X_{n-1}^{(2)}+\beta\Delta X_n^{(1)}\\X_n^{(3)}=X_{n-1}^{(3)}+\Delta X_n^{(2)}\end{cases}
$$

$\Delta\in(0,1),\alpha,\beta\in\mathbb{R}$ はサンプリング頻度とパラメータとする． $\epsilon_n\in2$ はBernoulli確率変数， $W_n\sim\mathrm{U}([0,a])$ などとモデリングしよう． $X_n$ の観測は，次のように部分的になされる：

$$
Y_n=X_n^{(3)}+\Delta V_n.
$$

この状態で， $X_0,\cdots,X_n|Y_0,\cdots,X_n$ の分布を推定する問題を，非線型フィルタリング問題という．この「パスの分布」に対する粒子近似は，次のようにして与えられる．まず， $X_0$ から $N$ 個サンプリングして粒子とする： $X_0\sim X_{0}^i$．次に，始めに定めたMarkov遷移確率に従って，発展させて，見本道 $X_{t_0,t_1}^i=(X_0^i,\cdots,X_{t_i}^i)$ を得る．それぞれの見本道の尤度は

$$
W_{t_0,t_1}^i=\exp\left(-\frac{1}{2}\sum_{t_0\le p<t_1}(Y_p-X_p^{(3),i})^2\right)
$$

で与えられる．これは， $[0,1]$ の値で，与えられた見本道 $X_{t_0,t_1}^i$ が「尤もらしいか」の度合いを定量評価していると見れる．この情報を取り入れて，配置 $\{X_{t_1}^i\}_{i=1}^N$ を更新する必要があるが，そのやり方には様々ある．ここでは，現在の見本道 $\{X_{t_0,t_1}^i\}_{i=1}^N$ の中から，分布

$$
W_{t_0,t_1}^i\delta_{X_{t_0,t_1}^i}+(1-W^i_{t_0,t_1})\sum_{j=1}^N\frac{W_{t_0,t_1}^j}{\sum_{k=1}^NW_{t_0,t_1}^k}\delta_{X_{t_0,t_1}^j}
$$

でリサンプリングすることを考える．これは，尤度 $W_{t_0,t_1}^i$ の確率でその見本道は残存させ，さもなくば，尤度の重み付けに従って他の見本道で置き換えてしまう，という確率的操作を施すということである．この更新ののち，新たに心機一転 $t_1(>t_0=0)$ から開始した見本道 $X_{t_1,t_2}^i=(X_{t_1}^i,\cdots,X_{t_2}^i)$ を得て，同じ操作を繰り返す．ただし， $X_{t_1}^i\gets\widehat{X}_{t_1}^i$ として更新したものを用いる．

この操作をすると，各粒子は死亡・分岐を繰り返すように見える．同時に，遺伝的に効率的な探索を行えていることも分かる．尤度が高いところに自然に粒子が集中していくようにできているのである．

この例を見て，最も基本的な疑問は「この手法に理論的保証がつくだろうか？」という点になる． $N$ の増加に対して，収束のスピードはどう速まっていくだろうか？この手法を他の最適化やシミュレーションに応用できないか？また，この遺伝的アルゴリズムを死亡と繁殖の過程と見たとき，その系統木について何が言えるだろうか？

このような漸近解析の中心的なアイデアは，目的の条件付き分布 $Y_1,\cdots,Y_n|X_1,\cdots,X_n$ を，離散生成モデルとFeynman-Kac粒子近似モデルと関連づけることである．すると，系統木モデルの占有測度が，目的の条件付き分布 $Y_1,\cdots,Y_n|X_1,\cdots,X_n$ に収束することを示せるのである！また，現在残存している個体の祖先の系列を， $Y_1,\cdots,Y_n|X_1,\cdots,X_n$ の経路の近似的に独立なサンプルの集まりと近似的にみなせる．

この「うまくいっている個体を複製することで，状態空間を効率的に探索する」というのは，多くの確率的探索アルゴリズムの基本的な態度である．このアイデアは，どうやら1950年代の生物学での Rosenbluth の貢献と，物理学の Kahn and Harris の貢献とに端を発するようである．

一般の距離空間上のFeynman-Kacモデルと粒子法の研究は，Del Moralに20世紀の終わりから21世紀の初めにかけて行われた．この手法の応用は大きく広がっており，Doucet (2001) では多くの応用が紹介されているが，これは物理学・数学的な側面から離陸しつつあることは残念なことである．

これらの発展は全て，古典的な遺伝的アルゴリズムのトピックと深く強い関連を持つ．遺伝的アルゴリズムは Holland (1975) によって始められ，それ以降大域的最適化の数値解法に広く用いられている．このアルゴリズムの収束解析は R. Cerf によって1994年から始められ， Del Moral and Miclo (1999) On the Convergence and Applications of the Generalized Simulated Annealing で洗練された．大偏差解析と対数ソボレフ不等式を取り入れた半群の方法によって，遺伝的アルゴリズムの集中性が示された．