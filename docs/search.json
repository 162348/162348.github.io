[
  {
    "objectID": "static/Lectures.html",
    "href": "static/Lectures.html",
    "title": "Sessions",
    "section": "",
    "text": "Textbook: Quantitative Analysis of Law by Koichi Kusano 草野耕一\n\n\n数学と法学，双方からの交流と理解を図ります．\n\n開催情報\n\n\nPlace (Building, Station)\nStarting Time & Day\nFrequency\n\n\n\n\nSapia 8F, Tokyo\n18:00, Wed.\nBiweekly\n\n\n\n\n講義録\n\n\nTime\nDate\nText\nKeywords\n\n\n\n\n1\n11/22/2023\n第1章第1節\n確率の公理，確率の性質，条件付き確率\n\n\n2\n12/6/2023\n第1章第2-4節\n条件付き確率，独立性，Bayesの公式，ベイズ計算\n\n\n3\n12/20/2023\n第1章第4節-第2章第1節\nBayes更新，決定木"
  },
  {
    "objectID": "static/Lectures.html#勉強会-study-group",
    "href": "static/Lectures.html#勉強会-study-group",
    "title": "Sessions",
    "section": "",
    "text": "Textbook: Quantitative Analysis of Law by Koichi Kusano 草野耕一\n\n\n数学と法学，双方からの交流と理解を図ります．\n\n開催情報\n\n\nPlace (Building, Station)\nStarting Time & Day\nFrequency\n\n\n\n\nSapia 8F, Tokyo\n18:00, Wed.\nBiweekly\n\n\n\n\n講義録\n\n\nTime\nDate\nText\nKeywords\n\n\n\n\n1\n11/22/2023\n第1章第1節\n確率の公理，確率の性質，条件付き確率\n\n\n2\n12/6/2023\n第1章第2-4節\n条件付き確率，独立性，Bayesの公式，ベイズ計算\n\n\n3\n12/20/2023\n第1章第4節-第2章第1節\nBayes更新，決定木"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Blog by a Bayesian Computation Researcher",
    "section": "",
    "text": "粒子フィルターを用いたサンプリング\n\n\n\n\n\n\n\nParticles\n\n\nSurvey\n\n\n\n\n粒子フィルターは30年前に「万能」非線型フィルタリング手法として開発されたが，近年その真の力が明らかになりつつある．相関を持つ粒子系によって分布を逐次的に近似することで，複雑な分布からでも効率的にサンプリング出来るまたとない手法であるようだ．本稿では現在までのサンプラーとしてのSMC手法に対する理解をまとめる．\n\n\n\n\n\n\nDec 14, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\n数学記法一覧 | Notations on This Website\n\n\n\n\n\n\n\nSurvey\n\n\nMath Notes\n\n\n\n\n本サイトで用いる記法と規約をまとめる．\n\n\n\n\n\n\nDec 12, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\n粒子フィルターの実装 | Particles Package\n\n\n\n\n\n\n\nParticles\n\n\nPython\n\n\n\n\nPythonを用いて粒子フィルターを実装する方法を，Nicolas Chopinによるparticlesパッケージを参考に解説する．\n\n\n\n\n\n\nDec 11, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\nインターネットとは AS 間が BGP で相互接続された裏路地である\n\n\n\n\n\n\n\nSurvey\n\n\nDigital Nature\n\n\n\n\n\n\n\n\n\n\n\nDec 8, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\n法律家のための統計数理（2）第1章第2-4節\n\n\n\n\n\n\n\n草野数理法務\n\n\n\n\n教科書第1章第2-3節(pp.14-30)までの内容を自分たちで一から解いた．特に，第3節の内容で，Bayesの定理を自分たちの手だけで，公理のみから導出した．加えて，Bayes統計学と筆者の専門であるBayes計算の分野紹介をした．\n\n\n\n\n\n\nDec 6, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\nベイズ計算とは何か | About Bayesian Computation\n\n\n\n\n\n\n\nSurvey\n\n\nComputation\n\n\n\n\n「ベイズ統計学」は一大トピックであるが，「ベイズ計算」という分野があることはそれほど周知のことではない．しかし，ベイズ統計学は常に「計算が困難で実行が難しい」という問題と共にあってきたのであり，ここ30年のベイズ統計学の興隆は計算機の普及と効率的なベイズ計算法の発明に因る．モデル・データがいずれも大規模で複雑になっていく現代において，ベイズの枠組みも柔軟に取り入れた更なる統計計算法の発展が欠かせない．\n\n\n\n\n\n\nDec 6, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\nAbout Mental Health Issues\n\n\n\n\n\n\n\nLife\n\n\n\n\nメンタルヘルスの世界を知らざるを得なくなった人と，「自分は今後どうなるのか」という不安に苛まれている人へ．\n\n\n\n\n\n\nDec 4, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\n「有界」測度と「有限」測度 | Between ‘Bounded’ Measures and ‘Finite’ Measures\n\n\n\n\n\n\n\nFunctional Analysis\n\n\nMath Notes\n\n\n\n\nThey are the same mathematical object. Let’s step back to view the big picture.\n\n\n\n\n\n\nDec 2, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\n条件付き期待値の測度論的基礎付け\n\n\n\n\n\n\n\nProbability\n\n\nMath Notes\n\n\n\n\n\n\n\n\n\n\n\nDec 2, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\nInfluential Books Which Paved My Path into Mathematics\n\n\n\n\n\n\n\nLife\n\n\n\n\n筆者の数学を形作った書籍を編年体で紹介する．\n\n\n\n\n\n\nDec 1, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\n粒子フィルターとは何か | About Particle Filter\n\n\n\n\n\n\n\nParticles\n\n\nSurvey\n\n\n\n\n粒子フィルターは今年で誕生30周年を迎える「万能」非線型フィルタリング手法である．相関を持つ粒子系によって分布を逐次的に近似する遺伝的アルゴリズムであり，多くの科学分野にまたがる応用を持つと同時に，数理的対象としても豊かな構造を持つ．その発明の歴史と今後の研究方向を紹介する．\n\n\n\n\n\n\nNov 25, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\n確率測度の変換則 | Gamma分布とBeta分布を例に\n\n\n\n\n\n\n\nProbability\n\n\nMath Notes\n\n\n\n\n\n\n\n\n\n\n\nNov 24, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\nWhispter APIを通じて日本語音声を書き起こす方法\n\n\n\n\n\n\n\nLifestyle\n\n\nPython\n\n\n\n\nWhispter APIは25MBまでの音声ファイルしか書き起こししてくれないので，長時間の音声ファイルを一度に書き起こしてもらうには工夫が必要．\n\n\n\n\n\n\nNov 23, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\n法律家のための統計数理（1）第1章第1節\n\n\n\n\n\n\n\n草野数理法務\n\n\n\n\n教科書第1章第1節(pp.1-14)までの内容を，確率論の公理と数学の考え方を補足しながら，自分の言葉で導出しなおした．\n\n\n\n\n\n\nNov 22, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\n正規標本の標本平均と標本分散が独立であることの証明\n\n\n\n\n\n\n\nMath Notes\n\n\n\n\n\n\n\n\n\n\n\nNov 22, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\n条件付き正規分布からのシミュレーション法\n\n\n\n\n\n\n\nMath Notes\n\n\n\n\n\n\n\n\n\n\n\nNov 17, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\nMarkov Category (nLab) | 紹介\n\n\n\n\n\n\n\nCategories\n\n\nProbability\n\n\n\n\nnLabのMarkov圏のページを翻訳\n\n\n\n\n\n\nNov 11, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\nPierre Del Moral 著作まとめ\n\n\n\n\n\n\n\nSurvey\n\n\nParticles\n\n\n\n\n英語で書かれた著作と論文を一覧にしたページ\n\n\n\n\n\n\nNov 10, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\n書籍紹介 Del Moral (2013) Mean field simulation for Monte Carlo integration\n\n\n\n\n\n\n\nReview\n\n\nParticles\n\n\n\n\n前文を翻訳\n\n\n\n\n\n\nNov 9, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\n書籍紹介 Del Moral (2004) Feynman-Kac Formulae\n\n\n\n\n\n\n\nReview\n\n\nParticles\n\n\n\n\n1.1節”On the Origins of Feynman-Kac and Particle Models”を翻訳\n\n\n\n\n\n\nNov 8, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\n数学者のためのカーネル法概観\n\n\n\n\n\n\n\nKernel Methods\n\n\nMath Notes\n\n\n\n\n数学者のために，カーネル法によるデータ解析が何をやっているのかを抽象的に説明する．\n\n\n\n\n\n\nNov 7, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\n相関粒子系の社会実装\n\n\n\n\n\n\n\nParticles\n\n\nSurvey\n\n\n\n\n相関粒子系がどのように社会で活躍出来るか？という問いに対する1つの案として，「ビジネスモデルのモデル」が提示される．ここでは「状態空間モデル」の構造を人間社会に見つけることが肝要になる．\n\n\n\n\n\n\nNov 6, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\n俺の人生を変えたものTop5\n\n\n\n\n\n\n\nLifestyle\n\n\n\n\n10月以前と10月以降で過ごし方が大きく変わった その要因のうち最も大きいと思われるもの５つを紹介\n\n\n\n\n\n\nNov 5, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\nQuartoはじめて良かった | Quarto Basics in Japanese\n\n\n\n\n\n\n\nQuarto\n\n\nLifestyle\n\n\n\n\nQuartoのチュートリアル＋紹介＋おすすめポイント\n\n\n\n\n\n\nNov 4, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\n  \n\n\n\n\nSerotonin Reduction in Post-acute Sequelae of Viral Infection | ウイルスの腸管持続感染によって血中セロトニン濃度が低下する\n\n\n\n\n\n\n\nSurvey\n\n\nMedicine\n\n\n\n\n\n\n\n\n\n\n\nOct 29, 2023\n\n\nHirofumi Shiba\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-11-23/書き起こし.html",
    "href": "posts/2023-11-23/書き起こし.html",
    "title": "Whispter APIを通じて日本語音声を書き起こす方法",
    "section": "",
    "text": "Whispter"
  },
  {
    "objectID": "posts/2023-11-23/書き起こし.html#whispterのダウンロード",
    "href": "posts/2023-11-23/書き起こし.html#whispterのダウンロード",
    "title": "Whispter APIを通じて日本語音声を書き起こす方法",
    "section": "1 Whispterのダウンロード",
    "text": "1 Whispterのダウンロード\nまずWhisperをOpenAIのGitHubからダウンロードします．\n!pip install git+https://github.com/openai/whisper.git\nさらに，内部で ffmpeg が必要になるので，これもダウンロードしておく必要があります．MacOSの場合は次のコマンドでインストールできます．1\nbrew install ffmpeg\nローカル環境ではなくとも，Google Colaboratoryを用いてブラウザ上で実行することもできます．その場合の詳しいやり方は，こちらのサイトが参考になります．"
  },
  {
    "objectID": "posts/2023-11-23/書き起こし.html#ファイルの分割",
    "href": "posts/2023-11-23/書き起こし.html#ファイルの分割",
    "title": "Whispter APIを通じて日本語音声を書き起こす方法",
    "section": "2 ファイルの分割",
    "text": "2 ファイルの分割\nWhispterはどんなに大きな音声ファイルを渡しても25MB時点までしか書き起こしてくれません．そのため，ファイルを分割してWhispterに渡すこととします．次のコードは大きなファイルを分割するための関数を定義しています． duration=240 で，何秒間でファイルを区切るかを指定します．筆者の経験上240秒（4分）がうまくいきます．\nimport wave\n\ndef split_wav_file(filename, duration=240):\n    # WAVファイルを開く\n    with wave.open(filename, 'rb') as wav:\n        # パラメータの取得\n        n_channels, sampwidth, framerate, n_frames, comptype, compname = wav.getparams()\n\n        # 5分間のフレーム数を計算\n        frames_per_split = framerate * duration * n_channels * sampwidth\n\n        # 全フレームを読み込み\n        frames = wav.readframes(n_frames)\n\n        # 分割してファイルに書き込む\n        for i in range(0, len(frames), frames_per_split):\n            # 新しいファイル名\n            new_file = f'split_{i // frames_per_split}.wav'\n\n            # 新しいファイルを書き込む\n            with wave.open(new_file, 'wb') as new_wav:\n                new_wav.setparams((n_channels, sampwidth, framerate, frames_per_split // (n_channels * sampwidth), comptype, compname))\n                new_wav.writeframes(frames[i:i+frames_per_split])\nこうして定義した関数を次のように用いると， split_n.wav という名前で，複数のファイルに分割してくれます．\nsplit_wav_file('［あなたの手元のファイル名］.wav')"
  },
  {
    "objectID": "posts/2023-11-23/書き起こし.html#書き起こし",
    "href": "posts/2023-11-23/書き起こし.html#書き起こし",
    "title": "Whispter APIを通じて日本語音声を書き起こす方法",
    "section": "3 書き起こし",
    "text": "3 書き起こし\n続いて，細かく分けたファイル split_n.wav たちを順にWhisperに渡して書き起こしてもらい，結果を1つのテキストファイル 書き起こし.txt にまとめてもらいます．\nimport whisper\n\n# モデルのロード\nmodel = whisper.load_model(\"large\")  # やっぱ精度が違います\n\n# ファイルのリスト\nfiles = [f\"split_{i}.wav\" for i in range(27)]  # split_0.wav から split_26.wav まで\n\n# 結果を格納するための空の文字列\ntranscription = \"\"\n\n# 各ファイルを順番に処理\nfor file in files:\n    # ファイルを書き起こし\n    result = model.transcribe(file, language='ja')\n    transcription += result[\"text\"] + \"\\n\\n\"\n\n# 書き起こし結果をテキストファイルに書き込む\nwith open(\"書き起こし.txt\", \"w\", encoding=\"utf-8\") as text_file:\n    text_file.write(transcription)\nここでは最大のモデル large を用いています．その場合，結構な時間がかかります．"
  },
  {
    "objectID": "posts/2023-11-23/書き起こし.html#footnotes",
    "href": "posts/2023-11-23/書き起こし.html#footnotes",
    "title": "Whispter APIを通じて日本語音声を書き起こす方法",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nそれ以外のOSの場合はこちらのREADME.mdにやり方が書いてあります．↩︎"
  },
  {
    "objectID": "posts/2023-11-22/法律家のための統計数理1.html",
    "href": "posts/2023-11-22/法律家のための統計数理1.html",
    "title": "法律家のための統計数理（1）第1章第1節",
    "section": "",
    "text": "(草野耕一, 2016) の勉強会第1回の補足として，確率論の数学的枠組みを紹介する．"
  },
  {
    "objectID": "posts/2023-11-22/法律家のための統計数理1.html#今回の内容",
    "href": "posts/2023-11-22/法律家のための統計数理1.html#今回の内容",
    "title": "法律家のための統計数理（1）第1章第1節",
    "section": "1 今回の内容",
    "text": "1 今回の内容\n\n1.1 本書の概観\n本書は「数理法務」＝「法の数理分析」に関する発展的内容を扱った書籍で，内容は大きく次の1から3の3つからなる：\n\n法の行動分析：法律家がとるべき行動を数理を用いて分析する．\n法の統計分析：事実の推定や因果関係の推定に統計手法を応用する．\n法の財務分析：企業や金融に関わる法事象をファイナンス理論を用いて分析する．\n法の経済分析：法を経済学的な観点から分析する（本書では扱われていない）．\n\n第1回勉強会では第1章「行動分析(1)事実認定」を扱った．事実認定を，Bayes推論の枠組みで捉え直し，法律家として誤謬やバイアスに陥ってしまうことを避けるツールとして，確率論を導入しており，「法の数理分析は役に立つ」ことを端的に実感できる，導入として極めて鮮やかな章になっている．\n\n\n1.2 主観確率とBayes計算\nまず，第1章は，事実認定の文脈で妥当な確率概念は「主観確率」であり，今後「確率」とはこの意味で用いることを注意喚起する内容から始まる．\n主観確率と客観確率の詳細な定義は本書を参照願いたいが，一言で言えば，後者は「人間に不可知な真の値」というものの存在を前提とするのに対し，前者はそれを仮定しない．\n従って，主観確率の考え方は，より多くのものに「確率」を導入することを可能にし，より柔軟な議論が可能であるが，その分数理的な困難も増し，真に発展が進んだと言えるのは，計算機が十分に爛熟した21世紀になってのことであると言える．この統計学分野を Bayes計算 (Bayesian Computation) といい，筆者の研究分野である．\n\nThe development of computing algorithms especially suited for Bayesian analysis in the 1990s together with the exponential growth of computing resources enabled Bayesian nonparametrics to go beyond the simplest problems and made it a universally applicable paradigm for inference. (Ghosal & van der Vaart, 2017)\n\n\n\n1.3 Bayes統計学とは？\n大雑把に言って，客観確率に基づく統計手法を 頻度論的手法 (frequentist methods)，主観確率に対する統計手法を Bayes手法 (Bayesian methods)という．一般に後者は前者を包含する（前者は後者の特別な場合1）と考えられる．しかしこれは「確率の解釈」が違うのみであり，数学としては確率の定義は1つである．「確率の解釈」については，双方の立場の中でもそれぞれ複数の立場が乱立しており，ここでは立ち入らない．と言っても，この注記も教科書的なもので，実用上不便を生じる場面はほとんどないだろう．\n\n不確実性を定量化するのに、ベイズ計算では必ず『確率』を使います。一般の人から見たら、統計で確率を使うのは当たり前と思うでしょうが、じつは他の統計手法ではそうでもなく、さまざまな解釈が生まれてしまう。定量化にはすべて統一的に確率を使うベイズ計算は、非常にシンプルなので、最終的にすべての統計はベイズに行き着くしかないと思っています。 鎌谷研吾\n\n\n\n1.4 Bayes確率の基礎付けの試み……！？\n法律家による事実認定の文脈においても，「真実はいつも1つだからそれを推定したい」と考えても，「不確実な中でも，判断を誤らないようにしたい」と考えても，どちらから議論しても良いことは納得いただけるだろう．ただ，一般の人の素朴な「確率」の理解は，Bayes流のものに近いと言われている．2\nそのこともあり，本書で「主観確率の考え方を採用する」というのは，「確率の解釈の議論はここではしない」「主観的な確信度合いの意味で，現実から多少の乖離を許す」という程度の意味であろう．\nしかし，本書の「主観確率」の議論は中途半端な取り扱いでは終わらず，興味深いことに，One More Step 1-1 (pp.9-10) にて，数理哲学者Donald A. Gilliesによる主観確率の測定による基礎付けの議論が紹介されていた．筆者は初耳の議論であり，己の議論の正統性・基礎付けに細心の注意を施す法律家の心が現れていると筆者は見た．"
  },
  {
    "objectID": "posts/2023-11-22/法律家のための統計数理1.html#sec-2",
    "href": "posts/2023-11-22/法律家のための統計数理1.html#sec-2",
    "title": "法律家のための統計数理（1）第1章第1節",
    "section": "2 【深掘り】確率の公理",
    "text": "2 【深掘り】確率の公理\n\n$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$\n\n\n2.1 「確率の公理」がなぜ重要なのか？\n本書1.1節では確率の性質が列挙されている．1.2節以降では，これらの性質が「確率の定義」として引用されるが，いまいちどれを指して「定義」と呼んでいるのか定かでない．\n数学的な議論に慣れたあとはそれでも良いかも知れないが，法学も初学の間は逐一根拠条文に戻ることが大切であるように，数学もはっきりと定義を列挙し，「それのみを根拠とすること」を徹底することが大事である．\nなお，数学では何を定義として採用するかに任意性がある場合が多いが，唯一やってはいけないことは「定義が曖昧な状態で進むこと」である．そこで，せっかくであるから，現代数学が定義する最も筋の良い定義を採用して，本書の内容を俯瞰することにする．\n\n人は，確率論のもった政治的，社会的意義を忘れてはならない．理知を一切の尺度として「代数学の炉火によって倫理学及び政治学を照さん」(Condorcet) という時代精神，神の啓示に代らんとする確率論，それはフランス革命の思想的基礎に連関することを見失ってはならないのである．(北川敏男, 1949)\n\n現代数学において，確率を特徴付けるものは「代数的性質」であり，それは次の3つのみに集約される．3\n\n\n2.2 確率の公理\n\n\n\n\n\n\n定義（確率） (Kolmogorov, 1931)\n\n\n\n集合 \\(\\Omega\\) 上の確率とは，次の3条件を満たす関数 \\(P:\\mathcal{P}(\\Omega)\\to\\mathbb{R}\\) である：4\n   [P1] \\(P(\\Omega)=1\\)．\n   [P2] \\(A\\cap B=\\emptyset\\) ならば， \\[P(A\\sqcup B)=P(A)+P(B).\\]\n   [P3] 任意の事象 \\(A\\subset\\Omega\\) について， \\[0\\le P(A).\\]5\nただし，\n\n\\(P\\) の定義域 \\(\\mathcal{P}(\\Omega)\\) は「\\(\\Omega\\) の部分集合全体の集合」のことである．これを \\(\\Omega\\) の冪集合という．\n\\(A\\sqcup B\\) とは， \\(A\\cap B=\\emptyset\\) が成り立つときの \\(A,B\\) の合併 \\(A\\cup B\\) を，\\(A\\cap B=\\emptyset\\) を強調して書き分ける記法とする．\n\n\n\nこの公理から，我々が日常的な感覚から「確率に成り立っていて欲しい性質」が全て導ける，ということが現代数学の重要な発見である．性質を見ていく前に，「定義」として，主要な概念に親しみやすい名前を付ける．そのすべての過程において，上の[P1], [P2], [P3]以外を用いていないことを確認することは，数学入門の際には非常に大事な営みである．6\n\n\n\n\n\n\n確率論に関連する用語\n\n\n\n全体集合 \\(\\Omega\\) は所与のものとする．7\n\n事象 とは，部分集合 \\(A\\subset\\Omega\\) のことをいう．\n事象 \\(A\\subset\\Omega\\) の補集合\\[A^\\complement=\\Omega\\setminus A=\\overline{A}:=\\left\\{\\omega\\in\\Omega\\mid \\omega\\notin A\\right\\}\\]を \\(A\\) の余事象という．左から順に，数学で一般によく使われる記号である．8\n2つの事象 \\(A,B\\subset\\Omega\\) が 排反 であるとは，集合として共通部分を持たないことをいう： \\(A\\cap B=\\emptyset\\)．\n\n\n\nこの3性質から，本書第1.1節にいう「確率の推論法則」が全て導出できる．\n\n\n2.3 式(1.1) p.4の証明\n\n\n\n\n\n\n式(1.1) p.4\n\n\n\n任意の事象 \\(A\\subset\\Omega\\) について，\\[0\\le P(A)\\le 1.\\]9\n\n\n\n\n\n\n\n\n式(1.2) p.5\n\n\n\n任意の事象 \\(A\\subset\\Omega\\) について， \\[\nP(A)+P(A^\\complement)=1.\n\\]\n\n\n\n\n\n\n\n\n証明\n\n\n\n\\(0\\le P(A)\\) は[P3]に他ならない．式(1.2)も[P2]から従う．\\(A\\subset\\Omega\\) の補集合を \\(A^\\complement:=\\Omega\\setminus A\\) で表すと， \\(P(A^\\complement)\\ge0\\) も成り立つから， \\[\n\\begin{align*}\nP(A)&\\le P(A)+P(A^\\complement)\\\\\n&=P(A\\sqcup A^\\complement)\\\\\n&=P(\\Omega)=1.\n\\end{align*}\n\\]\n\n\n\n\n2.4 式(1.3) p.5の証明\n\n\n\n\n\n\n式(1.3) p.5\n\n\n\n任意の \\(n\\ge1\\) について， \\(n\\) 個の事象 \\(A_1,\\cdots,A_n\\subset\\Omega\\) が互いに排反であるとき， \\[\n\\begin{align*}\n&P(A_1)+P(A_2)+\\cdots+P(A_n)\\\\\n&\\qquad\\qquad=P(A_1\\sqcup A_2\\sqcup\\cdots\\sqcup A_n).\n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\n証明\n\n\n\n\\(n\\) に関する数学的帰納法による．\n\n\n\n\n2.5 式(1.4) p.6の証明\n\n\n\n\n\n\n式(1.4) p.6\n\n\n\n任意の事象 \\(A,B\\subset\\Omega\\) について， \\[\nP(A)+P(B)=P(A\\cup B)+P(A\\cap B).\n\\]\n\n\n[P2] の条件は，\\(A_1,A_2\\) が排反である場合に限定しており，その制限が邪魔であった．ここで一般の加法公式を得ることになる．\n\n\n\n\n\n\n証明\n\n\n\n\\(C:=A\\cap B\\) とおくと，3つの集合 \\(A\\setminus B,C,B\\setminus A\\) が互いに排反であることから，\n\\[\n\\begin{align*}\n&\\quad P(A)+P(B)\\\\\n&=\\biggr(P(A\\setminus B)+P(C)\\biggl)+\\biggr(P(C)+P(B\\setminus A)\\biggl)\\\\\n&=\\biggr(P(A\\setminus B)+P(C)+P(B\\setminus A)\\biggl)+P(C)\\\\\n&=P(A\\cup B)+P(A\\cap B).\n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\n\n2.6 条件付き確率の定義\n\n\n\n\n\n\n定義（条件付き確率）\n\n\n\n\\(A,B\\subset\\Omega\\) を事象とする． 事象 \\(A\\) が起こった場合の，事象 \\(B\\) の条件付き確率とは， \\[\nP(B|A):=\\begin{cases}\\frac{P(A\\cap B)}{P(A)}&P(A)\\ne0\\;\\text{のとき}\\\\0&P(A)=0\\;\\text{のとき}\\end{cases}\n\\] という値を指す．10\n\n\n\n\n2.7 式(1.7) p.7の証明\n\n\n\n\n\n\n式(1.7) p.7\n\n\n\n\\(A,B\\subset\\Omega\\) を事象，\\(P(A)&gt;0\\) とする． \\[\nP(A|B)+P(A^\\complement|B)=1.\n\\]\n\n\n\n\n\n\n\n\n証明\n\n\n\n\\[\n\\begin{align*}\n&\\quad P(A|B)+P(A^\\complement|B)\\\\\n&=\\frac{P(A\\cap B)}{P(B)}+\\frac{P(A^\\complement\\cap B)}{P(B)}\\\\\n&\\overset{\\text{[P2]}}{=}\\frac{P((A\\cap B)\\sqcup (A^\\complement\\cap B))}{P(B)}\\\\\n&=\\frac{P(B)}{P(B)}=1.\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/2023-11-22/法律家のための統計数理1.html#重要概念統計的独立性",
    "href": "posts/2023-11-22/法律家のための統計数理1.html#重要概念統計的独立性",
    "title": "法律家のための統計数理（1）第1章第1節",
    "section": "3 【重要概念】統計的独立性",
    "text": "3 【重要概念】統計的独立性\n\n3.1 定義\n\n\n\n\n\n\n定義（独立性）\n\n\n\n2つの事象 \\(A,B\\subset\\Omega\\) が独立であるとは，次を満たすことをいう： \\[\nP(A\\cap B)=P(A)P(B).\n\\] このとき， \\(A\\perp\\!\\!\\!\\perp B\\) と表す．\n\n\nこの式は本書p.7 (1.8)式に一致している．これを「積の公式」として導出しているが，これは実は独立性の定義とすべき性質である．その意味するところを次節で解説する．\n\n\n3.2 条件付き確率による特徴付け\nSection 2 で「数学では何を定義として採用するかに任意性がある場合が多い」と言った．今回の「独立性」概念も，2つの同値な定義がある．しかし，「唯一やってはいけないことは定義が曖昧な状態で進むことである」とも言った．従って，どちらか片方を定義とし，「定義ともう一つの条件が同値である」という命題が生まれることになる．\nこの形の命題のことを（数学概念の）特徴付け という．このことを解説するWikipediaページもある．\n\n\n\n\n\n\n命題（独立性の特徴付け）\n\n\n\n2つの事象 \\(A,B\\subset\\Omega\\) について，次の2条件は同値：\n\n\\(A,B\\) は独立である：\\(A\\perp\\!\\!\\!\\perp B\\)．\n\\(P(B|A)=P(B)\\)．\n\n\n\n\n\n\n\n\n\n証明\n\n\n\n\\(P[A]=0\\) の場合，任意の \\(B\\) について(1),(2)はいずれも常に成り立つ． あとは，\\(P[A]\\ne0\\)の場合を考える． すると，条件付き確率の定義 \\[P[A\\cap B]=P[A]P[B|A]\\] を考えれば，この右辺が\\(P[A]P[B]\\)に等しいことと，\\(P[B|A]=P[B]\\)であることとは同値．\n\n\n本書では2.の性質の方を定義としているが， \\(P(B|A)\\) という量は， \\(P(A)=0\\) の場合に定義に任意性が残る．従って，1.の方が定義として明瞭ということになる．\nさらに重要なことには，1.の方が一般個数の事象 \\(A_1,\\cdots,A_n\\) の場合に「独立性」の概念の拡張が可能であり，より本質的な定義だと思われる，ということが確率論の示唆である．実は，無限個の事象が独立であることも同様に定義する．\n\n\n\n\n\n\n定義（独立性）\n\n\n\n集合族 \\(\\{A_\\lambda\\}_{\\lambda\\in\\Lambda}\\subset\\mathcal{F}\\) が独立であるとは，任意の \\(n\\in\\mathbb{N}\\) 個の相異なる元 \\(A_{\\lambda_1},\\cdots,A_{\\lambda_n}\\) に対して， \\[P[A_{\\lambda_1}\\cap\\cdots\\cap A_{\\lambda_n}]=P[A_{\\lambda_1}]\\cdots P[A_{\\lambda_n}]\\] が成り立つことをいう．"
  },
  {
    "objectID": "posts/2023-11-22/法律家のための統計数理1.html#余談数学について",
    "href": "posts/2023-11-22/法律家のための統計数理1.html#余談数学について",
    "title": "法律家のための統計数理（1）第1章第1節",
    "section": "4 【余談】数学について",
    "text": "4 【余談】数学について\nここまでを読んだ読者の中で，「集合」「写像」の言葉に，定義が十分に提示されていないと感じたものがあるなら，あなたは極めて筋が良い．実は，これらの裏に全て厳密な定義があるのが数学であるが，今回は確率論に集中するために省いた．\n実際，確率論をKolmogorovによる確率の公理的な定義 (Kolmogorov, 1931) から始まる数学分野だとするならば，これはまだ100年の歴史もない，数学分野にしては極めて珍しい若い分野である．\n確率論の確率が遅れた理由は，「確率」の概念がつかみどころのない日常に根ざした概念であり，抽象化が本質的に難しいこともあるだろうが，第一に「集合」「写像」といった概念が十分に数学者の間で理解が深まるのを待つ必要があったということがある．\n現代の確率論では，「確率は測度の特別なものである」という態度をとっていることは本文中でも述べたが，この「測度」という概念の成立が，そもそもLebesgueによる積分論が確立される20世紀に入るのを待つ必要があった．"
  },
  {
    "objectID": "posts/2023-11-22/法律家のための統計数理1.html#footnotes",
    "href": "posts/2023-11-22/法律家のための統計数理1.html#footnotes",
    "title": "法律家のための統計数理（1）第1章第1節",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(McElreath, 2020) 1.3節．頻度論はさらに「仮想的な反復」(imaginary resampling of data)を想定する，という性質を除けば，不確実性が観測からくるもののみである特別な場合が頻度論であると捉えられる．↩︎\n(McElreath, 2020) 1.3節，(Rubin, 1984)．↩︎\nWikipediaページ確率の公理も参照．↩︎\n関数とは，入力と出力の集合 \\(X,Y\\) の間に定まる対応であって，任意の入力 \\(x\\in X\\) に対してただ一つの出力 \\(y\\in Y\\) が対応するもののことをいう．この対応を \\(f(x)=y\\) と表す．↩︎\n後ろの2条件[P2], [P3] のみを満たす関数 \\(P\\) は「測度」という．そのため，確率は測度でもある．数学用語では「確率分布」は「確率測度」ともいう（例えばこのwikipediaページ）．↩︎\n[P1] などの P は Probability のつもりである．↩︎\n集合にも公理があり，現代数学はZFC公理系の下で展開される．が，ここでは深入りしない．↩︎\n\\(\\lnot A\\) という記法について，\\(\\lnot\\) は論理記号であるから，集合 \\(A\\) に用いることは好ましくない．↩︎\n確率は必ず\\(0\\)から\\(1\\)の値を取る，ということを主張している命題である．初学者はこれが「示すべき内容」として提示されていることに戸惑いを覚えるだろうが，現代数学では「これが示せるような必要最小限の定義が見つかった」ことに価値を見出す．↩︎\nここでは \\(P(A)=0\\) の場合は \\(0\\) としたが，実際はどんな値でも良い．↩︎"
  },
  {
    "objectID": "posts/2023-11-4/QuartoBasics.html",
    "href": "posts/2023-11-4/QuartoBasics.html",
    "title": "Quartoはじめて良かった | Quarto Basics in Japanese",
    "section": "",
    "text": "筆者はQuartoを，「TeXにような使用感で数式・コードが併存する文章を書き，RStudioのような使用感でコードの実行やプレゼンができる，等号開発環境」と理解した． 前述のTeX, RStudioに慣れている人にとっては極めて低い限界コストで莫大な利益を得るだろう．"
  },
  {
    "objectID": "posts/2023-11-4/QuartoBasics.html#デモページ",
    "href": "posts/2023-11-4/QuartoBasics.html#デモページ",
    "title": "Quartoはじめて良かった | Quarto Basics in Japanese",
    "section": "1 デモページ",
    "text": "1 デモページ\n\n\n\n\n\n\nNote\n\n\n\nNote: The followings were pasted from the official documentation.1\n\n\nFor a demonstration of a line plot on a polar axis, see Figure 1.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 4 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "posts/2023-11-4/QuartoBasics.html#使い方の概要",
    "href": "posts/2023-11-4/QuartoBasics.html#使い方の概要",
    "title": "Quartoはじめて良かった | Quarto Basics in Japanese",
    "section": "2 使い方の概要",
    "text": "2 使い方の概要\nQuartoではこのようなNotebook-likeなドキュメントが，極めて簡単に＋凡ゆるフォーマットで作成できる． 特にVSCodeの拡張機能と組み合わせれば，RStudioのような隙のない統合開発環境が得られる．またVSCodeではビジュアルモードでの編集もサポートされており，Jupyter Notebookと全く同じ使用感で始められる．\n基本的な仕組みとして，自分で作成するのは .qmdファイルのみである．その後はquarto renderコマンドにより，コードブロックはJupyterによって処理され，全体はmarkdownに変換され，Pandocによってpdf, html, word など好きな形式に最終出力できる．\n拡張機能をオンにしたVSCodeではRun Cellボタンもあるので，ノートブック全体を毎度ビルドせずとも，コードブロックごとに実行して結果を見ることもできる．Ctrl+Enterで１行ごとに実行できる操作感はRStudioと同じである．\n各ファイルの冒頭にYAML blockを用意することで，ノートブックの詳細を調整できる（参照：HTML Options）．\n---\ntitle: \"Quarto Basics\"\nformat:\n  html:\n    code-fold: true\njupyter: python3\n---\n本文はmarkdown記法で書く．数式も使える： \\[\\mathrm{P}[|\\xi|&lt;t]\\le2e^{-\\frac{t^2}{2\\sigma^2}},\\qquad t&gt;0.\\]\nまた，コードブロックにもコメントアウトと接頭辞の組み合わせ#|を前につけることでYAMLで指示が出せる（参照：指示のリスト）．上のコードブロックには\n#| label: fig-polar\n#| fig-cap: \"A line plot on a polar axis\"\nと追加されているために，出力された図にラベリングとキャプションが付いているのである．"
  },
  {
    "objectID": "posts/2023-11-4/QuartoBasics.html#美点",
    "href": "posts/2023-11-4/QuartoBasics.html#美点",
    "title": "Quartoはじめて良かった | Quarto Basics in Japanese",
    "section": "3 美点",
    "text": "3 美点\n\nレンダリングがとんでもなく速い．体感でTeXの10分の1である．\nそれでいて数式とコードブロックを併在させることが出来る．なお，明かにTeXを意識していることがわかる使用感になっているし，本の作成も可能としている．\nローカル環境で動く．Jupyter Notebookが続かない筆者にとって，この点は肝要である．\n私用の勉強ノートとしても使えると同時に，内容そのままブログとして公開できる．\nプレゼンテーションにも使える．\nすごい細かいが，例えばproject typeをwebsiteとしたリポジトリでquarto renderをしても，不要なファイルが自動で削除される．このような点がライトユーザーでもとにかく使いやすい．\nさらにインタラクティブな機能を実現してみたい．"
  },
  {
    "objectID": "posts/2023-11-4/QuartoBasics.html#website-hostingのやり方",
    "href": "posts/2023-11-4/QuartoBasics.html#website-hostingのやり方",
    "title": "Quartoはじめて良かった | Quarto Basics in Japanese",
    "section": "4 Website Hostingのやり方",
    "text": "4 Website Hostingのやり方\n公式Guideを参考．\n\n4.1 Source Branchをmainと別ける\nまずgh-pagesという全く新しいブランチを作成する．既存のリポジトリのコミット履歴とは独立している新しいブランチを作るときは--orphanオプションが利用される．\n\n\nTerminal\n\ngit checkout --orphan gh-pages\ngit reset --hard # make sure all changes are committed before running this!\ngit commit --allow-empty -m \"Initialising gh-pages branch\"\ngit push origin gh-pages\ngit checkout main\n\n基本gh-pagesブランチには自分では立ち入らない．\n\n\n4.2 Publishコマンドによるサイトの公開\nmainブランチにいることを確認して，\n\n\nTerminal\n\nquarto publish gh-pages\n\nを実行．\nGitHubの方の設定Settings: Pagesで，Sourceをgh-pagesブランチの/(root)にしていることを確認すれば，これで無事サイトが公開されていることが確認できる．\n\n\n4.3 GitHub Actionの使用\nさらに，ローカル上でrenderするのではなく，コミットする度にGitHub上でレンダリングしてもらえるように自動化することもできる．こうするとスマホからも自分のサイトが更新できる．\nまず，GitHubの設定のActionsセクションのWorkflow permissionsから，読み書きの権限をGitHub Actionに付与する．\n続いて，次の内容のファイルを.github/workflows/publish.ymlに書き込む：\n\n\n.github/workflows/publish.yml\n\non:\n  workflow_dispatch:\n  push:\n    branches: main\n\nname: Quarto Publish\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v4\n\n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n\n      - name: Render and Publish\n        uses: quarto-dev/quarto-actions/publish@v2\n        with:\n          target: gh-pages\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\nこれで，mainブランチにコミットする度に，GitHub上でrenderが実行されることとなる．"
  },
  {
    "objectID": "posts/2023-11-4/QuartoBasics.html#footnotes",
    "href": "posts/2023-11-4/QuartoBasics.html#footnotes",
    "title": "Quartoはじめて良かった | Quarto Basics in Japanese",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is footnote. What a great feature!↩︎"
  },
  {
    "objectID": "posts/2023-12-4/MentalHealth.html",
    "href": "posts/2023-12-4/MentalHealth.html",
    "title": "About Mental Health Issues",
    "section": "",
    "text": "メンタルヘルスを損なってしまったとき，「もう二度と以前の状態には戻れないのではないか」という絶望が最初に付きまとうと思う．結論から言うと，絶対戻れる．だが，今じゃない．\nそもそも，メンタルヘルスの問題は「病気」と「健常」の境界が曖昧になってしまったと感じるだろう．治ったと思ったら治っていなくて，「一体いつまで続くのだろう」「以前は『正常』だと思っていた状態に，二度と戻れないのではないか？」という反芻思考が心を襲うだろう．\nそれは当然である．あなたはまだ治っていない．そもそも普通の風邪だって，「病気」と「健常」の境界など無いに等しい．熱があると社会は許してくれるが，熱とはそもそもウイルス・病原菌の感染から身体を守るための「正常な」反応である．身体に標準に組み込まれた防衛機制の想定された挙動の範囲内である．風邪は感染の可能性もあるから社会の方から休養を許してくれるのである．\nメンタルヘルスの問題だって，（一定範囲では）身体の正常な反応である．だが，あなたは休養を取っただろうか？社会は多くの場合理解を示さない．その中で自分の身体を守る対策を毅然と断行しただろうか？1 もし，休み休み前に進むことが出来る環境だったならば，あなたはメンタルヘルスに悩んでいなかっただろうし，「正常」と「異常」の境界にも悩んでいなかっただろう．食事が喉を通らない，眠れない，些細な刺激が絶大なストレスになる，胃を痛める，これらの反応は適度な休養が取れていて心に弾力がある状態ならば，「大変な時期もあったが，それを乗り越えて，私は大きく成功できた」という美談で終われる「正常」な心の反応である．風邪も流行感冒もそうだろう．だが，休まないまま通ろうとすると，本当に「異常」になる．風邪を治さずに活動し続けて，拗らせた経験はあるか？インフルになっても普段の生活を続けたことはあるか？あなたはそれをやろうとしていたのである．身体が想定外の挙動を起こしがちになるのも仕方ないというものである．\nだから，あなたはそもそも治っていないのである．風邪の原因はウイルスであり，あなたは休養をして免疫機構に対処してもらう，そうして来ただろう．一方で心の病の原因は，人間関係と期待，社会的なプレッシャーがある立場，休養を許さないストレスフルな環境，あなたの場合はどれに該当するかわからないが，ほとんどの場合すぐには休養が取れない．だからこそあなたはメンタルヘルスを病んでいるのだろう．つまり，普段通りだと思っているあなたの心の風邪はまだ絶賛発熱中である．それどころか，何ヶ月も発熱したままである．早い段階で自分の免疫に治してもらわなければ，薬などの外部からの補助が必要になる（それでも治るが）．\n「一体いつまで続くのだろう？」「もう二度と正常の状態に戻れないのではないか？」という不安が的外れであることがわかっていただけただろうか？まずはストレスの原因がない状態に生活を持っていき，心の免疫が働く状態を整えよう．これには時間がかかるだろう．信頼できる人以外との関係を一度整理する必要があるし，ほとんどの場合金策の問題ですぐには十分に休めないかもしれない．さらに悪いことに「ストレスのない状態に生活を変える」こと自体が，あなたのアイデンティティの死を意味するかも知れない．だからあなたはボロボロになってこれ以上前に進めなくなるまで頑張ってしまったのだろう．だが，メンタルヘルスに変調をきたしてしまった場合，そのアイデンティティは少し修正せざるを得ない．ここはどうしても残酷な部分であるが，仕方のないことである．だが，考えてみてほしい．身体を強く病んでしまった人で，ここに深く絶望する人は少ない．\nストレスの原因のない状態に持っていってから，それでも治らないならばしっかり専門家に頼り，通院して服薬をすれば，絶対に治るし，元の「正常」な状態に戻る．そのときには，あなたは「正常」と「病気」との区別について，より深い理解を得ていることだろう．私がそうだった．"
  },
  {
    "objectID": "posts/2023-12-4/MentalHealth.html#本当にあなたの運が良かっただけではと思う人へ",
    "href": "posts/2023-12-4/MentalHealth.html#本当にあなたの運が良かっただけではと思う人へ",
    "title": "About Mental Health Issues",
    "section": "本当に？あなたの運が良かっただけでは？と思う人へ",
    "text": "本当に？あなたの運が良かっただけでは？と思う人へ\n「もう二度と治らないのだ」「脳の構造が変わってしまう」などと言う体験者の言葉は意外と多い．だが，これは「自分はメンタルヘルスの大きな病を抱えており，休養が必要である」ということを周囲に理解してもらうには多少荒技が必要であった人が，自身の休養を守るために使う表現としてもよく使われることに注意していただきたい．メンタルヘルスの病は，「一刻も早く治したい」と思っている人が全てではないことに注意する必要がある．彼らの言動に，あなたが傷ついたり，絶望する必要はない．治したいと思っているならば，専門家に相談すれば治る．度合いによってかかる時間は変わるかもしれないが，あなたが満足のいくレベルまで，治る．今すぐクリニックを検索して予約の電話を入れよう．良いクリニックなら1ヶ月前後待つことになるから，とりあえず予約だけして後からそれで良かったのか考えれば良い．運悪く，合うクリニックがすぐには見つからない可能性もあるが，とにかくトライし続けるのだ．正しい手を掴めば絶対に治るから．"
  },
  {
    "objectID": "posts/2023-12-4/MentalHealth.html#footnotes",
    "href": "posts/2023-12-4/MentalHealth.html#footnotes",
    "title": "About Mental Health Issues",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n当然，「メンタルヘルスは自分で守らなきゃいけない」という自衛に頼った構造になっている現代社会は，少しずつ変わっていくし，変わるべきだろう．だがいつの時代も自衛は大事だ．↩︎"
  },
  {
    "objectID": "posts/2023-12-2/BoundedMeasure.html",
    "href": "posts/2023-12-2/BoundedMeasure.html",
    "title": "「有界」測度と「有限」測度 | Between ‘Bounded’ Measures and ‘Finite’ Measures",
    "section": "",
    "text": "$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$"
  },
  {
    "objectID": "posts/2023-12-2/BoundedMeasure.html#sec-1",
    "href": "posts/2023-12-2/BoundedMeasure.html#sec-1",
    "title": "「有界」測度と「有限」測度 | Between ‘Bounded’ Measures and ‘Finite’ Measures",
    "section": "1 Jordan分解からの理解",
    "text": "1 Jordan分解からの理解\nJordan分解より，符号付き測度 \\(\\mu:\\Sigma\\to[-\\infty,\\infty]\\) が関数として有界であることと，全変動が有限（＝\\(\\mathbb{R}\\)-値）になること（有界変動であること）とは同値になる．\n\n\n\n\n\n\n定理（Hahn分解）\n\n\n\n\\((S,\\Sigma)\\) を可測空間，\\(\\mu:\\Sigma\\to[-\\infty,\\infty]\\) を符号付き測度とする．このとき，ある可測集合 \\(E_0\\in\\Sigma\\) が存在して，\\(\\mu:E_0\\cap\\Sigma\\to[0,\\infty]\\) は非負で，\\(\\mu:E_0^\\complement\\cap\\Sigma\\to[-\\infty,0]\\) は非正である．\n\n\n証明は (藤田宏，吉田耕作, 1991) はHahn分解を先に，Jordan分解を後に与えている．一方で (Dunford & Schwartz, 1958) は有限加法的測度のJordan分解を先に与えている．\n\n\n\n\n\n\n系（Jordan分解）\n\n\n\n\\((S,\\Sigma)\\) を可測空間，\\(\\mu:\\Sigma\\to[-\\infty,\\infty]\\) を符号付き測度とする．このとき， \\[\n\\mu^+(E):=\\mu(E_0\\cap E),\n\\] \\[\n\\mu^-(E):=-\\mu(E_0^\\complement\\cap E)\n\\] はHahn分解 \\(E_0\\in\\Sigma\\) の取り方に依らずに定まる測度となる．\n\n\n\n系2 (Hahn) \\(\\Phi(E)\\) が最大値 \\(+\\infty\\) をとれば，\\(\\Phi(E)\\) の最小値は \\(&gt;-\\infty\\)．また \\(\\Phi(E)\\) が最小値 \\(-\\infty\\) をとれば \\(\\Phi(E)\\) の最大値は \\(&lt;+\\infty\\)．とくに \\(\\Phi(E)\\) が有限であるならば（すなわち有限値しかとらないならば），\\(\\Phi\\) の値域 \\(\\{\\Phi(E)\\mid E\\in\\mathcal{M}\\}\\) は有界である．(藤田宏，吉田耕作, 1991, p. 389)"
  },
  {
    "objectID": "posts/2023-12-2/BoundedMeasure.html#直接の証明",
    "href": "posts/2023-12-2/BoundedMeasure.html#直接の証明",
    "title": "「有界」測度と「有限」測度 | Between ‘Bounded’ Measures and ‘Finite’ Measures",
    "section": "2 直接の証明",
    "text": "2 直接の証明\n\n\n\n\n\n\n命題（有限ならば有界）\n\n\n\n\\((S,\\Sigma)\\) を可測空間，\\(\\mu:\\Sigma\\to[-\\infty,\\infty)\\) を \\(\\sigma\\)-加法的な集合関数とする．このとき，\\(\\mu\\) は上に有界である．\n\n\n\n\n\n\n\n\n証明\n\n\n\n4 仮に \\(\\mu\\) は上に有界ではないと仮定して，矛盾を導く．可測集合 \\(E_1\\in\\Sigma\\) が非有界集合であるとは， \\[\\sup_{E\\in\\Sigma}\\mu(E\\cap E_1)=+\\infty\\] が成り立つこととすると，仮定より，少なくとも全体集合 \\(S\\) は非有界である．ここで，\n\n任意の非有界集合は，任意に大きな測度を持つ非有界部分集合を持つ．\nある非有界集合 \\(F\\in\\Sigma\\) が存在して，ある \\(N\\in\\mathbb{N}\\) よりも大きな測度を持つ \\(F\\) の非有界部分集合は存在しない．\n\nの２つの場合に分けられる．\n\nこのとき，減少列 \\(\\{E_n\\}\\subset\\Sigma\\) であって \\(\\mu(E_n)\\ge n\\;(n\\in\\mathbb{N}^+)\\) を満たすものが取れる．このとき，\\(\\sigma\\)-加法性から \\[\\mu\\left(\\bigcap_{i=1}^\\infty E_i\\right)+\\sum_{i=n}^\\infty\\mu(E_i\\setminus E_{i+1})=\\mu(E_n)\\] が成り立つが，仮定より \\(\\mu(E_n)&lt;\\infty\\) だから，左辺の第二項の無限和は任意の \\(n\\in\\mathbb{N}^+\\) について収束することがわかる．よって，\\(n\\to\\infty\\) の極限を考えることで右辺は発散するから，左辺も第一項が発散している必要がある： \\[\\mu\\left(\\bigcap_{i=1}^\\infty E_i\\right)=\\lim_{n\\to\\infty}\\mu(E_n)=\\infty.\\] これは \\(\\bigcap_{i=1}^\\infty E_i\\in\\Sigma\\) に矛盾．\n条件を満たす \\(F\\in\\Sigma\\) を取り，ある可測部分集合 \\(F_1\\subset F\\) は \\(\\mu(F_1)=\\mu(F_1\\cap F)&gt;N\\) を満たすとする．すると \\(F_1\\) は有界である必要があるが，\\(F\\) は非有界としたから，\\(F\\setminus F_1\\) が非有界である必要がある．よって可測部分集合 \\(A_1\\subset F\\setminus F_1\\) で \\(\\mu(A_1)\\ge1\\) を満たすものが取れる．すると \\(F_2:=F_1\\cup A_1\\) も \\(\\mu(F_2)\\ge\\mu(F_1)&gt;N\\) より，やはり有界である必要がある．これを繰り返すことで， \\[\\mu\\left(\\bigcup_{i=1}^\\infty A_i\\right)=\\infty\\] を満たす \\(\\{A_i\\}_{i\\in\\mathbb{N}^+}\\subset\\Sigma\\) が見つかってしまう．"
  },
  {
    "objectID": "posts/2023-12-2/BoundedMeasure.html#sec-3",
    "href": "posts/2023-12-2/BoundedMeasure.html#sec-3",
    "title": "「有界」測度と「有限」測度 | Between ‘Bounded’ Measures and ‘Finite’ Measures",
    "section": "3 一般のベクトル値測度の場合",
    "text": "3 一般のベクトル値測度の場合\n\n\n\n\n\n\n命題（有限ならば有界）\n\n\n\n\\((E,\\mathcal{E})\\) を可測空間，\\(B\\) をBanach空間，\\(\\nu:\\mathcal{E}\\to B\\) を可算加法的集合関数とする．\n\n写像 \\(\\lvert\\nu\\rvert:\\mathcal{E}\\to[0,\\infty]\\) を \\[\\lvert\\nu\\rvert(A):=\\sup_{(A_n)\\in\\mathrm{Map}(E,\\mathbb{N})}\\sum_{n=1}^\\infty\\lvert\\nu(A_n)\\rvert\\] で定めると，これは測度である．\n\\(B\\) が有限次元ならば，\\(\\mathrm{Im}\\;(\\lvert\\nu\\rvert)\\subset\\mathbb{R}_+\\) が成り立つ．すなわち，有界な測度である．\n\n\n\n\n\n\n\n\n\n証明\n\n\n\n5 仮に \\(\\lvert\\nu\\rvert(E)=\\infty\\) と仮定して矛盾を導く．\\(B=\\mathbb{R}\\) として示せば，あとは成分ごとに考えることで一般次元の場合も同様である．\n\\(A_1:=E\\) から始まる減少列を定める．全変動の定義から，ある部分集合 \\(B\\in\\mathcal{E},B\\subset A_1\\) が存在して， \\[\\lvert\\nu(B)\\rvert\\ge\\lvert\\nu(A_1)\\rvert+2\\] を満たす．\\(\\lvert\\nu\\rvert(B)=\\infty\\) のとき \\(A_2:=B\\) とし，\\(\\lvert\\nu\\rvert(B)&lt;\\infty\\) のとき\\(A_2:=A_1\\setminus B\\) とすると， \\[\\lvert\\nu\\rvert(A_1\\setminus B)=\\lvert\\nu\\rvert(A_1)-\\lvert\\nu\\rvert(B)=\\infty.\\] このとき，三角不等式から，どちらの場合も \\[\\lvert\\nu(A_2)\\rvert\\ge\\lvert\\nu(B)\\rvert-\\lvert\\nu(A_1)\\rvert\\ge2.\\] これを繰り返すことで，\\(\\lvert\\nu(A_n)\\rvert\\ge n\\;(n\\in\\mathbb{N}^+)\\) を満たす減少列 \\(\\{A_n\\}_{n=1}^\\infty\\) を得る．するとこの極限 \\(A:=\\bigcap_{n=1}^\\infty A_n\\) の測度は発散するが，これは \\(\\nu\\) が \\(B\\)-値であることに矛盾する．"
  },
  {
    "objectID": "posts/2023-12-2/BoundedMeasure.html#footnotes",
    "href": "posts/2023-12-2/BoundedMeasure.html#footnotes",
    "title": "「有界」測度と「有限」測度 | Between ‘Bounded’ Measures and ‘Finite’ Measures",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nここで符号付き測度とは，\\(\\sigma\\)-加法的な集合関数 \\(\\mu:\\Sigma\\to[-\\infty,\\infty]\\) であって，値域には \\(\\infty,-\\infty\\) のいずれか一方しか含まれないもの，としている．↩︎\n(Lang, 1993, p. 198)↩︎\n(Giesy, 1970)↩︎\n(Dunford & Schwartz, 1958, pp. 補題III.4.4 p.127) 参照．↩︎\n(Lang, 1993, pp. 定理3.2 p.197)．↩︎"
  },
  {
    "objectID": "posts/2023-11-17/条件付き正規分布からのシミュレーション法.html",
    "href": "posts/2023-11-17/条件付き正規分布からのシミュレーション法.html",
    "title": "条件付き正規分布からのシミュレーション法",
    "section": "",
    "text": "文献 (Doucet, 2010) の主張に証明を与える．"
  },
  {
    "objectID": "posts/2023-11-17/条件付き正規分布からのシミュレーション法.html#sec-1",
    "href": "posts/2023-11-17/条件付き正規分布からのシミュレーション法.html#sec-1",
    "title": "条件付き正規分布からのシミュレーション法",
    "section": "1 正規確率変数同士の条件付き分布",
    "text": "1 正規確率変数同士の条件付き分布\n\n\n\n\n\n\n命題：正規確率変数同士の条件付き分布\n\n\n\n\\[Z=(X,Y)\\sim\\mathrm{N}_n(m,\\Sigma)\\] \\[m=\\begin{pmatrix}m_x\\\\m_y\\end{pmatrix},\\qquad\\Sigma=\\begin{pmatrix}\\Sigma_{xx}&\\Sigma_{xy}\\\\\\Sigma_{xy}^\\top&\\Sigma_{yy}\\end{pmatrix}\\] で，共分散行列は正則 \\(\\Sigma\\in\\mathrm{GL}_n(\\mathbb{R})\\) とする．このとき， \\[X|Y=y\\sim\\mathrm{N}_{n_x}(m_{x|y},\\Sigma_{x|y}),\\] \\[m_{x|y}=m_x+\\Sigma_{xy}\\Sigma_{yy}^{-1}(y-m_y),\\] \\[\\Sigma_{x|y}=\\Sigma_{xx}-\\Sigma_{xy}\\Sigma_{yy}^{-1}\\Sigma_{xy}^\\top.\\]\n\n\n\n\n\n\n\n\n証明\n\n\n\n\\(Z\\)の密度 \\[\\frac{1}{(2\\pi)^{n/2}(\\det\\Sigma)^{1/2}}\\exp\\left(-\\frac{1}{2}(z-m)^\\top\\Sigma^{-1}(z-m)\\right)\\] を，\\(Y\\) の密度との積で表した際，残った因子が \\(X|Y\\) の密度となる． \\(\\exp\\) の中身に注目する．Schur補行列を \\(S:=\\Sigma_{xx}-\\Sigma_{xy}\\Sigma_{yy}^{-1}\\Sigma_{xy}^\\top\\) とすると， \\[\\Sigma^{-1}=\\begin{pmatrix}S^{-1}&-S^{-1}T\\\\-T^\\top S^{-1}&\\Sigma_{yy}^{-1}+T^\\top S^{-1}T\\end{pmatrix},\\qquad T:=\\Sigma_{xy}\\Sigma_{yy}^{-1}\\] であるから， \\(\\eta:=T(y-m_y)=\\Sigma_{xx}\\Sigma_{yy}^{-1}(y-m_y)\\) とおくと， \\[\\begin{align*}\n    &\\quad(z-m)^\\top\\Sigma^{-1}(z-m)\\\\\n    &=(x-m_x)^\\top S^{-1}(x-m_x)\\\\\n    &\\qquad\\qquad-(y-m_y)^\\top T^\\top S^{-1}(x-m_x)-(x-m_x)^\\top S^{-1}T(y-m_y)\\\\\n    &\\qquad\\qquad+(y-m_y)^\\top T^\\top S^{-1}T(y-m_y) +(y-m_y)^\\top\\Sigma_{yy}^{-1}(y-m_y)\\\\\n    &=\\biggr((x-m_x)^\\top-\\eta^\\top\\biggl)S^{-1}(x-m_x)-\\biggr((x-m_x)^\\top+\\eta^\\top\\biggl)S^{-1}\\eta\\\\\n    &\\qquad\\qquad+(y-m_y)^\\top\\Sigma_{yy}^{-1}(y-m_y)\\\\\n    &=\\biggr((x-m_x)^\\top-\\eta^\\top\\biggl)S^{-1}\\biggr((x-m_x)-\\eta\\biggl)\\\\\n    &\\qquad\\qquad+(y-m_y)^\\top\\Sigma_{yy}^{-1}(y-m_y).\n\\end{align*}\\] 以上より，平均は \\(m_{x|y}=m_x+\\eta\\) で，共分散行列は \\(\\Sigma_{x|y}=S\\) ．"
  },
  {
    "objectID": "posts/2023-11-17/条件付き正規分布からのシミュレーション法.html#sec-2",
    "href": "posts/2023-11-17/条件付き正規分布からのシミュレーション法.html#sec-2",
    "title": "条件付き正規分布からのシミュレーション法",
    "section": "2 条件付き分布からのシミュレーション",
    "text": "2 条件付き分布からのシミュレーション\n\n\n\n\n\n\n条件付き分布からのシミュレーション\n\n\n\n条件付き確率変数 \\(X|Y=y\\) のシミュレーションは，条件付き共分散行列 \\(\\Sigma_{x|y}\\) のCholesky分解 \\(\\Sigma_{x|y}=\\sqrt{\\Sigma_{x|y}}\\left(\\sqrt{\\Sigma_{x|y}}\\right)^\\top\\) を用いて， \\[\\overline{X}=m_{x|y}+\\sqrt{\\Sigma_{x|y}}U,\\] \\[U\\sim\\mathrm{N}_{n_x}(0,I_{n_x})\\] によって行うのも直接的だが， \\(n_x\\) の次元が大きすぎる場合，Cholesky分解の計算がネックとなる．そのような場合は， \\[\\overline{X}=X+\\Sigma_{xy}\\Sigma_{yy}^{-1}(y-Y),\\] \\[Z=\\begin{pmatrix}X\\\\Y\\end{pmatrix}\\sim\\mathrm{N}_n(m,\\Sigma),\\] というアルゴリズムを用いることが出来る (Hoffman & Ribak, 1991)．\n\n\n\n\n\n\n\n\n証明\n\n\n\n\\(\\overline{X}\\) はGauss確率変数の線型変換だからやはりGaussである．よって，平均と分散が \\(X|Y\\) に一致することを示せば良い． 次のように \\(\\overline{X}\\) を書き換えることが出来る： \\[\\begin{align*}\n    \\overline{X}&=X+\\Sigma_{xy}\\Sigma_{yy}^{-1}(y-Y)\\\\\n    &=X+\\biggr(m_x+\\Sigma_{xy}\\Sigma_{yy}^{-1}(y-m_y)\\biggl)\\\\\n    &\\qquad+\\biggr(m_x+\\Sigma_{xy}\\Sigma_{yy}^{-1}(Y-m_y)\\biggl)\\\\\n    &=X+m_{x|y}-\\mathrm{E}[X|Y]\n\\end{align*}\\] これより，\\(\\mathrm{E}[\\overline{X}|Y]=m_{x|y}\\)．よって， \\[\\mathrm{E}[\\overline{X}]=\\mathrm{E}[\\mathrm{E}[\\overline{X}|Y]]=m_{x|y}.\\] 続いて， \\[\\mathrm{Var}[\\overline{X}|Y]=\\mathrm{Var}[X-\\mathrm{E}[X|Y]|Y]=\\mathrm{E}[(X-\\mathrm{E}[X|Y])^2|Y]=\\mathrm{Var}[X|Y]=\\Sigma_{x|y}\\] より，全分散の公式から \\[\\begin{align*}\n\\mathrm{Var}[\\overline{X}]&=\\mathrm{E}[\\mathrm{Var}[\\overline{X}|Y]]+\\underbrace{\\mathrm{Var}[\\mathrm{E}[\\overline{X}|Y]]}_{=0}\\\\\n&=\\Sigma_{x|y}.\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/2023-11-17/条件付き正規分布からのシミュレーション法.html#応用-ensemble-kalman-filter",
    "href": "posts/2023-11-17/条件付き正規分布からのシミュレーション法.html#応用-ensemble-kalman-filter",
    "title": "条件付き正規分布からのシミュレーション法",
    "section": "3 応用 Ensemble Kalman filter",
    "text": "3 応用 Ensemble Kalman filter\nまた，Ensemble Kalman filterはこの手法の応用と理解することができ，この手法の別の応用としてFFBS (Forward Filtering Backward Sampling)アルゴリズムを代替するサンプリングアルゴリズムを得ることが出来ることも論じている．\n線型Gaussな状態空間モデル \\[\n\\begin{cases}\nX_n=A_nX_{n-1}+a_n+W_n&n\\ge 1,\\\\\nY_n=B_nX_n+b_n+V_n,&n\\ge0.\n\\end{cases}\n\\] \\[\nW_n\\sim\\mathrm{N}_p(0,R^w_n),\\quad V_n\\sim\\mathrm{N}_q(0,R_n^v),\n\\]\nの最適な一段階予測推定量 \\[\n\\eta_n:=\\mathcal{L}[X_n|(Y_0,\\cdots,Y_{n-1})]\n\\] も，フィルタリング推定量 \\[\n\\widehat{\\eta}_n:=\\mathcal{L}[X_n|(Y_0,\\cdots,Y_n)]\n\\] もGauss確率変数で，平均と分散は Section 1 の命題の繰り返し適用によって計算できる．これをKalman filterという．1\n\n3.1 EnKF\nしかし，状態空間（\\(X_n\\)の値域）の次元が大きすぎる場合，Section 2 で述べた理由と同様の理由で，Kalman gainの行列計算が実行不可能になる．\nこのステップを，粒子平均によって代替する粒子法がEnsemble Kalman filterであり，前述の障碍が典型的に生じてきた地球科学・海洋科学の分野で発展してきた (Evensen, 1994)．この方法では， Section 2 のサンプリングトリックを用いて，再帰的にフィルタリング分布と予測分布を近似していく．\n\n\n3.2 FFBS\nまた，線型Gauss状態空間モデルのハイパーパラメータの推定が必要な場合などでは，Feynman-Kac分布 \\(p(x_{0:n}|y_{1:n})\\) からのサンプリングが必要になる．\n典型的にはFFBS (Foward Filtering Backward Sampling) などの方法が知られている．これは \\(p(x_{0:n}|y_{1:n})\\) があるMarkov連鎖の見本道の分布に一致することに基づき，その後ろ向き核による分解から，\n\n前向きにフィルタリング分布と予測分布を計算する再帰的アルゴリズムを実行する．\n2つの分布から後ろ向き核を計算する．\n後ろ向き核を用いて， \\(X_n\\sim p(x_n|y_{1:n})\\) を後ろ向きにサンプリングしていく．\n\nと実行する方法である．2\n一方で， Section 2 のテクニックで次のようにしてサンプリングすることもできる．\n\n前向きに \\(\\mathrm{E}[X_{0:n}|Y_{1:n}], \\mathrm{E}[X_{0:n}|Y_{1:n}=y_{1:n}]\\) を計算する．\n次をサンプリングする：\\[\n\\begin{align*}\n\\overline{X}_{0:n}&:=E[X_{0:n}|Y_{1:n}=y_{1:n}]\\\\\n&\\qquad+X_{0:n}-\\mathrm{E}[X_{0:n}|Y_{1:n}]\n\\end{align*}\n\\]\n\n(Durbin & Koopman, 2002) では，多くの場合 \\(R^w_n\\) のランクが低いことに注目して， \\(\\mathrm{E}[W_{1:n}|Y_{1:n}]\\) を計算して， \\(p(x_0,w_{1:n}|y_{1:n})\\) からサンプリングすることを提唱している．\n\n\n3.3 その他\n(Doucet, 2010) は他にも，時空間統計 (Cressie, 1993) と機械学習 (Rasmussen & Williams, 2006) などで生じるGauss過程への応用で役に立ち得るのではないかと示唆している．"
  },
  {
    "objectID": "posts/2023-11-17/条件付き正規分布からのシミュレーション法.html#footnotes",
    "href": "posts/2023-11-17/条件付き正規分布からのシミュレーション法.html#footnotes",
    "title": "条件付き正規分布からのシミュレーション法",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(Del Moral & Penev, 2014) p.280 など参照．↩︎\n(Chopin & Papaspiliopoulos, 2020) 5.4.4節 p.63 など参照．↩︎"
  },
  {
    "objectID": "posts/2023-11-7/KernelMethods4Mathematicians.html",
    "href": "posts/2023-11-7/KernelMethods4Mathematicians.html",
    "title": "数学者のためのカーネル法概観",
    "section": "",
    "text": "$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$"
  },
  {
    "objectID": "posts/2023-11-7/KernelMethods4Mathematicians.html#導入",
    "href": "posts/2023-11-7/KernelMethods4Mathematicians.html#導入",
    "title": "数学者のためのカーネル法概観",
    "section": "1 導入",
    "text": "1 導入\n\n1.1 カーネル法の歴史1\n1992年，当時は2023年に生きる我々と全く同じく，ニューラルネットワーク（以降NN）のブームのさなかにあった（当時は第二期ブーム）．このブームを一度終わらせたのが，(Boser et al., 1992) によるカーネル法であった．\n当時は数学の範疇から出たことがなかったカーネルの概念を用いて，SVMを非線形化したKernel SVMという手法を提案したのである．以降，非線形問題を扱えるモデルとして，NNを凌ぐ勢いで発展し，NNがvanishing gradientsという障壁にぶつかったこともあり，2000年から2006年を「深層学習の冬」とまで言わしめた．\n\n\n1.2 カーネル法の課題\n2006年というのは，(Hinton & Salakhutdinov, 2006)の年である．この自己符号化器の発表がきっかけになり，DNNの訓練がますます効率的になり，一方でKernel SVMは次の2つの障壁に直面しており，現在のDNN最強の時代を我々は見ている．2\n\n種々のタスクに対して，最適なカーネルが何かがわかっていない．\nデータ数が多すぎると実行不可能になる．\n\nカーネル法のトリックは単純であるから，個々の問題に即したカーネルの選び方，または適応的にカーネルを定めるアルゴリズムのデザインが，今後の課題である．"
  },
  {
    "objectID": "posts/2023-11-7/KernelMethods4Mathematicians.html#カーネル法の数理",
    "href": "posts/2023-11-7/KernelMethods4Mathematicians.html#カーネル法の数理",
    "title": "数学者のためのカーネル法概観",
    "section": "2 カーネル法の数理",
    "text": "2 カーネル法の数理\n\n2.1 カーネル法とは「データの前処理／データの変換をするための方法論」である\n線型手法が使えないときに，良い変数変換を考えることで，線型分離可能にする，というのは統計の基本的な手法である．\n例えば，データが正規分布から大きく違っている場合，Box-Cox変換\n\\[x \\longmapsto x^{(\\lambda)} = \\begin{cases}\n\\displaystyle \\frac{x^\\lambda - 1}{\\lambda} & \\lambda \\neq 0\\\\\n\\log x & \\lambda = 0\\end{cases}\\]\nを通じて正規分布に近づけることが出来る．このパラメータ \\(\\lambda\\in\\mathbb{R}\\) をデータから調整する．\nカーネル法は，このような非線形変換（はカーネル法ではないが3）を見つけてくるための系統的な枠組みであると言える．そして，カーネル法を通じて得た空間（特徴空間という）で従来の線型なデータ解析を施すだけで，全体としては非線型な手法の完成である．だから「カーネル法」という手法があるというより，種々の線型手法の「カーネル化」が常に考えられる，というものである．\n一方で，DNNはモデルの構成要素自体が非線型であり，全く精神が違う非線型手法だと言えるだろう．\n\n\n2.2 カーネル法の骨格\nカーネルと言ったとき，数学的には「（実数値の）半正定値対称関数」を指す．\n\n\n\n\n\n\n定義：（実数値の）正定値カーネル\n\n\n\n関数 \\(k:\\Omega\\times\\Omega\\to\\mathbb{R}\\) が正定値カーネルであるとは，次の２条件を満たすことをいう：\n\n対称性：\\(k(x,y)=k(y,x)\\)．\n正値性：任意有限個の点 \\(x_1,\\cdots,x_n\\in\\Omega\\) に対し，行列 \\(\\bigl(k(x_i,x_j)\\bigr)^n_{i,j=1}\\) は半正定値：4 \\[\n  \\sum_{i,j=1}^nc_ic_jk(x_i,x_j)\\ge0,\\qquad c_i\\in\\mathbb{R}.\n\\]\n\n\n\n\n\n\n\n\n\n例：\\(\\Omega=\\mathbb{R}^d\\) 上の正定値カーネル\n\n\n\n\nEuclid内積：\\(k(x,y)=x^\\top y\\)．\nGaussカーネル：\\(k_G(x,y)=\\exp\\left(-\\frac{1}{2\\sigma^2}\\|x-y\\|^2\\right)\\;(\\sigma&gt;0)\\)．\nLaplaceカーネル：\\(k_L(x,y)=\\exp\\left(-\\alpha\\sum_{a=1}^d|x_a-y_a|\\right)\\;(\\alpha&gt;0)\\)．\n多項式カーネル：\\(k_P(x,y)=(c+x^\\top y)^d\\;(c\\ge0,d\\in\\mathbb{N})\\)．\n\n\n\nこの「正定値カーネル」の概念は，次の意味で，「内積」と同一視できる．「内積」と同一視できるという意味で，「類似度の測り方」に対応する．\n\n\n\n\n\n\n定理：Moore-Aronszajn 1950\n\n\n\n任意の集合 \\(\\Omega\\) 上の正定値カーネル \\(k\\) に対して，\\(\\Omega\\) 上の関数からなるHilbert空間 \\(H_k\\) であって，以下を満たすものが一意に定まる：5\n\n\\(k(-,x)\\in H_k\\;(\\forall_{x\\in\\Omega})\\)．\n（再生性）\\((f\\,|\\,k(-,x))_{H_k}=f(x)\\)．\n\nこのHilbert空間 \\(H_k\\) を数学では \\(k\\)-再生核Hilbert空間といい，データ解析では \\(k\\)-特徴空間という．\n\n\nここで，数学概念について，少し突飛に思えるかもしれないが，次の名前をつける．\n\n\n\n\n\n\n定義\n\n\n\n正定値カーネル \\(k:\\Omega\\to\\mathbb{R}\\) について，\n\n\\(x\\mapsto k(-,x)\\) という対応 \\(\\Phi:\\Omega\\to H_k\\) を特徴写像という．\n\\(\\Phi\\) は「内積を保つ」が，この性質をカーネルトリックという： \\[\n\\left(\\Phi(x)\\,\\middle|\\,\\Phi(y)\\right)_{H_k}=k(x,y).\n\\]\n\n\n\n「特徴写像」は，データ \\(x,y\\in\\Omega\\) を正定値カーネルが測る「類似度」を変えないように，しかしながら全く違う空間内の点 \\(\\Phi(x),\\Phi(y)\\in H_k\\) に写している．「類似度」が変わっていないことを「カーネルトリック」と呼ぶ．\nこの「トリック」は少し米田埋め込みに似ている．データ \\(x\\in\\Omega\\) の他のデータとの類似度の全体 \\(k(-,x):\\Omega\\to\\mathbb{R}\\) は，そのデータを特徴づけるのである \\(k(-,x)=\\Phi(x)\\in H_k\\)．\nまた，関数のなすHilbert空間 \\(H\\subset\\mathbb{R}^\\Omega\\) が， \\(\\{\\mathrm{ev}_x\\}_{x\\in\\Omega}\\subset H^*\\) を満たすならば，\\(H\\) は再生核を持つ．このような関数空間 \\(H\\) の内積の構造を \\(\\Omega\\) にも導入したいとき， \\(k\\) を通じてすれば良いということになる． \\(k\\) は違う \\(H_k\\) と \\(\\Omega\\) を対応づけ，正しい \\(k\\) を選ぶと，データ \\(\\{x_1,\\cdots,x_n\\}\\subset\\Omega\\) のうちなる「特徴」を暴き出せるかもしれない．\n\n\n2.3 カーネル法の強み\nこうして見たように，カーネル法は\n\n非線型な情報，特に高次モーメントの扱いができる．\nデータの次元 \\(X_i\\in\\mathbb{R}^p\\) に依らない．が，データ数 \\(N\\) に依存し，次元の呪いを受ける．\nデータの形式にも依らない．ベクトルでなくとも，グラフでも，行列でも，分布でも良い．"
  },
  {
    "objectID": "posts/2023-11-7/KernelMethods4Mathematicians.html#種々のデータ解析のカーネル化",
    "href": "posts/2023-11-7/KernelMethods4Mathematicians.html#種々のデータ解析のカーネル化",
    "title": "数学者のためのカーネル法概観",
    "section": "3 種々のデータ解析のカーネル化",
    "text": "3 種々のデータ解析のカーネル化\n\n3.1 データ解析のやり方\n\nカーネル \\(k\\) を用意する．すると，特徴空間 \\(H_k\\) が定まるが，これは一般に関数空間であり，無限次元である．\\(H_k\\) の元を「特徴ベクトル」と言ったりするのに，その正体は関数である．\nカーネルトリック（≒再生性）が，「特徴ベクトル同士の内積」だけを計算可能にする．\n\n要は計算できることは内積だけなのである！しかし，特徴写像や特徴ベクトルの表示を陽に使わずとも，内積だけで実行可能な線型データ解析は，実に多いのである．\n\n\n3.2 例：Ridge回帰\nRidge回帰は，次の最適化によって線型回帰係数 \\(a\\in\\mathbb{R}^p\\) を推定するロバスト手法である：\n\\[\n  \\min_{a\\in\\mathbb{R}^p}\\frac{1}{n}\\sum_{i=1}^n(Y_i-a^\\top X_i)^2+\\lambda\\|a\\|^2.\n\\]\nこれを「カーネル化する」とは，「特徴空間で実行する」ということである． \\(X_i\\) の代わりに \\(\\Phi(X_i)\\) 上で，Euclid内積 \\(a^\\top X_i\\) の代わりに特徴空間の内積 \\((f|\\Phi(X_i))_{H_k}\\) で実行するということである：\n\\[\n  \\min_{f\\in H_k}\\frac{1}{n}\\sum_{i=1}^n\\biggl(Y_i-(f|\\Phi(X_i))_{H_k}\\biggr)+\\lambda\\|f\\|^2_H\n\\]\n実はこの式は次と等価：\n\\[\n  \\min_{f\\in H_k}\\frac{1}{n}\\sum_{i=1}^n\\biggl(Y_i-f(X_i)\\biggr)+\\lambda\\|f\\|^2_H\n\\]\nたしかに，\\(f\\in H\\) は一般の関数であり，非線形な回帰を行なっていることになる！\nしかし，最後にこの最適化問題をどう解くか？という問題が残り，無限次元空間 \\(H\\) 上での最適化の理論が必要になるかといえばそうではなく，\n\\[\n  f=f_\\Phi:=\\sum_{i=1}^nc_i\\Phi(X_i)\n\\]\nという形のみで解を探せば良いことが判る．これは \\(f=f_\\Phi\\oplus f_\\perp\\) という直交分解を考えることで従う．つまり，最適化はデータ点 \\(\\Phi(X_1),\\cdots,\\Phi(X_n)\\) の張る有限次元部分空間上のみで考えれば良い．この事実にはRepresenter定理という仰々しい名前がついている．\nすると目的関数は\n\\[\n\\frac{1}{N}\\sum_{i=1}^N\\biggl(Y_i-\\sum_{j=1}^Nc_jk(X_i,X_j)\\biggr)^2+\\lambda\\underbrace{\\sum_{i,j=1}^Nc_ic_jk(X_i,X_j)}_{=c^\\top Kc}\n\\]\nとなり，これを解くと，カーネルRidge回帰の解は\n\\[\n\\widehat{f}(x)=\\boldsymbol{k}(x)^\\top(K+n\\lambda_nI_n)^{-1}\\boldsymbol{Y},\n\\]\n\\[\n\\boldsymbol{k}(x)=\\begin{pmatrix}k(x,X_1)\\\\\\vdots\\\\k(x,X_N)\\end{pmatrix},\\boldsymbol{Y}=\\begin{pmatrix}Y_1\\\\\\vdots\\\\Y_N\\end{pmatrix}\n\\]\nと表せることがわかる．\n\n\n3.3 発展\nここで，最初の節 Section 1.1 で紹介した2つの問題点に戻る．\n\n種々のタスクに対して，最適なカーネルが何かがわかっていない．\nデータ数が多すぎると実行不可能になる．\n\nこの2.について，カーネルRidge回帰の例だと，逆行列 $\\((K+n\\lambda_nI_n)^{-1}\\) の計算が実行不可能になるという形で現前する．しかし，Woodburyの公式から，低ランク近似が得られていれば，それを活用できる．一般にGram行列の固有値の減衰は速いことが知られており，この低ランク近似の戦略は筋が良いと言える．\n1.について，まずSVMなどの教師あり学習の設定では，CVを使うことでカーネル選択をすることができる．が，教師なし学習では一般的な方法はない．特にカーネル主成分分析（次節の例）．しかし，これを適応的に学習するというのは良いアイデアだろう．Multiple Kernel Learning (Gönen & Alpaydin, 2011) はカーネルの凸結合を学習し，Deep Kernel Learning (Wilson et al., 2016) はNNによってカーネルを学習する．\n\n\n3.4 例：主成分分析\n主成分分析を抽象的に理解すれば，分散が大きい方向に射影をすることで，「意味がある方向」を見つける手法なのであった．\n主成分方向とは\n\\[\n\\max_{a\\in\\mathbb{R}^p:\\|a\\|=1}\\sum_{i=1}^N(a^\\top(X_i-\\overline{X}))^2.\n\\]\nの解 \\(a\\in\\mathbb{R}^p\\) である．これは分散共分散行列の固有値問題を解くことに等価になる．\nこの手法を「カーネル化」するには，特徴空間で実行すれば良い．\n\\[\n\\max_{f:\\|f\\|_H=1}\\sum_{i=1}^N\\biggl(f\\,\\bigg|\\,\\Phi(X_i)-\\overline{\\Phi}(X)\\biggr)^2\n\\]\nこの解も，データの特徴ベクトルの張る有限部分空間内で調べれば十分なのである！というのも，正確には，平均を引いた次の形のみを考えれば良いことが判る：\n\\[\nf=\\sum_{i=1}^Nc_i\\biggl(\\Phi(X_i)-\\overline{\\Phi(X)}\\biggr)\n\\]\n実際には，中心化Gram行列の固有値問題に帰着する：\n\\[\n\\widetilde{K}_{ij}=k(X_i,X_j)-\\frac{1}{N}\\sum_{b=1}^Nk(X_i,X_b)\\qquad\\qquad\n\\]\n\\[\n\\qquad\\qquad-\\frac{1}{N}\\sum_{a=1}^Nk(X_a,X_j)+\\frac{1}{n^2}\\sum_{a,b=1}^Nk(X_a,X_b).\n\\]\n\n\n3.5 例：SVM\nデータ \\(\\{x_1,\\cdots,x_n\\}\\subset\\mathbb{R}^p\\) が線型分離可能であるとき，ハードマージン法と呼ばれる手法を用いて，これを分離する最大マージン超平面 \\[\nH_\\mathrm{max}:=\\mathop{\\mathrm{arg\\,max}}_{H\\subset\\mathbb{R}^p}\\min_{1\\le i\\le n}d(x_i,H)\n\\] を，凸二次計画問題を解くことによって見つけることができる．このとき，最大のマージンを達成する \\[\nd(x_{j},H)=\\min_{1\\le i\\le n}d(x_i,H)\n\\] ときの \\(x_j\\) （複数あり得る）をサポートベクトル といい，これが解 \\(H_{\\text{max}}\\) を特徴付ける．\nこの問題において，特徴写像 \\(\\Phi:\\mathbb{R}^p\\to H_k\\) を考えても，やはり解を \\(n\\) 次元部分空間 \\[\nv\\in\\left\\{\\sum_{j=1}^nc_j\\Phi(x_j)\\in H_k\\;\\middle|\\;c_j\\in\\mathbb{R}\\right\\}\n\\] 上で考えれば良いから， \\[\n\\underset{v,\\gamma}{\\text{minimize}}\\quad\\|v\\|^2_{H_k}=\\sum_{i,j=1}^nc_ic_jk(x_i,x_j)\n\\] \\[\n\\text{subject to}\\quad\\lambda_i\\left(\\sum_{j=1}^nc_jk(x_i,x_j)+\\gamma\\right)\\ge1\\quad(i\\in[n])\n\\] という，やはり凸二次計画問題を解けば良い．\n\n\n3.6 総括\n\n\n\n\n\n\nまとめ\n\n\n\n典型的には，線型手法の目的関数が \\((\\Phi(X_i)|\\Phi(X_j)),(f|\\Phi(X_i))\\) で表現され，さらに解がデータ数の次元を持った有限次元部分空間で見つかる．その結果，Gram行列の解析に帰着し，データ数 \\(n\\) に依存するが，個々のデータの形式に依らない！データはベクトルでなく，カーネルが定義できさえすれば，確率分布自体でも問題がない．\n\n\n\n\n\nbook cover"
  },
  {
    "objectID": "posts/2023-11-7/KernelMethods4Mathematicians.html#footnotes",
    "href": "posts/2023-11-7/KernelMethods4Mathematicians.html#footnotes",
    "title": "数学者のためのカーネル法概観",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(Ghojogh et al., 2021) など参考．↩︎\n一方でここにきて，現代におけるDNNの最先端とも言えるTransformerをSVMとみなせる，という報告も出てきた (Tarzanagh et al., 2023)↩︎\nどちらかといえば，Box-Cox変換は一般化線型モデルの発想の先駆けと見れる．「リンク関数 \\(G\\) を用いて回帰関係を変換し非線形にする」という発想である．(Wolfgang Härdle & Sperlich, 2004, p. 162)↩︎\nこのようにして構成される行列をGram行列と呼ぶ．↩︎\n(Aronszajn, 1950) 参照．↩︎"
  },
  {
    "objectID": "posts/2023-11-8/index.html",
    "href": "posts/2023-11-8/index.html",
    "title": "書籍紹介 Del Moral (2004) Feynman-Kac Formulae",
    "section": "",
    "text": "book cover"
  },
  {
    "objectID": "posts/2023-11-8/index.html#書籍紹介-del-moral-2004-feynman-kac-formulae",
    "href": "posts/2023-11-8/index.html#書籍紹介-del-moral-2004-feynman-kac-formulae",
    "title": "書籍紹介 Del Moral (2004) Feynman-Kac Formulae",
    "section": "書籍紹介 Del Moral (2004) Feynman-Kac Formulae",
    "text": "書籍紹介 Del Moral (2004) Feynman-Kac Formulae\n前文と一部の内容が著者のHPからご覧になれます．\nFeynman-Kac Formulae\nこの本はFeynman-Kac道測度とその粒子法による解釈とその各種科学分野への応用を統一的に扱った初のモノグラフ．"
  },
  {
    "objectID": "posts/2023-11-8/index.html#内容",
    "href": "posts/2023-11-8/index.html#内容",
    "title": "書籍紹介 Del Moral (2004) Feynman-Kac Formulae",
    "section": "内容",
    "text": "内容\n\nPreface\n本書はFeynman-Kac path distribution, 相関粒子系，系統木モデルを扱う．生物学，物理学，確率統計学，工学，信号処理に渡る共通の話題である．21世紀に入ってやっと理論の形が見えてきたので，ここに教科書を書く．粒子法とFeynman-Kacモデル自体は，統計物理学，とりわけ気体分子運動論に起源を持つが，この本はその知識がなくても読めるようになっている．確率過程の素養がある学部生，工学・統計学・生物学・物理学の大学院生が対象読者である．\nまた，Feynman-Kacモデルと粒子法の漸近理論の研究に必要な数学，経験過程論，大偏差解析，半群・マルチンゲール理論，カオスの伝播，測度値過程の集中，関数不等式，エルゴード係数，Markov作用素の引き戻し，非線形半群など，の参考書になるようにも用意した．\nまた本書には種々のFeynman-Kac distribution flow, 相関粒子モデルの例の宝庫になっている．制限Markov連鎖シミュレーション，吸収媒体内のランダム粒子，Schrödinger作用素とFeynman-Kac半群のスペクトル解析，稀事象解析，Dirichlet境界問題，非線型フィルタリング問題，相関Kalman-Bucyフィルタ，方向つきポリマーシミュレーション，相関Metropolisアルゴリズムなど，種々のモデルの粒子近似と収束解析の例が含まれている．\nこれほど物理学・工学・数学にまたがるトピックを書籍化できたことに感謝しかない．本書を書いた理由は，まず第一にFeynman-Kac path modelとその粒子近似を扱う書籍は皆無だったからである．しかし同時に，この理論は現代のBayes統計学，工学，物理学，生物学で用いられるモンテカルロ法の解析に共通の土台を提供する，極めて有用な理論である．さらに，オペレータ記法に対する恐怖心さえ払拭して貰えば，非線型問題や相関粒子近似の研究に，強力な道具となること間違いなしである．\n第1と12章では連続なモデルも扱っているが，離散時間のFeynman-Kacモデルに集中した．その理由は第一に，離散時間ならばMarkov過程の前提知識をほとんど用いないためである．これは本書の「なるべくself-containedな教科書を書く」という目的に合致している．第二に，連続な場合の漸近解析は，ほとんど離散の場合と同じ道を辿るからである．一方で多くのopen problemも残るが．\n\n\nSec1.1 On the Origins of Feynman-Kac and Particle Models\n\n\n\n\n\n\nポイント\n\n\n\nWienerの道積分は，量子の運動を確率測度の言葉で書いた．FeynmanはSchrödinger方程式と繋げて，ポテンシャルを与えたモデルにおいて，当該ポテンシャルが定める「確率測度の変換則」を与えた．これがFeynman-Kacの公式である． Feynman-Kac測度は，生きたり死んだりする粒子系の見本道の分布や，一般に淘汰圧や相互作用にさらされる粒子の分布のモデリングに広く有用であることが判りつつある． 尤度，淘汰圧，相互作用が「ポテンシャル」という一つの枠組みで捉えられるのである．ポテンシャルを尤度とすると，特定の粒子に淘汰圧をかけることで，効率的に探索することに使える．\n\n\nFeynman-Kac公式はFeynmanの1942年の博士論文に起源を持つ．これはSchrödinger方程式とWienerの道積分とをヒューリスティックに繋いだ．この研究は1950年代のMark Kacの研究に受け継がれることになる．ポテンシャルに従って運動する量子の半群を，汎函数の道積分の言葉で記述する，というアイデアである．直感的には，Feynman-Kac測度は粒子の経路の分布に，ポテンシャルの効果を組み込むということである．\nこれは「ポテンシャル関数が定める確率測度の変換」であるが，この発想が多くの数理物理，確率過程の分野の研究の方向性を決定づけた．そして今日，このモデルは多くの現象のモデリングに有用であることがわかっている．例えば物理学で，吸収的で非規則的な媒質内での単一粒子の見本道の分布を記述することが出来る．このモデルでは，ポテンシャル関数というのは，「死亡／生成率」を表している．\nより一般的に，物理化学における有向ポリマーなどの物理・生物学的存在のBoltzmann-Gibbs分布ともみなせる．この例では，ポテンシャル関数というのは，ハミルトニアンや，ともかく相互作用のエネルギー関数や淘汰圧に相当するものになる．さらに工学や統計学者の文脈では，ポテンシャル関数は，特定の観察過程に対する変数の条件付き確率（＝尤度）を表すことになる．この見方はフィルタリング問題やBayes解析をはじめとし，信号処理の分野で広く使われている．ともかく，ポテンシャルとは，観測過程や，参照道に対する，状態変数の尤度と同一視されるのである．\n確率的粒子算譜は，Monte Carlo法の一種である．その源は，確率を頻度として捉えたBernoulliの基礎づけから見られる．そこから現代の確率論の発展に至るまでの大きな一歩は，1920年代のMarkovによる「確率過程」という対象の創出である．Markov過程という概念は，種々の工学・自然科学的対象を，自然な形でモデリングするための最適な語彙を与えた．さらに，粒子法の，他の数値解放にない美点は，工学や自然科学が与える発展方程式に対して，「微視的な粒子解釈を与える」という点である．他にも，モデルの係数に正則性の仮定を必要としないこと，大規模モデルにも使えることなど，美点は尽きない．1さらに現在発見されつつあるもう一つの魅力として，分布の空間上で非線型方程式が数値的に解ける，という方面での応用である．これらの分布モデルの非線型な構造は，その粒子近似版のモデルに，自然な相互作用と分岐のメカニズムを課す．この近年の応用は，1960年代の流体力学と統計物理の発展に源を発する．この方面については，McKeanの開拓的仕事を参照すると良い．\nこの相関粒子法を工学や，とりわけ信号処理の分野に使うという応用は，さらに最近になってのことである．この方面での最初の厳密な研究は，1996年の非線型推定問題への粒子法の応用であるように思われる．この研究は，1990年台に初めて提案された新たな種の相関粒子モデルに対して，初めて厳密な収束の結果を与えた．同様の研究が4つ追随し，この種の相関粒子モデルが，大規模かつ非線型な測度値過程を数値的に解く手法として優れていることが判明した．同時期に，別の粒子分岐過程が，連続時間のフィルタリング問題を解く手法として独立に提案された．このときの手法は，現在でも非線型平滑化や道推定問題に使われている系統木粒子モデルの漸近解析に，ほとんどそのまま使えることが判明した（Del Moral and Miclo (2001) Genealogies and Increasing Propagation of Chaos for Feynman-Kac and Genetics Model）．\n本書の要点を掴むために，最初の例を与える．Singer modelと呼ばれており，レーダーのモデルである．3次元のMarkov過程 \\(X_n=(X_n^{(1)},X_n^{(2)},X_n^{(3)})\\) を考え，それぞれ加速度，速度，位置を表し，次のように発展するとする：\n\\[\n\\begin{cases}X_n^{(1)}=X_{n-1}^{(1)}+\\epsilon_nW_n\\\\X_n^{(2)}=(1-\\alpha\\Delta)X_{n-1}^{(2)}+\\beta\\Delta X_n^{(1)}\\\\X_n^{(3)}=X_{n-1}^{(3)}+\\Delta X_n^{(2)}\\end{cases}\n\\]\n\\(\\Delta\\in(0,1),\\alpha,\\beta\\in\\mathbb{R}\\) はサンプリング頻度とパラメータとする． \\(\\epsilon_n\\in2\\) はBernoulli確率変数， \\(W_n\\sim\\mathrm{U}([0,a])\\) などとモデリングしよう． \\(X_n\\) の観測は，次のように部分的になされる：\n\\[\nY_n=X_n^{(3)}+\\Delta V_n.\n\\]\nこの状態で， \\(X_0,\\cdots,X_n|Y_0,\\cdots,X_n\\) の分布を推定する問題を，非線型フィルタリング問題という．この「パスの分布」に対する粒子近似は，次のようにして与えられる．まず， \\(X_0\\) から \\(N\\) 個サンプリングして粒子とする： \\(X_0\\sim X_{0}^i\\)．次に，始めに定めたMarkov遷移確率に従って，発展させて，見本道 \\(X_{t_0,t_1}^i=(X_0^i,\\cdots,X_{t_i}^i)\\) を得る．それぞれの見本道の尤度は\n\\[\nW_{t_0,t_1}^i=\\exp\\left(-\\frac{1}{2}\\sum_{t_0\\le p&lt;t_1}(Y_p-X_p^{(3),i})^2\\right)\n\\]\nで与えられる．これは， \\([0,1]\\) の値で，与えられた見本道 \\(X_{t_0,t_1}^i\\) が「尤もらしいか」の度合いを定量評価していると見れる．この情報を取り入れて，配置 \\(\\{X_{t_1}^i\\}_{i=1}^N\\) を更新する必要があるが，そのやり方には様々ある．ここでは，現在の見本道 \\(\\{X_{t_0,t_1}^i\\}_{i=1}^N\\) の中から，分布\n\\[\nW_{t_0,t_1}^i\\delta_{X_{t_0,t_1}^i}+(1-W^i_{t_0,t_1})\\sum_{j=1}^N\\frac{W_{t_0,t_1}^j}{\\sum_{k=1}^NW_{t_0,t_1}^k}\\delta_{X_{t_0,t_1}^j}\n\\]\nでリサンプリングすることを考える．これは，尤度 \\(W_{t_0,t_1}^i\\) の確率でその見本道は残存させ，さもなくば，尤度の重み付けに従って他の見本道で置き換えてしまう，という確率的操作を施すということである．この更新ののち，新たに心機一転 \\(t_1(&gt;t_0=0)\\) から開始した見本道 \\(X_{t_1,t_2}^i=(X_{t_1}^i,\\cdots,X_{t_2}^i)\\) を得て，同じ操作を繰り返す．ただし， \\(X_{t_1}^i\\gets\\widehat{X}_{t_1}^i\\) として更新したものを用いる．\nこの操作をすると，各粒子は死亡・分岐を繰り返すように見える．同時に，遺伝的に効率的な探索を行えていることも分かる．尤度が高いところに自然に粒子が集中していくようにできているのである．\nこの例を見て，最も基本的な疑問は「この手法に理論的保証がつくだろうか？」という点になる． \\(N\\) の増加に対して，収束のスピードはどう速まっていくだろうか？この手法を他の最適化やシミュレーションに応用できないか？また，この遺伝的アルゴリズムを死亡と繁殖の過程と見たとき，その系統木について何が言えるだろうか？\nこのような漸近解析の中心的なアイデアは，目的の条件付き分布 \\(Y_1,\\cdots,Y_n|X_1,\\cdots,X_n\\) を，離散生成モデルとFeynman-Kac粒子近似モデルと関連づけることである．すると，系統木モデルの占有測度が，目的の条件付き分布 \\(Y_1,\\cdots,Y_n|X_1,\\cdots,X_n\\) に収束することを示せるのである！また，現在残存している個体の祖先の系列を， \\(Y_1,\\cdots,Y_n|X_1,\\cdots,X_n\\) の経路の近似的に独立なサンプルの集まりと近似的にみなせる．\nこの「うまくいっている個体を複製することで，状態空間を効率的に探索する」というのは，多くの確率的探索アルゴリズムの基本的な態度である．このアイデアは，どうやら1950年代の生物学での Rosenbluth の貢献と，物理学の Kahn and Harris の貢献とに端を発するようである．\n一般の距離空間上のFeynman-Kacモデルと粒子法の研究は，Del Moralに20世紀の終わりから21世紀の初めにかけて行われた．この手法の応用は大きく広がっており，Doucet (2001) では多くの応用が紹介されているが，これは物理学・数学的な側面から離陸しつつあることは残念なことである．\nこれらの発展は全て，古典的な遺伝的アルゴリズムのトピックと深く強い関連を持つ．遺伝的アルゴリズムは Holland (1975) によって始められ，それ以降大域的最適化の数値解法に広く用いられている．このアルゴリズムの収束解析は R. Cerf によって1994年から始められ， Del Moral and Miclo (1999) On the Convergence and Applications of the Generalized Simulated Annealing で洗練された．大偏差解析と対数ソボレフ不等式を取り入れた半群の方法によって，遺伝的アルゴリズムの集中性が示された．"
  },
  {
    "objectID": "posts/2023-11-8/index.html#footnotes",
    "href": "posts/2023-11-8/index.html#footnotes",
    "title": "書籍紹介 Del Moral (2004) Feynman-Kac Formulae",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFeynman Lecturesの第1章第2節で，「現代科学最大の発見を1つ挙げるとすると原子論だ」と言っている．粒子法によるモデリングは，人間が理解しやすいモデリングの究極形の1つであるかもしれない．↩︎"
  },
  {
    "objectID": "posts/2023-10-27/index.html",
    "href": "posts/2023-10-27/index.html",
    "title": "Welcome to the newly-opened quarto-based blog | 新ブログ始動",
    "section": "",
    "text": "Hey! We have just branched this blog from WordPress to GitHub. The new version is based on quarto, which will make it much easier to write mathematical sentences, e.g. \\(\\pi(\\theta|x) \\propto \\pi(\\theta) L(x|\\theta)\\), and codes, e.g. \nimport numpy as np\n\ndef fact(n):\n    return np.prod(range(1, n + 1))\nまた日本語での記述も当然できます！ この喜びの詳細はこちらで記述しています．\n\n\n\nimg"
  },
  {
    "objectID": "posts/2023-12-1/BookRecommendation.html",
    "href": "posts/2023-12-1/BookRecommendation.html",
    "title": "Influential Books Which Paved My Path into Mathematics",
    "section": "",
    "text": "I am currently a Ph.D. candidate specializing in Bayesian Computation. I pursued my studies in Mathematics at the University of Tokyo, where I laid a solid foundation to study Statistical Inference for Stochastic Processes, a field renowned for its rigorous and mathematically demanding nature.\nInitially, I had not planed to major in Mathemacis when I embarked on my freshman year with a curious mind.1 However, it was the faculty of the Mathematics Department at the university, along with the books listed below, that awakened my intrinsic interest in Mathematics. In the remainder of this article, I will explore how these books inspired me and molded my style."
  },
  {
    "objectID": "posts/2023-12-1/BookRecommendation.html#footnotes",
    "href": "posts/2023-12-1/BookRecommendation.html#footnotes",
    "title": "Influential Books Which Paved My Path into Mathematics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAt the University of Tokyo, students don’t choose their major until the middle of their sophomore year. In June of the second year, they submit their preferences and the department they will advance to is determined based on their GPA ranking.↩︎\nSome readers might question how a truly new set can be defined, given that the two allowed methods appear quite restrictive. However, this issue is addressed by the axiom that guarantees the existence of the power set \\(P(X)\\) from any existing set \\(X\\). Additionally, it might be helpful to note that the only initial set is the empty set \\(\\emptyset\\). From this, we can generate an infinite hierarchy of power sets starting with \\(\\emptyset\\), accompanied by enormous auxiliary sets constructed in the two aforementioned manners.↩︎\nAs some readers might guess this, the majority of attendees were actually 3rd and 4th-year math students. We sophomores lacked even basic tools from Topology. Surprisingly, my first introduction to topological concepts was through Sheaf Theory.↩︎\nTake, for instance, the theory of Markov Categories, which offers a dual perspective on Probability Theory.↩︎"
  },
  {
    "objectID": "posts/2023-10-29/index.html",
    "href": "posts/2023-10-29/index.html",
    "title": "Serotonin Reduction in Post-acute Sequelae of Viral Infection | ウイルスの腸管持続感染によって血中セロトニン濃度が低下する",
    "section": "",
    "text": "Wong+ (2023) Serotonin reduction in post-acute sequelae of viral infection\n\n\n\n\nimg\n\n\nに衝撃の事実が書かれていました．アブストラクトのみから内容を概略すると，\n\nウイルスが腸管で持続的な感染を起こした場合は、トリプトファンの吸収が免疫活動により阻害されるようで、血液内のセロトニンが減少し、その状態が急性症状が落ち着いた後も戻らず、末梢の迷走神経に機能障害を起こし、認知機能への障害を自覚症状とするブレインフォッグを催す、という作用機序を示唆するデータを示している。ただし全てマウスでのデータ。\nブレインフォッグにSSRI（抗うつ剤だがパニック障害などにも適応あり）やトリプトファンサプリが有効であることを実証。\n以上の機序はあらゆるウイルスによる腸炎で起こるはずだが、SARS-Cov2は腸管感染と腸への持続感染を特に起こしやすく、社会問題化しやすかったという背景がある。\n\n現実とは，一体なんと複雑なのでしょうか．しかし，その一端を掴みつつあることが，とても喜ばしく感じます．\n筆者は過去に家庭教師先の教え子が，コロナウイルスワクチンの接種を機に深刻なブレインフォッグを催し，大学受験を１年遅らせる決断に至るまでを見届けたことがあります．当時はどう調べようにも，情報が限られていました．\nそこから約２年が経ち，その病理に始まり，「コロナに限らないということ」「ブレインフォッグも治るということ」が判ったのは大きな進歩だと感じられます．\nブレインフォッグに限らず，自律神経様の症状（めまいがする，眠れない，集中できない，頭がぼうっとする）は，多くの神経的疾患に付随する症状で，原因特定が難しく（病の原因と思われがちだが結果の場合が多い），周りからの理解が得にくいことが多いです．\nそれぞれの症例に対して，上述のような生理学的な要因が明らかになり，必ずしも心因性ではないこと（ましてや「気のせい」や「病は気から」などとんでもないこと）が周知されることは，このような現代特有の病気をも，現代が再包摂する第一歩になると感じます．"
  },
  {
    "objectID": "posts/2023-11-6/index.html",
    "href": "posts/2023-11-6/index.html",
    "title": "粒子によるビジネスモデルのモデル",
    "section": "",
    "text": "要は僕の専門分野である訳だが，これが今回のビジネスモデルの「骨格」の部分になる．\n状態空間モデル1とは，\n\n状態変数と言われる観測不可能だが興味深い量\\(X_t\\)と，観測変数\\(Y_t\\)の組からなる確率過程\\(\\{(X_t,Y_t)\\}_{t=1}^T\\)のこと．\n\\(Y_t\\)から\\(X_t\\)を推定することを考える（フィルタリング問題2という）．\n次の依存関係を仮定する：\n\n\\(\\{X_t\\}\\)はMarkov過程で，その遷移の仕方\\(X_{t+1}|X_{t}\\)にモデルを立てる．\n観測のモデル\\(Y_t|X_t\\)を立てる． 図で表すと次のような状態である：\n\n\n\n\n\n状態空間モデルで仮定する依存関係の図示\n\n\nこの状態空間モデルのフィルタリング問題を解いて，観測\\(Y_1=y_1,\\cdots,Y_t=y_t\\)から\\(X_t\\)の推定値を得るための方法（アルゴリズム）は多く知られているが，モデル\\(X_{t+1}|X_t,Y_t|X_t\\)が複雑で尤度が明示的な表示を持たない場合でも通用する手法は粒子フィルターのみである．3\n粒子フィルターは，\\(X_t\\)の観測\\(Y_t\\)に関する事後分布を\\(N\\)個の（大量の）粒子によって近似するBayes推定手法で，各\\(Y_t\\)の尤度の情報を重点リサンプリングによって取り入れながらも，計算コスト低く\\(X_t\\)の事後分布を逐次近似していく．\n\n\n\n要は，\\(Y_t\\)を安価に集めて，\\(X_t\\)を高値で売ることを考える．本当にこれをビジネスにするためには，\n\n\\(X_t\\)は多くの人がリアルタイムに知りたいが，（少なくともリアルタイムには）知れない\n\\(Y_t\\)をたくさん集めれば\\(X_t\\)を推測できるが，簡単にはできない（さもなくばレッドオーシャンになってしまうので）\n\nを満たす必要がある．が，意外とこのようなものは多いかも知れない．我々の売りは\n\n\n\n\n\n\n今回のビジネスモデルのコア\n\n\n\nどんなに推定しにくい\\(X_t\\)でも（モデルが複雑で尤度が解析的な表示を持たなくても），十分な情報を含む観測データ\\(Y_t\\)が得られれば，逐次推定できる．\n\n\nということになる．\n\n\n\n最も示唆的と思われる例は，\\(X_t\\)としてGDP，商業販売額などのマクロ指標を取った場合だと思われる．\nマクロ指標は，各企業単体では推測できず，たとえ業界を絞っても各企業の売り上げデータやATM取引データなど，多くのデータを集めて高次元な\\(Y_t\\)を構成しなければ，信頼できる\\(X_t\\)の推定はできないだろう．高次元な\\(Y_t\\)から\\(X_t\\)をフィルタリング際の粒子法は安定せず，現在でも解決されていないオープンクエスチョンである．必然的にブルーオーシャンで誰も参入できない．\nさらに，マクロ指標はフィルタリングすること＝今現在の値を知ることに意味がある．理論的な障壁や技術的な障壁は高いが，経営判断に使ったり，投資判断に使ったり，需要は大きいと思われる．\n\n\n\n以上，例を先に挙げたが，これは「ビジネスモデルの種」になっていて\n\n\\(X_t\\)として需要のある指標・数値\n\\(Y_t\\)として，\\(X_t\\)を推定するのに使える，観測可能＝お金を払えばリアルタイムで手に入る情報\n\\(Y_t|X_t\\)と\\(X_{t+1}|X_t\\)のモデルを立てるためのドメイン知識\n\nが手に入れば，すぐに１つのビジネスモデルになる．\nこれが実はあまりたくさん思いつく訳ではないから，皆さんのアイデアが欲しい．ちなみに，\\(X_t\\)が天気というのがよくあるが，これは民間でやる必要はないし，お金にならないし，\\(Y_t\\)を得るコストが高い気がする．\n個人的には，\\(X_t\\)は個人の体調スコア（あるいは特定の病気のリスク）で，\\(Y_t\\)がApple Watchなどのスマートデバイスからの心拍や体温や移動距離などの測定データ，という属人化医療の場面設定をよく考えるが，粒子フィルタを使うまででもない気がして，AppleやFitBitにそのアルゴリズムを買ってもらえるかというと疑念しかない．\nさらに，\\(Y_t\\)はデータとして広く流通しているわけではないならば（ATM利用データなど），技術力だけでなく，「信頼を得てデータを提供してもらっている」ことが我々の競争力に加わっていき，市場で不動の地位を占めやすいだろう．"
  },
  {
    "objectID": "posts/2023-11-6/index.html#粒子ビジネスモデルモデルの概要",
    "href": "posts/2023-11-6/index.html#粒子ビジネスモデルモデルの概要",
    "title": "粒子によるビジネスモデルのモデル",
    "section": "",
    "text": "要は僕の専門分野である訳だが，これが今回のビジネスモデルの「骨格」の部分になる．\n状態空間モデル1とは，\n\n状態変数と言われる観測不可能だが興味深い量\\(X_t\\)と，観測変数\\(Y_t\\)の組からなる確率過程\\(\\{(X_t,Y_t)\\}_{t=1}^T\\)のこと．\n\\(Y_t\\)から\\(X_t\\)を推定することを考える（フィルタリング問題2という）．\n次の依存関係を仮定する：\n\n\\(\\{X_t\\}\\)はMarkov過程で，その遷移の仕方\\(X_{t+1}|X_{t}\\)にモデルを立てる．\n観測のモデル\\(Y_t|X_t\\)を立てる． 図で表すと次のような状態である：\n\n\n\n\n\n状態空間モデルで仮定する依存関係の図示\n\n\nこの状態空間モデルのフィルタリング問題を解いて，観測\\(Y_1=y_1,\\cdots,Y_t=y_t\\)から\\(X_t\\)の推定値を得るための方法（アルゴリズム）は多く知られているが，モデル\\(X_{t+1}|X_t,Y_t|X_t\\)が複雑で尤度が明示的な表示を持たない場合でも通用する手法は粒子フィルターのみである．3\n粒子フィルターは，\\(X_t\\)の観測\\(Y_t\\)に関する事後分布を\\(N\\)個の（大量の）粒子によって近似するBayes推定手法で，各\\(Y_t\\)の尤度の情報を重点リサンプリングによって取り入れながらも，計算コスト低く\\(X_t\\)の事後分布を逐次近似していく．\n\n\n\n要は，\\(Y_t\\)を安価に集めて，\\(X_t\\)を高値で売ることを考える．本当にこれをビジネスにするためには，\n\n\\(X_t\\)は多くの人がリアルタイムに知りたいが，（少なくともリアルタイムには）知れない\n\\(Y_t\\)をたくさん集めれば\\(X_t\\)を推測できるが，簡単にはできない（さもなくばレッドオーシャンになってしまうので）\n\nを満たす必要がある．が，意外とこのようなものは多いかも知れない．我々の売りは\n\n\n\n\n\n\n今回のビジネスモデルのコア\n\n\n\nどんなに推定しにくい\\(X_t\\)でも（モデルが複雑で尤度が解析的な表示を持たなくても），十分な情報を含む観測データ\\(Y_t\\)が得られれば，逐次推定できる．\n\n\nということになる．\n\n\n\n最も示唆的と思われる例は，\\(X_t\\)としてGDP，商業販売額などのマクロ指標を取った場合だと思われる．\nマクロ指標は，各企業単体では推測できず，たとえ業界を絞っても各企業の売り上げデータやATM取引データなど，多くのデータを集めて高次元な\\(Y_t\\)を構成しなければ，信頼できる\\(X_t\\)の推定はできないだろう．高次元な\\(Y_t\\)から\\(X_t\\)をフィルタリング際の粒子法は安定せず，現在でも解決されていないオープンクエスチョンである．必然的にブルーオーシャンで誰も参入できない．\nさらに，マクロ指標はフィルタリングすること＝今現在の値を知ることに意味がある．理論的な障壁や技術的な障壁は高いが，経営判断に使ったり，投資判断に使ったり，需要は大きいと思われる．\n\n\n\n以上，例を先に挙げたが，これは「ビジネスモデルの種」になっていて\n\n\\(X_t\\)として需要のある指標・数値\n\\(Y_t\\)として，\\(X_t\\)を推定するのに使える，観測可能＝お金を払えばリアルタイムで手に入る情報\n\\(Y_t|X_t\\)と\\(X_{t+1}|X_t\\)のモデルを立てるためのドメイン知識\n\nが手に入れば，すぐに１つのビジネスモデルになる．\nこれが実はあまりたくさん思いつく訳ではないから，皆さんのアイデアが欲しい．ちなみに，\\(X_t\\)が天気というのがよくあるが，これは民間でやる必要はないし，お金にならないし，\\(Y_t\\)を得るコストが高い気がする．\n個人的には，\\(X_t\\)は個人の体調スコア（あるいは特定の病気のリスク）で，\\(Y_t\\)がApple Watchなどのスマートデバイスからの心拍や体温や移動距離などの測定データ，という属人化医療の場面設定をよく考えるが，粒子フィルタを使うまででもない気がして，AppleやFitBitにそのアルゴリズムを買ってもらえるかというと疑念しかない．\nさらに，\\(Y_t\\)はデータとして広く流通しているわけではないならば（ATM利用データなど），技術力だけでなく，「信頼を得てデータを提供してもらっている」ことが我々の競争力に加わっていき，市場で不動の地位を占めやすいだろう．"
  },
  {
    "objectID": "posts/2023-11-6/index.html#todo",
    "href": "posts/2023-11-6/index.html#todo",
    "title": "粒子によるビジネスモデルのモデル",
    "section": "2 ToDo",
    "text": "2 ToDo\nまとめると，僕が提供できるものは高次元・大規模状態空間モデルでの粒子フィルターの研究開発力．これは前節で語ったような「\\(Y_t\\)を集めて\\(X_t\\)を売る」ビジネスモデルを示唆する．\n足りないものは研究成果と実装する時間と仲間と交渉力である．その代わり初期投資は極めて少なくて済む．\n\n2.1 情報収集\n元々は星野研究室の次の研究を知って，新里さんに紹介したときに得た着想であった．\nCard\n「ナウキャスト」「オルタナティブデータを活用した経済分析」と言った言葉でビジネス界で議論されているようだ．特に「ナウキャスト」という名前の会社はこの分野を開拓している．\nナウキャストとエム・データ、機関投資家向けオルタナティブデータ活用で協業\nオルタナティブデータを用いた経済活動分析\n当然粒子法は用いているまい．まずはナウキャストについて知るべし．\n\n\n2.2 懸念\n\n\\(Y_t\\)が高次元と言っても，モデル\\(Y_t|X_t\\)が正確に立てられないのではないか？"
  },
  {
    "objectID": "posts/2023-11-6/index.html#footnotes",
    "href": "posts/2023-11-6/index.html#footnotes",
    "title": "粒子によるビジネスモデルのモデル",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n隠れMarkovモデルともいうが，こう言ったときは状態空間が有限集合であるという制約が暗につく．↩︎\n一方で\\(Y_t\\)から，未来の値\\(Y_{t+1}\\)を予測する問題を「予測問題，\\(Y_{1},\\cdots,Y_t\\)から，過去の状態変数の値\\(X_{s}\\;(s&lt;t)\\)を推定する問題を「平滑化問題」という．↩︎\n\\(Y_t|X_t,X_{t+1}|X_t\\)のいずれも線型Gaussなモデルを仮定した場合は，Kalman filterというもっと効率の良い安価なアルゴリズムが使える．↩︎"
  },
  {
    "objectID": "posts/2023-11-9/index.html",
    "href": "posts/2023-11-9/index.html",
    "title": "書籍紹介 Del Moral (2013) Mean field simulation for Monte Carlo integration",
    "section": "",
    "text": "book cover"
  },
  {
    "objectID": "posts/2023-11-9/index.html#書籍紹介-del-moral-2013-mean-field-simulation-for-monte-carlo-integration",
    "href": "posts/2023-11-9/index.html#書籍紹介-del-moral-2013-mean-field-simulation-for-monte-carlo-integration",
    "title": "書籍紹介 Del Moral (2013) Mean field simulation for Monte Carlo integration",
    "section": "書籍紹介 Del Moral (2013) Mean field simulation for Monte Carlo integration",
    "text": "書籍紹介 Del Moral (2013) Mean field simulation for Monte Carlo integration\nリンクの在処は分かりにくいですが，前文と一部の内容が著者のHPからご覧になれます．\nMean Field Simulation for Monte Carlo Integration | Pierre Del Moral |\n「平均場粒子モデルは非線型発展方程式を確率的に線型化する技法である」とはどういうことか？前文を読むだけでストーリーがあらかた掴めます（が長いです）．"
  },
  {
    "objectID": "posts/2023-11-9/index.html#preface",
    "href": "posts/2023-11-9/index.html#preface",
    "title": "書籍紹介 Del Moral (2013) Mean field simulation for Monte Carlo integration",
    "section": "Preface",
    "text": "Preface\n\nMonte Carlo Integration\n本書は平均場シミュレーションモデルのモンテカルロ積分への応用と理論的基礎を扱う．\nここ30年，このトピックが純粋・応用確率論，ベイズ推論，統計的機械学習，情報理論，理論化学，量子物理，金融数学，信号処理，リスク解析，工学，計算機科学の，最も活発な接点の1つとなっている．\nモンテカルロシミュレーションの源は， Metropolis and Ulam (1949) The Monte Carlo Method であり，MetropolisがUlamのポーカー付きから，モナコの首都にちなんで名付けた．\nモンテカルロ積分の最初の応用はロスアラモス国立研究所でのManhattan計画にて，原子爆弾着火のモデルにおいてSchödinger作用素の基底状態のエネルギーを計算するために用いられたものだ．\nMonte Carlo積分の理論，MCMCとSMC，そして平均場IPS (Interacting Particle Systems)とは，いずれも複雑な確率分布からサンプリングするために用いられる．この文脈では，ランダムサンプルは積分の計算のために用いられる．他の状況で，確率的なアルゴリズムは，逆問題，大域的最適化，事後分布計算，非線形推定問題，統計的学習問題など，複雑な推定問題を解くのにも使われる．\n最も有名なMCMCアルゴリズムはMetropolis-Hastings法だろう． Metropolis and Ulam (1949) The Monte Carlo Method によると，\n\nthe Monte Carlo method is, “essentially, a statistical approach to the study of differential equations, or more generally, of integro-differential equations that occur in various branches of the natural sciences.”\n\nまさにそういうように，「確率測度の空間上の任意の発展モデルは，いつでもMarkov過程のランダムな状態の分布だと解釈できる」ことを強調しておきたい．この観察は，Markov過程と関連する線型発展モデルとの研究ではよく知られていることである．\nさらに面白いことには，Markov過程のランダムな状態の分布と，非線形に相互作用することを許すならば，非線型な発展モデルもMarkov過程の分布とみれる．そのMarkov連鎖のランダムな状態は複雑な確率分布のフローに従い，しばしば解析的な解が存在しない（計算不可能）であることもある．この文脈で，Monte Carlo法と平均場法は，このような複雑系をシミュレーションしたり分析するにあたって，シンプルで安価な方法を提供してくれる．\nこの2点の観察が，本書で展開される平均場粒子理論の大事な到達点である．\n\n\nMean Field Simulation\n平均場IPSの研究は1960年代の Henry McKean の流体力学における非線型楕円型偏微分方程式のMarkov解釈の研究から始まった．\nこの初期の研究から1990年代の半ばにかけて，複数の研究者がこの分野を開拓した．主な内容は非線型Markov連鎖モデルの存在に関連するマルチンゲール問題を解く問題，連続時間IPSモデル（McKean-Vlasov拡散，反応拡散方程式，Boltzmann型相関ジャンプ過程など）のカオスの伝播の記述などであった．古典的な応用は基本的に流体力学，化学，凝縮系物理に制限されていた．\nしかし1990年代の中盤から，平均場IPS手法を，情報理論，工学，計算物理学，統計的機械学習理論におけるMonte Carloシミュレーションへの応用が爆発した．この洗練された，個体群タイプのIPSアルゴリズムは，並列化や分散化された計算環境にも向いていた．その結果，ここ数年来，安価な計算資源の普及に後押しされて，これらの計算機集約的なツールは大きく知名度を上げた．この発展的なMonte Carlo積分法は，決定論的な関数射影アルゴリズムやグリッドを用いるアルゴリズムが低次元空間における線型モデルにしか使えない弱みを補完する手法を提供している．\n古典的なMCMC法と違って，平均場IPS法の大きな美点は，正確性を司るパラメータは，何か固定された目的分布とも，予備動作時間とも関係なく，ただ粒子数 \\(N\\) のみに依存する，という点である．つまり，IPS算譜を動かす計算機の並列計算力などのみに依存して，正確性を発揮することが出来るということである．\n過去20年，非線型フィルタリング問題や複雑なBayes事後分布を計算したり，遺伝的手法で最適化問題を解いたりする中で，新たなクラスの平均場PISサンプラーが発明された．こうして，古典的な流体力学モデルから，種々の科学分野で見られる様々な非線型問題に，射程を広げつつある．\n非線型フィルタリング問題への応用は，乱流についての流体力学や，天気予報の問題で生じる．最近では空間的点過程への応用が進んでいるが，これは生態系モデリング，生物学，疫学，地震，物質科学，待ち行列理論，天文学など種々の分野で見つかる．\nさらに最近では金融への応用も盛んである．粒子法の稀事象解釈を通じて，信頼のおけるポートフォリオが同時にデフォルトを起こす確率のシミュレーションを行っている研究が Carmona, Fouque and Vestal (2009) にある．\nさらに最近には，ジャンプ拡散過程による価格モデルで，ジャンプ時刻やジャンプサイズなどの潜在変数をフィルタリングする研究もある．粒子法は，確率的最適化アルゴリズムの構築にも使えるが，これも金融数学の分野で応用が進みつつある．これは複数の最小値点が存在する場合でも使える手法として Ben Hamida and Cont (2005) が開拓している．\nさらに分岐するIPSは，直接生物学や自然淘汰理論のモデルとして応用が進んでいる．\nこの文脈で，平均場ゲーム理論にも触れねばならないだろう．ここで「流体粒子」に当たるものはエージェント（または会社）とみなされ，ある報酬関数に対して最適な行動を取るように，社会経済的な環境で競争をしていく様子をモデリングする．\nKolokoltsovにより，大量のエージェントを備えるゲーム理論の生物学・経済学・ファイナンスへの応用が進んでいる．平均場ゲームのHamilton-Jacobi非線型方程式を解くための有限差分法の研究も同時に進んでいる．\n\n\nA Need for Inter-diciplinary Research\nこの平均場シミュレーション理論には多くの分野の研究者が参入していることは，その文献の多さが証明している．しかし，これらの異なる分野の間のコミュニケーションは非常に難しいことで，実際まだまだ伸び代がある．実際，平均場Feynman-Kacモデルは多くの別の名前で知られている．\n\nIn physics, engineering sciences, as well as in Bayesian statistical analysis, the same interacting jump mean ﬁeld model is known under several lively buzzwords; to name a few: pruning [403, 549], branching selection [170, 286, 484, 569], rejuvenation [8, 134, 275, 336, 490], condensation [339], look-ahead and pilot exploration resampling [263, 403, 405], Resampled Monte Carlo and RMC methods [556], subset simulation [20, 21, 22, 396, 399], Rao-Blackwellized particle filters [280, 444, 457], spawning [138], cloning [310, 500, 501, 502], go-with-the-winner [7, 310], resampling [324, 522, 408], rejection and weighting [403], survival of the fittest [138], splitting [121, 124, 282], bootstrapping [43, 289, 290, 409], replenish [316, 408], enrichment [54, 336, 262, 374], and many other botanical names.\n\n一方で，多くの応用的な研究が，数学的な側面については盲目に突き進んでいるという現状もある．結果として，多くの応用的な研究で平均場IPSモデルが自然言語的に直感的に提示され，全くパフォーマンス解析もロバスト性や安定性に対する言及もなく使われている．\n逆に数学的な側面の研究についても，多くの未解決問題が存在する．数理統計楽や確率論の研究者は，現在の多くの応用研究で進行中の研究を注視する必要がある．より豊かな応用数学と応用科学のためには，学際的な交流が欠かせないと考える．\nそのためには，統一的な数学的基盤，共通言語というのが欠かせないだろう．この本は，Monte Carlo積分に対する平均場シミュレーションの技術に対して最新の取り扱いを統一的に記述することで，複数の分野を橋渡しするためにある！この本が確率論研究者，応用統計家，生物学者，統計物理学者，計算機科学者が，互いの障壁を乗り越える一助になることを願っている．\n古典的なMonte Carlo法やシミュレーション法本は数え切れないにも拘らず，平均場シミュレーション理論を扱った書籍は少ない．\n本書は Del Moral (2004) と確率論セミナー (2000)，そしてさらに新しいサーベイ (2012) の続編とみなすことができる．本書は，Feynmna-Kacモデルだけでなく，McKean-Vlasovモデルや分岐相関ジャンプ過程などの種々のIPSアルゴリズムに応用可能な平均場理論も提供する．\n\n\nUse and Interpretations of Mean Field Models\n特に強調したいことは，本書で扱うほとんどの平均場IPSアルゴリズムは数学的には全く等価であり，ただ解釈の仕方が，その応用分野に依って異なるのみである．\n流体力学と計算物理学において，平均場粒子モデルはマクロ物理量がミクロ変数の分布と相互作用しながら発展していく系のモデルになる．例えば期待，マクロ流体モデルや，分子系である．中心的なアイデアは，2次の摂動項を無視することで，分布の空間上の閉じた非線型発展方程式に還元することである．このモデルの平均場極限は，（多くの場合微分／積分方程式の言葉で）物理量の発展を記述する．\n計算生物学や個体群動態学では，生誕・死亡や競争選択の過程によって，平均場遺伝的粒子モデルが構成される．このモデルの平均場極限はしばしば「無限人口モデル (infinite population model)」と呼ばれる．\n計算機科学では，平均場遺伝的IPSアルゴリズムは複雑な最適化問題を解くための確率的探索手法として使われる．この場合のモデルの平均場極限は，ある種の適合度を表すポテンシャル関数に付随するBoltzmann-Gibbs測度によって与えられる．\n信号処理と機械学習理論において，平均場IPSモデルは逐次Monte Carloサンプラーとも呼ばれる．名前の通り，このモデルは，複雑性が増していく確率分布の列から逐次的にサンプリングをするために用いられる．状態空間は，稀事象シミュレーションではexcursion space，逐次重点サンプリングでは遷移状態空間，フィルタリングと平滑化問題では見本道の空間である．信号処理の分野においては，この手法は「粒子フィルター」とも呼ばれる．このモデルにおいて，平均場極限は，ある事象について条件づけた際の確率過程の条件付き分布の発展方程式系になる．線型Gaussモデルにおいて，最適フィルターは，平均と分散がKalmanフィルターによって逐次的に与えられるような条件付きGauss分布になる．この設定において，その発展方程式はMcKean-Vlasov拡散モデルとみなせる！この平均場モデルは，気象予測とデータ同化の分野で用いられているアンサンブルKalmanフィルターに一致するのである．\n物理学と分子化学において，平均場IPS発展モデルは多体Schödinger発展方程式の基底状態のエネルギーの推定に用いられる．この設定において，「粒子」と呼ぶと物理的対象と混同してしまうため，”walker”（探索者）と呼ばれる．この確率的な発展モデルは QMC (Quantum Monte Carlo) または DMC (Diffusion Monte Carlo) 法と呼ばれる．この手法は多体系の状態空間上での経路積分を近似するために設計される．このモデルの平均場極限は正規化されたSchrödinger方程式になる．したがって，このモデルの非線型半群の長期的な振る舞いは，Schrödinger作用素の最大固有値と基底状態のエネルギーに関連を持つのである．\n確率論において，平均場IPSモデルは2通りの解釈を持つ．1つ目の見方として，粒子系は，目的の発展方程式の解を，逐次的に経験測度の空間へ射影しているとみれる．より正確に，平均場IPSモデルの定める経験測度は，この削減された有限次元状態空間上のMarkov過程として発展していく．従来のMCMC法は単一の確率過程の長期的な振る舞いに基づいて設計されていたのと対照的に，平均場IPSのMarkov過程は \\(N\\) 個の状態空間上の積上で発展する．この意味で「平均場粒子モデルは非線型発展方程式を確率的に線型化する技法である」と言える．2つ目の見方は，分布の空間上の非線型発展方程式の新たな確率的摂動論という見方である．粒子の集団の局所的なサンプリングの推移は，現在の粒子の経験測度に依存するので，局所的なサンプリング誤差を系に導入する．粒子はこの摂動を持ちながら非線型発展方程式に従っている，と見れるのである．\n\n\nA Unifying Theoretical Framework\n本書の大半は，「平均場理論の離散世代と分布空間上の非線型発展方程式への応用」を扱う．ほとんどのモデルは，連続時間における測度値過程を，離散時間で近似することで生じる．物理学，金融，生物学分野での連続時間モデルの重要性を鑑みて，本書の多くの部分は離散時間測度値過程とその連続時間の場合（特に線型・非線型微分・積分方程式）との関連も取り扱っている．\n古典的なMCMC法の平衡への収束に関する解析で用いられている数学と，我々が用いる数学とは大きく異なる．加えて，従来のMonte Carloサンプラーと対照的に，平均場IPSモデルは統計的に独立な粒子を取り扱っている訳ではないから，従来の大数の法則の知識を直接適用して相関粒子系によるサンプラーの解析に用いることは出来ない．\n直近に発展した，連続時間の相関粒子系の解析は，「カオスの伝播」という性質と漸近理論に基づいており，エルゴード的な性質や指数集中性については全く判っていなかった．\n筆者の知る限り，離散世代平均場粒子モデル，時間パラメータに対する一様な定量的推定とその非線型フィルタリング問題への応用とについての最初の研究は，Del Moral (1996), Del Moral (1998) である．その後この研究は更なる発展を遂げ，多くの応用を持った．\n離散世代平均場モデルの収束解析を進めるにあたって，次の数学理論を使うことになるだろう：分布空間上の非線型半群，相関を持つ経験過程理論，指数集中不等式，時間上限 \\(T\\) に関する一様収束推定，汎函数揺動定理．さらにこれらの複合を用いることが日常茶飯事である．例えば，一様指数集中不等式は，後ろ向き非線型半群と，分布空間上の1次のTaylor展開， \\(L^m\\)-平均誤差推定，Orliczノルム解析とLaplace近似を用いる．\n時間上限 \\(T\\) の一様定量的 \\(L^m\\)-平均誤差バウンドと一様集中不等式とは，非線型半群の極限的な安定性に関する振る舞いに依存する．このような，平均場粒子モデルの長期的な振る舞いと，測度のフローの極限的な安定性とが関連しているというタイプの結果は新しいものではない．\n離散世代遺伝的粒子モデルの解析は，系統樹モデル，部分的に観測された分岐過程，粒子自由エネルギー，後ろ向きMarkov粒子モデルなど，他の数学モデルとも深い繋がりを持っている．本書の大部分は，半群理論と確率的摂動理論とを組み合わせて，種々の相関粒子系の収束を示す，という議論を抽象的に行う．\nいま，抽象的で一般的な非線型発展方程式の解析で苦しんでいる人の苦悩は，本書を読めば，すぐに解決されるかもしれない．というのも，平均場相関粒子近似は，すぐさまに強力なMonte Carloシミュレーション法を与えるからである．このタイプの叙述も，McKean-Vlasov拡散モデルと，Feynman-Kac分布フローと，空間分岐発展モデルなどとについて行った．\n本書は，現状強力な道具となっているカオスの伝播の性質や，Berry-Esseen定理や，漸近的な大偏差原理については触れない．これらは Del Moral (2004) を参照のこと．\n\n\nA Contents Guide\n本書の中心的なテーマは平均場シミュレーション理論の，分布空間上の非線型発展方程式への応用である．\n初めの第1章と第2章は概観を提供する．この2つの章は読み飛ばすべきではない．\n理論の基礎はMarkov過程である．線型だろうと非線型だろうと，発展方程式の解析においてMarkov過程は中心的な役割を果たす．分布の空間上の発展モデルは常にランダムな状態を持つMarkov過程の分布として解釈できる．この同一視により，Markov過程の理論が，分布値の方程式を，そのMarkov過程からランダムにサンプリングすることで解く方法を示唆する．この抽象的な理論を，種々の応用例で解説しているのが第1章である．\n第2章はMcKean-Vlasov拡散モデル，Feynman-Kacモデルを，種々の応用の中で見ていく．\n第3章はFeynman-Kacモデルを導入し，応用を見る．\n第4章で，Feynman-Kacモデルの4つの等価な解釈を見る．それは分岐過程による解釈とそれが導く遺伝的アルゴリズム(GA)，逐次Monte Carlo法を導く解釈(SMC)，相関を持つMCMCサンプラーを導く解釈(i-MCMC)，そして最後に平均場相関粒子系としての解釈である(IPS)．\n数学的な観点からは，いずれの解釈も全く等価である．しかしながら，それぞれの解釈は異なるアルゴリズムを導く．\nさらに，McKean-Vlasov拡散モデルも，平均場Feynman-Kacモデルと結びつくということを強調しておきたい．この種の平均場IPSフィルタリングモデルは乱流流体力学や気象予測問題における非線型フィルタリング問題を解くのに使われている．\n第5章で，離散世代Feynman-Kacモデルとその連続時間バージョンとの関係を述べる．\n第6章で，\n本書の第II部は，平均場IPS理論を種々の科学分野への応用を扱う．"
  },
  {
    "objectID": "posts/2023-11-10/index.html",
    "href": "posts/2023-11-10/index.html",
    "title": "Pierre Del Moral 著作まとめ",
    "section": "",
    "text": "HPも参照．"
  },
  {
    "objectID": "posts/2023-11-10/index.html#feynman-kac模型についての本",
    "href": "posts/2023-11-10/index.html#feynman-kac模型についての本",
    "title": "Pierre Del Moral 著作まとめ",
    "section": "1 Feynman-Kac模型についての本",
    "text": "1 Feynman-Kac模型についての本\n\n1.1 Del Moral and Penev (2014) Stochastic Processes\n\n\n1.2 Del Moral (2013) Mean Field Simulation for Monte Carlo Integration\n\n\n1.3 Del Moral (2004) Feynman-Kac Formulae\n\n\n1.4 Del Moral and Miclo (2000) in Seminaire de Probabilites XXXIV\nDel Moral and Miclo (2000) Branching and interacting particle systems approximations of feynman-kac formulae with applications to non-linear filtering"
  },
  {
    "objectID": "posts/2023-11-10/index.html#feynman-kac模型についてのレビュー",
    "href": "posts/2023-11-10/index.html#feynman-kac模型についてのレビュー",
    "title": "Pierre Del Moral 著作まとめ",
    "section": "2 Feynman-Kac模型についてのレビュー",
    "text": "2 Feynman-Kac模型についてのレビュー\n\n2.1 Del Moral+ (2012) On the Concentration Properties of Interacting Particle Processes\nDel Moral, P., Hu, P. and Wu, L. (2012) On the Concentration Properties of Interacting Particle Processes. Foundations and Trends in Machine Learning, 3(3-4): 255-389.\nINRIAにもpdfあり．\n\n\n2.2 Del MoralのHP"
  },
  {
    "objectID": "posts/2023-11-10/index.html#その他レビュー",
    "href": "posts/2023-11-10/index.html#その他レビュー",
    "title": "Pierre Del Moral 著作まとめ",
    "section": "3 その他レビュー",
    "text": "3 その他レビュー\n\n3.1 ランダム行列理論： Bishop, Del Moral, and Angele (2018) An Introduction to Wishart Matrix Moments\nBishop, A., Del Moral, P. and Angele, N. (2018) An Introduction to Wishart Matrix Moments. Foundations and Trends in Machine Learning, 11(2): 97-218."
  },
  {
    "objectID": "posts/2023-11-11/index.html",
    "href": "posts/2023-11-11/index.html",
    "title": "Markov Category (nLab) | 紹介",
    "section": "",
    "text": "nLabとは，圏論的な視点から種々の数学・物理学・哲学の概念をまとめた，有志によって運営されているウィキである．今回はMarkov圏のページを翻訳．\n\n\n\nimg\n\n\n\n1．アイデア\nMarkov圏の概念は，確率統計学の綜合的(synthetic)な側面を表現する方法の1つである．すなわち，確率統計学を基礎付ける構造と公理からなり，これを用いて測度論を介することなく直接的に種々の定理が示せる．通常の測度論的な議論は，綜合的確率論のモデル（意味論）の1つであると見なされる．\n直感的に言えば，Markov圏とは射が「確率変数」または「Markov核」（ここから名前がついた）と見なせるような，確率論で用いられる圏である．標準的な例に，Kleisli圏や確率モナドがあるが，Markov圏は更に一般的な枠組みである．\n\n\n2．定義\nMarkov圏とは，半デカルト対称モノイダル圏 \\((C,\\otimes,1)\\) であって，その対象 \\(X\\in C\\) が可換な内部余モノイドの構造を持つものである．余乗法と余単位写像は \\(\\mathrm{copy}:X\\to X\\otimes X\\) と \\(\\mathrm{delete}:X\\to1\\) とそれぞれ表される．\n複製写像とテンソル積の間に次の整合性条件を課す：任意の対象 \\(X,Y\\in C\\) に対して，\n\\[\n\\mathrm{copy}_{X\\otimes Y}=(\\mathrm{id}_X\\otimes b_{Y,X}\\otimes\\mathrm{id}_Y)(\\mathrm{copy}_X\\otimes\\mathrm{copy}_Y).\n\\]\nただし， \\(d\\) でブライダルを表す．\nまた，写像 \\(\\mathrm{delete}:X\\to 1\\) は， \\(1\\) が終対象であることから一意的であるため，更に \\(X\\) 内で自然であることに注意．一方で，複製写像は自然とは限らない．\n\n\n3．注\n\nA Markov category can equivalently be defined as a semicartesian symmetric monoidal category that supplies commutative comonoids.\n\n\n\n4．例\n\n有限集合と確率行列のなす圏 \\(\\mathtt{FinStoch}\\) ．\n可測空間とMarkov核のなす圏 \\(\\mathtt{Stoch}\\) ．\n任意のデカルトモノイダル圏 \\(C\\) が，モノイド単位を保存するモノイダルモナド \\(T\\) を持つならば，そのKleisli圏 \\(\\mathrm{Kl}(T)\\) はMarkov圏になる．\n\n\n\n5．決定論的な射\nMarkov圏の射 \\(f:X\\to Y\\) が決定論的であるとは，複製写像と可換であることをいう：\n\\[\n\\mathrm{copy}\\circ f=(f\\otimes f)\\circ\\mathrm{copy}.\n\\]\nこの定義のモチベーションは以下の通りである． \\(f\\) が例えば実数上の実確率変数で，入力に，サイコロの目を振ってでた値を加えるような関数であるとしよう．すると，入力 \\(x\\in\\mathbb{R}\\) に対して，サイコロを振り，出た目 \\(n\\in[6]\\) を加えて得た結果をコピーするから，左辺は \\((x+n,x+n)\\) である．一方で，まず入力 \\(x\\in\\mathbb{R}\\) を複製写像 \\(\\mathrm{copy}\\) に渡し， \\((x,x)\\) を得た後でサイコロを2回降り，出た目 \\(n_1,n_2\\in[6]\\) をそれぞれ加えると，右辺は \\((x+n_1,x+n_2)\\) となるが，別々の試行で出た目が一致する \\(n_1=n_2\\) とは限らない．この性質を，「ランダム性」の定義とする，というのである：つまりランダム性とは，2回行ったときに結果が異なり得る，という過程に宿るものとする．また，同値なことだが，その過程の前に情報を複製することと，その過程を見た後に情報を複製することとで，異なる状況を与えるような「過程」のことだとも理解できる．\n\n\n10．参考文献\nTobias Fritz（現在オーストリアInnsbruck大学）がこの分野の騎手であり，他にホモトピー型理論のレクチャーノートも執筆している．\n\nTobias Fritz (2019) A synthetic approach to Markov kernels, conditional independence and theorems on sufficient statistics. (arXiv:1908.07021)\nTobias Fritz and Eigil Fjeldgren Rischel (2019) The zero-one laws of Kolmogorov and Hewitt–Savage in categorical probability. (arXiv:1912.02769)\n\nこの研究の流れは，Bart Jacobsによるchannel perspectiveを汲んでいる．彼らは同様の概念をaffine CD-圏と呼んでいたようだ．\n\nBart Jacobs and Fabio Zanasi (2018) The Logical Essentials of Bayesian Reasoning. (arXiv:1804.01193)"
  },
  {
    "objectID": "posts/2023-12-2/条件付き期待値の問題.html",
    "href": "posts/2023-12-2/条件付き期待値の問題.html",
    "title": "条件付き期待値の測度論的基礎付け",
    "section": "",
    "text": "条件付き期待値を，測度論から厳密に定義する際，ポイントは次の4点である．\n\n$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$\n\n\n\n\n\n\n\nポイント\n\n\n\n\n条件付き期待値は \\(\\sigma\\)-代数 \\(\\mathcal{G}\\) に対して \\(\\mathrm{E}[X|\\mathcal{G}]\\) の形で（\\(\\Omega\\) 上殆ど至る所）定義される確率変数である．\n\\(\\mathrm{E}[X|Y]\\) というのは，\\(\\mathrm{E}[X|\\sigma(Y)]\\) の略記である．\n\\(\\mathrm{E}[X|Y=y]\\) というのは，\\(\\mathrm{E}[X|\\sigma(Y)](Y^{-1}(y))\\) のことである．\n\\(X\\in L^2(\\Omega)\\) でもあるとき，\\(\\mathrm{E}[X|\\mathcal{F}]\\) は \\(X\\) に \\(L^2(\\Omega)\\)-距離で最も近いような \\(\\mathcal{F}\\)-可測確率変数である．\n条件付き確率は \\(\\mathrm{P}[Y\\in B|X]:=\\mathrm{E}[1_{\\left\\{Y\\in B\\right\\}}|X]\\) と定義する．\n\n\n\n\n\n\n\n\n\n\n\n定義（条件付き期待値）\n\n\n\n\\((\\Omega,\\mathcal{F},\\mathrm{P})\\) を確率空間とし，\\(\\mathcal{G}\\) を \\(\\mathcal{F}\\) の部分 \\(\\sigma\\)-代数とする．可積分確率変数 \\(X\\in\\mathcal{L}^1(\\Omega)\\) について， 次の2条件を満たす，\\(\\mathrm{P}\\)-零集合を除いて一意な確率変数を条件付き期待値といい，\\(\\mathrm{E}[X|\\mathcal{G}]\\) で表す．\n\n\\(\\mathcal{G}\\)-可測でもある \\(\\mathrm{P}\\)-可積分確率変数である．\n任意の \\(\\mathcal{G}\\)-可測集合 \\(B\\in\\mathcal{G}\\) 上では \\(X\\) と期待値が同じ確率変数になる：\\[\\mathrm{E}[X1_B]=\\mathrm{E}[\\mathrm{E}[X|\\mathcal{G}]1_B]\\]\n\n\n\n\\[\\mathrm{E}[X,B]:=\\mathrm{E}[X1_B]\\] という記法を採用すれば，条件2は \\[\\mathrm{E}[X,B]=\\mathrm{E}[\\mathrm{E}[X|\\mathcal{G}],B]\\] と書くこともできる．\n\n\n\n\n\n\n証明\n\n\n\n定義の2条件のみから，\\(\\mathrm{E}[X|\\mathcal{G}]\\) が \\(\\mathrm{P}\\)-零集合を除いて一意に定まること（とその存在）を示す．\n\\[Q(B):=\\mathrm{E}[X,B]=\\mathrm{E}[1_BX]\\;(B\\in\\mathcal{G})\\] とおくことで，\\(Q\\) は可測空間 \\((\\Omega,\\mathcal{G})\\) 上の確率測度を定める． いま，\\(\\mathrm{P}|_\\mathcal{G}\\) に関して \\(Q\\) は絶対連続になっている：\\[\\forall_{B\\in\\mathcal{G}}\\;P(B)=0\\Rightarrow Q(B)=0.\\] これより，Radon-Nikodymの定理から， ある \\(\\mathcal{G}\\)-可測で \\(\\mathrm{P}\\)-可積分な可測関数 \\(Y:\\Omega\\to\\mathbb{R}\\) が，\\(\\mathrm{P}\\)-零集合上での違いを除いて一意的に存在して，\\[\\forall_{B\\in\\mathcal{G}}\\;Q(B)=\\int_BY(\\omega)P(d\\omega)\\] が成り立つ． よって，条件付き期待値 \\(Y\\) は確かに存在して（同値類 \\(L^1(\\mathrm{P})\\) の元としては）一意的で，(1),(2)が成り立つ．\n\n\n(Dudley, 2002, pp. 10.1節 p.336), (吉田朋広, 2006, p. 43) がおすすめな参照先．(舟木直久, 2004, p. 88) が入門しやすい．\\(X\\in L^2(\\Omega)\\) でいい場合は，より「射影」としてわかりやすい特徴付けがある（ Section 1.3 ）．これのおすすめは (Jacod & Protter, 2004, pp. 第23節 p.200), (Kallenberg, 2021, p. 164)．\n\n\n\n\n\n\n\n\n\n定義（確率変数を与えた下での条件付き期待値）\n\n\n\n\\((E,\\mathcal{E})\\) を可測空間とする．確率変数 \\(X\\in\\mathcal{L}(\\Omega;E)\\) による \\(Y\\in\\mathcal{L}^1(\\Omega)\\) の条件付き期待値は，次を満たす可測関数 \\(\\mathrm{E}[Y|X=-]:E\\to\\mathbb{R}\\) のことをいう： \\[\n\\begin{align*}\n\\forall_{B\\in\\mathcal{E}}\\quad&\\int_{X^{-1}(B)}Y(\\omega)P(d\\omega)\\\\\n&\\quad=\\int_B\\mathrm{E}[Y|X=x]P^X(dx).\n\\end{align*}\n\\]\n\n\nすると，\\(X\\) が \\(\\Omega\\) 上に引き戻す \\(\\sigma\\)-代数 \\[\n\\sigma(X):=\\left\\{A\\subset\\Omega\\mid\\exists_{B\\in\\mathcal{E}}\\; X^{-1}(B)=A\\right\\}\n\\] を与えた下での条件付き期待値 \\(\\mathrm{E}[Y|\\sigma(X)]\\) と，次のように関係する．1 \\(\\mathrm{E}[Y|\\sigma(X)]\\) は定義 Section 1.1 1から \\(\\sigma[X]\\)-可測であるが，可測性の特徴付け（後述）から，これはあるBorel可測関数 \\(f\\) について，\\[\\mathrm{E}[Y|X]=f(X)\\;\\;\\mathrm{a.s.}\\] と表せる．この \\(f:\\mathcal{X}\\to\\mathbb{R}\\) が，\\(X\\) を与えた下での \\(Y\\) の条件付き期待値 \\(\\mathrm{E}[Y|X=-]\\) である．\nこの記法 \\(\\mathrm{E}[Y|X=x]\\) とは何かというと，\\(X\\) の値域 \\(\\mathcal{X}\\) 上の関数として，新たに \\[\\mathrm{E}[Y|X=x]:=f(x)\\;\\;\\mathrm{a.s.}\\] と書くことにするのである．2 すると， \\[\n\\mathrm{E}[Y|X=x]|_{x=X(\\omega)}=\\mathrm{E}[Y|X](\\omega)\\;\\;\\mathrm{a.s.}\n\\] も満たす．つまり，次の図式が可換である：\n\n\n\nCommutative Diagram for Conditional Expectations\n\n\n\n\n\n\n\n\n命題（Doobの汎函数表現）\n\n\n\n\\(S\\) を位相空間，\\(X\\in \\mathcal{L}(\\Omega;S),Y\\in \\mathcal{L}(\\Omega)\\) を確率変数とする．次は同値：\n\n\\(Y\\)は \\(\\sigma(X)\\)-可測．\nあるBorel可測関数 \\(f:S\\to\\mathbb{R}\\) が存在して，\\(Y=f(X)\\) を満たす．\n\n\n\n\n\n\n\n\n\n証明\n\n\n\n2 \\(\\Rightarrow\\) 1 はすぐに従う．任意の \\(B\\in\\mathcal{B}(\\mathbb{R})\\) について，\\(f^{-1}(B)\\in\\mathcal{B}(S)\\) であるから， \\[Y^{-1}(B)=X^{-1}(f^{-1}(B))\\in\\sigma(X).\\] あとは 1 \\(\\Rightarrow\\) 2 を示せば良い．3段階で示す．\n\nまず \\(Y\\) が単関数 \\[Y=\\sum_{i=1}^nc_i1_{A_i},\\qquad c_i\\ne c_j\\;(i\\ne j).\\] の場合について示す．仮定より \\(A_i\\in\\sigma(X)\\) であるから，ある \\(B_i\\in\\mathcal{B}(S)\\) が存在して \\(A_i=X^{-1}(B_i)\\)．よって， \\[f(x):=\\sum_{i=1}^nc_i1_{B_i}(x).\\] と定めると \\(Y=f(X)\\)．\n次に \\(Y\\ge0\\;\\;\\mathrm{a.s.}\\) の場合を考えると，正な単関数の単調増加列 \\(\\{Y_n\\}\\) で \\(Y\\) に収束するものが取れる．各 \\(Y_n\\) について，\\(f_n\\in\\mathcal{L}(S)\\) が存在して \\(Y_n=f_n(X)\\) が成り立つ．このとき，\\(f:=\\limsup_{n\\to\\infty}f_n\\) と定めれば， \\[\\begin{align*}\nY&=\\limsup_{n\\to\\infty}Y_n\\\\\n&=(\\limsup_{n\\to\\infty}f_n)(X)=f(X).\n\\end{align*}\\]\n一般の場合は \\(Y=Y^+-Y^-\\) の分解から従う．\n\n\n\n(Dudley, 2002, pp. 定理4.2.8 p.128) は \\(S=\\mathbb{R}\\) の場合，(Landkov, 1972) は \\(S=\\mathbb{R}^m\\) の場合, (Kallenberg, 2021, pp. 補題1.14 p.18) に一般の標準Borel空間の場合の証明がある．\n\n\n\n\\(L^2(\\Omega)\\subset L^1(\\Omega)\\) 上に議論を制限してみると，実は \\(\\mathcal{F}\\) の部分 \\(\\sigma\\)-代数 \\(\\mathcal{G}\\) に関する条件付き期待値は，部分空間 \\[\nL^2_\\mathcal{G}(\\Omega):=\\left\\{X\\in L^2(\\Omega)\\mid X\\,\\text{は}\\,\\mathcal{B}(\\mathbb{R})/\\mathcal{G}\\,\\text{-可測}\\right\\}\n\\] への射影になっている．\n\n\n\n\n\n\n定理（条件付き期待値の特徴付け）\n\n\n\n部分 \\(\\sigma\\)-代数 \\(\\mathcal{G}\\subset\\mathcal{F}\\) と \\(X\\in\\mathcal{L}^2(\\Omega)\\) を考える． 任意の \\(\\widehat{X}_\\mathcal{G}\\in\\mathcal{L}^2_\\mathcal{G}(\\Omega)\\) について，次は同値：\n\n\\(\\widetilde{X}_\\mathcal{G}\\) は \\(X\\) の \\(L^2_\\mathcal{G}(\\Omega)\\) への射影である：\\[\\|X-\\widehat{X}_\\mathcal{G}\\|_{L^2(\\Omega)}=\\inf_{X'\\in\\mathcal{L}^2_\\mathcal{G}(\\Omega)}\\|X-X'\\|_{L^2(\\Omega)}\\]．\n\\(\\widetilde{X}_\\mathcal{G}\\) は \\(X\\) の条件付き期待値である：\\[\\forall_{Z\\in L^2_\\mathcal{G}(\\Omega)}\\;\\mathrm{E}[ZX]=\\mathrm{E}[Z\\widehat{X}_\\mathcal{G}].\\]\n\n\n\n\n\n\n\n\n\n\n\n\n定義（条件付き確率）\n\n\n\n\\((\\Omega,\\mathcal{F},\\mathrm{P})\\) を確率空間，\\(\\mathcal{G}\\subset\\mathcal{F}\\) を部分 \\(\\sigma\\)-代数とする．\\(\\mathcal{G}\\) の定める条件付き確率を， \\[\n\\mathrm{P}[B|\\mathcal{G}](\\omega):=\\mathrm{E}[1_B|\\mathcal{G}](\\omega)\\;(B\\in\\mathcal{F})\n\\] で定める．\n\n\nしかしこの定義には問題がある．条件付き期待値 \\(\\mathrm{E}[X|\\mathcal{G}]\\) が \\(\\Omega\\) 上 \\(\\mathrm{P}\\text{-a.e.}\\) でしか定まらない（場合がある）から，\\(\\mathrm{P}\\) も一般には可算加法性をa.s.にしか満たさない： \\[\n\\mathrm{P}\\left[\\bigcap_{n\\in\\mathbb{N}}A_n\\,\\middle|\\,\\mathcal{G}\\right]=\\sum_{n\\in\\mathbb{N}}\\mathrm{P}[A_n]\\;\\;\\mathrm{a.s.}\n\\] この式自体は後述の単調収束定理（ Section 2.3 ）から示せる．\nだが，\\(\\mathcal{G}\\) がある完備可分距離空間に値を取る確率変数 \\(Y\\) について \\(\\mathcal{G}=\\sigma(Y)\\) である場合など，殆どの場合で，うまく \\(\\mathrm{P}\\) を取ることが出来る．3 このように，a.s.抜きで正式に確率測度として定まる場合を，正則条件付き確率と呼び分ける．"
  },
  {
    "objectID": "posts/2023-12-2/条件付き期待値の問題.html#条件付き期待値の定義",
    "href": "posts/2023-12-2/条件付き期待値の問題.html#条件付き期待値の定義",
    "title": "条件付き期待値の測度論的基礎付け",
    "section": "",
    "text": "条件付き期待値を，測度論から厳密に定義する際，ポイントは次の4点である．\n\n$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$\n\n\n\n\n\n\n\nポイント\n\n\n\n\n条件付き期待値は \\(\\sigma\\)-代数 \\(\\mathcal{G}\\) に対して \\(\\mathrm{E}[X|\\mathcal{G}]\\) の形で（\\(\\Omega\\) 上殆ど至る所）定義される確率変数である．\n\\(\\mathrm{E}[X|Y]\\) というのは，\\(\\mathrm{E}[X|\\sigma(Y)]\\) の略記である．\n\\(\\mathrm{E}[X|Y=y]\\) というのは，\\(\\mathrm{E}[X|\\sigma(Y)](Y^{-1}(y))\\) のことである．\n\\(X\\in L^2(\\Omega)\\) でもあるとき，\\(\\mathrm{E}[X|\\mathcal{F}]\\) は \\(X\\) に \\(L^2(\\Omega)\\)-距離で最も近いような \\(\\mathcal{F}\\)-可測確率変数である．\n条件付き確率は \\(\\mathrm{P}[Y\\in B|X]:=\\mathrm{E}[1_{\\left\\{Y\\in B\\right\\}}|X]\\) と定義する．\n\n\n\n\n\n\n\n\n\n\n\n定義（条件付き期待値）\n\n\n\n\\((\\Omega,\\mathcal{F},\\mathrm{P})\\) を確率空間とし，\\(\\mathcal{G}\\) を \\(\\mathcal{F}\\) の部分 \\(\\sigma\\)-代数とする．可積分確率変数 \\(X\\in\\mathcal{L}^1(\\Omega)\\) について， 次の2条件を満たす，\\(\\mathrm{P}\\)-零集合を除いて一意な確率変数を条件付き期待値といい，\\(\\mathrm{E}[X|\\mathcal{G}]\\) で表す．\n\n\\(\\mathcal{G}\\)-可測でもある \\(\\mathrm{P}\\)-可積分確率変数である．\n任意の \\(\\mathcal{G}\\)-可測集合 \\(B\\in\\mathcal{G}\\) 上では \\(X\\) と期待値が同じ確率変数になる：\\[\\mathrm{E}[X1_B]=\\mathrm{E}[\\mathrm{E}[X|\\mathcal{G}]1_B]\\]\n\n\n\n\\[\\mathrm{E}[X,B]:=\\mathrm{E}[X1_B]\\] という記法を採用すれば，条件2は \\[\\mathrm{E}[X,B]=\\mathrm{E}[\\mathrm{E}[X|\\mathcal{G}],B]\\] と書くこともできる．\n\n\n\n\n\n\n証明\n\n\n\n定義の2条件のみから，\\(\\mathrm{E}[X|\\mathcal{G}]\\) が \\(\\mathrm{P}\\)-零集合を除いて一意に定まること（とその存在）を示す．\n\\[Q(B):=\\mathrm{E}[X,B]=\\mathrm{E}[1_BX]\\;(B\\in\\mathcal{G})\\] とおくことで，\\(Q\\) は可測空間 \\((\\Omega,\\mathcal{G})\\) 上の確率測度を定める． いま，\\(\\mathrm{P}|_\\mathcal{G}\\) に関して \\(Q\\) は絶対連続になっている：\\[\\forall_{B\\in\\mathcal{G}}\\;P(B)=0\\Rightarrow Q(B)=0.\\] これより，Radon-Nikodymの定理から， ある \\(\\mathcal{G}\\)-可測で \\(\\mathrm{P}\\)-可積分な可測関数 \\(Y:\\Omega\\to\\mathbb{R}\\) が，\\(\\mathrm{P}\\)-零集合上での違いを除いて一意的に存在して，\\[\\forall_{B\\in\\mathcal{G}}\\;Q(B)=\\int_BY(\\omega)P(d\\omega)\\] が成り立つ． よって，条件付き期待値 \\(Y\\) は確かに存在して（同値類 \\(L^1(\\mathrm{P})\\) の元としては）一意的で，(1),(2)が成り立つ．\n\n\n(Dudley, 2002, pp. 10.1節 p.336), (吉田朋広, 2006, p. 43) がおすすめな参照先．(舟木直久, 2004, p. 88) が入門しやすい．\\(X\\in L^2(\\Omega)\\) でいい場合は，より「射影」としてわかりやすい特徴付けがある（ Section 1.3 ）．これのおすすめは (Jacod & Protter, 2004, pp. 第23節 p.200), (Kallenberg, 2021, p. 164)．\n\n\n\n\n\n\n\n\n\n定義（確率変数を与えた下での条件付き期待値）\n\n\n\n\\((E,\\mathcal{E})\\) を可測空間とする．確率変数 \\(X\\in\\mathcal{L}(\\Omega;E)\\) による \\(Y\\in\\mathcal{L}^1(\\Omega)\\) の条件付き期待値は，次を満たす可測関数 \\(\\mathrm{E}[Y|X=-]:E\\to\\mathbb{R}\\) のことをいう： \\[\n\\begin{align*}\n\\forall_{B\\in\\mathcal{E}}\\quad&\\int_{X^{-1}(B)}Y(\\omega)P(d\\omega)\\\\\n&\\quad=\\int_B\\mathrm{E}[Y|X=x]P^X(dx).\n\\end{align*}\n\\]\n\n\nすると，\\(X\\) が \\(\\Omega\\) 上に引き戻す \\(\\sigma\\)-代数 \\[\n\\sigma(X):=\\left\\{A\\subset\\Omega\\mid\\exists_{B\\in\\mathcal{E}}\\; X^{-1}(B)=A\\right\\}\n\\] を与えた下での条件付き期待値 \\(\\mathrm{E}[Y|\\sigma(X)]\\) と，次のように関係する．1 \\(\\mathrm{E}[Y|\\sigma(X)]\\) は定義 Section 1.1 1から \\(\\sigma[X]\\)-可測であるが，可測性の特徴付け（後述）から，これはあるBorel可測関数 \\(f\\) について，\\[\\mathrm{E}[Y|X]=f(X)\\;\\;\\mathrm{a.s.}\\] と表せる．この \\(f:\\mathcal{X}\\to\\mathbb{R}\\) が，\\(X\\) を与えた下での \\(Y\\) の条件付き期待値 \\(\\mathrm{E}[Y|X=-]\\) である．\nこの記法 \\(\\mathrm{E}[Y|X=x]\\) とは何かというと，\\(X\\) の値域 \\(\\mathcal{X}\\) 上の関数として，新たに \\[\\mathrm{E}[Y|X=x]:=f(x)\\;\\;\\mathrm{a.s.}\\] と書くことにするのである．2 すると， \\[\n\\mathrm{E}[Y|X=x]|_{x=X(\\omega)}=\\mathrm{E}[Y|X](\\omega)\\;\\;\\mathrm{a.s.}\n\\] も満たす．つまり，次の図式が可換である：\n\n\n\nCommutative Diagram for Conditional Expectations\n\n\n\n\n\n\n\n\n命題（Doobの汎函数表現）\n\n\n\n\\(S\\) を位相空間，\\(X\\in \\mathcal{L}(\\Omega;S),Y\\in \\mathcal{L}(\\Omega)\\) を確率変数とする．次は同値：\n\n\\(Y\\)は \\(\\sigma(X)\\)-可測．\nあるBorel可測関数 \\(f:S\\to\\mathbb{R}\\) が存在して，\\(Y=f(X)\\) を満たす．\n\n\n\n\n\n\n\n\n\n証明\n\n\n\n2 \\(\\Rightarrow\\) 1 はすぐに従う．任意の \\(B\\in\\mathcal{B}(\\mathbb{R})\\) について，\\(f^{-1}(B)\\in\\mathcal{B}(S)\\) であるから， \\[Y^{-1}(B)=X^{-1}(f^{-1}(B))\\in\\sigma(X).\\] あとは 1 \\(\\Rightarrow\\) 2 を示せば良い．3段階で示す．\n\nまず \\(Y\\) が単関数 \\[Y=\\sum_{i=1}^nc_i1_{A_i},\\qquad c_i\\ne c_j\\;(i\\ne j).\\] の場合について示す．仮定より \\(A_i\\in\\sigma(X)\\) であるから，ある \\(B_i\\in\\mathcal{B}(S)\\) が存在して \\(A_i=X^{-1}(B_i)\\)．よって， \\[f(x):=\\sum_{i=1}^nc_i1_{B_i}(x).\\] と定めると \\(Y=f(X)\\)．\n次に \\(Y\\ge0\\;\\;\\mathrm{a.s.}\\) の場合を考えると，正な単関数の単調増加列 \\(\\{Y_n\\}\\) で \\(Y\\) に収束するものが取れる．各 \\(Y_n\\) について，\\(f_n\\in\\mathcal{L}(S)\\) が存在して \\(Y_n=f_n(X)\\) が成り立つ．このとき，\\(f:=\\limsup_{n\\to\\infty}f_n\\) と定めれば， \\[\\begin{align*}\nY&=\\limsup_{n\\to\\infty}Y_n\\\\\n&=(\\limsup_{n\\to\\infty}f_n)(X)=f(X).\n\\end{align*}\\]\n一般の場合は \\(Y=Y^+-Y^-\\) の分解から従う．\n\n\n\n(Dudley, 2002, pp. 定理4.2.8 p.128) は \\(S=\\mathbb{R}\\) の場合，(Landkov, 1972) は \\(S=\\mathbb{R}^m\\) の場合, (Kallenberg, 2021, pp. 補題1.14 p.18) に一般の標準Borel空間の場合の証明がある．\n\n\n\n\\(L^2(\\Omega)\\subset L^1(\\Omega)\\) 上に議論を制限してみると，実は \\(\\mathcal{F}\\) の部分 \\(\\sigma\\)-代数 \\(\\mathcal{G}\\) に関する条件付き期待値は，部分空間 \\[\nL^2_\\mathcal{G}(\\Omega):=\\left\\{X\\in L^2(\\Omega)\\mid X\\,\\text{は}\\,\\mathcal{B}(\\mathbb{R})/\\mathcal{G}\\,\\text{-可測}\\right\\}\n\\] への射影になっている．\n\n\n\n\n\n\n定理（条件付き期待値の特徴付け）\n\n\n\n部分 \\(\\sigma\\)-代数 \\(\\mathcal{G}\\subset\\mathcal{F}\\) と \\(X\\in\\mathcal{L}^2(\\Omega)\\) を考える． 任意の \\(\\widehat{X}_\\mathcal{G}\\in\\mathcal{L}^2_\\mathcal{G}(\\Omega)\\) について，次は同値：\n\n\\(\\widetilde{X}_\\mathcal{G}\\) は \\(X\\) の \\(L^2_\\mathcal{G}(\\Omega)\\) への射影である：\\[\\|X-\\widehat{X}_\\mathcal{G}\\|_{L^2(\\Omega)}=\\inf_{X'\\in\\mathcal{L}^2_\\mathcal{G}(\\Omega)}\\|X-X'\\|_{L^2(\\Omega)}\\]．\n\\(\\widetilde{X}_\\mathcal{G}\\) は \\(X\\) の条件付き期待値である：\\[\\forall_{Z\\in L^2_\\mathcal{G}(\\Omega)}\\;\\mathrm{E}[ZX]=\\mathrm{E}[Z\\widehat{X}_\\mathcal{G}].\\]\n\n\n\n\n\n\n\n\n\n\n\n\n定義（条件付き確率）\n\n\n\n\\((\\Omega,\\mathcal{F},\\mathrm{P})\\) を確率空間，\\(\\mathcal{G}\\subset\\mathcal{F}\\) を部分 \\(\\sigma\\)-代数とする．\\(\\mathcal{G}\\) の定める条件付き確率を， \\[\n\\mathrm{P}[B|\\mathcal{G}](\\omega):=\\mathrm{E}[1_B|\\mathcal{G}](\\omega)\\;(B\\in\\mathcal{F})\n\\] で定める．\n\n\nしかしこの定義には問題がある．条件付き期待値 \\(\\mathrm{E}[X|\\mathcal{G}]\\) が \\(\\Omega\\) 上 \\(\\mathrm{P}\\text{-a.e.}\\) でしか定まらない（場合がある）から，\\(\\mathrm{P}\\) も一般には可算加法性をa.s.にしか満たさない： \\[\n\\mathrm{P}\\left[\\bigcap_{n\\in\\mathbb{N}}A_n\\,\\middle|\\,\\mathcal{G}\\right]=\\sum_{n\\in\\mathbb{N}}\\mathrm{P}[A_n]\\;\\;\\mathrm{a.s.}\n\\] この式自体は後述の単調収束定理（ Section 2.3 ）から示せる．\nだが，\\(\\mathcal{G}\\) がある完備可分距離空間に値を取る確率変数 \\(Y\\) について \\(\\mathcal{G}=\\sigma(Y)\\) である場合など，殆どの場合で，うまく \\(\\mathrm{P}\\) を取ることが出来る．3 このように，a.s.抜きで正式に確率測度として定まる場合を，正則条件付き確率と呼び分ける．"
  },
  {
    "objectID": "posts/2023-12-2/条件付き期待値の問題.html#性質",
    "href": "posts/2023-12-2/条件付き期待値の問題.html#性質",
    "title": "条件付き期待値の測度論的基礎付け",
    "section": "2 性質",
    "text": "2 性質\n\n2.1 作用素としての性質\n\\(\\mathcal{G}\\)-可測な可積分関数のなす部分空間を \\(L_{\\mathcal{G}}^1(\\Omega)\\subset L^1(\\Omega)\\) で表す．\n\n\n\n\n\n\n命題（条件付き期待値はノルム減少的な正作用素）\n\n\n\n条件付き期待値 \\(\\mathrm{E}_{\\mathcal{G}}:L^1(\\Omega)\\to L_{\\mathcal{G}}^1(\\Omega)\\) はノルム減少的で正な線型汎作用素である．すなわち，\n\n線型性：任意の実数 \\(a,b\\in\\mathbb{R}\\) について， \\[\\begin{align*}\n\\mathrm{E}[aX+bY|\\mathcal{G}]&=a\\mathrm{E}[X|\\mathcal{G}]\\\\\n&\\qquad+b\\mathrm{E}[Y|\\mathcal{G}]\\;\\;\\mathrm{a.s.}\n\\end{align*}\\]\n正性：\\(X\\le Y\\;\\;\\mathrm{a.s.}\\) ならば， \\[\\mathrm{E}[X|\\mathcal{G}]\\le\\mathrm{E}[Y|\\mathcal{G}]\\;\\;\\mathrm{a.s.}\\]\nJensenの不等式：\\(\\varphi:\\mathbb{R}\\to\\mathbb{R}\\) を凸関数とする．\\(\\varphi(X)\\in L^1(\\Omega)\\) ならば，\\[\\varphi(\\mathrm{E}[X|\\mathcal{G}])\\le\\mathrm{E}[\\varphi(X)|\\mathcal{G}]\\;\\;\\mathrm{a.s.}\\]\n三角不等式：\\[\\lvert\\mathrm{E}[X|\\mathcal{G}]\\rvert\\le\\mathrm{E}[\\lvert X\\rvert|\\mathcal{G}]\\;\\;\\mathrm{a.s.}\\]\n\nいずれも \\(L_{\\mathcal{G}}^1(\\Omega)\\) 上の等式・不等式であり，殆ど確実ににしか成り立たないことに注意．\n\n\n\n\n\n\n\n\n証明\n\n\n\n1は結局積分の線型性から従います．2は次のように議論できます．\n任意の \\(X\\in L^1(\\Omega)_+\\) について \\(\\mathrm{E}[X|\\mathcal{G}]\\in L^1(\\Omega)\\) を示せば良い．\\(A_n:=\\left\\{X'\\le 1/n\\right\\}\\in\\mathcal{G}\\) について，条件付き期待値の定義から，任意の \\(n\\in\\mathbb{N}^+\\) について， \\[\n\\begin{align*}\n0\\le\\mathrm{E}[X,A_n]&=\\mathrm{E}[\\mathrm{E}[X|\\mathcal{G}],A_n]\\\\\n&\\le\\frac{1}{n}\\mathrm{P}[A_n].\n\\end{align*}\n\\] より，\\(\\lim_{n\\to\\infty}\\mathrm{P}[A_n]=0\\) が必要．これより， \\[\\mathrm{P}[\\mathrm{E}[X|\\mathcal{G}]&lt;0]\\le\\mathrm{P}[\\cup_{n=1}^\\infty A_n]=0.\\] が解る．\n3は単関数の場合から地道に示します．4はその特別の場合で \\(\\varphi(x)=\\lvert x\\rvert\\) と取った場合に当たります．\n\n\n\n\n2.2 Tower Property\n\n\n\n\n\n\n命題（繰り返し期待値の法則）\n\n\n\n2つの \\(\\sigma\\)-代数が \\(\\mathcal{G}_1\\subset\\mathcal{G}_2\\) を満たすならば，\\(\\mathrm{E}_{\\mathcal{G}_1}=\\mathrm{E}_{\\mathcal{G}_1}\\circ\\mathrm{E}_{\\mathcal{G}_2}\\)．すなわち， \\[\\mathrm{E}[X|\\mathcal{G}_1]=\\mathrm{E}[\\mathrm{E}[X|\\mathcal{G}_2]|\\mathcal{G}_1]\\;\\;\\mathrm{a.s.}\\]\n\n\n\n\n\n\n\n\n証明\n\n\n\n右辺を \\(Z\\) とおく．任意の \\(A\\in\\mathcal{G}_1\\) について，\\(A\\in\\mathcal{G}_2\\) でもあるから， \\[\\begin{align*}\n\\mathrm{E}[Z1_A]&=\\mathrm{E}[\\mathrm{E}[X|\\mathcal{G}_1]1_A]\\\\\n&=\\mathrm{E}[X1_A].\n\\end{align*}\\]\n\n\n\n\n2.3 単調収束定理\n\n\n\n\n\n\n命題（条件付き期待値に対する単調収束定理）\n\n\n\n可積分な実確率変数の列 \\(\\{X_n\\}\\cup\\{X\\}\\subset L^1(\\Omega)\\) について， \\[X_n\\nearrow X\\;\\;\\mathrm{a.s.}\\] \\[\\Rightarrow\\quad\\mathrm{E}[X_n|\\mathcal{G}]\\nearrow\\mathrm{E}[X|\\mathcal{G}]\\;\\;\\mathrm{a.s.}\\]\n\n\n\n\n\n\n\n\n証明\n\n\n\n条件付き期待値の正性 Section 2.1 より， \\[\\mathrm{E}[X_n|\\mathcal{G}]\\le\\mathrm{E}[X|\\mathcal{G}]\\;\\;\\mathrm{a.s.},\\qquad n\\in\\mathbb{N}.\\] よって，有界な単調列は収束するから，ある \\(Y\\in L^1(\\Omega)\\) を \\(E[X_n|\\mathcal{G}]\\nearrow Y\\;\\;\\mathrm{a.s.}\\) を満たすように定めることが出来る．同時に，通常の期待値に関する単調収束定理から， \\[\n\\begin{align*}\n\\mathrm{E}[X1_A]&=\\lim_{n\\to\\infty}\\mathrm{E}[X_n1_A]\\\\&=\\mathrm{E}[Y1_A]\\;(A\\in\\mathcal{G})\n\\end{align*}\n\\] が必要であるから，条件付き期待値の一意性より，\\(Y=\\mathrm{E}[X|\\mathcal{G}]\\;\\;\\mathrm{a.s.}\\)\n\n\n\n\n2.4 可測関数の取り出し\n\n\n\n\n\n\n命題（可測関数の取り出し）\n\n\n\n\\(X,XY\\in L^1(\\Omega)\\) を可積分，\\(Y\\in L_\\mathcal{G}(\\Omega)\\) を \\(\\mathcal{G}\\)-可測実確率変数とする．このとき，\n\n\\(XY\\in L^1(\\Omega)\\)ならば，\\[\\mathrm{E}[XY|\\mathcal{G}]=Y\\mathrm{E}[X|\\mathcal{G}]\\;\\;\\mathrm{a.s.}\\]\n特に，\\(\\mathrm{E}[Y|\\mathcal{G}]=Y\\;\\;\\mathrm{a.s.}\\)\n\n\n\n\n\n\n\n\n\n証明\n\n\n\n条件付き期待値の線型性から，\\(X,Y\\ge0\\) の場合について示せば良い．このとき，非負値単関数の収束列 \\(X_n\\nearrow X,Y_n\\nearrow Y\\) が取れる．\\(X_nY\\nearrow XY\\in L^1(\\Omega)\\) だから，単調収束定理 Section 2.3 から \\[\\mathrm{E}[X_n|\\mathcal{G}]\\nearrow\\mathrm{E}[X|\\mathcal{G}]\\] \\[\n\\begin{align*}\n\\Rightarrow&\\quad Y\\mathrm{E}[X_n|\\mathcal{G}]\\nearrow Y\\mathrm{E}[X|\\mathcal{G}]\\\\\n\\quad\\land&\\quad\\mathrm{E}[X_nY|\\mathcal{G}]\\nearrow\\mathrm{E}[XY|\\mathcal{G}].\n\\end{align*}\\] よって，各 \\(n\\in\\mathbb{N}\\) について \\(Y\\mathrm{E}[X_n|\\mathcal{G}]=\\mathrm{E}[X_nY|\\mathcal{G}]\\) を示せば良い．単関数とは \\(X=1_C\\;(C\\in\\mathcal{G})\\) という形の関数の線型和だから，畢竟この形の関数について考えれば良いのである．任意の \\(B\\in\\mathcal{G}\\) について \\(C\\cap B\\in\\mathcal{G}\\) であるから， \\[\n\\begin{align*}\n\\int_B1_C\\mathrm{E}[Y|\\mathcal{G}]\\,d\\mathrm{P}&=\\int_{C\\cap B}\\mathrm{E}[Y|\\mathcal{G}]\\,d\\mathrm{P}\\\\\n&=\\int_{C\\cap B}Y\\,d\\mathrm{P}\\\\\n&=\\int_B1_CY\\,d\\mathrm{P}.\n\\end{align*}\n\\] 条件付き期待値の一意性より，\\(1_C\\mathrm{E}[Y|\\mathcal{G}]=\\mathrm{E}[1_CY|\\mathcal{G}]\\;\\;\\mathrm{a.s.}\\) を得る．\n\n\n\n\n2.5 独立な場合\n\n\n\n\n\n\n命題（独立確率変数に対する性質）\n\n\n\n可積分実確率変数 \\(X\\in L^1(\\Omega)\\)は \\(\\sigma\\)-代数 \\(\\mathcal{G}\\) と独立とする．\n\n\\(E[X|\\mathcal{G}]=E[X]\\;\\;\\mathrm{a.s.}\\)\n特に，\\(E[X|\\boldsymbol{2}]=E[X]\\;\\;\\mathrm{a.s.}\\)．\n\n\n\n\n\n2.6 練習\n\n\n\n\n\n\n問題\n\n\n\n確率変数 \\(X,Y\\) とその値域の値 \\(y\\in\\mathcal{Y}\\) について， \\[\n\\mathrm{E}[X|Y=y]\\mathrm{P}[Y=y]=\\mathrm{E}[X1_{\\left\\{Y=y\\right\\}}]\n\\] はどう正当化されるか？\n\n\n\n\n\n\n\n\n説明\n\n\n\n\\(\\mathrm{E}[X1_{\\left\\{Y=y\\right\\}}]\\) の中身を \\(\\sigma(Y)\\) で条件付けてTower property（ Section 2.2 ）を使うと（定義 Section 1.1 の条件2からと論じても良い），\\(1_{\\left\\{Y=y\\right\\}}\\) は \\(\\sigma(Y)\\)-可測だから，条件付き期待値の中身から出る（ Section 2.4 参照）．これによって正当化できる．式で表すと， \\[\n\\begin{align*}\n\\mathrm{E}[X1_{\\left\\{Y=y\\right\\}}]&=\\mathrm{E}[\\mathrm{E}[X1_{\\left\\{Y=y\\right\\}}|Y]]\\\\\n&=\\mathrm{E}[1_{\\left\\{Y=y\\right\\}}\\mathrm{E}[X|Y]]\\\\\n&=\\int_{\\mathcal{Y}}\\delta_y(y')\\mathrm{E}[X|Y=y']\\mathrm{P}(dy')\\\\\n&=\\mathrm{E}[X|Y=y]\\mathrm{P}[Y=y].\n\\end{align*}\n\\] ただし，\\(\\mathcal{Y}\\) 上の確率測度を \\(\\mathrm{P}\\) と置いた．\n\n\n条件付き確率の定義 Section 1.4 から， \\[\n\\mathrm{P}[Y\\in B|X=x]:=\\mathrm{E}[1_{\\left\\{Y\\in B\\right\\}}|X=x]\n\\] と議論できる．さらに \\(\\mathrm{P}[X=x]&gt;0\\) のとき， \\[\n=\\frac{\\mathrm{E}[1_{\\left\\{Y\\in B\\right\\}}1_{\\left\\{X=x\\right\\}}]}{\\mathrm{P}[X=x]}=\\frac{\\mathrm{P}[Y\\in B,X=x]}{\\mathrm{P}[X=x]}\n\\] という見慣れた表示を得る．"
  },
  {
    "objectID": "posts/2023-12-2/条件付き期待値の問題.html#footnotes",
    "href": "posts/2023-12-2/条件付き期待値の問題.html#footnotes",
    "title": "条件付き期待値の測度論的基礎付け",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(Dudley, 2002, p. 340) など．↩︎\n(Kallenberg, 2021, p. 167)．↩︎\n(Dudley, 2002, pp. 定理10.2.2 p.345)．一般には Borel空間に値を取る確率変数について成り立つ (Kallenberg, 2021, p. 165)．↩︎"
  },
  {
    "objectID": "posts/2023-11-5/index.html",
    "href": "posts/2023-11-5/index.html",
    "title": "俺の人生を変えたものTop5",
    "section": "",
    "text": "９月の京都学会→台湾研修（３週間）から帰ってきて，最初に手をつけたのが家の片付けであった．不要な本は全て売り（段ボール5箱），粗大ゴミを8000円分捨て，古着も処分した．特に，半ば物置と化していた和室をリフォームし，自分の書斎として使えるようにした．結果，11月を迎えた今，8月までの生活に比べて，\n\n3時に寝て1時に起きるのもザラにあった生活が，12時には寝て10時には活動を始めているようになった．特に，午前中からだらけることなく研究に従事することができるようになった．\n1日2食（昼に当たる時間と晩）でも胃もたれしたり，冷たいものを飲み過ぎて戻してしまうことがしばしばあった生活が，1日3食がっつり食べるようになった．それで居て胃もたれもなく，冷たい飲み物が苦手ということも無くなった．\n急に立ち上がったり，電車から降りて階段を登ったりするタイミングで目の前が見えなくなるほどの立ちくらみがすることがよくあった（週の2,3回ほど）が，今では1度もなければ前兆もない．\n以前は週1回ランニングに出れば良い方だったが，今では外出しない日は殆どランニングに出ている．\n結果，「やられっぱなしにはならず耐える」ことが人生の中心になっていたが，いまでは「自分の手で人生を変えていける」という感覚を得ることが出来ている．\n\n正直これほどの変化が起こるとは思わなかったし，すでに２週間近く全くブレずに持続している．自分のこれまでの人生から見ても，これからを思っても，これほど効果覿面な投資もなかったと思うので，10月に導入して良かったものベスト5を書きおこうと思う．"
  },
  {
    "objectID": "posts/2023-11-5/index.html#何が起こったか",
    "href": "posts/2023-11-5/index.html#何が起こったか",
    "title": "俺の人生を変えたものTop5",
    "section": "",
    "text": "９月の京都学会→台湾研修（３週間）から帰ってきて，最初に手をつけたのが家の片付けであった．不要な本は全て売り（段ボール5箱），粗大ゴミを8000円分捨て，古着も処分した．特に，半ば物置と化していた和室をリフォームし，自分の書斎として使えるようにした．結果，11月を迎えた今，8月までの生活に比べて，\n\n3時に寝て1時に起きるのもザラにあった生活が，12時には寝て10時には活動を始めているようになった．特に，午前中からだらけることなく研究に従事することができるようになった．\n1日2食（昼に当たる時間と晩）でも胃もたれしたり，冷たいものを飲み過ぎて戻してしまうことがしばしばあった生活が，1日3食がっつり食べるようになった．それで居て胃もたれもなく，冷たい飲み物が苦手ということも無くなった．\n急に立ち上がったり，電車から降りて階段を登ったりするタイミングで目の前が見えなくなるほどの立ちくらみがすることがよくあった（週の2,3回ほど）が，今では1度もなければ前兆もない．\n以前は週1回ランニングに出れば良い方だったが，今では外出しない日は殆どランニングに出ている．\n結果，「やられっぱなしにはならず耐える」ことが人生の中心になっていたが，いまでは「自分の手で人生を変えていける」という感覚を得ることが出来ている．\n\n正直これほどの変化が起こるとは思わなかったし，すでに２週間近く全くブレずに持続している．自分のこれまでの人生から見ても，これからを思っても，これほど効果覿面な投資もなかったと思うので，10月に導入して良かったものベスト5を書きおこうと思う．"
  },
  {
    "objectID": "posts/2023-11-5/index.html#スタンディングデスクの導入",
    "href": "posts/2023-11-5/index.html#スタンディングデスクの導入",
    "title": "俺の人生を変えたものTop5",
    "section": "１．スタンディングデスクの導入1",
    "text": "１．スタンディングデスクの導入1\n\n\n\n\nStanding Desk\n\n\nこれが俺の生活を根底から変えてしまった．\n１週間ほどかけて物置状態の和室にスタンディングデスクを導入し，書斎として使えるようにした．すると，朝ご飯から研究が，晩御飯から読書が，シームレスに繋がるようになった．特に何もせずにだらだらしていた時間がまるごと消えてしまった．外から家に帰ってきて，風呂に入るわけでもなくソファに座ってだらだらしているようなことも減った．\nあとから思えば，朝起きて研究に取りかかれない理由のうち殆どの部分が「日当たりのない部屋で」「座るのが嫌だ」の２つの事項に帰することが出来たのだ．私の部屋は北向きで窓はあれど殆ど陽は入らず，一方で和室はリビングに繋がっており，大きな窓から朝日が差し込んでくる．午前中に自宅で勉強する行為は人生全体で見て殆ど初めてのことだったが，心の底から幸せだと感じた．\nまた，睡眠の改善は，後述の睡眠グッズの影響も大きいだろうが，朝日当たりの良い場所で研究・読書をすることで，午前中から太陽の光を浴びるようになったことによる影響も大きいだろうと思われる．\nさらに，筆者はオンライン授業を聞くのが極めて苦手で，全く集中できない上に他のことをがっつりやることも出来ない，大きなストレス源であったが，スタンディングデスクであると自然な形で聴くことができる．\nこのような例もあるのだ．「ダラダラしてしまうのは自分が臆病だからだ」とか，「朝に弱いのだ」などと早合点せず，もっと早くスタンディングデスクを導入して，自宅内にも２箇所勉強できる場所を用意しておけば良かったと今では思う．疲れたら立って／座ってみるだけでギアが変わるように集中力が持続する．スタンディングデスクにステッパーを組み合わせて，歩きながら作業できるようにすると雑務にもストレスが溜まらない．"
  },
  {
    "objectID": "posts/2023-11-5/index.html#段ハンガーラック",
    "href": "posts/2023-11-5/index.html#段ハンガーラック",
    "title": "俺の人生を変えたものTop5",
    "section": "２．２段ハンガーラック2",
    "text": "２．２段ハンガーラック2\n【ポール径25mm】 エリソン ハンガーラック ワードローブ [ホワイト] 幅110cm 3段 幅111×奥行41×高さ220cm EHE11213WH [EHE11183WH ADD-P45WH HP-110WH]| スチールラック・メタル製ラック通販のルミナスクラブ\n和室には他に本棚，ベッドと，この２段ハンガーラックが用意してある．縦方向に長い(220cmある)ために場所を取らないが，多くの衣服を収納できるし，何より取り出しやすい．これで散らかしがちだった服を一箇所に整理することが出来た．"
  },
  {
    "objectID": "posts/2023-11-5/index.html#高反発マットレス",
    "href": "posts/2023-11-5/index.html#高反発マットレス",
    "title": "俺の人生を変えたものTop5",
    "section": "３．高反発マットレス3",
    "text": "３．高反発マットレス3\n\nこれも全く予想外だった．マットレスを変えることが睡眠に影響を与えるとも思っていなかったし，「痩せている場合は低反発」というネット上の文句がやけに腑に落ちる部分もあったため，「高反発で本当に良かったのか？」と買ってからも逡巡していたが，「体圧分散マットレス」であれば高反発だろうと身体を痛めることはない．さらに筆者の場合は，高反発マットレスで寝起きした方が，身体が疲れていないと感じる．"
  },
  {
    "objectID": "posts/2023-11-5/index.html#iotシーリングライト",
    "href": "posts/2023-11-5/index.html#iotシーリングライト",
    "title": "俺の人生を変えたものTop5",
    "section": "４．IoTシーリングライト4",
    "text": "４．IoTシーリングライト4\n【調光調色 スマホ操作やタイマーが便利】6畳 LEDシーリングライト フラヴィア リモート リモコン付き IoT スマホで操作 おしゃれ 照明器具 リビング用 居間用 ダイニング用 食卓用 電気 寝室 一人暮らし シンプル 声で操作 子供部屋 間接照明 電灯-おしゃれ照明・ライトのBeauBelle（ボーベル）\n部屋のライトが音を出すようになったことがきっかけで買い替えたが，このライトは色の調整も可能でありながら，「朝９時に点灯させる」といったようなスケジューリングも可能である．\n実際明るくなったことで起きることはなかったが，起きた場合に二度寝することが減った．それも，不快感も特に強くなく，勝手に身体にエネルギーが起きてくれるのである．\nまた，集中する際は白色光で，寝る前は暖色で光の強さも弱めていくことで，自然な眠気を誘うこともできる．"
  },
  {
    "objectID": "posts/2023-11-5/index.html#日13時間は水以外口に入れない時間を作る",
    "href": "posts/2023-11-5/index.html#日13時間は水以外口に入れない時間を作る",
    "title": "俺の人生を変えたものTop5",
    "section": "５．1日13時間は水以外口に入れない時間を作る",
    "text": "５．1日13時間は水以外口に入れない時間を作る\nこれが今回唯一の自助努力となったが，最大の気づきでもあった．夜寝る前にラーメンや甘いものをつい食べがちになっていたが，その代わりに日中の摂取カロリーを増やし，（翌朝10時に朝ご飯を食べるとするならば）９時以降は水以外，口に何も入れないようにする．大事なのはカロリーを取らない点である．人体は，口腔内にカロリーを検出するだけで，それに合わせて胃も消化の必要を見越して胃液を分泌し，調和を図るようになっている．5\n思い返せば，小学校低学年までは胃腸が弱く，体調を崩した際は必ず嘔吐を繰り返した．その際に学んだ絶対の規則は「一度吐いたら６時間は何も食べないし何も飲まない」を徹底することであった．疲れさせてしまったら休ませることが人体の鉄則である．\n筆者の場合は夜はしっかり半日以上胃腸を休ませることにより，日中にフルパワーで活動させることができ，夜中にお腹が空くということは減ったのであった．\n正直、いまの自分は、昔の自分がなりたかった自分の最新バージョンに他ならない。己に恥じない毎日を過ごしたいと思う。"
  },
  {
    "objectID": "posts/2023-11-5/index.html#footnotes",
    "href": "posts/2023-11-5/index.html#footnotes",
    "title": "俺の人生を変えたものTop5",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFlexiSpot 電動昇降式デスクEF1↩︎\n【ポール径25mm】 エリソン ハンガーラック ワードローブ [ホワイト] 幅110cm 3段 幅111×奥行41×高さ220cm EHE11213WH [EHE11183WH ADD-P45WH HP-110WH] ↩︎\nGOKUMIN 高反発マットレス↩︎\nBeauBelle IoT シーリングライト Flavia bbs-095t↩︎\n関連する話はこのブログなどにも紹介されている．↩︎"
  },
  {
    "objectID": "posts/2023-11-25/ParticleFilter.html",
    "href": "posts/2023-11-25/ParticleFilter.html",
    "title": "粒子フィルターとは何か | About Particle Filters（執筆中）",
    "section": "",
    "text": "フィルタ（濾波器）の第一義は，液体から不純物を取り除くための装置である．そのアナロジーで「フィルタリング問題」と言った場合は，信号処理の意味で電圧や電波の信号を「濾過」してノイズを除去し本当に欲しい部分を純粋化する営みのことを指す．特に，凡ゆる通信機器において装置の熱運動によるノイズが入ることは避けられぬ自然の摂理である．1\n従ってGaussが天体観測から「誤差論」として統計的推定理論を創始したように，通信と制御の分野では「時々刻々と受信するデータから時々刻々と変化する信号をどのようにうまく濾波するか」という独自の課題から，独自の理論が発展していった．特に，デジタル回路がない時代では，「どのような電気回路のシステムとして濾波機をデザインすれば良いか？」という電気工学的な回路設計の問題としての側面も大きかった．\nフィルタリングの問題を統計的技術で解くための理論2が，まず離散時間の場合が (Kolmogorov, 1941)，続いて連続時間の場合が (Wiener, 1949) によって模索された．3 しかし，このKolmogorov-Wiener理論では「信号とノイズの過程が定常である」という仮定を置いており，これが広い応用を阻んでいた．当時の技術（抵抗器やコンデンサーなど）で実装出来る範囲という制約がある以上，仕方ないことでもあったため，更なる理論的発展はデジタル技術の登場を待つ必要があった．\nトランジスタというデジタル技術が使われるようになると，「フィルタ（濾波器）」はアナログデジタル変換器，レジスタ，メモリ，マイクロプロセッサから構成されるようになり，物理的な姿は全く変わってしまった．その中で (Kalman, 1960) が，定常性の仮定が満たされない場合でも使えるアルゴリズムを提案すると，すぐにApollo計画に導入されるに止まらず，NASAのスペースシャトル，海軍の潜水艦などにも応用されていった．4\nこうして「フィルタ（濾波器）」の語は，「水を濾過する如く電圧情報のノイズを除去する機器」という類比から，デジタル技術の出現により更なる一段階の抽象化を受けて物理的実体も失い，「ノイズを除去してメッセージ部分をなるべく正確に推定するアルゴリズム」という完全に数学的で抽象的な存在として研究が進められていくことになる．\nこのKalman filterは素晴らしかった．だが，モデルが線型かつ正規である場合にしか使えない．そこで，計算機や情報通信技術の発展と共に複雑化していくシステム・データに併せて，様々なフィルターが考案されていく必要があるのである．5 これが統計計算の時代である．\n\n\n\n線型性や正規性の仮定を一才必要としない濾波アルゴリズムとして，(Gordon et al., 1993) がbootstrap filterという名前で発表し，角度観測のみを用いた物体追跡の問題への応用を付した．この角度情報のみから物体を追跡するという問題は古典的な非線型濾波問題で，従来の拡張Kalman filterの方法では精度が全く伸びず，これに比べてbootstrap filterでは圧倒的に性能が改善したのであった．リサンプリングは多項リサンプリングを採用しており，極めて実装が簡単という点も多くの応用を生んだ理由である．6\nなお，北川源四郎も同年（1993年）のカンファレンスでMonte Carlo filterの名前で同様のアルゴリズムを発表している．そのジャーナル版は (北川源四郎, 1996a)．7 日本語文献 (北川源四郎, 1996b) はウェブ上からも読める．\n\n\n\nまず，(Gordon et al., 1993) による粒子フィルターの考案は，防衛，特に物体追跡への応用が念頭にあり，これを扱った一冊の本もある (Ristic et al., 2004)．8\nこれに関連して，ロボティクス，HCI (Human-Computer Interaction) 分野への応用もなされている(岡兼司, 2005), (Wills & Schön, 2023)．\nファイナンスで扱う時系列は非線型性・非正規性を示すと同時にデータ数も多い．逐次推定のステップ数が増えようとも誤差が蓄積しない粒子フィルターが見事に推定を実行する．9\n加えて，マクロ経済学の分野で動学的確率的一般均衡モデルの推定にも応用されている．このモデルは，非線型なミクロ経済学的モデルの上に構築されたモデルで，非線型な1次条件を持つ．10\n近年ではエージェント・ベースド・モデルへの応用もある (Lux, 2018)．\n\n\n\nこうして，粒子フィルターは濾波問題の文脈で発明されたMonte Carlo法であるが，濾波問題に限らず，多くの逐次推定問題，更には（逐次的構造を持たない）一般の推定問題にも応用できる．この観点から，粒子フィルターは「逐次Monte Carlo法（Sequential Monte Carlo methods 略して SMC ）」ともいう．11\n逐次的ではない通常の設定，いわば「静的」な設定の下でのBayes推論にSMCを用いる方法は (Chopin, 2002) が草分け的な仕事をした．この枠組みでは，Bayes事後分布 \\(\\pi(\\theta|y_1,\\cdots,y_N)\\) の近似において，途中の \\(\\pi(\\theta|y_1,\\cdots,y_n)\\) を経由して逐次的に近似することが，自然な計算コスト削減法として理解できる．\n\n\n\n粒子フィルターは高い汎用性の代償として，多数の粒子を用意したいなら計算量が多くなることを欠点に持つ．従って，粒子フィルターは，他の手法が実行不可能なほどの非線型性・非正規性を示す問題に（のみ）用いるべきというものである．が，CPUや並列計算の発展により十分な量の粒子を用意できる場面も増えたため，その問題点も形骸化してきてると言える．12\nまた，粒子フィルターは，観測 \\(Y_t\\) の次元が大きいなど，観測から得られる情報量が多く，尤度（ポテンシャル）の尖度が高いとき，多くの粒子が小さな荷重を持ってしまう．この状態は近似精度悪化の原因となり縮退と呼ばれる．13 そのような場合は，観測の情報を柔軟に取り入れた提案核を構築し，誘導粒子フィルターをうまく設計する必要がある．\n地球科学や天気予報の分野では \\(Y_t\\) は大きく（\\(10^7\\)を超えることもある），このような場合は粒子フィルターは実行可能でなくなる．加えてKalmanフィルターも行列計算の部分が実行不可能になり，アンサンブルKalmanフィルタという粒子法が用いられる．"
  },
  {
    "objectID": "posts/2023-11-25/ParticleFilter.html#背景",
    "href": "posts/2023-11-25/ParticleFilter.html#背景",
    "title": "粒子フィルターとは何か | About Particle Filters（執筆中）",
    "section": "",
    "text": "フィルタ（濾波器）の第一義は，液体から不純物を取り除くための装置である．そのアナロジーで「フィルタリング問題」と言った場合は，信号処理の意味で電圧や電波の信号を「濾過」してノイズを除去し本当に欲しい部分を純粋化する営みのことを指す．特に，凡ゆる通信機器において装置の熱運動によるノイズが入ることは避けられぬ自然の摂理である．1\n従ってGaussが天体観測から「誤差論」として統計的推定理論を創始したように，通信と制御の分野では「時々刻々と受信するデータから時々刻々と変化する信号をどのようにうまく濾波するか」という独自の課題から，独自の理論が発展していった．特に，デジタル回路がない時代では，「どのような電気回路のシステムとして濾波機をデザインすれば良いか？」という電気工学的な回路設計の問題としての側面も大きかった．\nフィルタリングの問題を統計的技術で解くための理論2が，まず離散時間の場合が (Kolmogorov, 1941)，続いて連続時間の場合が (Wiener, 1949) によって模索された．3 しかし，このKolmogorov-Wiener理論では「信号とノイズの過程が定常である」という仮定を置いており，これが広い応用を阻んでいた．当時の技術（抵抗器やコンデンサーなど）で実装出来る範囲という制約がある以上，仕方ないことでもあったため，更なる理論的発展はデジタル技術の登場を待つ必要があった．\nトランジスタというデジタル技術が使われるようになると，「フィルタ（濾波器）」はアナログデジタル変換器，レジスタ，メモリ，マイクロプロセッサから構成されるようになり，物理的な姿は全く変わってしまった．その中で (Kalman, 1960) が，定常性の仮定が満たされない場合でも使えるアルゴリズムを提案すると，すぐにApollo計画に導入されるに止まらず，NASAのスペースシャトル，海軍の潜水艦などにも応用されていった．4\nこうして「フィルタ（濾波器）」の語は，「水を濾過する如く電圧情報のノイズを除去する機器」という類比から，デジタル技術の出現により更なる一段階の抽象化を受けて物理的実体も失い，「ノイズを除去してメッセージ部分をなるべく正確に推定するアルゴリズム」という完全に数学的で抽象的な存在として研究が進められていくことになる．\nこのKalman filterは素晴らしかった．だが，モデルが線型かつ正規である場合にしか使えない．そこで，計算機や情報通信技術の発展と共に複雑化していくシステム・データに併せて，様々なフィルターが考案されていく必要があるのである．5 これが統計計算の時代である．\n\n\n\n線型性や正規性の仮定を一才必要としない濾波アルゴリズムとして，(Gordon et al., 1993) がbootstrap filterという名前で発表し，角度観測のみを用いた物体追跡の問題への応用を付した．この角度情報のみから物体を追跡するという問題は古典的な非線型濾波問題で，従来の拡張Kalman filterの方法では精度が全く伸びず，これに比べてbootstrap filterでは圧倒的に性能が改善したのであった．リサンプリングは多項リサンプリングを採用しており，極めて実装が簡単という点も多くの応用を生んだ理由である．6\nなお，北川源四郎も同年（1993年）のカンファレンスでMonte Carlo filterの名前で同様のアルゴリズムを発表している．そのジャーナル版は (北川源四郎, 1996a)．7 日本語文献 (北川源四郎, 1996b) はウェブ上からも読める．\n\n\n\nまず，(Gordon et al., 1993) による粒子フィルターの考案は，防衛，特に物体追跡への応用が念頭にあり，これを扱った一冊の本もある (Ristic et al., 2004)．8\nこれに関連して，ロボティクス，HCI (Human-Computer Interaction) 分野への応用もなされている(岡兼司, 2005), (Wills & Schön, 2023)．\nファイナンスで扱う時系列は非線型性・非正規性を示すと同時にデータ数も多い．逐次推定のステップ数が増えようとも誤差が蓄積しない粒子フィルターが見事に推定を実行する．9\n加えて，マクロ経済学の分野で動学的確率的一般均衡モデルの推定にも応用されている．このモデルは，非線型なミクロ経済学的モデルの上に構築されたモデルで，非線型な1次条件を持つ．10\n近年ではエージェント・ベースド・モデルへの応用もある (Lux, 2018)．\n\n\n\nこうして，粒子フィルターは濾波問題の文脈で発明されたMonte Carlo法であるが，濾波問題に限らず，多くの逐次推定問題，更には（逐次的構造を持たない）一般の推定問題にも応用できる．この観点から，粒子フィルターは「逐次Monte Carlo法（Sequential Monte Carlo methods 略して SMC ）」ともいう．11\n逐次的ではない通常の設定，いわば「静的」な設定の下でのBayes推論にSMCを用いる方法は (Chopin, 2002) が草分け的な仕事をした．この枠組みでは，Bayes事後分布 \\(\\pi(\\theta|y_1,\\cdots,y_N)\\) の近似において，途中の \\(\\pi(\\theta|y_1,\\cdots,y_n)\\) を経由して逐次的に近似することが，自然な計算コスト削減法として理解できる．\n\n\n\n粒子フィルターは高い汎用性の代償として，多数の粒子を用意したいなら計算量が多くなることを欠点に持つ．従って，粒子フィルターは，他の手法が実行不可能なほどの非線型性・非正規性を示す問題に（のみ）用いるべきというものである．が，CPUや並列計算の発展により十分な量の粒子を用意できる場面も増えたため，その問題点も形骸化してきてると言える．12\nまた，粒子フィルターは，観測 \\(Y_t\\) の次元が大きいなど，観測から得られる情報量が多く，尤度（ポテンシャル）の尖度が高いとき，多くの粒子が小さな荷重を持ってしまう．この状態は近似精度悪化の原因となり縮退と呼ばれる．13 そのような場合は，観測の情報を柔軟に取り入れた提案核を構築し，誘導粒子フィルターをうまく設計する必要がある．\n地球科学や天気予報の分野では \\(Y_t\\) は大きく（\\(10^7\\)を超えることもある），このような場合は粒子フィルターは実行可能でなくなる．加えてKalmanフィルターも行列計算の部分が実行不可能になり，アンサンブルKalmanフィルタという粒子法が用いられる．"
  },
  {
    "objectID": "posts/2023-11-25/ParticleFilter.html#粒子フィルター入門",
    "href": "posts/2023-11-25/ParticleFilter.html#粒子フィルター入門",
    "title": "粒子フィルターとは何か | About Particle Filters（執筆中）",
    "section": "2 粒子フィルター入門",
    "text": "2 粒子フィルター入門\n\n2.1 重点サンプリング\n\n\n2.2 逐次重点サンプリングの修正としての粒子フィルター\n逐次重点サンプリングは，次元が上がっていくにつれて分散が指数増大するという致命的欠点がある．14 そこで，「リサンプリング」（「選択（セレクション）」ともいう）という新たな機構を各段階に取り入れることを考える．この機構により，次元の呪いを克服し，推定精度が保たれるのであるが，一方で粒子の間に相関が導入されるために，理論的解析を困難にする．この点から粒子フィルターは「（平均場）相関粒子法」「遺伝型粒子フィルター」15 ともいう．16"
  },
  {
    "objectID": "posts/2023-11-25/ParticleFilter.html#技術的障壁と今後の研究",
    "href": "posts/2023-11-25/ParticleFilter.html#技術的障壁と今後の研究",
    "title": "粒子フィルターとは何か | About Particle Filters（執筆中）",
    "section": "3 技術的障壁と今後の研究",
    "text": "3 技術的障壁と今後の研究\n粒子フィルターの応用には次の点の研究が肝要である．17\n\n3.1 提案分布の取り方\nSection 1.5 で触れた通り，特に観測の情報量が大きい場合，提案分布の選び方が粒子フィルターの精度を大きく左右するが，この取り方について普遍的な指針というものが得られていない．\n(Guarniero et al., 2017) と (Heng et al., 2020) は提案分布にパラメトリックモデルを用意し，粒子推定量の分散を最小化するようにそのモデル内で逐次的に最適化していく機構を提案している．\n(Naesseth et al., 2015) が提唱するnested SMCは，は各時刻での提案分布を近似するために，もう一つのSMCを内部に走らせる．当然計算量は二倍になるが，それでも単純なbootstrap filterから大きく性能が改善する場合が多い．\n\n粒子フィルタを適用する際の課題の一つは，各粒子に割り当てられる重みが1粒子に集中する，いわゆる退化の問題を限られた数の粒子でいかに克服するかである．(上野玄太, 2019)\n\n\n\n3.2 部分的な線型構造の利用\n周辺化粒子フィルター，またはRao-Blackwellized particle filterとも呼ばれる方法である．これは多くの場面で，仮定されている状態空間モデルが部分的に線型である場合に，線型の部分をKalmanフィルターによって正確に解き，残った部分のみを粒子フィルターで解くことで，精度の向上とアルゴリズムの効率化を図る方法である．\n(Ristic et al., 2004, p. 287) では，探知前追跡 (track-before-detect) の問題18において，周辺化粒子フィルタが，必要な粒子数を大きく削減してくれることを紹介している．\nその他にも，問題毎の特有の構造を利用して計算量を削減・パフォーマンスを最適化することは重要な営みである．\n\n\n3.3 粒子数に関する漸近論\n目前の問題を，所与の精度で解くために必要な粒子数は幾ばくか？という問題は実用上も有益だと思われる．19\n\n\n3.4 属人化医療への応用\n筆者は属人化医療への応用が大きなモチベーションになっている．20\n病気の進行（あるいは健康）のモニタリングのために，健康診断やウェアラブルデバイス，フォローアップから得られるデータは，治療の見直しや異常の早期発見のために即時処理されることが望ましい．これに逐次モンテカルロ法でBayes的に迫る研究がある (Alvares et al., 2021) ！\nさらに，個々人の日常生活のレベルではSMCを用いているものはどうやらまだなく，運動と睡眠時間の間の関係と処置効果をMonte Carlo法を用いて推定している研究はある (Daza & Schneider, 2022)．これを逐次化することで，よりリアルタイムで自分に合った生活習慣への示唆が得られるアプリを開発できるかもしれない．\nまた，属人化医療においてはシステム生物学的なモデルに基づいた薬効推定が欠かせない．小規模な患者群と測定時間（服薬時間）に関する不確定性を考慮した手法が (Krengel et al., 2013) で考察されている．\n次世代DNAシークエンサーでは，DNAの各塩基ごとに異なる蛍光物質を結合させ，蛍光の波長と強度により塩基を読み取る仕組みであり，蛍光強度の生データからDNA配列データへ変換するベースコールと呼ばれる段階で粒子フィルターを使うことも提案されている (Shen & Vikalo, 2012)．\nまた，腫瘍サンプルに含まれる体細胞の突然変異に関するデータから，SMCを用いて腫瘍の発達と進行の状態を理解する手法も提案されている (Ogundijo et al., 2019)．\nCovid-19のようなパンデミックにおいて，疫学モデルを通じて時間変動する再生産数をリアルタイムでモニタリングをして意思決定に繋げるためのSMC手法も考えられており，実際にノルウェーで使用され有効性が実証された (Strovik et al., 2023)．\n状態空間が高次元になることと，既存のモデルを状態空間モデルに定式化することに困難が伴うことが，朧げながら共通課題のように思われるが，その現れ方と解決法は個々の事例で異なる．"
  },
  {
    "objectID": "posts/2023-11-25/ParticleFilter.html#footnotes",
    "href": "posts/2023-11-25/ParticleFilter.html#footnotes",
    "title": "粒子フィルターとは何か | About Particle Filters（執筆中）",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(Anderson & Moore, 1979) 第1.1節．↩︎\nこのフィルタリング問題の統計的な側面を，前述の電気工学的な側面から区別して，stochastic filteringと呼んだりもする．↩︎\n(Bain & Crisan, 2009) 1.3節．↩︎\n(Del Moral & Penev, 2014) 参照．また，(Kalman, 1960) からちょうど10周年の文献 (有本卓, 1970) に当時の雰囲気も感じさせる良いサーベイがある．↩︎\n初めの非線型化の試みは，モデルの局所線型近似に基づく拡張Kalman filterであった．しかしこれらは本稿では触れない．(Bain & Crisan, 2009) など参照．↩︎\n(Creal, 2011) p.256．↩︎\nDel MoralのWebサイトも歴史的背景に詳しい．↩︎\n(Yang et al., 2023) は水中での物体追跡が縮退により従来は粒子フィルタが使えなかった問題の解決を試みている．(Kummert et al., 2021) はロボット支援を用いた手術中に物体追跡を利用する際に，尤度が低すぎるなどの要素から追跡対象を失った状態を検出してアラートを出す機構を開発している．↩︎\nファイナンスにおける確率ボラティリティモデルなどの例が挙げられている (Creal, 2011) p.256．↩︎\n(Creal, 2011) p.246 に，粒子フィルターの経済学での応用が増えたきっかけがFernández-Villaverde and Rubio-Ramírez (2005, 2007) によるDSGEモデルの推定への応用だとしている．(矢野浩一, 2014) 実物景気循環モデル (Real Business Cycles Model) への応用を解説している．↩︎\n(Chopin & Papaspiliopoulos, 2020) 第3章参照．↩︎\n(矢野浩一, 2014) p.190，(Ristic et al., 2004) 前文 p.xi．↩︎\n(Chopin & Papaspiliopoulos, 2020, pp. 19.1節 p.371), (Creal, 2011, pp. 2.5.1節 p.258)．↩︎\n(Chopin & Papaspiliopoulos, 2020) 第8.7節 p.95，(Creal, 2011) p.253．↩︎\n(Del Moral & Horton, 2023) など↩︎\n呼び方については(Del Morel, 2013)とこの記事 も参照．↩︎\n(Ristic et al., 2004) Epilogueに次の言葉がある &gt; “The key factors for a successful application of particle filters in practice are therefore a good choice of the importance density and Rao-Blackwellization if possible.””↩︎\n探知前追跡とは，信号が弱い，またはノイズが強い環境下において，信頼のおける初期信号を頼りにせずとも，物体追跡を実行するための手法．↩︎\n(Ristic et al., 2004, p. 288) に示唆されている．↩︎\n過去の記事でも触れた．↩︎"
  },
  {
    "objectID": "posts/2023-11-22/独立性.html",
    "href": "posts/2023-11-22/独立性.html",
    "title": "正規標本の標本平均と標本分散が独立であることの証明",
    "section": "",
    "text": "次の命題の証明を与える．\nなお，この性質は正規分布を特徴付ける (Kawata & Sakamoto, 1949)．"
  },
  {
    "objectID": "posts/2023-11-22/独立性.html#sec-1",
    "href": "posts/2023-11-22/独立性.html#sec-1",
    "title": "正規標本の標本平均と標本分散が独立であることの証明",
    "section": "1 Helmert変換による証明",
    "text": "1 Helmert変換による証明\n最も直接的で，示唆も深い． (竹村彰道, 2020) 第4.3節 pp.69-70 も参照．\n\n\n\n\n\n\n定義\n\n\n\n次のように定まる行列 \\(\\mathbb{H}\\in M_{N+1}(\\mathbb{R})\\) を Helmert行列 という．2 最初の行を \\[\\mathbb{H}_{1,j}:=\\frac{1}{\\sqrt{N+1}},\\qquad 1\\le j\\le N+1,\\] とし，それ以下の行を \\[\\mathbb{H}_{i,j}:=\\overline{\\mathbb{H}}_{i,j}:=\\begin{cases}\n\\frac{1}{\\sqrt{i(i-1)}}&1\\le j&lt;i,\\\\\n-\\frac{i-1}{\\sqrt{i(i-1)}}&j=i,\\\\\n0&i&lt;j\\le N+1.\n\\end{cases}\\] と定める．このとき， \\[\\mathbb{H}=\\begin{pmatrix}\\frac{\\boldsymbol{1}_{N+1}^\\top}{\\sqrt{N+1}}\\\\\\overline{\\mathbb{H}}\\end{pmatrix}\\] と表せる．3\n\n\n\n\n\n\n\n\n補題\n\n\n\nHelmert行列 \\(\\mathbb{H}\\in M_{N+1}(\\mathbb{R})\\) とその部分行列 \\(\\overline{\\mathbb{H}}\\in M_{N,N+1}(\\mathbb{R})\\) について，\n\n直交行列である．\n次を満たす：\\[\\overline{\\mathbb{H}}^\\top\\overline{\\mathbb{H}}=I-\\frac{1}{N+1}J=\\epsilon.\\]\n\nただし，次のように定めた： \\[\n\\epsilon:=I_{N+1}-\\frac{J_{N+1}}{N+1},\\qquad J_{N+1}:=\\boldsymbol{1}_{N+1}\\boldsymbol{1}_{N+1}^\\top.\n\\]\n\n\\(x,y\\in\\mathbb{R}^{N+1}\\) に対して， \\(x^\\top\\epsilon y=(x-\\overline{x}\\boldsymbol{1}_{N+1})^\\top(y-\\overline{y}\\boldsymbol{1}_{N+1})\\)\n\n\n\n\n\n\n\n\n\n証明（補題）\n\n\n\n\\(\\mathbb{H}\\) を具体的に書けば，\n\\[\n\\mathbb{H}:=\\begin{pmatrix}\\frac{1}{\\sqrt{N+1}}&\\frac{1}{\\sqrt{N+1}}&\\frac{1}{\\sqrt{N+1}}&\\frac{1}{\\sqrt{N+1}}&\\cdots&\\cdots&\\frac{1}{\\sqrt{N+1}}\\\\\n\\frac{1}{\\sqrt{2}}&-\\frac{1}{\\sqrt{2}}&0&0&\\cdots&\\cdots&0\\\\\n\\frac{1}{\\sqrt{6}}&\\frac{1}{\\sqrt{6}}&-\\frac{2}{\\sqrt{6}}&0&\\cdots&\\cdots&0\\\\\n\\vdots&\\vdots&\\vdots&\\vdots&\\ddots&\\ddots&\\vdots\\\\\n\\frac{1}{\\sqrt{k(k-1)}}&\\cdots&\\frac{1}{\\sqrt{k(k-1)}}&\\frac{1-k}{\\sqrt{k(k-1)}}&0&\\cdots&0\\\\\n\\vdots&\\ddots&\\vdots&\\vdots&\\ddots&\\ddots&\\vdots\\\\\n\\frac{1}{\\sqrt{N(N+1)}}&\\cdots&\\cdots&\\cdots&\\cdots&\\frac{1}{\\sqrt{N(N+1)}}&\\frac{N}{\\sqrt{N(N+1)}}\n\\end{pmatrix}\n\\]\n\n\\(\\mathbb{H}\\) の任意の行は正規化されており，異なる行の間の内積は必ず零になることはすぐに判る．よって， \\(\\mathbb{H}\\mathbb{H}^\\top=I\\)．列についても同様であることが， \\[\n\\frac{1}{N+1}+\\sum_{k=1}^N\\frac{1}{k(k+1)}=1\n\\] に注意すれば同様に判る．よって，\n\n\\[\n\\mathbb{H}\\mathbb{H}^\\top=I=\\mathbb{H}^\\top\\mathbb{H}=\\frac{1}{N+1}J+\\overline{\\mathbb{H}}^\\top\\overline{\\mathbb{H}}.\n\\]\n\n1.の最後の等式から従う．なお，1.の最後の等式は次のように判る：\n\n\\[\n\\left(\\frac{\\boldsymbol{1}_{N+1}}{\\sqrt{N+1}}\\;\\overline{\\mathbb{H}}^\\top\\right)\\begin{pmatrix}\\frac{\\boldsymbol{1}_{N+1}^\\top}{\\sqrt{N+1}}\\\\\\overline{\\mathbb{H}}\\end{pmatrix}=\\frac{\\boldsymbol{1}_{N+1}\\boldsymbol{1}_{N+1}^\\top}{N+1}+\\overline{\\mathbb{H}}^\\top\\overline{\\mathbb{H}}.\n\\]\n\n\\(\\epsilon=I_{N+1}-\\frac{\\boldsymbol{1}_{N+1}\\boldsymbol{1}_{N+1}^\\top}{N+1}\\) を具体的に書けば \\[\n\\epsilon=\\begin{pmatrix}\n\\frac{N}{N+1}&-\\frac{1}{N+1}&-\\frac{1}{N+1}&\\cdots&-\\frac{1}{N+1}\\\\\n-\\frac{1}{N+1}&\\frac{N}{N+1}&-\\frac{1}{N+1}&\\cdots&-\\frac{1}{N+1}\\\\\n\\vdots&\\ddots&\\ddots&\\ddots&\\vdots\\\\\n-\\frac{1}{N+1}&\\cdots&\\cdots&-\\frac{1}{N+1}&\\frac{N}{N+1}\n\\end{pmatrix}\n\\]\n\nとなるから， \\[\n\\begin{align*}\nx^\\top\\epsilon y&=\\frac{1}{N+1}(x_1\\;\\cdots\\;x_{N+1})\\begin{pmatrix}(N+1)y_1-\\sum_{i=1}^{N+1}y_i\\\\\\vdots\\\\(N+1)y_{N+1}-\\sum_{i=1}^{N+1}y_i\\end{pmatrix}\\\\\n&=\\frac{1}{N+1}\\left((N+1)\\sum_{i=1}^{N+1}x_iy_i-\\left(\\sum_{i=1}^{N+1}x_i\\right)\\left(\\sum_{i=1}^{N+1}y_i\\right)\\right)\\\\\n&=\\sum_{i=1}^{N+1}x_iy_i-(N+1)\\overline{x}\\cdot\\overline{y}\\\\\n&=\\sum_{i=1}^{N+1}(x_iy_i-\\overline{x}\\overline{y})\\\\\n&=\\sum_{i=1}^{N+1}(x_i-\\overline{x})(y_i-\\overline{y})\\\\\n&=(x-\\boldsymbol{1}_{N+1}\\overline{x})^\\top(y-\\boldsymbol{1}_{N+1}\\overline{y}).\n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\n証明\n\n\n\n\\(\\mu=0,\\sigma^2=1\\) と仮定して示せば， 一般の \\(X_i\\) に対しても \\(\\frac{X_i-\\mu}{\\sigma}\\sim\\mathrm{N}(0,1)\\) に対して同様の議論をすることで一般の場合の結果も得る．\n\\[X_{1:N+1}:=\\begin{pmatrix}X_1\\\\\\vdots\\\\X_{N+1}\\end{pmatrix}\\sim\\mathrm{N}_{N+1}(0,I_{N+1})\\]\nに対して， \\(Y_{1:N+1}:=\\mathbb{H}X_{1:N+1}\\) と定めると， \\(\\mathbb{H}\\) は直交行列だからやはり \\(Y\\sim\\mathrm{N}_{N+1}(0,I_{N+1})\\)．加えて，\\(\\mathbb{H}\\) の構成から \\[\nY_0=\\frac{\\boldsymbol{1}_{N+1}^\\top}{\\sqrt{N+1}}X_{1:N+1}=\\sqrt{N+1}\\cdot\\overline{X}\n\\] が成り立っている．\n補題の2.と3.から， \\(Y_{2:N+1}=\\overline{\\mathbb{H}}X_{1:N+1}\\) に注意して， \\[\n\\begin{align*}\n\\|Y_{2:N+1}\\|^2&=(\\overline{\\mathbb{H}}X_{1:N+1})^\\top(\\overline{\\mathbb{H}}X_{1:N+1})\\\\\n&=X_{1:N+1}^\\top(\\overline{\\mathbb{H}}^\\top\\overline{\\mathbb{H}})X_{1:N+1}\\\\\n&=X_{1:N+1}^\\top\\epsilon X_{1:N+1}=\\|X_{1:N+1}-\\overline{X}\\boldsymbol{1}_{N+1}\\|^2\\\\\n&=\\sum_{i=1}^{N+1}(X_i^2-\\overline{X}^2)\\\\\n&=\\sum_{i=1}^{N+1}(X_i-\\overline{X})^2=NU^2.\n\\end{align*}\n\\]\n以上より， \\(\\overline{X}\\) は \\(Y_1\\) のみの関数で， \\(S^2,U^2\\) は \\(Y_{2:N+1}\\) のみの関数であるから，互いに独立である．"
  },
  {
    "objectID": "posts/2023-11-22/独立性.html#basuの定理による証明",
    "href": "posts/2023-11-22/独立性.html#basuの定理による証明",
    "title": "正規標本の標本平均と標本分散が独立であることの証明",
    "section": "2 Basuの定理による証明",
    "text": "2 Basuの定理による証明\n\n\n\n\n\n\n(Basu, 1955)\n\n\n\n\\(\\{P_\\theta\\}_{\\theta\\in\\Theta}\\) を分布族， \\((\\mathcal{X},\\mathcal{A}),(\\mathcal{T},\\mathcal{B}),(\\mathcal{V},\\mathcal{C})\\) を可測空間とする． \\(T:\\mathcal{X}\\to\\mathcal{T}\\) を \\(\\{P_\\theta\\}_{\\theta\\in\\Theta}\\) の完備十分統計量，統計量 \\(V:\\mathcal{X}\\to\\mathcal{V}\\) の分布 \\(P^V_\\theta\\) は \\(\\theta\\) に依らないとする．4 このとき，任意の \\(\\theta\\in\\Theta\\) に対して，\\(T\\) と \\(V\\) は独立である： \\[P_\\theta[T\\in A,V\\in B]=P_\\theta[T\\in A]P_\\theta[V\\in B]\\qquad(A\\in\\mathcal{B},B\\in\\mathcal{C},\\theta\\in\\Theta)\\]\n\n\n\n\n\n\n\n\n証明（Basuの定理）\n\n\n\n仮定より，\\(p_B:=P_\\theta[V\\in B]\\in\\mathbb{R},q_B(T):=P_\\theta[V\\in B|T]:\\mathcal{X}\\to\\mathbb{R}\\) は \\(\\theta\\in\\Theta\\) に依らない． これに対して，条件付き期待値の性質から \\[p_B=E_\\theta[1_B(V)]=E_\\theta[E_\\theta[1_B(V)|T]]=E_\\theta[q_B(T)]\\] であるから，\\(E_\\theta[p_B-q_B(T)]=0\\) が従う． 完備性から，\\(P_\\theta[p_B=q_B(T)]=1\\)．よって，任意の \\(\\theta\\in\\Theta\\) について， \\[\\begin{align*}\n    P_\\theta[T\\in A,V\\in B]&=E_\\theta[1_A(T)1_B(V)]\\\\\n    &=E_\\theta[1_A(T)E_\\theta[1_B(V)|T]]\\\\\n    &=E_\\theta[1_A(T)q_B(T)]\\\\\n    &=E_\\theta[1_A(T)p_B]\\\\\n    &=E_\\theta[1_A(T)]p_B\\\\\n    &=P_\\theta[T\\in A]P_\\theta[V\\in B].\n\\end{align*}\\]\n\n\nこれを用いて，次のように証明できる．\n\n\n\n\n\n\n証明\n\n\n\n\n標本平均は平均の完備十分統計量である\n標本分散は平均の補助統計量である\n\nの2点を示せば，Basuの定理から，標本平均と標本分散は独立である：\\(\\overline{X}\\perp\\!\\!\\!\\perp S^2\\)． 同様にして，標本平均と不偏分散も独立である．\n\n分布族 \\(\\{\\mathrm{N}(\\mu,\\sigma^2)^{\\otimes n}\\}_{\\mu\\in\\mathbb{R}}\\) は指数型であり， 統計量 \\[T_1(x):=\\sum_{i\\in[n]}x_i=n\\overline{X}\\] は \\(\\mu\\) の完備十分統計量である．\n標本分散の分布は \\[S^2:=\\frac{1}{n}\\sum_{i\\in[n]}(X_i-\\overline{X})^2\\sim\\chi^2(n-1)\\] より，パラメータ\\(\\mu\\in\\mathbb{R}\\)に依らない．"
  },
  {
    "objectID": "posts/2023-11-22/独立性.html#fisher-cochranの定理の考え方",
    "href": "posts/2023-11-22/独立性.html#fisher-cochranの定理の考え方",
    "title": "正規標本の標本平均と標本分散が独立であることの証明",
    "section": "3 Fisher-Cochranの定理の考え方",
    "text": "3 Fisher-Cochranの定理の考え方\n総合研究大学院大学統計科学コース2021年8月実施の入試問題の第三問にて，本命題を背景とした問題が出題された．このアプローチは Section 1 の証明法を別の角度から見れる．5\n\n\n\n\n\n\n補題\n\n\n\n\\[X_{1:n}=\\begin{pmatrix}X_1\\\\\\vdots\\\\X_n\\end{pmatrix},\\qquad X_i\\overset{\\mathrm{i.i.d.}}{\\sim}\\mathrm{N}(\\mu,\\sigma^2),\\] をGauss確率ベクトル，\\(B\\in M_{mn}(\\mathbb{R}),A\\in M_n(\\mathbb{R})\\) を対称行列とする．\\(BA=O_{m,n}\\) のとき，2つの確率変数 \\(BX_{1:n}\\) と \\(X^\\top_{1:n} AX_{1:n}\\) とは独立になる．\n\n\n\n\n\n\n\n\n証明（補題）\n\n\n\n\\(A\\) は対称行列だから，ある直交行列 \\(U\\in \\mathrm{O}_n(\\mathbb{R}),U^\\top U=I_n\\) を用いて，\\(U^\\top DU=A\\) と対角化出来る．ただし， \\(D:=\\mathrm{diag}(a_1,\\cdots,a_r)\\in M_n(\\mathbb{R}),r:=\\mathop{\\mathrm{\\mathrm{rank}}}A\\) は対角行列とした． よって，\\(Y_{1:n}:=UX_{1:n}\\) と定めると，これは再び成分が互いに独立な正規確率変数のベクトル \\(Y_{1:n}\\sim\\mathrm{N}_n(\\mu U1_n,\\sigma^2I_n)\\) で， \\[X_{1:n}^\\top AX_{1:n}=(UX_{1:n})^\\top D(UX_{1:n})=a_1Y_1^2+\\cdots+a_rY_r^2,\\] と表せる．\n次に，\\(BA=0\\) より，\\(\\mathrm{Im}\\;A\\subset\\mathrm{Ker}\\;B\\)，従って双方の直交補空間を考えると \\(\\mathrm{Im}\\;B\\subset\\mathrm{Ker}\\;A\\) でもあるから，\\(BX_{1:n}\\) は \\(y_{r+1},\\cdots,y_{n}\\) のみによって表せる確率変数のベクトルである（使わないものも許す）． よって，\\(BX_{1:n}\\) と \\(X_{1:n}^\\top AX_{1:n}\\) は独立．\n\n\n\n\n\n\n\n\n証明\n\n\n\n\\(m=1,B:=\\frac{1}{N+1}1_{N+1}^\\top\\) と \\[A:=N\\epsilon=\\frac{N}{N+1}\\begin{pmatrix}\nN&-1&-1&\\cdots&-1\\\\\n-1&N&-1&\\cdots&-1\\\\\n\\vdots&\\ddots&\\ddots&\\ddots&\\vdots\\\\\n-1&\\cdots&\\cdots&-1&N\n\\end{pmatrix}\\in M_{N+1}(\\mathbb{R})\\] と定めると，\\(BA=O\\) であり，同時に \\(\\overline{X}=BX_{1:N+1}\\) かつ \\(U^2=X^\\top_{1:N} AX_{1:N}\\) である．"
  },
  {
    "objectID": "posts/2023-11-22/独立性.html#footnotes",
    "href": "posts/2023-11-22/独立性.html#footnotes",
    "title": "正規標本の標本平均と標本分散が独立であることの証明",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n\\(U^2\\) は不偏分散と呼ばれる統計量である．代わりに標本分散 \\(S^2:=\\frac{1}{N+1}\\sum_{i=1}^{N+1}(X_i-\\overline{X})^2\\) を考えても同様の主張 \\(\\overline{X}\\perp\\!\\!\\!\\perp S^2\\) を得る．↩︎\n(Del Moral & Horton, 2023) も参照．↩︎\n\\(\\boldsymbol{1}_{N+1}\\) は \\(1\\) のみを成分に持つ \\(\\mathbb{R}^{N+1}\\) の元， \\(\\overline{\\mathbb{H}}\\) は行列 \\(\\overline{\\mathbb{H}}:=(\\overline{\\mathbb{H}}_{i,j})_{2\\le i\\le N+1,1\\le i\\le N+1}\\) とした．↩︎\nこのような性質を満たす統計量 \\(V\\) を分布族 \\(\\{P_\\theta\\}_{\\theta\\in\\Theta}\\) の補助統計量という．↩︎\n過去9年分の入試問題の解答はこちらから↩︎"
  },
  {
    "objectID": "posts/2023-11-24/Beta-Gamma.html",
    "href": "posts/2023-11-24/Beta-Gamma.html",
    "title": "独立なGamma確率変数の商による変換も独立",
    "section": "",
    "text": "Gamma確率変数と，その変換として得るBeta確率変数とに関する次の命題の証明を与える．"
  },
  {
    "objectID": "posts/2023-11-24/Beta-Gamma.html#gamma分布を見る",
    "href": "posts/2023-11-24/Beta-Gamma.html#gamma分布を見る",
    "title": "独立なGamma確率変数の商による変換も独立",
    "section": "1 Gamma分布を見る",
    "text": "1 Gamma分布を見る\n\n1.1 定義\n\n\n\n\n\n\n定義（Gamma分布）\n\n\n\n可測空間 \\((\\mathbb{R},\\mathcal{B}(\\mathbb{R}))\\) 上の Gamma分布 \\(\\mathrm{Gamma}(\\alpha,\\nu)\\;(\\alpha,\\nu&gt;0)\\) とは， 密度関数 \\[g(x;\\alpha,\\nu):=\\frac{1}{\\Gamma(\\nu)}\\alpha^\\nu x^{\\nu-1}e^{-\\alpha x}1_{\\left\\{x&gt;0\\right\\}}\\] が定める分布をいう．実際，\\(t=\\alpha x\\) と変数変換すると， \\[\n\\begin{align*}\n&\\quad\\int_0^\\infty \\alpha^\\nu x^{\\nu-1}e^{-\\alpha x}dx\\\\\n&=\\alpha^\\nu\\int^\\infty_0\\left(\\frac{t}{\\alpha}\\right)^{\\nu-1}e^{-t}\\frac{dt}{\\alpha}\\\\&=\\int^\\infty_0t^{\\nu-1}e^{-t}dt=\\Gamma(\\nu).\\end{align*}\\]\n\n\n\n\n1.2 形状\n\\(\\alpha\\) をレートパラメータ（スケールパラメータと呼ばれるものの逆数），\\(\\nu\\) を形状パラメータともいう．レートパラメータが大きいほど突起も大きく，手前に寄る．形状パラメータ \\(\\nu\\) は分布の形状を大きく司る．実際，先度と歪度は形状パラメータのみに依って \\[\\gamma_1=\\frac{2}{\\sqrt{\\nu}},\\qquad\\gamma_2=3+\\frac{6}{\\nu},\\] と記述される． その意味するところを感得するために，scipy.statsでの実装を用いてプロットしてみる．\n\n\nコードを表示\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import gamma\n\nnu = 1.5  # 形状パラメーター\n\n# Gamma分布のPDFをグリッド上で計算\nx = np.linspace(0, 8, 100)\npdf = gamma.pdf(x, nu)\n\n# プロットの実行\nplt.figure(figsize=(3.2, 4.8)) # スマホサイズに合わせる\nplt.plot(x, pdf)\nplt.title('Gamma(1,3/2) Distribution')\nplt.ylabel('Density')\nplt.xlabel('Value')\nplt.show()\n\n\n\n\n\nレートパラメータを固定し，形状パラメータを残した \\[\\chi^2(k):=\\mathrm{Gamma}(1/2,k/2)\\] を自由度 \\(k\\) のカイ自乗分布ということに注意．\n\n\n\n\n\n最後に，レートパラメータが大きいほど突起が大きくなる様子は次の通り：\n\n\n\n\n\nなお，形状パラメータが \\(\\nu=1\\) であるGamma分布のことを指数分布という： \\[\n\\mathrm{Exp}\\;(\\gamma):=\\mathrm{Gamma}(\\gamma,1)\\;(\\gamma&gt;0)\n\\]"
  },
  {
    "objectID": "posts/2023-11-24/Beta-Gamma.html#beta分布を見る",
    "href": "posts/2023-11-24/Beta-Gamma.html#beta分布を見る",
    "title": "独立なGamma確率変数の商による変換も独立",
    "section": "2 Beta分布を見る",
    "text": "2 Beta分布を見る\n\n2.1 定義\n\n\n\n\n\n\n定義（Beta分布）\n\n\n\n可測空間 \\(((0,1),\\mathcal{B}((0,1)))\\)上の （第１種）ベータ分布 \\(\\mathrm{Beta}(\\alpha,\\beta)\\;(\\alpha,\\beta&gt;0)\\) とは， 密度関数 \\[\\frac{1}{B(\\alpha,\\beta)}x^{\\alpha-1}(1-x)^{\\beta-1}1_{(0,1)}(x)\\] が定める分布をいう．ただし，\\[B(\\alpha,\\beta)=\\int^1_0x^{\\alpha-1}(1-x)^{\\beta-1}\\,dx.\\]\n\n\n\n\n2.2 形状\n次のような性質を持つ：1\n\n\\(\\alpha_1=\\alpha_2=1\\) のとき一様分布となり，\\(\\alpha_1=\\alpha_2&gt;1\\) の場合に左右対称な単峰性分布，\\(\\alpha_1=\\alpha_2&lt;1\\) の場合に左右対称なU字型の二峰性分布を得る．\nいずれも \\(1\\) より大きい場合，左のパラメータが大きい場合 \\(\\alpha_1&gt;\\alpha_2&gt;1\\) 左に，右のパラメータが大きい場合 \\(\\alpha_2&gt;\\alpha_1&gt;1\\) 右に歪んだ単峰性分布を得る．\nいずれも \\(1\\) より小さい場合はその逆．"
  },
  {
    "objectID": "posts/2023-11-24/Beta-Gamma.html#証明",
    "href": "posts/2023-11-24/Beta-Gamma.html#証明",
    "title": "独立なGamma確率変数の商による変換も独立",
    "section": "3 証明",
    "text": "3 証明\n\n\n\n\n\n\n証明\n\n\n\n\\[\\begin{cases}\n    X_1=\\frac{Y_1}{Y_1+Y_2},\\\\\n    X_2=Y_1+Y_2.\n\\end{cases}\\] を逆に解くことで， \\[\\begin{pmatrix}y_1\\\\y_2\\end{pmatrix}=\\begin{pmatrix}x_1x_2\\\\x_2\\end{pmatrix}=:T(x_1,x_2)\\] を得る．\\(A:=(0,1)\\times(0,\\infty),B:=(0,\\infty)^2\\) と定めると，\\(T:A\\to B\\) は可微分同相で，Jacobianは \\[DT=\\begin{pmatrix}x_2&x_1\\\\0&1\\end{pmatrix},\\qquad J_T=x_2,\\] と計算でき，\\(A\\) 上で は消えない．\nよって \\((X_1,X_2)\\) の結合分布は \\[\n\\begin{align*}\n    &\\quad p(T(x_1,x_2))J_T(x_1,x_2)dx_1dx_2\\\\\n    &=\\frac{\\alpha^{\\nu_1}}{\\Gamma(\\nu_1)}y_1^{\\nu_1-1}e^{-\\alpha y_1}\\frac{\\alpha^{\\nu_2}}{\\Gamma(\\nu_2)}y_2^{\\nu_2-1}e^{-\\alpha y_2}\\frac{x_2}{(1-x_1)^2}\\,dx_1dx_2\\\\\n    &=\\frac{\\alpha^{\\nu_1}}{\\Gamma(\\nu_1)}x_1^{\\nu_1-1}x_2^{\\nu_1-1}e^{-\\alpha x_1x_2}\\frac{\\alpha^{\\nu_2}}{\\Gamma(\\nu_2)}x_2^{\\nu_2-1}(1-x_1)^{\\nu_2-1}e^{-\\alpha x_2(1-x_1)}\\\\\n    &\\hspace{10cm}\\times x_2\\,dx_1dx_2\\\\\n    &=\\underbrace{\\frac{\\Gamma(\\nu_1+\\nu_2)}{\\Gamma(\\nu_1)\\Gamma(\\nu_2)}}_{=B(\\nu_1,\\nu_2)^{-1}}x_1^{\\nu_1-1}(1-x_1)^{\\nu_2-1}\\,dx_1\\\\\n    &\\hspace{5cm}\\times\\frac{\\alpha^{\\nu_1+\\nu_2}}{\\Gamma(\\nu_1+\\nu_2)}x_2^{(\\nu_1+\\nu_2)-1}e^{-\\alpha x_2}\\,dx_2.\n\\end{align*}\n\\] これは \\(X_1\\) が \\(\\mathrm{Beta}(\\nu_1,\\nu_2)\\) に，\\(X_2\\) が \\(\\mathrm{Gamma}(\\alpha,\\nu_1+\\nu_2)\\) に独立に従った場合の密度になっている．"
  },
  {
    "objectID": "posts/2023-11-24/Beta-Gamma.html#余談",
    "href": "posts/2023-11-24/Beta-Gamma.html#余談",
    "title": "独立なGamma確率変数の商による変換も独立",
    "section": "4 余談",
    "text": "4 余談\n総合研究大学院大学統計科学コース2018年8月実施の入試問題の第三問にて，本命題を背景とした問題が出題された．2\n\n\n\n\n\n\n第３問\n\n\n\n\n数直線 \\(\\mathbb{R}\\) 上の点Pの \\(x\\) 座標 \\(X\\) は \\(\\mathrm{N}(0,1)\\) に従うとする． Pの原点からの距離の自乗の確率密度関数が \\[\\frac{1}{\\sqrt{2\\pi x}}e^{-\\frac{x}{2}},\\qquad(x&gt;0)\\] であることを示せ．\nEuclid空間 \\(\\mathbb{R}^n\\) 内の点Qの座標 \\((X_1,\\cdots,X_n)\\) は \\(\\mathrm{N}_n(0,I_n)\\) に従うとする． Qの原点からの距離の自乗の確率密度関数が \\[\\frac{1}{\\Gamma\\left(\\frac{n}{2}\\right)2^{\\frac{n}{2}}}x^{\\frac{n}{2}-1}e^{-\\frac{x}{2}},\\qquad(x&gt;0)\\] であることを示せ．\n(2)の確率密度関数を持つ分布を \\(\\chi^2(n)\\) という． 確率変数 \\(X,Y\\) は独立で \\(X\\sim\\chi^2(n),Y\\sim\\chi^2(m)\\) であるとする．このとき， \\[X+Y\\sim\\chi^2(n+m),\\] \\[\\frac{X}{X+Y}\\sim\\mathrm{Beta}(n/2,m/2),\\] であり，互いに独立であることを示せ．"
  },
  {
    "objectID": "posts/2023-11-24/Beta-Gamma.html#footnotes",
    "href": "posts/2023-11-24/Beta-Gamma.html#footnotes",
    "title": "独立なGamma確率変数の商による変換も独立",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(Agresti, 2012) 第1.6.2節 Binomial Estimation: Beta and Logit-Normal Prior Distributions p.24 参照．↩︎\n過去9年分の入試問題の解答はこちらから↩︎"
  },
  {
    "objectID": "static/About.html",
    "href": "static/About.html",
    "title": "Hirofumi Shiba | 司馬博文",
    "section": "",
    "text": "Hirofumi Shiba, specializing in Bayesian Computation – a field focused on developing computational methods for Bayesian inference and learning, is a Ph.D. candidate at the Institute of Statistical Mathematics in Japan.\nHe was born in Yokohama in May 1999. He received his Bachelor of Science degree in Mathematics from the University of Tokyo in 2023, where he was mentored by Professor Nakahiro Yoshida.\nContinuing his focus on statistical inference for stochastic processes, he is now further specializing in nonlinear filtering and particle methods under the supervision of Professor Kengo Kamatani.\nHe is fluent in Japanese, Mandarin Chinese, and English.\nHe also contributes to the YUIMA package, an open-source project focused on the simulation and inference of multidimensional stochastic differential equations.\nThis blog was branched off from the team’s homepage to cover more specialized topics in English and Japanese. The team name “Ano2math5” is pronounced in the same way as the word “anonymous” when read in Japanese."
  },
  {
    "objectID": "static/About.html#biography",
    "href": "static/About.html#biography",
    "title": "Hirofumi Shiba | 司馬博文",
    "section": "",
    "text": "Hirofumi Shiba, specializing in Bayesian Computation – a field focused on developing computational methods for Bayesian inference and learning, is a Ph.D. candidate at the Institute of Statistical Mathematics in Japan.\nHe was born in Yokohama in May 1999. He received his Bachelor of Science degree in Mathematics from the University of Tokyo in 2023, where he was mentored by Professor Nakahiro Yoshida.\nContinuing his focus on statistical inference for stochastic processes, he is now further specializing in nonlinear filtering and particle methods under the supervision of Professor Kengo Kamatani.\nHe is fluent in Japanese, Mandarin Chinese, and English.\nHe also contributes to the YUIMA package, an open-source project focused on the simulation and inference of multidimensional stochastic differential equations.\nThis blog was branched off from the team’s homepage to cover more specialized topics in English and Japanese. The team name “Ano2math5” is pronounced in the same way as the word “anonymous” when read in Japanese."
  },
  {
    "objectID": "static/About.html#education",
    "href": "static/About.html#education",
    "title": "Hirofumi Shiba | 司馬博文",
    "section": "Education",
    "text": "Education\n\nPh.D. in Statistical Science\nGraduate University for Advanced Studies, SOKENDAI, Tokyo, Japan\nApr. 2023 - Mar. 2028 (expected)\nB.A. in Mathematics\nUniversity of Tokyo, Japan\nApr. 2019 - Mar. 2023"
  },
  {
    "objectID": "static/About.html#experience",
    "href": "static/About.html#experience",
    "title": "Hirofumi Shiba | 司馬博文",
    "section": "Experience",
    "text": "Experience\n\nResearch Assistant at the Institute of Statistical Mathematics\nJuly 2023 - present\nCooperative Researcher at the RCAST, the University of Tokyo\nApr. 2023 - present\nData Scientist at IMIS Co., Ltd.\nAug. 2022 - Dec. 2023\n\n\nLast Update: Dec. 3rd, 2023"
  },
  {
    "objectID": "static/about.html",
    "href": "static/about.html",
    "title": "Hirofumi Shiba | 司馬博文",
    "section": "",
    "text": "Hirofumi Shiba, specializing in Bayesian Computation – a field focused on developing computational methods for Bayesian inference and learning, is a Ph.D. candidate at the Institute of Statistical Mathematics in Japan.\nHe was born in Yokohama in May 1999. He received his Bachelor of Science degree in Mathematics from the University of Tokyo in 2023, where he was mentored by Professor Nakahiro Yoshida.\nContinuing his focus on statistical inference for stochastic processes, he is now further specializing in nonlinear filtering and particle methods under the supervision of Professor Kengo Kamatani.\nHe is fluent in Japanese, Mandarin Chinese, and English.\nHe also contributes to the YUIMA package, an open-source project focused on the simulation and inference of multidimensional stochastic differential equations.\nThis blog was branched off from the team’s homepage to cover more specialized topics in English and Japanese. The team name “Ano2math5” is pronounced in the same way as the word “anonymous” when read in Japanese."
  },
  {
    "objectID": "static/about.html#biography",
    "href": "static/about.html#biography",
    "title": "Hirofumi Shiba | 司馬博文",
    "section": "",
    "text": "Hirofumi Shiba, specializing in Bayesian Computation – a field focused on developing computational methods for Bayesian inference and learning, is a Ph.D. candidate at the Institute of Statistical Mathematics in Japan.\nHe was born in Yokohama in May 1999. He received his Bachelor of Science degree in Mathematics from the University of Tokyo in 2023, where he was mentored by Professor Nakahiro Yoshida.\nContinuing his focus on statistical inference for stochastic processes, he is now further specializing in nonlinear filtering and particle methods under the supervision of Professor Kengo Kamatani.\nHe is fluent in Japanese, Mandarin Chinese, and English.\nHe also contributes to the YUIMA package, an open-source project focused on the simulation and inference of multidimensional stochastic differential equations.\nThis blog was branched off from the team’s homepage to cover more specialized topics in English and Japanese. The team name “Ano2math5” is pronounced in the same way as the word “anonymous” when read in Japanese."
  },
  {
    "objectID": "static/about.html#education",
    "href": "static/about.html#education",
    "title": "Hirofumi Shiba | 司馬博文",
    "section": "Education",
    "text": "Education\n\nPh.D. in Statistical Science\nGraduate University for Advanced Studies, SOKENDAI, Tokyo, Japan\nApr. 2023 - Mar. 2028 (expected)\nB.A. in Mathematics\nUniversity of Tokyo, Japan\nApr. 2019 - Mar. 2023"
  },
  {
    "objectID": "static/about.html#interests",
    "href": "static/about.html#interests",
    "title": "Hirofumi Shiba | 司馬博文",
    "section": "Interests",
    "text": "Interests"
  },
  {
    "objectID": "static/about.html#experiences",
    "href": "static/about.html#experiences",
    "title": "Hirofumi Shiba | 司馬博文",
    "section": "Experiences",
    "text": "Experiences\n\nResearch Assistant at the Institute of Statistical Mathematics\nJuly 2023 - present\nCooperative Researcher at the RCAST, the University of Tokyo\nApr. 2023 - present\nData Scientist at IMIS Co., Ltd.\nAug. 2022 - Dec. 2023\n\n\nLast Update: Dec. 3rd, 2023"
  },
  {
    "objectID": "posts/2023-11-11/MarkovCategory.html",
    "href": "posts/2023-11-11/MarkovCategory.html",
    "title": "Markov Category (nLab) | 紹介",
    "section": "",
    "text": "綜合的確率論(synthetic probability)とは，確率論の定義と定理を，その性質によって特徴づけようとする試みである．確率論が測度論に依拠しているのは「一つの実装例」に過ぎず，より普遍的で自然な定義が見つかるはずだ，というものである．思えば，条件付き期待値がa.s.にしか定まらないこと，多くの正則性条件が成り立つためには空間の可分性が必要であること．確率論には，あまりにも恣意的で非本質的な，「確率論に関係のない議論」が多いとは思わないか？これは，確率というものの数理的な構造を，我々が正しく把握できていないからなのではないか？\n\nThe basic object of study in probability is the random variable and I will argue that it should be treated as a basic construct . . . and it is artificial and unnatural to define it in terms of measure theory. [@Mumford00-DawnOfStochasticity]\n\nこのような精神を持ち，具体的には圏論的な方法で，確率論のもう一つのモデルを構築しようとするのが綜合的確率論(synthetic probability)である．Anders Kock と Lewvereによる綜合的微分幾何学(synthetic differential geometry)からのシリーズを意識した命名であり，数学の各分野を「圏論化」することを，「綜合的」という形容詞で捉えようとしている．\nnLabとは，圏論的な視点から種々の数学・物理学・哲学の概念をまとめた，有志によって運営されているウィキである．今回はMarkov圏のページを翻訳．\n\n\n\nimg\n\n\n\n1．アイデア\nMarkov圏の概念は，確率統計学の綜合的(synthetic)な側面を表現する方法の1つである．すなわち，確率統計学を基礎付ける構造と公理からなり，これを用いて測度論を介することなく直接的に種々の定理が示せる．通常の測度論的な議論は，綜合的確率論のモデル（意味論）の1つであると見なされる．\n直感的に言えば，Markov圏とは射が「確率変数」または「Markov核」（ここから名前がついた）と見なせるような，確率論で用いられる圏である．標準的な例に，Kleisli圏や確率モナドがあるが，Markov圏は更に一般的な枠組みである．\n\n\n2．定義\nMarkov圏とは，半デカルト対称モノイダル圏 \\((C,\\otimes,1)\\) であって，その対象 \\(X\\in C\\) が可換な内部余モノイドの構造を持つものである．余乗法と余単位写像は \\(\\mathrm{copy}:X\\to X\\otimes X\\) と \\(\\mathrm{delete}:X\\to1\\) とそれぞれ表される．\n複製写像とテンソル積の間に次の整合性条件を課す：任意の対象 \\(X,Y\\in C\\) に対して，\n\\[\n\\mathrm{copy}_{X\\otimes Y}=(\\mathrm{id}_X\\otimes b_{Y,X}\\otimes\\mathrm{id}_Y)(\\mathrm{copy}_X\\otimes\\mathrm{copy}_Y).\n\\]\nただし， \\(d\\) でブライダルを表す．\nまた，写像 \\(\\mathrm{delete}:X\\to 1\\) は， \\(1\\) が終対象であることから一意的であるため，更に \\(X\\) 内で自然であることに注意．一方で，複製写像は自然とは限らない．\n\n\n3．注\n\nA Markov category can equivalently be defined as a semicartesian symmetric monoidal category that supplies commutative comonoids.\n\n\n\n4．例\n\n有限集合と確率行列のなす圏 \\(\\mathtt{FinStoch}\\) ．\n可測空間とMarkov核のなす圏 \\(\\mathtt{Stoch}\\) ．\n任意のデカルトモノイダル圏 \\(C\\) が，モノイド単位を保存するモノイダルモナド \\(T\\) を持つならば，そのKleisli圏 \\(\\mathrm{Kl}(T)\\) はMarkov圏になる．\n\n\n\n5．決定論的な射\nMarkov圏の射 \\(f:X\\to Y\\) が決定論的であるとは，複製写像と可換であることをいう：\n\\[\n\\mathrm{copy}\\circ f=(f\\otimes f)\\circ\\mathrm{copy}.\n\\]\nこの定義のモチベーションは以下の通りである． \\(f\\) が例えば実数上の実確率変数で，入力に，サイコロの目を振ってでた値を加えるような関数であるとしよう．すると，入力 \\(x\\in\\mathbb{R}\\) に対して，サイコロを振り，出た目 \\(n\\in[6]\\) を加えて得た結果をコピーするから，左辺は \\((x+n,x+n)\\) である．一方で，まず入力 \\(x\\in\\mathbb{R}\\) を複製写像 \\(\\mathrm{copy}\\) に渡し， \\((x,x)\\) を得た後でサイコロを2回降り，出た目 \\(n_1,n_2\\in[6]\\) をそれぞれ加えると，右辺は \\((x+n_1,x+n_2)\\) となるが，別々の試行で出た目が一致する \\(n_1=n_2\\) とは限らない．この性質を，「ランダム性」の定義とする，というのである：つまりランダム性とは，2回行ったときに結果が異なり得る，という過程に宿るものとする．また，同値なことだが，その過程の前に情報を複製することと，その過程を見た後に情報を複製することとで，異なる状況を与えるような「過程」のことだとも理解できる．\n\n\n10．参考文献\nTobias Fritz（現在オーストリアInnsbruck大学）がこの分野の騎手であり，他にホモトピー型理論のレクチャーノートも執筆している．\n\nTobias Fritz (2019) A synthetic approach to Markov kernels, conditional independence and theorems on sufficient statistics. (arXiv:1908.07021)\nTobias Fritz and Eigil Fjeldgren Rischel (2019) The zero-one laws of Kolmogorov and Hewitt–Savage in categorical probability. (arXiv:1912.02769)\n\nこの研究の流れは，Bart Jacobsによるchannel perspectiveを汲んでいる．彼らは同様の概念をaffine CD-圏と呼んでいたようだ．\n\nBart Jacobs and Fabio Zanasi (2018) The Logical Essentials of Bayesian Reasoning. (arXiv:1804.01193)"
  },
  {
    "objectID": "static/about.html#experience",
    "href": "static/about.html#experience",
    "title": "Hirofumi Shiba | 司馬博文",
    "section": "Experience",
    "text": "Experience\n\nResearch Assistant at the Institute of Statistical Mathematics\nJuly 2023 - present\nCooperative Researcher at the RCAST, the University of Tokyo\nApr. 2023 - present\nData Scientist at IMIS Co., Ltd.\nAug. 2022 - Dec. 2023\n\n\nLast Update: Dec. 3rd, 2023"
  },
  {
    "objectID": "posts/2023-12-6/BayesainComp.html",
    "href": "posts/2023-12-6/BayesainComp.html",
    "title": "ベイズ計算とは何か | About Bayesian Computation（執筆中）",
    "section": "",
    "text": "Thomas Bayes 1701-1761 は英国の牧師である．\n当時は統計的推定の問題が肝要であった．その中でも，次のような「区間推定」の問題を考えていた．\n\n$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$\n\n\n\n\n\n\n\n問題\n\n\n\n2値のデータ \\(Y_i\\in\\{0,1\\}\\) は，ある未知の「成功率」 \\(\\theta\\in(0,1)\\) に従って，確率 \\(\\theta\\) で \\(Y_i=1\\)，確率 \\(1-\\theta\\) で \\(Y_i=0\\) となるとする．1 仮に，\\(Y_i\\) は性別で，\\(\\theta\\) は男児が生まれる確率だと捉えることとしよう．2 このようなデータが独立に観測されて，\\(Y_1,\\cdots,Y_n\\) と得られているとする．真の成功率 \\(\\theta\\) が区間 \\((a,b)\\subset(0,1)\\) に入っているという確率をどう見積もれば良いか？\n\n\n彼の発想は極めてシンプルである．\n\nまず事前分布 \\(p(\\theta)\\) と呼ばれる，最初の \\(\\theta\\) に対する予想を自由に表現する．\nこれをデータを用いて修正して，事後分布 \\(p(\\theta|Y_1,\\cdots,Y_n)\\) を得る．これは「データ \\(Y_1,\\cdots,Y_n\\) が得られた，という条件の下で考えた条件付き分布」である．\nこの事後分布の形から区間推定を実行する．\n\n\n\n\n\n\n\n(Bayes, 1763) のアイデア\n\n\n\n事前分布として最初の予想をすると言っても，\\(\\theta\\in(0,1)\\) は全く予想がつかないとして，ここでは「どんな \\(\\theta\\) もあり得る」という意味で，\\(p(\\theta)\\) を一様分布に設定しよう：\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define the range for x-axis\nx = np.linspace(0, 1, 1000)\n\n# Uniform distribution density function is constant\ny = np.ones_like(x)\n\n# Plot the graph\nplt.figure(figsize=(6, 4)) # Size suitable for a smartphone screen\nplt.plot(x, y, label='Uniform Distribution (0,1)', color=(0.35, 0.71, 0.73, 1))\nplt.fill_between(x, y, color=(0.35, 0.71, 0.73, 0.3))\nplt.xlabel('x')\nplt.ylim(0, 1.5)\nplt.ylabel('Density')\nplt.title('Density Function of Uniform Distribution on (0,1)')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\nこのように，一様分布とは「どのような \\(\\theta\\) の値も同様に確からしい」という予想の表現である．しかし，データ \\(Y_1,\\cdots,Y_n\\) が得られている今，どんな \\(\\theta\\) も等しく尤もらしいという訳ではない．そこで，「データ \\(Y_1,\\cdots,Y_n\\) に関する条件付き分布」を計算することとする．実は，簡単な確率の法則から，次の公式を得ることができる：3 \\[\np(\\theta|Y_1,\\cdots,Y_n)=\\frac{p(Y_1,\\cdots,Y_n|\\theta)p(\\theta)}{\\int_\\Theta p(Y_1,\\cdots,Y_n|\\theta)p(\\theta)\\,d\\theta}\n\\tag{1}\\]\nこれを用いて，条件付き分布 \\(p(\\theta|Y_1,\\cdots,Y_n)\\) を計算する．例えば日本の2021年の出生児性別のデータを用いると次のようになる．\n\n\nCode\nimport matplotlib.pyplot as plt\nfrom scipy.stats import beta\n\n# パラメータの設定\nn = 811622\nmale = 415903\nfemale = n - male\n\n# ベータ分布のPDFを計算\nx = np.linspace(0, 1, 1000)\ny = beta.pdf(x, 1+male, 1+female)\n\n# プロット\nplt.figure(figsize=(6, 4))\nplt.plot(x, y, label=f'Beta({1+male}, {1+female})', color=(0.35, 0.71, 0.73, 1))\nplt.fill_between(x, y, color=(0.35, 0.71, 0.73, 0.3))\nplt.xlabel('p')\nplt.xlim(0.4, 0.6)\nplt.ylabel('Probability Density')\nplt.title('Bayesian Posterior Distribution')\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\nこうして極めて鋭い事後分布が出来た．では区間推定の例として，\\((a,b)=(0.5,1.0)\\) として，「男児の方が女児よりも多い確率」を推定しよう．これは次を計算することになる： \\[\n\\mathrm{P}\\left[\\frac{1}{2}&lt;\\theta&lt;1\\right]=\\int^1_{\\frac{1}{2}}p(Y_1,\\cdots,Y_n|\\theta)\\,d\\theta.\n\\]\n\n\nCode\nprint(sum(y[500:600])/1000)\n\n\n1.003097768300707\n\n\nもはや丸め誤差により \\(1\\) を越してしまっている．ほとんど確実に「男児の方が生まれる確率が高い」と結論づけて良いだろう．\n\n\nこの (Bayes, 1763) が実行したように，事後確率 \\(p(\\theta|Y_1,\\cdots,Y_n)\\) をみて \\(\\theta\\) に関する推論をする，という立場からの統計的営み全体を，ベイズ統計学という．\n\n\n\n事後確率を導く際に用いた公式 Equation 1 はBayesの公式と呼ばれており，従ってベイズ統計学の最も肝要なパーツである．今回の場合では，Pythonコードをご覧になった方はわかったかもしれないが， \\[\np(\\theta|Y_1,\\cdots,Y_n)\\,\\propto\\,\\int^1_0\\theta^m(1-\\theta)^{n-m}\n\\] となっており，これはBeta分布と呼ばれるものである．こんな簡単な設定でも，この積分が殆ど計算できないことはBayes自身もよくわかっていた．\nさらに悪いことに，現代のBayes統計学の多くの統計量は，ある関数 \\(g:\\Theta\\to\\mathbb{R}\\) を用いて \\[\n\\mathrm{E}[g(\\theta)|Y_1,\\cdots,Y_n]=\\int_{\\Theta}g(\\theta)p(\\theta|Y_1,\\cdots,Y_n)\\,d\\theta\n\\] と表される．ここでも積分が登場するのである．先ほどのBayesの区間推定の例では \\(g=1_{(a,b)}\\) と取った場合に当たる．\\(g(\\theta)=\\theta^p\\) と取った場合，事後積率という統計量になる．等に \\(p=1\\) の場合が事後平均である．\nそこでBayesは，\\(g=1_{(a,b)}\\) と取った場合の積分 \\(\\mathrm{E}[g(\\theta)|Y_1,\\dots,Y_n]\\) の値を，男児の数 \\[m:=\\#\\left\\{i\\in[n]\\mid Y_i=1\\right\\}\\] が非常に多いか，非常に少ない場合については，被積分関数を二項展開して項別積分により計算することを提案した．しかしこの手法は明らかに今回の例では使えず（我々は男女の出生率にそこまで偏りがないことを経験的に知っている），真に興味のある場合を包含していない．この場合について，Bayesは \\(\\mathrm{E}[g(\\theta)|Y_1,\\dots,Y_n]\\) の値を上下から評価するにとどまった．\nそのこともあってか，文献 (Bayes, 1763) は実はBayesの死後にRichard Priceによって投稿されたものであり，生前に自ら投稿・発表した訳ではなかった．4 当然，発表当時は全く注目を受けなかった．\nまとめると，Bayesのアプローチは非常に自然で，特に確率分布を簡単にプロットできる現代では不確実性が明確に図示できるという美点がある．しかしながら，その肝心の「事後分布の公式（Bayesの公式）」がほとんどの場合で計算不可能なのである！そこでBayesは計算法の開発を余儀なくされた．このように，Bayes統計学は当初からBayes計算の問題を懐胎していたのである．\n実際，Bayes統計学はそのポテンシャルが評価されているだけであった期間が長く，真に日の目を見たと言えるのはここ30年のことである．\n\nIn fact, until Bayesians discovered MCMC, the only computational methodology that seemed to offer much chance of making practical Bayesian statistics practical was the portfolio of quadrature methods developed under Adrian Smith’s leadership at Nottingham (Naylor and Smith 1982; Smith et al. 1985, 1987). (Green et al., 2015, p. 836)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Hirofumi Shiba | 司馬博文",
    "section": "",
    "text": "Hirofumi Shiba is a Ph.D. candidate at the Institute of Statistical Mathematics in Japan, specializing in Bayesian Computation, a field focused on developing computational methods for Bayesian inference and learning.\nHe was born in Yokohama in May 1999. He received his Bachelor of Science degree in Mathematics from the University of Tokyo in 2023, where he was mentored by Professor Nakahiro Yoshida.\nExpanding his study on statistical inference for stochastic processes, he is now further specializing in nonlinear filtering and particle methods under the supervision of Professor Kengo Kamatani.\nHe is fluent in Japanese, Mandarin Chinese, and English.\nHe also contributes to the YUIMA package, an open-source project concerned with the simulation and inference of multidimensional stochastic differential equations.\nThis blog was branched off from the team’s homepage to cover more specialized topics in English and Japanese. The team name “Ano2math5” is pronounced in the same way as the word “anonymous” when read in Japanese."
  },
  {
    "objectID": "about.html#biography",
    "href": "about.html#biography",
    "title": "Hirofumi Shiba | 司馬博文",
    "section": "",
    "text": "Hirofumi Shiba is a Ph.D. candidate at the Institute of Statistical Mathematics in Japan, specializing in Bayesian Computation, a field focused on developing computational methods for Bayesian inference and learning.\nHe was born in Yokohama in May 1999. He received his Bachelor of Science degree in Mathematics from the University of Tokyo in 2023, where he was mentored by Professor Nakahiro Yoshida.\nExpanding his study on statistical inference for stochastic processes, he is now further specializing in nonlinear filtering and particle methods under the supervision of Professor Kengo Kamatani.\nHe is fluent in Japanese, Mandarin Chinese, and English.\nHe also contributes to the YUIMA package, an open-source project concerned with the simulation and inference of multidimensional stochastic differential equations.\nThis blog was branched off from the team’s homepage to cover more specialized topics in English and Japanese. The team name “Ano2math5” is pronounced in the same way as the word “anonymous” when read in Japanese."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Hirofumi Shiba | 司馬博文",
    "section": "Education",
    "text": "Education\n\nPh.D. in Statistical Science\nGraduate University for Advanced Studies, SOKENDAI, Tokyo, Japan\nApr. 2023 - Mar. 2028 (expected)\nB.A. in Mathematics\nUniversity of Tokyo, Japan\nApr. 2019 - Mar. 2023"
  },
  {
    "objectID": "about.html#interest",
    "href": "about.html#interest",
    "title": "Hirofumi Shiba | 司馬博文",
    "section": "Interest",
    "text": "Interest\nI am deeply fascinated by Bayesian Computation, a domain dedicated to advancing computational techniques for Bayesian inference and learning. My current research is on exploring the convergence properties of particle methods, especially the Sequential Monte Carlo methods.\nI firmly believe that Bayesian methods are one of the most effective approaches for translating the world models of all beings into formats understandable by both humans and computers. This conviction has broadened my interest to include Bayesian modelling and its diverse applications.\nIt is my aspiration to demonstrate that mathematics is a universal form comprehensible to humans, animals, and computers equally. My blog aims to become a hub where we explore more effective ways of communication among these diverse entities."
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Hirofumi Shiba | 司馬博文",
    "section": "Experience",
    "text": "Experience\n\nResearch Assistant at the Institute of Statistical Mathematics\nJuly 2023 - present\nCooperative Researcher at the RCAST, the University of Tokyo\nApr. 2023 - present\nData Scientist at IMIS Co., Ltd.\nAug. 2022 - Dec. 2023\n\n\nLast Update: Dec. 3rd, 2023"
  },
  {
    "objectID": "posts/2023-12-6/BayesainComp.html#footnotes",
    "href": "posts/2023-12-6/BayesainComp.html#footnotes",
    "title": "ベイズ計算とは何か | About Bayesian Computation（執筆中）",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nこれはBernoulli分布 \\(Y_i|\\theta\\overset{\\mathrm{i.i.d.}}{\\sim}\\mathrm{Ber}(\\theta)\\) を仮定するということである．↩︎\nBayes自身は「テーブル上にボールを転がしていく」という表現をしたという (Martin et al., 2023)．↩︎\n各 \\(\\theta\\) の下で目の前のデータ \\(Y_1,\\cdots,Y_n\\) が生成される確率 \\(p(Y_1,\\cdots,Y_n|\\theta)\\) が低いということは，「その \\(\\theta\\) から生成されたデータである確率は低い」という逆の発想ができる．そこで \\(p(Y_1,\\cdots,Y_n|\\theta)\\) という条件付き確率を尤度ともいう．↩︎\nなお，(Stigler, 1990) によると実際の出版年は1764年であったという．↩︎"
  },
  {
    "objectID": "posts/2023-12-6/BayesainComp.html#ベイズのアイデア",
    "href": "posts/2023-12-6/BayesainComp.html#ベイズのアイデア",
    "title": "ベイズ計算とは何か | About Bayesian Computation（執筆中）",
    "section": "",
    "text": "Thomas Bayes 1701-1761 は英国の牧師である．\n当時は統計的推定の問題が肝要であった．その中でも，次のような「区間推定」の問題を考えていた．\n\n$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$\n\n\n\n\n\n\n\n問題\n\n\n\n2値のデータ \\(Y_i\\in\\{0,1\\}\\) は，ある未知の「成功率」 \\(\\theta\\in(0,1)\\) に従って，確率 \\(\\theta\\) で \\(Y_i=1\\)，確率 \\(1-\\theta\\) で \\(Y_i=0\\) となるとする．1 仮に，\\(Y_i\\) は性別で，\\(\\theta\\) は男児が生まれる確率だと捉えることとしよう．2 このようなデータが独立に観測されて，\\(Y_1,\\cdots,Y_n\\) と得られているとする．真の成功率 \\(\\theta\\) が区間 \\((a,b)\\subset(0,1)\\) に入っているという確率をどう見積もれば良いか？\n\n\n彼の発想は極めてシンプルである．\n\nまず事前分布 \\(p(\\theta)\\) と呼ばれる，最初の \\(\\theta\\) に対する予想を自由に表現する．\nこれをデータを用いて修正して，事後分布 \\(p(\\theta|Y_1,\\cdots,Y_n)\\) を得る．これは「データ \\(Y_1,\\cdots,Y_n\\) が得られた，という条件の下で考えた条件付き分布」である．\nこの事後分布の形から区間推定を実行する．\n\n\n\n\n\n\n\n(Bayes, 1763) のアイデア\n\n\n\n事前分布として最初の予想をすると言っても，\\(\\theta\\in(0,1)\\) は全く予想がつかないとして，ここでは「どんな \\(\\theta\\) もあり得る」という意味で，\\(p(\\theta)\\) を一様分布に設定しよう：\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define the range for x-axis\nx = np.linspace(0, 1, 1000)\n\n# Uniform distribution density function is constant\ny = np.ones_like(x)\n\n# Plot the graph\nplt.figure(figsize=(6, 4)) # Size suitable for a smartphone screen\nplt.plot(x, y, label='Uniform Distribution (0,1)', color=(0.35, 0.71, 0.73, 1))\nplt.fill_between(x, y, color=(0.35, 0.71, 0.73, 0.3))\nplt.xlabel('x')\nplt.ylim(0, 1.5)\nplt.ylabel('Density')\nplt.title('Density Function of Uniform Distribution on (0,1)')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\nこのように，一様分布とは「どのような \\(\\theta\\) の値も同様に確からしい」という予想の表現である．しかし，データ \\(Y_1,\\cdots,Y_n\\) が得られている今，どんな \\(\\theta\\) も等しく尤もらしいという訳ではない．そこで，「データ \\(Y_1,\\cdots,Y_n\\) に関する条件付き分布」を計算することとする．実は，簡単な確率の法則から，次の公式を得ることができる：3 \\[\np(\\theta|Y_1,\\cdots,Y_n)=\\frac{p(Y_1,\\cdots,Y_n|\\theta)p(\\theta)}{\\int_\\Theta p(Y_1,\\cdots,Y_n|\\theta)p(\\theta)\\,d\\theta}\n\\tag{1}\\]\nこれを用いて，条件付き分布 \\(p(\\theta|Y_1,\\cdots,Y_n)\\) を計算する．例えば日本の2021年の出生児性別のデータを用いると次のようになる．\n\n\nCode\nimport matplotlib.pyplot as plt\nfrom scipy.stats import beta\n\n# パラメータの設定\nn = 811622\nmale = 415903\nfemale = n - male\n\n# ベータ分布のPDFを計算\nx = np.linspace(0, 1, 1000)\ny = beta.pdf(x, 1+male, 1+female)\n\n# プロット\nplt.figure(figsize=(6, 4))\nplt.plot(x, y, label=f'Beta({1+male}, {1+female})', color=(0.35, 0.71, 0.73, 1))\nplt.fill_between(x, y, color=(0.35, 0.71, 0.73, 0.3))\nplt.xlabel('p')\nplt.xlim(0.4, 0.6)\nplt.ylabel('Probability Density')\nplt.title('Bayesian Posterior Distribution')\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\nこうして極めて鋭い事後分布が出来た．では区間推定の例として，\\((a,b)=(0.5,1.0)\\) として，「男児の方が女児よりも多い確率」を推定しよう．これは次を計算することになる： \\[\n\\mathrm{P}\\left[\\frac{1}{2}&lt;\\theta&lt;1\\right]=\\int^1_{\\frac{1}{2}}p(Y_1,\\cdots,Y_n|\\theta)\\,d\\theta.\n\\]\n\n\nCode\nprint(sum(y[500:600])/1000)\n\n\n1.003097768300707\n\n\nもはや丸め誤差により \\(1\\) を越してしまっている．ほとんど確実に「男児の方が生まれる確率が高い」と結論づけて良いだろう．\n\n\nこの (Bayes, 1763) が実行したように，事後確率 \\(p(\\theta|Y_1,\\cdots,Y_n)\\) をみて \\(\\theta\\) に関する推論をする，という立場からの統計的営み全体を，ベイズ統計学という．"
  },
  {
    "objectID": "posts/2023-12-6/BayesainComp.html#bayes統計学の基本問題",
    "href": "posts/2023-12-6/BayesainComp.html#bayes統計学の基本問題",
    "title": "ベイズ計算とは何か | About Bayesian Computation（執筆中）",
    "section": "",
    "text": "事後確率を導く際に用いた公式 Equation 1 はBayesの公式と呼ばれており，従ってベイズ統計学の最も肝要なパーツである．今回の場合では，Pythonコードをご覧になった方はわかったかもしれないが， \\[\np(\\theta|Y_1,\\cdots,Y_n)\\,\\propto\\,\\int^1_0\\theta^m(1-\\theta)^{n-m}\n\\] となっており，これはBeta分布と呼ばれるものである．こんな簡単な設定でも，この積分が殆ど計算できないことはBayes自身もよくわかっていた．\nさらに悪いことに，現代のBayes統計学の多くの統計量は，ある関数 \\(g:\\Theta\\to\\mathbb{R}\\) を用いて \\[\n\\mathrm{E}[g(\\theta)|Y_1,\\cdots,Y_n]=\\int_{\\Theta}g(\\theta)p(\\theta|Y_1,\\cdots,Y_n)\\,d\\theta\n\\] と表される．ここでも積分が登場するのである．先ほどのBayesの区間推定の例では \\(g=1_{(a,b)}\\) と取った場合に当たる．\\(g(\\theta)=\\theta^p\\) と取った場合，事後積率という統計量になる．等に \\(p=1\\) の場合が事後平均である．\nそこでBayesは，\\(g=1_{(a,b)}\\) と取った場合の積分 \\(\\mathrm{E}[g(\\theta)|Y_1,\\dots,Y_n]\\) の値を，男児の数 \\[m:=\\#\\left\\{i\\in[n]\\mid Y_i=1\\right\\}\\] が非常に多いか，非常に少ない場合については，被積分関数を二項展開して項別積分により計算することを提案した．しかしこの手法は明らかに今回の例では使えず（我々は男女の出生率にそこまで偏りがないことを経験的に知っている），真に興味のある場合を包含していない．\nつまり，Bayesのアプローチは非常に自然で，特に確率分布を簡単にプロットできる現代では不確実性が明確に図示できるという美点がある．しかしながら，その肝心の「事後分布の公式（Bayesの公式）」がほとんどの場合で計算不可能なのである！そこでBayesは計算法の開発を余儀なくされた．このように，Bayes統計学は当初からBayes計算の問題を懐胎していたのである．"
  },
  {
    "objectID": "posts/2023-12-6/BayesainComp.html#ベイズ統計学の基本問題",
    "href": "posts/2023-12-6/BayesainComp.html#ベイズ統計学の基本問題",
    "title": "ベイズ計算とは何か | About Bayesian Computation（執筆中）",
    "section": "",
    "text": "事後確率を導く際に用いた公式 Equation 1 はBayesの公式と呼ばれており，従ってベイズ統計学の最も肝要なパーツである．今回の場合では，Pythonコードをご覧になった方はわかったかもしれないが， \\[\np(\\theta|Y_1,\\cdots,Y_n)\\,\\propto\\,\\int^1_0\\theta^m(1-\\theta)^{n-m}\n\\] となっており，これはBeta分布と呼ばれるものである．こんな簡単な設定でも，この積分が殆ど計算できないことはBayes自身もよくわかっていた．\nさらに悪いことに，現代のBayes統計学の多くの統計量は，ある関数 \\(g:\\Theta\\to\\mathbb{R}\\) を用いて \\[\n\\mathrm{E}[g(\\theta)|Y_1,\\cdots,Y_n]=\\int_{\\Theta}g(\\theta)p(\\theta|Y_1,\\cdots,Y_n)\\,d\\theta\n\\] と表される．ここでも積分が登場するのである．先ほどのBayesの区間推定の例では \\(g=1_{(a,b)}\\) と取った場合に当たる．\\(g(\\theta)=\\theta^p\\) と取った場合，事後積率という統計量になる．等に \\(p=1\\) の場合が事後平均である．\nそこでBayesは，\\(g=1_{(a,b)}\\) と取った場合の積分 \\(\\mathrm{E}[g(\\theta)|Y_1,\\dots,Y_n]\\) の値を，男児の数 \\[m:=\\#\\left\\{i\\in[n]\\mid Y_i=1\\right\\}\\] が非常に多いか，非常に少ない場合については，被積分関数を二項展開して項別積分により計算することを提案した．しかしこの手法は明らかに今回の例では使えず（我々は男女の出生率にそこまで偏りがないことを経験的に知っている），真に興味のある場合を包含していない．この場合について，Bayesは \\(\\mathrm{E}[g(\\theta)|Y_1,\\dots,Y_n]\\) の値を上下から評価するにとどまった．\nそのこともあってか，文献 (Bayes, 1763) は実はBayesの死後にRichard Priceによって投稿されたものであり，生前に自ら投稿・発表した訳ではなかった．4 当然，発表当時は全く注目を受けなかった．\nまとめると，Bayesのアプローチは非常に自然で，特に確率分布を簡単にプロットできる現代では不確実性が明確に図示できるという美点がある．しかしながら，その肝心の「事後分布の公式（Bayesの公式）」がほとんどの場合で計算不可能なのである！そこでBayesは計算法の開発を余儀なくされた．このように，Bayes統計学は当初からBayes計算の問題を懐胎していたのである．\n実際，Bayes統計学はそのポテンシャルが評価されているだけであった期間が長く，真に日の目を見たと言えるのはここ30年のことである．\n\nIn fact, until Bayesians discovered MCMC, the only computational methodology that seemed to offer much chance of making practical Bayesian statistics practical was the portfolio of quadrature methods developed under Adrian Smith’s leadership at Nottingham (Naylor and Smith 1982; Smith et al. 1985, 1987). (Green et al., 2015, p. 836)"
  },
  {
    "objectID": "posts/2023-12-6/法律家のための統計数理2.html",
    "href": "posts/2023-12-6/法律家のための統計数理2.html",
    "title": "法律家のための統計数理（2）第1章第2-4節",
    "section": "",
    "text": "$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$"
  },
  {
    "objectID": "posts/2023-12-6/法律家のための統計数理2.html#今回の内容",
    "href": "posts/2023-12-6/法律家のための統計数理2.html#今回の内容",
    "title": "法律家のための統計数理（2）第1章第2-4節",
    "section": "1 今回の内容",
    "text": "1 今回の内容\n第一審の裁判において，事実認定が中心的な問題である．この際に起き得る誤謬を，ベイズの方法を用いてどう回避できるか？という例が３つ挙げられている．\n\n1.1 主観確率の基本的な計算方法と捜査官の誤謬\n\n\n\n\n\n\n問題1-1\n\n\n\n殺人事件の加害者はAとBのどちらか？利用可能な情報は次のみ：被疑者のA, Bは同居しており，そのうちどちらかが加害者であることはわかっているものとする．\n\n台所に左利きの包丁があった．Aが左利きである確率はいくらか？ただし，人間が左利きである確率は1割とする．\nAは左利きであること，被害者の外傷の部位や凶器の形状から加害者も左利きであったことは確定的であるとする．Aに逮捕令状を出しても良いだろうか？ただし，利き手の情報を除けば，AかBかは完全に五分五分であるとする．なお，共犯はなく，どちらか一方の単独犯であることも確実であるとする．\n\n\n\n\n\n\n\n\n\n結論\n\n\n\n\nAもBも左利きである可能性があるため，5割より少し大きい．\nAもBも左利きである可能性があるため，9割強である．95%を一つの基準にするなら，逮捕令状は出すべきではない．\n\n\n\nこの問題のポイントは「条件付き確率」への理解である．\n\n\n\n\n\n\n論証\n\n\n\n\n事象を \\[\nA:=\\left\\{\\text{Aは左利きである}\\right\\}\n\\] \\[\nB:=\\left\\{\\text{Bは左利きである}\\right\\}\n\\] と定めると， \\[\n\\begin{align*}\n&\\quad\\;\\mathrm{P}[A\\cup B]\\\\\n&=\\mathrm{P}[A]+\\mathrm{P}[B]-\\mathrm{P}[A\\cap B]\\\\\n&=\\frac{19}{100}\n\\end{align*}\n\\] これより，条件付き確率の定義から \\[\n\\begin{align*}\n\\mathrm{P}[A|A\\cup B]&=\\frac{\\mathrm{P}[A]}{\\mathrm{P}[A\\cup B]}\\\\\n&=\\frac{10}{19}\\approx52.6\\%\n\\end{align*}\n\\]\n\n\n\n今回の肝は，事象 \\(A,B,C\\) を互いに独立に設定したために，各積事象 \\(A\\cap B,B\\cap C,C\\cap A\\) が悉く計算可能なものとして得られた，という点である．これを計算しておけば，欲しい値がこれらの言葉で得られているから，答えまで一本道で辿り着ける，という訳である．\n\n\n\n\n\n\nMonty Hall問題\n\n\n\nモンティ・ホール問題 も条件付けを正しく行えない（「何が分母か」を分別せず，違う次元の話を混同する）ことによって起こるパラドックスの有名な例である．\n\n\n\n\n\n\n\n\nまとめ\n\n\n\n「捜査官の誤謬」は「条件付け」を正しく行わないことにより起こる誤謬である．これを回避するには，独立な事象 \\(A,B\\) を抽出し，これらの確率を計算し，最終的に求めたい確率が何かを正しく特定することが重要である．\n\n\n\n\n1.2 ベイズの公式と検察官の誤謬\n\n\n\n\n\n\n問題1-2\n\n\n\nドーピング検査の結果から，ある日本選手Iが金メダルを剥奪された．弁護人としては，どのような弁護の筋があるか？\n\n本ドーピング検査において，禁止薬物をを用いていない人に対して陽性の結果が出る（偽陽性）確率は1%で，逆の偽陰性も1%である．\n日本選手で，禁止薬物を用いている割合は0.1%とする．当該日本選手Iもこの割合に従うものとする（とりわけ禁止薬物を使っていそうな理由・いそうでない理由はないものとする）．\n\n\n\n各事象を \\[\nA:=\\left\\{\\text{ I は薬物を使用していた}\\right\\}\n\\] \\[\nE:=\\left\\{\\text{ I に陽性反応が出た}\\right\\}\n\\] と設定する．今回は \\(A,E\\) は独立ではないことに注意．例えば，後からわかることだが， \\[\\mathrm{P}[A\\cap E]\\ne\\mathrm{P}[A]\\mathrm{P}[E]\\] である．ここで，条件付き確率の計算の問題に分け入ることになる．今回与えられている条件はそれぞれ，\n\\[\n\\begin{align*}\n\\text{1.}&\\qquad\\mathrm{P}[\\overline{E}|A]=\\frac{1}{100},\\\\\n&\\qquad\\mathrm{P}[E|\\overline{A}]=\\frac{1}{100}\\\\\n\\text{2.}&\\qquad\\mathrm{P}[A]=\\frac{1}{1000}\n\\end{align*}\n\\]\nと表現できており，知りたい値は，今現在Iが本当に薬を使っていたという確率 \\(\\mathrm{P}[A|E]\\) である．\n実は，これは全く大きな値ではない！これは，そもそも薬物を使っている人が少なく，健常な人の方が大多数であるために，検査で陽性が出たからといってそれが本当に薬物を使っている人から出た「真の陽性」である確率が極めて小さくなってしまうという普遍的な現象である．\n\n\n\n\n\n\n証明\n\n\n\n求めたい量 \\(\\mathrm{P}[A|E]\\) は \\[\n\\begin{align*}\n&\\quad\\;\\mathrm{P}[A|E]\\\\\n&=\\frac{\\mathrm{P}[A\\cap E]}{\\mathrm{P}[E]}\\\\\n&\\overset{\\text{(2)}}{=}\\frac{\\mathrm{P}[E|A]\\mathrm{P}[A]}{\\mathrm{P}[E]}\\\\\n&\\overset{\\text{(3)}}{=}\\frac{\\mathrm{P}[E|A]\\mathrm{P}[A]}{\\mathrm{P}[E|A]\\mathrm{P}[A]+\\mathrm{P}[E|\\overline{A}]\\mathrm{P}[\\overline{A}]}\n\\end{align*}\n\\tag{1}\\] と式変形できる．この右辺は，全て既知の値で表現できている．\nなお，途中の式変形については，条件付き確率の定義から\n\\[\n\\mathrm{P}[A\\cap E]=\\mathrm{P}[E|A]\\mathrm{P}[A]\n\\tag{2}\\]\nと，全確率の法則\n\\[\n\\begin{align*}\n&\\quad\\;\\mathrm{P}[E|A]\\mathrm{P}[A]+\\mathrm{P}[E|\\overline{A}]\\mathrm{P}[\\overline{A}]\\\\\n&=\\frac{\\mathrm{P}[E\\cap A]}{\\mathrm{P}[A]}\\mathrm{P}[A]\\\\\n&\\qquad\\qquad+\\frac{\\mathrm{P}[E\\cap\\overline{A}]}{\\mathrm{P}[\\overline{A}]}\\mathrm{P}[\\overline{A}]\\\\\n&=\\mathrm{P}[E\\cap A]+\\mathrm{P}[E\\cap\\overline{A}]\\\\\n&=\\mathrm{P}[E]\n\\end{align*}\n\\tag{3}\\] とを用いた．\n\n\n実際に計算してみると， \\[\n\\mathrm{P}[A|E]=\\frac{99}{1098}\\approx9.0\\%.\n\\] 選手Iは実際は薬を使っていない可能性の方がよっぽど高いのである．\n\n\n\n\n\n\nBase rate fallacy\n\n\n\nこの検察官の誤謬は，特に不良品検出の文脈では深刻なバイアスになり，英語では基準確率の誤謬ともいう．1\n\\(n\\) 人の母集団に，ある病気の検査を行うとしよう． \\[\\begin{cases}A_i:=\\left\\{i\\text{は有病}\\right\\},\\\\B_i:=\\left\\{i\\text{は陽性}\\right\\}.\\end{cases}\\quad i\\in[n].\\] としたとき，\n\n\\(\\alpha:=P[B_i|A_i^\\complement]\\) を偽陽率・危険度という．検定一般に言う，第一種の過誤率である．\n患者が有病であるときに陽性が出る確率 \\(1-\\alpha\\) の値を 感度(sensiticity)という．\n\\(\\beta:=P[B_i^\\complement|A_i]\\) を偽陰率という．検定一般に言う，第二種の過誤率である．\n患者が無病であるときに陰性が出る確率 \\(1-\\beta\\) の値を特異度(specificity)という．2 検定一般に言う検出力(power)である．\n\n統計的検定では第一種の過誤率を重く見て，これを制限した上での第二種の過誤率の低さを指標とする．このために「検出力」が重要．一方で失病検査の際は第一種の過誤率が大変重要であり，これに「感度」という名前がついている．\nこのような一般的な設定の下で，陽性の結果を見て，患者の有病率を \\(1-\\beta\\) だと結論づけてしまう誤謬を基準確率の誤謬という．"
  },
  {
    "objectID": "posts/2023-12-6/法律家のための統計数理2.html#ベイズ統計学",
    "href": "posts/2023-12-6/法律家のための統計数理2.html#ベイズ統計学",
    "title": "法律家のための統計数理（2）第1章第2-4節",
    "section": "2 ベイズ統計学",
    "text": "2 ベイズ統計学\n\n2.1 ベイズの公式\nSection 1.2 で使った式変形 Equation 1 の最左辺と最右辺のみに注目して公式化すると，次のようになる： \nこれを（分割 \\(\\Omega=A\\sqcup\\overline{A}\\) に関する）Bayesの公式という．\nこれは独立性の特徴付け \\[\n\\mathrm{P}[A|E]=\\mathrm{P}[A],\\quad\\mathrm{P}[E|A]=\\mathrm{P}[E]\n\\] の一般化になっているともみれる．\n\n\n2.2 ベイズ統計学\n事前に確率 \\(\\mathrm{P}[A]\\) を想定しておく．そして，\\(A\\) に関連する観測の結果 \\(\\mathrm{P}[E|A]\\) を見てから，ベイズの公式を通じて \\(\\mathrm{P}[A|E]\\) を計算し，事象 \\(A\\) に関する理解を深める営みが，ベイズ統計学の雛形である．\nこの \\(\\mathrm{P}[A]\\) を事前確率，\\(\\mathrm{P}[A|E]\\) を事後確率という．\n\n事象 \\(A\\) として何を選んでも良い．\n事前情報 \\(\\mathrm{P}[A]\\) を推論に取り込む余地がある．\n\\(A\\) と \\(E\\) に対して多様な関係を想定できる．\n\\(\\mathrm{P}[A|E]\\) は一般にグラフの形で与えられるので，（他の統計手法と比べて）情報量が多い．\nベイズの公式が全てであり，何をやっているかがわかりやすい．\n\n点がよくベイズ統計学の美点として挙げられる．\n\n\n2.3 ベイズ計算\n前節で解説した通り，ベイズ統計学はベイズの公式が全てであり，原理的には極めて明快である．では，何が難しいかというと，一般的な形のベイズの公式 \\[\np(\\theta|x)=\\frac{p(x|\\theta)p(\\theta)}{\\int_\\Theta p(x|\\theta)p(\\theta)\\,d\\theta}\n\\] は，最も単純な場合でも，計算が不可能であるという点である．積分は現代では高校で習う数学の範囲であるが，実際に計算できる積分など応用の現場では都合よく出てこないのである．\n従って，ベイズ統計学の研究において，計算手法の研究が極めて重要な位置を占める．この分野をベイズ計算というのである．詳しくは ベイズ計算とは何か の記事を参照してほしい．"
  },
  {
    "objectID": "posts/2023-12-6/法律家のための統計数理2.html#footnotes",
    "href": "posts/2023-12-6/法律家のための統計数理2.html#footnotes",
    "title": "法律家のための統計数理（2）第1章第2-4節",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(Arias-Castro, 2022) と (Agresti, 2012, pp. 第2.1.3節 p.39) も参照．↩︎\n(Yerushalmy, 1947) ↩︎"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html",
    "href": "posts/2023/2023-12-6/BayesianComp.html",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "",
    "text": "History of Bayesian Computation (Martin et al., 2023, p. 4)"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#ベイズのアイデア",
    "href": "posts/2023/2023-12-6/BayesianComp.html#ベイズのアイデア",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "1.3 ベイズのアイデア",
    "text": "1.3 ベイズのアイデア\n彼の発想は極めてシンプルであり，次の3段階によって推定を試みた：\n\n事前分布 \\(p(\\theta)\\) と呼ばれる，最初の \\(\\theta\\in(0,1)\\) に対する予想 \\(p(\\theta)\\) を自由に表現する．4\n事前分布のデータ \\(\\boldsymbol{y}\\) を観測した下での条件付き分布 \\[p(\\theta|\\boldsymbol{y}):=\\frac{p(\\theta,\\boldsymbol{y})}{p(\\boldsymbol{y})}\\] を計算する．これを事後分布という．\nこの事後分布 \\(p(\\theta|\\boldsymbol{y})\\) の形から区間推定を実行する．\n\nこの 3.の部分は，Bayes が特に区間推定に拘ったためのものであり，点推定でも良ければ次期予測でも良い．推定対象 3.を目的に応じて自由に入れ替えても，1.と 2.の部分が同じように動作するということ，これがベイズ統計学の枠組みである．\nそれだけに事後分布というものが表現力に富んでいるのである．また，以下の例で納得していただけるかもしれないが，ベイズ統計学の手続きは「眼前のデータは，事前の信念を変えるのにどれほど説得的であるか？」という観点からも見れ，定量的であると同時に定性的な判断も可能にする． 節 3.5 で紹介するように，この特徴は意思決定への応用おいても重要である．\n\n\n\n\n\n\n問題に対する (Bayes, 1763) の解決\n\n\n\n\nまず，事前分布 \\(p(\\theta)\\) を設定する．Bayes は前述のビリヤードの問題を考えていたこともあり， 「\\(\\theta\\in(0,1)\\) は全く予想がつかない」「どんな \\(\\theta\\) も同様にあり得る」という立場を取った．横軸を \\(\\theta\\in(0,1)\\) の値，縦軸を「主観的にあり得ると思う度合い」として図で表すと次の通りである：\n\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define the range for x-axis\nx = np.linspace(0, 1, 1000)\n\n# Uniform distribution density function is constant\ny = np.ones_like(x)\n\n# Plot the graph\nplt.figure(figsize=(3, 2)) # Size suitable for a smartphone screen\nplt.plot(x, y, label='Uniform Distribution (0,1)', color=(0.35, 0.71, 0.73, 1))\nplt.fill_between(x, y, color=(0.35, 0.71, 0.73, 0.3))\nplt.xlabel('x')\nplt.ylim(0, 1.5)\nplt.ylabel('Density')\nplt.title('Posterior Distribution')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\nこの図が表す \\((0,1)\\) 上の確率分布を一様分布という．このように，一様分布とは「どのような \\(\\theta\\) の値も同様に確からしい」という予想の表現である．\n\n次に，データ \\(\\boldsymbol{y}=(y_1,\\cdots,y_n)^\\top\\) が観測された後の条件付き分布 \\(p(\\theta|\\boldsymbol{y})\\) を計算することで，本データ \\(\\boldsymbol{y}\\) が事前の信念 \\(p(\\theta)\\) をどのように変えてしまうかを観る．簡単な確率論の結果として，条件付き分布は次の公式によって計算できる（講義ノートも参照）：5 \\[\np(\\theta|\\boldsymbol{y})=\\frac{p(\\boldsymbol{y}|\\theta)p(\\theta)}{\\int_\\Theta p(\\boldsymbol{y}|\\theta)p(\\theta)\\,d\\theta}\n\\tag{1}\\]\n例えば 日本の2021年の出生児性別のデータ を用いると次のようになる．\n\n\n\nCode\nimport matplotlib.pyplot as plt\nfrom scipy.stats import beta\n\n# パラメータの設定\nn = 811622\nmale = 415903\nfemale = n - male\n\n# ベータ分布のPDFを計算\nx = np.linspace(0, 1, 1000)\ny = beta.pdf(x, 1+male, 1+female)\n\n# プロット\nplt.figure(figsize=(3, 2))\nplt.plot(x, y, label=f'Beta({1+male}, {1+female})', color=(0.35, 0.71, 0.73, 1))\nplt.fill_between(x, y, color=(0.35, 0.71, 0.73, 0.3))\nplt.xlabel('p')\nplt.xlim(0.4, 0.6)\nplt.ylabel('Probability Density')\nplt.title('Bayesian Posterior Distribution')\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\nこうして極めて鋭い事後分布が出来た．事前に設定した分布 \\(p(\\theta)\\) は極めて平坦な一様分布であったのに，それをデータで条件付けた \\(p(\\theta|\\boldsymbol{y})\\) には極めて鋭いスパイクが現れたのである．式 1 を認めるならば，この図は「男児の方が女児よりも生まれる確率が高い」ことの証拠として，極めて説得的ではないだろうか？\n\nでは区間推定の例として，\\((a,b)=(0.5,1.0)\\) として，「男児の方が女児よりも多い確率」を推定しよう．これは次を計算することになる： \\[\n\\begin{align*}\n&\\mathrm{P}\\left[\\frac{1}{2}&lt;\\theta&lt;1\\right]\\\\\n&=\\int^1_{\\frac{1}{2}}p(\\boldsymbol{y}|\\theta)\\,d\\theta.\n\\end{align*}\n\\]\n\n\n\nCode\nprint(sum(y[500:600])/1000)\n\n\n1.003097768300707\n\n\nもはや丸め誤差により \\(1\\) を越してしまっている．ほとんど確実に「男児の方が生まれる確率が高い」と結論づけて良いだろう．\n\n\nこの (Bayes, 1763) が実行したように，事後分布 \\(p(\\theta|\\boldsymbol{y})\\) をみて \\(\\theta\\) に関する推論をする，という立場からの統計的営み全体をベイズ統計学．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#ベイズ統計学の基本問題",
    "href": "posts/2023/2023-12-6/BayesianComp.html#ベイズ統計学の基本問題",
    "title": "ベイズ計算とは何か | About Bayesian Computation（執筆中）",
    "section": "",
    "text": "事後確率を導く際に用いた 式 1 はBayesの公式と呼ばれており，従ってベイズ統計学の最も肝要なパーツである．今回の場合では，Pythonコードをご覧になった方はわかったかもしれないが， \\[\np(\\theta|\\boldsymbol{y})=\\frac{\\theta^m(1-\\theta)^{n-m}}{B(m+1,n-m+1)}\n\\] となっており，これは \\((0,1)\\) 上の Beta分布 と呼ばれるものである．\n現代のBayes統計学の多くの統計量は，ある関数 \\(g:\\Theta\\to\\mathbb{R}\\) を用いて \\[\n\\mathrm{E}[g(\\theta)|\\boldsymbol{y}]=\\int_{\\Theta}g(\\theta)p(\\theta|\\boldsymbol{y})\\,d\\theta\n\\] と表される．先ほどのBayesの区間推定の例では \\(g=1_{(a,b)}\\) と取った場合に当たる．5\n実は，この最も簡単と思われる設定でも，この積分は殆ど計算できないのである．そのこともあってか，論文 (Bayes, 1763) は実はBayesの死後にRichard Priceによって投稿されたものであり，生前に自ら投稿・発表した訳ではなかった．6 当然，発表当時も全く注目を受けなかった．\n\nHence, despite the analytical availability of \\(p(\\theta|\\boldsymbol{y})\\) via (2)-—“Bayes’ rule” as it is now known—the quantity that was of interest to Bayes needed to be estimated, or computed. The quest for a computational solution to a Bayesian problem was thus born. (Martin et al., 2023, p. 2)\n\n\n\n\n\n\n\nベイズ統計学の基本問題\n\n\n\nベイズの枠組み\n\nまず事前分布 \\(p(\\theta)\\) と呼ばれる，最初の \\(\\theta\\in(0,1)\\) に対する予想を自由に表現する．\nこの事前の信念をデータを用いて修正する形で，事後分布 \\(p(\\theta|\\boldsymbol{y})\\) を得る．\n\nは非常に自然で，特に確率分布を簡単にプロットできる現代では不確実性が明確に図示できるという美点がある．しかしながら，モデル \\(p(\\theta),p(\\boldsymbol{y}|\\theta)\\) の設定をいくら簡単にしても根本的に計算が困難で実行不可能なのである．これを解決する分野をベイズ計算という．Bayesの論文 (Bayes, 1763) でも，計算法の開発が約半分を占めた．このように，Bayes統計学は当初からBayes計算の問題を懐胎していたのである．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#footnotes",
    "href": "posts/2023/2023-12-6/BayesianComp.html#footnotes",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n正式名称をThe Royal Society for the Improvement of Natural Knowledge by Experimentという↩︎\n当局の人間に死亡を報告する義務は全くなかった。その代わり、それぞれの教区では2人かそれ以上の死体を調査し、死因を決定する義務を負う調査員を任命していた。「調査員」は死亡を報告する毎に遺族より少額の手数料を徴収する資格が与えられていたので、教区では任命しなければ貧困のため救貧税による支援が必要となりそうな人間を割り当てていた。（Wikipediaページより）↩︎\nこれは統計的モデルとしてBernoulli分布 \\(Y_i|\\theta\\overset{\\mathrm{i.i.d.}}{\\sim}\\mathrm{Ber}(\\theta)\\) を仮定するということである．↩︎\nパラメータ \\(\\theta\\) は「男児が生まれる確率」であるが，これ自体にも事前分布という「確率」\\(p(\\theta)\\) を導入することに戸惑う読者も居るだろう．しかし，これがベイズ統計学の特徴である．「男児が生まれる確率 \\(\\theta\\)」だろうとなんだろうと，「わからない」「不確実性がある」と主観的に感じるあらゆる対象に，確率分布を導入して事後分布を得ることで推論を実行する，これがベイズ統計学の枠組みの普遍性であり，無差別性であり，有用性を支えている．↩︎\n各 \\(\\theta\\) の下で目の前のデータ \\(y_1,\\cdots,y_n\\) が生成される確率 \\(p(\\boldsymbol{y}|\\theta)\\) が低いということは，「その \\(\\theta\\) から生成されたデータである確率は低い」という逆の発想ができる．そこで \\(p(\\boldsymbol{y}|\\theta)\\) という条件付き確率を尤度ともいう．今回は \\(p(\\boldsymbol{y}|\\theta)=\\theta^{\\sum_{i=1}^ny_i}(1-\\theta)^{\\sum_{i=1}^n(1-y_i)}\\) である．↩︎\nさらに，\\(g(\\theta)=\\theta^p\\) と取った場合，事後積率という統計量になる．等に \\(p=1\\) の場合が事後平均である．↩︎\nなお，1763に出版されたものはPriceによる補遺も付いた短縮版であり，全文は1974年に出版された．(Stigler, 1990)↩︎\npp.376-403 がBayesの論文の本論の内容であり pp.399-403 で計算法を３つのルールにまとめているが，その導出部は一部「長すぎるから掲載を省略する」とされている．↩︎\n一方で，Bayesの逆確率の問題への言及自体は，Laplaceの後年の1781年の著作Mémoire sur les probabilitésへのCondorcetによる序文で初めて登場する (Martin et al., 2023, p. 5)．↩︎\nnCatLab 参照．↩︎\n1970年にインテルが世界初の DRAMである Intel 1103 を発売した．Wikipediaページ参照．↩︎\n物理学ではHeat Bath法と呼ばれ古くから同様のアルゴリズムが存在したが，統計学界隈では現在でもGibbsサンプラーと呼ばれる．↩︎\nこの性質を指して，approximateの対義語としてexactという形容詞で表現される．↩︎\nfunctional Bayes (Sun et al., 2019) という手法では，希望する入力と出力の組を事前に用意するのみで，適切な事前分布を提案してくれる枠組みである．↩︎\n推定結果に自信がないときはそう表明してくれる機械は親しみやすい．↩︎"
  },
  {
    "objectID": "posts/2023/2023-11-23/書き起こし.html",
    "href": "posts/2023/2023-11-23/書き起こし.html",
    "title": "Whispter APIを通じて日本語音声を書き起こす方法",
    "section": "",
    "text": "Whispter"
  },
  {
    "objectID": "posts/2023/2023-11-23/書き起こし.html#whispterのダウンロード",
    "href": "posts/2023/2023-11-23/書き起こし.html#whispterのダウンロード",
    "title": "Whispter APIを通じて日本語音声を書き起こす方法",
    "section": "1 Whispterのダウンロード",
    "text": "1 Whispterのダウンロード\nまずWhisperをOpenAIのGitHubからダウンロードします．\n!pip install git+https://github.com/openai/whisper.git\nさらに，内部で ffmpeg が必要になるので，これもダウンロードしておく必要があります．MacOSの場合は次のコマンドでインストールできます．1\nbrew install ffmpeg\nローカル環境ではなくとも，Google Colaboratoryを用いてブラウザ上で実行することもできます．その場合の詳しいやり方は，こちらのサイトが参考になります．"
  },
  {
    "objectID": "posts/2023/2023-11-23/書き起こし.html#ファイルの分割",
    "href": "posts/2023/2023-11-23/書き起こし.html#ファイルの分割",
    "title": "Whispter APIを通じて日本語音声を書き起こす方法",
    "section": "2 ファイルの分割",
    "text": "2 ファイルの分割\nWhispterはどんなに大きな音声ファイルを渡しても25MB時点までしか書き起こしてくれません．そのため，ファイルを分割してWhispterに渡すこととします．次のコードは大きなファイルを分割するための関数を定義しています． duration=240 で，何秒間でファイルを区切るかを指定します．筆者の経験上240秒（4分）がうまくいきます．\nimport wave\n\ndef split_wav_file(filename, duration=240):\n    # WAVファイルを開く\n    with wave.open(filename, 'rb') as wav:\n        # パラメータの取得\n        n_channels, sampwidth, framerate, n_frames, comptype, compname = wav.getparams()\n\n        # 5分間のフレーム数を計算\n        frames_per_split = framerate * duration * n_channels * sampwidth\n\n        # 全フレームを読み込み\n        frames = wav.readframes(n_frames)\n\n        # 分割してファイルに書き込む\n        for i in range(0, len(frames), frames_per_split):\n            # 新しいファイル名\n            new_file = f'split_{i // frames_per_split}.wav'\n\n            # 新しいファイルを書き込む\n            with wave.open(new_file, 'wb') as new_wav:\n                new_wav.setparams((n_channels, sampwidth, framerate, frames_per_split // (n_channels * sampwidth), comptype, compname))\n                new_wav.writeframes(frames[i:i+frames_per_split])\nこうして定義した関数を次のように用いると， split_n.wav という名前で，複数のファイルに分割してくれます．\nsplit_wav_file('［あなたの手元のファイル名］.wav')"
  },
  {
    "objectID": "posts/2023/2023-11-23/書き起こし.html#書き起こし",
    "href": "posts/2023/2023-11-23/書き起こし.html#書き起こし",
    "title": "Whispter APIを通じて日本語音声を書き起こす方法",
    "section": "3 書き起こし",
    "text": "3 書き起こし\n続いて，細かく分けたファイル split_n.wav たちを順にWhisperに渡して書き起こしてもらい，結果を1つのテキストファイル 書き起こし.txt にまとめてもらいます．\nimport whisper\n\n# モデルのロード\nmodel = whisper.load_model(\"large\")  # やっぱ精度が違います\n\n# ファイルのリスト\nfiles = [f\"split_{i}.wav\" for i in range(27)]  # split_0.wav から split_26.wav まで\n\n# 結果を格納するための空の文字列\ntranscription = \"\"\n\n# 各ファイルを順番に処理\nfor file in files:\n    # ファイルを書き起こし\n    result = model.transcribe(file, language='ja')\n    transcription += result[\"text\"] + \"\\n\\n\"\n\n# 書き起こし結果をテキストファイルに書き込む\nwith open(\"書き起こし.txt\", \"w\", encoding=\"utf-8\") as text_file:\n    text_file.write(transcription)\nここでは最大のモデル large を用いています．その場合，結構な時間がかかります．"
  },
  {
    "objectID": "posts/2023/2023-11-23/書き起こし.html#footnotes",
    "href": "posts/2023/2023-11-23/書き起こし.html#footnotes",
    "title": "Whispter APIを通じて日本語音声を書き起こす方法",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nそれ以外のOSの場合はこちらのREADME.mdにやり方が書いてあります．↩︎"
  },
  {
    "objectID": "posts/2023/2023-11-22/法律家のための統計数理1.html",
    "href": "posts/2023/2023-11-22/法律家のための統計数理1.html",
    "title": "法律家のための統計数理（1）第1章第1節",
    "section": "",
    "text": "(草野耕一, 2016) の勉強会第1回の補足として，確率論の数学的枠組みを紹介する．"
  },
  {
    "objectID": "posts/2023/2023-11-22/法律家のための統計数理1.html#今回の内容",
    "href": "posts/2023/2023-11-22/法律家のための統計数理1.html#今回の内容",
    "title": "法律家のための統計数理（1）第1章第1節",
    "section": "1 今回の内容",
    "text": "1 今回の内容\n\n1.1 本書の概観\n本書は「数理法務」＝「法の数理分析」に関する発展的内容を扱った書籍で，内容は大きく次の1から3の3つからなる：\n\n法の行動分析：法律家がとるべき行動を数理を用いて分析する．\n法の統計分析：事実の推定や因果関係の推定に統計手法を応用する．\n法の財務分析：企業や金融に関わる法事象をファイナンス理論を用いて分析する．\n法の経済分析：法を経済学的な観点から分析する（本書では扱われていない）．\n\n第1回勉強会では第1章「行動分析(1)事実認定」を扱った．事実認定を，Bayes推論の枠組みで捉え直し，法律家として誤謬やバイアスに陥ってしまうことを避けるツールとして，確率論を導入しており，「法の数理分析は役に立つ」ことを端的に実感できる，導入として極めて鮮やかな章になっている．\n\n\n1.2 主観確率とBayes計算\nまず，第1章は，事実認定の文脈で妥当な確率概念は「主観確率」であり，今後「確率」とはこの意味で用いることを注意喚起する内容から始まる．\n主観確率と客観確率の詳細な定義は本書を参照願いたいが，一言で言えば，後者は「人間に不可知な真の値」というものの存在を前提とするのに対し，前者はそれを仮定しない．\n従って，主観確率の考え方は，より多くのものに「確率」を導入することを可能にし，より柔軟な議論が可能であるが，その分数理的な困難も増し，真に発展が進んだと言えるのは，計算機が十分に爛熟した21世紀になってのことであると言える．この統計学分野を Bayes計算 (Bayesian Computation) といい，筆者の研究分野である．\n\nThe development of computing algorithms especially suited for Bayesian analysis in the 1990s together with the exponential growth of computing resources enabled Bayesian nonparametrics to go beyond the simplest problems and made it a universally applicable paradigm for inference. (Ghosal & van der Vaart, 2017)\n\n\n\n1.3 Bayes統計学とは？\n大雑把に言って，客観確率に基づく統計手法を 頻度論的手法 (frequentist methods)，主観確率に対する統計手法を Bayes手法 (Bayesian methods)という．一般に後者は前者を包含する（前者は後者の特別な場合1）と考えられる．しかしこれは「確率の解釈」が違うのみであり，数学としては確率の定義は1つである．「確率の解釈」については，双方の立場の中でもそれぞれ複数の立場が乱立しており，ここでは立ち入らない．と言っても，この注記も教科書的なもので，実用上不便を生じる場面はほとんどないだろう．\n\n不確実性を定量化するのに、ベイズ計算では必ず『確率』を使います。一般の人から見たら、統計で確率を使うのは当たり前と思うでしょうが、じつは他の統計手法ではそうでもなく、さまざまな解釈が生まれてしまう。定量化にはすべて統一的に確率を使うベイズ計算は、非常にシンプルなので、最終的にすべての統計はベイズに行き着くしかないと思っています。 鎌谷研吾\n\n\n\n1.4 Bayes確率の基礎付けの試み……！？\n法律家による事実認定の文脈においても，「真実はいつも1つだからそれを推定したい」と考えても，「不確実な中でも，判断を誤らないようにしたい」と考えても，どちらから議論しても良いことは納得いただけるだろう．ただ，一般の人の素朴な「確率」の理解は，Bayes流のものに近いと言われている．2\nそのこともあり，本書で「主観確率の考え方を採用する」というのは，「確率の解釈の議論はここではしない」「主観的な確信度合いの意味で，現実から多少の乖離を許す」という程度の意味であろう．\nしかし，本書の「主観確率」の議論は中途半端な取り扱いでは終わらず，興味深いことに，One More Step 1-1 (pp.9-10) にて，数理哲学者Donald A. Gilliesによる主観確率の測定による基礎付けの議論が紹介されていた．筆者は初耳の議論であり，己の議論の正統性・基礎付けに細心の注意を施す法律家の心が現れていると筆者は見た．"
  },
  {
    "objectID": "posts/2023/2023-11-22/法律家のための統計数理1.html#sec-2",
    "href": "posts/2023/2023-11-22/法律家のための統計数理1.html#sec-2",
    "title": "法律家のための統計数理（1）第1章第1節",
    "section": "2 【深掘り】確率の公理",
    "text": "2 【深掘り】確率の公理\n\n$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$\n\n\n2.1 「確率の公理」がなぜ重要なのか？\n本書1.1節では確率の性質が列挙されている．1.2節以降では，これらの性質が「確率の定義」として引用されるが，いまいちどれを指して「定義」と呼んでいるのか定かでない．\n数学的な議論に慣れたあとはそれでも良いかも知れないが，法学も初学の間は逐一根拠条文に戻ることが大切であるように，数学もはっきりと定義を列挙し，「それのみを根拠とすること」を徹底することが大事である．\nなお，数学では何を定義として採用するかに任意性がある場合が多いが，唯一やってはいけないことは「定義が曖昧な状態で進むこと」である．そこで，せっかくであるから，現代数学が定義する最も筋の良い定義を採用して，本書の内容を俯瞰することにする．\n\n人は，確率論のもった政治的，社会的意義を忘れてはならない．理知を一切の尺度として「代数学の炉火によって倫理学及び政治学を照さん」(Condorcet) という時代精神，神の啓示に代らんとする確率論，それはフランス革命の思想的基礎に連関することを見失ってはならないのである．(北川敏男, 1949)\n\n現代数学において，確率を特徴付けるものは「代数的性質」であり，それは次の3つのみに集約される．3\n\n\n2.2 確率の公理\n\n\n\n\n\n\n定義（確率） (Kolmogorov, 1931)\n\n\n\n集合 \\(\\Omega\\) 上の確率とは，次の3条件を満たす関数 \\(P:\\mathcal{P}(\\Omega)\\to\\mathbb{R}\\) である：4\n   [P1] \\(P(\\Omega)=1\\)．\n   [P2] \\(A\\cap B=\\emptyset\\) ならば， \\[P(A\\sqcup B)=P(A)+P(B).\\]\n   [P3] 任意の事象 \\(A\\subset\\Omega\\) について， \\[0\\le P(A).\\]5\nただし，\n\n\\(P\\) の定義域 \\(\\mathcal{P}(\\Omega)\\) は「\\(\\Omega\\) の部分集合全体の集合」のことである．これを \\(\\Omega\\) の冪集合という．\n\\(A\\sqcup B\\) とは， \\(A\\cap B=\\emptyset\\) が成り立つときの \\(A,B\\) の合併 \\(A\\cup B\\) を，\\(A\\cap B=\\emptyset\\) を強調して書き分ける記法とする．\n\n\n\nこの公理から，我々が日常的な感覚から「確率に成り立っていて欲しい性質」が全て導ける，ということが現代数学の重要な発見である．性質を見ていく前に，「定義」として，主要な概念に親しみやすい名前を付ける．そのすべての過程において，上の[P1], [P2], [P3]以外を用いていないことを確認することは，数学入門の際には非常に大事な営みである．6\n\n\n\n\n\n\n確率論に関連する用語\n\n\n\n全体集合 \\(\\Omega\\) は所与のものとする．7\n\n事象 とは，部分集合 \\(A\\subset\\Omega\\) のことをいう．\n事象 \\(A\\subset\\Omega\\) の補集合\\[A^\\complement=\\Omega\\setminus A=\\overline{A}:=\\left\\{\\omega\\in\\Omega\\mid \\omega\\notin A\\right\\}\\]を \\(A\\) の余事象という．左から順に，数学で一般によく使われる記号である．8\n2つの事象 \\(A,B\\subset\\Omega\\) が 排反 であるとは，集合として共通部分を持たないことをいう： \\(A\\cap B=\\emptyset\\)．\n\n\n\nこの3性質から，本書第1.1節にいう「確率の推論法則」が全て導出できる．\n\n\n2.3 式(1.1) p.4の証明\n\n\n\n\n\n\n式(1.1) p.4\n\n\n\n任意の事象 \\(A\\subset\\Omega\\) について，\\[0\\le P(A)\\le 1.\\]9\n\n\n\n\n\n\n\n\n式(1.2) p.5\n\n\n\n任意の事象 \\(A\\subset\\Omega\\) について， \\[\nP(A)+P(A^\\complement)=1.\n\\]\n\n\n\n\n\n\n\n\n証明\n\n\n\n\\(0\\le P(A)\\) は[P3]に他ならない．式(1.2)も[P2]から従う．\\(A\\subset\\Omega\\) の補集合を \\(A^\\complement:=\\Omega\\setminus A\\) で表すと， \\(P(A^\\complement)\\ge0\\) も成り立つから， \\[\n\\begin{align*}\nP(A)&\\le P(A)+P(A^\\complement)\\\\\n&=P(A\\sqcup A^\\complement)\\\\\n&=P(\\Omega)=1.\n\\end{align*}\n\\]\n\n\n\n\n2.4 式(1.3) p.5の証明\n\n\n\n\n\n\n式(1.3) p.5\n\n\n\n任意の \\(n\\ge1\\) について， \\(n\\) 個の事象 \\(A_1,\\cdots,A_n\\subset\\Omega\\) が互いに排反であるとき， \\[\n\\begin{align*}\n&P(A_1)+P(A_2)+\\cdots+P(A_n)\\\\\n&\\qquad\\qquad=P(A_1\\sqcup A_2\\sqcup\\cdots\\sqcup A_n).\n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\n証明\n\n\n\n\\(n\\) に関する数学的帰納法による．\n\n\n\n\n2.5 式(1.4) p.6の証明\n\n\n\n\n\n\n式(1.4) p.6\n\n\n\n任意の事象 \\(A,B\\subset\\Omega\\) について， \\[\nP(A)+P(B)=P(A\\cup B)+P(A\\cap B).\n\\]\n\n\n[P2] の条件は，\\(A_1,A_2\\) が排反である場合に限定しており，その制限が邪魔であった．ここで一般の加法公式を得ることになる．\n\n\n\n\n\n\n証明\n\n\n\n\\(C:=A\\cap B\\) とおくと，3つの集合 \\(A\\setminus B,C,B\\setminus A\\) が互いに排反であることから，\n\\[\n\\begin{align*}\n&\\quad P(A)+P(B)\\\\\n&=\\biggr(P(A\\setminus B)+P(C)\\biggl)+\\biggr(P(C)+P(B\\setminus A)\\biggl)\\\\\n&=\\biggr(P(A\\setminus B)+P(C)+P(B\\setminus A)\\biggl)+P(C)\\\\\n&=P(A\\cup B)+P(A\\cap B).\n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\n\n2.6 条件付き確率の定義\n\n\n\n\n\n\n定義（条件付き確率）\n\n\n\n\\(A,B\\subset\\Omega\\) を事象とする． 事象 \\(A\\) が起こった場合の，事象 \\(B\\) の条件付き確率とは， \\[\nP(B|A):=\\begin{cases}\\frac{P(A\\cap B)}{P(A)}&P(A)\\ne0\\;\\text{のとき}\\\\0&P(A)=0\\;\\text{のとき}\\end{cases}\n\\] という値を指す．10\n\n\n\n\n2.7 式(1.7) p.7の証明\n\n\n\n\n\n\n式(1.7) p.7\n\n\n\n\\(A,B\\subset\\Omega\\) を事象，\\(P(A)&gt;0\\) とする． \\[\nP(A|B)+P(A^\\complement|B)=1.\n\\]\n\n\n\n\n\n\n\n\n証明\n\n\n\n\\[\n\\begin{align*}\n&\\quad P(A|B)+P(A^\\complement|B)\\\\\n&=\\frac{P(A\\cap B)}{P(B)}+\\frac{P(A^\\complement\\cap B)}{P(B)}\\\\\n&\\overset{\\text{[P2]}}{=}\\frac{P((A\\cap B)\\sqcup (A^\\complement\\cap B))}{P(B)}\\\\\n&=\\frac{P(B)}{P(B)}=1.\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/2023/2023-11-22/法律家のための統計数理1.html#sec-independent",
    "href": "posts/2023/2023-11-22/法律家のための統計数理1.html#sec-independent",
    "title": "法律家のための統計数理（1）第1章第1節",
    "section": "3 【重要概念】統計的独立性",
    "text": "3 【重要概念】統計的独立性\n\n3.1 定義\n\n\n\n\n\n\n定義（独立性）\n\n\n\n2つの事象 \\(A,B\\subset\\Omega\\) が独立であるとは，次を満たすことをいう： \\[\nP(A\\cap B)=P(A)P(B).\n\\] このとき， \\(A\\perp\\!\\!\\!\\perp B\\) と表す．\n\n\nこの式は本書p.7 (1.8)式に一致している．これを「積の公式」として導出しているが，これは実は独立性の定義とすべき性質である．その意味するところを次節で解説する．\n\n\n3.2 条件付き確率による特徴付け\nSection 2 で「数学では何を定義として採用するかに任意性がある場合が多い」と言った．今回の「独立性」概念も，2つの同値な定義がある．しかし，「唯一やってはいけないことは定義が曖昧な状態で進むことである」とも言った．従って，どちらか片方を定義とし，「定義ともう一つの条件が同値である」という命題が生まれることになる．\nこの形の命題のことを（数学概念の）特徴付け という．このことを解説するWikipediaページもある．\n\n\n\n\n\n\n命題（独立性の特徴付け）\n\n\n\n2つの事象 \\(A,B\\subset\\Omega\\) について，次の2条件は同値：\n\n\\(A,B\\) は独立である：\\(A\\perp\\!\\!\\!\\perp B\\)．\n\\(P(B|A)=P(B)\\)．\n\n\n\n\n\n\n\n\n\n証明\n\n\n\n\\(P[A]=0\\) の場合，任意の \\(B\\) について(1),(2)はいずれも常に成り立つ． あとは，\\(P[A]\\ne0\\)の場合を考える． すると，条件付き確率の定義 \\[P[A\\cap B]=P[A]P[B|A]\\] を考えれば，この右辺が\\(P[A]P[B]\\)に等しいことと，\\(P[B|A]=P[B]\\)であることとは同値．\n\n\n本書では2.の性質の方を定義としているが， \\(P(B|A)\\) という量は， \\(P(A)=0\\) の場合に定義に任意性が残る．従って，1.の方が定義として明瞭ということになる．\nさらに重要なことには，1.の方が一般個数の事象 \\(A_1,\\cdots,A_n\\) の場合に「独立性」の概念の拡張が可能であり，より本質的な定義だと思われる，ということが確率論の示唆である．実は，無限個の事象が独立であることも同様に定義する．\n\n\n\n\n\n\n定義（独立性）\n\n\n\n集合族 \\(\\{A_\\lambda\\}_{\\lambda\\in\\Lambda}\\subset\\mathcal{F}\\) が独立であるとは，任意の \\(n\\in\\mathbb{N}\\) 個の相異なる元 \\(A_{\\lambda_1},\\cdots,A_{\\lambda_n}\\) に対して， \\[P[A_{\\lambda_1}\\cap\\cdots\\cap A_{\\lambda_n}]=P[A_{\\lambda_1}]\\cdots P[A_{\\lambda_n}]\\] が成り立つことをいう．"
  },
  {
    "objectID": "posts/2023/2023-11-22/法律家のための統計数理1.html#余談数学について",
    "href": "posts/2023/2023-11-22/法律家のための統計数理1.html#余談数学について",
    "title": "法律家のための統計数理（1）第1章第1節",
    "section": "4 【余談】数学について",
    "text": "4 【余談】数学について\nここまでを読んだ読者の中で，「集合」「写像」の言葉に，定義が十分に提示されていないと感じたものがあるなら，あなたは極めて筋が良い．実は，これらの裏に全て厳密な定義があるのが数学であるが，今回は確率論に集中するために省いた．\n実際，確率論をKolmogorovによる確率の公理的な定義 (Kolmogorov, 1931) から始まる数学分野だとするならば，これはまだ100年の歴史もない，数学分野にしては極めて珍しい若い分野である．\n確率論の確率が遅れた理由は，「確率」の概念がつかみどころのない日常に根ざした概念であり，抽象化が本質的に難しいこともあるだろうが，第一に「集合」「写像」といった概念が十分に数学者の間で理解が深まるのを待つ必要があったということがある．\n現代の確率論では，「確率は測度の特別なものである」という態度をとっていることは本文中でも述べたが，この「測度」という概念の成立が，そもそもLebesgueによる積分論が確立される20世紀に入るのを待つ必要があった．"
  },
  {
    "objectID": "posts/2023/2023-11-22/法律家のための統計数理1.html#footnotes",
    "href": "posts/2023/2023-11-22/法律家のための統計数理1.html#footnotes",
    "title": "法律家のための統計数理（1）第1章第1節",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(McElreath, 2020) 1.3節．頻度論はさらに「仮想的な反復」(imaginary resampling of data)を想定する，という性質を除けば，不確実性が観測からくるもののみである特別な場合が頻度論であると捉えられる．↩︎\n(McElreath, 2020) 1.3節，(Rubin, 1984)．↩︎\nWikipediaページ確率の公理も参照．↩︎\n関数とは，入力と出力の集合 \\(X,Y\\) の間に定まる対応であって，任意の入力 \\(x\\in X\\) に対してただ一つの出力 \\(y\\in Y\\) が対応するもののことをいう．この対応を \\(f(x)=y\\) と表す．↩︎\n後ろの2条件[P2], [P3] のみを満たす関数 \\(P\\) は「測度」という．そのため，確率は測度でもある．数学用語では「確率分布」は「確率測度」ともいう（例えばこのwikipediaページ）．↩︎\n[P1] などの P は Probability のつもりである．↩︎\n集合にも公理があり，現代数学はZFC公理系の下で展開される．が，ここでは深入りしない．↩︎\n\\(\\lnot A\\) という記法について，\\(\\lnot\\) は論理記号であるから，集合 \\(A\\) に用いることは好ましくない．↩︎\n確率は必ず\\(0\\)から\\(1\\)の値を取る，ということを主張している命題である．初学者はこれが「示すべき内容」として提示されていることに戸惑いを覚えるだろうが，現代数学では「これが示せるような必要最小限の定義が見つかった」ことに価値を見出す．↩︎\nここでは \\(P(A)=0\\) の場合は \\(0\\) としたが，実際はどんな値でも良い．↩︎"
  },
  {
    "objectID": "posts/2023/2023-11-4/QuartoBasics.html",
    "href": "posts/2023/2023-11-4/QuartoBasics.html",
    "title": "Quartoはじめて良かった | Quarto Basics in Japanese",
    "section": "",
    "text": "筆者はQuartoを，「TeXにような使用感で数式・コードが併存する文章を書き，RStudioのような使用感でコードの実行やプレゼンができる，等号開発環境」と理解した． 前述のTeX, RStudioに慣れている人にとっては極めて低い限界コストで莫大な利益を得るだろう．"
  },
  {
    "objectID": "posts/2023/2023-11-4/QuartoBasics.html#デモページ",
    "href": "posts/2023/2023-11-4/QuartoBasics.html#デモページ",
    "title": "Quartoはじめて良かった | Quarto Basics in Japanese",
    "section": "1 デモページ",
    "text": "1 デモページ\n\n\n\n\n\n\nNote\n\n\n\nNote: The followings were pasted from the official documentation.1\n\n\nFor a demonstration of a line plot on a polar axis, see Figure 1.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 4 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "posts/2023/2023-11-4/QuartoBasics.html#使い方の概要",
    "href": "posts/2023/2023-11-4/QuartoBasics.html#使い方の概要",
    "title": "Quartoはじめて良かった | Quarto Basics in Japanese",
    "section": "2 使い方の概要",
    "text": "2 使い方の概要\nQuartoではこのようなNotebook-likeなドキュメントが，極めて簡単に＋凡ゆるフォーマットで作成できる． 特にVSCodeの拡張機能と組み合わせれば，RStudioのような隙のない統合開発環境が得られる．またVSCodeではビジュアルモードでの編集もサポートされており，Jupyter Notebookと全く同じ使用感で始められる．\n基本的な仕組みとして，自分で作成するのは .qmdファイルのみである．その後はquarto renderコマンドにより，コードブロックはJupyterによって処理され，全体はmarkdownに変換され，Pandocによってpdf, html, word など好きな形式に最終出力できる．\n拡張機能をオンにしたVSCodeではRun Cellボタンもあるので，ノートブック全体を毎度ビルドせずとも，コードブロックごとに実行して結果を見ることもできる．Ctrl+Enterで１行ごとに実行できる操作感はRStudioと同じである．\n各ファイルの冒頭にYAML blockを用意することで，ノートブックの詳細を調整できる（参照：HTML Options）．\n---\ntitle: \"Quarto Basics\"\nformat:\n  html:\n    code-fold: true\njupyter: python3\n---\n本文はmarkdown記法で書く．数式も使える： \\[\\mathrm{P}[|\\xi|&lt;t]\\le2e^{-\\frac{t^2}{2\\sigma^2}},\\qquad t&gt;0.\\]\nまた，コードブロックにもコメントアウトと接頭辞の組み合わせ#|を前につけることでYAMLで指示が出せる（参照：指示のリスト）．上のコードブロックには\n#| label: fig-polar\n#| fig-cap: \"A line plot on a polar axis\"\nと追加されているために，出力された図にラベリングとキャプションが付いているのである．"
  },
  {
    "objectID": "posts/2023/2023-11-4/QuartoBasics.html#美点",
    "href": "posts/2023/2023-11-4/QuartoBasics.html#美点",
    "title": "Quartoはじめて良かった | Quarto Basics in Japanese",
    "section": "3 美点",
    "text": "3 美点\n\nレンダリングがとんでもなく速い．体感でTeXの10分の1である．\nそれでいて数式とコードブロックを併在させることが出来る．なお，明かにTeXを意識していることがわかる使用感になっているし，本の作成も可能としている．\nローカル環境で動く．Jupyter Notebookが続かない筆者にとって，この点は肝要である．\n私用の勉強ノートとしても使えると同時に，内容そのままブログとして公開できる．\nプレゼンテーションにも使える．\nすごい細かいが，例えばproject typeをwebsiteとしたリポジトリでquarto renderをしても，不要なファイルが自動で削除される．このような点がライトユーザーでもとにかく使いやすい．\nさらにインタラクティブな機能を実現してみたい．"
  },
  {
    "objectID": "posts/2023/2023-11-4/QuartoBasics.html#website-hostingのやり方",
    "href": "posts/2023/2023-11-4/QuartoBasics.html#website-hostingのやり方",
    "title": "Quartoはじめて良かった | Quarto Basics in Japanese",
    "section": "4 Website Hostingのやり方",
    "text": "4 Website Hostingのやり方\n公式Guideを参考．\n\n4.1 Source Branchをmainと別ける\nまずgh-pagesという全く新しいブランチを作成する．既存のリポジトリのコミット履歴とは独立している新しいブランチを作るときは--orphanオプションが利用される．\n\n\nTerminal\n\ngit checkout --orphan gh-pages\ngit reset --hard # make sure all changes are committed before running this!\ngit commit --allow-empty -m \"Initialising gh-pages branch\"\ngit push origin gh-pages\ngit checkout main\n\n基本gh-pagesブランチには自分では立ち入らない．\n\n\n4.2 Publishコマンドによるサイトの公開\nmainブランチにいることを確認して，\n\n\nTerminal\n\nquarto publish gh-pages\n\nを実行．\nGitHubの方の設定Settings: Pagesで，Sourceをgh-pagesブランチの/(root)にしていることを確認すれば，これで無事サイトが公開されていることが確認できる．\n\n\n4.3 GitHub Actionの使用\nさらに，ローカル上でrenderするのではなく，コミットする度にGitHub上でレンダリングしてもらえるように自動化することもできる．こうするとスマホからも自分のサイトが更新できる．\nまず，GitHubの設定のActionsセクションのWorkflow permissionsから，読み書きの権限をGitHub Actionに付与する．\n続いて，次の内容のファイルを.github/workflows/publish.ymlに書き込む：\n\n\n.github/workflows/publish.yml\n\non:\n  workflow_dispatch:\n  push:\n    branches: main\n\nname: Quarto Publish\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v4\n\n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n\n      - name: Render and Publish\n        uses: quarto-dev/quarto-actions/publish@v2\n        with:\n          target: gh-pages\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\nこれで，mainブランチにコミットする度に，GitHub上でrenderが実行されることとなる．"
  },
  {
    "objectID": "posts/2023/2023-11-4/QuartoBasics.html#footnotes",
    "href": "posts/2023/2023-11-4/QuartoBasics.html#footnotes",
    "title": "Quartoはじめて良かった | Quarto Basics in Japanese",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is footnote. What a great feature!↩︎"
  },
  {
    "objectID": "posts/2023/2023-12-4/MentalHealth.html",
    "href": "posts/2023/2023-12-4/MentalHealth.html",
    "title": "About Mental Health Issues",
    "section": "",
    "text": "メンタルヘルスを損なってしまったとき，「もう二度と以前の状態には戻れないのではないか」という絶望が最初に付きまとうと思う．結論から言うと，絶対戻れる．だが，今じゃない．\nそもそも，メンタルヘルスの問題は「病気」と「健常」の境界が曖昧になってしまったと感じるだろう．治ったと思ったら治っていなくて，「一体いつまで続くのだろう」「以前は『正常』だと思っていた状態に，二度と戻れないのではないか？」という反芻思考が心を襲うだろう．\nそれは当然である．あなたはまだ治っていない．そもそも普通の風邪だって，「病気」と「健常」の境界など無いに等しい．熱があると社会は許してくれるが，熱とはそもそもウイルス・病原菌の感染から身体を守るための「正常な」反応である．身体に標準に組み込まれた防衛機制の想定された挙動の範囲内である．風邪は感染の可能性もあるから社会の方から休養を許してくれるのである．\nメンタルヘルスの問題だって，（一定範囲では）身体の正常な反応である．だが，あなたは休養を取っただろうか？社会は多くの場合理解を示さない．その中で自分の身体を守る対策を毅然と断行しただろうか？1 もし，休み休み前に進むことが出来る環境だったならば，あなたはメンタルヘルスに悩んでいなかっただろうし，「正常」と「異常」の境界にも悩んでいなかっただろう．食事が喉を通らない，眠れない，些細な刺激が絶大なストレスになる，胃を痛める，これらの反応は適度な休養が取れていて心に弾力がある状態ならば，「大変な時期もあったが，それを乗り越えて，私は大きく成功できた」という美談で終われる「正常」な心の反応である．風邪も流行感冒もそうだろう．だが，休まないまま通ろうとすると，本当に「異常」になる．風邪を治さずに活動し続けて，拗らせた経験はあるか？インフルになっても普段の生活を続けたことはあるか？あなたはそれをやろうとしていたのである．身体が想定外の挙動を起こしがちになるのも仕方ないというものである．\nだから，あなたはそもそも治っていないのである．風邪の原因はウイルスであり，あなたは休養をして免疫機構に対処してもらう，そうして来ただろう．一方で心の病の原因は，人間関係と期待，社会的なプレッシャーがある立場，休養を許さないストレスフルな環境，あなたの場合はどれに該当するかわからないが，ほとんどの場合すぐには休養が取れない．だからこそあなたはメンタルヘルスを病んでいるのだろう．つまり，普段通りだと思っているあなたの心の風邪はまだ絶賛発熱中である．それどころか，何ヶ月も発熱したままである．早い段階で自分の免疫に治してもらわなければ，薬などの外部からの補助が必要になる（それでも治るが）．\n「一体いつまで続くのだろう？」「もう二度と正常の状態に戻れないのではないか？」という不安が的外れであることがわかっていただけただろうか？まずはストレスの原因がない状態に生活を持っていき，心の免疫が働く状態を整えよう．これには時間がかかるだろう．信頼できる人以外との関係を一度整理する必要があるし，ほとんどの場合金策の問題ですぐには十分に休めないかもしれない．さらに悪いことに「ストレスのない状態に生活を変える」こと自体が，あなたのアイデンティティの死を意味するかも知れない．だからあなたはボロボロになってこれ以上前に進めなくなるまで頑張ってしまったのだろう．だが，メンタルヘルスに変調をきたしてしまった場合，そのアイデンティティは少し修正せざるを得ない．ここはどうしても残酷な部分であるが，仕方のないことである．だが，考えてみてほしい．身体を強く病んでしまった人で，ここに深く絶望する人は少ない．\nストレスの原因のない状態に持っていってから，それでも治らないならばしっかり専門家に頼り，通院して服薬をすれば，絶対に治るし，元の「正常」な状態に戻る．そのときには，あなたは「正常」と「病気」との区別について，より深い理解を得ていることだろう．私がそうだった．"
  },
  {
    "objectID": "posts/2023/2023-12-4/MentalHealth.html#本当にあなたの運が良かっただけではと思う人へ",
    "href": "posts/2023/2023-12-4/MentalHealth.html#本当にあなたの運が良かっただけではと思う人へ",
    "title": "About Mental Health Issues",
    "section": "本当に？あなたの運が良かっただけでは？と思う人へ",
    "text": "本当に？あなたの運が良かっただけでは？と思う人へ\n「もう二度と治らないのだ」「脳の構造が変わってしまう」などと言う体験者の言葉は意外と多い．だが，これは「自分はメンタルヘルスの大きな病を抱えており，休養が必要である」ということを周囲に理解してもらうには多少荒技が必要であった人が，自身の休養を守るために使う表現としてもよく使われることに注意していただきたい．メンタルヘルスの病は，「一刻も早く治したい」と思っている人が全てではないことに注意する必要がある．彼らの言動に，あなたが傷ついたり，絶望する必要はない．治したいと思っているならば，専門家に相談すれば治る．度合いによってかかる時間は変わるかもしれないが，あなたが満足のいくレベルまで，治る．今すぐクリニックを検索して予約の電話を入れよう．良いクリニックなら1ヶ月前後待つことになるから，とりあえず予約だけして後からそれで良かったのか考えれば良い．運悪く，合うクリニックがすぐには見つからない可能性もあるが，とにかくトライし続けるのだ．正しい手を掴めば絶対に治るから．"
  },
  {
    "objectID": "posts/2023/2023-12-4/MentalHealth.html#footnotes",
    "href": "posts/2023/2023-12-4/MentalHealth.html#footnotes",
    "title": "About Mental Health Issues",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n当然，「メンタルヘルスは自分で守らなきゃいけない」という自衛に頼った構造になっている現代社会は，少しずつ変わっていくし，変わるべきだろう．だがいつの時代も自衛は大事だ．↩︎"
  },
  {
    "objectID": "posts/2023/2023-12-2/BoundedMeasure.html",
    "href": "posts/2023/2023-12-2/BoundedMeasure.html",
    "title": "「有界」測度と「有限」測度 | Between ‘Bounded’ Measures and ‘Finite’ Measures",
    "section": "",
    "text": "$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$"
  },
  {
    "objectID": "posts/2023/2023-12-2/BoundedMeasure.html#sec-1",
    "href": "posts/2023/2023-12-2/BoundedMeasure.html#sec-1",
    "title": "「有界」測度と「有限」測度 | Between ‘Bounded’ Measures and ‘Finite’ Measures",
    "section": "1 Jordan分解からの理解",
    "text": "1 Jordan分解からの理解\nJordan分解より，符号付き測度 \\(\\mu:\\Sigma\\to[-\\infty,\\infty]\\) が関数として有界であることと，全変動が有限（＝\\(\\mathbb{R}\\)-値）になること（有界変動であること）とは同値になる．\n\n\n\n\n\n\n定理（Hahn分解）\n\n\n\n\\((S,\\Sigma)\\) を可測空間，\\(\\mu:\\Sigma\\to[-\\infty,\\infty]\\) を符号付き測度とする．このとき，ある可測集合 \\(E_0\\in\\Sigma\\) が存在して，\\(\\mu:E_0\\cap\\Sigma\\to[0,\\infty]\\) は非負で，\\(\\mu:E_0^\\complement\\cap\\Sigma\\to[-\\infty,0]\\) は非正である．\n\n\n証明は (藤田宏，吉田耕作, 1991) はHahn分解を先に，Jordan分解を後に与えている．一方で (Dunford & Schwartz, 1958) は有限加法的測度のJordan分解を先に与えている．\n\n\n\n\n\n\n系（Jordan分解）\n\n\n\n\\((S,\\Sigma)\\) を可測空間，\\(\\mu:\\Sigma\\to[-\\infty,\\infty]\\) を符号付き測度とする．このとき， \\[\n\\mu^+(E):=\\mu(E_0\\cap E),\n\\] \\[\n\\mu^-(E):=-\\mu(E_0^\\complement\\cap E)\n\\] はHahn分解 \\(E_0\\in\\Sigma\\) の取り方に依らずに定まる測度となる．\n\n\n\n系2 (Hahn) \\(\\Phi(E)\\) が最大値 \\(+\\infty\\) をとれば，\\(\\Phi(E)\\) の最小値は \\(&gt;-\\infty\\)．また \\(\\Phi(E)\\) が最小値 \\(-\\infty\\) をとれば \\(\\Phi(E)\\) の最大値は \\(&lt;+\\infty\\)．とくに \\(\\Phi(E)\\) が有限であるならば（すなわち有限値しかとらないならば），\\(\\Phi\\) の値域 \\(\\{\\Phi(E)\\mid E\\in\\mathcal{M}\\}\\) は有界である．(藤田宏，吉田耕作, 1991, p. 389)"
  },
  {
    "objectID": "posts/2023/2023-12-2/BoundedMeasure.html#直接の証明",
    "href": "posts/2023/2023-12-2/BoundedMeasure.html#直接の証明",
    "title": "「有界」測度と「有限」測度 | Between ‘Bounded’ Measures and ‘Finite’ Measures",
    "section": "2 直接の証明",
    "text": "2 直接の証明\n\n\n\n\n\n\n命題（有限ならば有界）\n\n\n\n\\((S,\\Sigma)\\) を可測空間，\\(\\mu:\\Sigma\\to[-\\infty,\\infty)\\) を \\(\\sigma\\)-加法的な集合関数とする．このとき，\\(\\mu\\) は上に有界である．\n\n\n\n\n\n\n\n\n証明\n\n\n\n4 仮に \\(\\mu\\) は上に有界ではないと仮定して，矛盾を導く．可測集合 \\(E_1\\in\\Sigma\\) が非有界集合であるとは， \\[\\sup_{E\\in\\Sigma}\\mu(E\\cap E_1)=+\\infty\\] が成り立つこととすると，仮定より，少なくとも全体集合 \\(S\\) は非有界である．ここで，\n\n任意の非有界集合は，任意に大きな測度を持つ非有界部分集合を持つ．\nある非有界集合 \\(F\\in\\Sigma\\) が存在して，ある \\(N\\in\\mathbb{N}\\) よりも大きな測度を持つ \\(F\\) の非有界部分集合は存在しない．\n\nの２つの場合に分けられる．\n\nこのとき，減少列 \\(\\{E_n\\}\\subset\\Sigma\\) であって \\(\\mu(E_n)\\ge n\\;(n\\in\\mathbb{N}^+)\\) を満たすものが取れる．このとき，\\(\\sigma\\)-加法性から \\[\\mu\\left(\\bigcap_{i=1}^\\infty E_i\\right)+\\sum_{i=n}^\\infty\\mu(E_i\\setminus E_{i+1})=\\mu(E_n)\\] が成り立つが，仮定より \\(\\mu(E_n)&lt;\\infty\\) だから，左辺の第二項の無限和は任意の \\(n\\in\\mathbb{N}^+\\) について収束することがわかる．よって，\\(n\\to\\infty\\) の極限を考えることで右辺は発散するから，左辺も第一項が発散している必要がある： \\[\\mu\\left(\\bigcap_{i=1}^\\infty E_i\\right)=\\lim_{n\\to\\infty}\\mu(E_n)=\\infty.\\] これは \\(\\bigcap_{i=1}^\\infty E_i\\in\\Sigma\\) に矛盾．\n条件を満たす \\(F\\in\\Sigma\\) を取り，ある可測部分集合 \\(F_1\\subset F\\) は \\(\\mu(F_1)=\\mu(F_1\\cap F)&gt;N\\) を満たすとする．すると \\(F_1\\) は有界である必要があるが，\\(F\\) は非有界としたから，\\(F\\setminus F_1\\) が非有界である必要がある．よって可測部分集合 \\(A_1\\subset F\\setminus F_1\\) で \\(\\mu(A_1)\\ge1\\) を満たすものが取れる．すると \\(F_2:=F_1\\cup A_1\\) も \\(\\mu(F_2)\\ge\\mu(F_1)&gt;N\\) より，やはり有界である必要がある．これを繰り返すことで， \\[\\mu\\left(\\bigcup_{i=1}^\\infty A_i\\right)=\\infty\\] を満たす \\(\\{A_i\\}_{i\\in\\mathbb{N}^+}\\subset\\Sigma\\) が見つかってしまう．"
  },
  {
    "objectID": "posts/2023/2023-12-2/BoundedMeasure.html#sec-3",
    "href": "posts/2023/2023-12-2/BoundedMeasure.html#sec-3",
    "title": "「有界」測度と「有限」測度 | Between ‘Bounded’ Measures and ‘Finite’ Measures",
    "section": "3 一般のベクトル値測度の場合",
    "text": "3 一般のベクトル値測度の場合\n\n\n\n\n\n\n命題（有限ならば有界）\n\n\n\n\\((E,\\mathcal{E})\\) を可測空間，\\(B\\) をBanach空間，\\(\\nu:\\mathcal{E}\\to B\\) を可算加法的集合関数とする．\n\n写像 \\(\\lvert\\nu\\rvert:\\mathcal{E}\\to[0,\\infty]\\) を \\[\\lvert\\nu\\rvert(A):=\\sup_{(A_n)\\in\\mathrm{Map}(E,\\mathbb{N})}\\sum_{n=1}^\\infty\\lvert\\nu(A_n)\\rvert\\] で定めると，これは測度である．\n\\(B\\) が有限次元ならば，\\(\\mathrm{Im}\\;(\\lvert\\nu\\rvert)\\subset\\mathbb{R}_+\\) が成り立つ．すなわち，有界な測度である．\n\n\n\n\n\n\n\n\n\n証明\n\n\n\n5 仮に \\(\\lvert\\nu\\rvert(E)=\\infty\\) と仮定して矛盾を導く．\\(B=\\mathbb{R}\\) として示せば，あとは成分ごとに考えることで一般次元の場合も同様である．\n\\(A_1:=E\\) から始まる減少列を定める．全変動の定義から，ある部分集合 \\(B\\in\\mathcal{E},B\\subset A_1\\) が存在して， \\[\\lvert\\nu(B)\\rvert\\ge\\lvert\\nu(A_1)\\rvert+2\\] を満たす．\\(\\lvert\\nu\\rvert(B)=\\infty\\) のとき \\(A_2:=B\\) とし，\\(\\lvert\\nu\\rvert(B)&lt;\\infty\\) のとき\\(A_2:=A_1\\setminus B\\) とすると， \\[\\lvert\\nu\\rvert(A_1\\setminus B)=\\lvert\\nu\\rvert(A_1)-\\lvert\\nu\\rvert(B)=\\infty.\\] このとき，三角不等式から，どちらの場合も \\[\\lvert\\nu(A_2)\\rvert\\ge\\lvert\\nu(B)\\rvert-\\lvert\\nu(A_1)\\rvert\\ge2.\\] これを繰り返すことで，\\(\\lvert\\nu(A_n)\\rvert\\ge n\\;(n\\in\\mathbb{N}^+)\\) を満たす減少列 \\(\\{A_n\\}_{n=1}^\\infty\\) を得る．するとこの極限 \\(A:=\\bigcap_{n=1}^\\infty A_n\\) の測度は発散するが，これは \\(\\nu\\) が \\(B\\)-値であることに矛盾する．"
  },
  {
    "objectID": "posts/2023/2023-12-2/BoundedMeasure.html#footnotes",
    "href": "posts/2023/2023-12-2/BoundedMeasure.html#footnotes",
    "title": "「有界」測度と「有限」測度 | Between ‘Bounded’ Measures and ‘Finite’ Measures",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nここで符号付き測度とは，\\(\\sigma\\)-加法的な集合関数 \\(\\mu:\\Sigma\\to[-\\infty,\\infty]\\) であって，値域には \\(\\infty,-\\infty\\) のいずれか一方しか含まれないもの，としている．↩︎\n(Lang, 1993, p. 198)↩︎\n(Giesy, 1970)↩︎\n(Dunford & Schwartz, 1958, pp. 補題III.4.4 p.127) 参照．↩︎\n(Lang, 1993, pp. 定理3.2 p.197)．↩︎"
  },
  {
    "objectID": "posts/2023/2023-11-17/条件付き正規分布からのシミュレーション法.html",
    "href": "posts/2023/2023-11-17/条件付き正規分布からのシミュレーション法.html",
    "title": "条件付き正規分布からのシミュレーション法",
    "section": "",
    "text": "文献 (Doucet, 2010) の内容に基づき，証明を与えながら，条件付きGauss分布の特定と，効率的なシミュレーション法を議論し，線型Gauss状態空間モデルのフィルタリング（特にEnsemble Kalman filter）に応用する．"
  },
  {
    "objectID": "posts/2023/2023-11-17/条件付き正規分布からのシミュレーション法.html#sec-1",
    "href": "posts/2023/2023-11-17/条件付き正規分布からのシミュレーション法.html#sec-1",
    "title": "条件付き正規分布からのシミュレーション法",
    "section": "1 正規確率変数同士の条件付き分布",
    "text": "1 正規確率変数同士の条件付き分布\n\n\n\n\n\n\n命題：正規確率変数同士の条件付き分布\n\n\n\n\\[Z=(X,Y)\\sim\\mathrm{N}_n(m,\\Sigma)\\] \\[m=\\begin{pmatrix}m_x\\\\m_y\\end{pmatrix},\\qquad\\Sigma=\\begin{pmatrix}\\Sigma_{xx}&\\Sigma_{xy}\\\\\\Sigma_{xy}^\\top&\\Sigma_{yy}\\end{pmatrix}\\] で，共分散行列は正則 \\(\\Sigma\\in\\mathrm{GL}_n(\\mathbb{R})\\) とする．このとき， \\[X|Y=y\\sim\\mathrm{N}_{n_x}(m_{x|y},\\Sigma_{x|y}),\\] \\[m_{x|y}=m_x+\\Sigma_{xy}\\Sigma_{yy}^{-1}(y-m_y),\\] \\[\\Sigma_{x|y}=\\Sigma_{xx}-\\Sigma_{xy}\\Sigma_{yy}^{-1}\\Sigma_{xy}^\\top.\\]\n\n\n\n\n\n\n\n\n証明\n\n\n\n\\(Z\\)の密度 \\[\n\\begin{align*}\n    &\\frac{1}{(2\\pi)^{n/2}(\\det\\Sigma)^{1/2}}\\\\\n    &\\quad\\times\\exp\\left(-\\frac{1}{2}(z-m)^\\top\\Sigma^{-1}(z-m)\\right)\n\\end{align*}\n\\] を，\\(Y\\) の密度との積で表した際，残った因子が \\(X|Y\\) の密度となる． \\(\\exp\\) の中身に注目する．Schur補行列を \\(S:=\\Sigma_{xx}-\\Sigma_{xy}\\Sigma_{yy}^{-1}\\Sigma_{xy}^\\top\\) とすると， \\[\n\\Sigma^{-1}=\\begin{pmatrix}S^{-1}&-S^{-1}T\\\\-T^\\top S^{-1}&\\Sigma_{yy}^{-1}+T^\\top S^{-1}T\\end{pmatrix},\n\\] \\[\nT:=\\Sigma_{xy}\\Sigma_{yy}^{-1},\n\\] であるから， \\(\\eta:=T(y-m_y)=\\Sigma_{xx}\\Sigma_{yy}^{-1}(y-m_y)\\) とおくと， \\[\n\\begin{align*}\n    &\\quad(z-m)^\\top\\Sigma^{-1}(z-m)\\\\\n    &=(x-m_x)^\\top S^{-1}(x-m_x)\\\\\n    &\\qquad\\quad-(y-m_y)^\\top T^\\top S^{-1}(x-m_x)\\\\\n    &\\qquad\\quad-(x-m_x)^\\top S^{-1}T(y-m_y)\\\\\n    &\\qquad\\quad+(y-m_y)^\\top T^\\top S^{-1}T(y-m_y)\\\\\n    &\\qquad\\quad+(y-m_y)^\\top\\Sigma_{yy}^{-1}(y-m_y)\\\\\n    &=\\biggr((x-m_x)^\\top-\\eta^\\top\\biggl)S^{-1}(x-m_x)\\\\\n    &\\qquad\\quad-\\biggr((x-m_x)^\\top+\\eta^\\top\\biggl)S^{-1}\\eta\\\\\n    &\\qquad\\quad+(y-m_y)^\\top\\Sigma_{yy}^{-1}(y-m_y)\\\\\n    &=\\biggr((x-m_x)^\\top-\\eta^\\top\\biggl)S^{-1}\\biggr((x-m_x)-\\eta\\biggl)\\\\\n    &\\qquad\\qquad+(y-m_y)^\\top\\Sigma_{yy}^{-1}(y-m_y).\n\\end{align*}\n\\] 以上より，平均は \\(m_{x|y}=m_x+\\eta\\) で，共分散行列は \\(\\Sigma_{x|y}=S\\) ．"
  },
  {
    "objectID": "posts/2023/2023-11-17/条件付き正規分布からのシミュレーション法.html#sec-2",
    "href": "posts/2023/2023-11-17/条件付き正規分布からのシミュレーション法.html#sec-2",
    "title": "条件付き正規分布からのシミュレーション法",
    "section": "2 条件付き分布からのシミュレーション",
    "text": "2 条件付き分布からのシミュレーション\n\n\n\n\n\n\n条件付き分布からのシミュレーション\n\n\n\n条件付き確率変数 \\(X|Y=y\\) のシミュレーションは，条件付き共分散行列 \\(\\Sigma_{x|y}\\) のCholesky分解 \\(\\Sigma_{x|y}=\\sqrt{\\Sigma_{x|y}}\\left(\\sqrt{\\Sigma_{x|y}}\\right)^\\top\\) を用いて， \\[\\overline{X}=m_{x|y}+\\sqrt{\\Sigma_{x|y}}U,\\] \\[U\\sim\\mathrm{N}_{n_x}(0,I_{n_x})\\] によって行うのも直接的だが， \\(n_x\\) の次元が大きすぎる場合，Cholesky分解の計算がネックとなる．そのような場合は， \\[\\overline{X}=X+\\Sigma_{xy}\\Sigma_{yy}^{-1}(y-Y),\\] \\[Z=\\begin{pmatrix}X\\\\Y\\end{pmatrix}\\sim\\mathrm{N}_n(m,\\Sigma),\\] というアルゴリズムを用いることが出来る (Hoffman & Ribak, 1991)．\n\n\n\n\n\n\n\n\n証明\n\n\n\n\\(\\overline{X}\\) はGauss確率変数の線型変換だからやはりGaussである．よって，平均と分散が \\(X|Y\\) に一致することを示せば良い． 次のように \\(\\overline{X}\\) を書き換えることが出来る： \\[\\begin{align*}\n    \\overline{X}&=X+\\Sigma_{xy}\\Sigma_{yy}^{-1}(y-Y)\\\\\n    &=X+\\biggr(m_x+\\Sigma_{xy}\\Sigma_{yy}^{-1}(y-m_y)\\biggl)\\\\\n    &\\qquad+\\biggr(m_x+\\Sigma_{xy}\\Sigma_{yy}^{-1}(Y-m_y)\\biggl)\\\\\n    &=X+m_{x|y}-\\mathrm{E}[X|Y]\n\\end{align*}\\] これより，\\(\\mathrm{E}[\\overline{X}|Y]=m_{x|y}\\)．よって， \\[\\mathrm{E}[\\overline{X}]=\\mathrm{E}[\\mathrm{E}[\\overline{X}|Y]]=m_{x|y}.\\] 続いて， \\[\n\\begin{align*}\n    \\mathrm{V}[\\overline{X}|Y]&=\\mathrm{V}[X-\\mathrm{E}[X|Y]|Y]\\\\\n    &=\\mathrm{E}[(X-\\mathrm{E}[X|Y])^2|Y]\\\\\n    &=\\mathrm{V}[X|Y]=\\Sigma_{x|y}\n\\end{align*}\n\\] より，全分散の公式から \\[\n\\begin{align*}\n\\mathrm{V}[\\overline{X}]&=\\mathrm{E}[\\mathrm{V}[\\overline{X}|Y]]+\\underbrace{\\mathrm{V}[\\mathrm{E}[\\overline{X}|Y]]}_{=0}\\\\\n&=\\Sigma_{x|y}.\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/2023/2023-11-17/条件付き正規分布からのシミュレーション法.html#応用-ensemble-kalman-filter",
    "href": "posts/2023/2023-11-17/条件付き正規分布からのシミュレーション法.html#応用-ensemble-kalman-filter",
    "title": "条件付き正規分布からのシミュレーション法",
    "section": "3 応用 Ensemble Kalman filter",
    "text": "3 応用 Ensemble Kalman filter\nまた，Ensemble Kalman filterはこの手法の応用と理解することができ，この手法の別の応用としてFFBS (Forward Filtering Backward Sampling)アルゴリズムを代替するサンプリングアルゴリズムを得ることが出来ることも論じている．\n線型Gaussな状態空間モデル \\[\n\\begin{cases}\nX_n=A_nX_{n-1}+a_n+W_n&n\\ge 1,\\\\\nY_n=B_nX_n+b_n+V_n,&n\\ge0.\n\\end{cases}\n\\] \\[\nW_n\\sim\\mathrm{N}_p(0,R^w_n),\\quad V_n\\sim\\mathrm{N}_q(0,R_n^v),\n\\]\nの最適な一段階予測推定量 \\[\n\\eta_n:=\\mathcal{L}[X_n|(Y_0,\\cdots,Y_{n-1})]\n\\] も，フィルタリング推定量 \\[\n\\widehat{\\eta}_n:=\\mathcal{L}[X_n|(Y_0,\\cdots,Y_n)]\n\\] もGauss確率変数で，平均と分散は 節 1 の命題の繰り返し適用によって計算できる．これをKalman filterという．1\n\n3.1 EnKF\nしかし，状態空間（\\(X_n\\)の値域）の次元が大きすぎる場合，節 2 で述べた理由と同様の理由で，Kalman gainの行列計算が実行不可能になる．\nこのステップを，粒子平均によって代替する粒子法がEnsemble Kalman filterであり，前述の障碍が典型的に生じてきた地球科学・海洋科学の分野で発展してきた (Evensen, 1994)．この方法では， 節 2 のサンプリングトリックを用いて，再帰的にフィルタリング分布と予測分布を近似していく．\n\n\n3.2 FFBS\nまた，線型Gauss状態空間モデルのハイパーパラメータの推定が必要な場合などでは，Feynman-Kac分布 \\(p(x_{0:n}|y_{1:n})\\) からのサンプリングが必要になる．\n典型的にはFFBS (Foward Filtering Backward Sampling) などの方法が知られている．これは \\(p(x_{0:n}|y_{1:n})\\) があるMarkov連鎖の見本道の分布に一致することに基づき，その後ろ向き核による分解から，\n\n前向きにフィルタリング分布と予測分布を計算する再帰的アルゴリズムを実行する．\n2つの分布から後ろ向き核を計算する．\n後ろ向き核を用いて， \\(X_n\\sim p(x_n|y_{1:n})\\) を後ろ向きにサンプリングしていく．\n\nと実行する方法である．2\n一方で， 節 2 のテクニックで次のようにしてサンプリングすることもできる．\n\n前向きに \\(\\mathrm{E}[X_{0:n}|Y_{1:n}], \\mathrm{E}[X_{0:n}|Y_{1:n}=y_{1:n}]\\) を計算する．\n次をサンプリングする： \\[\n\\begin{align*}\n\\overline{X}_{0:n}&:=\\mathrm{E}[X_{0:n}|Y_{1:n}=y_{1:n}]\\\\\n&\\qquad+X_{0:n}-\\mathrm{E}[X_{0:n}|Y_{1:n}]\n\\end{align*}\n\\]\n\n(Durbin & Koopman, 2002) では，多くの場合 \\(R^w_n\\) のランクが低いことに注目して， \\(\\mathrm{E}[W_{1:n}|Y_{1:n}]\\) を計算して， \\(p(x_0,w_{1:n}|y_{1:n})\\) からサンプリングすることを提唱している．\n\n\n3.3 その他\n(Doucet, 2010) は他にも，時空間統計 (Cressie, 1993) と機械学習 (Rasmussen & Williams, 2006) などで生じるGauss過程への応用で役に立ち得るのではないかと示唆している．\nCard"
  },
  {
    "objectID": "posts/2023/2023-11-17/条件付き正規分布からのシミュレーション法.html#footnotes",
    "href": "posts/2023/2023-11-17/条件付き正規分布からのシミュレーション法.html#footnotes",
    "title": "条件付き正規分布からのシミュレーション法",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(Del Moral & Penev, 2014) p.280 など参照．↩︎\n(Chopin & Papaspiliopoulos, 2020) 5.4.4節 p.63 など参照．↩︎"
  },
  {
    "objectID": "posts/2023/2023-11-7/KernelMethods4Mathematicians.html",
    "href": "posts/2023/2023-11-7/KernelMethods4Mathematicians.html",
    "title": "数学者のためのカーネル法概観",
    "section": "",
    "text": "$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$"
  },
  {
    "objectID": "posts/2023/2023-11-7/KernelMethods4Mathematicians.html#導入",
    "href": "posts/2023/2023-11-7/KernelMethods4Mathematicians.html#導入",
    "title": "数学者のためのカーネル法概観",
    "section": "1 導入",
    "text": "1 導入\n\n1.1 カーネル法の歴史1\n1992年，当時は2023年に生きる我々と全く同じく，ニューラルネットワーク（以降NN）のブームのさなかにあった（当時は第二期ブーム）．このブームを一度終わらせたのが，(Boser et al., 1992) によるカーネル法であった．\n当時は数学の範疇から出たことがなかったカーネルの概念を用いて，SVMを非線形化したKernel SVMという手法を提案したのである．以降，非線形問題を扱えるモデルとして，NNを凌ぐ勢いで発展し，NNがvanishing gradientsという障壁にぶつかったこともあり，2000年から2006年を「深層学習の冬」とまで言わしめた．\n\n\n1.2 カーネル法の課題\n2006年というのは，(Hinton & Salakhutdinov, 2006)の年である．この自己符号化器の発表がきっかけになり，DNNの訓練がますます効率的になり，一方でKernel SVMは次の2つの障壁に直面しており，現在のDNN最強の時代を我々は見ている．2\n\n種々のタスクに対して，最適なカーネルが何かがわかっていない．\nデータ数が多すぎると実行不可能になる．\n\nカーネル法のトリックは単純であるから，個々の問題に即したカーネルの選び方，または適応的にカーネルを定めるアルゴリズムのデザインが，今後の課題である．"
  },
  {
    "objectID": "posts/2023/2023-11-7/KernelMethods4Mathematicians.html#カーネル法の数理",
    "href": "posts/2023/2023-11-7/KernelMethods4Mathematicians.html#カーネル法の数理",
    "title": "数学者のためのカーネル法概観",
    "section": "2 カーネル法の数理",
    "text": "2 カーネル法の数理\n\n2.1 カーネル法とは「データの前処理／データの変換をするための方法論」である\n線型手法が使えないときに，良い変数変換を考えることで，線型分離可能にする，というのは統計の基本的な手法である．\n例えば，データが正規分布から大きく違っている場合，Box-Cox変換\n\\[x \\longmapsto x^{(\\lambda)} = \\begin{cases}\n\\displaystyle \\frac{x^\\lambda - 1}{\\lambda} & \\lambda \\neq 0\\\\\n\\log x & \\lambda = 0\\end{cases}\\]\nを通じて正規分布に近づけることが出来る．このパラメータ \\(\\lambda\\in\\mathbb{R}\\) をデータから調整する．\nカーネル法は，このような非線形変換（はカーネル法ではないが3）を見つけてくるための系統的な枠組みであると言える．そして，カーネル法を通じて得た空間（特徴空間という）で従来の線型なデータ解析を施すだけで，全体としては非線型な手法の完成である．だから「カーネル法」という手法があるというより，種々の線型手法の「カーネル化」が常に考えられる，というものである．\n一方で，DNNはモデルの構成要素自体が非線型であり，全く精神が違う非線型手法だと言えるだろう．\n\n\n2.2 カーネル法の骨格\nカーネルと言ったとき，数学的には「（実数値の）半正定値対称関数」を指す．\n\n\n\n\n\n\n定義：（実数値の）正定値カーネル\n\n\n\n関数 \\(k:\\Omega\\times\\Omega\\to\\mathbb{R}\\) が正定値カーネルであるとは，次の２条件を満たすことをいう：\n\n対称性：\\(k(x,y)=k(y,x)\\)．\n正値性：任意有限個の点 \\(x_1,\\cdots,x_n\\in\\Omega\\) に対し，行列 \\(\\bigl(k(x_i,x_j)\\bigr)^n_{i,j=1}\\) は半正定値：4 \\[\n  \\sum_{i,j=1}^nc_ic_jk(x_i,x_j)\\ge0,\\qquad c_i\\in\\mathbb{R}.\n\\]\n\n\n\n\n\n\n\n\n\n例：\\(\\Omega=\\mathbb{R}^d\\) 上の正定値カーネル\n\n\n\n\nEuclid内積：\\(k(x,y)=x^\\top y\\)．\nGaussカーネル：\\(k_G(x,y)=\\exp\\left(-\\frac{1}{2\\sigma^2}\\|x-y\\|^2\\right)\\;(\\sigma&gt;0)\\)．\nLaplaceカーネル：\\(k_L(x,y)=\\exp\\left(-\\alpha\\sum_{a=1}^d|x_a-y_a|\\right)\\;(\\alpha&gt;0)\\)．\n多項式カーネル：\\(k_P(x,y)=(c+x^\\top y)^d\\;(c\\ge0,d\\in\\mathbb{N})\\)．\n\n\n\nこの「正定値カーネル」の概念は，次の意味で，「内積」と同一視できる．「内積」と同一視できるという意味で，「類似度の測り方」に対応する．\n\n\n\n\n\n\n定理：Moore-Aronszajn 1950\n\n\n\n任意の集合 \\(\\Omega\\) 上の正定値カーネル \\(k\\) に対して，\\(\\Omega\\) 上の関数からなるHilbert空間 \\(H_k\\) であって，以下を満たすものが一意に定まる：5\n\n\\(k(-,x)\\in H_k\\;(\\forall_{x\\in\\Omega})\\)．\n（再生性）\\((f\\,|\\,k(-,x))_{H_k}=f(x)\\)．\n\nこのHilbert空間 \\(H_k\\) を数学では \\(k\\)-再生核Hilbert空間といい，データ解析では \\(k\\)-特徴空間という．\n\n\nここで，数学概念について，少し突飛に思えるかもしれないが，次の名前をつける．\n\n\n\n\n\n\n定義\n\n\n\n正定値カーネル \\(k:\\Omega\\to\\mathbb{R}\\) について，\n\n\\(x\\mapsto k(-,x)\\) という対応 \\(\\Phi:\\Omega\\to H_k\\) を特徴写像という．\n\\(\\Phi\\) は「内積を保つ」が，この性質をカーネルトリックという： \\[\n\\left(\\Phi(x)\\,\\middle|\\,\\Phi(y)\\right)_{H_k}=k(x,y).\n\\]\n\n\n\n「特徴写像」は，データ \\(x,y\\in\\Omega\\) を正定値カーネルが測る「類似度」を変えないように，しかしながら全く違う空間内の点 \\(\\Phi(x),\\Phi(y)\\in H_k\\) に写している．「類似度」が変わっていないことを「カーネルトリック」と呼ぶ．\nこの「トリック」は少し米田埋め込みに似ている．データ \\(x\\in\\Omega\\) の他のデータとの類似度の全体 \\(k(-,x):\\Omega\\to\\mathbb{R}\\) は，そのデータを特徴づけるのである \\(k(-,x)=\\Phi(x)\\in H_k\\)．\nまた，関数のなすHilbert空間 \\(H\\subset\\mathbb{R}^\\Omega\\) が， \\(\\{\\mathrm{ev}_x\\}_{x\\in\\Omega}\\subset H^*\\) を満たすならば，\\(H\\) は再生核を持つ．このような関数空間 \\(H\\) の内積の構造を \\(\\Omega\\) にも導入したいとき， \\(k\\) を通じてすれば良いということになる． \\(k\\) は違う \\(H_k\\) と \\(\\Omega\\) を対応づけ，正しい \\(k\\) を選ぶと，データ \\(\\{x_1,\\cdots,x_n\\}\\subset\\Omega\\) のうちなる「特徴」を暴き出せるかもしれない．\n\n\n2.3 カーネル法の強み\nこうして見たように，カーネル法は\n\n非線型な情報，特に高次モーメントの扱いができる．\nデータの次元 \\(X_i\\in\\mathbb{R}^p\\) に依らない．が，データ数 \\(N\\) に依存し，次元の呪いを受ける．\nデータの形式にも依らない．ベクトルでなくとも，グラフでも，行列でも，分布でも良い．"
  },
  {
    "objectID": "posts/2023/2023-11-7/KernelMethods4Mathematicians.html#種々のデータ解析のカーネル化",
    "href": "posts/2023/2023-11-7/KernelMethods4Mathematicians.html#種々のデータ解析のカーネル化",
    "title": "数学者のためのカーネル法概観",
    "section": "3 種々のデータ解析のカーネル化",
    "text": "3 種々のデータ解析のカーネル化\n\n3.1 データ解析のやり方\n\nカーネル \\(k\\) を用意する．すると，特徴空間 \\(H_k\\) が定まるが，これは一般に関数空間であり，無限次元である．\\(H_k\\) の元を「特徴ベクトル」と言ったりするのに，その正体は関数である．\nカーネルトリック（≒再生性）が，「特徴ベクトル同士の内積」だけを計算可能にする．\n\n要は計算できることは内積だけなのである！しかし，特徴写像や特徴ベクトルの表示を陽に使わずとも，内積だけで実行可能な線型データ解析は，実に多いのである．\n\n\n3.2 例：Ridge回帰\nRidge回帰は，次の最適化によって線型回帰係数 \\(a\\in\\mathbb{R}^p\\) を推定するロバスト手法である：\n\\[\n  \\min_{a\\in\\mathbb{R}^p}\\frac{1}{n}\\sum_{i=1}^n(Y_i-a^\\top X_i)^2+\\lambda\\|a\\|^2.\n\\]\nこれを「カーネル化する」とは，「特徴空間で実行する」ということである． \\(X_i\\) の代わりに \\(\\Phi(X_i)\\) 上で，Euclid内積 \\(a^\\top X_i\\) の代わりに特徴空間の内積 \\((f|\\Phi(X_i))_{H_k}\\) で実行するということである：\n\\[\n  \\min_{f\\in H_k}\\frac{1}{n}\\sum_{i=1}^n\\biggl(Y_i-(f|\\Phi(X_i))_{H_k}\\biggr)+\\lambda\\|f\\|^2_H\n\\]\n実はこの式は次と等価：\n\\[\n  \\min_{f\\in H_k}\\frac{1}{n}\\sum_{i=1}^n\\biggl(Y_i-f(X_i)\\biggr)+\\lambda\\|f\\|^2_H\n\\]\nたしかに，\\(f\\in H\\) は一般の関数であり，非線形な回帰を行なっていることになる！\nしかし，最後にこの最適化問題をどう解くか？という問題が残り，無限次元空間 \\(H\\) 上での最適化の理論が必要になるかといえばそうではなく，\n\\[\n  f=f_\\Phi:=\\sum_{i=1}^nc_i\\Phi(X_i)\n\\]\nという形のみで解を探せば良いことが判る．これは \\(f=f_\\Phi\\oplus f_\\perp\\) という直交分解を考えることで従う．つまり，最適化はデータ点 \\(\\Phi(X_1),\\cdots,\\Phi(X_n)\\) の張る有限次元部分空間上のみで考えれば良い．この事実にはRepresenter定理という仰々しい名前がついている．\nすると目的関数は\n\\[\n\\frac{1}{N}\\sum_{i=1}^N\\biggl(Y_i-\\sum_{j=1}^Nc_jk(X_i,X_j)\\biggr)^2+\\lambda\\underbrace{\\sum_{i,j=1}^Nc_ic_jk(X_i,X_j)}_{=c^\\top Kc}\n\\]\nとなり，これを解くと，カーネルRidge回帰の解は\n\\[\n\\widehat{f}(x)=\\boldsymbol{k}(x)^\\top(K+n\\lambda_nI_n)^{-1}\\boldsymbol{Y},\n\\]\n\\[\n\\boldsymbol{k}(x)=\\begin{pmatrix}k(x,X_1)\\\\\\vdots\\\\k(x,X_N)\\end{pmatrix},\\boldsymbol{Y}=\\begin{pmatrix}Y_1\\\\\\vdots\\\\Y_N\\end{pmatrix}\n\\]\nと表せることがわかる．\n\n\n3.3 発展\nここで，最初の節 節 1.1 で紹介した2つの問題点に戻る．\n\n種々のタスクに対して，最適なカーネルが何かがわかっていない．\nデータ数が多すぎると実行不可能になる．\n\nこの2.について，カーネルRidge回帰の例だと，逆行列 $\\((K+n\\lambda_nI_n)^{-1}\\) の計算が実行不可能になるという形で現前する．しかし，Woodburyの公式から，低ランク近似が得られていれば，それを活用できる．一般にGram行列の固有値の減衰は速いことが知られており，この低ランク近似の戦略は筋が良いと言える．\n1.について，まずSVMなどの教師あり学習の設定では，CVを使うことでカーネル選択をすることができる．が，教師なし学習では一般的な方法はない．特にカーネル主成分分析（次節の例）．しかし，これを適応的に学習するというのは良いアイデアだろう．Multiple Kernel Learning (Gönen & Alpaydin, 2011) はカーネルの凸結合を学習し，Deep Kernel Learning (Wilson et al., 2016) はNNによってカーネルを学習する．\n\n\n3.4 例：主成分分析\n主成分分析を抽象的に理解すれば，分散が大きい方向に射影をすることで，「意味がある方向」を見つける手法なのであった．\n主成分方向とは\n\\[\n\\max_{a\\in\\mathbb{R}^p:\\|a\\|=1}\\sum_{i=1}^N(a^\\top(X_i-\\overline{X}))^2.\n\\]\nの解 \\(a\\in\\mathbb{R}^p\\) である．これは分散共分散行列の固有値問題を解くことに等価になる．\nこの手法を「カーネル化」するには，特徴空間で実行すれば良い．\n\\[\n\\max_{f:\\|f\\|_H=1}\\sum_{i=1}^N\\biggl(f\\,\\bigg|\\,\\Phi(X_i)-\\overline{\\Phi}(X)\\biggr)^2\n\\]\nこの解も，データの特徴ベクトルの張る有限部分空間内で調べれば十分なのである！というのも，正確には，平均を引いた次の形のみを考えれば良いことが判る：\n\\[\nf=\\sum_{i=1}^Nc_i\\biggl(\\Phi(X_i)-\\overline{\\Phi(X)}\\biggr)\n\\]\n実際には，中心化Gram行列の固有値問題に帰着する：\n\\[\n\\widetilde{K}_{ij}=k(X_i,X_j)-\\frac{1}{N}\\sum_{b=1}^Nk(X_i,X_b)\\qquad\\qquad\n\\]\n\\[\n\\qquad\\qquad-\\frac{1}{N}\\sum_{a=1}^Nk(X_a,X_j)+\\frac{1}{n^2}\\sum_{a,b=1}^Nk(X_a,X_b).\n\\]\n\n\n3.5 例：SVM\nデータ \\(\\{x_1,\\cdots,x_n\\}\\subset\\mathbb{R}^p\\) が線型分離可能であるとき，ハードマージン法と呼ばれる手法を用いて，これを分離する最大マージン超平面 \\[\nH_\\mathrm{max}:=\\mathop{\\mathrm{arg\\,max}}_{H\\subset\\mathbb{R}^p}\\min_{1\\le i\\le n}d(x_i,H)\n\\] を，凸二次計画問題を解くことによって見つけることができる．このとき，最大のマージンを達成する \\[\nd(x_{j},H)=\\min_{1\\le i\\le n}d(x_i,H)\n\\] ときの \\(x_j\\) （複数あり得る）をサポートベクトル といい，これが解 \\(H_{\\text{max}}\\) を特徴付ける．\nこの問題において，特徴写像 \\(\\Phi:\\mathbb{R}^p\\to H_k\\) を考えても，やはり解を \\(n\\) 次元部分空間 \\[\nv\\in\\left\\{\\sum_{j=1}^nc_j\\Phi(x_j)\\in H_k\\;\\middle|\\;c_j\\in\\mathbb{R}\\right\\}\n\\] 上で考えれば良いから， \\[\n\\underset{v,\\gamma}{\\text{minimize}}\\quad\\|v\\|^2_{H_k}=\\sum_{i,j=1}^nc_ic_jk(x_i,x_j)\n\\] \\[\n\\text{subject to}\\quad\\lambda_i\\left(\\sum_{j=1}^nc_jk(x_i,x_j)+\\gamma\\right)\\ge1\\quad(i\\in[n])\n\\] という，やはり凸二次計画問題を解けば良い．\n\n\n3.6 総括\n\n\n\n\n\n\nまとめ\n\n\n\n典型的には，線型手法の目的関数が \\((\\Phi(X_i)|\\Phi(X_j)),(f|\\Phi(X_i))\\) で表現され，さらに解がデータ数の次元を持った有限次元部分空間で見つかる．その結果，Gram行列の解析に帰着し，データ数 \\(n\\) に依存するが，個々のデータの形式に依らない！データはベクトルでなく，カーネルが定義できさえすれば，確率分布自体でも問題がない．\n\n\n\n\n\nbook cover"
  },
  {
    "objectID": "posts/2023/2023-11-7/KernelMethods4Mathematicians.html#footnotes",
    "href": "posts/2023/2023-11-7/KernelMethods4Mathematicians.html#footnotes",
    "title": "数学者のためのカーネル法概観",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(Ghojogh et al., 2021) など参考．↩︎\n一方でここにきて，現代におけるDNNの最先端とも言えるTransformerをSVMとみなせる，という報告も出てきた (Tarzanagh et al., 2023)↩︎\nどちらかといえば，Box-Cox変換は一般化線型モデルの発想の先駆けと見れる．「リンク関数 \\(G\\) を用いて回帰関係を変換し非線形にする」という発想である．(Wolfgang Härdle & Sperlich, 2004, p. 162)↩︎\nこのようにして構成される行列をGram行列と呼ぶ．↩︎\n(Aronszajn, 1950) 参照．↩︎"
  },
  {
    "objectID": "posts/2023/2023-11-8/index.html",
    "href": "posts/2023/2023-11-8/index.html",
    "title": "書籍紹介 Del Moral (2004) Feynman-Kac Formulae",
    "section": "",
    "text": "book cover"
  },
  {
    "objectID": "posts/2023/2023-11-8/index.html#書籍紹介-del-moral-2004-feynman-kac-formulae",
    "href": "posts/2023/2023-11-8/index.html#書籍紹介-del-moral-2004-feynman-kac-formulae",
    "title": "書籍紹介 Del Moral (2004) Feynman-Kac Formulae",
    "section": "書籍紹介 Del Moral (2004) Feynman-Kac Formulae",
    "text": "書籍紹介 Del Moral (2004) Feynman-Kac Formulae\n前文と一部の内容が著者のHPからご覧になれます．\nFeynman-Kac Formulae\nこの本はFeynman-Kac道測度とその粒子法による解釈とその各種科学分野への応用を統一的に扱った初のモノグラフ．"
  },
  {
    "objectID": "posts/2023/2023-11-8/index.html#内容",
    "href": "posts/2023/2023-11-8/index.html#内容",
    "title": "書籍紹介 Del Moral (2004) Feynman-Kac Formulae",
    "section": "内容",
    "text": "内容\n\nPreface\n本書はFeynman-Kac path distribution, 相関粒子系，系統木モデルを扱う．生物学，物理学，確率統計学，工学，信号処理に渡る共通の話題である．21世紀に入ってやっと理論の形が見えてきたので，ここに教科書を書く．粒子法とFeynman-Kacモデル自体は，統計物理学，とりわけ気体分子運動論に起源を持つが，この本はその知識がなくても読めるようになっている．確率過程の素養がある学部生，工学・統計学・生物学・物理学の大学院生が対象読者である．\nまた，Feynman-Kacモデルと粒子法の漸近理論の研究に必要な数学，経験過程論，大偏差解析，半群・マルチンゲール理論，カオスの伝播，測度値過程の集中，関数不等式，エルゴード係数，Markov作用素の引き戻し，非線形半群など，の参考書になるようにも用意した．\nまた本書には種々のFeynman-Kac distribution flow, 相関粒子モデルの例の宝庫になっている．制限Markov連鎖シミュレーション，吸収媒体内のランダム粒子，Schrödinger作用素とFeynman-Kac半群のスペクトル解析，稀事象解析，Dirichlet境界問題，非線型フィルタリング問題，相関Kalman-Bucyフィルタ，方向つきポリマーシミュレーション，相関Metropolisアルゴリズムなど，種々のモデルの粒子近似と収束解析の例が含まれている．\nこれほど物理学・工学・数学にまたがるトピックを書籍化できたことに感謝しかない．本書を書いた理由は，まず第一にFeynman-Kac path modelとその粒子近似を扱う書籍は皆無だったからである．しかし同時に，この理論は現代のBayes統計学，工学，物理学，生物学で用いられるモンテカルロ法の解析に共通の土台を提供する，極めて有用な理論である．さらに，オペレータ記法に対する恐怖心さえ払拭して貰えば，非線型問題や相関粒子近似の研究に，強力な道具となること間違いなしである．\n第1と12章では連続なモデルも扱っているが，離散時間のFeynman-Kacモデルに集中した．その理由は第一に，離散時間ならばMarkov過程の前提知識をほとんど用いないためである．これは本書の「なるべくself-containedな教科書を書く」という目的に合致している．第二に，連続な場合の漸近解析は，ほとんど離散の場合と同じ道を辿るからである．一方で多くのopen problemも残るが．\n\n\nSec1.1 On the Origins of Feynman-Kac and Particle Models\n\n\n\n\n\n\nポイント\n\n\n\nWienerの道積分は，量子の運動を確率測度の言葉で書いた．FeynmanはSchrödinger方程式と繋げて，ポテンシャルを与えたモデルにおいて，当該ポテンシャルが定める「確率測度の変換則」を与えた．これがFeynman-Kacの公式である． Feynman-Kac測度は，生きたり死んだりする粒子系の見本道の分布や，一般に淘汰圧や相互作用にさらされる粒子の分布のモデリングに広く有用であることが判りつつある． 尤度，淘汰圧，相互作用が「ポテンシャル」という一つの枠組みで捉えられるのである．ポテンシャルを尤度とすると，特定の粒子に淘汰圧をかけることで，効率的に探索することに使える．\n\n\nFeynman-Kac公式はFeynmanの1942年の博士論文に起源を持つ．これはSchrödinger方程式とWienerの道積分とをヒューリスティックに繋いだ．この研究は1950年代のMark Kacの研究に受け継がれることになる．ポテンシャルに従って運動する量子の半群を，汎函数の道積分の言葉で記述する，というアイデアである．直感的には，Feynman-Kac測度は粒子の経路の分布に，ポテンシャルの効果を組み込むということである．\nこれは「ポテンシャル関数が定める確率測度の変換」であるが，この発想が多くの数理物理，確率過程の分野の研究の方向性を決定づけた．そして今日，このモデルは多くの現象のモデリングに有用であることがわかっている．例えば物理学で，吸収的で非規則的な媒質内での単一粒子の見本道の分布を記述することが出来る．このモデルでは，ポテンシャル関数というのは，「死亡／生成率」を表している．\nより一般的に，物理化学における有向ポリマーなどの物理・生物学的存在のBoltzmann-Gibbs分布ともみなせる．この例では，ポテンシャル関数というのは，ハミルトニアンや，ともかく相互作用のエネルギー関数や淘汰圧に相当するものになる．さらに工学や統計学者の文脈では，ポテンシャル関数は，特定の観察過程に対する変数の条件付き確率（＝尤度）を表すことになる．この見方はフィルタリング問題やBayes解析をはじめとし，信号処理の分野で広く使われている．ともかく，ポテンシャルとは，観測過程や，参照道に対する，状態変数の尤度と同一視されるのである．\n確率的粒子算譜は，Monte Carlo法の一種である．その源は，確率を頻度として捉えたBernoulliの基礎づけから見られる．そこから現代の確率論の発展に至るまでの大きな一歩は，1920年代のMarkovによる「確率過程」という対象の創出である．Markov過程という概念は，種々の工学・自然科学的対象を，自然な形でモデリングするための最適な語彙を与えた．さらに，粒子法の，他の数値解放にない美点は，工学や自然科学が与える発展方程式に対して，「微視的な粒子解釈を与える」という点である．他にも，モデルの係数に正則性の仮定を必要としないこと，大規模モデルにも使えることなど，美点は尽きない．1さらに現在発見されつつあるもう一つの魅力として，分布の空間上で非線型方程式が数値的に解ける，という方面での応用である．これらの分布モデルの非線型な構造は，その粒子近似版のモデルに，自然な相互作用と分岐のメカニズムを課す．この近年の応用は，1960年代の流体力学と統計物理の発展に源を発する．この方面については，McKeanの開拓的仕事を参照すると良い．\nこの相関粒子法を工学や，とりわけ信号処理の分野に使うという応用は，さらに最近になってのことである．この方面での最初の厳密な研究は，1996年の非線型推定問題への粒子法の応用であるように思われる．この研究は，1990年台に初めて提案された新たな種の相関粒子モデルに対して，初めて厳密な収束の結果を与えた．同様の研究が4つ追随し，この種の相関粒子モデルが，大規模かつ非線型な測度値過程を数値的に解く手法として優れていることが判明した．同時期に，別の粒子分岐過程が，連続時間のフィルタリング問題を解く手法として独立に提案された．このときの手法は，現在でも非線型平滑化や道推定問題に使われている系統木粒子モデルの漸近解析に，ほとんどそのまま使えることが判明した（Del Moral and Miclo (2001) Genealogies and Increasing Propagation of Chaos for Feynman-Kac and Genetics Model）．\n本書の要点を掴むために，最初の例を与える．Singer modelと呼ばれており，レーダーのモデルである．3次元のMarkov過程 \\(X_n=(X_n^{(1)},X_n^{(2)},X_n^{(3)})\\) を考え，それぞれ加速度，速度，位置を表し，次のように発展するとする：\n\\[\n\\begin{cases}X_n^{(1)}=X_{n-1}^{(1)}+\\epsilon_nW_n\\\\X_n^{(2)}=(1-\\alpha\\Delta)X_{n-1}^{(2)}+\\beta\\Delta X_n^{(1)}\\\\X_n^{(3)}=X_{n-1}^{(3)}+\\Delta X_n^{(2)}\\end{cases}\n\\]\n\\(\\Delta\\in(0,1),\\alpha,\\beta\\in\\mathbb{R}\\) はサンプリング頻度とパラメータとする． \\(\\epsilon_n\\in2\\) はBernoulli確率変数， \\(W_n\\sim\\mathrm{U}([0,a])\\) などとモデリングしよう． \\(X_n\\) の観測は，次のように部分的になされる：\n\\[\nY_n=X_n^{(3)}+\\Delta V_n.\n\\]\nこの状態で， \\(X_0,\\cdots,X_n|Y_0,\\cdots,X_n\\) の分布を推定する問題を，非線型フィルタリング問題という．この「パスの分布」に対する粒子近似は，次のようにして与えられる．まず， \\(X_0\\) から \\(N\\) 個サンプリングして粒子とする： \\(X_0\\sim X_{0}^i\\)．次に，始めに定めたMarkov遷移確率に従って，発展させて，見本道 \\(X_{t_0,t_1}^i=(X_0^i,\\cdots,X_{t_i}^i)\\) を得る．それぞれの見本道の尤度は\n\\[\nW_{t_0,t_1}^i=\\exp\\left(-\\frac{1}{2}\\sum_{t_0\\le p&lt;t_1}(Y_p-X_p^{(3),i})^2\\right)\n\\]\nで与えられる．これは， \\([0,1]\\) の値で，与えられた見本道 \\(X_{t_0,t_1}^i\\) が「尤もらしいか」の度合いを定量評価していると見れる．この情報を取り入れて，配置 \\(\\{X_{t_1}^i\\}_{i=1}^N\\) を更新する必要があるが，そのやり方には様々ある．ここでは，現在の見本道 \\(\\{X_{t_0,t_1}^i\\}_{i=1}^N\\) の中から，分布\n\\[\nW_{t_0,t_1}^i\\delta_{X_{t_0,t_1}^i}+(1-W^i_{t_0,t_1})\\sum_{j=1}^N\\frac{W_{t_0,t_1}^j}{\\sum_{k=1}^NW_{t_0,t_1}^k}\\delta_{X_{t_0,t_1}^j}\n\\]\nでリサンプリングすることを考える．これは，尤度 \\(W_{t_0,t_1}^i\\) の確率でその見本道は残存させ，さもなくば，尤度の重み付けに従って他の見本道で置き換えてしまう，という確率的操作を施すということである．この更新ののち，新たに心機一転 \\(t_1(&gt;t_0=0)\\) から開始した見本道 \\(X_{t_1,t_2}^i=(X_{t_1}^i,\\cdots,X_{t_2}^i)\\) を得て，同じ操作を繰り返す．ただし， \\(X_{t_1}^i\\gets\\widehat{X}_{t_1}^i\\) として更新したものを用いる．\nこの操作をすると，各粒子は死亡・分岐を繰り返すように見える．同時に，遺伝的に効率的な探索を行えていることも分かる．尤度が高いところに自然に粒子が集中していくようにできているのである．\nこの例を見て，最も基本的な疑問は「この手法に理論的保証がつくだろうか？」という点になる． \\(N\\) の増加に対して，収束のスピードはどう速まっていくだろうか？この手法を他の最適化やシミュレーションに応用できないか？また，この遺伝的アルゴリズムを死亡と繁殖の過程と見たとき，その系統木について何が言えるだろうか？\nこのような漸近解析の中心的なアイデアは，目的の条件付き分布 \\(Y_1,\\cdots,Y_n|X_1,\\cdots,X_n\\) を，離散生成モデルとFeynman-Kac粒子近似モデルと関連づけることである．すると，系統木モデルの占有測度が，目的の条件付き分布 \\(Y_1,\\cdots,Y_n|X_1,\\cdots,X_n\\) に収束することを示せるのである！また，現在残存している個体の祖先の系列を， \\(Y_1,\\cdots,Y_n|X_1,\\cdots,X_n\\) の経路の近似的に独立なサンプルの集まりと近似的にみなせる．\nこの「うまくいっている個体を複製することで，状態空間を効率的に探索する」というのは，多くの確率的探索アルゴリズムの基本的な態度である．このアイデアは，どうやら1950年代の生物学での Rosenbluth の貢献と，物理学の Kahn and Harris の貢献とに端を発するようである．\n一般の距離空間上のFeynman-Kacモデルと粒子法の研究は，Del Moralに20世紀の終わりから21世紀の初めにかけて行われた．この手法の応用は大きく広がっており，Doucet (2001) では多くの応用が紹介されているが，これは物理学・数学的な側面から離陸しつつあることは残念なことである．\nこれらの発展は全て，古典的な遺伝的アルゴリズムのトピックと深く強い関連を持つ．遺伝的アルゴリズムは Holland (1975) によって始められ，それ以降大域的最適化の数値解法に広く用いられている．このアルゴリズムの収束解析は R. Cerf によって1994年から始められ， Del Moral and Miclo (1999) On the Convergence and Applications of the Generalized Simulated Annealing で洗練された．大偏差解析と対数ソボレフ不等式を取り入れた半群の方法によって，遺伝的アルゴリズムの集中性が示された．"
  },
  {
    "objectID": "posts/2023/2023-11-8/index.html#footnotes",
    "href": "posts/2023/2023-11-8/index.html#footnotes",
    "title": "書籍紹介 Del Moral (2004) Feynman-Kac Formulae",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFeynman Lecturesの第1章第2節で，「現代科学最大の発見を1つ挙げるとすると原子論だ」と言っている．粒子法によるモデリングは，人間が理解しやすいモデリングの究極形の1つであるかもしれない．↩︎"
  },
  {
    "objectID": "posts/2023/2023-10-29/index.html",
    "href": "posts/2023/2023-10-29/index.html",
    "title": "Serotonin Reduction in Post-acute Sequelae of Viral Infection | ウイルスの腸管持続感染によって血中セロトニン濃度が低下する",
    "section": "",
    "text": "Wong+ (2023) Serotonin reduction in post-acute sequelae of viral infection\n\n\n\n\nimg\n\n\nに衝撃の事実が書かれていました．アブストラクトのみから内容を概略すると，\n\nウイルスが腸管で持続的な感染を起こした場合は、トリプトファンの吸収が免疫活動により阻害されるようで、血液内のセロトニンが減少し、その状態が急性症状が落ち着いた後も戻らず、末梢の迷走神経に機能障害を起こし、認知機能への障害を自覚症状とするブレインフォッグを催す、という作用機序を示唆するデータを示している。ただし全てマウスでのデータ。\nブレインフォッグにSSRI（抗うつ剤だがパニック障害などにも適応あり）やトリプトファンサプリが有効であることを実証。\n以上の機序はあらゆるウイルスによる腸炎で起こるはずだが、SARS-Cov2は腸管感染と腸への持続感染を特に起こしやすく、社会問題化しやすかったという背景がある。\n\n現実とは，一体なんと複雑なのでしょうか．しかし，その一端を掴みつつあることが，とても喜ばしく感じます．\n筆者は過去に家庭教師先の教え子が，コロナウイルスワクチンの接種を機に深刻なブレインフォッグを催し，大学受験を１年遅らせる決断に至るまでを見届けたことがあります．当時はどう調べようにも，情報が限られていました．\nそこから約２年が経ち，その病理に始まり，「コロナに限らないということ」「ブレインフォッグも治るということ」が判ったのは大きな進歩だと感じられます．\nブレインフォッグに限らず，自律神経様の症状（めまいがする，眠れない，集中できない，頭がぼうっとする）は，多くの神経的疾患に付随する症状で，原因特定が難しく（病の原因と思われがちだが結果の場合が多い），周りからの理解が得にくいことが多いです．\nそれぞれの症例に対して，上述のような生理学的な要因が明らかになり，必ずしも心因性ではないこと（ましてや「気のせい」や「病は気から」などとんでもないこと）が周知されることは，このような現代特有の病気をも，現代が再包摂する第一歩になると感じます．"
  },
  {
    "objectID": "posts/2023/2023-12-1/BookRecommendation.html",
    "href": "posts/2023/2023-12-1/BookRecommendation.html",
    "title": "Influential Books Which Paved My Path into Mathematics",
    "section": "",
    "text": "I am currently a Ph.D. candidate specializing in Bayesian Computation. I pursued my studies in Mathematics at the University of Tokyo, where I laid a solid foundation to study Statistical Inference for Stochastic Processes, a field renowned for its rigorous and mathematically demanding nature.\nInitially, I had not planed to major in Mathemacis when I embarked on my freshman year with a curious mind.1 However, it was the faculty of the Mathematics Department at the university, along with the books listed below, that awakened my intrinsic interest in Mathematics. In the remainder of this article, I will explore how these books inspired me and molded my style."
  },
  {
    "objectID": "posts/2023/2023-12-1/BookRecommendation.html#footnotes",
    "href": "posts/2023/2023-12-1/BookRecommendation.html#footnotes",
    "title": "Influential Books Which Paved My Path into Mathematics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAt the University of Tokyo, students don’t choose their major until the middle of their sophomore year. In June of the second year, they submit their preferences and the department they will advance to is determined based on their GPA ranking.↩︎\nSome readers might question how a truly new set can be defined, given that the two allowed methods appear quite restrictive. However, this issue is addressed by the axiom that guarantees the existence of the power set \\(P(X)\\) from any existing set \\(X\\). Additionally, it might be helpful to note that the only initial set is the empty set \\(\\emptyset\\). From this, we can generate an infinite hierarchy of power sets starting with \\(\\emptyset\\), accompanied by enormous auxiliary sets constructed in the two aforementioned manners.↩︎\nAs some readers might guess this, the majority of attendees were actually 3rd and 4th-year math students. We sophomores lacked even basic tools from Topology. Surprisingly, my first introduction to topological concepts was through Sheaf Theory.↩︎\nTake, for instance, the theory of Markov Categories, which offers a dual perspective on Probability Theory.↩︎"
  },
  {
    "objectID": "posts/2023/2023-12-6/法律家のための統計数理2.html",
    "href": "posts/2023/2023-12-6/法律家のための統計数理2.html",
    "title": "法律家のための統計数理（2）第1章第2-4節",
    "section": "",
    "text": "$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$"
  },
  {
    "objectID": "posts/2023/2023-12-6/法律家のための統計数理2.html#今回の内容",
    "href": "posts/2023/2023-12-6/法律家のための統計数理2.html#今回の内容",
    "title": "法律家のための統計数理（2）第1章第2-4節",
    "section": "1 今回の内容",
    "text": "1 今回の内容\n第一審の裁判において，事実認定が中心的な問題である．この際に起き得る誤謬を，ベイズの方法を用いてどう回避できるか？という例が３つ挙げられている．\n\n1.1 主観確率の基本的な計算方法と捜査官の誤謬\n\n\n\n\n\n\n問題1-1\n\n\n\n殺人事件の加害者はAとBのどちらか？利用可能な情報は次のみ：被疑者のA, Bは同居しており，そのうちどちらかが加害者であることはわかっているものとする．\n\n台所に左利きの包丁があった．Aが左利きである確率はいくらか？ただし，人間が左利きである確率は1割とする．\nAは左利きであること，被害者の外傷の部位や凶器の形状から加害者も左利きであったことは確定的であるとする．Aに逮捕令状を出しても良いだろうか？ただし，利き手の情報を除けば，AかBかは完全に五分五分であるとする．なお，共犯はなく，どちらか一方の単独犯であることも確実であるとする．\n\n\n\n\n\n\n\n\n\n結論\n\n\n\n\nAもBも左利きである可能性があるため，5割より少し大きい．\nAもBも左利きである可能性があるため，9割強である．95%を一つの基準にするなら，逮捕令状は出すべきではない．\n\n\n\nこの問題のポイントは「条件付き確率」への理解である．\n\n\n\n\n\n\n論証\n\n\n\n\n事象を \\[\nA:=\\left\\{\\text{Aは左利きである}\\right\\}\n\\] \\[\nB:=\\left\\{\\text{Bは左利きである}\\right\\}\n\\] と定めると， \\[\n\\begin{align*}\n&\\quad\\;\\mathrm{P}[A\\cup B]\\\\\n&=\\mathrm{P}[A]+\\mathrm{P}[B]-\\mathrm{P}[A\\cap B]\\\\\n&=\\frac{19}{100}\n\\end{align*}\n\\] これより，条件付き確率の定義から \\[\n\\begin{align*}\n\\mathrm{P}[A|A\\cup B]&=\\frac{\\mathrm{P}[A]}{\\mathrm{P}[A\\cup B]}\\\\\n&=\\frac{10}{19}\\approx52.6\\%\n\\end{align*}\n\\]\n\n\n\n今回の肝は，事象 \\(A,B,C\\) を互いに独立に設定したために，各積事象 \\(A\\cap B,B\\cap C,C\\cap A\\) が悉く計算可能なものとして得られた，という点である．これを計算しておけば，欲しい値がこれらの言葉で得られているから，答えまで一本道で辿り着ける，という訳である．\n\n\n\n\n\n\nMonty Hall問題\n\n\n\nモンティ・ホール問題 も条件付けを正しく行えない（「何が分母か」を分別せず，違う次元の話を混同する）ことによって起こるパラドックスの有名な例である．\n\n\n\n\n\n\n\n\nまとめ\n\n\n\n「捜査官の誤謬」は「条件付け」を正しく行わないことにより起こる誤謬である．これを回避するには，独立な事象 \\(A,B\\) を抽出し，これらの確率を計算し，最終的に求めたい確率が何かを正しく特定することが重要である．\n\n\n\n\n1.2 ベイズの公式と検察官の誤謬\n\n\n\n\n\n\n問題1-2\n\n\n\nドーピング検査の結果から，ある日本選手Iが金メダルを剥奪された．弁護人としては，どのような弁護の筋があるか？\n\n本ドーピング検査において，禁止薬物をを用いていない人に対して陽性の結果が出る（偽陽性）確率は1%で，逆の偽陰性も1%である．\n日本選手で，禁止薬物を用いている割合は0.1%とする．当該日本選手Iもこの割合に従うものとする（とりわけ禁止薬物を使っていそうな理由・いそうでない理由はないものとする）．\n\n\n\n各事象を \\[\nA:=\\left\\{\\text{ I は薬物を使用していた}\\right\\}\n\\] \\[\nE:=\\left\\{\\text{ I に陽性反応が出た}\\right\\}\n\\] と設定する．今回は \\(A,E\\) は独立ではないことに注意．例えば，後からわかることだが， \\[\\mathrm{P}[A\\cap E]\\ne\\mathrm{P}[A]\\mathrm{P}[E]\\] である．ここで，条件付き確率の計算の問題に分け入ることになる．今回与えられている条件はそれぞれ，\n\\[\n\\begin{align*}\n\\text{1.}&\\qquad\\mathrm{P}[\\overline{E}|A]=\\frac{1}{100},\\\\\n&\\qquad\\mathrm{P}[E|\\overline{A}]=\\frac{1}{100}\\\\\n\\text{2.}&\\qquad\\mathrm{P}[A]=\\frac{1}{1000}\n\\end{align*}\n\\]\nと表現できており，知りたい値は，今現在Iが本当に薬を使っていたという確率 \\(\\mathrm{P}[A|E]\\) である．\n実は，これは全く大きな値ではない！これは，そもそも薬物を使っている人が少なく，健常な人の方が大多数であるために，検査で陽性が出たからといってそれが本当に薬物を使っている人から出た「真の陽性」である確率が極めて小さくなってしまうという普遍的な現象である．\n\n\n\n\n\n\n証明\n\n\n\n求めたい量 \\(\\mathrm{P}[A|E]\\) は \\[\n\\begin{align*}\n&\\quad\\;\\mathrm{P}[A|E]\\\\\n&=\\frac{\\mathrm{P}[A\\cap E]}{\\mathrm{P}[E]}\\\\\n&\\overset{\\text{(2)}}{=}\\frac{\\mathrm{P}[E|A]\\mathrm{P}[A]}{\\mathrm{P}[E]}\\\\\n&\\overset{\\text{(3)}}{=}\\frac{\\mathrm{P}[E|A]\\mathrm{P}[A]}{\\mathrm{P}[E|A]\\mathrm{P}[A]+\\mathrm{P}[E|\\overline{A}]\\mathrm{P}[\\overline{A}]}\n\\end{align*}\n\\tag{1}\\] と式変形できる．この右辺は，全て既知の値で表現できている．\nなお，途中の式変形については，条件付き確率の定義から\n\\[\n\\mathrm{P}[A\\cap E]=\\mathrm{P}[E|A]\\mathrm{P}[A]\n\\tag{2}\\]\nと，全確率の法則\n\\[\n\\begin{align*}\n&\\quad\\;\\mathrm{P}[E|A]\\mathrm{P}[A]+\\mathrm{P}[E|\\overline{A}]\\mathrm{P}[\\overline{A}]\\\\\n&=\\frac{\\mathrm{P}[E\\cap A]}{\\mathrm{P}[A]}\\mathrm{P}[A]\\\\\n&\\qquad\\qquad+\\frac{\\mathrm{P}[E\\cap\\overline{A}]}{\\mathrm{P}[\\overline{A}]}\\mathrm{P}[\\overline{A}]\\\\\n&=\\mathrm{P}[E\\cap A]+\\mathrm{P}[E\\cap\\overline{A}]\\\\\n&=\\mathrm{P}[E]\n\\end{align*}\n\\tag{3}\\] とを用いた．\n\n\n実際に計算してみると， \\[\n\\mathrm{P}[A|E]=\\frac{99}{1098}\\approx9.0\\%.\n\\] 選手Iは実際は薬を使っていない可能性の方がよっぽど高いのである．\n\n\n\n\n\n\nBase rate fallacy\n\n\n\nこの検察官の誤謬は，特に不良品検出の文脈では深刻なバイアスになり，英語では基準確率の誤謬ともいう．1\n\\(n\\) 人の母集団に，ある病気の検査を行うとしよう． \\[\\begin{cases}A_i:=\\left\\{i\\text{は有病}\\right\\},\\\\B_i:=\\left\\{i\\text{は陽性}\\right\\}.\\end{cases}\\quad i\\in[n].\\] としたとき，\n\n\\(\\alpha:=P[B_i|A_i^\\complement]\\) を偽陽率・危険度という．検定一般に言う，第一種の過誤率である．\n患者が有病であるときに陽性が出る確率 \\(1-\\alpha\\) の値を 感度(sensiticity)という．\n\\(\\beta:=P[B_i^\\complement|A_i]\\) を偽陰率という．検定一般に言う，第二種の過誤率である．\n患者が無病であるときに陰性が出る確率 \\(1-\\beta\\) の値を特異度(specificity)という．2 検定一般に言う検出力(power)である．\n\n統計的検定では第一種の過誤率を重く見て，これを制限した上での第二種の過誤率の低さを指標とする．このために「検出力」が重要．一方で失病検査の際は第一種の過誤率が大変重要であり，これに「感度」という名前がついている．\nこのような一般的な設定の下で，陽性の結果を見て，患者の有病率を \\(1-\\beta\\) だと結論づけてしまう誤謬を基準確率の誤謬という．"
  },
  {
    "objectID": "posts/2023/2023-12-6/法律家のための統計数理2.html#ベイズ統計学",
    "href": "posts/2023/2023-12-6/法律家のための統計数理2.html#ベイズ統計学",
    "title": "法律家のための統計数理（2）第1章第2-4節",
    "section": "2 ベイズ統計学",
    "text": "2 ベイズ統計学\n\n2.1 ベイズの公式\n節 1.2 で使った式変形 式 1 の最左辺と最右辺のみに注目して公式化すると，次のようになる： \nこれを（分割 \\(\\Omega=A\\sqcup\\overline{A}\\) に関する）Bayesの公式という．\nこれは独立性の特徴付け \\[\n\\mathrm{P}[A|E]=\\mathrm{P}[A],\\quad\\mathrm{P}[E|A]=\\mathrm{P}[E]\n\\] の一般化になっているともみれる．\n\n\n2.2 ベイズ統計学\n事前に確率 \\(\\mathrm{P}[A]\\) を想定しておく．そして，\\(A\\) に関連する観測の結果 \\(\\mathrm{P}[E|A]\\) を見てから，ベイズの公式を通じて \\(\\mathrm{P}[A|E]\\) を計算し，事象 \\(A\\) に関する理解を深める営みが，ベイズ統計学の雛形である．\nこの \\(\\mathrm{P}[A]\\) を事前確率，\\(\\mathrm{P}[A|E]\\) を事後確率という．\n\n事象 \\(A\\) として何を選んでも良い．\n事前情報 \\(\\mathrm{P}[A]\\) を推論に取り込む余地がある．\n\\(A\\) と \\(E\\) に対して多様な関係を想定できる．\n\\(\\mathrm{P}[A|E]\\) は一般にグラフの形で与えられるので，（他の統計手法と比べて）情報量が多い．\nベイズの公式が全てであり，何をやっているかがわかりやすい．\n\n点がよくベイズ統計学の美点として挙げられる．\n\n\n2.3 ベイズ計算\n前節で解説した通り，ベイズ統計学はベイズの公式が全てであり，原理的には極めて明快である．では，何が難しいかというと，一般的な形のベイズの公式 \\[\np(\\theta|x)=\\frac{p(x|\\theta)p(\\theta)}{\\int_\\Theta p(x|\\theta)p(\\theta)\\,d\\theta}\n\\] は，最も単純な場合でも，計算が不可能であるという点である．積分は現代では高校で習う数学の範囲であるが，実際に計算できる積分など応用の現場では都合よく出てこないのである．\n従って，ベイズ統計学の研究において，計算手法の研究が極めて重要な位置を占める．この分野をベイズ計算というのである．詳しくは ベイズ計算とは何か の記事を参照してほしい．"
  },
  {
    "objectID": "posts/2023/2023-12-6/法律家のための統計数理2.html#footnotes",
    "href": "posts/2023/2023-12-6/法律家のための統計数理2.html#footnotes",
    "title": "法律家のための統計数理（2）第1章第2-4節",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(Arias-Castro, 2022) と (Agresti, 2012, pp. 第2.1.3節 p.39) も参照．↩︎\n(Yerushalmy, 1947) ↩︎"
  },
  {
    "objectID": "posts/2023/2023-11-6/index.html",
    "href": "posts/2023/2023-11-6/index.html",
    "title": "粒子によるビジネスモデルのモデル",
    "section": "",
    "text": "要は僕の専門分野である訳だが，これが今回のビジネスモデルの「骨格」の部分になる．\n状態空間モデル1とは，\n\n状態変数と言われる観測不可能だが興味深い量\\(X_t\\)と，観測変数\\(Y_t\\)の組からなる確率過程\\(\\{(X_t,Y_t)\\}_{t=1}^T\\)のこと．\n\\(Y_t\\)から\\(X_t\\)を推定することを考える（フィルタリング問題2という）．\n次の依存関係を仮定する：\n\n\\(\\{X_t\\}\\)はMarkov過程で，その遷移の仕方\\(X_{t+1}|X_{t}\\)にモデルを立てる．\n観測のモデル\\(Y_t|X_t\\)を立てる． 図で表すと次のような状態である：\n\n\n\n\n\n状態空間モデルで仮定する依存関係の図示\n\n\nこの状態空間モデルのフィルタリング問題を解いて，観測\\(Y_1=y_1,\\cdots,Y_t=y_t\\)から\\(X_t\\)の推定値を得るための方法（アルゴリズム）は多く知られているが，モデル\\(X_{t+1}|X_t,Y_t|X_t\\)が複雑で尤度が明示的な表示を持たない場合でも通用する手法は粒子フィルターのみである．3\n粒子フィルターは，\\(X_t\\)の観測\\(Y_t\\)に関する事後分布を\\(N\\)個の（大量の）粒子によって近似するBayes推定手法で，各\\(Y_t\\)の尤度の情報を重点リサンプリングによって取り入れながらも，計算コスト低く\\(X_t\\)の事後分布を逐次近似していく．\n\n\n\n要は，\\(Y_t\\)を安価に集めて，\\(X_t\\)を高値で売ることを考える．本当にこれをビジネスにするためには，\n\n\\(X_t\\)は多くの人がリアルタイムに知りたいが，（少なくともリアルタイムには）知れない\n\\(Y_t\\)をたくさん集めれば\\(X_t\\)を推測できるが，簡単にはできない（さもなくばレッドオーシャンになってしまうので）\n\nを満たす必要がある．が，意外とこのようなものは多いかも知れない．我々の売りは\n\n\n\n\n\n\n今回のビジネスモデルのコア\n\n\n\nどんなに推定しにくい\\(X_t\\)でも（モデルが複雑で尤度が解析的な表示を持たなくても），十分な情報を含む観測データ\\(Y_t\\)が得られれば，逐次推定できる．\n\n\nということになる．\n\n\n\n最も示唆的と思われる例は，\\(X_t\\)としてGDP，商業販売額などのマクロ指標を取った場合だと思われる．\nマクロ指標は，各企業単体では推測できず，たとえ業界を絞っても各企業の売り上げデータやATM取引データなど，多くのデータを集めて高次元な\\(Y_t\\)を構成しなければ，信頼できる\\(X_t\\)の推定はできないだろう．高次元な\\(Y_t\\)から\\(X_t\\)をフィルタリング際の粒子法は安定せず，現在でも解決されていないオープンクエスチョンである．必然的にブルーオーシャンで誰も参入できない．\nさらに，マクロ指標はフィルタリングすること＝今現在の値を知ることに意味がある．理論的な障壁や技術的な障壁は高いが，経営判断に使ったり，投資判断に使ったり，需要は大きいと思われる．\n\n\n\n以上，例を先に挙げたが，これは「ビジネスモデルの種」になっていて\n\n\\(X_t\\)として需要のある指標・数値\n\\(Y_t\\)として，\\(X_t\\)を推定するのに使える，観測可能＝お金を払えばリアルタイムで手に入る情報\n\\(Y_t|X_t\\)と\\(X_{t+1}|X_t\\)のモデルを立てるためのドメイン知識\n\nが手に入れば，すぐに１つのビジネスモデルになる．\nこれが実はあまりたくさん思いつく訳ではないから，皆さんのアイデアが欲しい．ちなみに，\\(X_t\\)が天気というのがよくあるが，これは民間でやる必要はないし，お金にならないし，\\(Y_t\\)を得るコストが高い気がする．\n個人的には，\\(X_t\\)は個人の体調スコア（あるいは特定の病気のリスク）で，\\(Y_t\\)がApple Watchなどのスマートデバイスからの心拍や体温や移動距離などの測定データ，という属人化医療の場面設定をよく考えるが，粒子フィルタを使うまででもない気がして，AppleやFitBitにそのアルゴリズムを買ってもらえるかというと疑念しかない．\nさらに，\\(Y_t\\)はデータとして広く流通しているわけではないならば（ATM利用データなど），技術力だけでなく，「信頼を得てデータを提供してもらっている」ことが我々の競争力に加わっていき，市場で不動の地位を占めやすいだろう．"
  },
  {
    "objectID": "posts/2023/2023-11-6/index.html#粒子ビジネスモデルモデルの概要",
    "href": "posts/2023/2023-11-6/index.html#粒子ビジネスモデルモデルの概要",
    "title": "粒子によるビジネスモデルのモデル",
    "section": "",
    "text": "要は僕の専門分野である訳だが，これが今回のビジネスモデルの「骨格」の部分になる．\n状態空間モデル1とは，\n\n状態変数と言われる観測不可能だが興味深い量\\(X_t\\)と，観測変数\\(Y_t\\)の組からなる確率過程\\(\\{(X_t,Y_t)\\}_{t=1}^T\\)のこと．\n\\(Y_t\\)から\\(X_t\\)を推定することを考える（フィルタリング問題2という）．\n次の依存関係を仮定する：\n\n\\(\\{X_t\\}\\)はMarkov過程で，その遷移の仕方\\(X_{t+1}|X_{t}\\)にモデルを立てる．\n観測のモデル\\(Y_t|X_t\\)を立てる． 図で表すと次のような状態である：\n\n\n\n\n\n状態空間モデルで仮定する依存関係の図示\n\n\nこの状態空間モデルのフィルタリング問題を解いて，観測\\(Y_1=y_1,\\cdots,Y_t=y_t\\)から\\(X_t\\)の推定値を得るための方法（アルゴリズム）は多く知られているが，モデル\\(X_{t+1}|X_t,Y_t|X_t\\)が複雑で尤度が明示的な表示を持たない場合でも通用する手法は粒子フィルターのみである．3\n粒子フィルターは，\\(X_t\\)の観測\\(Y_t\\)に関する事後分布を\\(N\\)個の（大量の）粒子によって近似するBayes推定手法で，各\\(Y_t\\)の尤度の情報を重点リサンプリングによって取り入れながらも，計算コスト低く\\(X_t\\)の事後分布を逐次近似していく．\n\n\n\n要は，\\(Y_t\\)を安価に集めて，\\(X_t\\)を高値で売ることを考える．本当にこれをビジネスにするためには，\n\n\\(X_t\\)は多くの人がリアルタイムに知りたいが，（少なくともリアルタイムには）知れない\n\\(Y_t\\)をたくさん集めれば\\(X_t\\)を推測できるが，簡単にはできない（さもなくばレッドオーシャンになってしまうので）\n\nを満たす必要がある．が，意外とこのようなものは多いかも知れない．我々の売りは\n\n\n\n\n\n\n今回のビジネスモデルのコア\n\n\n\nどんなに推定しにくい\\(X_t\\)でも（モデルが複雑で尤度が解析的な表示を持たなくても），十分な情報を含む観測データ\\(Y_t\\)が得られれば，逐次推定できる．\n\n\nということになる．\n\n\n\n最も示唆的と思われる例は，\\(X_t\\)としてGDP，商業販売額などのマクロ指標を取った場合だと思われる．\nマクロ指標は，各企業単体では推測できず，たとえ業界を絞っても各企業の売り上げデータやATM取引データなど，多くのデータを集めて高次元な\\(Y_t\\)を構成しなければ，信頼できる\\(X_t\\)の推定はできないだろう．高次元な\\(Y_t\\)から\\(X_t\\)をフィルタリング際の粒子法は安定せず，現在でも解決されていないオープンクエスチョンである．必然的にブルーオーシャンで誰も参入できない．\nさらに，マクロ指標はフィルタリングすること＝今現在の値を知ることに意味がある．理論的な障壁や技術的な障壁は高いが，経営判断に使ったり，投資判断に使ったり，需要は大きいと思われる．\n\n\n\n以上，例を先に挙げたが，これは「ビジネスモデルの種」になっていて\n\n\\(X_t\\)として需要のある指標・数値\n\\(Y_t\\)として，\\(X_t\\)を推定するのに使える，観測可能＝お金を払えばリアルタイムで手に入る情報\n\\(Y_t|X_t\\)と\\(X_{t+1}|X_t\\)のモデルを立てるためのドメイン知識\n\nが手に入れば，すぐに１つのビジネスモデルになる．\nこれが実はあまりたくさん思いつく訳ではないから，皆さんのアイデアが欲しい．ちなみに，\\(X_t\\)が天気というのがよくあるが，これは民間でやる必要はないし，お金にならないし，\\(Y_t\\)を得るコストが高い気がする．\n個人的には，\\(X_t\\)は個人の体調スコア（あるいは特定の病気のリスク）で，\\(Y_t\\)がApple Watchなどのスマートデバイスからの心拍や体温や移動距離などの測定データ，という属人化医療の場面設定をよく考えるが，粒子フィルタを使うまででもない気がして，AppleやFitBitにそのアルゴリズムを買ってもらえるかというと疑念しかない．\nさらに，\\(Y_t\\)はデータとして広く流通しているわけではないならば（ATM利用データなど），技術力だけでなく，「信頼を得てデータを提供してもらっている」ことが我々の競争力に加わっていき，市場で不動の地位を占めやすいだろう．"
  },
  {
    "objectID": "posts/2023/2023-11-6/index.html#todo",
    "href": "posts/2023/2023-11-6/index.html#todo",
    "title": "粒子によるビジネスモデルのモデル",
    "section": "2 ToDo",
    "text": "2 ToDo\nまとめると，僕が提供できるものは高次元・大規模状態空間モデルでの粒子フィルターの研究開発力．これは前節で語ったような「\\(Y_t\\)を集めて\\(X_t\\)を売る」ビジネスモデルを示唆する．\n足りないものは研究成果と実装する時間と仲間と交渉力である．その代わり初期投資は極めて少なくて済む．\n\n2.1 情報収集\n元々は星野研究室の次の研究を知って，新里さんに紹介したときに得た着想であった．\nCard\n「ナウキャスト」「オルタナティブデータを活用した経済分析」と言った言葉でビジネス界で議論されているようだ．特に「ナウキャスト」という名前の会社はこの分野を開拓している．\nナウキャストとエム・データ、機関投資家向けオルタナティブデータ活用で協業\nオルタナティブデータを用いた経済活動分析\n当然粒子法は用いているまい．まずはナウキャストについて知るべし．\n\n\n2.2 懸念\n\n\\(Y_t\\) が高次元と言っても，モデル \\(Y_t|X_t\\) が正確に立てられないのではないか？"
  },
  {
    "objectID": "posts/2023/2023-11-6/index.html#footnotes",
    "href": "posts/2023/2023-11-6/index.html#footnotes",
    "title": "粒子によるビジネスモデルのモデル",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n隠れMarkovモデルともいうが，こう言ったときは状態空間が有限集合であるという制約が暗につく．↩︎\n一方で\\(Y_t\\)から，未来の値\\(Y_{t+1}\\)を予測する問題を「予測問題，\\(Y_{1},\\cdots,Y_t\\)から，過去の状態変数の値\\(X_{s}\\;(s&lt;t)\\)を推定する問題を「平滑化問題」という．↩︎\n\\(Y_t|X_t,X_{t+1}|X_t\\)のいずれも線型Gaussなモデルを仮定した場合は，Kalman filterというもっと効率の良い安価なアルゴリズムが使える．↩︎"
  },
  {
    "objectID": "posts/2023/2023-11-9/index.html",
    "href": "posts/2023/2023-11-9/index.html",
    "title": "書籍紹介 Del Moral (2013) Mean field simulation for Monte Carlo integration",
    "section": "",
    "text": "book cover"
  },
  {
    "objectID": "posts/2023/2023-11-9/index.html#書籍紹介-del-moral-2013-mean-field-simulation-for-monte-carlo-integration",
    "href": "posts/2023/2023-11-9/index.html#書籍紹介-del-moral-2013-mean-field-simulation-for-monte-carlo-integration",
    "title": "書籍紹介 Del Moral (2013) Mean field simulation for Monte Carlo integration",
    "section": "書籍紹介 Del Moral (2013) Mean field simulation for Monte Carlo integration",
    "text": "書籍紹介 Del Moral (2013) Mean field simulation for Monte Carlo integration\nリンクの在処は分かりにくいですが，前文と一部の内容が著者のHPからご覧になれます．\nMean Field Simulation for Monte Carlo Integration | Pierre Del Moral |\n「平均場粒子モデルは非線型発展方程式を確率的に線型化する技法である」とはどういうことか？前文を読むだけでストーリーがあらかた掴めます（が長いです）．"
  },
  {
    "objectID": "posts/2023/2023-11-9/index.html#preface",
    "href": "posts/2023/2023-11-9/index.html#preface",
    "title": "書籍紹介 Del Moral (2013) Mean field simulation for Monte Carlo integration",
    "section": "Preface",
    "text": "Preface\n\nMonte Carlo Integration\n本書は平均場シミュレーションモデルのモンテカルロ積分への応用と理論的基礎を扱う．\nここ30年，このトピックが純粋・応用確率論，ベイズ推論，統計的機械学習，情報理論，理論化学，量子物理，金融数学，信号処理，リスク解析，工学，計算機科学の，最も活発な接点の1つとなっている．\nモンテカルロシミュレーションの源は， Metropolis and Ulam (1949) The Monte Carlo Method であり，MetropolisがUlamのポーカー付きから，モナコの首都にちなんで名付けた．\nモンテカルロ積分の最初の応用はロスアラモス国立研究所でのManhattan計画にて，原子爆弾着火のモデルにおいてSchödinger作用素の基底状態のエネルギーを計算するために用いられたものだ．\nMonte Carlo積分の理論，MCMCとSMC，そして平均場IPS (Interacting Particle Systems)とは，いずれも複雑な確率分布からサンプリングするために用いられる．この文脈では，ランダムサンプルは積分の計算のために用いられる．他の状況で，確率的なアルゴリズムは，逆問題，大域的最適化，事後分布計算，非線形推定問題，統計的学習問題など，複雑な推定問題を解くのにも使われる．\n最も有名なMCMCアルゴリズムはMetropolis-Hastings法だろう． Metropolis and Ulam (1949) The Monte Carlo Method によると，\n\nthe Monte Carlo method is, “essentially, a statistical approach to the study of differential equations, or more generally, of integro-differential equations that occur in various branches of the natural sciences.”\n\nまさにそういうように，「確率測度の空間上の任意の発展モデルは，いつでもMarkov過程のランダムな状態の分布だと解釈できる」ことを強調しておきたい．この観察は，Markov過程と関連する線型発展モデルとの研究ではよく知られていることである．\nさらに面白いことには，Markov過程のランダムな状態の分布と，非線形に相互作用することを許すならば，非線型な発展モデルもMarkov過程の分布とみれる．そのMarkov連鎖のランダムな状態は複雑な確率分布のフローに従い，しばしば解析的な解が存在しない（計算不可能）であることもある．この文脈で，Monte Carlo法と平均場法は，このような複雑系をシミュレーションしたり分析するにあたって，シンプルで安価な方法を提供してくれる．\nこの2点の観察が，本書で展開される平均場粒子理論の大事な到達点である．\n\n\nMean Field Simulation\n平均場IPSの研究は1960年代の Henry McKean の流体力学における非線型楕円型偏微分方程式のMarkov解釈の研究から始まった．\nこの初期の研究から1990年代の半ばにかけて，複数の研究者がこの分野を開拓した．主な内容は非線型Markov連鎖モデルの存在に関連するマルチンゲール問題を解く問題，連続時間IPSモデル（McKean-Vlasov拡散，反応拡散方程式，Boltzmann型相関ジャンプ過程など）のカオスの伝播の記述などであった．古典的な応用は基本的に流体力学，化学，凝縮系物理に制限されていた．\nしかし1990年代の中盤から，平均場IPS手法を，情報理論，工学，計算物理学，統計的機械学習理論におけるMonte Carloシミュレーションへの応用が爆発した．この洗練された，個体群タイプのIPSアルゴリズムは，並列化や分散化された計算環境にも向いていた．その結果，ここ数年来，安価な計算資源の普及に後押しされて，これらの計算機集約的なツールは大きく知名度を上げた．この発展的なMonte Carlo積分法は，決定論的な関数射影アルゴリズムやグリッドを用いるアルゴリズムが低次元空間における線型モデルにしか使えない弱みを補完する手法を提供している．\n古典的なMCMC法と違って，平均場IPS法の大きな美点は，正確性を司るパラメータは，何か固定された目的分布とも，予備動作時間とも関係なく，ただ粒子数 \\(N\\) のみに依存する，という点である．つまり，IPS算譜を動かす計算機の並列計算力などのみに依存して，正確性を発揮することが出来るということである．\n過去20年，非線型フィルタリング問題や複雑なBayes事後分布を計算したり，遺伝的手法で最適化問題を解いたりする中で，新たなクラスの平均場PISサンプラーが発明された．こうして，古典的な流体力学モデルから，種々の科学分野で見られる様々な非線型問題に，射程を広げつつある．\n非線型フィルタリング問題への応用は，乱流についての流体力学や，天気予報の問題で生じる．最近では空間的点過程への応用が進んでいるが，これは生態系モデリング，生物学，疫学，地震，物質科学，待ち行列理論，天文学など種々の分野で見つかる．\nさらに最近では金融への応用も盛んである．粒子法の稀事象解釈を通じて，信頼のおけるポートフォリオが同時にデフォルトを起こす確率のシミュレーションを行っている研究が Carmona, Fouque and Vestal (2009) にある．\nさらに最近には，ジャンプ拡散過程による価格モデルで，ジャンプ時刻やジャンプサイズなどの潜在変数をフィルタリングする研究もある．粒子法は，確率的最適化アルゴリズムの構築にも使えるが，これも金融数学の分野で応用が進みつつある．これは複数の最小値点が存在する場合でも使える手法として Ben Hamida and Cont (2005) が開拓している．\nさらに分岐するIPSは，直接生物学や自然淘汰理論のモデルとして応用が進んでいる．\nこの文脈で，平均場ゲーム理論にも触れねばならないだろう．ここで「流体粒子」に当たるものはエージェント（または会社）とみなされ，ある報酬関数に対して最適な行動を取るように，社会経済的な環境で競争をしていく様子をモデリングする．\nKolokoltsovにより，大量のエージェントを備えるゲーム理論の生物学・経済学・ファイナンスへの応用が進んでいる．平均場ゲームのHamilton-Jacobi非線型方程式を解くための有限差分法の研究も同時に進んでいる．\n\n\nA Need for Inter-diciplinary Research\nこの平均場シミュレーション理論には多くの分野の研究者が参入していることは，その文献の多さが証明している．しかし，これらの異なる分野の間のコミュニケーションは非常に難しいことで，実際まだまだ伸び代がある．実際，平均場Feynman-Kacモデルは多くの別の名前で知られている．\n\nIn physics, engineering sciences, as well as in Bayesian statistical analysis, the same interacting jump mean ﬁeld model is known under several lively buzzwords; to name a few: pruning [403, 549], branching selection [170, 286, 484, 569], rejuvenation [8, 134, 275, 336, 490], condensation [339], look-ahead and pilot exploration resampling [263, 403, 405], Resampled Monte Carlo and RMC methods [556], subset simulation [20, 21, 22, 396, 399], Rao-Blackwellized particle filters [280, 444, 457], spawning [138], cloning [310, 500, 501, 502], go-with-the-winner [7, 310], resampling [324, 522, 408], rejection and weighting [403], survival of the fittest [138], splitting [121, 124, 282], bootstrapping [43, 289, 290, 409], replenish [316, 408], enrichment [54, 336, 262, 374], and many other botanical names.\n\n一方で，多くの応用的な研究が，数学的な側面については盲目に突き進んでいるという現状もある．結果として，多くの応用的な研究で平均場IPSモデルが自然言語的に直感的に提示され，全くパフォーマンス解析もロバスト性や安定性に対する言及もなく使われている．\n逆に数学的な側面の研究についても，多くの未解決問題が存在する．数理統計楽や確率論の研究者は，現在の多くの応用研究で進行中の研究を注視する必要がある．より豊かな応用数学と応用科学のためには，学際的な交流が欠かせないと考える．\nそのためには，統一的な数学的基盤，共通言語というのが欠かせないだろう．この本は，Monte Carlo積分に対する平均場シミュレーションの技術に対して最新の取り扱いを統一的に記述することで，複数の分野を橋渡しするためにある！この本が確率論研究者，応用統計家，生物学者，統計物理学者，計算機科学者が，互いの障壁を乗り越える一助になることを願っている．\n古典的なMonte Carlo法やシミュレーション法本は数え切れないにも拘らず，平均場シミュレーション理論を扱った書籍は少ない．\n本書は Del Moral (2004) と確率論セミナー (2000)，そしてさらに新しいサーベイ (2012) の続編とみなすことができる．本書は，Feynmna-Kacモデルだけでなく，McKean-Vlasovモデルや分岐相関ジャンプ過程などの種々のIPSアルゴリズムに応用可能な平均場理論も提供する．\n\n\nUse and Interpretations of Mean Field Models\n特に強調したいことは，本書で扱うほとんどの平均場IPSアルゴリズムは数学的には全く等価であり，ただ解釈の仕方が，その応用分野に依って異なるのみである．\n流体力学と計算物理学において，平均場粒子モデルはマクロ物理量がミクロ変数の分布と相互作用しながら発展していく系のモデルになる．例えば期待，マクロ流体モデルや，分子系である．中心的なアイデアは，2次の摂動項を無視することで，分布の空間上の閉じた非線型発展方程式に還元することである．このモデルの平均場極限は，（多くの場合微分／積分方程式の言葉で）物理量の発展を記述する．\n計算生物学や個体群動態学では，生誕・死亡や競争選択の過程によって，平均場遺伝的粒子モデルが構成される．このモデルの平均場極限はしばしば「無限人口モデル (infinite population model)」と呼ばれる．\n計算機科学では，平均場遺伝的IPSアルゴリズムは複雑な最適化問題を解くための確率的探索手法として使われる．この場合のモデルの平均場極限は，ある種の適合度を表すポテンシャル関数に付随するBoltzmann-Gibbs測度によって与えられる．\n信号処理と機械学習理論において，平均場IPSモデルは逐次Monte Carloサンプラーとも呼ばれる．名前の通り，このモデルは，複雑性が増していく確率分布の列から逐次的にサンプリングをするために用いられる．状態空間は，稀事象シミュレーションではexcursion space，逐次重点サンプリングでは遷移状態空間，フィルタリングと平滑化問題では見本道の空間である．信号処理の分野においては，この手法は「粒子フィルター」とも呼ばれる．このモデルにおいて，平均場極限は，ある事象について条件づけた際の確率過程の条件付き分布の発展方程式系になる．線型Gaussモデルにおいて，最適フィルターは，平均と分散がKalmanフィルターによって逐次的に与えられるような条件付きGauss分布になる．この設定において，その発展方程式はMcKean-Vlasov拡散モデルとみなせる！この平均場モデルは，気象予測とデータ同化の分野で用いられているアンサンブルKalmanフィルターに一致するのである．\n物理学と分子化学において，平均場IPS発展モデルは多体Schödinger発展方程式の基底状態のエネルギーの推定に用いられる．この設定において，「粒子」と呼ぶと物理的対象と混同してしまうため，”walker”（探索者）と呼ばれる．この確率的な発展モデルは QMC (Quantum Monte Carlo) または DMC (Diffusion Monte Carlo) 法と呼ばれる．この手法は多体系の状態空間上での経路積分を近似するために設計される．このモデルの平均場極限は正規化されたSchrödinger方程式になる．したがって，このモデルの非線型半群の長期的な振る舞いは，Schrödinger作用素の最大固有値と基底状態のエネルギーに関連を持つのである．\n確率論において，平均場IPSモデルは2通りの解釈を持つ．1つ目の見方として，粒子系は，目的の発展方程式の解を，逐次的に経験測度の空間へ射影しているとみれる．より正確に，平均場IPSモデルの定める経験測度は，この削減された有限次元状態空間上のMarkov過程として発展していく．従来のMCMC法は単一の確率過程の長期的な振る舞いに基づいて設計されていたのと対照的に，平均場IPSのMarkov過程は \\(N\\) 個の状態空間上の積上で発展する．この意味で「平均場粒子モデルは非線型発展方程式を確率的に線型化する技法である」と言える．2つ目の見方は，分布の空間上の非線型発展方程式の新たな確率的摂動論という見方である．粒子の集団の局所的なサンプリングの推移は，現在の粒子の経験測度に依存するので，局所的なサンプリング誤差を系に導入する．粒子はこの摂動を持ちながら非線型発展方程式に従っている，と見れるのである．\n\n\nA Unifying Theoretical Framework\n本書の大半は，「平均場理論の離散世代と分布空間上の非線型発展方程式への応用」を扱う．ほとんどのモデルは，連続時間における測度値過程を，離散時間で近似することで生じる．物理学，金融，生物学分野での連続時間モデルの重要性を鑑みて，本書の多くの部分は離散時間測度値過程とその連続時間の場合（特に線型・非線型微分・積分方程式）との関連も取り扱っている．\n古典的なMCMC法の平衡への収束に関する解析で用いられている数学と，我々が用いる数学とは大きく異なる．加えて，従来のMonte Carloサンプラーと対照的に，平均場IPSモデルは統計的に独立な粒子を取り扱っている訳ではないから，従来の大数の法則の知識を直接適用して相関粒子系によるサンプラーの解析に用いることは出来ない．\n直近に発展した，連続時間の相関粒子系の解析は，「カオスの伝播」という性質と漸近理論に基づいており，エルゴード的な性質や指数集中性については全く判っていなかった．\n筆者の知る限り，離散世代平均場粒子モデル，時間パラメータに対する一様な定量的推定とその非線型フィルタリング問題への応用とについての最初の研究は，Del Moral (1996), Del Moral (1998) である．その後この研究は更なる発展を遂げ，多くの応用を持った．\n離散世代平均場モデルの収束解析を進めるにあたって，次の数学理論を使うことになるだろう：分布空間上の非線型半群，相関を持つ経験過程理論，指数集中不等式，時間上限 \\(T\\) に関する一様収束推定，汎函数揺動定理．さらにこれらの複合を用いることが日常茶飯事である．例えば，一様指数集中不等式は，後ろ向き非線型半群と，分布空間上の1次のTaylor展開， \\(L^m\\)-平均誤差推定，Orliczノルム解析とLaplace近似を用いる．\n時間上限 \\(T\\) の一様定量的 \\(L^m\\)-平均誤差バウンドと一様集中不等式とは，非線型半群の極限的な安定性に関する振る舞いに依存する．このような，平均場粒子モデルの長期的な振る舞いと，測度のフローの極限的な安定性とが関連しているというタイプの結果は新しいものではない．\n離散世代遺伝的粒子モデルの解析は，系統樹モデル，部分的に観測された分岐過程，粒子自由エネルギー，後ろ向きMarkov粒子モデルなど，他の数学モデルとも深い繋がりを持っている．本書の大部分は，半群理論と確率的摂動理論とを組み合わせて，種々の相関粒子系の収束を示す，という議論を抽象的に行う．\nいま，抽象的で一般的な非線型発展方程式の解析で苦しんでいる人の苦悩は，本書を読めば，すぐに解決されるかもしれない．というのも，平均場相関粒子近似は，すぐさまに強力なMonte Carloシミュレーション法を与えるからである．このタイプの叙述も，McKean-Vlasov拡散モデルと，Feynman-Kac分布フローと，空間分岐発展モデルなどとについて行った．\n本書は，現状強力な道具となっているカオスの伝播の性質や，Berry-Esseen定理や，漸近的な大偏差原理については触れない．これらは Del Moral (2004) を参照のこと．\n\n\nA Contents Guide\n本書の中心的なテーマは平均場シミュレーション理論の，分布空間上の非線型発展方程式への応用である．\n初めの第1章と第2章は概観を提供する．この2つの章は読み飛ばすべきではない．\n理論の基礎はMarkov過程である．線型だろうと非線型だろうと，発展方程式の解析においてMarkov過程は中心的な役割を果たす．分布の空間上の発展モデルは常にランダムな状態を持つMarkov過程の分布として解釈できる．この同一視により，Markov過程の理論が，分布値の方程式を，そのMarkov過程からランダムにサンプリングすることで解く方法を示唆する．この抽象的な理論を，種々の応用例で解説しているのが第1章である．\n第2章はMcKean-Vlasov拡散モデル，Feynman-Kacモデルを，種々の応用の中で見ていく．\n第3章はFeynman-Kacモデルを導入し，応用を見る．\n第4章で，Feynman-Kacモデルの4つの等価な解釈を見る．それは分岐過程による解釈とそれが導く遺伝的アルゴリズム(GA)，逐次Monte Carlo法を導く解釈(SMC)，相関を持つMCMCサンプラーを導く解釈(i-MCMC)，そして最後に平均場相関粒子系としての解釈である(IPS)．\n数学的な観点からは，いずれの解釈も全く等価である．しかしながら，それぞれの解釈は異なるアルゴリズムを導く．\nさらに，McKean-Vlasov拡散モデルも，平均場Feynman-Kacモデルと結びつくということを強調しておきたい．この種の平均場IPSフィルタリングモデルは乱流流体力学や気象予測問題における非線型フィルタリング問題を解くのに使われている．\n第5章で，離散世代Feynman-Kacモデルとその連続時間バージョンとの関係を述べる．\n第6章で，\n本書の第II部は，平均場IPS理論を種々の科学分野への応用を扱う．"
  },
  {
    "objectID": "posts/2023/2023-11-10/index.html",
    "href": "posts/2023/2023-11-10/index.html",
    "title": "Pierre Del Moral 著作まとめ",
    "section": "",
    "text": "HPも参照．"
  },
  {
    "objectID": "posts/2023/2023-11-10/index.html#feynman-kac模型についての本",
    "href": "posts/2023/2023-11-10/index.html#feynman-kac模型についての本",
    "title": "Pierre Del Moral 著作まとめ",
    "section": "1 Feynman-Kac模型についての本",
    "text": "1 Feynman-Kac模型についての本\n\n1.1 Del Moral and Penev (2014) Stochastic Processes\n\n\n1.2 Del Moral (2013) Mean Field Simulation for Monte Carlo Integration\n\n\n1.3 Del Moral (2004) Feynman-Kac Formulae\n\n\n1.4 Del Moral and Miclo (2000) in Seminaire de Probabilites XXXIV\nDel Moral and Miclo (2000) Branching and interacting particle systems approximations of feynman-kac formulae with applications to non-linear filtering"
  },
  {
    "objectID": "posts/2023/2023-11-10/index.html#feynman-kac模型についてのレビュー",
    "href": "posts/2023/2023-11-10/index.html#feynman-kac模型についてのレビュー",
    "title": "Pierre Del Moral 著作まとめ",
    "section": "2 Feynman-Kac模型についてのレビュー",
    "text": "2 Feynman-Kac模型についてのレビュー\n\n2.1 Del Moral+ (2012) On the Concentration Properties of Interacting Particle Processes\nDel Moral, P., Hu, P. and Wu, L. (2012) On the Concentration Properties of Interacting Particle Processes. Foundations and Trends in Machine Learning, 3(3-4): 255-389.\nINRIAにもpdfあり．\n\n\n2.2 Del MoralのHP"
  },
  {
    "objectID": "posts/2023/2023-11-10/index.html#その他レビュー",
    "href": "posts/2023/2023-11-10/index.html#その他レビュー",
    "title": "Pierre Del Moral 著作まとめ",
    "section": "3 その他レビュー",
    "text": "3 その他レビュー\n\n3.1 ランダム行列理論： Bishop, Del Moral, and Angele (2018) An Introduction to Wishart Matrix Moments\nBishop, A., Del Moral, P. and Angele, N. (2018) An Introduction to Wishart Matrix Moments. Foundations and Trends in Machine Learning, 11(2): 97-218."
  },
  {
    "objectID": "posts/2023/2023-11-11/MarkovCategory.html",
    "href": "posts/2023/2023-11-11/MarkovCategory.html",
    "title": "Markov Category (nLab) | 紹介",
    "section": "",
    "text": "綜合的確率論(synthetic probability)とは，確率論の定義と定理を，その性質によって特徴づけようとする試みである．確率論が測度論に依拠しているのは「一つの実装例」に過ぎず，より普遍的で自然な定義が見つかるはずだ，というものである．思えば，条件付き期待値がa.s.にしか定まらないこと，多くの正則性条件が成り立つためには空間の可分性が必要であること．確率論には，あまりにも恣意的で非本質的な，「確率論に関係のない議論」が多いとは思わないか？これは，確率というものの数理的な構造を，我々が正しく把握できていないからなのではないか？\n\nThe basic object of study in probability is the random variable and I will argue that it should be treated as a basic construct . . . and it is artificial and unnatural to define it in terms of measure theory. [@Mumford00-DawnOfStochasticity]\n\nこのような精神を持ち，具体的には圏論的な方法で，確率論のもう一つのモデルを構築しようとするのが綜合的確率論(synthetic probability)である．Anders Kock と Lewvereによる綜合的微分幾何学(synthetic differential geometry)からのシリーズを意識した命名であり，数学の各分野を「圏論化」することを，「綜合的」という形容詞で捉えようとしている．\nnLabとは，圏論的な視点から種々の数学・物理学・哲学の概念をまとめた，有志によって運営されているウィキである．今回はMarkov圏のページを翻訳．\n\n\n\nimg\n\n\n\n1．アイデア\nMarkov圏の概念は，確率統計学の綜合的(synthetic)な側面を表現する方法の1つである．すなわち，確率統計学を基礎付ける構造と公理からなり，これを用いて測度論を介することなく直接的に種々の定理が示せる．通常の測度論的な議論は，綜合的確率論のモデル（意味論）の1つであると見なされる．\n直感的に言えば，Markov圏とは射が「確率変数」または「Markov核」（ここから名前がついた）と見なせるような，確率論で用いられる圏である．標準的な例に，Kleisli圏や確率モナドがあるが，Markov圏は更に一般的な枠組みである．\n\n\n2．定義\nMarkov圏とは，半デカルト対称モノイダル圏 \\((C,\\otimes,1)\\) であって，その対象 \\(X\\in C\\) が可換な内部余モノイドの構造を持つものである．余乗法と余単位写像は \\(\\mathrm{copy}:X\\to X\\otimes X\\) と \\(\\mathrm{delete}:X\\to1\\) とそれぞれ表される．\n複製写像とテンソル積の間に次の整合性条件を課す：任意の対象 \\(X,Y\\in C\\) に対して，\n\\[\n\\mathrm{copy}_{X\\otimes Y}=(\\mathrm{id}_X\\otimes b_{Y,X}\\otimes\\mathrm{id}_Y)(\\mathrm{copy}_X\\otimes\\mathrm{copy}_Y).\n\\]\nただし， \\(d\\) でブライダルを表す．\nまた，写像 \\(\\mathrm{delete}:X\\to 1\\) は， \\(1\\) が終対象であることから一意的であるため，更に \\(X\\) 内で自然であることに注意．一方で，複製写像は自然とは限らない．\n\n\n3．注\n\nA Markov category can equivalently be defined as a semicartesian symmetric monoidal category that supplies commutative comonoids.\n\n\n\n4．例\n\n有限集合と確率行列のなす圏 \\(\\mathtt{FinStoch}\\) ．\n可測空間とMarkov核のなす圏 \\(\\mathtt{Stoch}\\) ．\n任意のデカルトモノイダル圏 \\(C\\) が，モノイド単位を保存するモノイダルモナド \\(T\\) を持つならば，そのKleisli圏 \\(\\mathrm{Kl}(T)\\) はMarkov圏になる．\n\n\n\n5．決定論的な射\nMarkov圏の射 \\(f:X\\to Y\\) が決定論的であるとは，複製写像と可換であることをいう：\n\\[\n\\mathrm{copy}\\circ f=(f\\otimes f)\\circ\\mathrm{copy}.\n\\]\nこの定義のモチベーションは以下の通りである． \\(f\\) が例えば実数上の実確率変数で，入力に，サイコロの目を振ってでた値を加えるような関数であるとしよう．すると，入力 \\(x\\in\\mathbb{R}\\) に対して，サイコロを振り，出た目 \\(n\\in[6]\\) を加えて得た結果をコピーするから，左辺は \\((x+n,x+n)\\) である．一方で，まず入力 \\(x\\in\\mathbb{R}\\) を複製写像 \\(\\mathrm{copy}\\) に渡し， \\((x,x)\\) を得た後でサイコロを2回降り，出た目 \\(n_1,n_2\\in[6]\\) をそれぞれ加えると，右辺は \\((x+n_1,x+n_2)\\) となるが，別々の試行で出た目が一致する \\(n_1=n_2\\) とは限らない．この性質を，「ランダム性」の定義とする，というのである：つまりランダム性とは，2回行ったときに結果が異なり得る，という過程に宿るものとする．また，同値なことだが，その過程の前に情報を複製することと，その過程を見た後に情報を複製することとで，異なる状況を与えるような「過程」のことだとも理解できる．\n\n\n10．参考文献\nTobias Fritz（現在オーストリアInnsbruck大学）がこの分野の騎手であり，他にホモトピー型理論のレクチャーノートも執筆している．\n\nTobias Fritz (2019) A synthetic approach to Markov kernels, conditional independence and theorems on sufficient statistics. (arXiv:1908.07021)\nTobias Fritz and Eigil Fjeldgren Rischel (2019) The zero-one laws of Kolmogorov and Hewitt–Savage in categorical probability. (arXiv:1912.02769)\n\nこの研究の流れは，Bart Jacobsによるchannel perspectiveを汲んでいる．彼らは同様の概念をaffine CD-圏と呼んでいたようだ．\n\nBart Jacobs and Fabio Zanasi (2018) The Logical Essentials of Bayesian Reasoning. (arXiv:1804.01193)"
  },
  {
    "objectID": "posts/2023/2023-12-2/条件付き期待値の問題.html",
    "href": "posts/2023/2023-12-2/条件付き期待値の問題.html",
    "title": "条件付き期待値の測度論的基礎付け",
    "section": "",
    "text": "条件付き期待値を，測度論から厳密に定義する際，ポイントは次の4点である．\n\n$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$\n\n\n\n\n\n\n\nポイント\n\n\n\n\n条件付き期待値は \\(\\sigma\\)-代数 \\(\\mathcal{G}\\) に対して \\(\\mathrm{E}[X|\\mathcal{G}]\\) の形で（\\(\\Omega\\) 上殆ど至る所）定義される確率変数である．\n\\(\\mathrm{E}[X|Y]\\) というのは，\\(\\mathrm{E}[X|\\sigma(Y)]\\) の略記である．\n\\(\\mathrm{E}[X|Y=y]\\) というのは，\\(\\mathrm{E}[X|\\sigma(Y)](Y^{-1}(y))\\) のことである．\n\\(X\\in L^2(\\Omega)\\) でもあるとき，\\(\\mathrm{E}[X|\\mathcal{F}]\\) は \\(X\\) に \\(L^2(\\Omega)\\)-距離で最も近いような \\(\\mathcal{F}\\)-可測確率変数である．\n条件付き確率は \\(\\mathrm{P}[Y\\in B|X]:=\\mathrm{E}[1_{\\left\\{Y\\in B\\right\\}}|X]\\) と定義する．\n\n\n\n\n\n\n\n\n\n\n\n定義（条件付き期待値）\n\n\n\n\\((\\Omega,\\mathcal{F},\\mathrm{P})\\) を確率空間とし，\\(\\mathcal{G}\\) を \\(\\mathcal{F}\\) の部分 \\(\\sigma\\)-代数とする．可積分確率変数 \\(X\\in\\mathcal{L}^1(\\Omega)\\) について， 次の2条件を満たす，\\(\\mathrm{P}\\)-零集合を除いて一意な確率変数を条件付き期待値といい，\\(\\mathrm{E}[X|\\mathcal{G}]\\) で表す．\n\n\\(\\mathcal{G}\\)-可測でもある \\(\\mathrm{P}\\)-可積分確率変数である．\n任意の \\(\\mathcal{G}\\)-可測集合 \\(B\\in\\mathcal{G}\\) 上では \\(X\\) と期待値が同じ確率変数になる：\\[\\mathrm{E}[X1_B]=\\mathrm{E}[\\mathrm{E}[X|\\mathcal{G}]1_B]\\]\n\n\n\n\\[\\mathrm{E}[X,B]:=\\mathrm{E}[X1_B]\\] という記法を採用すれば，条件2は \\[\\mathrm{E}[X,B]=\\mathrm{E}[\\mathrm{E}[X|\\mathcal{G}],B]\\] と書くこともできる．\n\n\n\n\n\n\n証明\n\n\n\n定義の2条件のみから，\\(\\mathrm{E}[X|\\mathcal{G}]\\) が \\(\\mathrm{P}\\)-零集合を除いて一意に定まること（とその存在）を示す．\n\\[Q(B):=\\mathrm{E}[X,B]=\\mathrm{E}[1_BX]\\;(B\\in\\mathcal{G})\\] とおくことで，\\(Q\\) は可測空間 \\((\\Omega,\\mathcal{G})\\) 上の確率測度を定める． いま，\\(\\mathrm{P}|_\\mathcal{G}\\) に関して \\(Q\\) は絶対連続になっている：\\[\\forall_{B\\in\\mathcal{G}}\\;P(B)=0\\Rightarrow Q(B)=0.\\] これより，Radon-Nikodymの定理から， ある \\(\\mathcal{G}\\)-可測で \\(\\mathrm{P}\\)-可積分な可測関数 \\(Y:\\Omega\\to\\mathbb{R}\\) が，\\(\\mathrm{P}\\)-零集合上での違いを除いて一意的に存在して，\\[\\forall_{B\\in\\mathcal{G}}\\;Q(B)=\\int_BY(\\omega)P(d\\omega)\\] が成り立つ． よって，条件付き期待値 \\(Y\\) は確かに存在して（同値類 \\(L^1(\\mathrm{P})\\) の元としては）一意的で，(1),(2)が成り立つ．\n\n\n(Dudley, 2002, pp. 10.1節 p.336), (吉田朋広, 2006, p. 43) がおすすめな参照先．(舟木直久, 2004, p. 88) が入門しやすい．\\(X\\in L^2(\\Omega)\\) でいい場合は，より「射影」としてわかりやすい特徴付けがある（ 節 1.3 ）．これのおすすめは (Jacod & Protter, 2004, pp. 第23節 p.200), (Kallenberg, 2021, p. 164)．\n\n\n\n\n\n\n\n\n\n定義（確率変数を与えた下での条件付き期待値）\n\n\n\n\\((E,\\mathcal{E})\\) を可測空間とする．確率変数 \\(X\\in\\mathcal{L}(\\Omega;E)\\) による \\(Y\\in\\mathcal{L}^1(\\Omega)\\) の条件付き期待値は，次を満たす可測関数 \\(\\mathrm{E}[Y|X=-]:E\\to\\mathbb{R}\\) のことをいう： \\[\n\\begin{align*}\n\\forall_{B\\in\\mathcal{E}}\\quad&\\int_{X^{-1}(B)}Y(\\omega)P(d\\omega)\\\\\n&\\quad=\\int_B\\mathrm{E}[Y|X=x]P^X(dx).\n\\end{align*}\n\\]\n\n\nすると，\\(X\\) が \\(\\Omega\\) 上に引き戻す \\(\\sigma\\)-代数 \\[\n\\sigma(X):=\\left\\{A\\subset\\Omega\\mid\\exists_{B\\in\\mathcal{E}}\\; X^{-1}(B)=A\\right\\}\n\\] を与えた下での条件付き期待値 \\(\\mathrm{E}[Y|\\sigma(X)]\\) と，次のように関係する．1 \\(\\mathrm{E}[Y|\\sigma(X)]\\) は定義 節 1.1 1から \\(\\sigma[X]\\)-可測であるが，可測性の特徴付け（後述）から，これはあるBorel可測関数 \\(f\\) について，\\[\\mathrm{E}[Y|X]=f(X)\\;\\;\\text{a.s.}\\] と表せる．この \\(f:\\mathcal{X}\\to\\mathbb{R}\\) が，\\(X\\) を与えた下での \\(Y\\) の条件付き期待値 \\(\\mathrm{E}[Y|X=-]\\) である．\nこの記法 \\(\\mathrm{E}[Y|X=x]\\) とは何かというと，\\(X\\) の値域 \\(\\mathcal{X}\\) 上の関数として，新たに \\[\\mathrm{E}[Y|X=x]:=f(x)\\;\\;\\text{a.s.}\\] と書くことにするのである．2 すると， \\[\n\\mathrm{E}[Y|X=x]|_{x=X(\\omega)}=\\mathrm{E}[Y|X](\\omega)\\;\\;\\text{a.s.}\n\\] も満たす．つまり，次の図式が可換である：\n\n\n\nCommutative Diagram for Conditional Expectations\n\n\n\n\n\n\n\n\n命題（Doobの汎函数表現）\n\n\n\n\\(S\\) を位相空間，\\(X\\in \\mathcal{L}(\\Omega;S),Y\\in \\mathcal{L}(\\Omega)\\) を確率変数とする．次は同値：\n\n\\(Y\\)は \\(\\sigma(X)\\)-可測．\nあるBorel可測関数 \\(f:S\\to\\mathbb{R}\\) が存在して，\\(Y=f(X)\\) を満たす．\n\n\n\n\n\n\n\n\n\n証明\n\n\n\n2 \\(\\Rightarrow\\) 1 はすぐに従う．任意の \\(B\\in\\mathcal{B}(\\mathbb{R})\\) について，\\(f^{-1}(B)\\in\\mathcal{B}(S)\\) であるから， \\[Y^{-1}(B)=X^{-1}(f^{-1}(B))\\in\\sigma(X).\\] あとは 1 \\(\\Rightarrow\\) 2 を示せば良い．3段階で示す．\n\nまず \\(Y\\) が単関数 \\[Y=\\sum_{i=1}^nc_i1_{A_i},\\qquad c_i\\ne c_j\\;(i\\ne j).\\] の場合について示す．仮定より \\(A_i\\in\\sigma(X)\\) であるから，ある \\(B_i\\in\\mathcal{B}(S)\\) が存在して \\(A_i=X^{-1}(B_i)\\)．よって， \\[f(x):=\\sum_{i=1}^nc_i1_{B_i}(x).\\] と定めると \\(Y=f(X)\\)．\n次に \\(Y\\ge0\\;\\;\\text{a.s.}\\) の場合を考えると，正な単関数の単調増加列 \\(\\{Y_n\\}\\) で \\(Y\\) に収束するものが取れる．各 \\(Y_n\\) について，\\(f_n\\in\\mathcal{L}(S)\\) が存在して \\(Y_n=f_n(X)\\) が成り立つ．このとき，\\(f:=\\limsup_{n\\to\\infty}f_n\\) と定めれば， \\[\\begin{align*}\nY&=\\limsup_{n\\to\\infty}Y_n\\\\\n&=(\\limsup_{n\\to\\infty}f_n)(X)=f(X).\n\\end{align*}\\]\n一般の場合は \\(Y=Y^+-Y^-\\) の分解から従う．\n\n\n\n(Dudley, 2002, pp. 定理4.2.8 p.128) は \\(S=\\mathbb{R}\\) の場合，(Landkov, 1972) は \\(S=\\mathbb{R}^m\\) の場合, (Kallenberg, 2021, pp. 補題1.14 p.18) に一般の標準Borel空間の場合の証明がある．nLab も極めて参考になる．\n\n\n\n\\(L^2(\\Omega)\\subset L^1(\\Omega)\\) 上に議論を制限してみると，実は \\(\\mathcal{F}\\) の部分 \\(\\sigma\\)-代数 \\(\\mathcal{G}\\) に関する条件付き期待値は，部分空間 \\[\nL^2_\\mathcal{G}(\\Omega):=\\left\\{X\\in L^2(\\Omega)\\:\\middle|\\:X\\,\\text{は}\\,\\mathcal{G}\\,\\text{-可測}\\right\\}\n\\] への射影になっている．\n\n\n\n\n\n\n定理（条件付き期待値の特徴付け）\n\n\n\n部分 \\(\\sigma\\)-代数 \\(\\mathcal{G}\\subset\\mathcal{F}\\) と \\(X\\in\\mathcal{L}^2(\\Omega)\\) を考える． 任意の \\(\\widehat{X}_\\mathcal{G}\\in\\mathcal{L}^2_\\mathcal{G}(\\Omega)\\) について，次は同値：\n\n\\(\\widetilde{X}_\\mathcal{G}\\) は \\(X\\) の \\(L^2_\\mathcal{G}(\\Omega)\\) への射影である： \\[\n\\begin{align*}\n&\\|X-\\widehat{X}_\\mathcal{G}\\|_{L^2(\\Omega)}\\\\\n&=\\inf_{X'\\in\\mathcal{L}^2_\\mathcal{G}(\\Omega)}\\|X-X'\\|_{L^2(\\Omega)}.\n\\end{align*}\n\\]\n\\(\\widetilde{X}_\\mathcal{G}\\) は \\(X\\) の条件付き期待値である：\\[\\forall_{Z\\in L^2_\\mathcal{G}(\\Omega)}\\;\\mathrm{E}[ZX]=\\mathrm{E}[Z\\widehat{X}_\\mathcal{G}].\\]\n\n\n\n\n\n\n\n\n\n\n\n\n定義（条件付き確率）\n\n\n\n\\((\\Omega,\\mathcal{F},\\mathrm{P})\\) を確率空間，\\(\\mathcal{G}\\subset\\mathcal{F}\\) を部分 \\(\\sigma\\)-代数とする．\\(\\mathcal{G}\\) の定める条件付き確率を， \\[\n\\mathrm{P}[B|\\mathcal{G}](\\omega):=\\mathrm{E}[1_B|\\mathcal{G}](\\omega)\\;(B\\in\\mathcal{F})\n\\] で定める．\n\n\nしかしこの定義には問題がある．条件付き期待値 \\(\\mathrm{E}[X|\\mathcal{G}]\\) が \\(\\Omega\\) 上 \\(\\mathrm{P}\\text{-a.e.}\\) でしか定まらない（場合がある）から，\\(\\mathrm{P}\\) も一般には可算加法性をa.s.にしか満たさない： \\[\n\\mathrm{P}\\left[\\bigcap_{n\\in\\mathbb{N}}A_n\\,\\middle|\\,\\mathcal{G}\\right]=\\sum_{n\\in\\mathbb{N}}\\mathrm{P}[A_n]\\;\\;\\text{a.s.}\n\\] この式自体は後述の単調収束定理（ 節 2.3 ）から示せる．\nだが，\\(\\mathcal{G}\\) がある完備可分距離空間に値を取る確率変数 \\(Y\\) について \\(\\mathcal{G}=\\sigma(Y)\\) である場合など，殆どの場合で，うまく \\(\\mathrm{P}\\) を取ることが出来る．3 このように，a.s.抜きで正式に確率測度として定まる場合を，正則条件付き確率と呼び分ける．"
  },
  {
    "objectID": "posts/2023/2023-12-2/条件付き期待値の問題.html#条件付き期待値の定義",
    "href": "posts/2023/2023-12-2/条件付き期待値の問題.html#条件付き期待値の定義",
    "title": "条件付き期待値の測度論的基礎付け",
    "section": "",
    "text": "条件付き期待値を，測度論から厳密に定義する際，ポイントは次の4点である．\n\n$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$\n\n\n\n\n\n\n\nポイント\n\n\n\n\n条件付き期待値は \\(\\sigma\\)-代数 \\(\\mathcal{G}\\) に対して \\(\\mathrm{E}[X|\\mathcal{G}]\\) の形で（\\(\\Omega\\) 上殆ど至る所）定義される確率変数である．\n\\(\\mathrm{E}[X|Y]\\) というのは，\\(\\mathrm{E}[X|\\sigma(Y)]\\) の略記である．\n\\(\\mathrm{E}[X|Y=y]\\) というのは，\\(\\mathrm{E}[X|\\sigma(Y)](Y^{-1}(y))\\) のことである．\n\\(X\\in L^2(\\Omega)\\) でもあるとき，\\(\\mathrm{E}[X|\\mathcal{F}]\\) は \\(X\\) に \\(L^2(\\Omega)\\)-距離で最も近いような \\(\\mathcal{F}\\)-可測確率変数である．\n条件付き確率は \\(\\mathrm{P}[Y\\in B|X]:=\\mathrm{E}[1_{\\left\\{Y\\in B\\right\\}}|X]\\) と定義する．\n\n\n\n\n\n\n\n\n\n\n\n定義（条件付き期待値）\n\n\n\n\\((\\Omega,\\mathcal{F},\\mathrm{P})\\) を確率空間とし，\\(\\mathcal{G}\\) を \\(\\mathcal{F}\\) の部分 \\(\\sigma\\)-代数とする．可積分確率変数 \\(X\\in\\mathcal{L}^1(\\Omega)\\) について， 次の2条件を満たす，\\(\\mathrm{P}\\)-零集合を除いて一意な確率変数を条件付き期待値といい，\\(\\mathrm{E}[X|\\mathcal{G}]\\) で表す．\n\n\\(\\mathcal{G}\\)-可測でもある \\(\\mathrm{P}\\)-可積分確率変数である．\n任意の \\(\\mathcal{G}\\)-可測集合 \\(B\\in\\mathcal{G}\\) 上では \\(X\\) と期待値が同じ確率変数になる：\\[\\mathrm{E}[X1_B]=\\mathrm{E}[\\mathrm{E}[X|\\mathcal{G}]1_B]\\]\n\n\n\n\\[\\mathrm{E}[X,B]:=\\mathrm{E}[X1_B]\\] という記法を採用すれば，条件2は \\[\\mathrm{E}[X,B]=\\mathrm{E}[\\mathrm{E}[X|\\mathcal{G}],B]\\] と書くこともできる．\n\n\n\n\n\n\n証明\n\n\n\n定義の2条件のみから，\\(\\mathrm{E}[X|\\mathcal{G}]\\) が \\(\\mathrm{P}\\)-零集合を除いて一意に定まること（とその存在）を示す．\n\\[Q(B):=\\mathrm{E}[X,B]=\\mathrm{E}[1_BX]\\;(B\\in\\mathcal{G})\\] とおくことで，\\(Q\\) は可測空間 \\((\\Omega,\\mathcal{G})\\) 上の確率測度を定める． いま，\\(\\mathrm{P}|_\\mathcal{G}\\) に関して \\(Q\\) は絶対連続になっている：\\[\\forall_{B\\in\\mathcal{G}}\\;P(B)=0\\Rightarrow Q(B)=0.\\] これより，Radon-Nikodymの定理から， ある \\(\\mathcal{G}\\)-可測で \\(\\mathrm{P}\\)-可積分な可測関数 \\(Y:\\Omega\\to\\mathbb{R}\\) が，\\(\\mathrm{P}\\)-零集合上での違いを除いて一意的に存在して，\\[\\forall_{B\\in\\mathcal{G}}\\;Q(B)=\\int_BY(\\omega)P(d\\omega)\\] が成り立つ． よって，条件付き期待値 \\(Y\\) は確かに存在して（同値類 \\(L^1(\\mathrm{P})\\) の元としては）一意的で，(1),(2)が成り立つ．\n\n\n(Dudley, 2002, pp. 10.1節 p.336), (吉田朋広, 2006, p. 43) がおすすめな参照先．(舟木直久, 2004, p. 88) が入門しやすい．\\(X\\in L^2(\\Omega)\\) でいい場合は，より「射影」としてわかりやすい特徴付けがある（ 節 1.3 ）．これのおすすめは (Jacod & Protter, 2004, pp. 第23節 p.200), (Kallenberg, 2021, p. 164)．\n\n\n\n\n\n\n\n\n\n定義（確率変数を与えた下での条件付き期待値）\n\n\n\n\\((E,\\mathcal{E})\\) を可測空間とする．確率変数 \\(X\\in\\mathcal{L}(\\Omega;E)\\) による \\(Y\\in\\mathcal{L}^1(\\Omega)\\) の条件付き期待値は，次を満たす可測関数 \\(\\mathrm{E}[Y|X=-]:E\\to\\mathbb{R}\\) のことをいう： \\[\n\\begin{align*}\n\\forall_{B\\in\\mathcal{E}}\\quad&\\int_{X^{-1}(B)}Y(\\omega)P(d\\omega)\\\\\n&\\quad=\\int_B\\mathrm{E}[Y|X=x]P^X(dx).\n\\end{align*}\n\\]\n\n\nすると，\\(X\\) が \\(\\Omega\\) 上に引き戻す \\(\\sigma\\)-代数 \\[\n\\sigma(X):=\\left\\{A\\subset\\Omega\\mid\\exists_{B\\in\\mathcal{E}}\\; X^{-1}(B)=A\\right\\}\n\\] を与えた下での条件付き期待値 \\(\\mathrm{E}[Y|\\sigma(X)]\\) と，次のように関係する．1 \\(\\mathrm{E}[Y|\\sigma(X)]\\) は定義 節 1.1 1から \\(\\sigma[X]\\)-可測であるが，可測性の特徴付け（後述）から，これはあるBorel可測関数 \\(f\\) について，\\[\\mathrm{E}[Y|X]=f(X)\\;\\;\\text{a.s.}\\] と表せる．この \\(f:\\mathcal{X}\\to\\mathbb{R}\\) が，\\(X\\) を与えた下での \\(Y\\) の条件付き期待値 \\(\\mathrm{E}[Y|X=-]\\) である．\nこの記法 \\(\\mathrm{E}[Y|X=x]\\) とは何かというと，\\(X\\) の値域 \\(\\mathcal{X}\\) 上の関数として，新たに \\[\\mathrm{E}[Y|X=x]:=f(x)\\;\\;\\text{a.s.}\\] と書くことにするのである．2 すると， \\[\n\\mathrm{E}[Y|X=x]|_{x=X(\\omega)}=\\mathrm{E}[Y|X](\\omega)\\;\\;\\text{a.s.}\n\\] も満たす．つまり，次の図式が可換である：\n\n\n\nCommutative Diagram for Conditional Expectations\n\n\n\n\n\n\n\n\n命題（Doobの汎函数表現）\n\n\n\n\\(S\\) を位相空間，\\(X\\in \\mathcal{L}(\\Omega;S),Y\\in \\mathcal{L}(\\Omega)\\) を確率変数とする．次は同値：\n\n\\(Y\\)は \\(\\sigma(X)\\)-可測．\nあるBorel可測関数 \\(f:S\\to\\mathbb{R}\\) が存在して，\\(Y=f(X)\\) を満たす．\n\n\n\n\n\n\n\n\n\n証明\n\n\n\n2 \\(\\Rightarrow\\) 1 はすぐに従う．任意の \\(B\\in\\mathcal{B}(\\mathbb{R})\\) について，\\(f^{-1}(B)\\in\\mathcal{B}(S)\\) であるから， \\[Y^{-1}(B)=X^{-1}(f^{-1}(B))\\in\\sigma(X).\\] あとは 1 \\(\\Rightarrow\\) 2 を示せば良い．3段階で示す．\n\nまず \\(Y\\) が単関数 \\[Y=\\sum_{i=1}^nc_i1_{A_i},\\qquad c_i\\ne c_j\\;(i\\ne j).\\] の場合について示す．仮定より \\(A_i\\in\\sigma(X)\\) であるから，ある \\(B_i\\in\\mathcal{B}(S)\\) が存在して \\(A_i=X^{-1}(B_i)\\)．よって， \\[f(x):=\\sum_{i=1}^nc_i1_{B_i}(x).\\] と定めると \\(Y=f(X)\\)．\n次に \\(Y\\ge0\\;\\;\\text{a.s.}\\) の場合を考えると，正な単関数の単調増加列 \\(\\{Y_n\\}\\) で \\(Y\\) に収束するものが取れる．各 \\(Y_n\\) について，\\(f_n\\in\\mathcal{L}(S)\\) が存在して \\(Y_n=f_n(X)\\) が成り立つ．このとき，\\(f:=\\limsup_{n\\to\\infty}f_n\\) と定めれば， \\[\\begin{align*}\nY&=\\limsup_{n\\to\\infty}Y_n\\\\\n&=(\\limsup_{n\\to\\infty}f_n)(X)=f(X).\n\\end{align*}\\]\n一般の場合は \\(Y=Y^+-Y^-\\) の分解から従う．\n\n\n\n(Dudley, 2002, pp. 定理4.2.8 p.128) は \\(S=\\mathbb{R}\\) の場合，(Landkov, 1972) は \\(S=\\mathbb{R}^m\\) の場合, (Kallenberg, 2021, pp. 補題1.14 p.18) に一般の標準Borel空間の場合の証明がある．nLab も極めて参考になる．\n\n\n\n\\(L^2(\\Omega)\\subset L^1(\\Omega)\\) 上に議論を制限してみると，実は \\(\\mathcal{F}\\) の部分 \\(\\sigma\\)-代数 \\(\\mathcal{G}\\) に関する条件付き期待値は，部分空間 \\[\nL^2_\\mathcal{G}(\\Omega):=\\left\\{X\\in L^2(\\Omega)\\:\\middle|\\:X\\,\\text{は}\\,\\mathcal{G}\\,\\text{-可測}\\right\\}\n\\] への射影になっている．\n\n\n\n\n\n\n定理（条件付き期待値の特徴付け）\n\n\n\n部分 \\(\\sigma\\)-代数 \\(\\mathcal{G}\\subset\\mathcal{F}\\) と \\(X\\in\\mathcal{L}^2(\\Omega)\\) を考える． 任意の \\(\\widehat{X}_\\mathcal{G}\\in\\mathcal{L}^2_\\mathcal{G}(\\Omega)\\) について，次は同値：\n\n\\(\\widetilde{X}_\\mathcal{G}\\) は \\(X\\) の \\(L^2_\\mathcal{G}(\\Omega)\\) への射影である： \\[\n\\begin{align*}\n&\\|X-\\widehat{X}_\\mathcal{G}\\|_{L^2(\\Omega)}\\\\\n&=\\inf_{X'\\in\\mathcal{L}^2_\\mathcal{G}(\\Omega)}\\|X-X'\\|_{L^2(\\Omega)}.\n\\end{align*}\n\\]\n\\(\\widetilde{X}_\\mathcal{G}\\) は \\(X\\) の条件付き期待値である：\\[\\forall_{Z\\in L^2_\\mathcal{G}(\\Omega)}\\;\\mathrm{E}[ZX]=\\mathrm{E}[Z\\widehat{X}_\\mathcal{G}].\\]\n\n\n\n\n\n\n\n\n\n\n\n\n定義（条件付き確率）\n\n\n\n\\((\\Omega,\\mathcal{F},\\mathrm{P})\\) を確率空間，\\(\\mathcal{G}\\subset\\mathcal{F}\\) を部分 \\(\\sigma\\)-代数とする．\\(\\mathcal{G}\\) の定める条件付き確率を， \\[\n\\mathrm{P}[B|\\mathcal{G}](\\omega):=\\mathrm{E}[1_B|\\mathcal{G}](\\omega)\\;(B\\in\\mathcal{F})\n\\] で定める．\n\n\nしかしこの定義には問題がある．条件付き期待値 \\(\\mathrm{E}[X|\\mathcal{G}]\\) が \\(\\Omega\\) 上 \\(\\mathrm{P}\\text{-a.e.}\\) でしか定まらない（場合がある）から，\\(\\mathrm{P}\\) も一般には可算加法性をa.s.にしか満たさない： \\[\n\\mathrm{P}\\left[\\bigcap_{n\\in\\mathbb{N}}A_n\\,\\middle|\\,\\mathcal{G}\\right]=\\sum_{n\\in\\mathbb{N}}\\mathrm{P}[A_n]\\;\\;\\text{a.s.}\n\\] この式自体は後述の単調収束定理（ 節 2.3 ）から示せる．\nだが，\\(\\mathcal{G}\\) がある完備可分距離空間に値を取る確率変数 \\(Y\\) について \\(\\mathcal{G}=\\sigma(Y)\\) である場合など，殆どの場合で，うまく \\(\\mathrm{P}\\) を取ることが出来る．3 このように，a.s.抜きで正式に確率測度として定まる場合を，正則条件付き確率と呼び分ける．"
  },
  {
    "objectID": "posts/2023/2023-12-2/条件付き期待値の問題.html#性質",
    "href": "posts/2023/2023-12-2/条件付き期待値の問題.html#性質",
    "title": "条件付き期待値の測度論的基礎付け",
    "section": "2 性質",
    "text": "2 性質\n\n2.1 作用素としての性質\n\\(\\mathcal{G}\\)-可測な可積分関数のなす部分空間を \\(L_{\\mathcal{G}}^1(\\Omega)\\subset L^1(\\Omega)\\) で表す．\n\n\n\n\n\n\n命題（条件付き期待値はノルム減少的な正作用素）\n\n\n\n条件付き期待値 \\(\\mathrm{E}_{\\mathcal{G}}:L^1(\\Omega)\\to L_{\\mathcal{G}}^1(\\Omega)\\) はノルム減少的で正な線型汎作用素である．すなわち，\n\n線型性：任意の実数 \\(a,b\\in\\mathbb{R}\\) について， \\[\\begin{align*}\n\\mathrm{E}[aX+bY|\\mathcal{G}]&=a\\mathrm{E}[X|\\mathcal{G}]\\\\\n&\\qquad+b\\mathrm{E}[Y|\\mathcal{G}]\\;\\;\\text{a.s.}\n\\end{align*}\\]\n正性：\\(X\\le Y\\;\\;\\text{a.s.}\\) ならば， \\[\\mathrm{E}[X|\\mathcal{G}]\\le\\mathrm{E}[Y|\\mathcal{G}]\\;\\;\\text{a.s.}\\]\nJensenの不等式：\\(\\varphi:\\mathbb{R}\\to\\mathbb{R}\\) を凸関数とする．\\(\\varphi(X)\\in L^1(\\Omega)\\) ならば，\\[\\varphi(\\mathrm{E}[X|\\mathcal{G}])\\le\\mathrm{E}[\\varphi(X)|\\mathcal{G}]\\;\\;\\text{a.s.}\\]\n三角不等式：\\[\\lvert\\mathrm{E}[X|\\mathcal{G}]\\rvert\\le\\mathrm{E}[\\lvert X\\rvert|\\mathcal{G}]\\;\\;\\text{a.s.}\\]\n\nいずれも \\(L_{\\mathcal{G}}^1(\\Omega)\\) 上の等式・不等式であり，殆ど確実ににしか成り立たないことに注意．\n\n\n\n\n\n\n\n\n証明\n\n\n\n1は結局積分の線型性から従います．2は次のように議論できます．\n任意の \\(X\\in L^1(\\Omega)_+\\) について \\(\\mathrm{E}[X|\\mathcal{G}]\\in L^1(\\Omega)\\) を示せば良い．\\(A_n:=\\left\\{X'\\le 1/n\\right\\}\\in\\mathcal{G}\\) について，条件付き期待値の定義から，任意の \\(n\\in\\mathbb{N}^+\\) について， \\[\n\\begin{align*}\n0\\le\\mathrm{E}[X,A_n]&=\\mathrm{E}[\\mathrm{E}[X|\\mathcal{G}],A_n]\\\\\n&\\le\\frac{1}{n}\\mathrm{P}[A_n].\n\\end{align*}\n\\] より，\\(\\lim_{n\\to\\infty}\\mathrm{P}[A_n]=0\\) が必要．これより， \\[\\mathrm{P}[\\mathrm{E}[X|\\mathcal{G}]&lt;0]\\le\\mathrm{P}[\\cup_{n=1}^\\infty A_n]=0.\\] が解る．\n3は単関数の場合から地道に示します．4はその特別の場合で \\(\\varphi(x)=\\lvert x\\rvert\\) と取った場合に当たります．\n\n\n\n\n2.2 Tower Property\n\n\n\n\n\n\n命題（繰り返し期待値の法則）\n\n\n\n2つの \\(\\sigma\\)-代数が \\(\\mathcal{G}_1\\subset\\mathcal{G}_2\\) を満たすならば，\\(\\mathrm{E}_{\\mathcal{G}_1}=\\mathrm{E}_{\\mathcal{G}_1}\\circ\\mathrm{E}_{\\mathcal{G}_2}\\)．すなわち， \\[\\mathrm{E}[X|\\mathcal{G}_1]=\\mathrm{E}[\\mathrm{E}[X|\\mathcal{G}_2]|\\mathcal{G}_1]\\;\\;\\text{a.s.}\\]\n\n\n\n\n\n\n\n\n証明\n\n\n\n右辺を \\(Z\\) とおく．任意の \\(A\\in\\mathcal{G}_1\\) について，\\(A\\in\\mathcal{G}_2\\) でもあるから， \\[\\begin{align*}\n\\mathrm{E}[Z1_A]&=\\mathrm{E}[\\mathrm{E}[X|\\mathcal{G}_1]1_A]\\\\\n&=\\mathrm{E}[X1_A].\n\\end{align*}\\]\n\n\n\n\n2.3 単調収束定理\n\n\n\n\n\n\n命題（条件付き期待値に対する単調収束定理）\n\n\n\n可積分な実確率変数の列 \\(\\{X_n\\}\\cup\\{X\\}\\subset L^1(\\Omega)\\) について， \\[X_n\\nearrow X\\;\\;\\text{a.s.}\\] \\[\\Rightarrow\\quad\\mathrm{E}[X_n|\\mathcal{G}]\\nearrow\\mathrm{E}[X|\\mathcal{G}]\\;\\;\\text{a.s.}\\]\n\n\n\n\n\n\n\n\n証明\n\n\n\n条件付き期待値の正性 節 2.1 より， \\[\\mathrm{E}[X_n|\\mathcal{G}]\\le\\mathrm{E}[X|\\mathcal{G}]\\;\\;\\text{a.s.},\\qquad n\\in\\mathbb{N}.\\] よって，有界な単調列は収束するから，ある \\(Y\\in L^1(\\Omega)\\) を \\(E[X_n|\\mathcal{G}]\\nearrow Y\\;\\;\\text{a.s.}\\) を満たすように定めることが出来る．同時に，通常の期待値に関する単調収束定理から， \\[\n\\begin{align*}\n\\mathrm{E}[X1_A]&=\\lim_{n\\to\\infty}\\mathrm{E}[X_n1_A]\\\\&=\\mathrm{E}[Y1_A]\\;(A\\in\\mathcal{G})\n\\end{align*}\n\\] が必要であるから，条件付き期待値の一意性より，\\(Y=\\mathrm{E}[X|\\mathcal{G}]\\;\\;\\text{a.s.}\\)\n\n\n\n\n2.4 可測関数の取り出し\n\n\n\n\n\n\n命題（可測関数の取り出し）\n\n\n\n\\(X,XY\\in L^1(\\Omega)\\) を可積分，\\(Y\\in L_\\mathcal{G}(\\Omega)\\) を \\(\\mathcal{G}\\)-可測実確率変数とする．このとき，\n\n\\(XY\\in L^1(\\Omega)\\)ならば，\\[\\mathrm{E}[XY|\\mathcal{G}]=Y\\mathrm{E}[X|\\mathcal{G}]\\;\\;\\text{a.s.}\\]\n特に，\\(\\mathrm{E}[Y|\\mathcal{G}]=Y\\;\\;\\text{a.s.}\\)\n\n\n\n\n\n\n\n\n\n証明\n\n\n\n条件付き期待値の線型性から，\\(X,Y\\ge0\\) の場合について示せば良い．このとき，非負値単関数の収束列 \\(X_n\\nearrow X,Y_n\\nearrow Y\\) が取れる．\\(X_nY\\nearrow XY\\in L^1(\\Omega)\\) だから，単調収束定理 節 2.3 から \\[\\mathrm{E}[X_n|\\mathcal{G}]\\nearrow\\mathrm{E}[X|\\mathcal{G}]\\] \\[\n\\begin{align*}\n\\Rightarrow&\\quad Y\\mathrm{E}[X_n|\\mathcal{G}]\\nearrow Y\\mathrm{E}[X|\\mathcal{G}]\\\\\n\\quad\\land&\\quad\\mathrm{E}[X_nY|\\mathcal{G}]\\nearrow\\mathrm{E}[XY|\\mathcal{G}].\n\\end{align*}\\] よって，各 \\(n\\in\\mathbb{N}\\) について \\(Y\\mathrm{E}[X_n|\\mathcal{G}]=\\mathrm{E}[X_nY|\\mathcal{G}]\\) を示せば良い．単関数とは \\(X=1_C\\;(C\\in\\mathcal{G})\\) という形の関数の線型和だから，畢竟この形の関数について考えれば良いのである．任意の \\(B\\in\\mathcal{G}\\) について \\(C\\cap B\\in\\mathcal{G}\\) であるから， \\[\n\\begin{align*}\n\\int_B1_C\\mathrm{E}[Y|\\mathcal{G}]\\,d\\mathrm{P}&=\\int_{C\\cap B}\\mathrm{E}[Y|\\mathcal{G}]\\,d\\mathrm{P}\\\\\n&=\\int_{C\\cap B}Y\\,d\\mathrm{P}\\\\\n&=\\int_B1_CY\\,d\\mathrm{P}.\n\\end{align*}\n\\] 条件付き期待値の一意性より，\\(1_C\\mathrm{E}[Y|\\mathcal{G}]=\\mathrm{E}[1_CY|\\mathcal{G}]\\;\\;\\text{a.s.}\\) を得る．\n\n\n\n\n2.5 独立な場合\n\n\n\n\n\n\n命題（独立確率変数に対する性質）\n\n\n\n可積分実確率変数 \\(X\\in L^1(\\Omega)\\)は \\(\\sigma\\)-代数 \\(\\mathcal{G}\\) と独立とする．\n\n\\(E[X|\\mathcal{G}]=E[X]\\;\\;\\text{a.s.}\\)\n特に，\\(E[X|\\boldsymbol{2}]=E[X]\\;\\;\\text{a.s.}\\)．\n\n\n\n\n\n2.6 練習\n\n\n\n\n\n\n問題\n\n\n\n確率変数 \\(X,Y\\) とその値域の値 \\(y\\in\\mathcal{Y}\\) について， \\[\n\\mathrm{E}[X|Y=y]\\mathrm{P}[Y=y]=\\mathrm{E}[X1_{\\left\\{Y=y\\right\\}}]\n\\] はどう正当化されるか？\n\n\n\n\n\n\n\n\n説明\n\n\n\n\\(\\mathrm{E}[X1_{\\left\\{Y=y\\right\\}}]\\) の中身を \\(\\sigma(Y)\\) で条件付けてTower property（ 節 2.2 ）を使うと（定義 節 1.1 の条件2からと論じても良い），\\(1_{\\left\\{Y=y\\right\\}}\\) は \\(\\sigma(Y)\\)-可測だから，条件付き期待値の中身から出る（ 節 2.4 参照）．これによって正当化できる．式で表すと， \\[\n\\begin{align*}\n\\mathrm{E}[X1_{\\left\\{Y=y\\right\\}}]&=\\mathrm{E}[\\mathrm{E}[X1_{\\left\\{Y=y\\right\\}}|Y]]\\\\\n&=\\mathrm{E}[1_{\\left\\{Y=y\\right\\}}\\mathrm{E}[X|Y]]\\\\\n&=\\int_{\\mathcal{Y}}\\delta_y(y')\\mathrm{E}[X|Y=y']\\mathrm{P}(dy')\\\\\n&=\\mathrm{E}[X|Y=y]\\mathrm{P}[Y=y].\n\\end{align*}\n\\] ただし，\\(\\mathcal{Y}\\) 上の確率測度を \\(\\mathrm{P}\\) と置いた．\n\n\n条件付き確率の定義 節 1.4 から， \\[\n\\mathrm{P}[Y\\in B|X=x]:=\\mathrm{E}[1_{\\left\\{Y\\in B\\right\\}}|X=x]\n\\] と議論できる．さらに \\(\\mathrm{P}[X=x]&gt;0\\) のとき， \\[\n\\begin{align*}\n    &=\\frac{\\mathrm{E}[1_{\\left\\{Y\\in B\\right\\}}1_{\\left\\{X=x\\right\\}}]}{\\mathrm{P}[X=x]}\\\\\n    &=\\frac{\\mathrm{P}[Y\\in B,X=x]}{\\mathrm{P}[X=x]}\n\\end{align*}\n\\] という見慣れた表示を得る．\n\n\n2.7 条件付き分散\n\n\n\n\n\n\n命題（Pythagorasの式）\n\n\n\n\\[\n\\|Y\\|^2_2=\\|Y-\\mathrm{E}[Y|\\mathcal{G}]\\|^2_2+\\|\\mathrm{E}[Y|\\mathcal{G}]\\|^2_2.\n\\]\n\n\nこれは条件付き期待値が \\(L^2(\\Omega)\\)-射影であるためである（ 節 1.3 ）．\n確率変数 \\(Y\\in\\mathcal{L}^2(\\Omega)\\) の \\(\\mathcal{G}\\) に関する条件付き分散を \\[\n\\mathrm{V}[Y|\\mathcal{G}]:=\\mathrm{E}\\left[(Y-\\mathrm{E}[Y|\\mathcal{G}])^2|\\mathcal{G}\\right]\n\\] と定める．このとき，次の 全分散の公式 と呼ばれる関係が成り立つ： \\[\n\\mathrm{V}[Y]=\\mathrm{E}[\\mathrm{V}[Y|\\mathcal{G}]]+\\mathrm{V}[\\mathrm{E}[Y|\\mathcal{G}]].\n\\]\n\n\n\n\n\n\n説明\n\n\n\nPythagorasの関係から， \\[\n\\begin{align*}\n    \\mathrm{E}[Y^2]&=\\mathrm{E}[(Y-\\mathrm{E}[Y|\\mathcal{G}])^2]\\\\\n    &\\qquad+\\mathrm{E}[\\mathrm{E}[Y|\\mathcal{G}]^2].\n\\end{align*}\n\\] 両辺から \\[\n\\mathrm{E}[Y]^2=\\mathrm{E}[\\mathrm{E}[Y|\\mathcal{G}]]^2\n\\] を減じると，右辺第一項の \\(\\mathrm{E}[-]\\) の中身は中心化確率変数であることから， \\[\n\\begin{align*}\n    \\mathrm{V}[Y]&=\\mathrm{V}[Y-\\mathrm{E}[Y|\\mathcal{G}]]\\\\\n    &\\qquad+\\mathrm{E}[\\mathrm{E}[Y|\\mathcal{G}]^2]-\\mathrm{E}[\\mathrm{E}[Y|\\mathcal{G}]]^2\\\\\n    &=\\mathrm{V}[Y-\\mathrm{E}[Y|\\mathcal{G}]]+\\mathrm{V}[\\mathrm{E}[Y|\\mathcal{G}]].\n\\end{align*}\n\\] 最後に， \\[\n\\mathrm{V}[Y-\\mathrm{E}[Y|\\mathcal{G}]]=\\mathrm{E}[\\mathrm{V}[Y|\\mathcal{G}]]\n\\] より結論が従う．\n\n\n\n\n2.8 条件付き共分散\n\n\n\n\n\n\n定義（条件付き共分散）\n\n\n\n\\(X,Y\\in\\mathcal{L}^2(\\Omega)\\) の \\(\\mathcal{G}\\) に関する 条件付き共分散 を \\[\n\\begin{align*}\n    &\\mathrm{C}[X,Y|\\mathcal{G}]\\\\\n    &=\\mathrm{E}\\biggl[(X-\\mathrm{E}[X|\\mathcal{G}])(Y-\\mathrm{E}[Y|\\mathcal{G}])\\bigg|\\mathcal{G}\\biggr]\\\\\n    &=\\mathrm{E}[XY|\\mathcal{G}]-\\mathrm{E}[X|\\mathcal{G}]\\mathrm{E}[Y|\\mathcal{G}].\n\\end{align*}\n\\] と定義する．\n\n\n\n\n\n\n\n\n命題（条件付き共分散公式）\n\n\n\n\\[\n\\begin{align*}\n    &\\mathrm{C}[X,Y]\\\\\n    &=\\mathrm{E}[\\mathrm{C}[X,Y|\\mathcal{G}]]+\\mathrm{C}[\\mathrm{E}[X|\\mathcal{G}],\\mathrm{E}[Y|\\mathcal{G}]].\n\\end{align*}\n\\]\n\n\n証明は (Kallenberg, 2021) 補題8.2 p.166 など．"
  },
  {
    "objectID": "posts/2023/2023-12-2/条件付き期待値の問題.html#footnotes",
    "href": "posts/2023/2023-12-2/条件付き期待値の問題.html#footnotes",
    "title": "条件付き期待値の測度論的基礎付け",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(Dudley, 2002, p. 340) など．↩︎\n(Kallenberg, 2021, p. 167)．↩︎\n(Dudley, 2002, pp. 定理10.2.2 p.345)．一般には Borel空間に値を取る確率変数について成り立つ (Kallenberg, 2021, p. 165)．↩︎"
  },
  {
    "objectID": "posts/2023/2023-11-5/index.html",
    "href": "posts/2023/2023-11-5/index.html",
    "title": "俺の人生を変えたものTop5",
    "section": "",
    "text": "９月の京都学会→台湾研修（３週間）から帰ってきて，最初に手をつけたのが家の片付けであった．不要な本は全て売り（段ボール5箱），粗大ゴミを8000円分捨て，古着も処分した．特に，半ば物置と化していた和室をリフォームし，自分の書斎として使えるようにした．結果，11月を迎えた今，8月までの生活に比べて，\n\n3時に寝て1時に起きるのもザラにあった生活が，12時には寝て10時には活動を始めているようになった．特に，午前中からだらけることなく研究に従事することができるようになった．\n1日2食（昼に当たる時間と晩）でも胃もたれしたり，冷たいものを飲み過ぎて戻してしまうことがしばしばあった生活が，1日3食がっつり食べるようになった．それで居て胃もたれもなく，冷たい飲み物が苦手ということも無くなった．\n急に立ち上がったり，電車から降りて階段を登ったりするタイミングで目の前が見えなくなるほどの立ちくらみがすることがよくあった（週の2,3回ほど）が，今では1度もなければ前兆もない．\n以前は週1回ランニングに出れば良い方だったが，今では外出しない日は殆どランニングに出ている．\n結果，「やられっぱなしにはならず耐える」ことが人生の中心になっていたが，いまでは「自分の手で人生を変えていける」という感覚を得ることが出来ている．\n\n正直これほどの変化が起こるとは思わなかったし，すでに２週間近く全くブレずに持続している．自分のこれまでの人生から見ても，これからを思っても，これほど効果覿面な投資もなかったと思うので，10月に導入して良かったものベスト5を書きおこうと思う．"
  },
  {
    "objectID": "posts/2023/2023-11-5/index.html#何が起こったか",
    "href": "posts/2023/2023-11-5/index.html#何が起こったか",
    "title": "俺の人生を変えたものTop5",
    "section": "",
    "text": "９月の京都学会→台湾研修（３週間）から帰ってきて，最初に手をつけたのが家の片付けであった．不要な本は全て売り（段ボール5箱），粗大ゴミを8000円分捨て，古着も処分した．特に，半ば物置と化していた和室をリフォームし，自分の書斎として使えるようにした．結果，11月を迎えた今，8月までの生活に比べて，\n\n3時に寝て1時に起きるのもザラにあった生活が，12時には寝て10時には活動を始めているようになった．特に，午前中からだらけることなく研究に従事することができるようになった．\n1日2食（昼に当たる時間と晩）でも胃もたれしたり，冷たいものを飲み過ぎて戻してしまうことがしばしばあった生活が，1日3食がっつり食べるようになった．それで居て胃もたれもなく，冷たい飲み物が苦手ということも無くなった．\n急に立ち上がったり，電車から降りて階段を登ったりするタイミングで目の前が見えなくなるほどの立ちくらみがすることがよくあった（週の2,3回ほど）が，今では1度もなければ前兆もない．\n以前は週1回ランニングに出れば良い方だったが，今では外出しない日は殆どランニングに出ている．\n結果，「やられっぱなしにはならず耐える」ことが人生の中心になっていたが，いまでは「自分の手で人生を変えていける」という感覚を得ることが出来ている．\n\n正直これほどの変化が起こるとは思わなかったし，すでに２週間近く全くブレずに持続している．自分のこれまでの人生から見ても，これからを思っても，これほど効果覿面な投資もなかったと思うので，10月に導入して良かったものベスト5を書きおこうと思う．"
  },
  {
    "objectID": "posts/2023/2023-11-5/index.html#スタンディングデスクの導入",
    "href": "posts/2023/2023-11-5/index.html#スタンディングデスクの導入",
    "title": "俺の人生を変えたものTop5",
    "section": "１．スタンディングデスクの導入1",
    "text": "１．スタンディングデスクの導入1\n\n\n\n\nStanding Desk\n\n\nこれが俺の生活を根底から変えてしまった．\n１週間ほどかけて物置状態の和室にスタンディングデスクを導入し，書斎として使えるようにした．すると，朝ご飯から研究が，晩御飯から読書が，シームレスに繋がるようになった．特に何もせずにだらだらしていた時間がまるごと消えてしまった．外から家に帰ってきて，風呂に入るわけでもなくソファに座ってだらだらしているようなことも減った．\nあとから思えば，朝起きて研究に取りかかれない理由のうち殆どの部分が「日当たりのない部屋で」「座るのが嫌だ」の２つの事項に帰することが出来たのだ．私の部屋は北向きで窓はあれど殆ど陽は入らず，一方で和室はリビングに繋がっており，大きな窓から朝日が差し込んでくる．午前中に自宅で勉強する行為は人生全体で見て殆ど初めてのことだったが，心の底から幸せだと感じた．\nまた，睡眠の改善は，後述の睡眠グッズの影響も大きいだろうが，朝日当たりの良い場所で研究・読書をすることで，午前中から太陽の光を浴びるようになったことによる影響も大きいだろうと思われる．\nさらに，筆者はオンライン授業を聞くのが極めて苦手で，全く集中できない上に他のことをがっつりやることも出来ない，大きなストレス源であったが，スタンディングデスクであると自然な形で聴くことができる．\nこのような例もあるのだ．「ダラダラしてしまうのは自分が臆病だからだ」とか，「朝に弱いのだ」などと早合点せず，もっと早くスタンディングデスクを導入して，自宅内にも２箇所勉強できる場所を用意しておけば良かったと今では思う．疲れたら立って／座ってみるだけでギアが変わるように集中力が持続する．スタンディングデスクにステッパーを組み合わせて，歩きながら作業できるようにすると雑務にもストレスが溜まらない．"
  },
  {
    "objectID": "posts/2023/2023-11-5/index.html#段ハンガーラック",
    "href": "posts/2023/2023-11-5/index.html#段ハンガーラック",
    "title": "俺の人生を変えたものTop5",
    "section": "２．２段ハンガーラック2",
    "text": "２．２段ハンガーラック2\n【ポール径25mm】 エリソン ハンガーラック ワードローブ [ホワイト] 幅110cm 3段 幅111×奥行41×高さ220cm EHE11213WH [EHE11183WH ADD-P45WH HP-110WH]| スチールラック・メタル製ラック通販のルミナスクラブ\n和室には他に本棚，ベッドと，この２段ハンガーラックが用意してある．縦方向に長い(220cmある)ために場所を取らないが，多くの衣服を収納できるし，何より取り出しやすい．これで散らかしがちだった服を一箇所に整理することが出来た．"
  },
  {
    "objectID": "posts/2023/2023-11-5/index.html#高反発マットレス",
    "href": "posts/2023/2023-11-5/index.html#高反発マットレス",
    "title": "俺の人生を変えたものTop5",
    "section": "３．高反発マットレス3",
    "text": "３．高反発マットレス3\n\nこれも全く予想外だった．マットレスを変えることが睡眠に影響を与えるとも思っていなかったし，「痩せている場合は低反発」というネット上の文句がやけに腑に落ちる部分もあったため，「高反発で本当に良かったのか？」と買ってからも逡巡していたが，「体圧分散マットレス」であれば高反発だろうと身体を痛めることはない．さらに筆者の場合は，高反発マットレスで寝起きした方が，身体が疲れていないと感じる．"
  },
  {
    "objectID": "posts/2023/2023-11-5/index.html#iotシーリングライト",
    "href": "posts/2023/2023-11-5/index.html#iotシーリングライト",
    "title": "俺の人生を変えたものTop5",
    "section": "４．IoTシーリングライト4",
    "text": "４．IoTシーリングライト4\n【調光調色 スマホ操作やタイマーが便利】6畳 LEDシーリングライト フラヴィア リモート リモコン付き IoT スマホで操作 おしゃれ 照明器具 リビング用 居間用 ダイニング用 食卓用 電気 寝室 一人暮らし シンプル 声で操作 子供部屋 間接照明 電灯-おしゃれ照明・ライトのBeauBelle（ボーベル）\n部屋のライトが音を出すようになったことがきっかけで買い替えたが，このライトは色の調整も可能でありながら，「朝９時に点灯させる」といったようなスケジューリングも可能である．\n実際明るくなったことで起きることはなかったが，起きた場合に二度寝することが減った．それも，不快感も特に強くなく，勝手に身体にエネルギーが起きてくれるのである．\nまた，集中する際は白色光で，寝る前は暖色で光の強さも弱めていくことで，自然な眠気を誘うこともできる．"
  },
  {
    "objectID": "posts/2023/2023-11-5/index.html#日13時間は水以外口に入れない時間を作る",
    "href": "posts/2023/2023-11-5/index.html#日13時間は水以外口に入れない時間を作る",
    "title": "俺の人生を変えたものTop5",
    "section": "５．1日13時間は水以外口に入れない時間を作る",
    "text": "５．1日13時間は水以外口に入れない時間を作る\nこれが今回唯一の自助努力となったが，最大の気づきでもあった．夜寝る前にラーメンや甘いものをつい食べがちになっていたが，その代わりに日中の摂取カロリーを増やし，（翌朝10時に朝ご飯を食べるとするならば）９時以降は水以外，口に何も入れないようにする．大事なのはカロリーを取らない点である．人体は，口腔内にカロリーを検出するだけで，それに合わせて胃も消化の必要を見越して胃液を分泌し，調和を図るようになっている．5\n思い返せば，小学校低学年までは胃腸が弱く，体調を崩した際は必ず嘔吐を繰り返した．その際に学んだ絶対の規則は「一度吐いたら６時間は何も食べないし何も飲まない」を徹底することであった．疲れさせてしまったら休ませることが人体の鉄則である．\n筆者の場合は夜はしっかり半日以上胃腸を休ませることにより，日中にフルパワーで活動させることができ，夜中にお腹が空くということは減ったのであった．\n正直、いまの自分は、昔の自分がなりたかった自分の最新バージョンに他ならない。己に恥じない毎日を過ごしたいと思う。"
  },
  {
    "objectID": "posts/2023/2023-11-5/index.html#footnotes",
    "href": "posts/2023/2023-11-5/index.html#footnotes",
    "title": "俺の人生を変えたものTop5",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFlexiSpot 電動昇降式デスクEF1↩︎\n【ポール径25mm】 エリソン ハンガーラック ワードローブ [ホワイト] 幅110cm 3段 幅111×奥行41×高さ220cm EHE11213WH [EHE11183WH ADD-P45WH HP-110WH] ↩︎\nGOKUMIN 高反発マットレス↩︎\nBeauBelle IoT シーリングライト Flavia bbs-095t↩︎\n関連する話はこのブログなどにも紹介されている．↩︎"
  },
  {
    "objectID": "posts/2023/2023-11-25/ParticleFilter.html",
    "href": "posts/2023/2023-11-25/ParticleFilter.html",
    "title": "粒子フィルターとは何か | About Particle Filter",
    "section": "",
    "text": "$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$"
  },
  {
    "objectID": "posts/2023/2023-11-25/ParticleFilter.html#背景",
    "href": "posts/2023/2023-11-25/ParticleFilter.html#背景",
    "title": "粒子フィルターとは何か | About Particle Filter（執筆中）",
    "section": "",
    "text": "フィルタ（濾波器）の第一義は，液体から不純物を取り除くための装置である．そのアナロジーで「フィルタリング問題」と言った場合は，信号処理の意味で電圧や電波の信号を「濾過」してノイズを除去し本当に欲しい部分を純粋化する営みのことを指す．特に，凡ゆる通信機器において装置の熱運動によるノイズが入ることは避けられぬ自然の摂理である．1\n従ってGaussが天体観測から「誤差論」として統計的推定理論を創始したように，通信と制御の分野では「時々刻々と受信するデータから時々刻々と変化する信号をどのようにうまく濾波するか」という独自の課題から，独自の理論が発展していった．特に，デジタル回路がない時代では，「どのような電気回路のシステムとして濾波機をデザインすれば良いか？」という電気工学的な回路設計の問題としての側面も大きかった．\nフィルタリングの問題を統計的技術で解くための理論2が，まず離散時間の場合が (Kolmogorov, 1941)，続いて連続時間の場合が (Wiener, 1949) によって模索された．3 しかし，このKolmogorov-Wiener理論では「信号とノイズの過程が定常である」という仮定を置いており，これが広い応用を阻んでいた．当時の技術（抵抗器やコンデンサーなど）で実装出来る範囲という制約がある以上，仕方ないことでもあったため，更なる理論的発展はデジタル技術の登場を待つ必要があった．\nトランジスタというデジタル技術が使われるようになると，「フィルタ（濾波器）」はアナログデジタル変換器，レジスタ，メモリ，マイクロプロセッサから構成されるようになり，物理的な姿は全く変わってしまった．その中で (Kalman, 1960) が，定常性の仮定が満たされない場合でも使えるアルゴリズムを提案すると，すぐにApollo計画に導入されるに止まらず，NASAのスペースシャトル，海軍の潜水艦などにも応用されていった．4\nこうして「フィルタ（濾波器）」の語は，「水を濾過する如く電圧情報のノイズを除去する機器」という類比から，デジタル技術の出現により更なる一段階の抽象化を受けて物理的実体も失い，「ノイズを除去してメッセージ部分をなるべく正確に推定するアルゴリズム」という完全に数学的で抽象的な存在として研究が進められていくことになる．\nこのKalman filterは素晴らしかった．だが，モデルが線型かつ正規である場合にしか使えない．そこで，計算機や情報通信技術の発展と共に複雑化していくシステム・データに併せて，様々なフィルターが考案されていく必要があるのである．5 これが統計計算の時代である．\n\n\n\n線型性や正規性の仮定を一才必要としない濾波アルゴリズムとして，(Gordon et al., 1993) がbootstrap filterという名前で発表し，角度観測のみを用いた物体追跡の問題への応用を付した．この角度情報のみから物体を追跡するという問題は古典的な非線型濾波問題で，従来の拡張Kalman filterの方法では精度が全く伸びず，これに比べてbootstrap filterでは圧倒的に性能が改善したのであった．リサンプリングは多項リサンプリングを採用しており，極めて実装が簡単という点も多くの応用を生んだ理由である．6\nなお，北川源四郎も同年（1993年）のカンファレンスでMonte Carlo filterの名前で同様のアルゴリズムを発表している．そのジャーナル版は (北川源四郎, 1996a)．7 日本語文献 (北川源四郎, 1996b) はウェブ上からも読める．\n\n\n\nまず，(Gordon et al., 1993) による粒子フィルターの考案は，防衛，特に物体追跡への応用が念頭にあり，これを扱った一冊の本もある (Ristic et al., 2004)．8\nこれに関連して，ロボティクス，HCI (Human-Computer Interaction) 分野への応用もなされている(岡兼司, 2005), (Wills & Schön, 2023)．\nファイナンスで扱う時系列は非線型性・非正規性を示すと同時にデータ数も多い．逐次推定のステップ数が増えようとも誤差が蓄積しない粒子フィルターが見事に推定を実行する．9\n加えて，マクロ経済学の分野で 動学的確率的一般均衡モデル の推定にも応用されている．このモデルは，非線型なミクロ経済学的モデルの上に構築された大規模なモデルで，非線型な1次条件を持つ．10 このような複雑なモデルでは一般にMCMC法では収束が遅いが，粒子フィルターに焼戻し法や並列計算を組み合わせることでこの問題を回避でき，さらに事後分布が多峰性を持つ場合でさえ有用である (Herbst-Schorfheide2013?)．\n近年ではエージェント・ベースド・モデルへの応用もある (Lux, 2018)．\n\n\n\nこうして，粒子フィルターは濾波問題の文脈で発明されたMonte Carlo法であるが，状態空間モデルに対する濾波に限らず，種々の設定での逐次的問題，更には逐次的構造を持たない一般の推定問題にも応用できる．この発展により，粒子フィルターはMCMCと合流して，ベイズ計算 の主要トピックの１つに躍り出た (Martin+2023-history?)．この意味で，粒子フィルターは広く逐次Monte Carlo法（Sequential Monte Carlo methods 略して SMC ）とも呼ばれる．11\n逐次的ではない通常の設定，いわば「静的」な設定の下でのBayes推論にSMCを用いる方法は (Chopin, 2002) が草分け的な仕事をした．この枠組みでは，Bayes事後分布 \\(\\pi(\\theta|y_1,\\cdots,y_N)\\) の近似において，途中の \\(\\pi(\\theta|y_1,\\cdots,y_n)\\) を経由して逐次的に近似することが，自然な計算コスト削減法として理解できる．\n\n\n\n粒子フィルターは高い汎用性の代償として，多数の粒子を用意したいなら計算量が多くなることを欠点に持つ．従って，粒子フィルターは，他の手法が実行不可能なほどの非線型性・非正規性を示す問題に（のみ）用いるべきというものである．が，CPUや並列計算の発展により十分な量の粒子を用意できる場面も増えたため，その問題点も形骸化してきてると言える．12\nまた，粒子フィルターは，観測 \\(Y_t\\) の次元が大きいなど，観測から得られる情報量が多く，尤度（ポテンシャル）の尖度が高いとき，多くの粒子が小さな荷重を持ってしまう．この状態は近似精度悪化の原因となり縮退と呼ばれる．13 そのような場合は，観測の情報を柔軟に取り入れた提案核を構築し，誘導粒子フィルターをうまく設計する必要がある．\n地球科学や天気予報の分野では \\(Y_t\\) は大きく（\\(10^7\\)を超えることもある），このような場合は粒子フィルターは実行可能でなくなる．加えてKalmanフィルターも行列計算の部分が実行不可能になり，アンサンブルKalmanフィルタという粒子法が用いられる．"
  },
  {
    "objectID": "posts/2023/2023-11-25/ParticleFilter.html#粒子フィルター入門",
    "href": "posts/2023/2023-11-25/ParticleFilter.html#粒子フィルター入門",
    "title": "粒子フィルターとは何か | About Particle Filter（執筆中）",
    "section": "2 粒子フィルター入門",
    "text": "2 粒子フィルター入門\n\n2.1 重点サンプリング\n\n\n2.2 逐次重点サンプリングの修正としての粒子フィルター\n逐次重点サンプリングは，次元が上がっていくにつれて分散が指数増大するという致命的欠点がある．18 そこで，「リサンプリング」（「選択（セレクション）」ともいう）という新たな機構を各段階に取り入れることを考える．この機構により，次元の呪いを克服し，推定精度が保たれるのであるが，一方で粒子の間に相関が導入されるために，理論的解析を困難にする．この点から粒子フィルターは「（平均場）相関粒子法」「遺伝型粒子フィルター」19 ともいう．20"
  },
  {
    "objectID": "posts/2023/2023-11-25/ParticleFilter.html#技術的障壁と今後の研究",
    "href": "posts/2023/2023-11-25/ParticleFilter.html#技術的障壁と今後の研究",
    "title": "粒子フィルターとは何か | About Particle Filter（執筆中）",
    "section": "3 技術的障壁と今後の研究",
    "text": "3 技術的障壁と今後の研究\n粒子フィルターの応用には次の点の研究が肝要である．21\n\n3.1 提案分布の取り方\nSection 1.7 で触れた通り，特に観測の情報量が大きい場合，提案分布の選び方が粒子フィルターの精度を大きく左右するが，この取り方について普遍的な指針というものが得られていない．\n(Guarniero et al., 2017) と (Heng et al., 2020) は提案分布にパラメトリックモデルを用意し，粒子推定量の分散を最小化するようにそのモデル内で逐次的に最適化していく機構を提案している．\n(Naesseth et al., 2015) が提唱するnested SMCは，は各時刻での提案分布を近似するために，もう一つのSMCを内部に走らせる．当然計算量は二倍になるが，それでも単純なbootstrap filterから大きく性能が改善する場合が多い．\n\n粒子フィルタを適用する際の課題の一つは，各粒子に割り当てられる重みが1粒子に集中する，いわゆる退化の問題を限られた数の粒子でいかに克服するかである．(上野玄太, 2019)\n\n\n\n3.2 部分的な線型構造の利用\n周辺化粒子フィルター，またはRao-Blackwellized particle filterとも呼ばれる方法である．これは多くの場面で，仮定されている状態空間モデルが部分的に線型である場合に，線型の部分をKalmanフィルターによって正確に解き，残った部分のみを粒子フィルターで解くことで，精度の向上とアルゴリズムの効率化を図る方法である．\n(Ristic et al., 2004, p. 287) では，探知前追跡 (track-before-detect) の問題22において，周辺化粒子フィルタが，必要な粒子数を大きく削減してくれることを紹介している．\nその他にも，問題毎の特有の構造を利用して計算量を削減・パフォーマンスを最適化することは重要な営みである．\n\n\n3.3 粒子数に関する漸近論\n目前の問題を，所与の精度で解くために必要な粒子数は幾ばくか？という問題は実用上も有益だと思われる．23\n\n\n3.4 属人化医療への応用\n筆者は属人化医療への応用が大きなモチベーションになっている．24\n病気の進行（あるいは健康）のモニタリングのために，健康診断やウェアラブルデバイス，フォローアップから得られるデータは，治療の見直しや異常の早期発見のために即時処理されることが望ましい．これに逐次モンテカルロ法でBayes的に迫る研究がある (Alvares et al., 2021) ！\nさらに，個々人の日常生活のレベルではSMCを用いているものはどうやらまだなく，運動と睡眠時間の間の関係と処置効果をMonte Carlo法を用いて推定している研究はある (Daza & Schneider, 2022)．これを逐次化することで，よりリアルタイムで自分に合った生活習慣への示唆が得られるアプリを開発できるかもしれない．\nまた，属人化医療においてはシステム生物学的なモデルに基づいた薬効推定が欠かせない．小規模な患者群と測定時間（服薬時間）に関する不確定性を考慮した手法が (Krengel et al., 2013) で考察されている．\n次世代DNAシークエンサーでは，DNAの各塩基ごとに異なる蛍光物質を結合させ，蛍光の波長と強度により塩基を読み取る仕組みであり，蛍光強度の生データからDNA配列データへ変換するベースコールと呼ばれる段階で粒子フィルターを使うことも提案されている (Shen & Vikalo, 2012)．\nまた，腫瘍サンプルに含まれる体細胞の突然変異に関するデータから，SMCを用いて腫瘍の発達と進行の状態を理解する手法も提案されている (Ogundijo et al., 2019)．\nCovid-19のようなパンデミックにおいて，疫学モデルを通じて時間変動する再生産数をリアルタイムでモニタリングをして意思決定に繋げるためのSMC手法も考えられており，実際にノルウェーで使用され有効性が実証された (Strovik et al., 2023)．\n状態空間が高次元になることと，既存のモデルを状態空間モデルに定式化することに困難が伴うことが，朧げながら共通課題のように思われるが，その現れ方と解決法は個々の事例で異なる．"
  },
  {
    "objectID": "posts/2023/2023-11-25/ParticleFilter.html#footnotes",
    "href": "posts/2023/2023-11-25/ParticleFilter.html#footnotes",
    "title": "粒子フィルターとは何か | About Particle Filter",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(Anderson & Moore, 1979) 第1.1節．↩︎\n(有本卓, 1970)．↩︎\nこのフィルタリング問題の統計的な側面を，前述の電気工学的な側面から区別して，stochastic filteringと呼んだりもする．↩︎\n(Bain & Crisan, 2009) 1.3節．↩︎\n(青山友紀, 1986) 「当初は大型コンピュータを用いたシミュレーションの技法であったディジタルフィルタが，今では超LSI 1チップで実現されるまでになった．」他にも，発表時1986年では，音声信号を中心とする低周波帯域ではデジタルフィルタがアナログフィルタを駆逐しつつあること，通信システムのデジタル化に伴ってこの勢いは完全に代替するまで進むだろうとの筆者の考えが述べられている．↩︎\n(McGee & Schmidt, 1985) がNASAからの資料．また，(Del Moral & Penev, 2014) も参照．加えて，(Kalman, 1960) からちょうど10周年の文献 (有本卓, 1970) に当時の雰囲気も感じさせる良いサーベイがある．↩︎\n(Ristic et al., 2004, p. 3) “The state-space approach is convenient for handling multivariate data and nonlinear/non-Gaussian processes and it provides a significant advantage over traditional time-series techniques for these problems.”↩︎\n(Rabiner, 1989)．(Gales & Young, 2007) には “almost all present day large vocabulary continuous speech recognition (LVCSR) systems are based on HMMs” とある．↩︎\n(Kitagawa, 1998) で指摘されている．↩︎\nまた，同様にアポロ計画の中で，飛行体に載積出来るような小規模な計算資源と短い単語長でも安定してKalman filterが動くように，共分散行列の二乗根を保持するという “square-root” formulation of the filter が 1972年に考案されたことが，summary でも触れられている (McGee & Schmidt, 1985)．↩︎\n(S. J. Julier & Uhlmann, 2004, p. 402) など．拡張 Kalman filter は遷移関数を線型近似することに基づく．よって Jacobi 行列の計算が必要であり，このため 解析的方法 とも呼ばれる (Ristic et al., 2004, p. 21)．よって遷移関数が可微分でない場合も実行不可能である．とはいっても，拡張 Kalman filter はナビゲーションシステムや GPS のデファクトスタンダードである Wikipedia．(Ristic et al., 2004) 第7章では距離のみでの追跡 (range-only tracking) では拡張 Kalman filter の性能と大差なく，計算量の問題から EKF の選択を推奨している．第8章でも弾道物体追跡の問題で，限られた設定では粒子フィルターと同等の性能を見せている．↩︎\n(Ristic et al., 2004, p. 16)．↩︎\nこの結果は (Chopin & Papaspiliopoulos, 2020) 第5章 など．記法 \\(Y_{0:t}\\) は 本サイトの数学記法一覧 を参照↩︎\n(Crisan & Doucet, 2002) に3の数字が例示されている．↩︎\n(Chopin & Papaspiliopoulos, 2020) 第6章，(Ristic et al., 2004) 2.2節．↩︎\n(Ristic et al., 2004, p. 24)．↩︎\n(Ristic et al., 2004, p. 25)．↩︎\n(Gordon et al., 1993) の結果であると同時に，(Ristic et al., 2004) 第6章でも種々の手法と比較した数値実験がなされている．一方第7章にて，距離のみでの追跡 (range-only tracking) では拡張 Kalman filter の性能と大差なく，計算量の問題から EKF の選択を推奨している．↩︎\nDel MoralのWebサイトも歴史的背景に詳しい．↩︎\nweight degeneracy (Creal, 2011) p.253，(Cappé et al., 2005) 第7章，(Robert & Casella, 2004, p. 551) 14.3.3節 など．↩︎\nSIR (Sampling/Importance Resampling) Algorithm と呼ばれるものであった．これの逐次化が粒子フィルターだとみなせる (Robert & Casella, 2004, p. 552) 14.3.4節．↩︎\n(Del Moral & Doucet, 2014) などの用語である．↩︎\n(Del Moral & Horton, 2023) では mean-field type interacting particle methods と呼んでいる．呼び方については (Iba, 2001) と (Del Moral, 2013) と 紹介記事 も参照．↩︎\n(Creal, 2011) p.256．↩︎\n事前情報というのは，自動運転の文脈では自動車が動き得る領域というのは極めて限られている，というような事前に判明しているが，うまく取り入れにくい情報のことをいう．(Ristic et al., 2004) 第6章や第9章で繰り返し種々の設定で実証されている．(Yang et al., 2023) は水中での物体追跡が縮退により従来は粒子フィルタが使えなかった問題の解決を試みている．(Kummert et al., 2021) はロボット支援を用いた手術中に物体追跡を利用する際に，尤度が低すぎるなどの要素から追跡対象を失った状態を検出してアラートを出す機構を開発している．↩︎\nファイナンスにおける確率的ボラティリティモデルなどの例が挙げられている (Creal, 2011) p.256．↩︎\n粒子フィルターの経済学での応用が増えたきっかけが Fernández-Villaverde and Rubio-Ramírez (2005, 2007) による（小規模な）DSGEモデルの推定への応用だった (Creal, 2011, p. 246)．(矢野浩一, 2014) は実物景気循環モデル (Real Business Cycles Model) への応用を解説している．↩︎\n(Crisan & Doucet, 2002) ではすでに SMC とも呼ばれることが記されている．(Chopin & Papaspiliopoulos, 2020) 第3章にSMCのフィルタリング以外の多くの応用が紹介されている．↩︎\n(Behrens et al., 2012) はいずれも用いている．(Hamze & de Freitas, 2005) に tempered distribution の語用法がある，↩︎\n(Chopin & Papaspiliopoulos, 2020, pp. 3.4節 p.30)↩︎\n疾病マッピングは疾病の空間的な分布を把握すること，画像解析とは画像データから特徴を抽出してその意味論を理解することを指す．↩︎\n(Iba, 2001), (Kremer & Binder, 1988) などが良いレビューを提供している．(Assaraf et al., 2000) が量子系のシミュレーションの文脈で．↩︎\ndiffusion Monte Carlo, projector Monte Carlo などと呼ばれる手法に等しい．Green’s function Monte Carlo もポテンシャル \\(G\\) の取り方が違うのみである (Assaraf et al., 2000)．また (Iba, 2001) 3.1節 p.282 にも言及がある．↩︎\n(Iba, 2001) 3.1節 p.281．↩︎\n(矢野浩一, 2014) p.190，(Ristic et al., 2004) 前文 p.xi．↩︎\n(Chopin & Papaspiliopoulos, 2020, pp. 19.1節 p.371), (Creal, 2011, pp. 2.5.1節 p.258)．↩︎\n(Del Moral & Doucet, 2014) など．↩︎\n(Iba, 2001) などでは population Monte Carlo と呼ばれている．↩︎\nそのアイデアは (Doucet et al., 2001, pp. 79–95) 第4章 から．(Crisan & Doucet, 2002) も参照．↩︎\n探知前追跡とは，信号が弱い，またはノイズが強い環境下において，信頼のおける初期信号を頼りにせずとも，物体追跡を実行するための手法．↩︎\n(Ristic et al., 2004, p. 288) に示唆されている．↩︎\n(Del Moral & Horton, 2023) は ensemble Kalman particle filtering methodology と呼んでいる．↩︎\n過去の記事でも触れた．↩︎"
  },
  {
    "objectID": "posts/2023/2023-11-22/独立性.html",
    "href": "posts/2023/2023-11-22/独立性.html",
    "title": "正規標本の標本平均と標本分散が独立であることの証明",
    "section": "",
    "text": "次の命題の証明を与える．\nなお，この性質は正規分布を特徴付ける (Kawata & Sakamoto, 1949)．"
  },
  {
    "objectID": "posts/2023/2023-11-22/独立性.html#sec-1",
    "href": "posts/2023/2023-11-22/独立性.html#sec-1",
    "title": "正規標本の標本平均と標本分散が独立であることの証明",
    "section": "1 Helmert変換による証明",
    "text": "1 Helmert変換による証明\n最も直接的で，示唆も深い． (竹村彰道, 2020) 第4.3節 pp.69-70 も参照．\n\n\n\n\n\n\n定義\n\n\n\n次のように定まる行列 \\(\\mathbb{H}\\in M_{N+1}(\\mathbb{R})\\) を Helmert行列 という．2 最初の行を \\[\\mathbb{H}_{1,j}:=\\frac{1}{\\sqrt{N+1}},\\qquad 1\\le j\\le N+1,\\] とし，それ以下の行を \\[\\mathbb{H}_{i,j}:=\\overline{\\mathbb{H}}_{i,j}:=\\begin{cases}\n\\frac{1}{\\sqrt{i(i-1)}}&1\\le j&lt;i,\\\\\n-\\frac{i-1}{\\sqrt{i(i-1)}}&j=i,\\\\\n0&i&lt;j\\le N+1.\n\\end{cases}\\] と定める．このとき， \\[\\mathbb{H}=\\begin{pmatrix}\\frac{\\boldsymbol{1}_{N+1}^\\top}{\\sqrt{N+1}}\\\\\\overline{\\mathbb{H}}\\end{pmatrix}\\] と表せる．3\n\n\n\n\n\n\n\n\n補題\n\n\n\nHelmert行列 \\(\\mathbb{H}\\in M_{N+1}(\\mathbb{R})\\) とその部分行列 \\(\\overline{\\mathbb{H}}\\in M_{N,N+1}(\\mathbb{R})\\) について，\n\n直交行列である．\n次を満たす：\\[\\overline{\\mathbb{H}}^\\top\\overline{\\mathbb{H}}=I-\\frac{1}{N+1}J=\\epsilon.\\]\n\nただし，次のように定めた： \\[\n\\epsilon:=I_{N+1}-\\frac{J_{N+1}}{N+1},\\qquad J_{N+1}:=\\boldsymbol{1}_{N+1}\\boldsymbol{1}_{N+1}^\\top.\n\\]\n\n\\(x,y\\in\\mathbb{R}^{N+1}\\) に対して， \\(x^\\top\\epsilon y=(x-\\overline{x}\\boldsymbol{1}_{N+1})^\\top(y-\\overline{y}\\boldsymbol{1}_{N+1})\\)\n\n\n\n\n\n\n\n\n\n証明（補題）\n\n\n\n\\(\\mathbb{H}\\) を具体的に書けば，\n\\[\n\\mathbb{H}:=\\begin{pmatrix}\\frac{1}{\\sqrt{N+1}}&\\frac{1}{\\sqrt{N+1}}&\\frac{1}{\\sqrt{N+1}}&\\frac{1}{\\sqrt{N+1}}&\\cdots&\\cdots&\\frac{1}{\\sqrt{N+1}}\\\\\n\\frac{1}{\\sqrt{2}}&-\\frac{1}{\\sqrt{2}}&0&0&\\cdots&\\cdots&0\\\\\n\\frac{1}{\\sqrt{6}}&\\frac{1}{\\sqrt{6}}&-\\frac{2}{\\sqrt{6}}&0&\\cdots&\\cdots&0\\\\\n\\vdots&\\vdots&\\vdots&\\vdots&\\ddots&\\ddots&\\vdots\\\\\n\\frac{1}{\\sqrt{k(k-1)}}&\\cdots&\\frac{1}{\\sqrt{k(k-1)}}&\\frac{1-k}{\\sqrt{k(k-1)}}&0&\\cdots&0\\\\\n\\vdots&\\ddots&\\vdots&\\vdots&\\ddots&\\ddots&\\vdots\\\\\n\\frac{1}{\\sqrt{N(N+1)}}&\\cdots&\\cdots&\\cdots&\\cdots&\\frac{1}{\\sqrt{N(N+1)}}&\\frac{N}{\\sqrt{N(N+1)}}\n\\end{pmatrix}\n\\]\n\n\\(\\mathbb{H}\\) の任意の行は正規化されており，異なる行の間の内積は必ず零になることはすぐに判る．よって， \\(\\mathbb{H}\\mathbb{H}^\\top=I\\)．列についても同様であることが， \\[\n\\frac{1}{N+1}+\\sum_{k=1}^N\\frac{1}{k(k+1)}=1\n\\] に注意すれば同様に判る．よって，\n\n\\[\n\\mathbb{H}\\mathbb{H}^\\top=I=\\mathbb{H}^\\top\\mathbb{H}=\\frac{1}{N+1}J+\\overline{\\mathbb{H}}^\\top\\overline{\\mathbb{H}}.\n\\]\n\n1.の最後の等式から従う．なお，1.の最後の等式は次のように判る：\n\n\\[\n\\left(\\frac{\\boldsymbol{1}_{N+1}}{\\sqrt{N+1}}\\;\\overline{\\mathbb{H}}^\\top\\right)\\begin{pmatrix}\\frac{\\boldsymbol{1}_{N+1}^\\top}{\\sqrt{N+1}}\\\\\\overline{\\mathbb{H}}\\end{pmatrix}=\\frac{\\boldsymbol{1}_{N+1}\\boldsymbol{1}_{N+1}^\\top}{N+1}+\\overline{\\mathbb{H}}^\\top\\overline{\\mathbb{H}}.\n\\]\n\n\\(\\epsilon=I_{N+1}-\\frac{\\boldsymbol{1}_{N+1}\\boldsymbol{1}_{N+1}^\\top}{N+1}\\) を具体的に書けば \\[\n\\epsilon=\\begin{pmatrix}\n\\frac{N}{N+1}&-\\frac{1}{N+1}&-\\frac{1}{N+1}&\\cdots&-\\frac{1}{N+1}\\\\\n-\\frac{1}{N+1}&\\frac{N}{N+1}&-\\frac{1}{N+1}&\\cdots&-\\frac{1}{N+1}\\\\\n\\vdots&\\ddots&\\ddots&\\ddots&\\vdots\\\\\n-\\frac{1}{N+1}&\\cdots&\\cdots&-\\frac{1}{N+1}&\\frac{N}{N+1}\n\\end{pmatrix}\n\\]\n\nとなるから， \\[\n\\begin{align*}\nx^\\top\\epsilon y&=\\frac{1}{N+1}(x_1\\;\\cdots\\;x_{N+1})\\begin{pmatrix}(N+1)y_1-\\sum_{i=1}^{N+1}y_i\\\\\\vdots\\\\(N+1)y_{N+1}-\\sum_{i=1}^{N+1}y_i\\end{pmatrix}\\\\\n&=\\frac{1}{N+1}\\left((N+1)\\sum_{i=1}^{N+1}x_iy_i-\\left(\\sum_{i=1}^{N+1}x_i\\right)\\left(\\sum_{i=1}^{N+1}y_i\\right)\\right)\\\\\n&=\\sum_{i=1}^{N+1}x_iy_i-(N+1)\\overline{x}\\cdot\\overline{y}\\\\\n&=\\sum_{i=1}^{N+1}(x_iy_i-\\overline{x}\\overline{y})\\\\\n&=\\sum_{i=1}^{N+1}(x_i-\\overline{x})(y_i-\\overline{y})\\\\\n&=(x-\\boldsymbol{1}_{N+1}\\overline{x})^\\top(y-\\boldsymbol{1}_{N+1}\\overline{y}).\n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\n証明\n\n\n\n\\(\\mu=0,\\sigma^2=1\\) と仮定して示せば， 一般の \\(X_i\\) に対しても \\(\\frac{X_i-\\mu}{\\sigma}\\sim\\mathrm{N}(0,1)\\) に対して同様の議論をすることで一般の場合の結果も得る．\n\\[X_{1:N+1}:=\\begin{pmatrix}X_1\\\\\\vdots\\\\X_{N+1}\\end{pmatrix}\\sim\\mathrm{N}_{N+1}(0,I_{N+1})\\]\nに対して， \\(Y_{1:N+1}:=\\mathbb{H}X_{1:N+1}\\) と定めると， \\(\\mathbb{H}\\) は直交行列だからやはり \\(Y\\sim\\mathrm{N}_{N+1}(0,I_{N+1})\\)．加えて，\\(\\mathbb{H}\\) の構成から \\[\nY_0=\\frac{\\boldsymbol{1}_{N+1}^\\top}{\\sqrt{N+1}}X_{1:N+1}=\\sqrt{N+1}\\cdot\\overline{X}\n\\] が成り立っている．\n補題の2.と3.から， \\(Y_{2:N+1}=\\overline{\\mathbb{H}}X_{1:N+1}\\) に注意して， \\[\n\\begin{align*}\n\\|Y_{2:N+1}\\|^2&=(\\overline{\\mathbb{H}}X_{1:N+1})^\\top(\\overline{\\mathbb{H}}X_{1:N+1})\\\\\n&=X_{1:N+1}^\\top(\\overline{\\mathbb{H}}^\\top\\overline{\\mathbb{H}})X_{1:N+1}\\\\\n&=X_{1:N+1}^\\top\\epsilon X_{1:N+1}=\\|X_{1:N+1}-\\overline{X}\\boldsymbol{1}_{N+1}\\|^2\\\\\n&=\\sum_{i=1}^{N+1}(X_i^2-\\overline{X}^2)\\\\\n&=\\sum_{i=1}^{N+1}(X_i-\\overline{X})^2=NU^2.\n\\end{align*}\n\\]\n以上より， \\(\\overline{X}\\) は \\(Y_1\\) のみの関数で， \\(S^2,U^2\\) は \\(Y_{2:N+1}\\) のみの関数であるから，互いに独立である．"
  },
  {
    "objectID": "posts/2023/2023-11-22/独立性.html#basuの定理による証明",
    "href": "posts/2023/2023-11-22/独立性.html#basuの定理による証明",
    "title": "正規標本の標本平均と標本分散が独立であることの証明",
    "section": "2 Basuの定理による証明",
    "text": "2 Basuの定理による証明\n\n\n\n\n\n\n(Basu, 1955)\n\n\n\n\\(\\{P_\\theta\\}_{\\theta\\in\\Theta}\\) を分布族， \\((\\mathcal{X},\\mathcal{A}),(\\mathcal{T},\\mathcal{B}),(\\mathrm{V},\\mathcal{C})\\) を可測空間とする． \\(T:\\mathcal{X}\\to\\mathcal{T}\\) を \\(\\{P_\\theta\\}_{\\theta\\in\\Theta}\\) の完備十分統計量，統計量 \\(V:\\mathcal{X}\\to\\mathrm{V}\\) の分布 \\(P^V_\\theta\\) は \\(\\theta\\) に依らないとする．4 このとき，任意の \\(\\theta\\in\\Theta\\) に対して，\\(T\\) と \\(V\\) は独立である： \\[P_\\theta[T\\in A,V\\in B]=P_\\theta[T\\in A]P_\\theta[V\\in B]\\qquad(A\\in\\mathcal{B},B\\in\\mathcal{C},\\theta\\in\\Theta)\\]\n\n\n\n\n\n\n\n\n証明（Basuの定理）\n\n\n\n仮定より，\\(p_B:=P_\\theta[V\\in B]\\in\\mathbb{R},q_B(T):=P_\\theta[V\\in B|T]:\\mathcal{X}\\to\\mathbb{R}\\) は \\(\\theta\\in\\Theta\\) に依らない． これに対して，条件付き期待値の性質から \\[p_B=E_\\theta[1_B(V)]=E_\\theta[E_\\theta[1_B(V)|T]]=E_\\theta[q_B(T)]\\] であるから，\\(E_\\theta[p_B-q_B(T)]=0\\) が従う． 完備性から，\\(P_\\theta[p_B=q_B(T)]=1\\)．よって，任意の \\(\\theta\\in\\Theta\\) について， \\[\\begin{align*}\n    P_\\theta[T\\in A,V\\in B]&=E_\\theta[1_A(T)1_B(V)]\\\\\n    &=E_\\theta[1_A(T)E_\\theta[1_B(V)|T]]\\\\\n    &=E_\\theta[1_A(T)q_B(T)]\\\\\n    &=E_\\theta[1_A(T)p_B]\\\\\n    &=E_\\theta[1_A(T)]p_B\\\\\n    &=P_\\theta[T\\in A]P_\\theta[V\\in B].\n\\end{align*}\\]\n\n\nこれを用いて，次のように証明できる．\n\n\n\n\n\n\n証明\n\n\n\n\n標本平均は平均の完備十分統計量である\n標本分散は平均の補助統計量である\n\nの2点を示せば，Basuの定理から，標本平均と標本分散は独立である：\\(\\overline{X}\\perp\\!\\!\\!\\perp S^2\\)． 同様にして，標本平均と不偏分散も独立である．\n\n分布族 \\(\\{\\mathrm{N}(\\mu,\\sigma^2)^{\\otimes n}\\}_{\\mu\\in\\mathbb{R}}\\) は指数型であり， 統計量 \\[T_1(x):=\\sum_{i\\in[n]}x_i=n\\overline{X}\\] は \\(\\mu\\) の完備十分統計量である．\n標本分散の分布は \\[S^2:=\\frac{1}{n}\\sum_{i\\in[n]}(X_i-\\overline{X})^2\\sim\\chi^2(n-1)\\] より，パラメータ\\(\\mu\\in\\mathbb{R}\\)に依らない．"
  },
  {
    "objectID": "posts/2023/2023-11-22/独立性.html#fisher-cochranの定理の考え方",
    "href": "posts/2023/2023-11-22/独立性.html#fisher-cochranの定理の考え方",
    "title": "正規標本の標本平均と標本分散が独立であることの証明",
    "section": "3 Fisher-Cochranの定理の考え方",
    "text": "3 Fisher-Cochranの定理の考え方\n総合研究大学院大学統計科学コース2021年8月実施の入試問題の第三問にて，本命題を背景とした問題が出題された．このアプローチは 節 1 の証明法を別の角度から見れる．5\n\n\n\n\n\n\n補題\n\n\n\n\\[X_{1:n}=\\begin{pmatrix}X_1\\\\\\vdots\\\\X_n\\end{pmatrix},\\qquad X_i\\overset{\\text{iid}}{\\sim}\\mathrm{N}(\\mu,\\sigma^2),\\] をGauss確率ベクトル，\\(B\\in M_{mn}(\\mathbb{R}),A\\in M_n(\\mathbb{R})\\) を対称行列とする．\\(BA=O_{m,n}\\) のとき，2つの確率変数 \\(BX_{1:n}\\) と \\(X^\\top_{1:n} AX_{1:n}\\) とは独立になる．\n\n\n\n\n\n\n\n\n証明（補題）\n\n\n\n\\(A\\) は対称行列だから，ある直交行列 \\(U\\in \\mathrm{O}_n(\\mathbb{R}),U^\\top U=I_n\\) を用いて，\\(U^\\top DU=A\\) と対角化出来る．ただし， \\(D:=\\mathrm{diag}(a_1,\\cdots,a_r)\\in M_n(\\mathbb{R}),r:=\\mathop{\\mathrm{\\mathrm{rank}}}A\\) は対角行列とした． よって，\\(Y_{1:n}:=UX_{1:n}\\) と定めると，これは再び成分が互いに独立な正規確率変数のベクトル \\(Y_{1:n}\\sim\\mathrm{N}_n(\\mu U1_n,\\sigma^2I_n)\\) で， \\[X_{1:n}^\\top AX_{1:n}=(UX_{1:n})^\\top D(UX_{1:n})=a_1Y_1^2+\\cdots+a_rY_r^2,\\] と表せる．\n次に，\\(BA=0\\) より，\\(\\mathrm{Im}\\,A\\subset\\mathrm{Ker}\\;B\\)，従って双方の直交補空間を考えると \\(\\mathrm{Im}\\,B\\subset\\mathrm{Ker}\\;A\\) でもあるから，\\(BX_{1:n}\\) は \\(y_{r+1},\\cdots,y_{n}\\) のみによって表せる確率変数のベクトルである（使わないものも許す）． よって，\\(BX_{1:n}\\) と \\(X_{1:n}^\\top AX_{1:n}\\) は独立．\n\n\n\n\n\n\n\n\n証明\n\n\n\n\\(m=1,B:=\\frac{1}{N+1}1_{N+1}^\\top\\) と \\[A:=N\\epsilon=\\frac{N}{N+1}\\begin{pmatrix}\nN&-1&-1&\\cdots&-1\\\\\n-1&N&-1&\\cdots&-1\\\\\n\\vdots&\\ddots&\\ddots&\\ddots&\\vdots\\\\\n-1&\\cdots&\\cdots&-1&N\n\\end{pmatrix}\\in M_{N+1}(\\mathbb{R})\\] と定めると，\\(BA=O\\) であり，同時に \\(\\overline{X}=BX_{1:N+1}\\) かつ \\(U^2=X^\\top_{1:N} AX_{1:N}\\) である．"
  },
  {
    "objectID": "posts/2023/2023-11-22/独立性.html#footnotes",
    "href": "posts/2023/2023-11-22/独立性.html#footnotes",
    "title": "正規標本の標本平均と標本分散が独立であることの証明",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n\\(U^2\\) は不偏分散と呼ばれる統計量である．代わりに標本分散 \\(S^2:=\\frac{1}{N+1}\\sum_{i=1}^{N+1}(X_i-\\overline{X})^2\\) を考えても同様の主張 \\(\\overline{X}\\perp\\!\\!\\!\\perp S^2\\) を得る．↩︎\n(Del Moral & Horton, 2023) も参照．↩︎\n\\(\\boldsymbol{1}_{N+1}\\) は \\(1\\) のみを成分に持つ \\(\\mathbb{R}^{N+1}\\) の元， \\(\\overline{\\mathbb{H}}\\) は行列 \\(\\overline{\\mathbb{H}}:=(\\overline{\\mathbb{H}}_{i,j})_{2\\le i\\le N+1,1\\le i\\le N+1}\\) とした．↩︎\nこのような性質を満たす統計量 \\(V\\) を分布族 \\(\\{P_\\theta\\}_{\\theta\\in\\Theta}\\) の補助統計量という．↩︎\n過去9年分の入試問題の解答はこちらから↩︎"
  },
  {
    "objectID": "posts/2023/2023-11-24/Beta-Gamma.html",
    "href": "posts/2023/2023-11-24/Beta-Gamma.html",
    "title": "確率測度の変換則 | Gamma分布とBeta分布を例に",
    "section": "",
    "text": "Gamma確率変数と，その変換として得るBeta確率変数とに関する次の命題の証明を与える．"
  },
  {
    "objectID": "posts/2023/2023-11-24/Beta-Gamma.html#gamma分布を見る",
    "href": "posts/2023/2023-11-24/Beta-Gamma.html#gamma分布を見る",
    "title": "確率測度の変換則 | Gamma分布とBeta分布を例に",
    "section": "1 Gamma分布を見る",
    "text": "1 Gamma分布を見る\n\n1.1 定義\n\n\n\n\n\n\n定義（Gamma分布）\n\n\n\n可測空間 \\((\\mathbb{R},\\mathcal{B}(\\mathbb{R}))\\) 上の Gamma分布 \\(\\mathrm{Gamma}(\\alpha,\\nu)\\;(\\alpha,\\nu&gt;0)\\) とは， 密度関数 \\[g(x;\\alpha,\\nu):=\\frac{1}{\\Gamma(\\nu)}\\alpha^\\nu x^{\\nu-1}e^{-\\alpha x}1_{\\left\\{x&gt;0\\right\\}}\\] が定める分布をいう．実際，\\(t=\\alpha x\\) と変数変換すると， \\[\n\\begin{align*}\n&\\quad\\int_0^\\infty \\alpha^\\nu x^{\\nu-1}e^{-\\alpha x}dx\\\\\n&=\\alpha^\\nu\\int^\\infty_0\\left(\\frac{t}{\\alpha}\\right)^{\\nu-1}e^{-t}\\frac{dt}{\\alpha}\\\\&=\\int^\\infty_0t^{\\nu-1}e^{-t}dt=\\Gamma(\\nu).\\end{align*}\\]\n\n\n\n\n1.2 形状\n\\(\\alpha\\) をレートパラメータ（スケールパラメータと呼ばれるものの逆数），\\(\\nu\\) を形状パラメータともいう．レートパラメータが大きいほど突起も大きく，手前に寄る．形状パラメータ \\(\\nu\\) は分布の形状を大きく司る．実際，先度と歪度は形状パラメータのみに依って \\[\\gamma_1=\\frac{2}{\\sqrt{\\nu}},\\qquad\\gamma_2=3+\\frac{6}{\\nu},\\] と記述される． その意味するところを感得するために，scipy.statsでの実装を用いてプロットしてみる．\n\n\nコードを表示\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import gamma\n\nnu = 1.5  # 形状パラメーター\n\n# Gamma分布のPDFをグリッド上で計算\nx = np.linspace(0, 8, 100)\npdf = gamma.pdf(x, nu)\n\n# プロットの実行\nplt.figure(figsize=(3.2, 4.8)) # スマホサイズに合わせる\nplt.plot(x, pdf)\nplt.title('Gamma(1,3/2) Distribution')\nplt.ylabel('Density')\nplt.xlabel('Value')\nplt.show()\n\n\n\n\n\nレートパラメータを固定し，形状パラメータを残した \\[\\chi^2(k):=\\mathrm{Gamma}(1/2,k/2)\\] を自由度 \\(k\\) のカイ自乗分布ということに注意．\n\n\n\n\n\n最後に，レートパラメータが大きいほど突起が大きくなる様子は次の通り：\n\n\n\n\n\nなお，形状パラメータが \\(\\nu=1\\) であるGamma分布のことを指数分布という： \\[\n\\mathrm{Exp}\\;(\\gamma):=\\mathrm{Gamma}(\\gamma,1)\\;(\\gamma&gt;0)\n\\]"
  },
  {
    "objectID": "posts/2023/2023-11-24/Beta-Gamma.html#beta分布を見る",
    "href": "posts/2023/2023-11-24/Beta-Gamma.html#beta分布を見る",
    "title": "確率測度の変換則 | Gamma分布とBeta分布を例に",
    "section": "2 Beta分布を見る",
    "text": "2 Beta分布を見る\n\n2.1 定義\n\n\n\n\n\n\n定義（Beta分布）\n\n\n\n可測空間 \\(((0,1),\\mathcal{B}((0,1)))\\)上の （第１種）ベータ分布 \\(\\mathrm{Beta}(\\alpha,\\beta)\\;(\\alpha,\\beta&gt;0)\\) とは， 密度関数 \\[\\frac{1}{B(\\alpha,\\beta)}x^{\\alpha-1}(1-x)^{\\beta-1}1_{(0,1)}(x)\\] が定める分布をいう．ただし，\\[B(\\alpha,\\beta)=\\int^1_0x^{\\alpha-1}(1-x)^{\\beta-1}\\,dx.\\]\n\n\n\n\n2.2 形状\n次のような性質を持つ：1\n\n\\(\\alpha_1=\\alpha_2=1\\) のとき一様分布となり，\\(\\alpha_1=\\alpha_2&gt;1\\) の場合に左右対称な単峰性分布，\\(\\alpha_1=\\alpha_2&lt;1\\) の場合に左右対称なU字型の二峰性分布を得る．\nいずれも \\(1\\) より大きい場合，左のパラメータが大きい場合 \\(\\alpha_1&gt;\\alpha_2&gt;1\\) 左に，右のパラメータが大きい場合 \\(\\alpha_2&gt;\\alpha_1&gt;1\\) 右に歪んだ単峰性分布を得る．\nいずれも \\(1\\) より小さい場合はその逆．"
  },
  {
    "objectID": "posts/2023/2023-11-24/Beta-Gamma.html#証明",
    "href": "posts/2023/2023-11-24/Beta-Gamma.html#証明",
    "title": "確率測度の変換則 | Gamma分布とBeta分布を例に",
    "section": "3 証明",
    "text": "3 証明\n\n\n\n\n\n\n証明\n\n\n\n\\[\\begin{cases}\n    X_1=\\frac{Y_1}{Y_1+Y_2},\\\\\n    X_2=Y_1+Y_2.\n\\end{cases}\\] を逆に解くことで， \\[\\begin{pmatrix}y_1\\\\y_2\\end{pmatrix}=\\begin{pmatrix}x_1x_2\\\\x_2\\end{pmatrix}=:T(x_1,x_2)\\] を得る．\\(A:=(0,1)\\times(0,\\infty),B:=(0,\\infty)^2\\) と定めると，\\(T:A\\to B\\) は可微分同相で，Jacobianは \\[DT=\\begin{pmatrix}x_2&x_1\\\\0&1\\end{pmatrix},\\qquad J_T=x_2,\\] と計算でき，\\(A\\) 上で は消えない．\nよって \\((X_1,X_2)\\) の結合分布は \\[\n\\begin{align*}\n    &p(T(x_1,x_2))J_T(x_1,x_2)dx_1dx_2\\\\\n    &=\\frac{\\alpha^{\\nu_1}}{\\Gamma(\\nu_1)}y_1^{\\nu_1-1}e^{-\\alpha y_1}\\frac{\\alpha^{\\nu_2}}{\\Gamma(\\nu_2)}y_2^{\\nu_2-1}e^{-\\alpha y_2}\\\\\n    &\\qquad\\times\\frac{x_2}{(1-x_1)^2}\\,dx_1dx_2\\\\\n    &=\\frac{\\alpha^{\\nu_1}}{\\Gamma(\\nu_1)}x_1^{\\nu_1-1}x_2^{\\nu_1-1}e^{-\\alpha x_1x_2}\\frac{\\alpha^{\\nu_2}}{\\Gamma(\\nu_2)}x_2^{\\nu_2-1}\\\\\n    &\\qquad\\times(1-x_1)^{\\nu_2-1}e^{-\\alpha x_2(1-x_1)}x_2\\,dx_1dx_2\\\\\n    &=\\underbrace{\\frac{\\Gamma(\\nu_1+\\nu_2)}{\\Gamma(\\nu_1)\\Gamma(\\nu_2)}}_{=B(\\nu_1,\\nu_2)^{-1}}x_1^{\\nu_1-1}(1-x_1)^{\\nu_2-1}\\,dx_1\\\\\n    &\\qquad\\times\\frac{\\alpha^{\\nu_1+\\nu_2}}{\\Gamma(\\nu_1+\\nu_2)}x_2^{(\\nu_1+\\nu_2)-1}e^{-\\alpha x_2}\\,dx_2.\n\\end{align*}\n\\] これは \\(X_1\\) が \\(\\mathrm{Beta}(\\nu_1,\\nu_2)\\) に，\\(X_2\\) が \\(\\mathrm{Gamma}(\\alpha,\\nu_1+\\nu_2)\\) に独立に従った場合の密度になっている．\n\n\n\n3.1 余談\n総合研究大学院大学統計科学コース2018年8月実施の入試問題の第三問にて，本命題を背景とした問題が出題された．2\n\n\n\n\n\n\n第３問\n\n\n\n\n数直線 \\(\\mathbb{R}\\) 上の点Pの \\(x\\) 座標 \\(X\\) は \\(\\mathrm{N}(0,1)\\) に従うとする． Pの原点からの距離の自乗の確率密度関数が \\[\\frac{1}{\\sqrt{2\\pi x}}e^{-\\frac{x}{2}},\\qquad(x&gt;0)\\] であることを示せ．\nEuclid空間 \\(\\mathbb{R}^n\\) 内の点Qの座標 \\((X_1,\\cdots,X_n)\\) は \\(\\mathrm{N}_n(0,I_n)\\) に従うとする． Qの原点からの距離の自乗の確率密度関数が \\[\\frac{1}{\\Gamma\\left(\\frac{n}{2}\\right)2^{\\frac{n}{2}}}x^{\\frac{n}{2}-1}e^{-\\frac{x}{2}},\\qquad(x&gt;0)\\] であることを示せ．\n(2)の確率密度関数を持つ分布を \\(\\chi^2(n)\\) という． 確率変数 \\(X,Y\\) は独立で \\(X\\sim\\chi^2(n),Y\\sim\\chi^2(m)\\) であるとする．このとき， \\[X+Y\\sim\\chi^2(n+m),\\] \\[\\frac{X}{X+Y}\\sim\\mathrm{Beta}(n/2,m/2),\\] であり，互いに独立であることを示せ．"
  },
  {
    "objectID": "posts/2023/2023-11-24/Beta-Gamma.html#余談",
    "href": "posts/2023/2023-11-24/Beta-Gamma.html#余談",
    "title": "独立なGamma確率変数の商による変換も独立",
    "section": "4 余談",
    "text": "4 余談\n総合研究大学院大学統計科学コース2018年8月実施の入試問題の第三問にて，本命題を背景とした問題が出題された．2\n\n\n\n\n\n\n第３問\n\n\n\n\n数直線 \\(\\mathbb{R}\\) 上の点Pの \\(x\\) 座標 \\(X\\) は \\(\\mathrm{N}(0,1)\\) に従うとする． Pの原点からの距離の自乗の確率密度関数が \\[\\frac{1}{\\sqrt{2\\pi x}}e^{-\\frac{x}{2}},\\qquad(x&gt;0)\\] であることを示せ．\nEuclid空間 \\(\\mathbb{R}^n\\) 内の点Qの座標 \\((X_1,\\cdots,X_n)\\) は \\(\\mathrm{N}_n(0,I_n)\\) に従うとする． Qの原点からの距離の自乗の確率密度関数が \\[\\frac{1}{\\Gamma\\left(\\frac{n}{2}\\right)2^{\\frac{n}{2}}}x^{\\frac{n}{2}-1}e^{-\\frac{x}{2}},\\qquad(x&gt;0)\\] であることを示せ．\n(2)の確率密度関数を持つ分布を \\(\\chi^2(n)\\) という． 確率変数 \\(X,Y\\) は独立で \\(X\\sim\\chi^2(n),Y\\sim\\chi^2(m)\\) であるとする．このとき， \\[X+Y\\sim\\chi^2(n+m),\\] \\[\\frac{X}{X+Y}\\sim\\mathrm{Beta}(n/2,m/2),\\] であり，互いに独立であることを示せ．"
  },
  {
    "objectID": "posts/2023/2023-11-24/Beta-Gamma.html#footnotes",
    "href": "posts/2023/2023-11-24/Beta-Gamma.html#footnotes",
    "title": "確率測度の変換則 | Gamma分布とBeta分布を例に",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(Agresti, 2012) 第1.6.2節 Binomial Estimation: Beta and Logit-Normal Prior Distributions p.24 参照．↩︎\n過去9年分の入試問題の解答はこちらから↩︎\n記法 \\(\\overset{\\sim}{\\to}\\) は 記法一覧 参照．↩︎\n会田先生講義ノート 定理5.1 など参照．↩︎\n最後から2番目の等号は，測度の押し出し \\(T^*\\pi\\) の定義である．↩︎"
  },
  {
    "objectID": "posts/2023/2023-12-8/Internet.html",
    "href": "posts/2023/2023-12-8/Internet.html",
    "title": "インターネットとは AS 間が BGP で相互接続された裏路地である",
    "section": "",
    "text": "登氏による総務省「西日本横断サイバーセキュリティ・グランプリ」講演資料 登大遊 (2023) 秘密のNTT電話局，フレッツ光，およびインターネット入門(1) という文献を，引用を交えながら，筆者が理解した事項を驚いた事項を紹介する．どんな内容が書いてあるかを概観してもらい，読者にも自分で興味のある箇所をぜひ読んでいただきたい．"
  },
  {
    "objectID": "posts/2023/2023-12-8/Internet.html#as-autonomous-system-とは何か",
    "href": "posts/2023/2023-12-8/Internet.html#as-autonomous-system-とは何か",
    "title": "インターネットとは AS 間が BGP で相互接続された裏路地である",
    "section": "1 AS (Autonomous System) とは何か？",
    "text": "1 AS (Autonomous System) とは何か？\n\nインターネットという連合体を形成する主体 1 つ 1 つを、「AS (Autonomous System: 自律システム) 」 という。自律システムとは、独立した領主・領土というような意味である。インターネット上の概念における主権を持っていて、他の主権者によって決して干渉されない。AS は、免許番号のような形で、整数の番号を持っている。これは AS 番号と呼ばれる。AS は、インターネット上の土地のような、「IP アドレス」というものを持っている。IP アドレスの種類としては、IPv4 と IPv6 とがある。バージョン 4 と 6 という意味である。西暦 1970 年代に成立した IPv4 アドレスというアドレス空間は、今となってはとても希少である。 (登大遊, 2023, p. 32)\n\n登氏はASがインターネット空間の主権者の最大単位だと表現している．筆者は現実空間における法人と自然人を混ぜて1つの概念とした，インターネット空間上の抽象的存在と理解している．例として，ソフトイーサ社がASとして他のどのASと接続されているかを，「米国 Hurricane Electric 社 (激安 ISP) の BGP Toolkit のページ 」（登さんの語彙）で確認出来る．\n\n自宅のコンピュータから、一度いずれかの AS の中にアクセスしたら (これは電話会社によって提供される。)、裏路地を通って世界中のすべての AS にアクセスできる。裏路地は、主体 (AS) がそれぞれ大変適当に提供し合っている。裏路地の責任主体は、極めて怪しい。裏路地を通るとき、色々な AS の土地を勝手に通過させてもらうことができる。何ら契約関係がなくても、通っていって良いのである。ただし、裏路地にはぬかるんでいる所があり、不快なこともあるが、無料なのでまあいいや、ということになる。この裏路地の存在が、インターネットの画期的な点である。 (登大遊, 2023, p. 37)\n\nつまり，NTTやその販売代理店が，光フレッツというFTTH(Fiber To The Home)サービスを通じて提供してくれるのは，光ファイバーによる物理通信環境と，ASとの最初の接続を提供してくれる，というわけである．しかしインターネットはすべての主体が相対的であり，自らがAS割り当てを受けて，最寄のASとの通信を確立させたら（筆者はどうやれば良いのかまだわからないが），自分もインターネット空間においてISPと全く変わらない主体になる，というわけであるようだ．\n光フレッツが電話会社から提供されているばかりに，一消費者としてはついつい強権的な存在を想定して，「インターネットは電話会社が接続させてくれるもの」と思いがちであるが，「インターネットのめんどくさいことを全部やってくれるスターターキット」以上の意味はないようである．この点が筆者にとって衝撃的であった．"
  },
  {
    "objectID": "posts/2023/2023-12-8/Internet.html#bgp-border-gateway-protocol-とは何か",
    "href": "posts/2023/2023-12-8/Internet.html#bgp-border-gateway-protocol-とは何か",
    "title": "インターネットとは AS 間が BGP で相互接続された裏路地である",
    "section": "2 BGP (Border Gateway Protocol) とは何か",
    "text": "2 BGP (Border Gateway Protocol) とは何か\nインターネット空間に存在する唯一のルールともいうべき，P2Pにおける通信規約である．登氏は「国境接続儀礼」と訳している．\n\nBGP を少し悪用すると、勝手に他の主体の IP アドレスを使うと宣言して、その IP アドレス宛の通信を全世界から全部引っ張り込むこともできてしまう。セキュリティ的に大変危険であるが、これはなかなか防げないので、問題になっている。 AS は国際社会における最上位の主権者であり、BGP は国際社会における事実上の法 (国際法) である。ある AS が BGP の法に違反したからといって取り締まられることがない (より上位の主体がないため)。ただし、「あの AS は法を遵守していない危険な AS だ。」 (例: Google の Public DNS サーバーの IP アドレス 8.8.8.8 を他の AS が勝手に名乗った) ということで、すぐに世界中に風評が伝わり、他のすべての AS から村八分にされることで、事実上隔離され、危険は回避される。インターネットにおける IP アドレスに基づく通信というのは、このように、大変にいい加減な仕組みである。 このあたりのインターネット基礎中の基礎を知らずに、日本警察のサイバー犯罪対策課などは、IP アドレスについては、Whois 台帳 (どの IP アドレスがどの組織に割当てられているかを管理する台帳) の記載を信用していて、事件に使われた IP アドレスが分かれば確実に通信者 (少なくともプロバイダ) が特定できるなどと誤解していて、これを疑うことをしない。Whois 台帳と、実際に誰が IP アドレスを使っていたかは、全く無関係である。少し自ら BGP をやってみればすぐに分かることである。ある土地で殺人事件が起きたときに、登記簿を見て、土地の所有者にお前が犯人だと言うようなものである。土地の登記簿と、その事件があったときに土地に誰がいたのかは、無関係である。ちなみに、日本の警察がサイバー、サイバーといっておきながら、サイバー空間の根本部分の基礎知識が分かっていないことは、無理もないことである。警察組織の中に通信技術やインターネット技術といったものの内側の知識習得や試行錯誤を行なう環境がこれまで存在しなかったからである。しかし、これからは真剣に勉強する意欲があるようなので、未来は明るい。 (登大遊, 2023, pp. 37–38)"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#ベイズ統計モデリングが理論モデルの実証に役立つ",
    "href": "posts/2023/2023-12-6/BayesianComp.html#ベイズ統計モデリングが理論モデルの実証に役立つ",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "3.4 ベイズ統計モデリングが理論モデルの実証に役立つ",
    "text": "3.4 ベイズ統計モデリングが理論モデルの実証に役立つ\nベイズモデリングの有用性は，（上述のベイズ計算の問題を除けば）どんなに複雑で大規模なモデルでも，統一的な思想と方法で対応できる点にある．\n\nメカニズムを明示的に表現した数理社会学の数理モデルを，論理的に飛躍することなくダイレクトに統計モデルへと接続できるベイズ統計モデリングは，理論モデルベースの実証研究と相性のよい，たいへん便利な方法と言えるだろう． (浜田宏, 2022, p. 137)\n\nMCMCの開発とパッケージへの実装，そして安価で高性能な計算機が普及してからというもの，ベイズ統計学の興隆は目覚ましく，現在ではベイズ統計学は統計学に関する論文の1割強を占め，諸科学分野全体に浸透しつつある．経済学・心理学への応用は早かったのに比べて，政治科学・社会科学への応用は遅れ気味であり，社会学での使用はまだ稀であると言える (Lynch & Bartlett, 2019)．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#ベイズが取り組んだ問題",
    "href": "posts/2023/2023-12-6/BayesianComp.html#ベイズが取り組んだ問題",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "1.2 ベイズが取り組んだ問題",
    "text": "1.2 ベイズが取り組んだ問題\nというわけで，\\(i=1,\\cdots,n\\) 番目の世帯の新生児が，男児である \\(y_i=1\\) か女児である \\(y_i=0\\) かのデータなどから，人口・疫病・国家動態に役立つ知識を引き出すことが当時の重要な問題意識であることをわかっていただけただろう．\nイギリスの牧師 Thomas Bayes 1701-1761 は，より抽象的な設定で統計的推定の問題を研究していた．Bayes は就中，次のような区間推定の問題を考えていた．\n\n$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$\n\n\n\n\n\n\n\nベイズが取り組んだ問題（現代語訳）\n\n\n\n2値のデータ \\(Y_i\\in\\{0,1\\}\\) は，ある未知の「成功率」 \\(\\theta\\in(0,1)\\) に従って， \\[\nY_i=\\begin{cases}\n1&\\text{確率 }\\theta\\text{ で}\\\\\n0&\\text{残りの確率} 1-\\theta\\text{ で}\n\\end{cases}\n\\] という値を取るとする．3 このようなデータの独立観測標本 \\(\\boldsymbol{y}:=(y_1,\\cdots,y_n)^\\top\\) から．神のみぞ知る，このデータ \\(\\boldsymbol{y}\\) を生み出した真の成功率 \\(\\theta\\) が，区間 \\((a,b)\\subset(0,1)\\) に入っているという確率 \\(\\mathrm{P}[a&lt;\\theta&lt;b|\\boldsymbol{y}]\\) をどう見積もれば良いか？\n\n\nここでは引き続き \\(Y_i\\) は性別で，\\(\\theta\\) は男児が生まれる確率 \\(\\theta=\\mathrm{P}[Y_i=1]\\) だと解釈する．Bayes 自身は「ある未知の位置に白線が引かれたテーブル上にボールを \\(n\\) 個転がし，それぞれの領域に幾つのボールが入ったかの情報のみから，白線の位置を推定する」という表現によって問題を定式化した (Bayes, 1763)．これは後世ではビリヤード台の問題とも呼ばれた．こちらのサイトも参照．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#ベイズによるベイズ計算",
    "href": "posts/2023/2023-12-6/BayesianComp.html#ベイズによるベイズ計算",
    "title": "ベイズ計算とは何か | About Bayesian Computation（執筆中）",
    "section": "",
    "text": "上述の理由により，Bayesが興味があった値 \\(\\mathrm{E}[1_{(a,b)}(\\theta)|\\boldsymbol{y}]\\) を実際に計算する方法が，論文 (Bayes, 1763) の大部分を占めることになる．\nまず，男児の数 \\[m:=\\#\\left\\{i\\in[n]\\mid y_i=1\\right\\}\\] が非常に多いか，非常に少ない場合については，被積分関数を二項展開して項別積分により計算することを提案した．しかしこの手法は明らかに今回の例では使えず（我々は男女の出生率にそこまで偏りがないことを経験的に知っている），真に興味のある場合を包含していない．\nこの真に興味のある一般的な場合については，Bayesは \\(\\mathrm{E}[g(\\theta)|\\boldsymbol{y}]\\) の値を上下から評価するにとどまった．\n\n\n\n\n\n\nベイズ計算の興り\n\n\n\nまとめると，Bayesのアプローチは非常に自然で，特に確率分布を簡単にプロットできる現代では不確実性が明確に図示できるという美点がある．しかしながら，その肝心の「事後分布の公式（Bayesの公式）」がほとんどの場合で計算不可能なのである！そこでBayesは計算法の開発を余儀なくされた．このように，Bayes統計学は当初からBayes計算の問題を懐胎していたのである．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#ベイズ統計学の長く苦しい時代",
    "href": "posts/2023/2023-12-6/BayesianComp.html#ベイズ統計学の長く苦しい時代",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "1.6 ベイズ統計学の長く苦しい時代",
    "text": "1.6 ベイズ統計学の長く苦しい時代\n「ベイズの枠組みは理念的に好ましかろうと，実際には実行不可能である」というベイズ統計学の基本問題は，Laplace が普遍的な近似計算法を開発したこと（ 節 1.5 ）を除いて，次の進展を見るには計算機の発明と普及を待つ必要があった．その間実に2世紀超えである．\nまた，Laplace の近似手法は普遍的であり，Bayes の最初の設定のような簡単な設定の \\(p(\\theta|\\boldsymbol{y}),g\\) に限らずとも使えるという，ベイズ統計学に大きく資する特徴も備えていたが，パラメータ \\(\\theta\\in(0,1)\\) の次元が1ではなくなると途端に使えなくなるという欠点がある．\n\n（前略）ベイズ統計学の有用性は以前から理解されていたが，この問題の抜本的な解決は1980年代まで待たざるを得なかった．それ以前は，ベイズの定理自体は18世紀に早々に発見されたにもかかわらず，長い間，確率の解釈，事前分布の設定，事後分布の計算の困難さのために哲学的議論に終始し，実用化にはほど遠かったのである．実用化の扉の鍵となったのは，一つは計算機の急速な発達，もう一つは計算集約的な画期的アルゴリズムの提案である． (樋口知之, 2014, p. 17)"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#ベイズまでの統計学の黎明",
    "href": "posts/2023/2023-12-6/BayesianComp.html#ベイズまでの統計学の黎明",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "1.1 ベイズまでの統計学の黎明",
    "text": "1.1 ベイズまでの統計学の黎明\n統計学の黎明を要請したものは，社会への不安であった．筆者に言わせれば，この社会への不安を直視したのがドイツ，数で解決しようとしたのがイギリスで，解決への筋道を確率論で基礎づけたのがフランスである．\n17世紀初頭から何度も流行を繰り返し，遂に1665年にはロンドンの人口の1/4を死に至らしめた ペストの大流行 は恐怖の対象であった．パンデミックは現代でも恐怖の対象であるが，当時はその全貌の把握が難しく，これが第一に切望された．月の運行による健康被害，国王の統治が疫病を引き起こす，などの俗見が流布していた時代である．しかし，「数」という解決手段は極めて功を奏した．\n数による解決が他でもないイギリスから生まれたことは，Francis Bacon 1561-1626 に象徴される自然科学の風土，「Aristotelesの三段論法を通じて，経験的に因果関係を発見することで，我々は自然を理解できる」という希望が当時のイギリスには存在したことが挙げられる．\n\n海へ行け，きっと獲物があるぞという先輩が Bacon であった．漁獲法一般の講義をする先生が，例えば後世の J. S. Mill の帰納論理学に相当するのである．統計学を作った漁師たちは，Mill 先生の帰納法の論理学の講義などは，上の空で聞いた．そして各自の漁獲法を自らの浜で覚えたのである． (北川敏男, 1949, p. 12)\n\n\n1.1.1 John Grauntの死亡表\nペスト流行の激しさの判定に寄与する人口状況を，最初に数によって理解しようとしたのが John Graunt 1620-1674 であった．\n当時の英国王立理学協会1 は，封建的な諸関係の崩壊解消と同時に，商品生産・貨幣による売買の全面支配によって貨幣的表現が富の大部分に侵入したことにより新たに誕生した市民階級が勢力を占めており，Graunt もこのような商人階級の出身であった．\nそのような身分の Graunt が英国王の推薦を受けて王立協会員の名誉を勝ち取った論文 (Graunt, 1662) は，ギルド発行の死亡統計 Bills of Mortality と教会に蓄積していた統計資料2 から統計的な処理を通じて世界初の「死亡表」を作成し，次の内容を初めて結論づけた．\n\n36%の幼児は６歳未満で死亡する．\n洗礼数をみると，男女比は16:15くらいである．\n都市の死亡率は地方より高い．\nLondonの城外では死亡率は３倍である．\n\n加えてLondonの世帯数を3通りの方法で推算し，世帯数は5万であろうと結論づけた．なお，当時の俗見ではLondon人口は100万と言われていた．\nその後このような「生命表」は精緻化の一途を辿り，イギリスのギルド的な共助制度の土壌の上で，生命保険の成立という実を結んだ．\n\n\n1.1.2 統計学への期待と希望\nこのイギリスの数を使った解決は，政治算術学派 と呼ばれ，海外への輸出が進んだ．\nドイツの牧師 Johann Peter Süβmilch 1707-1767 は Graunt に倣って，教会に蓄積していた統計資料を用い，出生率の性別比が長期的には女性1,000対男性1,050に収束することを発見した．\n中でも特に，「たくさんのデータを集めると何かが見えてくる」ことに大きな希望を持ち，Graunt が教会の資料に注目したことを Columbus の新大陸発見になぞらえている．そう，歴史上最初の統計分析は，教会の資料によるものであったのである．\n\n若し我々が家を一軒一軒数えていくならば，ある家では娘だけに，またある家では息子だけに，あるいはそうでなくとも，非常に不釣り合いな両者の配合にでくわすであろう．小さな社会や村落でも秩序的なものを認めることは，容易ではない．（中略）．かかる場合に，誰が，能く規則と秩序とに想達し得るだろう．所で，教会の記録はこの秩序の確認のための大きな手段である．それは教会用及び世俗用のためにすでに数世紀前から取られ，とくに宗教改革後はかなり正確にとられてきた．誰がそれを利用したか？その発見はアメリカ発見と同時に可能であったのだ．（中略）それをGrauntがなし得たのである． –Süβmilch (1741) 『神の秩序』 訳文は (北川敏男, 1949) より．\n\nこのように Süβmilch は男児の出生率の方が高いことを神の存在証明と見なしたのであった．この宗教的な外被を取り去るには，確率論の登場をまたねばならなかったが，これにはさらにフランスの学派が合流するのを待つ必要があり，それには100年を要したのであった（ 節 1.7 も参照）．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#フランスでの確率論の歴史",
    "href": "posts/2023/2023-12-6/BayesianComp.html#フランスでの確率論の歴史",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "1.7 フランスでの確率論の歴史",
    "text": "1.7 フランスでの確率論の歴史\nこのように，Laplaceが，ベイズ統計学暗黒の時代の中で唯一の小さな前身を産んだ．それだけでなく，Laplaceは確率論最大の集大成を産んでおり，これが他でもないフランスから生まれたことにも相応の理由があった．\nまず第一に，賭博の流行により，確率というものの理解と征服が嘱望された．\n\nその（確率論の）発展の動きを与えたものは，交易を賭ける商業資本家が占星術よりも確実な指導をこの学術に求めるという様な社会が基盤となって存在したことである．例えば，17世紀中葉のPascalとFermatの間の往復文書に取り扱われたカード遊びの数学的問題が，広く人々の関心を呼び起こした事情の裏には，至富の途を確実に求める商人たちの渇望が学問が外の世界にあったことを忘れてはならない． (北川敏男, 1949)\n\n第二に，統計的現象を神学的な畏怖の対象と見るのではなく，自然科学による自然の理解と征服の文脈の最先端として理解する土壌がフランスにあったことが指摘できる．\n\n17, 18世紀の啓蒙的合理主義は，偶然的な事象に対しても数学的な取り扱いを行うことに特別の興味を持った．思想的にはこの時代精神こと確率論を発展させた最大の動力であった．その駆使する数学解析の多彩と合理主義の徹底とに於て，Laplaceの大著はよくこの時代を代表するものと言うべきであろう．\n\n\n古典確率論の一応の完成は典雅に見えるであろう．だが人は，確率論のもった政治的，社会的意義を忘れてはならない．理知を一切の尺度として「代数学の炉火によって倫理学及び政治学を照さん」(Condorcet) という時代精神，神の啓示に代らんとする確率論，それはフランス革命の思想的基礎に連関することを見失ってはならないのである． (北川敏男, 1949)"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#sec-fundamental-problem-of-Bayes",
    "href": "posts/2023/2023-12-6/BayesianComp.html#sec-fundamental-problem-of-Bayes",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "1.4 ベイズ統計学の基本問題",
    "text": "1.4 ベイズ統計学の基本問題\n事後分布 \\(p(\\theta|\\boldsymbol{y})\\) を導く際に用いた条件付き確率の公式である 式 1 \\[\np(\\theta|\\boldsymbol{y})=\\frac{p(\\boldsymbol{y}|\\theta)p(\\theta)}{\\int_\\Theta p(\\boldsymbol{y}|\\theta)p(\\theta)\\,d\\theta}\\quad\\text{(1)}\n\\] は Bayesの公式 と呼ばれるようになった．今回の場合では，Pythonコードをご覧になった方はわかったかもしれないが，事後分布は \\[\np(\\theta|\\boldsymbol{y})=\\frac{\\theta^m(1-\\theta)^{n-m}}{B(m+1,n-m+1)}\n\\] となり，これはパラメータの空間 \\((0,1)\\) 上の Beta分布 と呼ばれるものである．\n現代のベイズ統計学の多くの統計量は，ある可積分関数 \\(g:\\Theta\\to\\mathcal{X}\\) を用いて \\[\n\\mathrm{E}[g(\\theta)|\\boldsymbol{y}]=\\int_{\\Theta}g(\\theta)p(\\theta|\\boldsymbol{y})\\,d\\theta\n\\tag{2}\\] と表される．先ほどの Bayes の区間推定の例では \\(g=1_{(a,b)}\\) と取った場合に当たる．6 実は，この積分は，この最も簡単と思われる \\(p(\\theta),p(\\boldsymbol{y}|\\theta)\\) の設定でも，殆ど計算できないのである．\n鮮やかな解決法を提示したかと思えば，結局実行出来ないのでは全く本末転倒である！そのこともあってか，論文 (Bayes, 1763) は実は Bayes の死後に Richard Price によって投稿されたものであり，生前に自ら投稿・発表した訳ではなかった．7 当然，発表当時は全く注目を受けなかった (Stigler, 1990)．\n\nHence, despite the analytical availability of \\(p(\\theta|\\boldsymbol{y})\\) via (2)–“Bayes’ rule” as it is now known-—the quantity that was of interest to Bayes needed to be estimated, or computed. The quest for a computational solution to a Bayesian problem was thus born. (Martin et al., 2023, p. 2)\n\n\n\n\n\n\n\nまとめ：ベイズ統計学の基本問題\n\n\n\nベイズの提示した統一的な統計推測の枠組み\n\n推定したい値 \\(\\theta\\) の空間上に事前分布 \\(p(\\theta)\\) を設定する．\n事前分布 \\(p(\\theta)\\) のデータ \\(\\boldsymbol{y}\\) に関する条件付き分布として事後分布 \\(p(\\theta|\\boldsymbol{y})\\) を得る．\n\nは非常に自然で，特に確率分布 \\(p(\\theta),p(\\theta|\\boldsymbol{y})\\) を簡単に視覚化できる現代では「データ \\(\\boldsymbol{y}\\) は，パラメータ \\(\\theta\\) に対する事前の信念をどれほど変えるに値するか？」を定量的にも定性的にも実感出来るという美点がある．\nしかしながら，モデル \\(p(\\theta),p(\\boldsymbol{y}|\\theta)\\) の設定をいくら簡単にしても根本的に計算が困難で実行不可能なのである．これを解決する分野をベイズ計算という．ベイズの論文 (Bayes, 1763) でも，計算法の開発が約半分を占めた．8 このように，Bayes統計学は当初からBayes計算の問題を懐胎していたのである．\n\nIn short, the implementation of all forms of Bayesian analysis relies heavily on numerical computation. (Martin et al., 2023, p. 2)"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#sec-Laplace",
    "href": "posts/2023/2023-12-6/BayesianComp.html#sec-Laplace",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "1.5 Laplaceの近似",
    "text": "1.5 Laplaceの近似\nフランスの数学者 Laplace は25歳時の初めての統計に関する著作 (Laplace, 1774) を発表した．この中で，Bayes が解こうとしたものと全く同じ\n\\[\\begin{align*}\n    &\\mathrm{P}[a&lt;\\theta&lt;b|\\boldsymbol{y}]\\\\\n    &\\quad=\\frac{\\int^b_a\\theta^m(1-\\theta)^{n-m}\\,d\\theta}{B(m+1,n-m+1)}\n\\end{align*} \\tag{3}\\]\nという積分計算の問題を，被積分関数を \\[\nf(\\theta):=\\frac{\\log p(\\theta|\\boldsymbol{y})}{n}\n\\] を用いて指数関数の形に表すことで解いた：9 \\[\n\\begin{align*}\n    \\mathrm{P}[a&lt;\\theta&lt;b|\\boldsymbol{y}]&=\\int^b_ap(\\theta|\\boldsymbol{y})\\,d\\theta\\\\\n    &=\\int^b_ae^{nf(\\theta)}\\,d\\theta\n\\end{align*}\n\\] この形に変形することがどのように役立つかは，次の定理が説明してくれる：\n\n\n\n\n\n\n定理（Laplace近似）\n\n\n\n10 関数 \\(f:[a,b]\\to\\mathbb{R}\\) はただ一つの最大値を \\(x_0\\in(a,b)\\) で取り，\\(f''(x_0)&gt;0\\) を満たすとする．このとき \\(n\\to\\infty\\) の極限について， \\[\n\\int^b_ae^{nf(x)}\\,dx\\sim\\sqrt{-\\frac{2\\pi}{nf''(x_0)}}e^{nf(x_0)}\n\\]\n\n\nこれを \\(f\\) の二次近似について適用することで，あらゆる確率分布 \\(p(\\theta|\\boldsymbol{y})\\,d\\theta\\) に関する積分 式 3 を，その正規近似に関する積分で近似できるのである．\nこの手法は現在のBayes計算手法のアイデアの源泉であり続けている (Rue et al., 2009)．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#モンテカルロ法の発明",
    "href": "posts/2023/2023-12-6/BayesianComp.html#モンテカルロ法の発明",
    "title": "ベイズ計算とは何か | About Bayesian Computation（執筆中）",
    "section": "2.1 モンテカルロ法の発明",
    "text": "2.1 モンテカルロ法の発明\n乱数のシミュレーションを用いた確率的なアルゴリズムをMonte Carlo法と総称する．このようなアルゴリズムが最初に生まれたのが，第二次世界大戦中の Los Alamos研究所 においてである．当時の問題は，\\(p\\) を \\(N\\) 個の粒子が従うBoltzmann分布として 式 2 を計算することにあった．\n\\[\n\\mathrm{E}[g(\\boldsymbol{\\theta})]=\\int_\\Theta g(\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})\\,d\\boldsymbol{\\theta}\n\\]\nただし，積分領域 \\(\\Theta\\) が \\(2N\\) 次元というとてつもない高次元空間上であることと，分布 \\(p\\) は定数倍を除いてしか計算できないことという，2つの大きな制約があった．そのために，通常の数値積分ほうが使えず，Metropolisら当時のLos Alamosに集まった物理学者たちは新しい方法を考える必要があった．\n最終的な解決 (Metropolis et al., 1953) は，Monte Carlo法の中でもとりわけ画期的な発想によるものであった．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#マルコフ連鎖によるモンテカルロ法の発明",
    "href": "posts/2023/2023-12-6/BayesianComp.html#マルコフ連鎖によるモンテカルロ法の発明",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "2.1 マルコフ連鎖によるモンテカルロ法の発明",
    "text": "2.1 マルコフ連鎖によるモンテカルロ法の発明\n乱数のシミュレーションを用いた確率的なアルゴリズムをモンテカルロ法と総称する．これは Metropolis が同僚 Ulam のポーカー好きから，モナコの首都 Monte Carlo にちなんで名付けたものである (Metropolis & Ulam, 1949)．このようなアルゴリズムが最初に生まれたのが，第二次世界大戦中の Los Alamos研究所 で進行中だった原爆開発計画である Manhattan計画 においてである．\n当時の問題は，原子爆弾着火時における Schödinger 作用素の基底状態のエネルギーを計算することにあった．抽象的には，\\(p\\) を \\(N\\) 個の粒子が従う Boltzmann 分布として，積分 式 2 を計算することにあった：\n\\[\n\\mathrm{E}[g(\\boldsymbol{\\theta})]=\\int_\\Theta g(\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})\\,d\\boldsymbol{\\theta}\\quad\\text{(2)}\n\\]\nただし，\n\n積分領域 \\(\\Theta\\) が \\(2N\\) 次元というとてつもない高次元空間上であること\n分布 \\(p\\) は定数倍を除いてしか計算できない\n\nという，2つの大きな制約があった．1.のために通常の数値積分法が使えず，また 2.により \\(p\\) からの直接の乱数シミュレーションが出来ないので，\\(p\\) からの乱数 \\(X_1,\\cdots,X_M\\) を十分多く生成することで積分 式 2 を \\[\n\\frac{1}{M}\\sum_{i=1}^Mg(X_i)\n\\] によって近似するという通常の Monte Carlo 積分法を実行することも出来ない．そこで，Metropolis ら当時の Los Alamos に集まった物理学者たちは新しい方法を考える必要があった．\n最終的な解決 (Metropolis et al., 1953) は，Monte Carlo 法の中でもとりわけ画期的な発想によるものであった．それは，Markov 連鎖を用いるということである．Markov連鎖とは（ある一定の条件を満たす）確率過程のクラスであり，\\(p\\) から直接のシミュレーションが出来ない状況でも，\\(p\\) に収束するようなMarkov 連鎖を構成することは可能だったのである．\n制約 1.と 2.は広く物理学とベイズ統計学の至る所で見られる障壁であり，これをものともしない汎用アルゴリズムの発明は極めて大きなブレイクスルーであった．(Dongarra & Sullivan, 2000) は Metropolis アルゴリズムを理学・工学分野に20世紀最大の影響を与えたアルゴリズムの1つとしている．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#重点サンプリング法の発明",
    "href": "posts/2023/2023-12-6/BayesianComp.html#重点サンプリング法の発明",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "2.2 重点サンプリング法の発明",
    "text": "2.2 重点サンプリング法の発明\n実は Manhattan 計画に最中に，もう一つのサンプリング技法が生まれていた．厚い壁で中性子線とガンマ線がどのように吸収されるかに取り組んでいたグループにて，Herman Kahn らが中心となり，式 2 の分布 \\(p\\) に関する積分が \\[\n\\begin{align*}\n    \\mathrm{E}[g(\\boldsymbol{\\theta})]&=\\int_\\Theta g(\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})\\,d\\boldsymbol{\\theta}\\\\\n    &=\\int_\\Theta\\frac{g(\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})}{p^*(\\boldsymbol{\\theta})}p^*(\\boldsymbol{\\theta})\\,d\\boldsymbol{\\theta}\n\\end{align*}\n\\] という式変形により，別の分布 \\(p^*\\) からのサンプリングを通じて計算できる，という技法が利用された．彼らはこれに重点サンプリング法という名前をつけた．これは Gerald Goertzel による命名である可能性が高い (Andral, 2022)．\nなお，当時は \\(p\\) からのサンプリングを回避できるという点よりも，\\(p^*\\) をうまく選ぶことにより元々の \\(p\\) を用いた Monte Carlo 積分法を適用するよりも近似の精度をあげることが出来るという点の方が注目された (Hammersley & Handscomb, 1964)．\n前節の Metropolis 法がMCMCの先駆けであるとしたら，この2つの美点を持った重点サンプリング法は，SMC（粒子フィルター） の先駆けであった．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#mcmcの普及とギブスサンプラー",
    "href": "posts/2023/2023-12-6/BayesianComp.html#mcmcの普及とギブスサンプラー",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "2.3 MCMCの普及とギブスサンプラー",
    "text": "2.3 MCMCの普及とギブスサンプラー\nMetropolis 法の発明から，すぐにMCMCの画期性が広く認識された訳ではなかった．特に，元々物理学の文脈で発明されたこともあり，統計学の文脈への応用が始まるには (Hastings, 1970) の仕事を待つ必要があった．\nしかし1970年代とはマイクロプロセッサが開発されたばかりの時代であり，11 MCMCが実際の統計解析の現場で採用可能な計算手法になるとは（そもそも現代のように小型なコンピュータを個人が所有するようになるとは）夢にも思われなかった時代であったが，ここからたったの20年で現代人の生活とベイズ統計学は大きく変わることになる．\n\n各人が安価に高性能なコンピュータを所有するようになった．\n高次元分布からのサンプリングを可能にするアルゴリズムが発見された．\n\nの2点が最後に加わることで，MCMCがベイズ計算法不動の金科玉条となった．\nこの 2.は計算機の性能の問題だけでなく，Gibbsサンプラーという新たなアルゴリズムの開発 (Geman & Geman, 1984) によって実現された．12 これは，パラメータ \\(\\boldsymbol{\\theta}=(\\theta_1,\\theta_2)^\\top\\) と表されるとき，適切に定めた初期値 \\(\\theta_2^{(0)}\\) から初めて，条件付き分布からのサンプリング \\[\n\\theta_1^{(i)}\\sim p_1(\\theta_1^{(i)}|\\theta_2^{(i-1)},\\boldsymbol{y}),\n\\] \\[\n\\theta_2^{(i)}\\sim p_2(\\theta_2^{(i)}|\\theta_1^{(i)},\\boldsymbol{y}),\n\\] を繰り返すことで，最終的に \\(\\boldsymbol{\\theta}^{(i)}:=(\\theta_1^{(i)},\\theta_2^{(i)})^\\top\\) は全体として \\(p(\\boldsymbol{\\theta}|\\boldsymbol{y})\\) に従うように収束する，という技法である．\nGibbs 法により，パラメータ \\(\\boldsymbol{\\theta}\\) の次元が大きく，直接のサンプリングが難しい場合でも，\\(\\boldsymbol{\\theta}=(\\theta_1,\\theta_2,\\cdots)\\) というように低次元変数の結合と理解することで，あるいは補助変数を追加してわざと問題を高次元化してでもそのような状況をうまく作り出すことで (Tanner & Wong, 1987) ，部分的な低次元サンプリングから組み上げることが出来るようになった．さらにその後も，このアイデアが (Roberts & Rosenthal, 1999) のスライスサンプラーにつながっている．\nこの点をはっきり強調して示し，ベイズ統計学がすでに実行可能なものになっており，ベイズ統計学の基本問題（ 節 1.4 ）もすでに過去の遺物となっているということを，統計学界隈に広く知らしめたのが (Gelfand & Smith, 1990) であった．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#擬似周辺尤度法",
    "href": "posts/2023/2023-12-6/BayesianComp.html#擬似周辺尤度法",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "3.1 擬似周辺尤度法",
    "text": "3.1 擬似周辺尤度法\n実は尤度 \\(p(\\boldsymbol{y}|\\boldsymbol{\\theta})\\) が解析的に得られない場合や計算が極めて困難になる場合でも，この不偏推定量があればMCMCを実行して事後分布を得るのに十分である (Andrieu & Roberts, 2009)．この尤度 \\(p(\\boldsymbol{y}|\\boldsymbol{\\theta})\\) の不偏推定量を得るのに粒子フィルターを用いた場合を，特に粒子MCMCという (Andrieu et al., 2010)．\nこのときの不偏推定量の性能が最終的な Monte Carlo 推定量に影響する．不偏推定量の分散を改善するには，サブルーチンである粒子フィルターの反復数を増やす必要がある．すると本体であるMCMCの反復数とのトレードオフが生じる．こうしてアルゴリズムの最適な調整が課題になる．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#高次元問題に対処するmcmc",
    "href": "posts/2023/2023-12-6/BayesianComp.html#高次元問題に対処するmcmc",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "3.2 高次元問題に対処するMCMC",
    "text": "3.2 高次元問題に対処するMCMC\nほとんどのMCMC手法は，データサイズやモデルのパラメータサイズの増加に対して，計算負荷が飛躍的に上昇する次元の呪いに苦しむ．これを克服する手法はscalabilityの名の下に盛んに研究されている (鎌谷研吾, 2021, p. 394)．\n\n対象分布の探索を効率よく行う手法として，HMC (Hamiltonian Monte Carlo) 法が提案された (Neal, 2011)．他にも NUTS (No U-Turn Sampling) (Hoffman & Gelman, 2014), Metropolis-Adjusted Langevin Algorithm (Roberts & Tweedie, 1996), Stochastic Gradient MCMC (Nemeth & Fearnhead, 2021), PDMP (区分的確定なMCMC) (Bierkens et al., 2018), (Fearnhead et al., 2018) とジグザグサンプラー (Bierkens et al., 2019) などがある，\nより良い提案分布の選択法について，MH法の最適スケーリング法，適応的サンプリング，焼き戻しなどの手法がある．\n並列計算による効率化の方向性には，並列MCMC，完全サンプリングなどの手法がある．\n他の分散低減法に，Rao-Blackwell化 (Casella & Robert, 1996)，操作変数法などがある．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#ベイズ統計モデリングが複雑理論モデルの実証に役立つ",
    "href": "posts/2023/2023-12-6/BayesianComp.html#ベイズ統計モデリングが複雑理論モデルの実証に役立つ",
    "title": "ベイズ計算とは何か | About Bayesian Computation（執筆中）",
    "section": "3.4 ベイズ統計モデリングが複雑理論モデルの実証に役立つ",
    "text": "3.4 ベイズ統計モデリングが複雑理論モデルの実証に役立つ\nベイズモデルの有用性は，複雑なモデルにも統一的な方法で対応できる点にもある．\n\nメカニズムを明示的に表現した数理社会学の数理モデルを，論理的に飛躍することなくダイレクトに統計モデルへと接続できるベイズ統計モデリングは，理論モデルベースの実証研究と相性のよい，たいへん便利な方法と言えるだろう． (浜田宏, 2022, p. 137)\n\nMCMCの開発とパッケージへの実装と安価で高性能な計算機が普及してからベイズ統計学の興隆は目覚ましく，現在ではベイズ統計学は統計学に関する論文の1割強を占め，諸科学分野全体に浸透しつつあるが，経済学・心理学への応用は早かったのに比べて，政治科学・社会科学への応用は遅れ気味であり，社会学での使用はまだ稀であると言える (Lynch & Bartlett, 2019)．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#abc近似ベイズ計算",
    "href": "posts/2023/2023-12-6/BayesianComp.html#abc近似ベイズ計算",
    "title": "ベイズ計算とは何か | About Bayesian Computation（執筆中）",
    "section": "3.3 ABC（近似ベイズ計算）",
    "text": "3.3 ABC（近似ベイズ計算）\n上述までの手法はいずれもシミュレーションを十分多く行えば（理論的には）任意の精度で正しい値を得ることができるが，10 その適用範囲やスケーラビリティが課題なのであった．そこで同時に，最初からある許容精度を定めた下での近似を実行することとし，代わりにより広い適用可能性と計算速度を得るための手法も探求されている．これをABC (Approximate Bayesian Computation)という．\n一つのアプローチはシミュレーションによる方法 (Tavaré et al., 1997) である．データ生成過程（モデル）の複雑性と高次元性という２つの障壁が併存したときでも使える手法を目指す．まず事後分布 \\(p(\\boldsymbol{\\theta}|\\boldsymbol{y})\\) をある低次元な要約統計量 \\(S:\\mathcal{Y}\\to\\mathbb{R}^d\\) を用いて \\(p(\\boldsymbol{\\theta}|S(\\boldsymbol{y}))\\) で近似し，さらに尤度 \\(p(\\boldsymbol{y}|\\boldsymbol{\\theta})\\) を評価することは回避し，シミュレーションのみを用いて \\(p(\\boldsymbol{\\theta}|S(\\boldsymbol{y}))\\) を推定する．狭義にはこの手法を指してABCともいう．\n第二に最適化による方法がある．\nABCでは逐次モンテカルロ法も大きな役割を果たしており，ABC-SMC (Sisson et al., 2007)，ABCフィルタリング (Jasra et al., 2012)，更には変分Bayes法への応用 (Tran et al., 2017) なども進んでいる．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#ベイズ因果推論",
    "href": "posts/2023/2023-12-6/BayesianComp.html#ベイズ因果推論",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "3.6 ベイズ因果推論",
    "text": "3.6 ベイズ因果推論"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#近似ベイズ手法",
    "href": "posts/2023/2023-12-6/BayesianComp.html#近似ベイズ手法",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "3.3 近似ベイズ手法",
    "text": "3.3 近似ベイズ手法\n上述までの手法はいずれもシミュレーションを十分多く行えば（理論的には）任意の精度で正しい値を得ることができるが，13 その適用範囲やスケーラビリティが課題なのであった．そこで同時に，最初からある許容精度を定めた下での近似を実行することとし，代わりにより広い適用可能性と計算速度を得るための手法も探求されている．これを近似ベイズ法という．\n一つのアプローチはシミュレーションによる方法である．これにはABC (Approximation Bayesian Computation) (Tavaré et al., 1997) と BSL (Bayesian synthetic likelihood) (Price et al., 2018) の2つの手法があるが，いずれもデータ生成過程（モデル）の複雑性と高次元性という２つの障壁が併存したときでも使える手法である．ABCではまず事後分布 \\(p(\\boldsymbol{\\theta}|\\boldsymbol{y})\\) をある低次元な要約統計量 \\(S:\\mathcal{Y}\\to\\mathbb{R}^d\\) を用いて \\(p(\\boldsymbol{\\theta}|S(\\boldsymbol{y}))\\) で近似し，さらに尤度 \\(p(\\boldsymbol{y}|\\boldsymbol{\\theta})\\) を直接評価することは回避し，シミュレーションのみを用いて \\(p(\\boldsymbol{\\theta}|S(\\boldsymbol{y}))\\) を推定する．BSLはさらに尤度 \\(p(S(\\boldsymbol{y})|\\boldsymbol{\\theta})\\) にパラメトリックな仮定をおく．\n第二に最適化による方法がある．変分ベイズ手法とは，これは大きなパラメトリックモデル \\(\\{q^*(\\boldsymbol{\\theta})\\}\\) の中から \\(p(\\boldsymbol{\\theta}|\\boldsymbol{y})\\) に最も近いものを選ぶ手法である．一方で INLA (integrated nested Laplace approximation) とは，Laplaceの近似（ 節 1.5 ）に最適化を組み合わせて高次元の問題にも対応する．\nABCでは逐次モンテカルロ法も大きな役割を果たしており，ABC-SMC (Sisson et al., 2007)，ABCフィルタリング (Jasra et al., 2012)，更には変分Bayes法への応用 (Tran et al., 2017) なども進んでいる．\n変分Bayesの枠組みでは，モデルの誤想定に頑健な手法の開発も試みられている (Wang & Blei, 2019)．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#不確実性の定量化と意思決定まで",
    "href": "posts/2023/2023-12-6/BayesianComp.html#不確実性の定量化と意思決定まで",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "3.5 不確実性の定量化と意思決定まで",
    "text": "3.5 不確実性の定量化と意思決定まで\n前節に挙げたベイズモデリングの美点は因果推論の文脈でも全く同様であり，特に因果推論の問題によく見られるように，推定対象が複雑である際にも全く同じ枠組みを提供してくれるのがベイズである．頻度論的接近では設定に応じた個別具体的な議論がベイズ計算の問題に落ちる点が利点として働く場面は多いようである (Li et al., 2023)．\n加えて，「あらゆる種の不確実性に対する統一的な定量化を与える」というベイズの性質は，因果推論から意思決定までの接続を地続きにし，例えば属人化医療などの現場でのダイナミックな意思決定に活用できることが期待される．\n\n不確実性を定量化するのに、ベイズ計算では必ず『確率』を使います。一般の人から見たら、統計で確率を使うのは当たり前と思うでしょうが、じつは他の統計手法ではそうでもなく、さまざまな解釈が生まれてしまう。定量化にはすべて統一的に確率を使うベイズ計算は、非常にシンプルなので、最終的にすべての統計はベイズに行き着くしかないと思っています．鎌谷研吾\n\nしかし，ベイズの方法が因果推論の分野で普及するための障壁は，近づきやすさにあると議論できる (Li et al., 2023)．従来の頻度論的な因果推論手法の成功は，潜在反応モデルの想定を殆どしなくて良いこと（モデルフリー），実装が簡単であることが少なからず寄与しているとすれば，ベイズ的接近もこれに当たるものを提供できるようになる必要があるだろう．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#ベイズによる因果推論",
    "href": "posts/2023/2023-12-6/BayesianComp.html#ベイズによる因果推論",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "3.5 ベイズによる因果推論",
    "text": "3.5 ベイズによる因果推論\n前節に挙げたベイズモデリングの美点は因果推論の文脈でも全く同様であり，特に因果推論の問題によく見られるように，推定対象が複雑である際にも全く同じ枠組みを提供してくれるのがベイズである．頻度論的接近では設定に応じた個別具体的な議論がベイズ計算の問題に落ちる点が利点として働く場面は多いようである (Li et al., 2023)．\n実際，ベイズノンパラメトリック手法は2016年の大西洋因果推論カンファレンスのコンペティションで大きな成功を見ている (Dorie et al., 2019)．加えて強い理論的な保証も得られつつあり (Ray & van der Vaart, 2020)，これにより因果推論での注目を大きく集めつつある (Linero & Antonelli, 2023)．\n加えて，「あらゆる種の不確実性に対する統一的な定量化を与える」というベイズの性質は，因果推論から意思決定までの接続を地続きにし，例えば属人化医療などの現場でのダイナミックな意思決定に活用できることが期待される．\n\n不確実性を定量化するのに、ベイズ計算では必ず『確率』を使います。一般の人から見たら、統計で確率を使うのは当たり前と思うでしょうが、じつは他の統計手法ではそうでもなく、さまざまな解釈が生まれてしまう。定量化にはすべて統一的に確率を使うベイズ計算は、非常にシンプルなので、最終的にすべての統計はベイズに行き着くしかないと思っています．鎌谷研吾\n\nしかし，ベイズの方法が因果推論の分野で普及するための障壁は，近づきやすさにあると議論できる (Li et al., 2023)．従来の頻度論的な因果推論手法の成功は，潜在反応モデルの特定を殆どしなくて良いこと（モデルフリー），実装が簡単であることが少なからず寄与しているとすれば，ベイズ的接近もこれに当たるものを提供できるようになる必要があるだろう．Stan言語 (Carpenter et al., 2017) はこの方向への大きな試みである．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#ベイズ学習",
    "href": "posts/2023/2023-12-6/BayesianComp.html#ベイズ学習",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "3.6 ベイズ学習",
    "text": "3.6 ベイズ学習\n機械学習の手法を用いてベイズ推論を実行する営みをベイズ学習，または単に「機械学習への確率論的アプローチ」と言ってベイズの枠組みを暗に指す場合も多い (Murphy, 2022), (Ghahramani, 2013)．\n古典的な統計手法と同様，多くの既存の（頻度論的）手法にはベイズ手法の対応物が存在する．ベイズの方法だと推定の確信度合いもセットで定量化され，頻度論的対応物よりも得られる情報が多い一方で，計算は既存手法よりも難しいことが多いという構造は，機械学習においても変わらない．\n実際，現存のニューラルネットワークの訓練法を超えるベイズ計算法が今後提案されるとは考えにくいが，その最適化する所の目的関数が例えば正則化項付きの平均自乗誤差である場合は，ある正規事前分布と正規尤度に対するMAP推定量に対応する (Seitz 2022)．畢竟，多くの既存手法も「ベイズ学習を非ベイズ的な方法で実行している」と捉えられるのである（逆も然り）．\n中でもベイズ学習を採用するのが良い場面としては，モデルの大きさに対して学習に使えるデータの数が少ない場合や，モデルに事前情報を組み込みたい場合14 ，さらには医療・政策への応用など意思決定に繋げるために不確実性の定量化が肝要な場面などがあり得る．\n実際，ベイジアン・ニューラルネットワークでは計算の困難ささえ乗り越えれば，複数の適切なモデルに対し，事後分布によって平均を取って最終的なモデルとすることで，過学習を防止し (Mackay, 1995)，大きな性能改善を得ることができる (Wilson & Izmailov, 2020)．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#終わりに不確実性の定量化",
    "href": "posts/2023/2023-12-6/BayesianComp.html#終わりに不確実性の定量化",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "3.7 終わりに：不確実性の定量化",
    "text": "3.7 終わりに：不確実性の定量化\n最終的には，計算機・自然・人間の間のよきインターフェイスとなることも願っている．\n\nThe applied statistician should be Bayesian in principle and calibrated to the real world in practice-—appropriate frequency calculations help to define such a tie. (Rubin, 1984)"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#世紀の統計学とベイズの役割",
    "href": "posts/2023/2023-12-6/BayesianComp.html#世紀の統計学とベイズの役割",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "3.7 21世紀の統計学とベイズの役割",
    "text": "3.7 21世紀の統計学とベイズの役割\nこのように，21世紀に入ってからベイズの成功は目まぐるしく，この傾向はさらに進むと思われる．これは統計計算の手法の進化によって達成された．今後とも統計計算の手法は，シミュレーション・変分法・最適化の垣根を超えて多様化の一途を辿るだろう (Green et al., 2015, p. 857)．\nその中でも筆者は，ベイズ手法が提供する事後分布として得られる不確実性の表現・視覚化が，計算機・自然・人間の間のよきインターフェイスとなっていくことを願っている．15\n\nThe applied statistician should be Bayesian in principle and calibrated to the real world in practice-—appropriate frequency calculations help to define such a tie. (Rubin, 1984)"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#sec-BayesianCausalInference",
    "href": "posts/2023/2023-12-6/BayesianComp.html#sec-BayesianCausalInference",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "3.5 ベイズによる因果推論",
    "text": "3.5 ベイズによる因果推論\n前節に挙げたベイズモデリングの美点は因果推論の文脈でも全く同様である．特に因果推論の問題では推定対象が複雑であることが多いが，このような場合でも全く同じ枠組みを提供してくれるのがベイズである．頻度論的接近では設定に応じた個別具体的な議論がベイズ計算の問題に帰着する点が利点として働くことは多いようである (Li et al., 2023)．\n実際，ベイズノンパラメトリック手法は2016年の大西洋因果推論カンファレンスのコンペティションで大きな成功を見ている (Dorie et al., 2019)．加えて強い理論的な保証も得られつつあり (Ray & van der Vaart, 2020)，これにより因果推論分野で大きな注目を集めている (Linero & Antonelli, 2023), (Daniels et al., 2023)．\n加えて，「あらゆる種の不確実性に対する統一的な定量化を与える」というベイズの性質は，因果推論から意思決定までの接続を地続きにし，例えば属人化医療などの現場でのダイナミックな意思決定に活用できることが期待される．\n\n不確実性を定量化するのに、ベイズ計算では必ず『確率』を使います。一般の人から見たら、統計で確率を使うのは当たり前と思うでしょうが、じつは他の統計手法ではそうでもなく、さまざまな解釈が生まれてしまう。定量化にはすべて統一的に確率を使うベイズ計算は、非常にシンプルなので、最終的にすべての統計はベイズに行き着くしかないと思っています．鎌谷研吾\n\nしかし，ベイズの方法が因果推論の分野で普及するための障壁は，近づきやすさにあると議論できる (Li et al., 2023)．従来の頻度論的な因果推論手法の成功には，潜在反応モデルの特定を殆どしなくて良いこと（モデルフリー），実装が簡単であることが少なからず寄与しているとすれば，ベイズ的接近もこれに当たるものを提供できるようになる必要があるだろう．Stan言語 (Carpenter et al., 2017) はこの方向への大きな試みである．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#sec-France",
    "href": "posts/2023/2023-12-6/BayesianComp.html#sec-France",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "1.7 フランスでの確率論の歴史",
    "text": "1.7 フランスでの確率論の歴史\nこのように，Laplace が，ベイズ統計学暗黒の時代の中で唯一の小さな前進を生んだ．それだけでなく，Laplace は後の1812年に当時の確率論最大の集大成と言える大著『確率論の解析理論』を産んでおり，これが他でもないフランスから生まれたことにも相応の理由があった．\nまず第一に，賭博の流行により，確率というものの理解と征服が嘱望された．\n\nその（確率論の）発展の動きを与えたものは，交易を賭ける商業資本家が占星術よりも確実な指導をこの学術に求めるという様な社会が基盤となって存在したことである．例えば，17世紀中葉のPascalとFermatの間の往復文書に取り扱われたカード遊びの数学的問題が，広く人々の関心を呼び起こした事情の裏には，至富の途を確実に求める商人たちの渇望が学問が外の世界にあったことを忘れてはならない． (北川敏男, 1949)\n\n第二に，統計的現象を神学的な畏怖の対象と見るのではなく，自然科学による自然の理解と征服の文脈の最先端として理解する土壌がフランスにあったことが指摘できる．\n\n17, 18世紀の啓蒙的合理主義は，偶然的な事象に対しても数学的な取り扱いを行うことに特別の興味を持った．思想的にはこの時代精神こと確率論を発展させた最大の動力であった．その駆使する数学解析の多彩と合理主義の徹底とに於て，Laplace の大著はよくこの時代を代表するものと言うべきであろう．\n\n当時の財務総監 Jacques Turgot を通じてパリ造幣局の監査官も務めた Nicolas de Condorcet 1743-94 は Laplace の確率論を積極的に社会分析に応用した．「社会数学」と呼んだこの運動は社会学の源流ともみなされる． 当然後進も Laplace に続いた．ベルギーの数学者 Adolphe Quetelet 1796-74 は Laplace の確率論を社会に応用することを目指し「社会物理学」なる分野を創始し，BMIの別名「ケトレー指数」にも名を残している．\n\n古典確率論の一応の完成は典雅に見えるであろう．だが人は，確率論のもった政治的，社会的意義を忘れてはならない．理知を一切の尺度として「代数学の炉火によって倫理学及び政治学を照さん」(Condorcet) という時代精神，神の啓示に代らんとする確率論，それはフランス革命の思想的基礎に連関することを見失ってはならないのである． (北川敏男, 1949)"
  },
  {
    "objectID": "posts/2023/2023-12-11/ParticleFilter.html",
    "href": "posts/2023/2023-12-11/ParticleFilter.html",
    "title": "粒子フィルターの実装 | Particles Package",
    "section": "",
    "text": "Nicolas Chopin による逐次モンテカルロ法のための Python パッケージ particles の実装を参考に，NumPy, SciPy のみを用いて1から粒子フィルターを実装することで，その仕組みを理解することを目指す．"
  },
  {
    "objectID": "posts/2023/2023-12-11/ParticleFilter.html#リサンプリングの実装",
    "href": "posts/2023/2023-12-11/ParticleFilter.html#リサンプリングの実装",
    "title": "粒子フィルターの実装 | Particles Package",
    "section": "1 リサンプリングの実装",
    "text": "1 リサンプリングの実装\nまずリサンプリング法を実装する．今回は系統的リサンプリング法 (Carpenter et al., 1999) を用いることとする．1\n\n1.1 システマティックリサンプリング\n系統的リサンプリングとは，粒子数 \\(N\\) から \\(M\\) 個のサンプルを復元抽出する方法であって，次の2段階からなる．\n\n$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$\n\n\n各区間 \\(\\left[\\frac{n-1}{M},\\frac{n}{M}\\right]\\subset[0,1]\\;(n\\in[M])\\) での変動の由来をただ一つのサンプル \\(U\\sim\\mathrm{U}([0,1])\\) から取ってしまい， \\[\nU^{(n)}:=\\frac{n-1+U}{N}\\quad(n\\in[M])\n\\] と乱数列を定める．\n正規化荷重 \\(\\{w^{(n)}\\}_{n=1}^N\\) が定める累積和 \\[\nF(n):=\\sum_{i=1}^nw^{(i)}\n\\] に対して，この一般化逆関数 \\(F^-:[0,1]\\to[N]\\) を通じて，\\(A^{n}:=F^{-1}(U^{(n)})\\;(n\\in[M])\\) をサンプルとする．\n\nこれにより，粒子の添字の対応 \\((1,\\cdots,N)\\mapsto A^{1:M}\\) が得られる．\n\n\nCode\nimport numpy as np\nfrom numba import jit\n\n@jit(nopython=True)\ndef inverse_cdf(su, W):\n    \"\"\"Inverse CDF algorithm for a finite distribution.\n    su: (M,) ndarray of sorted uniform variables\n    W: (N,) ndarray of normalized weights\"\"\"\n    j = 0\n    s = W[0]\n    M = su.shape[0]\n    A = np.empty(M, dtype=np.int64)\n    for n in range(M):\n        while su[n] &gt; s:\n            j += 1\n            s += W[j]\n        A[n] = j\n    return A\n\ndef systematic(W, M):\n    \"\"\"Systematic resampling\n    W: (N,) ndarray of normalized weights\n    M : number of resampled points\"\"\"\n    su = (random.rand(1) + np.arange(M)) / M\n    return inverse_cdf(su, W)\n\n\n\n\n1.2 荷重を保持するWeightsクラス\n次に，SMC に繋げるために，粒子の荷重を保持するためのクラスを定義する．粒子の荷重は極めて小さくなり得るため，対数によって保持する．このクラス内の属性として，正規化荷重もESSも得られるようにする：\n\nlw：正規化されていない荷重を対数で保持\nw：正規化された荷重\nESS：有効サンプル数2\n\nこれらの属性を __init__(lw) 内で計算する．加えて add(delta) メソッドで，incremental weightsを乗じるルーチンを用意する．\n\n\nCode\nclass Weights:\n    \"\"\"A class to hold the N weights of the particles\"\"\"\n    def __init__(self, lw=None):\n        self.lw = lw  # t=0で呼ばれた際はNoneである\n        if lw is not None:\n            self.lw[np.isnan(self.lw)] = -np.inf  # 欠損値処理\n            m = self.lw.max()\n            w = np.exp(self.lw - m)  # 大きすぎる値にならないように\n            s = w.sum()\n            self.W = w / s  # 正規化荷重\n            self.ESS = 1.0 / np.sum(self.W ** 2)\n            self.log_mean = m + np.log(s / self.N)\n    \n    @property\n    def N(self):\n        \"\"\"Number of particles\"\"\"\n        return 0 if self.lw is None else self.lw.shape[0]\n\n    def add(self, delta):\n        \"\"\"Add increment weights delta to the log weights\"\"\"\n        if self.lw is None:\n            return self.__class__(lw=delta)\n        else:\n            return self.__class__(lw=self.lw + delta)\n\n\n初期化は \\[\nW^i=\\frac{e^{\\log w^i-m}}{\\sum_{j=1}^Ne^{\\log w^j-m}}\n\\] \\[\nm:=\\log\\left(\\max_{i\\in[N]}w^i\\right)\n\\] に基づいて計算されている．log_mean は \\[\n\\begin{align*}\n    &\\log\\left(\\max_{i\\in[N]}w^i\\right)+\\log\\left(\\frac{\\sum_{j=1}^Ne^{\\log w^j-m}}{N}\\right)\\\\\n    &=\\log\\left(\\frac{1}{N}\\sum_{j=1}^Nw^j\\right)\n\\end{align*}\n\\] という値である．"
  },
  {
    "objectID": "posts/2023/2023-12-11/ParticleFilter.html#粒子の情報保持particlehistoryクラス",
    "href": "posts/2023/2023-12-11/ParticleFilter.html#粒子の情報保持particlehistoryクラス",
    "title": "粒子フィルターの実装 | Particles Package",
    "section": "2 粒子の情報保持：ParticleHistoryクラス",
    "text": "2 粒子の情報保持：ParticleHistoryクラス\n\n2.1 情報を収集するCollectorクラス\nSMCの結果をプロットするために，各時間で粒子の標本統計量を SMC クラス（ 節 3 ）から適宜抜き出して保存しておくためのクラス Summaries を作成する．抜き出すためのメソッドを Collector クラスの継承クラスとして定義する．\n\n\nCode\nclass Collector:\n    \"\"\"Base class for collectors\"\"\"\n    def __init__(self, **kwargs):\n        self.summary = []\n\n    def collect(self, smc):\n        self.summary.append(self.fetch(smc))\n\nclass ESSs(Collector):\n    summary_name = \"ESSs\"\n    def fetch(self, smc):\n        return smc.wgts.ESS\n\nclass LogLts(Collector):\n    summary_name = \"LogLts\"\n    def fetch(self, smc):\n        return smc.logLt\n\nclass Rs_flags(Collector):\n    summary_name = \"Rs_flags\"\n    def fetch(self, smc):\n        return smc.rs_flag\n\nclass Moments(Collector):\n    \"\"\"Collects empirical moments of the particles\"\"\"\n    summary_name = \"Moments\"\n    def fetch(self, smc):\n        m = np.average(smc.X, weights=smc.wgts.W, axis=0)\n        m2 = np.average(smc.X ** 2, weights=smc.wgts.W, axis=0)\n        v = m2 - m ** 2\n        return {\"mean\": m, \"var\": v}\n\ndefault_collector_cls = [ESSs, LogLts, Rs_flags]\n\n\n\n\n2.2 標本統計量を保持するSummariesクラス\nこのクラスはデフォルトで用意されている default_collector_cls に加えて，cols引数で指定されたメソッドを追加し，collect() メソッドが呼ばれるとこれらを集めて属性として保持する．\n\n\nCode\nclass Summaries:\n    \"\"\"A class to hold the summaries of the SMC algorithm\"\"\"\n    def __init__(self, cols):\n        self._collectors = [cls() for cls in default_collector_cls]\n        if cols is not None:\n            self._collectors.extend(col() for col in cols)\n        for col in self._collectors:\n            setattr(self, col.summary_name, col.summary)\n\n    def collect(self, smc):\n        for col in self._collectors:\n            col.collect(smc)\n\n\n\n\n2.3 ヒストリを保持するParticleHistoryクラス\ndequeオブジェクト としてヒストリを格納するためのクラスParticleHistory実装する．これにより直前 \\(k\\) ステップの情報だけを保持出来るように作れるが，今回はプロットのために全履歴を保持する．\n\n\nCode\nclass ParticleHistory:\n    \"\"\"History of the particles\n    Full history that keeps all the particle systems based on lists.\n    \"\"\"\n    def __init__(self, fk):\n        self.X, self.A, self.wgts = [], [], []\n        self.fk = fk\n\n    def save(self, smc):\n        self.X.append(smc.X)\n        self.A.append(smc.A)\n        self.wgts.append(smc.wgts)\n\n\n\n\nCode\ndef generate_hist_obj(option, smc):\n    if option is True:\n        return ParticleHistory(smc.fk)\n    else:\n        return None"
  },
  {
    "objectID": "posts/2023/2023-12-11/ParticleFilter.html#sec-SMC",
    "href": "posts/2023/2023-12-11/ParticleFilter.html#sec-SMC",
    "title": "粒子フィルターの実装 | Particles Package",
    "section": "3 実行部分：SMCクラス",
    "text": "3 実行部分：SMCクラス\nこのクラスがやるべきことは多い．Feynman-Kacモデル fk（ 節 4.1 で後述），粒子数 N，リサンプリング法 resampling を引数に取り，粒子フィルターを実行する．\n最も大事なこととして，本クラスはイテレータとして定義し，__next__ メソッドを実装する．そして run() メソッドで __next__ を終了するまで繰り返し呼び出すことでイテレータプロトコルを実行する．\n__next__メソッドでは，次のような処理を行う：\n\n終了フラッグ fk.done(self) が立っているかどうかを確認する．\n\\(t=0\\) の場合，最初の粒子を初期分布 \\(M_0\\) から \\(N\\) 個サンプリングする．\n\\(t&gt;0\\) の場合は，リサンプリングと粒子移動を行う．これは resample_move() メソッドで行う．\n\nリサンプリングフラッグ fk.time_to_resample(self) が立っている場合にリサンプリングを systematic メソッド（ 節 1.1 ）により行う．これにより，移動（変異）する粒子 \\(A^{1:N}_t\\) を確定させる．\n確率核 \\(M_t(X_{t-1}^{A_t^{1:N}},-)\\) に従って，粒子 \\(X_t^{1:N}\\) をサンプリングする．\n\n粒子の荷重を更新する．これは reweight_particles() メソッドで行う．\ncompute_summariesメソッドを呼び出して，粒子の標本統計量を Summaries クラスに，ヒストリを Particle History クラスに追記する．\n時刻 \\(t\\) を進めて 3.に戻る．\n\n\n\nCode\nclass SMC:\n    \"\"\"Metaclass for SMC algorithms\"\"\"\n\n    def __init__(\n        self,\n        fk=None,\n        N=100,\n        resampling=\"systematic\",\n        ESSrmin=0.5,\n        store_history=False,\n        collect=None,\n    ):\n\n        self.fk = fk\n        self.N = N\n        self.resampling = resampling\n        self.ESSrmin = ESSrmin\n\n        # initialisation\n        self.t = 0\n        self.rs_flag = False  # no resampling at time 0, by construction\n        self.logLt = 0.0\n        self.wgts = Weights()\n        self.X, self.Xp, self.A = None, None, None\n\n        self.summaries = Summaries(collect)\n        self.hist = generate_hist_obj(store_history, self)\n\n    def generate_particles(self):\n        \"\"\"Generate particles at time t=0\"\"\"\n        self.X = self.fk.M0(self.N)\n    \n    def reset_weights(self):\n        \"\"\"Reset weights to uniform after a resamping step\"\"\"\n        self.wgts = Weights()\n    \n    def resample_move(self):\n        \"\"\"Adaptively resample and move particles at time t\"\"\"\n        self.rs_flag = self.fk.time_to_resample(self)\n        if self.rs_flag:\n            self.A  = systematic(self.wgts.W, M=self.N)\n            self.Xp = self.X[self.A]\n            self.reset_weights()\n        else:\n            self.A = np.arange(self.N)\n            self.Xp = self.X\n        self.X = self.fk.M(self.t, self.Xp)\n\n    def reweight_particles(self):\n        \"\"\"Reweight particles at time t\"\"\"\n        self.wgts = self.wgts.add(self.fk.logG(self.t, self.Xp, self.X))\n\n    def compute_summaries(self):\n        \"\"\"Compute summaries at time t\"\"\"\n        if self.t &gt; 0:  # なぜかこれを前におかないとUnboundLocalErrorが出る\n            prec_log_mean_w = self.log_mean_w\n        self.log_mean_w = self.wgts.log_mean\n        if self.t == 0 or self.rs_flag:\n            self.loglt = self.log_mean_w\n        else:\n            self.loglt = self.log_mean_w - prec_log_mean_w\n        self.logLt += self.loglt\n\n        self.hist.save(self)\n        self.summaries.collect(self)\n\n    def __next__(self):\n        \"\"\"One step of the SMC algorithm\"\"\"\n        if self.fk.done(self):\n            raise StopIteration\n        if self.t == 0:\n            self.generate_particles()\n        else:\n            self.resample_move()\n        self.reweight_particles()\n        self.compute_summaries()\n        self.t += 1\n\n    def __iter__(self):\n        return self\n\n    def run(self):\n        \"\"\"Run the SMC algorithm until completion\"\"\"\n        for _ in self:\n            pass"
  },
  {
    "objectID": "posts/2023/2023-12-11/ParticleFilter.html#粒子フィルタの実行東京の年別気温データ",
    "href": "posts/2023/2023-12-11/ParticleFilter.html#粒子フィルタの実行東京の年別気温データ",
    "title": "粒子フィルターの実装 | Particles Package",
    "section": "4 粒子フィルタの実行：東京の年別気温データ",
    "text": "4 粒子フィルタの実行：東京の年別気温データ\n\n4.1 Feynman-Kacモデルの枠組み\nparticle パッケージの抽象クラス FeynmanKac は次のメソッドを持つ．3\n\nM0(N): 初期分布 \\(M_0\\) から \\(N\\) 個のサンプルを生成する．\nM(t, xp): カーネル \\(M_t(x_{t-1}|-)\\) から \\(X_t\\) をサイズ xp.shape[0] で生成する．\nlogG(t, xp, x): ポテンシャル \\(G_t(x_{t-1},x_t)\\) の対数を返す．\n\n加えて，粒子フィルターの実行時に必要なフラグも用意する．\n\ntime_to_resample(smc): smc オブジェクトを引数に取り，その属性 smc.aux.ESS, smc.ESSrmin からリサンプリングが必要かどうかを判定する．\ndone(smc): smc オブジェクトを引数に取り，その属性 smc.t, smc.T からアルゴリズムを終了すべきかどうかを判定する．\n\nparticle パッケージを使うときは FeynmanKac クラスを継承して用いることになるが，ここでは自分で定義していく．\n\n\n4.2 使用するデータ\n気象庁が HP にて公開している1876年から2022年までの計147年分の東京の年別気温データを用いる．\n\n\nCode\nimport pandas as pd\n\ndata = pd.read_csv(\"TemperatureDataAtTokyo.csv\")\nprint(data.describe())\n\n\n                年度         日平均         日最高        日最低          最高          最低\ncount   147.000000  147.000000  147.000000  147.00000  147.000000  147.000000\nmean   1949.000000   14.963946   19.337415   11.12517   35.098639   -4.317687\nstd      42.579338    1.132396    0.875794    1.46614    1.674956    2.439366\nmin    1876.000000   12.900000   17.500000    8.30000   31.600000   -9.200000\n25%    1912.500000   14.000000   18.700000    9.90000   34.000000   -6.150000\n50%    1949.000000   14.800000   19.300000   10.80000   34.900000   -4.700000\n75%    1985.500000   15.800000   19.900000   12.30000   36.200000   -2.250000\nmax    2022.000000   17.300000   21.300000   13.90000   39.500000    0.900000\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(3, 2))\n\nplt.title(\"temperature in Tokyo\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Temperature (Celsius)\")\n\nplt.scatter(data['年度'], data['日平均'], s=2)\nplt.show()\n\n\n\n\n\n\n\n4.3 気温の1次のトレンドモデル\n気温の観測値 \\(\\{y_k\\}\\) に対して，1次元の線型Gauss状態空間モデル \\[\n\\begin{cases}\nx_k=x_{k-1}+v_k,\\\\\ny_k=x_k+w_k.\n\\end{cases}\n\\tag{1}\\] \\[\nv_k\\overset{\\mathrm{i.i.d.}}{\\sim}\\mathrm{N}(0,Q^2),\\quad w_k\\overset{\\mathrm{i.i.d.}}{\\sim}\\mathrm{N}(0,R^2),\n\\] を想定する．このモデルを1次のトレンドモデルという (北川, 2005, p. 第11章)．\nこれをSMCメソッド（ 節 3 ）に渡せるように実装するには次のようにする：\n\n\nCode\nfrom numpy import random\nfrom scipy import stats\n\nclass Bootstrap:\n    \"\"\"Abstract base class for Feynman-Kac models derived from State Space Model (1).\n    \"\"\"\n\n    def __init__(self, data, T, R, Q):\n        self.data = data\n        self.T = T\n        self.R = R\n        self.Q = Q\n    \n    def M0(self, N):\n        \"\"\"Sample N times from initial distribution M0 of the FK model\"\"\"\n        return random.normal(loc=13.6, scale=self.Q, size=N)\n    \n    def M(self, t, xp):  # xp: resampled previous state\n        \"\"\"Sample Xt from kernel Mt conditioned on Xt-1=xp\"\"\"\n        return random.normal(loc=xp, scale=self.Q, size=xp.shape[0])\n    \n    def logG(self, t, xp, x):  # x: current state\n        \"\"\"Evaluate the log potential Gt(xt-1,xt)\"\"\"\n        return stats.norm.logpdf(self.data[t], loc=x, scale=self.R)\n    \n    def time_to_resample(self, smc):\n        \"\"\"Return True if resampling is needed\"\"\"\n        return smc.wgts.ESS &lt; smc.N * smc.ESSrmin\n    \n    def done(self, smc):\n        \"\"\"Return True if the algorithm is done\"\"\"\n        return smc.t &gt;= self.T\n\n\n\n\n4.4 \\((R,Q)=(0.2,0.1)\\) の場合\n仮に \\((R,Q)=(0.2,0.1)\\) としてみる．すなわち，システムノイズ \\(Q^2=0.1\\) が小さく，観測ノイズ \\(R^2=0.4\\) はそれよりは大きいとしている．\n\n\nCode\nmodel1 = Bootstrap(data=data['日平均'], T=data.shape[0], R=0.2, Q=0.1)\nPF1 = SMC(fk=model1, N=1000, resampling=\"systematic\", ESSrmin=0.5, collect=[Moments], store_history=True)\nPF1.run()\n\n\n\n\nCode\nplt.figure(figsize=(3, 2))\nplt.plot(data['日平均'], label='data', linestyle='', marker='.')\nplt.plot([m['mean'] for m in PF1.summaries.Moments], label='filtered temperature trend')\nplt.show()\n\n\n\n\n\n図 1: (R,Q)=(0.2,0.1) の場合の粒子フィルターの実行結果\n\n\n\n\n少し揺らぎながらも，トレンドとして気温が上昇していく様子が見られる．\n\n\n4.5 \\((R,Q)=(0.7,0.1)\\) の場合\n濾波して得たトレンドの揺らぎが少し大きいと思われたため，観測誤差はもう少し大きいものとして \\((R,Q)=(0.7,0.1)\\) としてみる．\n\n\nCode\nmodel4 = Bootstrap(data=data['日平均'], T=data.shape[0], R=0.7, Q=0.1)\nPF4 = SMC(fk=model4, N=1000, resampling=\"systematic\", ESSrmin=0.5, collect=[Moments], store_history=True)\nPF4.run()\n\n\n\n\nCode\nplt.figure(figsize=(3, 2))\nplt.plot(data['日平均'], label='data', linestyle='', marker='.')\nplt.plot([m['mean'] for m in PF4.summaries.Moments], label='filtered temperature trend')\nplt.show()\n\n\n\n\n\n(R,Q)=(0.7,0.1) の場合の粒子フィルターの実行結果\n\n\n\n\nこうしてトレンドとして少しばかり直線的なものが得られた．やはり上昇トレンドが見られる．\n\n\n4.6 \\((R,Q)=(0.2,0.01)\\) の場合\n\\(Q^2=10^{-4}\\) としてシステムノイズは極めて小さいと想定してみる．「トレンドは殆ど変化しない」という仮定を置いたことになる．\n\n\nCode\nmodel2 = Bootstrap(data=data['日平均'], T=data.shape[0], R=0.2, Q=0.01)\nPF2 = SMC(fk=model2, N=1000, resampling=\"systematic\", ESSrmin=0.5, collect=[Moments], store_history=True)\nPF2.run()\n\n\n\n\nCode\nplt.figure(figsize=(3, 2))\nplt.plot(data['日平均'], label='data', linestyle='', marker='.')\nplt.plot([m['mean'] for m in PF2.summaries.Moments], label='filtered temperature trend')\nplt.show()\n\n\n\n\n\n(R,Q)=(0.2,0.01) の場合の粒子フィルターの実行結果\n\n\n\n\nあまり良い当てはまりを見せないため，この気温の時系列を全てが観測誤差によるものだと理解するのは妥当ではないと考えられる．\n\n\n4.7 \\((R,Q)=(0.2,1)\\) の場合\n逆にシステムノイズを極めて大きい値 \\(Q^2=1\\) と設定する．トレンドは年別の揺らぎが大きいと想定したことになる．\n\n\nCode\nmodel3 = Bootstrap(data=data['日平均'], T=data.shape[0], R=0.2, Q=1.0)\nPF3 = SMC(fk=model3, N=1000, resampling=\"systematic\", ESSrmin=0.5, collect=[Moments], store_history=True)\nPF3.run()\n\n\n\n\nCode\nplt.figure(figsize=(3, 2))\nplt.plot(data['日平均'], label='data', linestyle='', marker='.')\nplt.plot([m['mean'] for m in PF3.summaries.Moments], label='filtered temperature trend')\nplt.show()\n\n\n\n\n\n(R,Q)=(0.2,1) の場合の粒子フィルターの実行結果\n\n\n\n\nとんでもない過適応を見せて，全てをトレンドとして説明してしまっており，これもまた妥当ではないと考えられる．\n\n\n4.8 カルマンフィルタとの比較\n線型Gaussモデルを想定しているため，粒子フィルターは \\(N\\to\\infty\\) の極限で最適フィルターであるカルマンフィルターに一致するはずである．そこで，pykalman パッケージを用いてこれを実装する．\\((R,Q)=(0.2,0.1)\\) とする．\n\n\nCode\nfrom pykalman import KalmanFilter\nKF1 = KalmanFilter(initial_state_mean=13.6, initial_state_covariance=0.1,\n                   transition_matrices=1, observation_matrices=1,\n                   transition_covariance=0.1, observation_covariance=0.2, n_dim_state=1, n_dim_obs=1)\nKF1 = KF1.em(data['日平均'], n_iter=5)  # EMアルゴリズムの過適応回避のため\n(filtered_state_means, filtered_state_covariances) = KF1.filter(data['日平均'])\n\n\n\n\nCode\nplt.figure(figsize=(3, 2))\nplt.plot(data['日平均'], label='data', linestyle='', marker='.')\nplt.plot(filtered_state_means, label='filtered temperature trend')\nplt.show()\n\n\n\n\n\n(R,Q)=(0.2,0.1) の場合のKalmanフィルターの実行結果\n\n\n\n\nたしかに 図 1 と極めて似通った結果になっている．\n\n\n4.9 カルマン平滑化の結果\n\n\nCode\n(smoothed_state_means, smoothed_state_covariances) = KF1.smooth(data['日平均'])\n\n\n\n\nCode\nplt.figure(figsize=(3.5, 3))\nplt.plot(data['日平均'], label='data', linestyle='', marker='.')\nplt.plot(smoothed_state_means, label='smoothed temperature trend')\nplt.show()\n\n\n\n\n\n(R,Q)=(0.2,0.1) の場合のKalman平滑化の実行結果\n\n\n\n\nより滑らかなトレンドが得られている．"
  },
  {
    "objectID": "posts/2023/2023-12-11/ParticleFilter.html#footnotes",
    "href": "posts/2023/2023-12-11/ParticleFilter.html#footnotes",
    "title": "粒子フィルターの実装 | Particles Package",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n実はこのリサンプリング法は (北川源四郎, 1996) の付録で原型が（全く決定論的なアルゴリズムとして）提案されている↩︎\n有効サンプル数の定義については (Chopin & Papaspiliopoulos, 2020) 参照．↩︎\nFeynman-Kacモデルなどの用語については (Chopin & Papaspiliopoulos, 2020) 参照．↩︎"
  },
  {
    "objectID": "static/Materials.html",
    "href": "static/Materials.html",
    "title": "Materials",
    "section": "",
    "text": "筆者の専門であるベイズ計算と相関粒子法（特に粒子フィルター）に関する概観的な記事．\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nCategories\n\n\n\n\n\n\n\n\n\n12/6/23\n\n\nベイズ計算とは何か | About Bayesian Computation\n\n\nSurvey,Computation\n\n\n\n\n\n\n\n11/25/23\n\n\n粒子フィルターとは何か | About Particle Filters（執筆中）\n\n\nParticles,Survey\n\n\n\n\n\n\n\n12/11/23\n\n\n粒子フィルターの実装 | Particles Package\n\n\nParticles,Python\n\n\n\n\n\n\nNo matching items\n\n\n相関粒子法に関連する記事の全ては，カテゴリ Particles から．"
  },
  {
    "objectID": "static/Materials.html#紹介記事",
    "href": "static/Materials.html#紹介記事",
    "title": "Materials",
    "section": "紹介記事",
    "text": "紹介記事\n筆者の専門であるベイズ計算と相関粒子法（特に粒子フィルター）に関する概観的な記事．\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nCategories\n\n\n\n\n\n\n\n\n\n12/6/23\n\n\nベイズ計算とは何か | About Bayesian Computation\n\n\nSurvey,Computation\n\n\n\n\n\n\n\n11/25/23\n\n\n粒子フィルターとは何か | About Particle Filters（執筆中）\n\n\nParticles,Survey\n\n\n\n\n\n\n\n12/11/23\n\n\n粒子フィルターの実装 | Particles Package\n\n\nParticles,Python\n\n\n\n\n\n\nNo matching items\n\n\n相関粒子法に関連する記事の全ては，カテゴリ Particles から．"
  },
  {
    "objectID": "posts/2023/2023-11-4/QuartoBasics.html#pdfの作り方",
    "href": "posts/2023/2023-11-4/QuartoBasics.html#pdfの作り方",
    "title": "Quartoはじめて良かった | Quarto Basics in Japanese",
    "section": "5 PDFの作り方",
    "text": "5 PDFの作り方\nLuaLaTeXを利用することで日本語を含んだPDFを作成できる．\n\n\nreport.qmd\n\ntitle: \"タイトル\"\nauthor: Hirofumi Shiba\ndate: 2023/12/11\nformat:\n  pdf:\n    toc: true\n    number-sections: true\n    colorlinks: true\n    include-in-header: \n      - file: ../_preamble.tex\npdf-engine: lualatex\ndocumentclass: ltjsarticle"
  },
  {
    "objectID": "posts/2023/2023-11-4/QuartoBasics.html#スライドの作り方",
    "href": "posts/2023/2023-11-4/QuartoBasics.html#スライドの作り方",
    "title": "Quartoはじめて良かった | Quarto Basics in Japanese",
    "section": "6 スライドの作り方",
    "text": "6 スライドの作り方"
  },
  {
    "objectID": "static/Materials.html#その他",
    "href": "static/Materials.html#その他",
    "title": "Materials",
    "section": "その他",
    "text": "その他\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nCategories\n\n\n\n\n\n\n\n\n\n12/2/23\n\n\n条件付き期待値の測度論的基礎付け\n\n\nProbability,Math Notes\n\n\n\n\n\n\n\n11/25/23\n\n\n粒子フィルターとは何か | About Particle Filters（執筆中）\n\n\nParticles,Survey\n\n\n\n\n\n\n\n12/11/23\n\n\n粒子フィルターの実装 | Particles Package\n\n\nParticles,Python\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "static/Materials.html#数学記事",
    "href": "static/Materials.html#数学記事",
    "title": "Materials",
    "section": "数学記事",
    "text": "数学記事\n\n\n\n\n\n\nTitle\n\n\n\n\n\n\n数学記法一覧 | Notations on This Website\n\n\n\n\n条件付き期待値の測度論的基礎付け\n\n\n\n\n数学者のためのカーネル法概観\n\n\n\n\n条件付き正規分布からのシミュレーション法\n\n\n\n\n独立なGamma確率変数の商による変換も独立\n\n\n\n\n\n\nNo matching items\n\n\n数学に関連する記事の全ては，カテゴリ Math Notes から．中でも確率論についてはカテゴリ Probability から．"
  },
  {
    "objectID": "static/Materials.html#自分について",
    "href": "static/Materials.html#自分について",
    "title": "Materials",
    "section": "自分について",
    "text": "自分について\n\n\n\n\n\n\nTitle\n\n\n\n\n\n\nInfluential Books Which Paved My Path into Mathematics\n\n\n\n\n俺の人生を変えたものTop5\n\n\n\n\n相関粒子系の社会実装\n\n\n\n\n\n\nNo matching items\n\n\n人生に関連する記事の全ては，カテゴリ Life から．生活に関する記事はカテゴリ Lifestyle から．"
  },
  {
    "objectID": "static/Materials.html#研究記事",
    "href": "static/Materials.html#研究記事",
    "title": "Materials",
    "section": "研究記事",
    "text": "研究記事\n筆者の専門であるベイズ計算と相関粒子法に関する概観的な記事．\n\n\n\n\n\n\nTitle\n\n\n\n\n\n\nベイズ計算とは何か | About Bayesian Computation\n\n\n\n\n粒子フィルターとは何か | About Particle Filter\n\n\n\n\n粒子フィルターの実装 | Particles Package\n\n\n\n\n粒子フィルターを用いたサンプリング\n\n\n\n\n\n\nNo matching items\n\n\n相関粒子法に関連する記事の全ては，カテゴリ Particles から．"
  },
  {
    "objectID": "posts/2023/2023-12-12/Notations.html",
    "href": "posts/2023/2023-12-12/Notations.html",
    "title": "数学記法一覧 | Notations on This Website",
    "section": "",
    "text": "本サイトの記法で筆者が最も注意することは，あらゆる記法を背後の数学的消息と調和するように定義するということである．それにあたり，あらゆる 数学的対象 を集合から構成する立場を取る一方で，理解するにあたっては集合と写像（または関手）とを厳密に峻別するということを徹底する．1"
  },
  {
    "objectID": "posts/2023/2023-12-12/Notations.html#集合の構成",
    "href": "posts/2023/2023-12-12/Notations.html#集合の構成",
    "title": "数学記法一覧 | Notations on This Website",
    "section": "1 集合の構成",
    "text": "1 集合の構成\n\n$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$\n\nここでは，あらゆる数学概念は，ZFC公理系 の下で集合として定義する．2 記号 \\(:=\\) は「右辺によって左辺を定義し，その結果等号が成り立つ」という主張の略記である．3\n\n1.1 集合\n\n空集合 を \\[\n\\emptyset:=\\{x\\mid x\\ne x\\}\n\\] で表す．4\n集合 \\(X\\) の 冪集合 を \\(P(X)\\) で表す．5\n非交和 \\(A\\sqcup B\\) とは，\\(A\\cup B\\) と同じ数学的対象であるが，同時に \\(A\\cap B\\) という事実も主張するものとする．6\n有限集合 \\(X\\) の元の数を \\(\\lvert X\\rvert\\) または \\(\\#X\\) で表す．7\n\n\n\n1.2 数\n\n自然数 を \\[\n0:=\\emptyset,\\quad 1:=\\{0\\}=0\\cup\\{0\\},\n\\] \\[\n2:=\\{0,1\\}=1\\cup\\{1\\},\n\\] \\[\nn+1:=n\\cup\\{n\\},\n\\] によって帰納的に定義する．8\n自然数の集合を表すため，次の記法を用意する：9 \\[\n[n]:=\\{1,\\cdots,n\\}=n+1\\setminus1.\n\\]\n\\(\\mathbb{R}_+\\) で 非負実数 の全体，10 \\(\\mathbb{R}^+\\) で 正実数 の全体がなす集合を表す： \\[\n\\mathbb{R}_+=[0,\\infty),\\quad\\mathbb{R}^+=(0,\\infty).\n\\]\n部分集合 \\(\\mathbb{Z},\\mathbb{Q}\\subset\\mathbb{R}\\) についても同様．特に \\(\\mathbb{N}=\\mathbb{Z}_+\\)．\n\n\n\n1.3 組\n\n\\(n\\)-組 を次のように帰納的に定める：11 \\[\n(x_1,x_2):=\\{\\{x_1\\},\\{x_1,x_2\\}\\},\n\\] \\[\n(x_1,\\cdots,x_n):=(x_1,(x_2,\\cdots,x_n)).\n\\]\n自然数の組を表すため，次の記法を用意する：12 \\[\n1:N:=(1,\\cdots,N).\n\\]\n数学的対象 \\(X_1,\\cdots,X_N\\) の組を \\[\nX_{1:N}:=(X_1,\\cdots,X_N)\n\\] と表す．13\n\n\n\n1.4 写像\n\\(X,Y\\) を集合，\\(f:X\\to Y\\) を写像とする．\n\n引数のプレイスホルダーとして \\(-\\) を用い，\\(f(-)\\) などと表す．\n写像 \\(f\\) の 値域 を \\[\\mathrm{Im}\\,f:=f(X)\\] で表す．\n\\(A\\subset X\\) の像を \\(f(A)\\) で表し，これが集合であることを特に明示する際は \\(f_*(A)\\) とも表す．14\n\\(f_*\\) は部分集合 \\(A\\subset X\\) を像 \\(f(A)\\subset Y\\) に対応させる写像 \\[\nf_*:P(X)\\to P(Y)\\] と定義する．\n同様に写像 \\(f^*:P(Y)\\to P(X)\\) を定める： \\[\nf^*(B)=f^{-1}(B)\\quad(B\\subset Y).\n\\]\n部分集合 \\(A\\subset X\\) の 特性関数 を \\(1_A:X\\to2\\) で表す．\n写像 \\(f:X\\to Y\\) の全体がなす集合を \\(Y^X\\) または \\(\\mathrm{Map}(X,Y)\\) で表す．15\n写像 \\(f:X\\to Y\\) のうち，有限個の元を除いて \\(f(x)=0\\) を満たすものがなす全体を \\[\nY^{(X)}:=\\left\\{f\\in Y^X\\mid f=0\\;\\;\\text{f.e.}\\right\\}\n\\] と表す．16\n\\(P(X)\\) を \\(2^X\\) と同一視する．特に，\\(X\\) の有限部分集合の全体を \\[\n2^{(X)}=\\left\\{A\\in P(X)\\:\\middle|\\: A\\overset{\\text{finite}}{\\subset}X\\right\\}\n\\] と表す．17\n全射 を \\(f:X\\twoheadrightarrow Y\\)，単射 を \\(f:X\\hookrightarrow Y\\) で強調して表すことがある．18\n全単射 が特に特定の圏での 同型射 でもある場合 \\(f:X\\overset{\\sim}{\\to}Y\\) と強調して表すことがある．\n積空間 \\(\\prod_{i\\in I}X_i\\) からの 第 \\(i\\) 射影 を \\[\n\\mathrm{pr}_i:\\prod_{i\\in I}X_i\\twoheadrightarrow X_i\n\\] で表す．\n\\(x\\in X\\) での 評価写像 を \\[\n\\mathrm{ev}_x:Y^X\\twoheadrightarrow Y\n\\] で表す．19\n写像 \\(I\\ni i\\mapsto X_i\\) を 族 とも呼び，\\((X_i)_{i\\in I}\\) と表す．\nしかしこの写像の値域も 族 と呼び，この場合は \\[\\{X_i\\}_{i\\in I}:=\\mathrm{Im}\\,(X_i)_{i\\in I}\\] と表す．20\n特に \\(I=\\mathbb{N}\\) のときは 列 ともいう．\\(I\\overset{\\text{finite}}{\\subset}\\mathbb{N}\\) のときは組と同一視する．21\n\n\n\n1.5 圏\n\n集合の圏 を \\(\\mathrm{Set}\\) で表す．\n確率空間と確率核の圏を \\(\\mathrm{Stoch}\\) で表す．22\n圏 \\(C\\) の対象 \\(X,Y\\in C\\) の間の 射 の全体を \\(\\mathrm{Hom}_C(X,Y)\\) で表す．23\n特に \\[\nY^X=\\mathrm{Map}(X,Y)=\\mathrm{Hom}_\\mathrm{Set}(X,Y).\n\\]\n圏 \\(C\\) の対象 \\(X\\in C\\) の自己射の全体を \\[\n\\mathrm{End}_C(X):=\\mathrm{Hom}_C(X,X)\n\\] で表す．\nそのうち可逆なもののなす部分集合を \\(\\mathrm{Aut}_C(X)\\) で表す．集合 \\([n]\\) の 置換群 は \\(\\mathrm{Aut}_\\mathrm{Set}([n])\\) と表せる．\n\n\n\n1.6 関数\n\n関数 \\(f:X\\to Y\\) のうち定値なもの \\(f\\equiv a\\in Y\\) を \\(Y\\hookrightarrow Y^X\\) により \\(Y\\) の元と同一視する．24\n束 \\(L\\) の元 \\(a,b\\) に対して，上限と下限を \\[\na\\lor b:=\\sup\\{a,b\\},\n\\] \\[\na\\land b:=\\inf\\{a,b\\},\n\\] で表す．25\n次の略記を使う： \\[a_+:=a\\lor0,\\] \\[a_-:=-(a\\land 0).\\]\n関数 \\(f,g\\in\\mathrm{Map}(X,Y)\\) について，\\(f\\le g\\) とは \\[\n\\forall_{x\\in X}\\;f(x)\\le g(x)\n\\] の略記とする．\n同じ条件を，一階の量化記号 \\(\\forall\\) を省略して \\[\nf(x)\\le g(x)\\quad(x\\in X)\n\\] とも略記する．\nこの順序により関数の空間 \\(\\mathrm{Map}(X,Y)\\) は束となり，演算 \\(\\land,\\lor\\) が定まる．\n関数 \\(g:\\mathbb{R}^+\\to\\mathbb{R}\\) に対して \\[\nO(g(\\epsilon))\\;(\\epsilon\\to\\infty)\\] とは，条件 \\[\n\\exists_{c&gt;0}\\;\\exists_{\\epsilon_0&gt;0}\\;\\forall_{\\epsilon\\ge\\epsilon_0}\\;\\lvert f(\\epsilon)\\rvert\\le c\\lvert g(\\epsilon)\\rvert\n\\] を満たす関数 \\(f:\\mathbb{R}^+\\to\\mathbb{R}\\) の全体とする．26\nただし，\\(O(g)\\) はその任意の元を表すとして， \\[\nf(\\epsilon)=O(g(\\epsilon))\\quad(\\epsilon\\to\\infty)\n\\] を \\(f(\\epsilon)\\in O(g(\\epsilon))\\;(\\epsilon\\to\\infty)\\) の意味でも使う．\n\n\n\n1.7 演算\n\n次の演算規則を約束する：27 \\[\n\\prod_\\emptyset=1,\\quad\\sum_{\\emptyset}=0.\n\\]"
  },
  {
    "objectID": "posts/2023/2023-12-12/Notations.html#関数空間",
    "href": "posts/2023/2023-12-12/Notations.html#関数空間",
    "title": "数学記法一覧",
    "section": "2 関数空間",
    "text": "2 関数空間\n\\((E,\\mathcal{E})\\) を可測空間とする．\n\n\\((E,\\mathcal{E})\\) 上の 確率測度 の全体を \\(\\mathcal{P}(E)\\) と書く．\n\\((E,\\mathcal{E})\\) 上の 可測関数 の全体を \\(\\mathcal{L}(E)\\) と書く．\n\\((E,\\mathcal{E})\\) 上のある測度について，殆ど至る所で等しい関数を同一視して得る商空間を \\(L(E)\\) と書く．この規則は任意のLebesgue空間 \\(L^p(E)\\) で同じである．\n\nなお，全ての関数空間 \\(F(E)\\) に対して，値域の空間が \\(\\mathcal{X}\\) であるとき，これを強調して \\(F(E;\\mathcal{X})\\) とも表す．"
  },
  {
    "objectID": "posts/2023/2023-12-12/Notations.html#footnotes",
    "href": "posts/2023/2023-12-12/Notations.html#footnotes",
    "title": "数学記法一覧 | Notations on This Website",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n例えば集合の合併と共通部分に \\(\\cap,\\cup\\) を用いること，直和と直積に \\(\\coprod,\\prod\\) を用いることは，圏論的な双対性を視覚的に認識しながら数学的議論を進めるためである．(斎藤毅, 2009, p. 37) にも詳しく解説されている．↩︎\n集合のなす圏 \\(\\mathrm{Set}\\) は数学の基礎付けとして採用するのに極めて良い性質を持つ nLab．↩︎\n(Del Moral & Penev, 2014) に一致する．\\(\\equiv,\\overset{\\text{def}}{=}\\) などもよく用いられる．(Crisan & Doucet, 2002) では \\(\\overset{\\mathop{}\\!\\mathbin\\bigtriangleup}{=}\\) も用いられる．ここでは，これらの左右対称な記号は避けた．↩︎\n(Shoenfield, 1967, p. 243), (新井敏康, 2011, p. 2) の定め方に一致する．↩︎\n(斎藤毅, 2009, p. 13) の記法に一致する．この定義と存在は公理から直ちに従う nLab．このときの \\(P\\) も関手である．関手が，対象 \\(S\\) に作用していると読めるように設計された記法である nLab．↩︎\n(斎藤毅, 2009, p. 10) は \\(A\\coprod B\\) と表す．↩︎\n\\(\\mathrm{Card}\\,(X)\\) とも表される，(Gerber et al., 2019) など．↩︎\n(von Neumann, 1923) による定義である．(斎藤毅, 2009, pp. 15–16), Wikipedia とも一致する．↩︎\n(Chopin et al., 2022), (Srinivasan, 2001) なども採用している．↩︎\n(鎌谷研吾, 2020, p. 106) の記法に一致する．↩︎\n(Kuratowski, 1921) による定義である．(Shoenfield, 1967, p. 243), (新井敏康, 2011, p. 118), (斎藤毅, 2009, pp. 定義1.3.1 p.15) の定め方に一致する．また \\(n\\)-組を英語では tuple と呼ぶが，全く同じ対象をリスト (list) とも呼ぶ nLab Concept with an Attitude．↩︎\n(Chopin & Papaspiliopoulos, 2020), (Chopin et al., 2022) などが採用している．↩︎\nこれは組 \\((X_1,\\cdots,X_N)\\) が定める \\(X:[N]\\ni i\\mapsto X_i\\) という写像があった際，この写像の積 \\(\\prod_{i\\in[N]}X\\) による \\(1:N\\) の像を \\(X_{1:N}\\) と略記する，という意味である．↩︎\n(斎藤毅, 2009, p. 43), (斎藤毅, 2020, p. 12) に従った．対応 \\(f\\mapsto f_*\\) は共変関手 \\(P_*:\\mathrm{Set}\\to\\mathrm{Set}\\) を定める．↩︎\nこれは配置集合とも言う．\\(Y^X\\) は (松坂和夫, 1968, p. 38), (Giné & Nickl, 2021) に，\\(\\mathrm{Map}(X,Y)\\) は (斎藤毅, 2009, p. 26) に倣った．↩︎\n(斎藤毅, 2007, pp. 例1.4.7 p.20) に従った．また f.e. とは with a finite number of exceptions の略で，「有限個の例外を除いて成り立つ」という意味である (伊藤清, 1991, p. 124)．↩︎\n(斎藤毅, 2009, p. 179) では \\(F(X)\\) と表記している．↩︎\nnLab に倣った．本来はエピ射とモノ射を表す記法であるが，ここでは集合の圏 \\(\\mathrm{Set}\\) に限ることとする．↩︎\n(斎藤毅, 2009, p. 27) では値写像と訳している．↩︎\n(斎藤毅, 2009, p. 26) に倣った．この混用については p.35 で触れられている．↩︎\n(斎藤毅, 2009, p. 37) にも詳しく解説されている．このような態度は concept with an attitude という．↩︎\n(Fritz, 2020, p. 19), (Perrone, 2022) など．Markov圏の稿 も参照↩︎\nnLab の記法に一致する．(斎藤毅, 2020, p. 7) では \\(\\mathrm{Mor}_C(X,Y)\\) と表す．↩︎\n\\(Y=\\mathbb{R}\\) のときなどは，\\(0,1\\) によって関数の環 \\(\\mathbb{R}^X\\) の零元と単位元が表せる (Del Moral, 2004, p. 7)．↩︎\n(Del Moral & Penev, 2014, p. xlvii) に一致する．↩︎\nnLab に従った．\\(O\\) は写像 \\(\\mathbb{R}^\\mathbb{R}\\to P(\\mathbb{R}^\\mathbb{R})\\) を定める．(Del Moral & Penev, 2014, p. xlvii) にも言及がある．↩︎\n(Del Moral & Penev, 2014, p. xlviii), (Del Moral, 2004, p. 10) の定義に一致する．これは \\(\\prod_{i\\in\\emptyset}X_i\\) が一点集合で，\\(\\coprod_{i\\in I}X_i\\) が空集合である消息の一般化と見れる．なお，集合 \\(X\\) の部分集合の空な族 \\((X_i)_{i\\in\\emptyset}\\) は存在し，それは \\(\\mathrm{Map}(\\emptyset,X_i)\\) のただ一つの元である．↩︎\n(Pedersen, 1989, p. 8) も同様の記法を採用しているが，近傍の全体の意味においてである．この場合は \\(P(X)\\) のフィルターをなす．一方で我々は開近傍に限る．この場合は \\(\\mathcal{O}\\) のフィルターをなす．↩︎\n(斎藤毅, 2009, p. 86), (斎藤毅, 2007, p. 13) に従った．↩︎\n(斎藤毅, 2009, p. 75) に従った．↩︎\n(Pedersen, 1989, p. 44) に倣った．↩︎\n(Pedersen, 1989, p. 41) など．↩︎\n(Pedersen, 1989, pp. 2.5.1 p.70) など．↩︎\nすなわち， \\(\\mathcal{F}(x;y)\\) という記法は，\\(y\\) は写像（あるいは関手） \\(\\mathcal{F}\\) のパラメータ付けをする添字として理解する数学的対象，\\(x\\) は写像（あるいは関手）の引数として理解する数学的対象として峻別する．↩︎\n(Bogachev, 2007, p. 188), (Lang, 1993, p. 158) に従った．↩︎\nこのような一般的な場合の定義は (Bogachev, 2007, p. 189) 参照．↩︎\n(Giné & Nickl, 2021, p. 16) に倣った．↩︎\n(Nualart & Nualart, 2018, p. 8) に倣った．(Gerber et al., 2019) などは \\(\\lambda_d\\) と表す．↩︎\n(Nualart & Nualart, 2018) に倣った．(Giné & Nickl, 2021) では \\(\\mathrm{Pr}\\) と表している．↩︎\n標準 Borel 空間 ともいう．↩︎\n(Nualart & Nualart, 2018, p. 1) に倣った．(Giné & Nickl, 2021) ではイタリック体で \\(E\\) と表している．(Del Moral & Penev, 2014) では \\(\\mathbb{E}\\) を用いる．↩︎\n(吉田朋広, 2006, p. 5) に倣った．筆者は \\(\\mathrm{E},\\mathrm{P}\\) のいずれも作用素と見る立場に立つためである．(Giné & Nickl, 2021) は \\(E[X],\\mathrm{Pr}\\{X\\in A\\}\\) と表す．(Nualart & Nualart, 2018), (伊藤清, 1991) はいずれも丸括弧である．(鎌谷研吾, 2020), (Bain & Crisan, 2009) では \\(\\mathbb{P}(-),\\mathbb{E}[-]\\) を用いている．(Del Moral & Penev, 2014) では \\(\\mathbb{E}(-),\\mathbb{P}(-)\\) を用いる．↩︎\n\\(V\\) は (伊藤清, 1991) に，\\(C\\) は (Giné & Nickl, 2021, p. 66) に倣った，いずれもイタリック体を用いていたが．(吉田朋広, 2006, p. 23), (鎌谷研吾, 2020), (Del Moral & Penev, 2014, p. xlvii) は代わりに \\(\\mathrm{Var},\\mathrm{Cov}\\) を用いている．↩︎\n(伊藤清, 1991, p. 125) に従った．ここでは 像測度 と 確率法則 と呼んでいる．像測度の呼び名は (Bogachev, 2007, p. 190) にも一致する．分布の押し出し測度としての理解は助けになると筆者は信ずる．nLab も参照．↩︎\n(Del Moral & Penev, 2014, p. xlvii) は \\(\\perp\\) を用いる．↩︎\nnLab (Concept with an Attitude) も参照．↩︎\n(Crisan & Doucet, 2002) に一致する．(Kechris, 1995, p. 109) はイタリックで \\(P(E)\\) と表す．↩︎\n(Pedersen, 1989, p. 72) に倣った．Radon 測度とは，内部正則性（＝緊密性） \\[\\forall_{B\\in\\mathcal{B}(E)}\\;\\forall_{\\epsilon&gt;0}\\;\\exists_{K\\overset{\\textrm{cpt}}{\\subset}B}\\;\\mu(B\\setminus K)&lt;\\epsilon\\] を満たす Borel 測度をいう．↩︎\n(竹村彰道, 2020) の記法に一致する．↩︎\n(Gerber et al., 2019) の記法に一致．分位点関数 (quantile function) (竹村彰道, 2020, p. 16)，確率表現関数 (森口繁一, 1995) などともいう．↩︎\n積空間 \\((\\mathcal{X}^T,\\mathcal{C})\\) に値を取る \\(\\mathcal{X}^T\\)-値確率変数とみなすことに同値になる nLab．積の普遍性が成り立つためである (Kallenberg, 2021, p. 15) 補題1.9．だが \\(\\mathcal{X}\\) が位相空間であるとき，\\(\\mathcal{X}^T\\) の Borel \\(\\sigma\\)-代数に \\(\\mathcal{B}(\\mathcal{X}^T)\\) ついても可測になるとは限らない．\\(X_t\\) の終域 \\(\\mathcal{X}\\) が 可分距離空間で，かつ \\(T\\) が可算集合であるときは，\\(\\mathcal{B}(\\mathcal{X}^T)=\\mathcal{C}\\) であるため，\\(\\mathcal{B}(\\mathcal{X}^T)/\\mathcal{F}\\)-可測であることとも同値になる (Kallenberg, 2021, p. 11) 補題1.2．↩︎\n筆者が考案した名称．族 \\((X_t)_{t\\in T}:T\\to\\mathcal{L}(\\Omega)\\) としての見方と転置の関係になっているところから．(伊藤清, 1991, p. 232) は 見本過程（関数） と呼び，記法 \\(X_\\bullet\\) を採用している．↩︎\n「第一種不連続」とは (伊藤清, 1991, p. 227) の用語．↩︎\n可測空間を \\((E,\\mathcal{E})\\) で表すのは，(Revuz, 1984)，(Le Gall, 2016), (Del Moral, 2004) に倣った．↩︎\n\\(\\mathcal{S}\\) は (Nihat Ay & Schwachhöfe, 2017, pp. 第3.1節 p.121) の記法に倣った．↩︎\n(Del Moral, 2004, p. 7) では \\(\\mathcal{M}(E)\\) と表し，(Lang, 1993, p. 199) で \\(M^1\\) と表す．有界かつRadonな符号付き測度を (Pedersen, 1989, p. 252) 6.5.8 は \\(M(E)\\) と表す．実は有限次元 Banach 空間 \\(B\\) について，\\(B\\)-値であることと有界であることは同値になる：「有界」測度と「有限」測度 を参照．\\(S(E;B)\\) の表記は，有界性はひとまず不問として \\(B\\)-値測度を表す際に使うこととする．↩︎\n(Del Moral & Penev, 2014, p. xli), (Del Moral, 2004, p. 7) では \\(\\mathcal{M}(E)\\) を有界な符号付き測度に用いている．↩︎\n(Revuz & Yor, 1999, p. 79) 定義III.1.1.1，(Revuz, 1984, p. 8) 定義1.1.1.1，(Kallenberg, 2017, p. 16), (Bass, 2011, p. 154) 定義19.2, (Cho & Jacobs, 2019, p. 962) 例7.2 では kernel，(Jacod & Shiryaev, 2003, p. 65)，(Kolokoltsov, 2011, p. 110) 3.5節, (Klenke, 2020, p. 204) 8.3節 では transition kernel と呼んでいる．↩︎\n(Kolokoltsov, 2011, p. 110) 3.5節 に倣った．(Del Moral, 2004, p. 9) は (bounded) integral operator と呼ぶ．↩︎\n実は有界核は，可測写像 \\(E\\to M^1(F)\\) と同一視出来る (Kallenberg, 2017, p. 30) 補題1.14．ただし，\\(M^1(F)\\) には \\(\\mathcal{L}_b(F)\\) が生成する最小の \\(\\sigma\\)-代数を考える．↩︎\n(Crisan & Doucet, 2002, p. 737) では Markov transition kernel，(Del Moral, 2004, p. 9), (Ghosal & van der Vaart, 2017, p. 6), (Fritz, 2020) では Markov kernel，(Kolokoltsov, 2011, p. 110) 3.5節 では transition probability kernel or simply probability kernel と呼び，(Chopin & Papaspiliopoulos, 2020, p. 36) 定義4.1, (Bremaud, 2020, p. 135) 3.3.3節 では propability kernel，(Kulik, 2018, p. 25) では probability kernel としてさらに半群性も満たす族を transition probability kernels と呼ぶ．(Le Gall, 2016, pp. 151–152) は Markovian transition kernel と transition semigroup と呼ぶ．(Kallenberg, 2017, p. 29) と (Hairer, 2021) では可測関数 \\(E\\to\\mathcal{P}(F)\\) と定義しており，transition kernel と呼んでしまう．(Bertsekas & Shreve, 1996, p. 134) 定義7.12 は stochastic kernel，(Giry, 1982), (Neveu, 1970) は transition probability, (Lawvere, 1962) は probabilistic mapping と呼んでいた．↩︎\n(Ghosal & van der Vaart, 2017, p. 510)，(Kallenberg, 2017) 補題1.14 p.30，(Hairer, 2021)．この事実により，\\(E\\) 上の（局所有限な） ランダム測度 とは，確率空間からの核 \\(\\Omega\\to E\\) に等しい．↩︎\nこれにより，積分核も核であり，\\(T\\) が \\(F\\) 上で密度を持つ特別な場合であったことがわかる．nLab も参照．↩︎\n(Kallenberg, 2017, p. 16) の呼び方に従った．(Gikhman & Skorokhod, 2004, p. 79) では 直積 と呼ばれており，p.76 定理II.4.1 でその存在が示されている．↩︎\nこちらも，行列積の一般化であることを踏まえて (Kallenberg, 2017, p. 16) の呼び方に従った．(Gikhman & Skorokhod, 2004, p. 79) では 畳み込み と呼ばれている．この式は Chapman-Kolmogorov 方程式 と呼ばれるものである．そこで，Chapman-Kolmogorov 方程式は，Markov 核の族 \\(\\{P_t\\}_{t\\in\\mathbb{R}_+}\\) が，この積という演算について半群性を満たす，という形の条件でよく登場する．↩︎\nこれより，確率核 \\(T:E\\to F\\) は，確率測度 \\((1,2)\\to(E,\\mathcal{E})\\) を \\((1,2)\\to(F,\\mathcal{F})\\) に「遷移」させているようにも思えるのである．↩︎\n(Pedersen, 1989, pp. 2.1.15 p.48) に倣った．↩︎\n(Del Moral & Penev, 2014, p. xliv) の記法に一致する．↩︎\n(Bogachev, 2007, p. 191) 8.3節 に倣った．↩︎\n例えば，コンパクト空間 \\(K\\) について，Radon 確率測度全体の集合 \\(P(X)\\) は \\(C(X)^*\\) の \\(w^*\\)-コンパクトな凸部分集合である (Pedersen, 1989, pp. 72–73) 命題2.5.7．↩︎\n\\(\\mathcal{F}_\\mathcal{X}(E)\\) という表記は (Ethier & Kurtz, 1986, p. 95) に倣った．↩︎\n(Giné & Nickl, 2021, p. 17) に倣った．↩︎\n(Pedersen, 1989, p. 222) に倣った．↩︎\n(Pedersen, 1989, p. 44) に倣った．↩︎\n(Lang, 1993, p. 65) に倣った．↩︎"
  },
  {
    "objectID": "posts/2023/2023-12-12/Notations.html#空間",
    "href": "posts/2023/2023-12-12/Notations.html#空間",
    "title": "数学記法一覧 | Notations on This Website",
    "section": "2 空間",
    "text": "2 空間\n\n2.1 位相\n\\((X,\\mathcal{O})\\) を 位相空間 とする．\n\n点 \\(x\\in X\\) の 開近傍 の全体を \\(\\mathcal{O}(x)\\subset\\mathcal{O}\\) で表す．28\n集合 \\(A\\subset X\\) について，\\(A^\\circ\\) で 内部，\\(\\overline{A}\\) で 閉包 を表す．\n\\(U\\in\\mathcal{O}\\) を \\(U\\overset{\\mathrm{open}}{\\subset}X\\) とも表す．\n閉集合 \\(F\\overset{\\textrm{closed}}{\\subset}X\\) とコンパクト集合 \\(K\\overset{\\textrm{cpt}}{\\subset}X\\) も同様の略記を用いる．\n\n\n\n2.2 線型空間\n\n体 \\(\\mathbb{F}\\) の元を成分に持つ \\((m,n)\\)-行列の全体を \\(M_{mn}(\\mathbb{F})\\) で表す．29\n\\(\\mathbb{F}\\)-線型空間 \\(X\\) の部分集合 \\(A,B\\subset X\\) と数 \\(\\lambda\\in\\mathbb{F}\\) について， \\[\n\\begin{align*}\n  A&+B\\\\\n  &\\quad:=\\left\\{a+b\\in X\\mid a\\in A,b\\in B\\right\\},\\\\\n  \\lambda &A:=\\left\\{\\lambda a\\in X\\mid a\\in A\\right\\},\n\\end{align*}\n\\] と表す．\n\n\n\n2.3 Banach空間\n\n距離空間 \\((T,d)\\) の 開球 を \\[\n\\begin{align*}\n  U_\\epsilon(t)&:=U(t;\\epsilon)\\\\\n  &:=\\left\\{s\\in T\\mid d(s,t)&lt;\\epsilon\\right\\}\n\\end{align*}\n\\] で表す．30\n閉球 を \\(B_\\epsilon(t)=B(t;\\epsilon)\\) で表す．31\n単位閉球を \\(B:=B(0;1)\\) で表す．\n\\(\\mathbb{R}^n\\) のものである場合は特に \\(B^n\\) とも表す．32\nBanach空間 \\(X\\) の双対空間 \\(X^*\\) のものは \\(B^*\\) とも表す．33\n\n以降も，ある記号 \\(\\mathcal{F}\\) に関して \\(\\mathcal{F}(x;y)\\) と表される記法は， \\(\\mathcal{F}_y(x)\\) として理解できる数学的対象の別記法と捉えられるように設計する．34\n\n\n2.4 可測空間\n\n集合族 \\(\\mathcal{A}\\subset P(X)\\) が生成する \\(\\sigma\\)-代数を \\(\\sigma(\\mathcal{A})\\) で表す．\n測度空間の族 \\((E_i,\\mathcal{E}_i,\\mu_i)\\) について，積集合 \\(\\prod_{i\\in I}E_i\\) 上の 積 \\(\\sigma\\)-加法族 を \\[\n\\bigotimes_{i\\in I}\\mathcal{E}_i=\\sigma\\left(\\bigcup_{i\\in I}\\mathrm{pr}_i^*(\\mathcal{E}_i)\\right)\n\\] で表す．35\nこの上の直積測度を \\(\\bigotimes_{i\\in I}\\mu_i\\) で表す．36\n\\(\\lvert I\\rvert=n,\\mu_i=\\mu\\) の場合は \\(\\mu^{\\otimes n}\\) とも表す．\n位相空間 \\((X,\\mathcal{O})\\) 上の Borel \\(\\sigma\\)-加法族 を \\[\n\\mathcal{B}(X):=\\sigma(\\mathcal{O})\n\\] で表す．\n\\((\\mathbb{R},\\mathcal{B}(\\mathbb{R}))\\) の積空間 \\(\\mathbb{R}^T\\) 上の積 \\(\\sigma\\)-加法族を \\(\\mathcal{C}\\) で表す．\\((\\mathbb{R}^T,\\mathcal{C})\\) 上の標準Gauss測度を \\(\\gamma\\) で表す．37\n\\(\\ell_n\\) は \\(\\mathbb{R}^n\\) 上の Lebesgue 測度 を表す．38 \\(\\gamma_n:=\\mathrm{N}(0,1)^{\\otimes n}\\) は 標準 Gauss 測度 を表す．\n\n\n\n2.5 確率空間\n\n\\((\\Omega,\\mathcal{F},\\mathrm{P})\\) を標準的な 確率空間 とする．39 よって，明示せずとも，確率変数 \\(X\\) と言ったときは \\(\\mathcal{L}(\\Omega,\\mathcal{F},\\mathrm{P})\\) の元とする．\nPolish 確率空間 と言ったとき，Polish 空間 \\(E\\) 上の Borel 可測空間 \\((E,\\mathcal{B}(E))\\) 上の確率空間を指す．40\n期待値作用素を \\[\\mathrm{E}:L(\\Omega)\\to[-\\infty,\\infty]\\] で表す．41\n期待値作用素と確率測度の引数は \\[\\mathrm{E}[X],\\quad\\mathrm{P}[X\\in A]\\] と角括弧内に記する．42\n分散と共分散は \\(\\mathrm{V}[X],\\mathrm{C}[X,Y]\\) と表す．43\n確率変数 \\(X\\in\\mathcal{L}(\\Omega;\\mathcal{X})\\) による測度 \\(\\mathrm{P}\\) の 押し出し を \\[\\mathrm{P}^X:=X_*\\mathrm{P}\\in\\mathcal{P}(\\mathcal{X})\\] で表し，これを \\(X\\) の 分布 という．44\nこの関係を \\(X\\sim\\mathrm{P}^X\\) とも表す．\n確率変数 \\(X\\) の分布 \\(\\mathrm{P}^X\\) を \\(\\mathcal{L}[X]\\in\\mathcal{P}(\\mathcal{X})\\) とも表す．\n\\(X\\perp\\!\\!\\!\\perp Y\\) とは確率変数 \\(X,Y\\) が 独立 であることを表す．45\n\nなお，確率変数，推定量，統計量とは，確率空間上の可測関数の，特定の意図を持った別名称に他ならない．46\n\n\n2.6 確率分布\n\n可測空間 \\((E,\\mathcal{E})\\) 上の 確率測度 の全体を \\(\\mathcal{P}(E)\\) と書く．47\n\\(E\\) を位相空間とする．\\((E,\\mathcal{B}(E))\\) 上の Radon 確率測度 の全体を \\[P(E)\\subset\\mathcal{P}(E)\\] で表す．48\n\\(d\\)-次元 正規分布 を \\[\\mathrm{N}_d(\\mu,\\Sigma)\\in\\mathcal{P}(\\mathbb{R}^d)\\] で表す．49\n集合 \\(A\\subset\\mathbb{R}^d\\) 上の 一様分布 を \\[\\mathrm{U}(A)\\in\\mathcal{P}(\\mathbb{R}^d)\\] で表す．\n確率変数 \\(X\\sim\\nu\\in\\mathcal{P}(\\mathbb{R}^d)\\) の 分布関数 を \\[\n\\begin{align*}\n  F_X(a)&:=F_\\nu(a)\\\\\n  &:=\\mathrm{P}[X_1\\le a_1,\\cdots,X_d\\le a_d]\\\\\n  &\\quad(a=a_{1:d}\\in\\mathbb{R}^d)\n\\end{align*}\n\\] で表す．\n\\(d=1\\) のとき，その一般化逆を \\[\nF^-_\\nu(u):=\\inf\\left\\{x\\in\\mathbb{R}\\mid F_\\nu(x)\\ge u\\right\\}\n\\] \\[\n(u\\in(0,1)^d)\n\\] で表す．50\n\n\n\n2.7 確率過程\n確率過程 と言ったとき，共通の確率空間 \\((\\Omega,\\mathcal{F},\\mathrm{P})\\) 上の確率変数の族 \\(\\{X_t\\}_{t\\in T}\\subset\\mathcal{L}(\\Omega)\\) を指すこととする．51\n\n確率過程 \\(\\{X_t\\}_{t\\in T}\\subset\\mathcal{L}(\\Omega)\\) に対して， \\[\nX_-:\\Omega\\to\\mathbb{R}^T\n\\] を 転置 と呼ぶ．52\n関数 \\(f:\\mathbb{R}\\supset T\\to\\mathcal{X}\\) が 第一種不連続 であるとは，右連続かつ左極限を持つことをいい，このような関数の全体を \\(D(T;\\mathcal{X})\\) で表す．53\n\\(T\\) を位相空間とする．\\(T\\) 上の連続関数の全体を \\(C(T)\\) で表す．"
  },
  {
    "objectID": "posts/2023/2023-12-12/Notations.html#位相",
    "href": "posts/2023/2023-12-12/Notations.html#位相",
    "title": "数学記法一覧",
    "section": "2 位相",
    "text": "2 位相\n\\((X,\\mathcal{O})\\) を 位相空間 とする．\n\n点 \\(x\\in X\\) の 開近傍 の全体を \\(\\mathcal{O}(x)\\subset\\mathcal{O}\\) で表す．9"
  },
  {
    "objectID": "posts/2023/2023-12-12/Notations.html#関数解析",
    "href": "posts/2023/2023-12-12/Notations.html#関数解析",
    "title": "数学記法一覧 | Notations on This Website",
    "section": "3 関数解析",
    "text": "3 関数解析\n\\((E,\\mathcal{E})\\) を 可測空間 とする．54\n\n3.1 測度\n\n符号付き測度 とは，可算加法的な関数 \\[\\mu:\\mathcal{E}\\to[-\\infty,\\infty]\\] であって， \\[\\{\\pm\\infty\\}\\subset\\mathrm{Im}\\,(\\mu)\\] が起こらないものをいう．この全体を \\(\\mathcal{S}(E)\\) で表す． 55\n有界な符号付き測度の全体を \\[\nS^1(E)=\\left\\{\\mu\\in\\mathcal{S}(E)\\mid\\|\\mu\\|_\\mathrm{TV}&lt;\\infty\\right\\}\n\\] で表す． 56\n測度 の全体を \\(\\mathcal{M}(E):=\\mathcal{S}(E)_+\\) で表す．57 有限な測度の全体を \\(M^1(E):=S^1(E)_+\\) で表す．\n\\(E\\) を位相空間とする．Borel 測度 \\(\\{\\mu_i\\}\\subset\\mathcal{M}(E,\\mathcal{B}(E))\\) の弱収束を，\\(\\mu_i\\Rightarrow\\mu\\) と表す．\n\n\n\n3.2 確率核\n確率核 は可測空間の射となる基本的な対象である．\\((E,\\mathcal{E}),(F,\\mathcal{F})\\) を可測空間とする．\n\n核 \\(T:E\\to F\\) とは，次の2条件を満たす写像 \\(T:E\\times\\mathcal{F}\\to[0,\\infty]\\) をいう：58\n\n\\(\\{T(x,-)\\}_{x\\in E}\\subset\\mathcal{M}(F)\\)．\n\\(\\{T(-,A)\\}_{A\\in\\mathcal{F}}\\subset\\mathcal{L}(E)\\)．\n\n核 \\(T:E\\times\\mathcal{F}\\to[0,\\infty]\\) が 有界 であるとは， \\[\n\\sup_{x\\in E}\\lvert P(x,F)\\rvert&lt;\\infty\n\\] を満たすことをいう．59 すなわち，写像 \\(E\\to M^1(F)\\) が有界な像を持つことをいう．60\n\\(\\{P(x,F)\\}_{x\\in E}=\\{1\\}\\) を満たす有界核 \\(P\\) を 確率核 または Markov核 という． 61\n\\(F\\) が Polish 確率空間であるとき，確率核 \\(P:E\\to F\\) とは可測写像 \\(T:E\\to\\mathcal{P}(F)\\) に等価である．ただし，\\(\\mathcal{P}(F)\\) は弱収束の位相による Borel 可測空間と考える．62\n核 \\(T\\) の符号付き測度の空間 \\(\\mathcal{S}(E)\\) への右作用 \\(\\cdot T:\\mathcal{S}(E)\\to\\mathcal{S}(F)\\) を \\[\n\\begin{align*}\n  &(\\mu T)(A)\\\\\n  &\\qquad:=\\int_E\\mu(dx)T(x,A),\\\\\n  &\\qquad\\qquad(A\\in\\mathcal{F}),\n\\end{align*}\n\\] で定める．\n核 \\(T\\) の可測関数の空間 \\(\\mathcal{L}(F)\\) への左作用 \\(T\\cdot:\\mathcal{L}(F)\\to\\mathcal{L}(E)\\) を \\[\n\\begin{align*}\n  &(Tf)(x)\\\\\n  &\\qquad:=\\int_FT(x,dy)f(y),\\\\\n  &\\qquad\\qquad (x\\in E),\n\\end{align*}\n\\] で定める．63\n核 \\(T:E\\to F,S:F\\to G\\) の 合成 \\(T\\otimes S:E\\to F\\times G\\) を \\[\n\\begin{align*}\n  &(T\\otimes S)(x,A\\times B)\\\\\n  &\\qquad:=\\int_AT(x,dy)S(y,B),\\\\\n  &\\qquad\\qquad(x\\in E,A\\in\\mathcal{F},B\\in\\mathcal{G}),\n\\end{align*}\n\\] で定める．64\n核 \\(T:E\\to F,S:F\\to G\\) の 積 \\(TS:E\\to G\\) を \\[\n\\begin{align*}\n  (TS)(x,B)&:=(T\\otimes S)(x,F\\times B)\\\\\n  &=\\int_FT(x,dy)S(y,B)\\\\\n  &\\qquad(x\\in E,B\\in\\mathcal{G}),\n\\end{align*}\n\\] で定める．65\n\n確率核は積に関して結合的で，\\(I(x,A):=\\delta_x(A)\\) を単位元に持ち，可測空間と確率核の圏 \\(\\mathrm{Stoch}\\) をなす．これは \\((1,2)\\) を 終対象 とする Markov圏 である．可測空間 \\((1,2)\\) からの確率核 \\((1,2)\\to(E,\\mathcal{E})\\) は \\(\\mathcal{P}(E)\\) の元に等価である．66\n\n\n3.3 関数の空間\n関数・確率変数と言った場合，断りがない限り \\(\\mathbb{R}\\)-値のものを考える．\n\n\\((E,\\mathcal{E})\\) 上の 可測関数 の全体を \\(\\mathcal{L}(E)\\) と書く．67\n\\((E,\\mathcal{E})\\) 上のある測度について，殆ど至る所で等しい関数を同一視して得る商空間を \\(L(E)\\) と書く．\nこの規則は任意の Lebesgue 空間 \\(L^p(E)\\) で同じである．\n\\((T,d)\\) を距離空間とする．\\(T\\) 上の Lipschitz 連続関数 の全体を \\(\\mathrm{Lip}(T)\\) で表す．68\nLipschitz 定数が \\(c\\) 以下になる関数の部分集合を \\[\n\\mathrm{Lip}_c(T):=\\left\\{f\\in\\mathrm{Lip}(T)\\mid\\forall_{x,y\\in T}\\;\\lvert f(x),f(y)\\rvert\\le cd(x,t)\\right\\}\n\\] で表す．69\n\nイタリック体のものが Banach 空間（の部分集合）に，カリグラフィー体のものがより一般的なものになるように注意している．70\n\n\n3.4 変形\n\\(\\mathcal{F}(E)\\subset\\mathbb{R}^E\\) は \\(L(E), C(E)\\) などの関数空間の一般形とする．\n\n測度空間 \\((E,\\mathcal{E},\\mu)\\) 上の関数空間 \\(\\mathcal{F}(E)\\) に対して，文脈により \\(\\mathcal{F}(\\mu)\\) とも \\(\\mathcal{F}(E,\\mathcal{E},\\mu)\\) とも表す．\n任意の関数空間 \\(\\mathcal{F}(E)\\) に対して，値域の空間が \\(\\mathcal{X}\\) であるとき，これを強調して \\(\\mathcal{F}(E;\\mathcal{X})\\) または \\(\\mathcal{F}_\\mathcal{X}(E)\\) とも表す．71\n任意の関数空間 \\(\\mathcal{F}(E)\\) に対して，\n\n有界なもののなす部分空間を \\(\\mathcal{F}_b(E)\\) で表す．\nコンパクト台を持つもののなす部分空間を \\(\\mathcal{F}_c(E)\\) で表す．\n有界かつ一様連続なもののなす部分空間を \\(\\mathcal{F}_u(E)\\) で表す．72\n非負値のもののなす部分空間を \\(\\mathcal{F}(E)_+:=\\mathcal{F}(E;\\mathbb{R}_+)\\) で表す．73\n\n\n\n\n3.5 作用素\n\\(E,F\\) をノルム空間とする．\n\n作用素 \\(T:E\\to F\\) と言ったとき，線型写像 \\(T:E\\to F\\) を指すこととする．\n\\(E\\) 内の作用素 \\(T:E\\to F\\) と言ったとき，ある \\(E\\) の部分空間 \\(\\mathcal{D}(T)\\) 上で定義された作用素 \\(T:\\mathcal{D}(T)\\to F\\) を指すこととする．\n有界作用素の全体を \\(B(E,F)\\) で表す．74\n連続作用素の全体を \\(L(E,F)\\) で表す．75"
  },
  {
    "objectID": "static/Materials.html#記法規約",
    "href": "static/Materials.html#記法規約",
    "title": "Materials",
    "section": "記法規約",
    "text": "記法規約\n\n\n\n\n\n\n\n\nTitle\n\n\nModified\n\n\n\n\n\n\n\n\n\n数学記法一覧 | Notations on This Site\n\n\n12/13/23, 1:52:50 AM\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023/2023-11-25/ParticleFilter.html#フィルタリング濾波問題とは",
    "href": "posts/2023/2023-11-25/ParticleFilter.html#フィルタリング濾波問題とは",
    "title": "粒子フィルターとは何か | About Particle Filter（執筆中）",
    "section": "",
    "text": "フィルタ（濾波器）の第一義は，液体から不純物を取り除くための装置である．そのアナロジーで「フィルタリング問題」と言った場合は，信号処理の意味で電圧や電波の信号を「濾過」してノイズを除去し本当に注目したい部分を純粋化する営みのことを指す．凡ゆる通信機器において装置の熱運動によるノイズが入ることは避けられぬ自然の摂理であり，フィルタリング問題は普遍的な課題である．1\nGaussは天体観測の経験から「誤差論」と最小二乗法を発明し，これが現代の統計的推定理論の先駆けとなった．これと同じように，通信と制御の分野では「時々刻々と受信するデータから時々刻々と変化する信号をどのようにうまく濾波するか」という独自の課題から，独自の理論が発展していった．2\n特に，デジタル回路がない時代では，「どのような電気回路のシステムとして濾波機をデザインすれば良いか？」という電気工学的な回路設計の問題としての側面も大きかった．\nこのアナログフィルタリングの時代で，フィルタリングの問題を統計的技術で解くための理論3 が，まず離散時間の場合が (Kolmogorov, 1941)，続いて連続時間の場合が (Wiener, 1949) によって模索された．4\nしかし，このKolmogorov-Wiener理論では「信号とノイズの過程が定常である」という仮定を置いており，これが広い応用を阻んでいた．当時の技術（抵抗器やコンデンサーなど）で実装出来る範囲という制約がある以上，仕方ないことでもあったため，更なる理論的発展はデジタル技術の登場を待つ必要があった．\n\n\n\nトランジスタというデジタル技術が使われるようになると，「フィルタ（濾波器）」はアナログデジタル変換器，レジスタ，メモリ，マイクロプロセッサから構成されるようになり，物理的な姿は全く変わってしまった．その中で (Kalman, 1960) が，定常性の仮定が満たされない場合でも使えるアルゴリズムを提案すると，すぐにApollo計画に導入されるに止まらず，NASAのスペースシャトル，海軍の潜水艦などにも応用されていった．5\nこうして「フィルタ（濾波器）」の語は，「水を濾過する如く電圧情報のノイズを除去する機器」という類比から，デジタル技術の出現により更なる一段階の抽象化を受けて物理的実体も失い，「ノイズを除去してメッセージ部分をなるべく正確に推定するアルゴリズム」という完全に数学的で抽象的な存在として研究が進められていくことになる．\nこのKalman filterは素晴らしかった．だが，モデルが線型かつ正規である場合にしか使えない．そこで，計算機や情報通信技術の発展と共に複雑化していくシステム・データに併せて，様々なフィルターが考案されていく必要があるのである．6 これが統計計算の時代である．\n\n\n\n線型性や正規性の仮定を一才必要としない濾波アルゴリズムとして，(Gordon et al., 1993) がbootstrap filterという名前で発表し，角度観測のみを用いた物体追跡の問題への応用を付した．この角度情報のみから物体を追跡するという問題は古典的な非線型濾波問題で，従来の拡張Kalman filterの方法では精度が全く伸びず，これに比べてbootstrap filterでは圧倒的に性能が改善したのであった．リサンプリングは多項リサンプリングを採用しており，極めて実装が簡単という点も多くの応用を生んだ理由である．7\nなお，北川源四郎も同年（1993年）のカンファレンスでMonte Carlo filterの名前で同様のアルゴリズムを発表している．そのジャーナル版は (北川源四郎, 1996a)．8 日本語文献 (北川源四郎, 1996b) はウェブ上からも読める．\n\n\n\nまず，(Gordon et al., 1993) による粒子フィルターの考案は，防衛，特に物体追跡への応用が念頭にあり，これを扱った一冊の本もある (Ristic et al., 2004)．9\nこれに関連して，ロボティクス，HCI (Human-Computer Interaction) 分野への応用もなされている(岡兼司, 2005), (Wills & Schön, 2023)．\nファイナンスで扱う時系列は非線型性・非正規性を示すと同時にデータ数も多い．逐次推定のステップ数が増えようとも誤差が蓄積しない粒子フィルターが見事に推定を実行する．10\n加えて，マクロ経済学の分野で 動学的確率的一般均衡モデル の推定にも応用されている．このモデルは，非線型なミクロ経済学的モデルの上に構築された大規模なモデルで，非線型な1次条件を持つ．11 このような複雑なモデルでは一般にMCMC法では収束が遅いが，粒子フィルターに焼戻し法や並列計算を組み合わせることでこの問題を回避でき，さらに事後分布が多峰性を持つ場合でさえ有用である (Herbst-Schorfheide2013?)．\n近年ではエージェント・ベースド・モデルへの応用もある (Lux, 2018)．\n\n\n\nこうして，粒子フィルターは濾波問題の文脈で発明されたMonte Carlo法であるが，状態空間モデルに対する濾波に限らず，種々の設定での逐次的問題，更には逐次的構造を持たない一般の推定問題にも応用できる．この発展により，粒子フィルターはMCMCと合流して，ベイズ計算 の主要トピックの１つに躍り出た (Martin+2023-history?)．この意味で，粒子フィルターは広く逐次Monte Carlo法（Sequential Monte Carlo methods 略して SMC ）とも呼ばれる．12\n逐次的ではない通常の設定，いわば「静的」な設定の下でのBayes推論にSMCを用いる方法は (Chopin, 2002) が草分け的な仕事をした．この枠組みでは，Bayes事後分布 \\(\\pi(\\theta|y_1,\\cdots,y_N)\\) の近似において，途中の \\(\\pi(\\theta|y_1,\\cdots,y_n)\\) を経由して逐次的に近似することが，自然な計算コスト削減法として理解できる．\n\n\n\n粒子フィルターは高い汎用性の代償として，多数の粒子を用意したいなら計算量が多くなることを欠点に持つ．従って，粒子フィルターは，他の手法が実行不可能なほどの非線型性・非正規性を示す問題に（のみ）用いるべきというものである．が，CPUや並列計算の発展により十分な量の粒子を用意できる場面も増えたため，その問題点も形骸化してきてると言える．13\nまた，粒子フィルターは，観測 \\(Y_t\\) の次元が大きいなど，観測から得られる情報量が多く，尤度（ポテンシャル）の尖度が高いとき，多くの粒子が小さな荷重を持ってしまう．この状態は近似精度悪化の原因となり縮退と呼ばれる．14 そのような場合は，観測の情報を柔軟に取り入れた提案核を構築し，誘導粒子フィルターをうまく設計する必要がある．\n地球科学や天気予報の分野では \\(Y_t\\) は大きく（\\(10^7\\)を超えることもある），このような場合は粒子フィルターは実行可能でなくなる．加えてKalmanフィルターも行列計算の部分が実行不可能になり，アンサンブルKalmanフィルタという粒子法が用いられる．"
  },
  {
    "objectID": "posts/2023/2023-11-25/ParticleFilter.html#フィルタリング問題の歴史",
    "href": "posts/2023/2023-11-25/ParticleFilter.html#フィルタリング問題の歴史",
    "title": "粒子フィルターとは何か | About Particle Filter",
    "section": "1 フィルタリング問題の歴史",
    "text": "1 フィルタリング問題の歴史\n\n1.1 フィルタリング（濾波）問題とは何か？\nフィルタ（濾波器）の第一義は，液体から不純物を取り除くための装置である．そのアナロジーで「フィルタリング問題」と言った場合は，信号処理の意味で電圧や電波の信号を「濾過」してノイズを除去し本当に注目したい部分を純粋化する営みのことを指す．凡ゆる通信機器において装置の熱運動によるノイズが入ることは避けられぬ自然の摂理であり，フィルタリング問題は普遍的な課題である．1\nGauss は天体観測の経験から「誤差論」と最小二乗法を発明し，これが現代の統計的推定理論の先駆けとなった．これと同じように，通信と制御の分野では「時々刻々と受信するデータから時々刻々と変化する信号をどのようにうまく濾波するか」という独自の課題から，独自の理論が発展していった．2\n特に，デジタル回路がない時代では，「どのような電気回路のシステムとして濾波機をデザインすれば良いか？」という電気工学的な回路設計の問題としての側面も大きかった．\n\n\n1.2 最初のフィルタリング理論\nこのアナログフィルタの時代で，フィルタリングの問題を統計的技術で解くための理論3 が，まず離散時間の場合が (Kolmogorov, 1941)，続いて連続時間の場合が (Wiener, 1949) によって模索された．4\nしかし，この Kolmogorov と Wiener 理論では「信号とノイズの過程が定常である」という仮定の下で展開されており，この定常性の制約が Kolmogorov-Wiener 理論の広い応用を阻んでいた．\nだがこれは，「当時の技術（抵抗器やコンデンサーなど）で実装出来る範囲」という制約がある上で考えられた理論としては，仕方ないことでもあった．更なる理論的発展も，デジタル技術の登場を待つ必要があった．\n\n\n1.3 デジタルフィルタリングの登場\nトランジスタというデジタル技術が使われるようになり，集積回路の製造技術が発達すると，「フィルタ（濾波器）」はアナログデジタル変換器，レジスタ，メモリ，マイクロプロセッサから構成されたデジタルフィルタが主に使われるようになった．アナログフィルタから物理的な姿は全く変わり，もはや肉眼では見えない装置になってしまったのである．5\nその中で (Kalman, 1960) が，定常性の仮定が満たされない場合でも使えるアルゴリズムである カルマンフィルター を提案すると，すぐに Apollo 計画に導入されてスペースシャトルの制御へ実用化され，更には海軍の潜水艦などにも応用されていった．6\nあらゆるシステムがデジタル化されていく中で，アナログフィルタは徹底的にデジタルフィルタに代替されるようになった．これに伴い，現代でフィルタリング問題と言った場合，現在 \\(t\\) までの観測 \\(Y_1,\\cdots,Y_t\\) からノイズを除去してメッセージ部分 \\(X_t\\) をなるべく正確に推定するアルゴリズム という完全に数学的で抽象的な存在として研究が進められていくことになる．\n\n\n1.4 状態空間モデルという語彙\nKalman の論文 (Kalman, 1960) の新規性はアルゴリズムだけではなく，状態空間モデル という枠組みを導入し，どのようなシステムに適用可能かに関する共通言語を提供したことが，即時的な応用に寄与した面もあるだろう．7 例えばこの語彙に従えば，「Kalman filter は状態空間モデルが線型正規であれば最適なフィルタリング手法」ということになる．\nこの状態空間モデルの枠組みと同様なものが (Baum & Petrie, 1966) によって隠れ Markov モデルとして展開され，こちらは (Baker, 1975) により音声認識に応用された．現代でも多くの音声認識システムは隠れ Markov モデルに基づく．8\n状態空間モデルはその後，(Akaike, 1974) で時系列モデリングに応用され，再び統計学の分野と深く関わるようになる．9\n\n\n1.5 カルマンフィルターの限界\nしかし Kalman filter にも大きな制約があった．それは モデルに線型かつ正規であるという大きな制約があった ということである．一方で現実のシステムは殆どが非線型性を持つ．\nそこで NASA の Ames 研究センター ではすぐに 拡張 Kalman フィルタ と共分散行列の二乗根を保持する実装が考案され，これが本当の意味で Kalman フィルターを実用に耐えるものにした (McGee & Schmidt, 1985)．10\nだが，「拡張」の名前の通り本質的な解決とは言えず，システムの非線型性が強い場合は性能が伸びない．11 こうして，計算機や情報通信技術の発展と共に複雑化していくシステムに併せて，様々なフィルターが考案されていく必要があるのである．統計計算の時代の黎明である．\n\n\n1.6 非線型性・非正規性という強敵\n実は，1960年に開発された Kalman filter を真に超克する手法は，1990年代に入るのを待つ必要がある．他のシミュレーションに基づく ベイズ計算手法 と同じく，計算機の十分な発達を待つ必要があったのである．\nというのも，Kalman filter は，線型正規状態空間モデルの下でフィルタリング分布 \\[\n\\mathcal{L}[X_t|Y_1,\\cdots,Y_t]\n\\tag{1}\\] は再び正規分布であり，平均と共分散という２つの量のみで完全に特徴付けられるため，これらのみを考慮し，微分方程式を解いて更新規則を事前に得ておくことで，計算量を大幅に削減することが出来る，というトリックに基づく．\nこのように線型性と正規性が同在する状況，または状態空間が有限であるなどの限られた状況でない限り，フィルタリング分布 式 1 は有限次元の十分統計量を持たない．12\n従って，一般の状況に対応出来るフィルタには，上述のような計算量削減のトリックは絶対に存在せず，正面から分布 式 1 を近似する方法を考える必要がある．これには新しいアイデアが必要であると同時に，一定の性能を持つ計算機の出現を待つ必要もあったのである．\n\n\n1.7 種々の近似戦略\nフィルタリング分布 式 1 \\[\\mathbb{P}_t(X_t\\in dx_t):=\\mathcal{L}[X_t|Y_{0:t}]\\] は Bayes の定理を通じて再帰的な関係 \\[\n\\begin{align*}\n    &\\mathbb{P}_{t-1}(X_t\\in dx_t|Y_{0:t-1})\\\\\n    &=\\int_{x_{t-1}\\in E}\\mathbb{P}_{t-1}(X_{t-1}\\in dx_{t-1}|\\\\\n    &\\qquad Y_{0:t-1}=y_{0:t-1})P_t(x_{t-1},dx_t),\\\\\n    &\\mathbb{P}_t(X_t\\in dx_t|Y_{0:t}=y_{0:t})\\\\\n    &=\\frac{1}{p_t(y_t|y_{0:t-1})}f_t(x_t|y_t)\\\\\n    &\\qquad\\mathbb{P}_{t-1}(X_t\\in dx_t|Y_{0:t-1}=y_{0:t-1}).\n\\end{align*}\n\\] を満たすが，この積分を計算する必要がある．13\n粒子フィルターでは相関を持った粒子系により，これらの値を逐次的に近似していくが，このアルゴリズムが出来る前に提案された近似手法を総覧する．\n\n1.7.1 解析的な方法\n節 1.5 で紹介した拡張 Kalman filter は，モデルが線型に近い場合には有効な近似手法であるが，一致推定量にはならない．この点を修正するために，線型近似の誤差を修正する IEKF (Iterated EKF) などが開発された．\n\n\n1.7.2 数値積分による方法\n状態空間 \\(E\\) の次元が3以下である場合，積分は数値積分法によっても効率的に近似できる (Kitagawa, 1987)．14\n特に状態空間が有限である場合は積分は加法に退化するため，正確に実行することができる．15 この場合が隠れMarkovモデルに当たる．\n隠れMarkovモデルに於て MAP 推定量を動的計画法に基づいて探索する Viterbi 算譜 (Forney, 1973), (Viterbi, 1982) とパラメータ推定のための EM アルゴリズムの変種 Baum-Welch 算譜 (Baum & Eagon, 1967), (Gopalakrishnan et al., 1989) とは音声認識の分野で広く使われており，また状態空間が近似的に離散である場合にも近似手法として採用される．16\n\n\n1.7.3 Gauss混合で近似する方法\nフィルタリング分布 式 1 を正規分布の有限混合で近似する方法は Gaussian sum filter と呼ばれる (Sorenson & Alspach, 1971)．これは多峰性を帯びる事後分布のモデリングに強く，物体追跡の分野で広く使われることとなったが，一般の設定に使える普遍的な手法ではなかった．17\n\n\n1.7.4 アンサンブルによる近似\nフィルタリング分布 式 1 を正規分布を表現する決定論的に設計された粒子系によって近似し，これをシステムモデルに従って伝播させる．これにより，フィルタリング分布の2次以下の積率までは性格に近似できていることになる．この手法を 無香 Kalman filter (Unscented Kalman filter) という (S. Julier et al., 2000), (S. J. Julier & Uhlmann, 2004)．\nこの手法は，宇宙から大気圏に再突入する弾道物体の追跡などの場面で，粒子フィルターよりやや正確性が劣るが計算が速く，実用的であることも知られている (Ristic et al., 2004, p. 101)．\nこの手法は本質的に (Evensen, 1994) の EnKF (Ensemble Kalman filter) によって拡張された（ 節 3.5 も参照）．"
  },
  {
    "objectID": "posts/2023/2023-11-6/SSM.html",
    "href": "posts/2023/2023-11-6/SSM.html",
    "title": "相関粒子系の社会実装",
    "section": "",
    "text": "要は僕の専門分野である訳だが，これが今回のビジネスモデルの「骨格」の部分になる．\n\n$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$\n\n\n\n\n\n\n\n定義 (State Space Model)\n\n\n\n状態空間モデル1とは，状態変数 \\(\\{X_t\\}_{t=0}^T\\) と，観測変数 \\(\\{Y_t\\}_{t=1}^T\\) の組からなる確率過程 \\[\n\\{(X_t,Y_t)\\}\\subset\\mathcal{L}(\\Omega;\\mathcal{X}\\times\\mathcal{Y})\n\\] であって，初期状態 \\(X_0\\) の分布と，\\(X_t,Y_t\\) の間の関係として次の2つの条件付き分布\n\nシステムモデル \\[\nX_{t+1}|X_t\\quad(t\\in T)\n\\]\n観測モデル \\[\nY_t|X_t\\quad(t\\in[T])\n\\]\n\nを想定したものをいう．2\n\n\n\n状態空間モデルの図示\n\n\n\n\nただし，\\(X_t\\) は観測不能で，\\(Y_t\\) のみを観測するものとする．従って，目標は \\(Y_1,\\cdots,Y_T\\) の値から \\(X_1,\\cdots,X_T\\) の値を推定することである．\n各時点 \\(t\\in[T]\\) において，現在までの観測 \\(Y_1,\\cdots,Y_t\\) から現在の状態 \\(X_t\\) を推定することを考える（フィルタリング問題3）．特に Bayes の枠組みでは，条件付き分布 \\[\n\\mathcal{L}[X_t|Y_1,\\cdots,Y_t]\\quad(t\\in [T])\n\\] を（逐次的に）決定することを目指す．4\n\n\n\n\n\n\n状態空間モデルに関する注意\n\n\n\n厳密には，初期状態 \\(X_0\\) の分布のモデル \\(\\{\\mathbb{P}_0^\\theta\\}\\)．Markov過程 \\(\\{X_t\\}\\) の遷移核のモデル \\(\\{P_t^\\theta\\}\\)，観測のモデル \\(\\{F_t^\\theta\\}\\) の3-組 \\((\\mathbb{P}_0^\\theta,P_t^\\theta,F_t^\\theta)\\) を 状態空間モデル という．また，過程 \\(\\{(X_t,Y_t)\\}\\) もMarkov過程になることが示せる．このため，状態空間モデルのことを 部分的に観測されるMarkov過程 とも表現する．\n\n\nこの状態空間モデルのフィルタリング問題を解くためのアルゴリズムは多く知られているが，そのうち，モデル \\(X_{t+1}|X_t,Y_t|X_t\\) が複雑で尤度が明示的な表示を持たない場合でも通用する手法は粒子フィルターのみである．5\n粒子フィルターは，\\(X_t\\) の観測 \\(Y_t\\) に関する事後分布を \\(N\\) 個（大量）の粒子によって近似する Bayes 推定手法で，各 \\(Y_t\\) の尤度の情報を重点リサンプリングによって取り入れながらも，計算コストを抑えながら \\(X_t\\) の事後分布を逐次近似していく．粒子フィルターとは何か？ も参照．\n\n\n\n要は，\\(Y_t\\) を安価に集めて，\\(X_t\\) を高値で売ることを考える．本当にこれがビジネスになるためには，２つの条件\n\n\\(X_t\\) は多くの人がリアルタイムに知りたいが，（少なくともリアルタイムには）知れない\n\\(Y_t\\) をたくさん集めれば \\(X_t\\) を推測できるが，簡単には推測するのに十分な次元の \\(Y_t\\) を用意できない\n\nを満たす必要がある．が，意外とこのようなものは多いかも知れない．\n一方で我々の売りは\n\n\n\n\n\n\n今回のビジネスモデルのコア\n\n\n\nどんなに推定しにくい \\(X_t\\) でも（モデルが複雑で尤度が解析的な表示を持たなくても），十分な情報を含む観測データ \\(Y_t\\) が得られれば，逐次推定できる．\n\n\nということになる．\n時系列データのオンライン推論は，需要が高い一方で実装が難しい．ここの乖離が好機になる可能性がある．"
  },
  {
    "objectID": "posts/2023/2023-11-6/SSM.html#粒子ビジネスモデルモデルの概要",
    "href": "posts/2023/2023-11-6/SSM.html#粒子ビジネスモデルモデルの概要",
    "title": "相関粒子系の社会実装",
    "section": "",
    "text": "要は僕の専門分野である訳だが，これが今回のビジネスモデルの「骨格」の部分になる．\n\n$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$\n\n\n\n\n\n\n\n定義 (State Space Model)\n\n\n\n状態空間モデル1とは，状態変数 \\(\\{X_t\\}_{t=0}^T\\) と，観測変数 \\(\\{Y_t\\}_{t=1}^T\\) の組からなる確率過程 \\[\n\\{(X_t,Y_t)\\}\\subset\\mathcal{L}(\\Omega;\\mathcal{X}\\times\\mathcal{Y})\n\\] であって，初期状態 \\(X_0\\) の分布と，\\(X_t,Y_t\\) の間の関係として次の2つの条件付き分布\n\nシステムモデル \\[\nX_{t+1}|X_t\\quad(t\\in T)\n\\]\n観測モデル \\[\nY_t|X_t\\quad(t\\in[T])\n\\]\n\nを想定したものをいう．2\n\n\n\n状態空間モデルの図示\n\n\n\n\nただし，\\(X_t\\) は観測不能で，\\(Y_t\\) のみを観測するものとする．従って，目標は \\(Y_1,\\cdots,Y_T\\) の値から \\(X_1,\\cdots,X_T\\) の値を推定することである．\n各時点 \\(t\\in[T]\\) において，現在までの観測 \\(Y_1,\\cdots,Y_t\\) から現在の状態 \\(X_t\\) を推定することを考える（フィルタリング問題3）．特に Bayes の枠組みでは，条件付き分布 \\[\n\\mathcal{L}[X_t|Y_1,\\cdots,Y_t]\\quad(t\\in [T])\n\\] を（逐次的に）決定することを目指す．4\n\n\n\n\n\n\n状態空間モデルに関する注意\n\n\n\n厳密には，初期状態 \\(X_0\\) の分布のモデル \\(\\{\\mathbb{P}_0^\\theta\\}\\)．Markov過程 \\(\\{X_t\\}\\) の遷移核のモデル \\(\\{P_t^\\theta\\}\\)，観測のモデル \\(\\{F_t^\\theta\\}\\) の3-組 \\((\\mathbb{P}_0^\\theta,P_t^\\theta,F_t^\\theta)\\) を 状態空間モデル という．また，過程 \\(\\{(X_t,Y_t)\\}\\) もMarkov過程になることが示せる．このため，状態空間モデルのことを 部分的に観測されるMarkov過程 とも表現する．\n\n\nこの状態空間モデルのフィルタリング問題を解くためのアルゴリズムは多く知られているが，そのうち，モデル \\(X_{t+1}|X_t,Y_t|X_t\\) が複雑で尤度が明示的な表示を持たない場合でも通用する手法は粒子フィルターのみである．5\n粒子フィルターは，\\(X_t\\) の観測 \\(Y_t\\) に関する事後分布を \\(N\\) 個（大量）の粒子によって近似する Bayes 推定手法で，各 \\(Y_t\\) の尤度の情報を重点リサンプリングによって取り入れながらも，計算コストを抑えながら \\(X_t\\) の事後分布を逐次近似していく．粒子フィルターとは何か？ も参照．\n\n\n\n要は，\\(Y_t\\) を安価に集めて，\\(X_t\\) を高値で売ることを考える．本当にこれがビジネスになるためには，２つの条件\n\n\\(X_t\\) は多くの人がリアルタイムに知りたいが，（少なくともリアルタイムには）知れない\n\\(Y_t\\) をたくさん集めれば \\(X_t\\) を推測できるが，簡単には推測するのに十分な次元の \\(Y_t\\) を用意できない\n\nを満たす必要がある．が，意外とこのようなものは多いかも知れない．\n一方で我々の売りは\n\n\n\n\n\n\n今回のビジネスモデルのコア\n\n\n\nどんなに推定しにくい \\(X_t\\) でも（モデルが複雑で尤度が解析的な表示を持たなくても），十分な情報を含む観測データ \\(Y_t\\) が得られれば，逐次推定できる．\n\n\nということになる．"
  },
  {
    "objectID": "posts/2023/2023-11-6/SSM.html#todo",
    "href": "posts/2023/2023-11-6/SSM.html#todo",
    "title": "相関粒子系の社会実装",
    "section": "2 ToDo",
    "text": "2 ToDo\nまとめると，僕が提供できるものは高次元・大規模状態空間モデルでの粒子フィルターの研究開発力．これは前節で語ったような「\\(Y_t\\)を集めて\\(X_t\\)を売る」ビジネスモデルを示唆する．\n足りないものは研究成果と実装する時間と仲間と交渉力である．その代わり初期投資は極めて少なくて済む．\n\n2.1 情報収集\n元々は星野研究室の次の研究を知って，新里さんに紹介したときに得た着想であった．\nCard\n「ナウキャスト」「オルタナティブデータを活用した経済分析」と言った言葉でビジネス界で議論されているようだ．特に「ナウキャスト」という名前の会社はこの分野を開拓している．\nナウキャストとエム・データ、機関投資家向けオルタナティブデータ活用で協業\nオルタナティブデータを用いた経済活動分析\n当然粒子法は用いているまい．まずはナウキャストについて知るべし．\n\n\n2.2 懸念\n\n\\(Y_t\\) が高次元と言っても，モデル \\(Y_t|X_t\\) が正確に立てられないのではないか？"
  },
  {
    "objectID": "posts/2023/2023-11-6/SSM.html#footnotes",
    "href": "posts/2023/2023-11-6/SSM.html#footnotes",
    "title": "相関粒子系の社会実装",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nここでの定義は (Chopin & Papaspiliopoulos, 2020, p. 42) に倣った．隠れMarkovモデルともいうが，こう言ったときは状態空間が有限集合であるという制約が暗につく．↩︎\n記法 \\(T,[T]\\) については 本サイトの数学記法一覧 を参照．↩︎\n一方で \\(Y_t\\) から，未来の値 \\(Y_{t+1}\\) を予測する問題を「予測問題」，\\(Y_{1},\\cdots,Y_t\\)から，過去の状態変数の値 \\(X_{s}\\;(s&lt;t)\\) を推定する問題を「平滑化問題」という．↩︎\n記法 \\(\\mathcal{L}\\) については 本サイトの数学記法一覧 を参照．ベイズ手法については ベイズ計算とは何か を参照．↩︎\n\\(Y_t|X_t,X_{t+1}|X_t\\) のいずれも線型Gaussなモデルを仮定した場合は，Kalman filter （とその変種）というもっと効率の良い安価なアルゴリズムが使える．↩︎"
  },
  {
    "objectID": "posts/2023/2023-11-6/SSM.html#サーベイ",
    "href": "posts/2023/2023-11-6/SSM.html#サーベイ",
    "title": "相関粒子系の社会実装",
    "section": "3 サーベイ",
    "text": "3 サーベイ\nまとめると，我々が提供できるものは高次元・大規模状態空間モデルの逐次推定手法の研究開発力．足りないものは研究成果と実装する時間と仲間と交渉力である．その代わり初期投資は極めて少なくて済む．\nまずは，前節での「\\(Y_t\\) を集めて \\(X_t\\) を売る」ビジネスモデルの実現に向けて，既存の成功事例を調べる．\n\n3.1 生態学\n生態学のモデリングにも状態空間モデルはよく使われる (Auger-Méthé et al., 2021)．特に非線型性が強く，粒子フィルターが有効になる (Chopin & Papaspiliopoulos, 2020, p. 19)．\n\n\n3.2 ナウキャスト\n元々は星野研究室の次の研究を知って，新里さんに紹介したときに得た着想であった．\nCard\n「ナウキャスト」「オルタナティブデータを活用した経済分析」と言った言葉でビジネス界で議論されているようだ．特に「ナウキャスト」という名前の会社はこの分野を開拓している．\nナウキャストとエム・データ、機関投資家向けオルタナティブデータ活用で協業\nオルタナティブデータを用いた経済活動分析"
  },
  {
    "objectID": "posts/2023/2023-11-6/SSM.html#どんな-x_t-が売れるか",
    "href": "posts/2023/2023-11-6/SSM.html#どんな-x_t-が売れるか",
    "title": "相関粒子系の社会実装",
    "section": "2 どんな \\(X_t\\) が売れるか？",
    "text": "2 どんな \\(X_t\\) が売れるか？\n\n2.1 マクロ指標のナウキャスト\n最も示唆的と思われる例は，\\(X_t\\) としてGDP，商業販売額などのマクロ指標を取った場合だと思われる．\nマクロ指標は，各企業単体では推測できず，たとえ業界を絞っても各企業の売り上げデータやATM取引データなど，多くのデータを集めて高次元な \\(Y_t\\) を構成しなければ，信頼できる \\(X_t\\) の推定はできないだろう．高次元な \\(Y_t\\) から \\(X_t\\) をフィルタリング際の粒子法は安定せず，現在でも解決されていないオープンクエスチョンである．必然的にブルーオーシャンで誰も参入できない．\nさらに，マクロ指標はフィルタリングすること＝今現在の値を知ることに意味がある．理論的な障壁や技術的な障壁は高いが，経営判断に使ったり，投資判断に使ったり，需要は大きいと思われる．\n\\(Y_t\\) はデータとして広く流通しているわけではないならば（ATM利用データなど），技術力だけでなく，「信頼を得てデータを提供してもらっている」ことが競争力に加わっていき得る．\n\n\n2.2 天気予報\n\\(Y_t\\) が天気（降水量）というのがよくある．\\(X_t\\) が高次元になり，データ同化の問題になる．\nこの天気予報とデリバティブとの関係は？\n\n\n2.3 属人化医療\n個人的には，\\(X_t\\) は個人の体調スコア（あるいは特定の病気のリスク）で，\\(Y_t\\) がApple Watchなどのスマートデバイスからの心拍や体温や移動距離などの測定データ，という属人化医療の場面設定をよく考える．"
  },
  {
    "objectID": "posts/2023/2023-11-6/SSM.html#粒子ビジネスモデルモデルの基幹技術",
    "href": "posts/2023/2023-11-6/SSM.html#粒子ビジネスモデルモデルの基幹技術",
    "title": "相関粒子系の社会実装",
    "section": "",
    "text": "要は僕の専門分野である訳だが，これが今回のビジネスモデルの「骨格」の部分になる．\n\n$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$\n\n\n\n\n\n\n\n定義 (State Space Model)\n\n\n\n状態空間モデル1とは，状態変数 \\(\\{X_t\\}_{t=0}^T\\) と，観測変数 \\(\\{Y_t\\}_{t=1}^T\\) の組からなる確率過程 \\[\n\\{(X_t,Y_t)\\}\\subset\\mathcal{L}(\\Omega;\\mathcal{X}\\times\\mathcal{Y})\n\\] であって，初期状態 \\(X_0\\) の分布と，\\(X_t,Y_t\\) の間の関係として次の2つの条件付き分布\n\nシステムモデル \\[\nX_{t+1}|X_t\\quad(t\\in T)\n\\]\n観測モデル \\[\nY_t|X_t\\quad(t\\in[T])\n\\]\n\nを想定したものをいう．2\n\n\n\n状態空間モデルの図示\n\n\n\n\nただし，\\(X_t\\) は観測不能で，\\(Y_t\\) のみを観測するものとする．従って，目標は \\(Y_1,\\cdots,Y_T\\) の値から \\(X_1,\\cdots,X_T\\) の値を推定することである．\n各時点 \\(t\\in[T]\\) において，現在までの観測 \\(Y_1,\\cdots,Y_t\\) から現在の状態 \\(X_t\\) を推定することを考える（フィルタリング問題3）．特に Bayes の枠組みでは，条件付き分布 \\[\n\\mathcal{L}[X_t|Y_1,\\cdots,Y_t]\\quad(t\\in [T])\n\\] を（逐次的に）決定することを目指す．4\n\n\n\n\n\n\n状態空間モデルに関する注意\n\n\n\n厳密には，初期状態 \\(X_0\\) の分布のモデル \\(\\{\\mathbb{P}_0^\\theta\\}\\)．Markov過程 \\(\\{X_t\\}\\) の遷移核のモデル \\(\\{P_t^\\theta\\}\\)，観測のモデル \\(\\{F_t^\\theta\\}\\) の3-組 \\((\\mathbb{P}_0^\\theta,P_t^\\theta,F_t^\\theta)\\) を 状態空間モデル という．また，過程 \\(\\{(X_t,Y_t)\\}\\) もMarkov過程になることが示せる．このため，状態空間モデルのことを 部分的に観測されるMarkov過程 とも表現する．\n\n\nこの状態空間モデルのフィルタリング問題を解くためのアルゴリズムは多く知られているが，そのうち，モデル \\(X_{t+1}|X_t,Y_t|X_t\\) が複雑で尤度が明示的な表示を持たない場合でも通用する手法は粒子フィルターのみである．5\n粒子フィルターは，\\(X_t\\) の観測 \\(Y_t\\) に関する事後分布を \\(N\\) 個（大量）の粒子によって近似する Bayes 推定手法で，各 \\(Y_t\\) の尤度の情報を重点リサンプリングによって取り入れながらも，計算コストを抑えながら \\(X_t\\) の事後分布を逐次近似していく．粒子フィルターとは何か？ も参照．\n\n\n\n要は，\\(Y_t\\) を安価に集めて，\\(X_t\\) を高値で売ることを考える．本当にこれがビジネスになるためには，２つの条件\n\n\\(X_t\\) は多くの人がリアルタイムに知りたいが，（少なくともリアルタイムには）知れない\n\\(Y_t\\) をたくさん集めれば \\(X_t\\) を推測できるが，簡単には推測するのに十分な次元の \\(Y_t\\) を用意できない\n\nを満たす必要がある．が，意外とこのようなものは多いかも知れない．\n一方で我々の売りは\n\n\n\n\n\n\n今回のビジネスモデルのコア\n\n\n\nどんなに推定しにくい \\(X_t\\) でも（モデルが複雑で尤度が解析的な表示を持たなくても），十分な情報を含む観測データ \\(Y_t\\) が得られれば，逐次推定できる．\n\n\nということになる．\n時系列データのオンライン推論は，需要が高い一方で実装が難しい．ここの乖離が好機になる可能性がある．"
  },
  {
    "objectID": "posts/2023/2023-11-25/ParticleFilter.html#粒子フィルターの発明",
    "href": "posts/2023/2023-11-25/ParticleFilter.html#粒子フィルターの発明",
    "title": "粒子フィルターとは何か | About Particle Filter",
    "section": "2 粒子フィルターの発明",
    "text": "2 粒子フィルターの発明\n線型性や正規性の仮定を 全く 必要とせず，あらゆる状態空間モデルに使えて，加えて高次元でも適用可能な夢の新フィルタリング手法は，確率的シミュレーションを利用する Monte Carlo 法の一種 であった．(Gordon et al., 1993) はこれを bootstrap filter という名前で発表し，角度観測のみを用いた物体追跡の問題 (bearings-only tracking) への応用も付した．\n実は，この bearings-only tracking は極めて非線型性が強い問題として古典的なものであり，従来の拡張 Kalman filter の方法では精度が全く伸びなかった．これに比べて bootstrap filter では圧倒的な性能改善が見られたのであった．18\nそれだけでなく，この手法はフィルタリング問題の範疇を超えて広範な応用先を見つけつつあり，MCMC と並ぶ ベイズ計算法 となっている（ 節 2.3 ）．\nなお，北川源四郎も同年（1993年）のカンファレンスにて，Monte Carlo filter の名前で同様のアルゴリズムを発表している．そのジャーナル版は (北川源四郎, 1996a)．19 日本語文献 (北川源四郎, 1996b) はウェブ上からも読める．\n\n2.1 逐次重点サンプリングの修正としての粒子フィルター\nこの手法は 重点サンプリング を繰り返すという逐次重点サンプリングの改良として開発された．逐次重点サンプリングのアイデアは古く，(Hammersley & Morton, 1954) で提案され，(Mayne, 1966), (Handschin & Mayne, 1969) で逐次推定に応用された．\nしかし，これには荷重の分散が指数増大するという致命的な欠点があった (Chopin, 2004)．特に何度か反復を経ると，１つの粒子を除いて他の粒子は全て荷重を殆ど持たなくなってしまうという現象が起こる (Del Moral & Doucet, 2003)．このように，荷重の分散が大きくなり，少数の粒子しか推定に関与しなくなる現象を 荷重の縮退 という．20\nそこで，(Rubin, 1987) のアイデアを基に，21 リサンプリング という新たな機構を取り入れることを考える．これは 遺伝的変異・選択機構 とも呼ばれ，22 尤度の高い粒子を複製する一方で尤度の低い粒子は削除するというものである\nこれにより定期的に荷重をリセットすることで分散の指数増大を抑えることができ，が保たれるのである．しかしながらこの仕組みにより粒子の間に相関が生じるために，理論的解析を困難にする．この点から粒子フィルターは （平均場）相関粒子法 ともいう．23\nリサンプリング機構の分計算負荷は上がるが，1990年代では計算機の性能はすでにこれを補って余りある段階に達していたのである．なお，(Gordon et al., 1993) はリサンプリング手法としては多項リサンプリングを採用しており，極めて実装が簡単という点も多くの応用を生んだ理由である．24\nリサンプリングの実際の実装については，粒子フィルターの実装の稿 も参照．\n\n\n2.2 粒子フィルターの応用\n(Gordon et al., 1993) による粒子フィルターの考案は，物体追跡（と防衛目的）への応用が念頭にあり，この分野では粒子フィルターが極めて有効である (Ristic et al., 2004)．これは非線型性をものともしない性質に加えて，事前情報を柔軟に取り入れやすいという粒子フィルターの性格も大きく貢献している．25\nコンピュータビジョンへの応用も早期から取り組まれており (Isard & Andrew, 1998)，これに続いてロボティクス，HCI (Human-Computer Interaction) 分野への応用もなされている (岡兼司, 2005), (Wills & Schön, 2023)．\n一方で，(北川源四郎, 1996a) は季節調整モデルなど非定常時系列への応用が念頭にあった．確率的ボラティリティモデルなど，ファイナンスで扱う時系列は非線型性・非正規性を示すと同時にデータ数も多い．逐次推定のステップ数が増えようとも誤差が蓄積しない粒子フィルターが見事に推定を実行する．26\n加えて，マクロ経済学の分野で 動学的確率的一般均衡モデル (DSGE) の推定にも応用されている．DSGE は非線型なミクロ経済学的モデルの上に構築された大規模なモデルで， 従来は MCMC を用いたベイズ推論が実行されていたが，粒子フィルターに焼戻し法や並列計算を組み合わせることでこの問題を回避でき，さらに事後分布が多峰性を持つ場合でも有用である (Herbst & Schorfheide, 2013)．27\n近年では他の社会科学分野でもベイジアンモデリングが用いられ（ベイズ計算の稿 参照），粒子フィルターも エージェント・ベースド・モデル への応用などが試みられている (Lux, 2018)．\n\n\n2.3 粒子フィルターの一般の推定問題への応用\nこうして，粒子フィルターは非正規・非線型フィルタリング問題の解決のために開発されたアルゴリズムであったが，非線型フィルタリングに限らず極めて広い問題へと応用出来ることが徐々に明らかになった．\n特にサンプラーとしても極めて有効であり（ 節 2.3.2 ），粒子フィルターは MCMC と併せて ベイズ計算 の主要トピックの１つに躍り出た (Martin et al., 2023, p. 11)．この意味で，粒子フィルターは広く 逐次 Monte Carlo 法（Sequential Monte Carlo methods 略して SMC ）とも呼ばれる．28\n\n2.3.1 ベイズ学習\n逐次的でない「静的」な設定の下での Bayes 推論に SMC を用いる方法は (Chopin, 2002) が草分け的な仕事をした．この枠組みでは，Bayes 事後分布 \\(\\pi(\\theta|y_1,\\cdots,y_N)\\) の近似において，途中の \\(\\pi(\\theta|y_1,\\cdots,y_n)\\) を経由して逐次的に近似することが，自然な計算コスト削減法として理解できる．\n\n\n2.3.2 サンプラーとしてのSMC\n複雑な分布からのサンプリングや，その正規化定数の計算という MCMC と同様の用途に SMC を使うこともできる (Del Moral et al., 2006)．\nSMC は 調音 (tempering) を通じてサンプリング問題に応用される．これは目標の分布 \\(\\pi_p\\in\\mathcal{P}(E)\\) に対して，これに至る \\(\\mathcal{P}(E)\\) 上の道 \\[\n[p]\\ni n\\mapsto\\pi_n\\in\\mathcal{P}(E)\n\\] を通じて，より簡単な分布 \\(\\pi_1,\\pi_2,\\cdots\\) から逐次的にサンプリングをするというアイデアである．\nこの媒介的な分布 \\(\\pi_n\\) を焼き戻し分布 (tempered distribution) または架橋分布 (bridging distribution) などとも呼ぶ．29\n詳しくは，SMC サンプラーの稿 を参照．\n\n\n2.3.3 最適化\nSMC を最適化へ応用することができる．\nまず，任意の確率的最適化アルゴリズムに対して，これを並列して実行し，うまくいっているものとうまくいっていないものの間に遺伝的変異・選択機構を導入することでより性能の良い発見的アルゴリズムを導出出来ることを (Aldous & Vazirani, 1994) が指摘しており，この機構を “go with the winners” と呼んでいる．\n古典的な大域的最適化法に 焼きなまし法 (simulated annealing) (Kirkpartick et al., 1983) があるが，(Schäfer, 2013) は特定の目的関数に対してこれを一般化して粒子法に基づく最適化法を提案し，特に多峰性を持つ場合に大きく性能を改善した．\n(Johansen et al., 2008) では潜在変数モデルのパラメータの最尤推定に，EM アルゴリズム (Dempster et al., 1977) の代わりに simulated annealing に基づいた手法を用いている．分布の台が最尤推定量に収束するような分布の列 \\[\n\\overline{\\pi}_{\\gamma_n}(\\theta)\\,\\propto\\,p(\\theta)p(y|\\theta)^{\\gamma_n}\n\\] を構成し，これから逐次的にサンプリングをするのである．最終的なアルゴリズムは，EM アルゴリズムや MCMC を用いる場合より，局所解に囚われることが少なく，初期値の設定に殆ど左右されないという利点がある．\nこの枠組みは一般の非凸最適化アルゴリズムになる可能性がある．30\n\n\n2.3.4 稀現象シミュレーション\nSMC によるサンプリングは，直接のシミュレーションが困難な分布 \\(\\pi_p\\) に対しても，\\(\\pi_1,\\cdots,\\pi_p\\) と逐次的に近似することでこれを可能にするというアイデアであった．\n特に，シミュレーションが困難である分布 \\(\\pi_p\\) の例として，極めて稀な事象 \\(A_p\\) に関する条件付き分布などがあり得る．これに対して事象列 \\(A_0\\supset\\cdots\\supset A_p\\) を取り， \\[\n\\pi_n(d\\theta)=\\frac{1}{L_n}1_{A_n}(\\theta)\\nu(d\\theta)\n\\] という仲介分布の列を取るのである．この問題を 稀現象シミュレーション という．\n\n\n2.3.5 確率的グラフィカルモデル\n変数間の統計的依存関係が無向グラフによって与えられるモデルを 確率的グラフィカルモデル という．ニューラルネットワーク (Rumelhart et al., 1986) もその例であるが，疫学における疾病マッピング (Green & Richardson, 2002)，画像解析 (Carbonetto & Freitas, 2003) などにも応用されている．31\nこのようなモデルの尤度は極めて複雑になるが，これへ至る道を自然な方法で構成することができる (Hamze & de Freitas, 2005)．複雑なモデルでは MCMC は尤度の正規化定数を評価する方法を持たないが，SMC ではこれを自然に評価することができる．\n\n\n2.3.6 ポリマーシミュレーション\nポリマーシミュレーションにおいても重点サンプリング法と同じ発想が提案されたのは極めて早い段階であった (Rosenbluth & Rosenbluth, 1955)．加えてリサンプリングにあたる enrichment の考え方もあった (Wall & Erpenbeck, 1959)．\nなお，このような物理・化学的文脈では，状態空間を探索する主体としての意味を強調し，「粒子」の代わりに walker と呼ぶ．32\nこれら２つを組み合わせることで，長いポリマー鎖のシミュレーションを可能にする方法として，相関粒子法に基づくアルゴリズム PERM (pruned-enriched Rosenbluth algorithm) が提案されている (Grassberger, 1997)．\nこの手法はたんぱく質の折り畳み問題にも応用されている (Hansmann & Okamoto, 1999)．\n\n\n2.3.7 量子系シミュレーション\n量子多体系の基底状態のシミュレーションにおけるモンテカルロ法である QMC (Quantum Monte Carlo)33 でも， branching というリサンプリング機構を取り入れた相関粒子法が用いられている (Assaraf et al., 2000)．\nこれは大規模な疎行列の最小固有値・固有ベクトルを近似する手法として，量子系に限らない幅広い応用がある．34\n\n\n\n2.4 粒子フィルターの弱点\n\n計算量\n粒子フィルターは高い汎用性の代償として，多数の粒子による高精度な推論のためには多くの計算量を必要とすることは欠点に挙げられる．が，CPU や並列計算の発展により十分な量の粒子を用意できる場面も増えたため，その問題点も形骸化してきてると言える．35\n荷重の縮退\nまた粒子フィルターは，観測 \\(Y_t\\) の次元が大きいなど，観測から得られる情報量が多く，尤度（ポテンシャル）の尖度が高いとき，リサンプリング機構があってもやはり縮退を起こしてしまう．36 このような場合は，観測の情報を柔軟に取り入れた提案核を構築し，誘導粒子フィルターをうまく設計する必要がある．\n\n\n粒子フィルタを適用する際の課題の一つは，各粒子に割り当てられる重みが１粒子に集中する，いわゆる退化の問題を限られた数の粒子でいかに克服するかである．(上野玄太, 2019)\n\n\n高次元\n地球科学や天気予報の分野では \\(Y_t\\) は大きく（\\(10^7\\) を超えることもある），このような場合は粒子フィルターは実行可能でなくなる．加えて Kalman フィルターも逆行列の計算が不安定になり，アンサンブル Kalman フィルタという粒子法が用いられる（ 節 3.5 ）．"
  },
  {
    "objectID": "posts/2023/2023-11-25/ParticleFilter.html#今後の研究",
    "href": "posts/2023/2023-11-25/ParticleFilter.html#今後の研究",
    "title": "粒子フィルターとは何か | About Particle Filter",
    "section": "3 今後の研究",
    "text": "3 今後の研究\n粒子フィルターの更なる応用には次の点の研究が肝要である．\n\n3.1 Feynman-Kac 理論と粒子法の統一的理解\n粒子フィルターは状態空間モデルのフィルタリングに使えるだけでなく，Feynman-Kac 測度の確率的近似に使える汎用手法である というのがより新しい数学的理解である．37 この文脈では 相関粒子法 (interacting particle methods) と呼ばれる．38\n\nthe mathematical concepts and models are now at a point where they provide a very natural and unifying mathematical basis for a large class of Monte Carlo algorithms. (Del Moral & Doucet, 2014, p. 2)\n\nこの枠組みからならば，粒子フィルターに限らず，物理学・化学・工学で用いられている多くの 発見的手法 について，理論的な解析が可能になる可能性がある．\n\n\n3.2 提案分布の取り方\n節 2.4 で触れた通り，特に観測の情報量が大きい場合，提案分布の選び方が粒子フィルターの精度を大きく左右する．これは粒子を高確率領域に始めから誘導するように設計する 誘導粒子フィルター によってある程度対処できる．39\nしかし，このときの提案分布の取り方について普遍的な指針というものが得られていない．\n\nThe key factors for a successful application of particle filters in practice are therefore a good choice of the importance density and Rao-Blackwellization if possible. (Ristic et al., 2004) Epilogue\n\n(Guarniero et al., 2017) と (Heng et al., 2020) は提案分布にパラメトリックモデルを用意し，粒子推定量の分散を最小化するようにそのモデル内で逐次的に最適化していく機構を提案している．\n(Naesseth et al., 2015) が提唱するnested SMCは，は各時刻での提案分布を近似するために，もう一つのSMCを内部に走らせる．当然計算量は二倍になるが，それでも単純な bootstrap filter から大きく性能が改善する場合が多い．\n\n\n3.3 高次元性への対応\n状態空間が高次元になることと，既存のモデルを状態空間モデルに定式化することに困難が伴うことが，朧げながら共通課題のように思われるが，その現れ方と解決法は個々の事例で異なる．\n\n3.3.1 部分的な線型構造の利用\n周辺化粒子フィルター，または Rao-Blackwellized particle filter とも呼ばれる方法である．これは多くの場面で，仮定されている状態空間モデルが部分的に線型である場合に，線型の部分をKalmanフィルターによって正確に解き，残った部分のみを粒子フィルターで解くことで，精度の向上とアルゴリズムの効率化を図る方法である．\n(Ristic et al., 2004, p. 287) では，探知前追跡 (track-before-detect) の問題40において，周辺化粒子フィルタが，必要な粒子数を大きく削減してくれることを紹介している．\nその他にも，問題毎の特有の構造を利用して計算量を削減・パフォーマンスを最適化することは重要な営みである．\n\n\n\n3.4 漸近論\n\n3.4.1 粒子数に関する漸近論\n目前の問題を，所与の精度で解くために必要な粒子数は幾ばくか？という問題は実用上も有益だと思われる．41\n\n\n3.4.2 時間離散化に関する漸近論\n(Chopin et al., 2022)\n\n\n\n3.5 EnKFの数学的解析\n状態空間が高次元である場合，（どうなる？）\nモデルが正規性を持つならば，EnKF (Ensemble Kalman Filter) (Evensen, 1994) が有効であり，データ同化の分野で広く使われている．42\n一方で，その数学的な振る舞いはほとんど解明されておらず，1次元の場合から調べている状況である (Del Moral & Horton, 2023)．\n\n\n3.6 粒子フィルターの応用\nリアルタイム性と ベイズ推定の意思決定への応用との相性の良さ が，今後多くの重要な応用を見る可能性がある．\n\n3.6.1 属人化医療への応用\n筆者は属人化医療への応用が大きなモチベーションになっている．43\n病気の進行（あるいは健康）のモニタリングのために，健康診断やウェアラブルデバイス，フォローアップから得られるデータは，治療の見直しや異常の早期発見のために即時処理されることが望ましい．これに逐次モンテカルロ法でBayes的に迫る研究がある (Alvares et al., 2021) ！\nさらに，個々人の日常生活のレベルではSMCを用いているものはどうやらまだなく，運動と睡眠時間の間の関係と処置効果をMonte Carlo法を用いて推定している研究はある (Daza & Schneider, 2022)．これを逐次化することで，よりリアルタイムで自分に合った生活習慣への示唆が得られるアプリを開発できるかもしれない．\nまた，属人化医療においてはシステム生物学的なモデルに基づいた薬効推定が欠かせない．小規模な患者群と測定時間（服薬時間）に関する不確定性を考慮した手法が (Krengel et al., 2013) で考察されている．\nまた，腫瘍サンプルに含まれる体細胞の突然変異に関するデータから，SMCを用いて腫瘍の発達と進行の状態を理解する手法も提案されている (Ogundijo et al., 2019)．\n\n\n3.6.2 ゲノム解析への応用\n次世代DNAシークエンサーでは，DNAの各塩基ごとに異なる蛍光物質を結合させ，蛍光の波長と強度により塩基を読み取る仕組みであり，蛍光強度の生データからDNA配列データへ変換するベースコールと呼ばれる段階で粒子フィルターを使うことも提案されている (Shen & Vikalo, 2012)．\n\n\n3.6.3 疫学への応用\nCovid-19のようなパンデミックにおいて，疫学モデルを通じて時間変動する再生産数をリアルタイムでモニタリングをして意思決定に繋げるためのSMC手法も考えられており，実際にノルウェーで使用され有効性が実証された (Strovik et al., 2023)．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#sec-importance-sampling",
    "href": "posts/2023/2023-12-6/BayesianComp.html#sec-importance-sampling",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "2.2 重点サンプリング法の発明",
    "text": "2.2 重点サンプリング法の発明\n実は Manhattan 計画に最中に，もう一つのサンプリング技法が生まれていた．厚い壁で中性子線とガンマ線がどのように吸収されるかに取り組んでいたグループにて，Herman Kahn らが中心となり，式 2 の分布 \\(p\\) に関する積分が \\[\n\\begin{align*}\n    \\mathrm{E}[g(\\boldsymbol{\\theta})]&=\\int_\\Theta g(\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})\\,d\\boldsymbol{\\theta}\\\\\n    &=\\int_\\Theta\\frac{g(\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})}{p^*(\\boldsymbol{\\theta})}p^*(\\boldsymbol{\\theta})\\,d\\boldsymbol{\\theta}\n\\end{align*}\n\\] という式変形により，別の分布 \\(p^*\\) からのサンプリングを通じて計算できる，という技法が利用された．彼らはこれに重点サンプリング法という名前をつけた．これは Gerald Goertzel による命名である可能性が高い (Andral, 2022)．\nなお，当時は \\(p\\) からのサンプリングを回避できるという点よりも，\\(p^*\\) をうまく選ぶことにより元々の \\(p\\) を用いた Monte Carlo 積分法を適用するよりも近似の精度をあげることが出来るという点の方が注目された (Hammersley & Handscomb, 1964)．\n前節の Metropolis 法がMCMCの先駆けであるとしたら，この2つの美点を持った重点サンプリング法は，SMC（粒子フィルター） の先駆けであった．"
  },
  {
    "objectID": "posts/Surveys/SMCSamplers.html",
    "href": "posts/Surveys/SMCSamplers.html",
    "title": "粒子フィルターを用いたサンプリング",
    "section": "",
    "text": "$$\n%%% 演算子 \n%%% 線型代数学\n%%% 複素解析学 %%% 集合と位相 \n%%% 形式言語理論 %%% Graph Theory \n%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学\n%%% 函数解析\n%%% 積分論\n%%% Fourier解析 %%% 数値解析 \n%%% 確率論\n%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス \n%%% 偏微分方程式\n%%% 常微分方程式 %%% 統計力学 %%% 解析力学 \n%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計\n%%% 計量経済学 \n%%% 無限次元統計模型の理論\n%%% Banach Lattices \n%%% 圏 %代数の圏 %Metric space & Contraction maps %確率空間とMarkov核の圏 %Sober space & continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 \n%%% SMC\n%%% 括弧類\n%%% 予約語 \n%%% 略記 \n%%% 矢印類 $$\n\nSMC の文脈で，目標の分布 \\(\\pi_p\\in\\mathcal{P}(E)\\) が複雑であるとき，これに至る \\(\\mathcal{P}(E)\\) 上の道 \\[\n[p]\\ni n\\mapsto\\pi_n\\in\\mathcal{P}(E)\n\\] を通じて，より簡単な分布 \\(\\pi_1,\\pi_2,\\cdots\\) から逐次的にサンプリングをする，というアイデアを 調温 (tempering) という（粒子フィルターの稿 も参照）．\nこの tempering という考え方は本質的に逐次的な発想を持っているが，元々は SMC の文脈とは全く独立に，MCMC を多峰性を持つ複雑な分布に対しても使えるように拡張する研究で提案された．\nまずはその歴史を概観する．\n\n\nまず最初の発想は，目標分布 \\(\\pi_p\\) が多峰性をもち，MCMC がうまく峰を見つけられず，収束が遅くなる問題を解決する中で生まれた．\nそこで，峰の間で遷移する動きを，不変分布を変えないように MCMC に加えることで，収束性が改善できないかと考えられた．\n峰を全て特定し，正しいステップサイズを選択するために，複数の MCMC を同時に走らせる MC3 (Metropolis-Coupled MCMC) という手法が (Geyer, 1991) により提案された．\nこれは \\(\\pi_1\\otimes\\cdots\\otimes\\pi_p\\) を目標分布として独立な MCMC を実行し，時折 Metropolis 核の提案に従って不変分布を変えないようにそれらの位置を交換するという手法である．\nこの手法は parallel tempering1 または レプリカ交換法，さらには population-based MCMC2 とも呼ばれる．\nしかしながら，交換の棄却率が高まりすぎないようにするためには隣り合う \\(\\pi_n,\\pi_{n+1}\\) を十分近く取る必要があり，すると必要な MCMC 鎖の数が極めて大きくなってしまう．3\n\n\n\n焼きなまし法（または擬似アニーリング） (Kirkpartick et al., 1983) の改良として最適化の文脈で提案されたのが 焼き戻し法，または 擬似テンパリング (simulated tempering) (Marinari & Parisi, 1992) である．\nこれは状態空間を \\(E\\times [p]\\) に拡大し，4 その上の標的分布を \\[\nX|N=n\\sim\\pi_n\n\\] を満たすようにし，\\(N|X\\) は適宜架橋分布 \\(\\{\\pi_n\\}\\) を往来するよう設計することで，MC3 が \\(p\\) 本の MCMC を用いて実現していたことを，\\(E\\times [p]\\) 上の MCMC 1つで効率的に実行する．\nまた，MCMC の収束を大幅に加速する手法としても，遺伝学における複雑な事後分布からのサンプリングへの応用を念頭に独立に提案された (Geyer & Thompson, 1995)．\n\n\n\ntempered transitions では，架橋列 \\(\\{\\pi_n\\}\\) をそれぞれの \\(\\pi_n\\) を不変分布に持つ Markov 核を通じて１往復して探索し，その結果を元に \\(\\pi_p\\) を効率的に探索するような MCMC の提案を構成する．5\nまた， \\[\n\\pi_n(x)\\,\\propto\\,\\pi_0(x)e^{-\\beta_nh(x)}\n\\] と表せる際，架橋分布 \\(\\{\\pi_n\\}\\) は温度比 \\(\\beta_n/\\beta_{n+1}\\) が一定になるように 幾何的に 取ることを提案しており，現在でも一般的な基準であるようである (Behrens et al., 2012)．\n\n\n\nここで初めて SMC の文脈にもテンパリングが輸入された．6 (Neal, 2001) は重点サンプリングによってあらゆる温度 \\(\\{\\pi_n\\}\\) からの提案を効率的に採用する方法を模索した．\nテンパリング遷移の後半のアルゴリズムを発展させた形である．\n\n\n\nこちらは擬似テンパリングを基にし，他の温度からの提案を保持しておく機構を提案している．\n\n\n\n\n\n\n目標分布の峰を特定するタスクを MCMC から分離して，BFGS 法 に基づく最適化法によって先に解いてしまう手法が (Pompe & Łatuszyński, 2020) によって提案されている．\nこれにより探索した峰の全体を \\(\\mathcal{I}:=\\{1,\\cdots,I\\}\\) に格納し，拡大した状態空間 \\(E\\times\\mathcal{I}\\) 上で \\(\\widetilde{\\pi}\\) を対象とした MCMC を実行するが，この \\(\\widetilde{\\pi}\\) をさらに適応的に更新する Auxiliary Variable Adaptive MCMC を提案している．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#sec-MCMC",
    "href": "posts/2023/2023-12-6/BayesianComp.html#sec-MCMC",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "2.1 マルコフ連鎖によるモンテカルロ法の発明",
    "text": "2.1 マルコフ連鎖によるモンテカルロ法の発明\n乱数のシミュレーションを用いた確率的なアルゴリズムをモンテカルロ法と総称する．これは Metropolis が同僚 Ulam のポーカー好きから，モナコの首都 Monte Carlo にちなんで名付けたものである (Metropolis & Ulam, 1949)．このようなアルゴリズムが最初に生まれたのが，第二次世界大戦中の Los Alamos研究所 で進行中だった原爆開発計画である Manhattan計画 においてである．\n当時の問題は，原子爆弾着火時における Schödinger 作用素の基底状態のエネルギーを計算することにあった．抽象的には，\\(p\\) を \\(N\\) 個の粒子が従う Boltzmann 分布として，積分 式 2 を計算することにあった：\n\\[\n\\mathrm{E}[g(\\boldsymbol{\\theta})]=\\int_\\Theta g(\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})\\,d\\boldsymbol{\\theta}\\quad\\text{(2)}\n\\]\nただし，\n\n積分領域 \\(\\Theta\\) が \\(2N\\) 次元というとてつもない高次元空間上であること\n分布 \\(p\\) は定数倍を除いてしか計算できない\n\nという，2つの大きな制約があった．1.のために通常の数値積分法が使えず，また 2.により \\(p\\) からの直接の乱数シミュレーションが出来ないので，\\(p\\) からの乱数 \\(X_1,\\cdots,X_M\\) を十分多く生成することで積分 式 2 を \\[\n\\frac{1}{M}\\sum_{i=1}^Mg(X_i)\n\\] によって近似するという通常の Monte Carlo 積分法を実行することも出来ない．そこで，Metropolis ら当時の Los Alamos に集まった物理学者たちは新しい方法を考える必要があった．\n最終的な解決 (Metropolis et al., 1953) は，Monte Carlo 法の中でもとりわけ画期的な発想によるものであった．それは，Markov 連鎖を用いるということである．Markov連鎖とは（ある一定の条件を満たす）確率過程のクラスであり，\\(p\\) から直接のシミュレーションが出来ない状況でも，\\(p\\) に収束するようなMarkov 連鎖を構成することは可能だったのである．\n制約 1.と 2.は広く物理学とベイズ統計学の至る所で見られる障壁であり，これをものともしない汎用アルゴリズムの発明は極めて大きなブレイクスルーであった．(Dongarra & Sullivan, 2000) は Metropolis アルゴリズムを理学・工学分野に20世紀最大の影響を与えたアルゴリズムの1つとしている．"
  },
  {
    "objectID": "posts/2023/2023-12-6/BayesianComp.html#sec-BayesianModeling",
    "href": "posts/2023/2023-12-6/BayesianComp.html#sec-BayesianModeling",
    "title": "ベイズ計算とは何か | About Bayesian Computation",
    "section": "3.4 ベイズ統計モデリングが理論モデルの実証に役立つ",
    "text": "3.4 ベイズ統計モデリングが理論モデルの実証に役立つ\nベイズモデリングの有用性は，（上述のベイズ計算の問題を除けば）どんなに複雑で大規模なモデルでも，統一的な思想と方法で対応できる点にある．\n\nメカニズムを明示的に表現した数理社会学の数理モデルを，論理的に飛躍することなくダイレクトに統計モデルへと接続できるベイズ統計モデリングは，理論モデルベースの実証研究と相性のよい，たいへん便利な方法と言えるだろう． (浜田宏, 2022, p. 137)\n\nMCMCの開発とパッケージへの実装，そして安価で高性能な計算機が普及してからというもの，ベイズ統計学の興隆は目覚ましく，現在ではベイズ統計学は統計学に関する論文の1割強を占め，諸科学分野全体に浸透しつつある．経済学・心理学への応用は早かったのに比べて，政治科学・社会科学への応用は遅れ気味であり，社会学での使用はまだ稀であると言える (Lynch & Bartlett, 2019)．"
  },
  {
    "objectID": "posts/Surveys/SMCSamplers.html#metropolis-coupled-mcmc-geyer1991",
    "href": "posts/Surveys/SMCSamplers.html#metropolis-coupled-mcmc-geyer1991",
    "title": "粒子フィルターを用いたサンプリング",
    "section": "",
    "text": "まず最初の発想は，目標分布 \\(\\pi_p\\) が多峰性をもち，MCMC がうまく峰を見つけられず，収束が遅くなる問題を解決する中で生まれた．\n峰を全て特定し，正しいステップサイズを選択するために，複数の MCMC を同時に走らせる MC3 (Metropolis-Coupled MCMC) という手法が提案された．"
  },
  {
    "objectID": "posts/Surveys/SMCSamplers.html#テンパリング遷移-neal1996",
    "href": "posts/Surveys/SMCSamplers.html#テンパリング遷移-neal1996",
    "title": "粒子フィルターを用いたサンプリング",
    "section": "",
    "text": "tempered transitions では，架橋列 \\(\\{\\pi_n\\}\\) をそれぞれの \\(\\pi_n\\) を不変分布に持つ Markov 核を通じて１往復して探索し，その結果を元に \\(\\pi_p\\) を効率的に探索するような MCMC の提案を構成する．5\nまた， \\[\n\\pi_n(x)\\,\\propto\\,\\pi_0(x)e^{-\\beta_nh(x)}\n\\] と表せる際，架橋分布 \\(\\{\\pi_n\\}\\) は温度比 \\(\\beta_n/\\beta_{n+1}\\) が一定になるように 幾何的に 取ることを提案しており，現在でも一般的な基準であるようである (Behrens et al., 2012)．"
  },
  {
    "objectID": "posts/Surveys/SMCSamplers.html#footnotes",
    "href": "posts/Surveys/SMCSamplers.html#footnotes",
    "title": "粒子フィルターを用いたサンプリング",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(Chopin et al., 2023) でも (Geyer, 1991) を引用して PT と呼んでいる．↩︎\n(Jasra et al., 2007) など．↩︎\n(Behrens et al., 2012, p. 66) も参照．↩︎\n記法 \\([p]=\\{1,\\cdots,p\\}\\) は 本サイトの数学記法一覧 を参照↩︎\n(Behrens et al., 2012) も参照．↩︎\n(Chopin & Papaspiliopoulos, 2020, p. 33) で，SMC を調音に初めて応用した論文として紹介されている．↩︎"
  },
  {
    "objectID": "posts/Surveys/SMCSamplers.html#metropolis-coupled-mcmc",
    "href": "posts/Surveys/SMCSamplers.html#metropolis-coupled-mcmc",
    "title": "粒子フィルターを用いたサンプリング",
    "section": "",
    "text": "まず最初の発想は，目標分布 \\(\\pi_p\\) が多峰性をもち，MCMC がうまく峰を見つけられず，収束が遅くなる問題を解決する中で生まれた．\nそこで，峰の間で遷移する動きを，不変分布を変えないように MCMC に加えることで，収束性が改善できないかと考えられた．\n峰を全て特定し，正しいステップサイズを選択するために，複数の MCMC を同時に走らせる MC3 (Metropolis-Coupled MCMC) という手法が (Geyer, 1991) により提案された．\nこれは \\(\\pi_1\\otimes\\cdots\\otimes\\pi_p\\) を目標分布として独立な MCMC を実行し，時折 Metropolis 核の提案に従って不変分布を変えないようにそれらの位置を交換するという手法である．\nこの手法は parallel tempering または レプリカ交換法 とも呼ばれる．1\nしかしながら，交換の棄却率が高まりすぎないようにするためには隣り合う \\(\\pi_n,\\pi_{n+1}\\) を十分近く取る必要があり，すると必要な MCMC 鎖の数が極めて大きくなってしまう．2"
  },
  {
    "objectID": "posts/Surveys/SMCSamplers.html#擬似テンパリング",
    "href": "posts/Surveys/SMCSamplers.html#擬似テンパリング",
    "title": "粒子フィルターを用いたサンプリング",
    "section": "",
    "text": "焼きなまし法（または擬似アニーリング） (Kirkpartick et al., 1983) の改良として最適化の文脈で提案されたのが 焼き戻し法，または 擬似テンパリング (simulated tempering) (Marinari & Parisi, 1992) である．\nこれは状態空間を \\(E\\times [p]\\) に拡大し，4 その上の標的分布を \\[\nX|N=n\\sim\\pi_n\n\\] を満たすようにし，\\(N|X\\) は適宜架橋分布 \\(\\{\\pi_n\\}\\) を往来するよう設計することで，MC3 が \\(p\\) 本の MCMC を用いて実現していたことを，\\(E\\times [p]\\) 上の MCMC 1つで効率的に実行する．\nまた，MCMC の収束を大幅に加速する手法としても，遺伝学における複雑な事後分布からのサンプリングへの応用を念頭に独立に提案された (Geyer & Thompson, 1995)．"
  },
  {
    "objectID": "posts/Surveys/SMCSamplers.html#焼きなまし重点サンプリング-neal2001",
    "href": "posts/Surveys/SMCSamplers.html#焼きなまし重点サンプリング-neal2001",
    "title": "粒子フィルターを用いたサンプリング",
    "section": "",
    "text": "ここで初めて SMC の文脈にもテンパリングが輸入された．6 (Neal, 2001) は重点サンプリングによってあらゆる温度 \\(\\{\\pi_n\\}\\) からの提案を効率的に採用する方法を模索した．\nテンパリング遷移の後半のアルゴリズムを発展させた形である．"
  },
  {
    "objectID": "posts/Surveys/SMCSamplers.html#多峰性の最適化に基づく対処",
    "href": "posts/Surveys/SMCSamplers.html#多峰性の最適化に基づく対処",
    "title": "粒子フィルターを用いたサンプリング",
    "section": "",
    "text": "目標分布の峰を特定するタスクを MCMC から分離して，BFGS 法 に基づく最適化法によって先に解いてしまう手法が (Pompe & Łatuszyński, 2020) によって提案されている．\nこれにより探索した峰の全体を \\(\\mathcal{I}:=\\{1,\\cdots,I\\}\\) に格納し，拡大した状態空間 \\(E\\times\\mathcal{I}\\) 上で \\(\\widetilde{\\pi}\\) を対象とした MCMC を実行するが，この \\(\\widetilde{\\pi}\\) をさらに適応的に更新する Auxiliary Variable Adaptive MCMC を提案している．"
  },
  {
    "objectID": "posts/Surveys/SMCSamplers.html#metropolis-coupled-mcmc-並行テンパリング",
    "href": "posts/Surveys/SMCSamplers.html#metropolis-coupled-mcmc-並行テンパリング",
    "title": "粒子フィルターを用いたサンプリング",
    "section": "",
    "text": "まず最初の発想は，目標分布 \\(\\pi_p\\) が多峰性をもち，MCMC がうまく峰を見つけられず，収束が遅くなる問題を解決する中で生まれた．\nそこで，峰の間で遷移する動きを，不変分布を変えないように MCMC に加えることで，収束性が改善できないかと考えられた．\n峰を全て特定し，正しいステップサイズを選択するために，複数の MCMC を同時に走らせる MC3 (Metropolis-Coupled MCMC) という手法が (Geyer, 1991) により提案された．\nこれは \\(\\pi_1\\otimes\\cdots\\otimes\\pi_p\\) を目標分布として独立な MCMC を実行し，時折 Metropolis 核の提案に従って不変分布を変えないようにそれらの位置を交換するという手法である．\nこの手法は parallel tempering または レプリカ交換法 とも呼ばれる．1\nしかしながら，交換の棄却率が高まりすぎないようにするためには隣り合う \\(\\pi_n,\\pi_{n+1}\\) を十分近く取る必要があり，すると必要な MCMC 鎖の数が極めて大きくなってしまう．2"
  },
  {
    "objectID": "posts/Surveys/SMCSamplers.html#mc3-並行テンパリング",
    "href": "posts/Surveys/SMCSamplers.html#mc3-並行テンパリング",
    "title": "粒子フィルターを用いたサンプリング",
    "section": "",
    "text": "まず最初の発想は，目標分布 \\(\\pi_p\\) が多峰性をもち，MCMC がうまく峰を見つけられず，収束が遅くなる問題を解決する中で生まれた．\nそこで，峰の間で遷移する動きを，不変分布を変えないように MCMC に加えることで，収束性が改善できないかと考えられた．\n峰を全て特定し，正しいステップサイズを選択するために，複数の MCMC を同時に走らせる MC3 (Metropolis-Coupled MCMC) という手法が (Geyer, 1991) により提案された．\nこれは \\(\\pi_1\\otimes\\cdots\\otimes\\pi_p\\) を目標分布として独立な MCMC を実行し，時折 Metropolis 核の提案に従って不変分布を変えないようにそれらの位置を交換するという手法である．\nこの手法は parallel tempering1 または レプリカ交換法，さらには population-based MCMC2 とも呼ばれる．\nしかしながら，交換の棄却率が高まりすぎないようにするためには隣り合う \\(\\pi_n,\\pi_{n+1}\\) を十分近く取る必要があり，すると必要な MCMC 鎖の数が極めて大きくなってしまう．3"
  },
  {
    "objectID": "posts/Surveys/SMCSamplers.html#重点テンパリング-gramacy2010",
    "href": "posts/Surveys/SMCSamplers.html#重点テンパリング-gramacy2010",
    "title": "粒子フィルターを用いたサンプリング",
    "section": "",
    "text": "こちらは擬似テンパリングを基にし，他の温度からの提案を保持しておく機構を提案している．"
  },
  {
    "objectID": "posts/2023/2023-12-2/条件付き期待値の問題.html#条件付き分散",
    "href": "posts/2023/2023-12-2/条件付き期待値の問題.html#条件付き分散",
    "title": "条件付き期待値の測度論的基礎付け",
    "section": "3 条件付き分散",
    "text": "3 条件付き分散\n確率変数 \\(Y\\in\\mathcal{L}^2(\\Omega)\\) の \\(\\mathcal{G}\\) に関する条件付き分散を \\[\n\\mathrm{V}[Y|\\mathcal{G}]:=\\mathrm{E}\\left[(Y-\\mathrm{E}[Y|\\mathcal{G}])^2|\\mathcal{G}\\right]\n\\] と定める．このとき，\n\n\n\n\n\n\n全分散の公式\n\n\n\n\nPythagorasの式： \\[\n\\|Y\\|^2_2=\\|Y-\\mathrm{E}[Y|\\mathcal{G}]\\|^2_2+\\|\\mathrm{E}[Y|\\mathcal{G}]\\|^2_2.\n\\]\n全分散の公式： \\[\n\\mathrm{V}[Y]=\\mathrm{E}[\\mathrm{V}[Y|\\mathcal{G}]]+\\mathrm{V}[\\mathrm{E}[Y|\\mathcal{G}]].\n\\]"
  },
  {
    "objectID": "posts/2023/2023-11-24/Beta-Gamma.html#確率分布の変換則",
    "href": "posts/2023/2023-11-24/Beta-Gamma.html#確率分布の変換則",
    "title": "確率測度の変換則 | Gamma分布とBeta分布を例に",
    "section": "4 確率分布の変換則",
    "text": "4 確率分布の変換則\n\\(A,B\\subset\\mathbb{R}^d\\) を連結開集合，\\(C^1\\)-微分同相 \\(T:A\\overset{\\sim}{\\to}B\\) に対して，3 \\(B\\) 上の分布 \\(\\pi\\in\\mathcal{P}(B)\\) の \\(T\\) による引き戻し \\(T^*\\pi\\) の密度 \\(p^*\\) が，\\(\\pi\\) の密度 \\(p\\) と Jacobian \\(J_T(x)\\) の絶対値との積になる： \\[\np^*(x)=p(T(x))\\lvert J_T(x)\\rvert\\;\\;\\text{a.s.}\\quad(x\\in A).\n\\]\n\n\n\nCommutative diagram discribing current situations\n\n\n\n\n\n\n\n\n定理（変数変換）\n\n\n\n4 \\(A,B\\subset\\mathbb{R}^d\\) を連結開集合，\\(T:A\\overset{\\sim}{\\to}B\\) を \\(C^1\\)-微分同相，\\(f:B\\to\\mathbb{R}\\) を Lebesgue 可測関数とする．\n\n\\(f\\circ T:A\\to\\mathbb{R}\\) も Lebesgue 可測．\n\\(f\\) は非負関数とする．このとき， \\[\n\\begin{align*}\n\\int_Af(T(x))\\lvert J_T(x)\\rvert\\,dx=\\int_Bf(y)\\,dy.\n\\end{align*}\n\\]\n\n\n\nこの定理より，任意の可測集合 \\(A_0\\in\\mathcal{B}(A)\\) に対して， \\[\n\\begin{align*}\n    \\int_{A_0}p^*(x)\\,dx&=(T^*\\pi)[A_0]\\\\\n    &=\\int_{T(A_0)}p(y)\\,dy\\\\\n    &=\\int_{A_0}p(T(x))\\lvert J_T(x)\\rvert\\,dx.\n\\end{align*}\n\\] ただし，最後の等号は定理による．5 \\(A_0\\in\\mathcal{B}(A)\\) は任意だったから， \\[\np^*(x)=p(T(x))\\lvert J_T(x)\\rvert\\;\\;\\text{a.s.}\\quad(x\\in A).\n\\]"
  }
]