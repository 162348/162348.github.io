<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="司馬 博文">
<meta name="dcterms.date" content="2024-03-11">

<title>Hirofumi Shiba - ベイズ機械学習</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../profile.jpg" rel="icon" type="image/jpeg">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-36GX2G6GLL"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-36GX2G6GLL', { 'anonymize_ip': true});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Hirofumi Shiba - ベイズ機械学習">
<meta property="og:description" content="A Blog by a Bayesian Computation Researcher">
<meta property="og:image" content="https://162348.github.io/posts/2024/Kernels/Images/model_sizes.png">
<meta property="og:site-name" content="Hirofumi Shiba">
<meta property="og:image:height" content="806">
<meta property="og:image:width" content="2098">
<meta name="twitter:title" content="Hirofumi Shiba - ベイズ機械学習">
<meta name="twitter:description" content="所信表明">
<meta name="twitter:image" content="https://162348.github.io/posts/2024/Kernels/Images/model_sizes.png">
<meta name="twitter:image-height" content="806">
<meta name="twitter:image-width" content="2098">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Hirofumi Shiba</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../recent.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Sessions.html" rel="" target="">
 <span class="menu-text">Sessions</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Japanese.html" rel="" target="">
 <span class="menu-text">日本語</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">ベイズ機械学習</h1>
            <p class="subtitle lead">所信表明</p>
                                <div class="quarto-categories">
                <div class="quarto-category">Bayesian</div>
                <div class="quarto-category">AI</div>
                <div class="quarto-category">Survey</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>司馬 博文 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 11, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#ベイズ機械学習のすすめ" id="toc-ベイズ機械学習のすすめ" class="nav-link active" data-scroll-target="#ベイズ機械学習のすすめ"><span class="header-section-number">1</span> ベイズ機械学習のすすめ</a>
  <ul class="collapse">
  <li><a href="#ベイズとは何か" id="toc-ベイズとは何か" class="nav-link" data-scroll-target="#ベイズとは何か"><span class="header-section-number">1.1</span> ベイズとは何か？</a></li>
  <li><a href="#つの世界樹" id="toc-つの世界樹" class="nav-link" data-scroll-target="#つの世界樹"><span class="header-section-number">1.2</span> ２つの世界樹</a></li>
  </ul></li>
  <li><a href="#sec-uncertainty-quantification" id="toc-sec-uncertainty-quantification" class="nav-link" data-scroll-target="#sec-uncertainty-quantification"><span class="header-section-number">2</span> ベイズは不確実性を定量化する</a>
  <ul class="collapse">
  <li><a href="#不確実性の定量化の必要性" id="toc-不確実性の定量化の必要性" class="nav-link" data-scroll-target="#不確実性の定量化の必要性"><span class="header-section-number">2.1</span> 不確実性の定量化の必要性</a></li>
  <li><a href="#信頼のおける-ai-システム" id="toc-信頼のおける-ai-システム" class="nav-link" data-scroll-target="#信頼のおける-ai-システム"><span class="header-section-number">2.2</span> 信頼のおける AI システム</a></li>
  <li><a href="#不確実性を扱うには-bayes-が必要である" id="toc-不確実性を扱うには-bayes-が必要である" class="nav-link" data-scroll-target="#不確実性を扱うには-bayes-が必要である"><span class="header-section-number">2.3</span> 不確実性を扱うには Bayes が必要である</a></li>
  </ul></li>
  <li><a href="#sec-distributional-representation" id="toc-sec-distributional-representation" class="nav-link" data-scroll-target="#sec-distributional-representation"><span class="header-section-number">3</span> ベイズは分布という共通言語を与える</a>
  <ul class="collapse">
  <li><a href="#継続学習という発想" id="toc-継続学習という発想" class="nav-link" data-scroll-target="#継続学習という発想"><span class="header-section-number">3.1</span> 継続学習という発想</a></li>
  <li><a href="#モデルの属人化" id="toc-モデルの属人化" class="nav-link" data-scroll-target="#モデルの属人化"><span class="header-section-number">3.2</span> モデルの属人化</a></li>
  <li><a href="#例強化学習への分布によるアプローチ" id="toc-例強化学習への分布によるアプローチ" class="nav-link" data-scroll-target="#例強化学習への分布によるアプローチ"><span class="header-section-number">3.3</span> 例：強化学習への分布によるアプローチ</a></li>
  </ul></li>
  <li><a href="#sec-inductive-bias" id="toc-sec-inductive-bias" class="nav-link" data-scroll-target="#sec-inductive-bias"><span class="header-section-number">4</span> ベイズは理解を促進する</a>
  <ul class="collapse">
  <li><a href="#帰納バイアスの明確化の必要性" id="toc-帰納バイアスの明確化の必要性" class="nav-link" data-scroll-target="#帰納バイアスの明確化の必要性"><span class="header-section-number">4.1</span> 帰納バイアスの明確化の必要性</a></li>
  <li><a href="#数学者の哲学" id="toc-数学者の哲学" class="nav-link" data-scroll-target="#数学者の哲学"><span class="header-section-number">4.2</span> 数学者の哲学</a></li>
  <li><a href="#例強化学習への確率的アプローチ" id="toc-例強化学習への確率的アプローチ" class="nav-link" data-scroll-target="#例強化学習への確率的アプローチ"><span class="header-section-number">4.3</span> 例：強化学習への確率的アプローチ</a></li>
  </ul></li>
  <li><a href="#bayes-機械学習の例" id="toc-bayes-機械学習の例" class="nav-link" data-scroll-target="#bayes-機械学習の例"><span class="header-section-number">5</span> Bayes 機械学習の例</a>
  <ul class="collapse">
  <li><a href="#bayes-深層学習" id="toc-bayes-深層学習" class="nav-link" data-scroll-target="#bayes-深層学習"><span class="header-section-number">5.1</span> Bayes 深層学習</a></li>
  <li><a href="#確率的グラフィカルモデル" id="toc-確率的グラフィカルモデル" class="nav-link" data-scroll-target="#確率的グラフィカルモデル"><span class="header-section-number">5.2</span> 確率的グラフィカルモデル</a></li>
  <li><a href="#推論アルゴリズムのプログラミングからモデルのプログラミングへ" id="toc-推論アルゴリズムのプログラミングからモデルのプログラミングへ" class="nav-link" data-scroll-target="#推論アルゴリズムのプログラミングからモデルのプログラミングへ"><span class="header-section-number">5.3</span> 推論アルゴリズムのプログラミングから，モデルのプログラミングへ</a></li>
  <li><a href="#bayes-最適化" id="toc-bayes-最適化" class="nav-link" data-scroll-target="#bayes-最適化"><span class="header-section-number">5.4</span> Bayes 最適化</a></li>
  <li><a href="#データ圧縮" id="toc-データ圧縮" class="nav-link" data-scroll-target="#データ圧縮"><span class="header-section-number">5.5</span> データ圧縮</a></li>
  <li><a href="#階層モデルと統計モデルの自動発見" id="toc-階層モデルと統計モデルの自動発見" class="nav-link" data-scroll-target="#階層モデルと統計モデルの自動発見"><span class="header-section-number">5.6</span> 階層モデルと統計モデルの自動発見</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>現在，産業界における “AI” というと専ら，いくつかの限られた巨大 IT 企業が，巨大ニューラルネットワークを最尤推定で学習させ，これを基盤モデルとして公開し，我々一般庶民はそれを有効活用して下流タスクを安価に解くことだけ考えるという営みを指す．</p>
<!--
その産業への破壊的な影響を憂慮しながらも，雨乞いをする日々である．
-->
<p>AI はこれにかぎるものではない．</p>
<p>AI が真に我々の友となり，我々の日常をほんとうに豊かにするは，AI の進歩だけが必要なのではなく，<strong>人間との協業が得意になる必要がある</strong>．</p>
<p>その中でも特に，「その AI には何が出来て何が出来ないか」「AI の出力がいつ信頼にたるもので，いつ人間の介入が必要であるのか」がわかりやすい形で伝わるコミュニケーション様式をそなえている必要がある．<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<div class="hidden">
$$
<p>%%% 演算子 </p>
%%% 線型代数学
<p>%%% 複素解析学 %%% 集合と位相 </p>
<p>%%% 形式言語理論 %%% Graph Theory </p>
%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学
%%% 函数解析
%%% 積分論
<p>%%% Fourier解析 %%% 数値解析 </p>
%%% 確率論
<p>%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス </p>
<p>%%% 偏微分方程式 %%% 常微分方程式 %%% 統計力学 %%% 解析力学 </p>
%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計
<p>%%% 計量経済学 </p>
%%% 無限次元統計模型の理論
<p>%%% Banach Lattices </p>
<p>%%% 圏 %代数の圏 %Metric space &amp; Contraction maps %確率空間とMarkov核の圏 %Sober space &amp; continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 </p>
%%% SMC
%%% 括弧類
<p>%%% 予約語 </p>
<p>%%% 略記 </p>
<p>%%% 矢印類 $$</p>
</div>
<section id="ベイズ機械学習のすすめ" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="ベイズ機械学習のすすめ"><span class="header-section-number">1</span> ベイズ機械学習のすすめ</h2>
<p>我々が AI をより信頼するためには，何が必要だろうか？</p>
<p>筆者の考えでは，信頼への第一歩は <strong>不確実性の定量化</strong> が出来るようになることのはずである．</p>
<p>そしてそのためには <strong>ベイズ機械学習</strong> (Bayesian Machine Learning) の発展が必要不可欠である．本稿はこの点を説明するために執筆されたものである．</p>
<p>ベイズ機械学習が，今後数年間で AI が経験すべき進展の方向である．この山を越えれば，今まででさえ思っても見なかった未来がひらけてくるだろう．</p>
<section id="ベイズとは何か" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="ベイズとは何か"><span class="header-section-number">1.1</span> ベイズとは何か？</h3>
<p>機械学習において，確率論的なモデリングに基づいた，モデルベースのアプローチを <strong>ベイズ機械学習</strong> ともいう．<strong>確率論的アプローチ</strong> や <strong>モデルベースアプローチ</strong> も同義語として用いられる．<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> 一方で，<strong>頻度論的</strong> という言葉は，よく非ベイズ的アプローチを示す接頭辞として用いられる．</p>
<table class="table-striped table-hover table">
<caption>Difference of the two main approachs to Machine Learning</caption>
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">Bayesian</th>
<th style="text-align: center;">Frequentist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Computational Idea<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></td>
<td style="text-align: center;">Integration</td>
<td style="text-align: center;">Optimization</td>
</tr>
</tbody>
</table>
<p>確率論的なモデリングは，合理的な意思決定の基礎でもある．<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> そのため意思決定解析ではベイズの手法が用いられていても，その他の分野ではモデリングを伴わない手法が好まれることが多かった．</p>
</section>
<section id="つの世界樹" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="つの世界樹"><span class="header-section-number">1.2</span> ２つの世界樹</h3>
<p>しかし今こそ，この２つの手法は根底では繋がっていることをよく周知し，適材適所に使うことが出来て初めて良い未来があることを認識する必要がある．</p>
<ol type="1">
<li><p>第 <a href="#sec-uncertainty-quantification">2</a> 節．ベイズは不確実性を定量化する</p>
<p>Bayes の方が不確実性の定量化が得意であるため，そのような応用先では Bayes のバージョンを用いることが出来ると便利である．</p></li>
<li><p>第 <a href="#sec-distributional-representation">3</a> 節．ベイズは分布という共通言語を与える</p>
<p>Bayes による統一的な扱いが必要になっている場面が増えている．</p></li>
<li><p>第 <a href="#sec-inductive-bias">4</a> 節．ベイズは理解を促進する</p>
<p>帰納バイアスを明確化する必要がある．</p></li>
</ol>
</section>
</section>
<section id="sec-uncertainty-quantification" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="sec-uncertainty-quantification"><span class="header-section-number">2</span> ベイズは不確実性を定量化する</h2>
<section id="不確実性の定量化の必要性" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="不確実性の定量化の必要性"><span class="header-section-number">2.1</span> 不確実性の定量化の必要性</h3>
<p>機械学習と統計学が単なる道具ではなく，人間のより大きな営みの一環を単独で担う場面が増えてきた．例えば，</p>
<ul>
<li>金融・経営・政策決定などの分野で，意思決定に繋げるデータ解析をするとき</li>
<li>科学において，発見や仮説を検証するためのデータ解析をするとき</li>
<li>ロボットや自動車などの自動化をし，社会に実装するとき</li>
<li>医療診断や裁判などの場面で，専門家を補助するシステムを作るとき</li>
</ul>
<p>人間社会では信頼が重要であるように，いずれの場面でも，性能の高さと正確さだけでなく，モデル自身が「自分は何を言っているのか」を少しでもわかっていてくれている必要がある．</p>
<p>特に，データから高い確証度で言えることと，そうではないことでは全く違う意味を持つ．それぞれの場面での例には，次のようなものがあるだろう：</p>
<ul>
<li>データから高い確証度で言えることと，意思決定者による采配が必要な部分を分離できない限り，意思決定プロセスの一部として組み込むことが難しく，結局機械学習手法が全く採用されないということもあり得る．</li>
<li>結果の再現可能性が科学の基本的な要請である以上，その結果の不確実性を実験結果に付記することは基本的な科学的態度である．後述（第 <a href="#sec-replication-crisis">2.3.1</a> 節）するが，<span class="math inline">\(p\)</span>-値や信頼区間などの統計量は<strong>これに応えるものではない</strong>．</li>
<li>ロボットや自動車の自動化 AI システムは，いくつかのモデルを組み合わせて作ることになるだろう．個々が十分な性能を持っていても，小さな誤差が累積してシステムとしての性能を著しく低下させることがある．これを防ぐために，統一した方法での不確実性の取り扱いが必要である．</li>
<li>個々人の権利と法益が衝突する場面にも AI が利用されより良い生活が実現されるには，法的な解釈可能性が担保される必要があることが，実は大きな難関として我々を待っている．その第一歩は，不確実性の可視化になるだろう．<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></li>
</ul>
<p>以上の内容は，結果の <strong>解釈可能性</strong> でも全く同じことが言えるだろう．</p>
</section>
<section id="信頼のおける-ai-システム" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="信頼のおける-ai-システム"><span class="header-section-number">2.2</span> 信頼のおける AI システム</h3>
<p>上述の点をまとめると，機械学習手法と人間社会がよりよく共生していくには AI の <strong>信頼性</strong> (trustworthyness) が必要とされているのである．不確実性の定量化と解釈可能性は，AI が人間社会で信頼を獲得するにあたって根本的な要素になるだろう．</p>
<p>現状の手法の延長でこの信頼性の問題は扱えず，新たな手法が必要とされている．Bayesian approach や probabilistic approach と呼ばれている試みは，まさにこれに応えるものであり，近年急速に発展している．</p>
</section>
<section id="不確実性を扱うには-bayes-が必要である" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="不確実性を扱うには-bayes-が必要である"><span class="header-section-number">2.3</span> 不確実性を扱うには Bayes が必要である</h3>
<p>（後述のように本質的には密接な関連があれど），たしかに Bayes の方法は従来の方法と大きく異なる．だからと言って慣習的に Bayes の方法を用いないで居ると，コミュニティの混乱をもたらす恐れがある場面も多い．</p>
<p>これを，科学における再現性の危機を例にとって確認したい．<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<section id="sec-replication-crisis" class="level4" data-number="2.3.1">
<h4 data-number="2.3.1" class="anchored" data-anchor-id="sec-replication-crisis"><span class="header-section-number">2.3.1</span> 再現性の危機</h4>
<p>多くの実験科学では不確実性の定量化が必要不可欠である <span class="citation" data-cites="Krzywinski-Altman2013">(<a href="#ref-Krzywinski-Altman2013" role="doc-biblioref">Krzywinski &amp; Altman, 2013</a>)</span>．</p>
<blockquote class="blockquote">
<p>It is necessary and true that all of the things we say in science, all of the conclusions, are uncertain … <span class="citation" data-cites="Feynman1998">(<a href="#ref-Feynman1998" role="doc-biblioref">Feynman, 1998</a>)</span></p>
</blockquote>
<p><a href="https://ja.wikipedia.org/wiki/%E5%86%8D%E7%8F%BE%E6%80%A7%E3%81%AE%E5%8D%B1%E6%A9%9F"><strong>再現性の危機</strong></a> (replication crisis) とは，多くの実験において報告されている統計的優位性が，再現実験において得られないことが多いという問題を指し，2010年代の初めから多くの科学分野において問題として取り上げられてきた．<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<p>その結果多くの科学分野では <strong>Bayes 統計学による不確実性の定量化に移行しつつある</strong> <span class="citation" data-cites="Herzog-Ostwald2013">(<a href="#ref-Herzog-Ostwald2013" role="doc-biblioref">Herzog &amp; Ostwald, 2013</a>)</span>, <span class="citation" data-cites="Trafimow-Marks2015">(<a href="#ref-Trafimow-Marks2015" role="doc-biblioref">Trafimow &amp; Marks, 2015</a>)</span>, <span class="citation" data-cites="Nuzzo2014">(<a href="#ref-Nuzzo2014" role="doc-biblioref">Nuzzo, 2014</a>)</span>．特に，信頼区間と信用区間の違いにおいてその本質が顕著に表れている．</p>
</section>
<section id="信頼区間と信用区間" class="level4" data-number="2.3.2">
<h4 data-number="2.3.2" class="anchored" data-anchor-id="信頼区間と信用区間"><span class="header-section-number">2.3.2</span> 信頼区間と信用区間</h4>
<p>「95 % の信頼区間」と言ったとき，「95 % の確率で真の値がその範囲に含まれるような区間」だと思いがちであるが，これはどちらかというと信用区間の説明であり，<strong>信頼区間は計算するごとに値が変わってしまう確率変数である</strong> ことを見落としがちである．<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<p>つまり，信頼区間は頻度論的な概念であり，「真の値」がまず存在し，区間自体が変動し，95 % の確率で被覆するというのである．今回見ている信頼区間が，別のデータセットで計算した場合にどう変わるかについては全く未知である．</p>
<p>このことは，信頼区間は「真のパラメータの値」で条件づけて得るものであるが，信用区間はデータによって条件づけて得るものであるという点で違う，とまとめられる．この２つの混同は「何で条件づけているか？」を意識することで回避することができる．<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<p>誤解を恐れず言うならば，再現性の危機とは，信頼区間というサイコロの出目によって科学が踊らされていたということに他ならない <span class="citation" data-cites="Nuzzo2014">(<a href="#ref-Nuzzo2014" role="doc-biblioref">Nuzzo, 2014</a>)</span>．<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
</section>
</section>
</section>
<section id="sec-distributional-representation" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="sec-distributional-representation"><span class="header-section-number">3</span> ベイズは分布という共通言語を与える</h2>
<section id="継続学習という発想" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="継続学習という発想"><span class="header-section-number">3.1</span> 継続学習という発想</h3>
<p>単に「教師あり」「教師なし」の１タスクを解く営みは爛熟しつつあり，機械学習の理論と応用の最先端は，より深い森に分け入りつつある．</p>
<p>ここにおいて，ベイズ流の接近が統一的な取り扱いを与えるという美点が，さらに重要でもはや必要不可欠な役割を果たすものと思われる．</p>
<p>これが，潜在空間上の事前分布が，我々人類の言う意味での事前知識という概念に，限りなく漸近しつつあることが背景にある．</p>
</section>
<section id="モデルの属人化" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="モデルの属人化"><span class="header-section-number">3.2</span> モデルの属人化</h3>
<p>大きなデータも，属人化医療や推薦システムなど多くの文脈では小さなデータの寄せ集めであり，そうでなくともその構造を正しく捉え，全ての不確実性を取り入れた柔軟なモデリングをすることで，さらに密接な形で社会に取り入れることができる．<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a></p>
<blockquote class="blockquote">
<p>Although considerable challenges remain, the c ing decade promises substantial advances in artificial intelligence and machine learning based on the probabilistic framework. <span class="citation" data-cites="Ghahramani2015">(<a href="#ref-Ghahramani2015" role="doc-biblioref">Ghahramani, 2015</a>)</span></p>
</blockquote>
</section>
<section id="例強化学習への分布によるアプローチ" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="例強化学習への分布によるアプローチ"><span class="header-section-number">3.3</span> 例：強化学習への分布によるアプローチ</h3>
<blockquote class="blockquote">
<p>we believe the value distribution has a central role to play in reinforcement learning. <span class="citation" data-cites="Bellemare+2017">(<a href="#ref-Bellemare+2017" role="doc-biblioref">Bellemare et al., 2017</a>)</span></p>
</blockquote>
</section>
</section>
<section id="sec-inductive-bias" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="sec-inductive-bias"><span class="header-section-number">4</span> ベイズは理解を促進する</h2>
<p>我々はもはや機械学習を通じて，自分たちが何をやっているのかわかっていない．この愚かさを AI に継がせてはならない．</p>
<p>ベイズ法の採用は，自分たちが何をやっているかへの理解と解釈可能性を，刺激するという側面がある．</p>
<p>これはベイズの美点であると同時に，ベイズの発展を阻害してきた困難の一つである．</p>
<section id="帰納バイアスの明確化の必要性" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="帰納バイアスの明確化の必要性"><span class="header-section-number">4.1</span> 帰納バイアスの明確化の必要性</h3>
<p>現状の AI システムは大量のラベル付きデータが必要であり，多くの現実的に有用なタスクでこのような教師データが用意できるわけではない．</p>
<p>一方で，人間は遥かに少ないデータから効率的に学習することができる．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../Kernels/Images/model_sizes.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Number of Training Tokens <a href="https://babylm.github.io/">BabyLM Challenge</a></figcaption>
</figure>
</div>
<p>その違いは，進化が我々生物に授けた <strong>帰納バイアス</strong> にある．</p>
<p>現状，機械学習は確率的な方法を取っていない．つまり，事前分布を明示せずに行われる Bayes 学習の理論によって現状の機械学習の成功が支えられているのであり，現状のままではモデルにどのような帰納バイアスが組み込まれているか不明瞭である．<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a></p>
</section>
<section id="数学者の哲学" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="数学者の哲学"><span class="header-section-number">4.2</span> 数学者の哲学</h3>
<p>Bayes の見方は，機械学習を底流する数理的枠組みになっている．仮に次の MacLane の言葉が数学者のあるべき態度の１つであるとするならば，数学者には Bayes 機械学習が特におすすめできる．</p>
<blockquote class="blockquote">
<p>However, I persisted in the position that <strong>as mathematicians we must know whereof we speak</strong>, be it a homotopy group or an adjoint functor. <span class="citation" data-cites="MacLane1983">(<a href="#ref-MacLane1983" role="doc-biblioref">Mac&nbsp;Lane, 1983, p. 55</a>)</span></p>
</blockquote>
<p>任意のモデル <span class="math inline">\(\mathcal{M}\)</span> の周辺尤度 <span class="math inline">\(p(x|\mathcal{M})\)</span> （<strong>証拠</strong> (model evidence) ともいう）は，全てのデータの空間 <span class="math inline">\(x\in\mathcal{X}\)</span> 上に有限な測度を定めるはずである．</p>
<p>よって，<strong>全てのモデルは，あるデータを得意とするならば他のデータについては不得意であることを免れない</strong>．これは no free lunch 定理と呼ばれる定理の一群により推測されており，分類問題などの簡単なタスクを除いて完全な形式的表現は持たない知識である．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Images/mackay.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">A Probabilistic Perspective of Genelization <span class="citation" data-cites="Wilson-Izmailov2020">(<a href="#ref-Wilson-Izmailov2020" role="doc-biblioref">Wilson &amp; Izmailov, 2020</a>)</span></figcaption>
</figure>
</div>
<p>例えば，<a href="../../../posts/2024/Kernels/Deep2.html#sec-fine-tuning">基盤モデル</a> とは，インターネット上のデータから最大限人間の言語というものに関する帰納バイアスを取り込んだ，パラメータ上の初期設定である．</p>
<p>これは，あるパラメータ空間上の理想的な事前分布からのサンプリングであるかも知れない．それ故，種々の下流タスクに対して，小さなモデル変更のみにより適応することが出来る．</p>
<p>大規模言語モデルの能力創発現象は，帰納バイアスを十分取り込むことにより自然に解かれるタスクであったのかもしれない．</p>
</section>
<section id="例強化学習への確率的アプローチ" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="例強化学習への確率的アプローチ"><span class="header-section-number">4.3</span> 例：強化学習への確率的アプローチ</h3>
<blockquote class="blockquote">
<p>Crucially, in the framework of PGMs, it is sufficient to write down the model and pose the question, and the objectives for learning and inference emerge automatically. <span class="citation" data-cites="Levine2018">(<a href="#ref-Levine2018" role="doc-biblioref">Levine, 2018</a>)</span></p>
</blockquote>
</section>
</section>
<section id="bayes-機械学習の例" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="bayes-機械学習の例"><span class="header-section-number">5</span> Bayes 機械学習の例</h2>
<section id="bayes-深層学習" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="bayes-深層学習"><span class="header-section-number">5.1</span> Bayes 深層学習</h3>
</section>
<section id="確率的グラフィカルモデル" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="確率的グラフィカルモデル"><span class="header-section-number">5.2</span> 確率的グラフィカルモデル</h3>
<p>歴史的に，（確率的）モデリングは，主に（確率的）グラフィカルモデルを通じて機械学習の分野に導入された．</p>
<p>そのため，20世紀に入ったばかりの頃は，Bayes 機械学習の唯一の例は確率的グラフィカルモデルなのであった．<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a></p>
</section>
<section id="推論アルゴリズムのプログラミングからモデルのプログラミングへ" class="level3" data-number="5.3">
<h3 data-number="5.3" class="anchored" data-anchor-id="推論アルゴリズムのプログラミングからモデルのプログラミングへ"><span class="header-section-number">5.3</span> 推論アルゴリズムのプログラミングから，モデルのプログラミングへ</h3>
<p>シミュレーターがあれば推論ができるというのが Bayes 計算の強みである．</p>
<p>そこで，推論手法をこれで統一し，解析者はモデルの構築に集中すれば良い，という新たなパラダイムを <strong>確率的プログラミング</strong> (Probabilistic Programming) と呼ぶ．</p>
</section>
<section id="bayes-最適化" class="level3" data-number="5.4">
<h3 data-number="5.4" class="anchored" data-anchor-id="bayes-最適化"><span class="header-section-number">5.4</span> Bayes 最適化</h3>
</section>
<section id="データ圧縮" class="level3" data-number="5.5">
<h3 data-number="5.5" class="anchored" data-anchor-id="データ圧縮"><span class="header-section-number">5.5</span> データ圧縮</h3>
</section>
<section id="階層モデルと統計モデルの自動発見" class="level3" data-number="5.6">




</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">5.6 階層モデルと統計モデルの自動発見</h2><div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="list">
<div id="ref-Amershi+2019" class="csl-entry" role="listitem">
Amershi, S., Weld, D., Vorvoreanu, M., Fourney, A., Nushi, B., Collisson, P., Suh, J., Iqbal, S., Bennett, P. N., Inkpen, K., Teevan, J., Kikin-Gil, R., &amp; Horvitz, E. (2019). Guidelines for human-AI interaction. <em>Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems</em>, 1–13. <a href="https://doi.org/10.1145/3290605.3300233">https://doi.org/10.1145/3290605.3300233</a>
</div>
<div id="ref-Angrist-Pischke2010" class="csl-entry" role="listitem">
Angrist, J. D., &amp; Pischke, J.-S. (2010). The credibility revolution in empirical economics: How better research design is taking the con out of econometrics. <em>The Journal of Economic Perspectives</em>, <em>24</em>(2), 3–30. <a href="http://www.jstor.org/stable/25703496">http://www.jstor.org/stable/25703496</a>
</div>
<div id="ref-Bensal+2019" class="csl-entry" role="listitem">
Bansal, G., Nushi, B., Kamar, E., Weld, D. S., Lasecki, W. S., &amp; Horvitz, E. (2019). Updates in human-AI teams: Understanding and addressing the performance/compatibility tradeoff. <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, <em>33</em>(01), 2429–2437. <a href="https://doi.org/10.1609/aaai.v33i01.33012429">https://doi.org/10.1609/aaai.v33i01.33012429</a>
</div>
<div id="ref-Bellemare+2017" class="csl-entry" role="listitem">
Bellemare, M. G., Dabney, W., &amp; Munos, R. (2017). A distributional perspective on reinforcement learning. In D. Precup &amp; Y. W. Teh (Eds.), <em>Proceedings of the 34th international conference on machine learning</em> (Vol. 70, pp. 449–458). PMLR. <a href="https://proceedings.mlr.press/v70/bellemare17a.html">https://proceedings.mlr.press/v70/bellemare17a.html</a>
</div>
<div id="ref-Broderick+2023" class="csl-entry" role="listitem">
Broderick, T., Gelman, A., Meager, R., Smith, A. L., &amp; Zheng, T. (2023). Toward a taxonomy of trust for probabilistic machine learning. <em>Science Advances</em>, <em>9</em>(7), eabn3999. <a href="https://doi.org/10.1126/sciadv.abn3999">https://doi.org/10.1126/sciadv.abn3999</a>
</div>
<div id="ref-Feynman1998" class="csl-entry" role="listitem">
Feynman, R. P. (1998). <em><a href="">The meaning of it all: Thoughts of a citizen scientist</a></em>. Addison-Wesley.
</div>
<div id="ref-Gal-Ghahramani2016" class="csl-entry" role="listitem">
Gal, Y., &amp; Ghahramani, Z. (2016). Dropout as a bayesian approximation: Representing model uncertainty in deep learning. In M. F. Balcan &amp; K. Q. Weinberger (Eds.), <em>Proceedings of the 33rd international conference on machine learning</em> (Vol. 48, pp. 1050–1059). PMLR. <a href="https://proceedings.mlr.press/v48/gal16.html">https://proceedings.mlr.press/v48/gal16.html</a>
</div>
<div id="ref-Ghahramani2015" class="csl-entry" role="listitem">
Ghahramani, Z. (2015). Probabilistic machine learning and artificial intelligence. <em>Nature</em>, <em>521</em>, 452–459. <a href="https://www.nature.com/articles/nature14541">https://www.nature.com/articles/nature14541</a>
</div>
<div id="ref-Herzog-Ostwald2013" class="csl-entry" role="listitem">
Herzog, S., &amp; Ostwald, D. (2013). Sometimes bayesian statistics are better. <em>Nature</em>, <em>494</em>(7435), 35–35. <a href="https://doi.org/10.1038/494035b">https://doi.org/10.1038/494035b</a>
</div>
<div id="ref-Krzywinski-Altman2013" class="csl-entry" role="listitem">
Krzywinski, M., &amp; Altman, N. (2013). Importance of being uncertain. <em>Nature Methods</em>, <em>10</em>(9), 809–810. <a href="https://doi.org/10.1038/nmeth.2613">https://doi.org/10.1038/nmeth.2613</a>
</div>
<div id="ref-Levine2018" class="csl-entry" role="listitem">
Levine, S. (2018). <em>Reinforcement learning and control as probabilistic inference: Tutorial and review</em>. <a href="https://arxiv.org/abs/1805.00909">https://arxiv.org/abs/1805.00909</a>
</div>
<div id="ref-MacLane1983" class="csl-entry" role="listitem">
Mac&nbsp;Lane, S. (1983). The health of mathematics. <em>The Mathematical Intelligencer</em>, <em>5</em>(4), 53–56. <a href="https://doi.org/10.1007/BF03026510">https://doi.org/10.1007/BF03026510</a>
</div>
<div id="ref-Neal-Hinton1998" class="csl-entry" role="listitem">
Neal, R. M., &amp; Hinton, G. E. (1998). <em>Learning in graphical models</em> (M. I. Jordan, Ed.; pp. 355–368). Springer Dordrecht. <a href="https://link.springer.com/chapter/10.1007/978-94-011-5014-9_12">https://link.springer.com/chapter/10.1007/978-94-011-5014-9_12</a>
</div>
<div id="ref-Nuzzo2014" class="csl-entry" role="listitem">
Nuzzo, R. (2014). Scientific method: Statistical errors. <em>Nature</em>, <em>506</em>(7487), 150–152. <a href="https://doi.org/10.1038/506150a">https://doi.org/10.1038/506150a</a>
</div>
<div id="ref-Trafimow-Marks2015" class="csl-entry" role="listitem">
Trafimow, D., &amp; Marks, M. (2015). Editorial. <em>Basic and Applied Social Psychology</em>, <em>37</em>(1), 1–2. <a href="https://doi.org/10.1080/01973533.2015.1012991">https://doi.org/10.1080/01973533.2015.1012991</a>
</div>
<div id="ref-Wilson-Izmailov2020" class="csl-entry" role="listitem">
Wilson, A. G., &amp; Izmailov, P. (2020). Bayesian deep learning and a probabilistic perspective of generalization. <em>Proceedings of the 34th International Conference on Neural Information Processing Systems</em>. <a href="https://proceedings.neurips.cc/paper/2020/hash/322f62469c5e3c7dc3e58f5a4d1ea399-Abstract.html">https://proceedings.neurips.cc/paper/2020/hash/322f62469c5e3c7dc3e58f5a4d1ea399-Abstract.html</a>
</div>
<div id="ref-平石-中村2022" class="csl-entry" role="listitem">
平石界, &amp; 中村大輝. (2022). 心理学における再現性危機の10年―危機は克服されたのか，克服され得るのか―. <em>科学哲学</em>, <em>54</em>(2), 27–50. <a href="https://www.jstage.jst.go.jp/article/jpssj/54/2/54_27/_article/-char/ja">https://www.jstage.jst.go.jp/article/jpssj/54/2/54_27/_article/-char/ja</a>
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>これは <a href="https://www.microsoft.com/en-us/research/project/guidelines-for-human-ai-interaction/">Human-AI interaction におけるガイドライン</a> <span class="citation" data-cites="Amershi+2019">(<a href="#ref-Amershi+2019" role="doc-biblioref">Amershi et al., 2019</a>)</span>, <span class="citation" data-cites="Bensal+2019">(<a href="#ref-Bensal+2019" role="doc-biblioref">Bansal et al., 2019</a>)</span> でも明確にされている点である．<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><span class="citation" data-cites="Broderick+2023">(<a href="#ref-Broderick+2023" role="doc-biblioref">Broderick et al., 2023</a>)</span> など．<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>多くの頻度論的な統計手法が最適化に拠る一方で，Bayes 統計・Bayes 学習は専ら積分法に拠る．このように，その用いる手法も鮮やかに対照的に見えるが，積分は変分近似を通じて最適化問題としても解けるし，Lengevin 法や HMC などの最適化手法は積分問題を解ける．<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>合理的な信念の度合い (degree of belief) は確率の公理を満たす必要がある，という主張は <a href="https://en.wikipedia.org/wiki/Cox%27s_theorem">Cox の名前でも呼ばれる</a>．この点から，Bayes の定理は，帰納的推論の確率論的な拡張だとも捉えられる．<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>モデルの予測結果に不確実性の定量化が伴われていたならば，モデルを信用出来ない場面で意思決定者がこれを信用したため責任があるのか，使用者には非難可能性がないのか，モデル設計者に過失があったと言えるのかの議論に，足場を与えることが出来るだろう．<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p><span class="citation" data-cites="Gal-Ghahramani2016">(<a href="#ref-Gal-Ghahramani2016" role="doc-biblioref">Gal &amp; Ghahramani, 2016</a>)</span> も参照．<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>心理学においては「再現性問題が大きく注目される大きな契機となった「超能力論文」が出版されたのが 2011 年である」 <span class="citation" data-cites="平石-中村2022">(<a href="#ref-平石-中村2022" role="doc-biblioref">平石界 &amp; 中村大輝, 2022</a>)</span> ようである．計量経済学における <strong>信頼性革命</strong> <span class="citation" data-cites="Angrist-Pischke2010">(<a href="#ref-Angrist-Pischke2010" role="doc-biblioref">Angrist &amp; Pischke, 2010</a>)</span> は，再現性の危機の，もう一つの革新的な解決法である．<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>「それでは，信頼区間は不確実性の正しい定量化を与えないではないか！」ということになるが，その通りなのである．<span class="math inline">\(P\)</span>-値を計算する過程とは，帰無仮説で条件付けているだけであり，データの関数でもある．<span class="math inline">\(P\)</span>-値の確率変数としての分散が大きいほど，何回か同じ実験を繰り返せばすぐに小さな <span class="math inline">\(P\)</span>-値が得られることになる．これは <a href="../../../posts/2023/数理法務/法律家のための統計数理2.html#sec-Bayes-problem"><strong>基準確率の誤謬</strong></a> と似ている．<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>“Confidence intervals suffer from an inverse inference problem that is not very different from that suffered by the NHSTP. In the NHSTP, the problem is in traversing the distance from the probability of the finding, given the null hypothesis, to the probability of the null hypothesis, given the finding.” <span class="citation" data-cites="Trafimow-Marks2015">(<a href="#ref-Trafimow-Marks2015" role="doc-biblioref">Trafimow &amp; Marks, 2015</a>)</span><a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p><span class="citation" data-cites="Nuzzo2014">(<a href="#ref-Nuzzo2014" role="doc-biblioref">Nuzzo, 2014</a>)</span> には，Fisher が最初に用いてから，Neyman-Pearson 理論がこれを排除したものの，コミュニティが <span class="math inline">\(P\)</span>-値を誤解して都合の良いように利用するようになるまでに至った歴史が説明されている．<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p><span class="citation" data-cites="Ghahramani2015">(<a href="#ref-Ghahramani2015" role="doc-biblioref">Ghahramani, 2015, p. 458</a>)</span> はこれを <strong>モデルの属人化</strong> (personalization of models) と呼んでいる．<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>Philipp Hennig <a href="https://youtu.be/TTo2kjrAuTo?si=QD_pqMkdLOl52OsR&amp;t=3703"><em>Probabilistic ML - Lecture 1 - Introduction</em></a><a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p><span class="citation" data-cites="Neal-Hinton1998">(<a href="#ref-Neal-Hinton1998" role="doc-biblioref">Neal &amp; Hinton, 1998</a>)</span> など．<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="quarto-dev/quarto-web" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



</body></html>