<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="司馬 博文">
<meta name="dcterms.date" content="2024-03-19">

<title>Hirofumi Shiba - ベイズ機械学習</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../profile.jpg" rel="icon" type="image/jpeg">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-36GX2G6GLL"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-36GX2G6GLL', { 'anonymize_ip': true});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Hirofumi Shiba - ベイズ機械学習">
<meta property="og:description" content="A Blog by a Bayesian Computation Researcher">
<meta property="og:image" content="https://162348.github.io/posts/2024/AI/anomaths.png">
<meta property="og:site_name" content="Hirofumi Shiba">
<meta name="twitter:title" content="Hirofumi Shiba - ベイズ機械学習">
<meta name="twitter:description" content="所信表明">
<meta name="twitter:image" content="https://162348.github.io/posts/2024/AI/anomaths.png">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Hirofumi Shiba</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../recent.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Sessions.html"> 
<span class="menu-text">Sessions</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Japanese.html"> 
<span class="menu-text">日本語</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">ベイズ機械学習</h1>
            <p class="subtitle lead">所信表明</p>
                                <div class="quarto-categories">
                <div class="quarto-category">Bayesian</div>
                <div class="quarto-category">AI</div>
                <div class="quarto-category">Survey</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>司馬 博文 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 19, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#ベイズ機械学習のすすめ" id="toc-ベイズ機械学習のすすめ" class="nav-link active" data-scroll-target="#ベイズ機械学習のすすめ"><span class="header-section-number">1</span> ベイズ機械学習のすすめ</a>
  <ul class="collapse">
  <li><a href="#ベイズとは何か" id="toc-ベイズとは何か" class="nav-link" data-scroll-target="#ベイズとは何か"><span class="header-section-number">1.1</span> ベイズとは何か？</a></li>
  <li><a href="#つの世界樹" id="toc-つの世界樹" class="nav-link" data-scroll-target="#つの世界樹"><span class="header-section-number">1.2</span> ２つの世界樹</a></li>
  </ul></li>
  <li><a href="#sec-uncertainty-quantification" id="toc-sec-uncertainty-quantification" class="nav-link" data-scroll-target="#sec-uncertainty-quantification"><span class="header-section-number">2</span> ベイズは不確実性を定量化する</a>
  <ul class="collapse">
  <li><a href="#不確実性の定量化の必要性" id="toc-不確実性の定量化の必要性" class="nav-link" data-scroll-target="#不確実性の定量化の必要性"><span class="header-section-number">2.1</span> 不確実性の定量化の必要性</a></li>
  <li><a href="#信頼のおける-ai-システム" id="toc-信頼のおける-ai-システム" class="nav-link" data-scroll-target="#信頼のおける-ai-システム"><span class="header-section-number">2.2</span> 信頼のおける AI システム</a></li>
  <li><a href="#不確実性を扱うには-bayes-が必要である" id="toc-不確実性を扱うには-bayes-が必要である" class="nav-link" data-scroll-target="#不確実性を扱うには-bayes-が必要である"><span class="header-section-number">2.3</span> 不確実性を扱うには Bayes が必要である</a></li>
  <li><a href="#ベイズ深層学習という夢" id="toc-ベイズ深層学習という夢" class="nav-link" data-scroll-target="#ベイズ深層学習という夢"><span class="header-section-number">2.4</span> ベイズ深層学習という夢</a></li>
  <li><a href="#分野全体の動向" id="toc-分野全体の動向" class="nav-link" data-scroll-target="#分野全体の動向"><span class="header-section-number">2.5</span> 分野全体の動向</a></li>
  </ul></li>
  <li><a href="#sec-distributional-representation" id="toc-sec-distributional-representation" class="nav-link" data-scroll-target="#sec-distributional-representation"><span class="header-section-number">3</span> ベイズは分布という共通言語を与える</a>
  <ul class="collapse">
  <li><a href="#継続学習という発想" id="toc-継続学習という発想" class="nav-link" data-scroll-target="#継続学習という発想"><span class="header-section-number">3.1</span> 継続学習という発想</a></li>
  <li><a href="#モデルの属人化" id="toc-モデルの属人化" class="nav-link" data-scroll-target="#モデルの属人化"><span class="header-section-number">3.2</span> モデルの属人化</a></li>
  <li><a href="#例強化学習への分布によるアプローチ" id="toc-例強化学習への分布によるアプローチ" class="nav-link" data-scroll-target="#例強化学習への分布によるアプローチ"><span class="header-section-number">3.3</span> 例：強化学習への分布によるアプローチ</a></li>
  </ul></li>
  <li><a href="#sec-inductive-bias" id="toc-sec-inductive-bias" class="nav-link" data-scroll-target="#sec-inductive-bias"><span class="header-section-number">4</span> ベイズは理解を促進する</a>
  <ul class="collapse">
  <li><a href="#帰納バイアスの明確化の必要性" id="toc-帰納バイアスの明確化の必要性" class="nav-link" data-scroll-target="#帰納バイアスの明確化の必要性"><span class="header-section-number">4.1</span> 帰納バイアスの明確化の必要性</a></li>
  <li><a href="#数学者の哲学" id="toc-数学者の哲学" class="nav-link" data-scroll-target="#数学者の哲学"><span class="header-section-number">4.2</span> 数学者の哲学</a></li>
  <li><a href="#例強化学習への確率的アプローチ" id="toc-例強化学習への確率的アプローチ" class="nav-link" data-scroll-target="#例強化学習への確率的アプローチ"><span class="header-section-number">4.3</span> 例：強化学習への確率的アプローチ</a></li>
  </ul></li>
  <li><a href="#bayes-機械学習の例" id="toc-bayes-機械学習の例" class="nav-link" data-scroll-target="#bayes-機械学習の例"><span class="header-section-number">5</span> Bayes 機械学習の例</a>
  <ul class="collapse">
  <li><a href="#bayes-深層学習" id="toc-bayes-深層学習" class="nav-link" data-scroll-target="#bayes-深層学習"><span class="header-section-number">5.1</span> Bayes 深層学習</a></li>
  <li><a href="#確率的グラフィカルモデル" id="toc-確率的グラフィカルモデル" class="nav-link" data-scroll-target="#確率的グラフィカルモデル"><span class="header-section-number">5.2</span> 確率的グラフィカルモデル</a></li>
  <li><a href="#推論アルゴリズムのプログラミングからモデルのプログラミングへ" id="toc-推論アルゴリズムのプログラミングからモデルのプログラミングへ" class="nav-link" data-scroll-target="#推論アルゴリズムのプログラミングからモデルのプログラミングへ"><span class="header-section-number">5.3</span> 推論アルゴリズムのプログラミングから，モデルのプログラミングへ</a></li>
  <li><a href="#bayes-最適化" id="toc-bayes-最適化" class="nav-link" data-scroll-target="#bayes-最適化"><span class="header-section-number">5.4</span> Bayes 最適化</a></li>
  <li><a href="#データ圧縮" id="toc-データ圧縮" class="nav-link" data-scroll-target="#データ圧縮"><span class="header-section-number">5.5</span> データ圧縮</a></li>
  <li><a href="#階層モデルと統計モデルの自動発見" id="toc-階層モデルと統計モデルの自動発見" class="nav-link" data-scroll-target="#階層モデルと統計モデルの自動発見"><span class="header-section-number">5.6</span> 階層モデルと統計モデルの自動発見</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>現在，産業界における “AI” というと専ら，いくつかの限られた巨大 IT 企業が，巨大ニューラルネットワークを最尤推定で学習させ，これを基盤モデルとして公開し，我々一般庶民はそれを有効活用して下流タスクを安価に解くことだけ考えるという営みを指す．</p>
<p>その産業や生活への破壊的な影響を憂慮しながらも，雨乞いをする日々である．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><video src="Images/SamAltman.mp4" class="img-fluid" controls=""><a href="Images/SamAltman.mp4">Video</a></video></p>
<figcaption>3月19日時点，GPT-5 にも Sora にもアクセス権を持たない我々 v.s. <a href="https://youtu.be/jvqFAi7vkBc?si=hwF_LJAs7XE3bNTR&amp;t=2695">Lex Fridman Podcast</a> に出演した Sam Altman</figcaption>
</figure>
</div>
<p>AI はそんなものではない．AI はこれにかぎるものではない．</p>
<p>AI が真に我々の友となり，我々の日常をほんとうに豊かにするは，AI の進歩だけが必要なのではなく，<strong>人間との協業が得意になる必要がある</strong>．</p>
<p>そのための第一歩はすでに明らかである．<strong>不確実性の定量化</strong> である．</p>
<p>つまり，「その AI には何が出来て何が出来ないか」「AI の出力がいつ信頼にたるもので，いつ人間の介入が必要であるのか」がわかりやすい形で伝わるコミュニケーション様式をそなえている必要があるのである．<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<div class="hidden">
$$
<p>%%% 演算子 </p>
%%% 線型代数学
<p>%%% 複素解析学 %%% 集合と位相 </p>
<p>%%% 形式言語理論 %%% Graph Theory </p>
%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学
%%% 函数解析
%%% 積分論
<p>%%% Fourier解析 %%% 数値解析 </p>
%%% 確率論
<p>%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス </p>
<p>%%% 偏微分方程式 %%% 常微分方程式 %%% 統計力学 %%% 解析力学 </p>
%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計
<p>%%% 計量経済学 </p>
%%% 無限次元統計模型の理論
<p>%%% Banach Lattices </p>
<p>%%% 圏 %代数の圏 %Metric space &amp; Contraction maps %確率空間とMarkov核の圏 %Sober space &amp; continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 </p>
%%% SMC
%%% 括弧類
<p>%%% 予約語 </p>
<p>%%% 略記 </p>
<p>%%% 矢印類 $$</p>
</div>
<section id="ベイズ機械学習のすすめ" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="ベイズ機械学習のすすめ"><span class="header-section-number">1</span> ベイズ機械学習のすすめ</h2>
<p>我々が AI をより信頼するためには，何が必要だろうか？</p>
<p>筆者の考えでは，信頼への第一歩は <strong>不確実性の定量化</strong> が出来るようになることのはずである．</p>
<p>そしてそのためには <strong>ベイズ機械学習</strong> (Bayesian Machine Learning) の発展による本質的解決が必要不可欠である．本稿はこの点を説明するために執筆されたものである．</p>
<p>筆者に言わせれば，ベイズ機械学習が，今後数年間で AI が経験すべき進展の方向である．この山を越えれば，今まででさえ思っても見なかった未来がひらけてくるだろう．</p>
<section id="ベイズとは何か" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="ベイズとは何か"><span class="header-section-number">1.1</span> ベイズとは何か？</h3>
<p>機械学習において，確率論的なモデリングに基づいたアプローチを <strong>ベイズ機械学習</strong> ともいう．典型的には，モデルの全変数上の結合分布をモデリングし，ベイズ規則によりパラメータのベイズ推定を行う，という手続きからなる．そのため，<strong>確率論的アプローチ</strong> や <strong>モデルベースアプローチ</strong> も同義語として用いられる．<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>一方で，<strong>頻度論的</strong> という言葉は，よく非ベイズ的アプローチを示す接頭辞として用いられる．この２つのアプローチは互いに対照的であり，統計学の始まりから基本的な二項対立の図式をなしてきた．</p>
<p>しかし，機械学習の時代においては，互いの弱みを補間し合う形で発展していくと筆者は考える．機械学習の世界樹は２本あるのである．</p>
<table class="table-striped table-hover table">
<caption>Contrast of the two main approachs to Machine Learning</caption>
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">Bayesian</th>
<th style="text-align: center;">Frequentist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Computational Idea<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></td>
<td style="text-align: center;">Integration and Marginalization</td>
<td style="text-align: center;">Optimization and Approximation</td>
</tr>
<tr class="even">
<td style="text-align: center;">Objective</td>
<td style="text-align: center;">Uncertainty Quantification</td>
<td style="text-align: center;">Approximation of True Value</td>
</tr>
</tbody>
</table>
<p>ベイズ推論は帰納的推論の確率論的拡張と見れるため，確率論的なモデリングは，合理的な意思決定の基礎でもある．<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<p>そのため意思決定解析などの分野では古くからベイズの手法が用いられていたが，その他の分野ではモデリングを伴わない手法が好まれることが多かった．<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
</section>
<section id="つの世界樹" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="つの世界樹"><span class="header-section-number">1.2</span> ２つの世界樹</h3>
<p>今こそ，この２つの手法は根底では繋がっていることをよく周知し，この２つの視座を往来しながら適材適所に使うことが大事だと筆者は考える．</p>
<p>しかしそのためには，ベイズ機械学習の発展が遅れている現状を鑑みて，ベイズの手法のより一層の発展と理解の深化が必要である．<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<p>本章「ベイズ機械学習のすすめ」は，ベイズの手法の特に肝心と思われる３つの側面を指摘して終わる．以下３章を通じて，</p>
<ol type="1">
<li><p>第 <a href="#sec-uncertainty-quantification" class="quarto-xref">2</a> 節 <u><strong>ベイズは不確実性を定量化する</strong></u></p>
<p>Bayes の方が不確実性の定量化が得意であるため，そのような応用先では Bayes のバージョンを用いることが出来ると便利である．</p></li>
<li><p>第 <a href="#sec-distributional-representation" class="quarto-xref">3</a> 節 <u><strong>ベイズは分布という共通言語を与える</strong></u></p>
<p>Bayes による統一的な扱いが理論的に有用である場面が増えている．その際に，Bayes による理論解析と最適化による実際の推論という適材適所の協業が未来の方向であるかも知れない．</p></li>
<li><p>第 <a href="#sec-inductive-bias" class="quarto-xref">4</a> 節 <u><strong>ベイズは理解を促進する</strong></u></p>
<p>機械学習の真の理解のためには，各モデルの帰納バイアスを明確化する必要がある．ベイズの手法が敬遠されていた理由も，換言すれば，「事前分布」という得体の知れないものを通じて，理論的深淵と直結するためである．ベイズ手法の研究が理論的な解明を要請するからこそ，数学者の魂を持った者がこの途を通ることは人類に大きく資すると筆者は考える．</p></li>
</ol>
</section>
</section>
<section id="sec-uncertainty-quantification" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="sec-uncertainty-quantification"><span class="header-section-number">2</span> ベイズは不確実性を定量化する</h2>
<section id="不確実性の定量化の必要性" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="不確実性の定量化の必要性"><span class="header-section-number">2.1</span> 不確実性の定量化の必要性</h3>
<p>機械学習と統計学が単なる道具ではなく，人間のより大きなシステムの一環を単独で担う場面が増えてきた．例えば，</p>
<ul>
<li>金融・経営・政策決定などの分野で，意思決定に繋げるデータ解析をするとき</li>
<li>科学において，発見や仮説を検証するためのデータ解析をするとき</li>
<li>ロボットや自動車などの自動化をし，社会に実装するとき</li>
<li>医療診断や裁判などの場面で，専門家を補助するシステムを作るとき</li>
</ul>
<p>これらのいずれの例でも，<u><strong>システムの一部を担うにあたって，不確実性を定量化しておくことが欠かせない</strong></u>．その出力を用いるのが人間である場合も勿論，別の機械学習モデルである場合は尚更である．</p>
<p>つまり，人間社会で優秀であるだけでなくホウレンソウと信頼獲得も重要であるように，機械学習モデルも性能の高さと正確さだけでなく，いつその結果を信頼して良いのかを「どの程度」という指標と共に知らせてくれることが信頼関係の基本となるだろう．</p>
<p>実際，殆どの場面で，データから高い確証度で言えることと，そうではないことでは全く違う意味を持つ．それぞれの場面での例には，次のようなものがあるだろう：</p>
<ul>
<li>データから高い確証度で言えることと，意思決定者による采配が必要な部分を分離できない限り，意思決定プロセスの一部として組み込むことが難しく，結局機械学習手法が全く採用されないということもあり得る．</li>
<li>結果の再現可能性が科学の基本的な要請である以上，その結果の不確実性を実験結果に付記することは基本的な科学的態度である．後述（第 <a href="#sec-replication-crisis" class="quarto-xref">2.3.1</a> 節）するが，<span class="math inline">\(p\)</span>-値や信頼区間などの統計量は<u><strong>これに応えるものではない</strong></u>．</li>
<li>ロボットや自動車の自動化 AI システムは，いくつかのモデルを組み合わせて作ることになるだろう．個々が十分な性能を持っていても，小さな誤差が累積してシステムとしての性能を著しく低下させることがある．これを防ぐために，統一した方法での不確実性の取り扱いが必要である．</li>
<li>個々人の権利と法益が衝突する場面にも AI が利用されより良い生活が実現されるには，法的な解釈可能性が担保される必要があることが，実は大きな難関として我々を待っている．その第一歩は，不確実性の可視化になるだろう．<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></li>
</ul>
<p>以上の内容は，結果の <strong>解釈可能性</strong> でも全く同じことが言えるだろう．</p>
</section>
<section id="信頼のおける-ai-システム" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="信頼のおける-ai-システム"><span class="header-section-number">2.2</span> 信頼のおける AI システム</h3>
<p>上述の点をまとめると，機械学習手法と人間社会がよりよく共生していくには AI の <strong>信頼性</strong> (trustworthyness) が必要とされているのである．不確実性の定量化と解釈可能性は，AI が人間社会で信頼を獲得するにあたって根本的な要素になるだろう．</p>
<p>現状の手法の延長でこの信頼性の問題は扱えず，新たな手法が必要とされている．Bayesian approach や probabilistic approach と呼ばれている試みは，まさにこれに応えるものであり，近年急速に発展している．</p>
</section>
<section id="不確実性を扱うには-bayes-が必要である" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="不確実性を扱うには-bayes-が必要である"><span class="header-section-number">2.3</span> 不確実性を扱うには Bayes が必要である</h3>
<p>（後述のように本質的には密接な関連があれど），たしかに Bayes の方法は従来の方法と大きく異なる．だからと言って慣習的に Bayes の方法を用いないで居ると，コミュニティの混乱をもたらす恐れがある場面も多い．</p>
<p>これを，科学における再現性の危機を例にとって確認したい．<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<section id="sec-replication-crisis" class="level4" data-number="2.3.1">
<h4 data-number="2.3.1" class="anchored" data-anchor-id="sec-replication-crisis"><span class="header-section-number">2.3.1</span> 再現性の危機</h4>
<p>多くの実験科学では不確実性の定量化が必要不可欠である <span class="citation" data-cites="Krzywinski-Altman2013">(<a href="#ref-Krzywinski-Altman2013" role="doc-biblioref">Krzywinski &amp; Altman, 2013</a>)</span>．</p>
<blockquote class="blockquote">
<p>It is necessary and true that all of the things we say in science, all of the conclusions, are uncertain … <span class="citation" data-cites="Feynman1998">(<a href="#ref-Feynman1998" role="doc-biblioref">Feynman, 1998</a>)</span></p>
</blockquote>
<p><a href="https://ja.wikipedia.org/wiki/%E5%86%8D%E7%8F%BE%E6%80%A7%E3%81%AE%E5%8D%B1%E6%A9%9F"><strong>再現性の危機</strong></a> (replication crisis) とは，多くの実験において報告されている統計的優位性が，再現実験において得られないことが多いという問題を指し，2010年代の初めから多くの科学分野において問題として取り上げられてきた．<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<p>その結果多くの科学分野では <strong>Bayes 統計学による不確実性の定量化に移行しつつある</strong> <span class="citation" data-cites="Herzog-Ostwald2013">(<a href="#ref-Herzog-Ostwald2013" role="doc-biblioref">Herzog &amp; Ostwald, 2013</a>)</span>, <span class="citation" data-cites="Trafimow-Marks2015">(<a href="#ref-Trafimow-Marks2015" role="doc-biblioref">Trafimow &amp; Marks, 2015</a>)</span>, <span class="citation" data-cites="Nuzzo2014">(<a href="#ref-Nuzzo2014" role="doc-biblioref">Nuzzo, 2014</a>)</span>．特に，信頼区間と信用区間の違いにおいてその本質が顕著に表れている．</p>
</section>
<section id="信頼区間と信用区間" class="level4" data-number="2.3.2">
<h4 data-number="2.3.2" class="anchored" data-anchor-id="信頼区間と信用区間"><span class="header-section-number">2.3.2</span> 信頼区間と信用区間</h4>
<p>「95 % の信頼区間」と言ったとき，「95 % の確率で真の値がその範囲に含まれるような区間」だと思いがちであるが，これはどちらかというと信用区間の説明であり，<strong>信頼区間は計算するごとに値が変わってしまう確率変数である</strong> ことを見落としがちである．<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<p>つまり，信頼区間は頻度論的な概念であり，「真の値」がまず存在し，区間自体が変動し，95 % の確率で被覆するというのである．今回見ている信頼区間が，別のデータセットで計算した場合にどう変わるかについては全く未知である．</p>
<p>このことは，信頼区間は「真のパラメータの値」で条件づけて得るものであるが，信用区間はデータによって条件づけて得るものであるという点で違う，とまとめられる．この２つの混同は「何で条件づけているか？」を意識することで回避することができる．<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a></p>
<p>誤解を恐れず言うならば，再現性の危機とは，信頼区間というサイコロの出目によって科学が踊らされていたということに他ならない <span class="citation" data-cites="Nuzzo2014">(<a href="#ref-Nuzzo2014" role="doc-biblioref">Nuzzo, 2014</a>)</span>．<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a></p>
</section>
</section>
<section id="ベイズ深層学習という夢" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="ベイズ深層学習という夢"><span class="header-section-number">2.4</span> ベイズ深層学習という夢</h3>
<p>深層学習モデルはパラメータが極めて多いため，特にベイズ化することが難しいと言われている．</p>
<p>同時に，ハルシネーション (hallucination) として，LLM が「事実に基づかない」情報を生成してしまうことが問題とされているが，これも不確実性の定量化の問題に他ならない．<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a></p>
<p>その他の場面でも，不確実性の定量化には conformal prediction などの事後的な手法が試みられているが，<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> ベイズ推論により学習しておけばこれらのステップは全く不要なのである．</p>
</section>
<section id="分野全体の動向" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="分野全体の動向"><span class="header-section-number">2.5</span> 分野全体の動向</h3>
<p>現状の機械学習モデルと実応用との乖離は，他の側面でも生じている．</p>
<p>まず，訓練データが実際の運用環境を十分に反映できていないということは極めて頻繁に起こるだろう．この現象を <strong>分布シフト</strong> といい，機械学種モデルの予測性能だけで無く，分布外汎化 (out-of-distribution generalization) 能力も重視するという潮流が生じている．</p>
<p>さらに，一度訓練したモデルを，分布シフト自体が移り変わっていく環境で，微調整のみによって繰り返し使い続けるという使用を想定した <strong>継続学習</strong> (continual learning) という考え方もある．<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a></p>
<p>章を変えて別の角度から議論を続けよう．</p>
</section>
</section>
<section id="sec-distributional-representation" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="sec-distributional-representation"><span class="header-section-number">3</span> ベイズは分布という共通言語を与える</h2>
<section id="継続学習という発想" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="継続学習という発想"><span class="header-section-number">3.1</span> 継続学習という発想</h3>
<p>継続学習は，機械学習モデルをより動的で実際的な環境でも使えるようにするための新たな枠組みである．そこまで，教師あり学習モデルがすでに実用的な性能を獲得したということでもある．</p>
<p>つまり，単に「教師あり」「教師なし」の１タスクを解く営みは爛熟しつつあり，機械学習の理論と応用の最先端は，より深い森に分け入りつつあるのである．</p>
<p>ここにおいて，ベイズ流の接近が統一的な取り扱いを与えるという美点が，さらに重要でもはや必要不可欠な役割を果たすものと思われる．</p>
<section id="ベイズ推論が与える統一的枠組み" class="level4" data-number="3.1.1">
<h4 data-number="3.1.1" class="anchored" data-anchor-id="ベイズ推論が与える統一的枠組み"><span class="header-section-number">3.1.1</span> ベイズ推論が与える統一的枠組み</h4>
<p>ベイズ推論とは，<strong>事前分布</strong> というものを設定して，これをデータによって更新するという営みである（その更新規則は Bayes の公式が与える）．</p>
<p>事前分布をどう設定すれば良いか？の問題は，ベイズ推論の初期からの問題であった．極めて自由度が高いことが，逆にベイズ推論が実際のデータ解析の場面において敬遠される一因ともなっていた．</p>
</section>
<section id="ベイズと最適化との協業" class="level4" data-number="3.1.2">
<h4 data-number="3.1.2" class="anchored" data-anchor-id="ベイズと最適化との協業"><span class="header-section-number">3.1.2</span> ベイズと最適化との協業</h4>
<p>しかし，継続学習が当たり前になった社会において，全てのパラメータ値を事前分布と事後分布とみなし，全ての学習過程をベイズの公式という統一的な方法で更新すると捉えられることは，極めて大きな利点になり得る．</p>
<p>というのも，継続学習においては，学習を繰り返すうちに過去に学んだ内容を忘れ去ってしまうという <strong>壊滅的忘却</strong> (catastrophically forgetting) が最大の困難である．</p>
<p>理論的には，分布のベイズ更新の繰り返しとして見る方が極めて見通しが良い．一方で，事後分布の近似が十分でない場合，実際にベイズ更新を行うことは性能に悪影響を与える．</p>
<p>そこで，理論解析や設計をベイズの観点から行い，実際の推論は最適化ベースで行うという適材適所により，壊滅的忘却を緩和できる可能性がある <span class="citation" data-cites="Farquhar-Gal2019">(<a href="#ref-Farquhar-Gal2019" role="doc-biblioref">Farquhar &amp; Gal, 2019</a>)</span>．</p>
</section>
</section>
<section id="モデルの属人化" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="モデルの属人化"><span class="header-section-number">3.2</span> モデルの属人化</h3>
<p>大きなデータも，属人化医療や推薦システムなど多くの文脈では小さなデータの寄せ集めであり，そうでなくともその構造を正しく捉え，全ての不確実性を取り入れた柔軟なモデリングをすることで，さらに密接な形で社会に取り入れることができる．<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a></p>
<blockquote class="blockquote">
<p>Although considerable challenges remain, the c ing decade promises substantial advances in artificial intelligence and machine learning based on the probabilistic framework. <span class="citation" data-cites="Ghahramani2015">(<a href="#ref-Ghahramani2015" role="doc-biblioref">Ghahramani, 2015</a>)</span></p>
</blockquote>
</section>
<section id="例強化学習への分布によるアプローチ" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="例強化学習への分布によるアプローチ"><span class="header-section-number">3.3</span> 例：強化学習への分布によるアプローチ</h3>
<blockquote class="blockquote">
<p>we believe the value distribution has a central role to play in reinforcement learning. <span class="citation" data-cites="Bellemare+2017">(<a href="#ref-Bellemare+2017" role="doc-biblioref">Bellemare et al., 2017</a>)</span></p>
</blockquote>
</section>
</section>
<section id="sec-inductive-bias" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="sec-inductive-bias"><span class="header-section-number">4</span> ベイズは理解を促進する</h2>
<p>我々はもはや機械学習を通じて，自分たちが何をやっているのかわかっていない．この愚かさを AI に継がせてはならない．</p>
<p>ベイズ法の採用は，自分たちが何をやっているかへの理解と解釈可能性を，刺激するという側面がある．</p>
<p>これはベイズの美点であると同時に，ベイズの発展を阻害してきた困難の一つである．</p>
<section id="帰納バイアスの明確化の必要性" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="帰納バイアスの明確化の必要性"><span class="header-section-number">4.1</span> 帰納バイアスの明確化の必要性</h3>
<p>現状の AI システムは大量のラベル付きデータが必要であり，多くの現実的に有用なタスクでこのような教師データが用意できるわけではない．</p>
<p>一方で，人間は遥かに少ないデータから効率的に学習することができる．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../Kernels/Images/model_sizes.png" class="img-fluid figure-img"></p>
<figcaption>Number of Training Tokens <a href="https://babylm.github.io/">BabyLM Challenge</a></figcaption>
</figure>
</div>
<p>その違いは，進化が我々生物に授けた <strong>帰納バイアス</strong> にある．</p>
<p>現状，機械学習は確率的な方法を取っていない．つまり，事前分布を明示せずに行われる Bayes 学習の理論によって現状の機械学習の成功が支えられているのであり，現状のままではモデルにどのような帰納バイアスが組み込まれているか不明瞭である．<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a></p>
</section>
<section id="数学者の哲学" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="数学者の哲学"><span class="header-section-number">4.2</span> 数学者の哲学</h3>
<p>Bayes の見方は，機械学習を底流する数理的枠組みになっている．仮に次の MacLane の言葉が数学者のあるべき態度の１つであるとするならば，数学者には Bayes 機械学習が特におすすめできる．</p>
<blockquote class="blockquote">
<p>However, I persisted in the position that <strong>as mathematicians we must know whereof we speak</strong>, be it a homotopy group or an adjoint functor. <span class="citation" data-cites="MacLane1983">(<a href="#ref-MacLane1983" role="doc-biblioref">Mac&nbsp;Lane, 1983, p. 55</a>)</span></p>
</blockquote>
<p>任意のモデル <span class="math inline">\(\mathcal{M}\)</span> の周辺尤度 <span class="math inline">\(p(x|\mathcal{M})\)</span> （<strong>証拠</strong> (model evidence) ともいう）は，全てのデータの空間 <span class="math inline">\(x\in\mathcal{X}\)</span> 上に有限な測度を定めるはずである．</p>
<p>よって，<strong>全てのモデルは，あるデータを得意とするならば他のデータについては不得意であることを免れない</strong>．これは no free lunch 定理と呼ばれる定理の一群により推測されており，分類問題などの簡単なタスクを除いて完全な形式的表現は持たない知識である．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Images/mackay.png" class="img-fluid figure-img"></p>
<figcaption>A Probabilistic Perspective of Genelization <span class="citation" data-cites="Wilson-Izmailov2020">(<a href="#ref-Wilson-Izmailov2020" role="doc-biblioref">Wilson &amp; Izmailov, 2020</a>)</span></figcaption>
</figure>
</div>
<p>例えば，<a href="../../../posts/2024/Kernels/Deep2.html#sec-fine-tuning">基盤モデル</a> とは，インターネット上のデータから最大限人間の言語というものに関する帰納バイアスを取り込んだ，パラメータ上の初期設定である．</p>
<p>これは，あるパラメータ空間上の理想的な事前分布からのサンプリングであるかも知れない．それ故，種々の下流タスクに対して，小さなモデル変更のみにより適応することが出来る．</p>
<p>大規模言語モデルの能力創発現象は，帰納バイアスを十分取り込むことにより自然に解かれるタスクであったのかもしれない．</p>
</section>
<section id="例強化学習への確率的アプローチ" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="例強化学習への確率的アプローチ"><span class="header-section-number">4.3</span> 例：強化学習への確率的アプローチ</h3>
<blockquote class="blockquote">
<p>Crucially, in the framework of PGMs, it is sufficient to write down the model and pose the question, and the objectives for learning and inference emerge automatically. <span class="citation" data-cites="Levine2018">(<a href="#ref-Levine2018" role="doc-biblioref">Levine, 2018</a>)</span></p>
</blockquote>
</section>
</section>
<section id="bayes-機械学習の例" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="bayes-機械学習の例"><span class="header-section-number">5</span> Bayes 機械学習の例</h2>
<section id="bayes-深層学習" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="bayes-深層学習"><span class="header-section-number">5.1</span> Bayes 深層学習</h3>
</section>
<section id="確率的グラフィカルモデル" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="確率的グラフィカルモデル"><span class="header-section-number">5.2</span> 確率的グラフィカルモデル</h3>
<p>歴史的に，（確率的）モデリングは，主に（確率的）グラフィカルモデルを通じて機械学習の分野に導入された．</p>
<p>そのため，20世紀に入ったばかりの頃は，Bayes 機械学習の唯一の例は確率的グラフィカルモデルなのであった．<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a></p>
</section>
<section id="推論アルゴリズムのプログラミングからモデルのプログラミングへ" class="level3" data-number="5.3">
<h3 data-number="5.3" class="anchored" data-anchor-id="推論アルゴリズムのプログラミングからモデルのプログラミングへ"><span class="header-section-number">5.3</span> 推論アルゴリズムのプログラミングから，モデルのプログラミングへ</h3>
<p>シミュレーターがあれば推論ができるというのが Bayes 計算の強みである．</p>
<p>そこで，推論手法をこれで統一し，解析者はモデルの構築に集中すれば良い，という新たなパラダイムを <strong>確率的プログラミング</strong> (Probabilistic Programming) と呼ぶ．</p>
</section>
<section id="bayes-最適化" class="level3" data-number="5.4">
<h3 data-number="5.4" class="anchored" data-anchor-id="bayes-最適化"><span class="header-section-number">5.4</span> Bayes 最適化</h3>
</section>
<section id="データ圧縮" class="level3" data-number="5.5">
<h3 data-number="5.5" class="anchored" data-anchor-id="データ圧縮"><span class="header-section-number">5.5</span> データ圧縮</h3>
</section>
<section id="階層モデルと統計モデルの自動発見" class="level3" data-number="5.6">




</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">5.6 階層モデルと統計モデルの自動発見</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-Amershi+2019" class="csl-entry" role="listitem">
Amershi, S., Weld, D., Vorvoreanu, M., Fourney, A., Nushi, B., Collisson, P., Suh, J., Iqbal, S., Bennett, P. N., Inkpen, K., Teevan, J., Kikin-Gil, R., &amp; Horvitz, E. (2019). Guidelines for human-AI interaction. <em>Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems</em>, 1–13. <a href="https://doi.org/10.1145/3290605.3300233">https://doi.org/10.1145/3290605.3300233</a>
</div>
<div id="ref-Angrist-Pischke2010" class="csl-entry" role="listitem">
Angrist, J. D., &amp; Pischke, J.-S. (2010). The credibility revolution in empirical economics: How better research design is taking the con out of econometrics. <em>The Journal of Economic Perspectives</em>, <em>24</em>(2), 3–30. <a href="http://www.jstor.org/stable/25703496">http://www.jstor.org/stable/25703496</a>
</div>
<div id="ref-Bensal+2019" class="csl-entry" role="listitem">
Bansal, G., Nushi, B., Kamar, E., Weld, D. S., Lasecki, W. S., &amp; Horvitz, E. (2019). Updates in human-AI teams: Understanding and addressing the performance/compatibility tradeoff. <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, <em>33</em>(01), 2429–2437. <a href="https://doi.org/10.1609/aaai.v33i01.33012429">https://doi.org/10.1609/aaai.v33i01.33012429</a>
</div>
<div id="ref-Bellemare+2017" class="csl-entry" role="listitem">
Bellemare, M. G., Dabney, W., &amp; Munos, R. (2017). A distributional perspective on reinforcement learning. In D. Precup &amp; Y. W. Teh (Eds.), <em>Proceedings of the 34th international conference on machine learning</em> (Vol. 70, pp. 449–458). PMLR. <a href="https://proceedings.mlr.press/v70/bellemare17a.html">https://proceedings.mlr.press/v70/bellemare17a.html</a>
</div>
<div id="ref-Broderick+2023" class="csl-entry" role="listitem">
Broderick, T., Gelman, A., Meager, R., Smith, A. L., &amp; Zheng, T. (2023). Toward a taxonomy of trust for probabilistic machine learning. <em>Science Advances</em>, <em>9</em>(7), eabn3999. <a href="https://doi.org/10.1126/sciadv.abn3999">https://doi.org/10.1126/sciadv.abn3999</a>
</div>
<div id="ref-Farquhar-Gal2019" class="csl-entry" role="listitem">
Farquhar, S., &amp; Gal, Y. (2019). <em>A unifying bayesian view of continual learning</em>. <a href="https://arxiv.org/abs/1902.06494">https://arxiv.org/abs/1902.06494</a>
</div>
<div id="ref-Feynman1998" class="csl-entry" role="listitem">
Feynman, R. P. (1998). <em><a href="">The meaning of it all: Thoughts of a citizen scientist</a></em>. Addison-Wesley.
</div>
<div id="ref-Gal-Ghahramani2016" class="csl-entry" role="listitem">
Gal, Y., &amp; Ghahramani, Z. (2016). Dropout as a bayesian approximation: Representing model uncertainty in deep learning. In M. F. Balcan &amp; K. Q. Weinberger (Eds.), <em>Proceedings of the 33rd international conference on machine learning</em> (Vol. 48, pp. 1050–1059). PMLR. <a href="https://proceedings.mlr.press/v48/gal16.html">https://proceedings.mlr.press/v48/gal16.html</a>
</div>
<div id="ref-Ghahramani2015" class="csl-entry" role="listitem">
Ghahramani, Z. (2015). Probabilistic machine learning and artificial intelligence. <em>Nature</em>, <em>521</em>, 452–459. <a href="https://www.nature.com/articles/nature14541">https://www.nature.com/articles/nature14541</a>
</div>
<div id="ref-Herzog-Ostwald2013" class="csl-entry" role="listitem">
Herzog, S., &amp; Ostwald, D. (2013). Sometimes bayesian statistics are better. <em>Nature</em>, <em>494</em>(7435), 35–35. <a href="https://doi.org/10.1038/494035b">https://doi.org/10.1038/494035b</a>
</div>
<div id="ref-Krzywinski-Altman2013" class="csl-entry" role="listitem">
Krzywinski, M., &amp; Altman, N. (2013). Importance of being uncertain. <em>Nature Methods</em>, <em>10</em>(9), 809–810. <a href="https://doi.org/10.1038/nmeth.2613">https://doi.org/10.1038/nmeth.2613</a>
</div>
<div id="ref-Levine2018" class="csl-entry" role="listitem">
Levine, S. (2018). <em>Reinforcement learning and control as probabilistic inference: Tutorial and review</em>. <a href="https://arxiv.org/abs/1805.00909">https://arxiv.org/abs/1805.00909</a>
</div>
<div id="ref-MacLane1983" class="csl-entry" role="listitem">
Mac&nbsp;Lane, S. (1983). The health of mathematics. <em>The Mathematical Intelligencer</em>, <em>5</em>(4), 53–56. <a href="https://doi.org/10.1007/BF03026510">https://doi.org/10.1007/BF03026510</a>
</div>
<div id="ref-Mohri-Hashimoto2024" class="csl-entry" role="listitem">
Mohri, C., &amp; Hashimoto, T. (2024). <em>Language models with conformal factuality guarantees</em>. <a href="https://arxiv.org/abs/2402.10978">https://arxiv.org/abs/2402.10978</a>
</div>
<div id="ref-Neal-Hinton1998" class="csl-entry" role="listitem">
Neal, R. M., &amp; Hinton, G. E. (1998). <em>Learning in graphical models</em> (M. I. Jordan, Ed.; pp. 355–368). Springer Dordrecht. <a href="https://link.springer.com/chapter/10.1007/978-94-011-5014-9_12">https://link.springer.com/chapter/10.1007/978-94-011-5014-9_12</a>
</div>
<div id="ref-Novello+2024" class="csl-entry" role="listitem">
Novello, P., Dalmau, J., &amp; Andeol, L. (2024). <em>Out-of-distribution detection should use conformal prediction (and vice-versa?)</em>. <a href="https://arxiv.org/abs/2403.11532">https://arxiv.org/abs/2403.11532</a>
</div>
<div id="ref-Nuzzo2014" class="csl-entry" role="listitem">
Nuzzo, R. (2014). Scientific method: Statistical errors. <em>Nature</em>, <em>506</em>(7487), 150–152. <a href="https://doi.org/10.1038/506150a">https://doi.org/10.1038/506150a</a>
</div>
<div id="ref-Trafimow-Marks2015" class="csl-entry" role="listitem">
Trafimow, D., &amp; Marks, M. (2015). Editorial. <em>Basic and Applied Social Psychology</em>, <em>37</em>(1), 1–2. <a href="https://doi.org/10.1080/01973533.2015.1012991">https://doi.org/10.1080/01973533.2015.1012991</a>
</div>
<div id="ref-Wamg+2024" class="csl-entry" role="listitem">
Wang, L., Zhang, X., Su, H., &amp; Zhu, J. (2024). A comprehensive survey of continual learning: Theory, method and application. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 1–20. <a href="https://doi.org/10.1109/TPAMI.2024.3367329">https://doi.org/10.1109/TPAMI.2024.3367329</a>
</div>
<div id="ref-Wilson-Izmailov2020" class="csl-entry" role="listitem">
Wilson, A. G., &amp; Izmailov, P. (2020). Bayesian deep learning and a probabilistic perspective of generalization. <em>Proceedings of the 34th International Conference on Neural Information Processing Systems</em>. <a href="https://proceedings.neurips.cc/paper/2020/hash/322f62469c5e3c7dc3e58f5a4d1ea399-Abstract.html">https://proceedings.neurips.cc/paper/2020/hash/322f62469c5e3c7dc3e58f5a4d1ea399-Abstract.html</a>
</div>
<div id="ref-平石-中村2022" class="csl-entry" role="listitem">
平石界, &amp; 中村大輝. (2022). 心理学における再現性危機の10年―危機は克服されたのか，克服され得るのか―. <em>科学哲学</em>, <em>54</em>(2), 27–50. <a href="https://www.jstage.jst.go.jp/article/jpssj/54/2/54_27/_article/-char/ja">https://www.jstage.jst.go.jp/article/jpssj/54/2/54_27/_article/-char/ja</a>
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>これは <a href="https://www.microsoft.com/en-us/research/project/guidelines-for-human-ai-interaction/">Human-AI interaction におけるガイドライン</a> <span class="citation" data-cites="Amershi+2019">(<a href="#ref-Amershi+2019" role="doc-biblioref">Amershi et al., 2019</a>)</span>, <span class="citation" data-cites="Bensal+2019">(<a href="#ref-Bensal+2019" role="doc-biblioref">Bansal et al., 2019</a>)</span> でも明確にされている点である．この方向への試みの代表がベイズ機械学習，というわけではないが，筆者はベイズ機械学習の興隆は信頼のおける AI システムの構築にための極めて盤石な土台になるだろうと論じる．<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><span class="citation" data-cites="Broderick+2023">(<a href="#ref-Broderick+2023" role="doc-biblioref">Broderick et al., 2023</a>)</span> など．<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>多くの頻度論的な統計手法が最適化に拠る一方で，Bayes 統計・Bayes 学習は専ら積分法に拠る．このように，その用いる手法も鮮やかに対照的に見えるが，積分は変分近似を通じて最適化問題としても解けるし，Lengevin 法や HMC などの最適化手法は積分問題を解ける．<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>合理的な信念の度合い (degree of belief) は確率の公理を満たす必要がある，という主張は <a href="https://en.wikipedia.org/wiki/Cox%27s_theorem">Cox の名前でも呼ばれる</a>．この点から，Bayes の定理は，帰納的推論の確率論的な拡張だとも捉えられる．<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>計算の困難さ，古典的には事前分布の設定が恣意的であること，現代的には MCMC のパラメータチューニングが難しい点などが，ユーザーフレンドリーではないこと，などが理由としてよく挙げられる．<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>現状，日本にてベイズ機械学習を専業として研究を進めている人は <a href="https://emtiyaz.github.io/">Emtiyaz Khan</a> に限ると思われる．<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>モデルの予測結果に不確実性の定量化が伴われていたならば，モデルを信用出来ない場面で意思決定者がこれを信用したため責任があるのか，使用者には非難可能性がないのか，モデル設計者に過失があったと言えるのかの議論に，足場を与えることが出来るだろう．<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p><span class="citation" data-cites="Gal-Ghahramani2016">(<a href="#ref-Gal-Ghahramani2016" role="doc-biblioref">Gal &amp; Ghahramani, 2016</a>)</span> も参照．<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>心理学においては「再現性問題が大きく注目される大きな契機となった「超能力論文」が出版されたのが 2011 年である」 <span class="citation" data-cites="平石-中村2022">(<a href="#ref-平石-中村2022" role="doc-biblioref">平石界 &amp; 中村大輝, 2022</a>)</span> ようである．計量経済学における <strong>信頼性革命</strong> <span class="citation" data-cites="Angrist-Pischke2010">(<a href="#ref-Angrist-Pischke2010" role="doc-biblioref">Angrist &amp; Pischke, 2010</a>)</span> は，再現性の危機の，もう一つの革新的な解決法である．<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>「それでは，信頼区間は不確実性の正しい定量化を与えないではないか！」ということになるが，その通りなのである．<span class="math inline">\(P\)</span>-値を計算する過程とは，帰無仮説で条件付けているだけであり，データの関数でもある．<span class="math inline">\(P\)</span>-値の確率変数としての分散が大きいほど，何回か同じ実験を繰り返せばすぐに小さな <span class="math inline">\(P\)</span>-値が得られることになる．これは <a href="../../../posts/2023/数理法務/法律家のための統計数理2.html#sec-Bayes-problem"><strong>基準確率の誤謬</strong></a> と似ている．<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>“Confidence intervals suffer from an inverse inference problem that is not very different from that suffered by the NHSTP. In the NHSTP, the problem is in traversing the distance from the probability of the finding, given the null hypothesis, to the probability of the null hypothesis, given the finding.” <span class="citation" data-cites="Trafimow-Marks2015">(<a href="#ref-Trafimow-Marks2015" role="doc-biblioref">Trafimow &amp; Marks, 2015</a>)</span><a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p><span class="citation" data-cites="Nuzzo2014">(<a href="#ref-Nuzzo2014" role="doc-biblioref">Nuzzo, 2014</a>)</span> には，Fisher が最初に用いてから，Neyman-Pearson 理論がこれを排除したものの，コミュニティが <span class="math inline">\(P\)</span>-値を誤解して都合の良いように利用するようになるまでに至った歴史が説明されている．<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p><span class="citation" data-cites="Mohri-Hashimoto2024">(<a href="#ref-Mohri-Hashimoto2024" role="doc-biblioref">Mohri &amp; Hashimoto, 2024</a>)</span> なども指摘している．<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p><span class="citation" data-cites="Novello+2024">(<a href="#ref-Novello+2024" role="doc-biblioref">Novello et al., 2024</a>)</span> では out-of-distribution detection, <span class="citation" data-cites="Mohri-Hashimoto2024">(<a href="#ref-Mohri-Hashimoto2024" role="doc-biblioref">Mohri &amp; Hashimoto, 2024</a>)</span> は LLM の hallucination への応用．<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p><span class="citation" data-cites="Wamg+2024">(<a href="#ref-Wamg+2024" role="doc-biblioref">Wang et al., 2024</a>)</span> が最新のサーベイであるようだ．<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p><span class="citation" data-cites="Ghahramani2015">(<a href="#ref-Ghahramani2015" role="doc-biblioref">Ghahramani, 2015, p. 458</a>)</span> はこれを <strong>モデルの属人化</strong> (personalization of models) と呼んでいる．<a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p>Philipp Hennig <a href="https://youtu.be/TTo2kjrAuTo?si=QD_pqMkdLOl52OsR&amp;t=3703"><em>Probabilistic ML - Lecture 1 - Introduction</em></a><a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p><span class="citation" data-cites="Neal-Hinton1998">(<a href="#ref-Neal-Hinton1998" role="doc-biblioref">Neal &amp; Hinton, 1998</a>)</span> など．<a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="quarto-dev/quarto-web" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->




</body></html>