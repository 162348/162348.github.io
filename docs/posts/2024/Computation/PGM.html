<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.552">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="司馬博文">
<meta name="dcterms.date" content="2023-12-20">

<title>Hirofumi Shiba - 数学者のための確率的グラフィカルモデル１</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../profile.jpg" rel="icon" type="image/jpeg">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-36GX2G6GLL"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-36GX2G6GLL', { 'anonymize_ip': true});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Hirofumi Shiba - 数学者のための確率的グラフィカルモデル１">
<meta property="og:description" content="A Blog by a Bayesian Computation Researcher">
<meta property="og:image" content="https://162348.github.io/posts/2024/Computation/PGM.png">
<meta property="og:site_name" content="Hirofumi Shiba">
<meta property="og:image:height" content="134">
<meta property="og:image:width" content="393">
<meta name="twitter:title" content="Hirofumi Shiba - 数学者のための確率的グラフィカルモデル１">
<meta name="twitter:description" content="数学者のために，PGM (Probabilistic Graphical Modelling) で用いられる代表的なモデル３つ（ベイジアンネットワーク，マルコフネットワーク，ファクターグラフ）を定義し，その性質を抽象的に説明する．これらは，複雑な高次元分布の分解を，計算機に理解可能な形で与える，計算幾科学的技術であるとみなせる．">
<meta name="twitter:image" content="https://162348.github.io/posts/2024/Computation/PGM.png">
<meta name="twitter:image-height" content="134">
<meta name="twitter:image-width" content="393">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Hirofumi Shiba</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Sessions.html"> 
<span class="menu-text">Sessions</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Slides.html"> 
<span class="menu-text">Slides</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Japanese.html"> 
<span class="menu-text">自己紹介</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">数学者のための確率的グラフィカルモデル１</h1>
            <p class="subtitle lead">ベイジアンネットワーク，マルコフネットワーク，ファクターグラフ</p>
                                <div class="quarto-categories">
                <div class="quarto-category">Bayesian</div>
                <div class="quarto-category">Computation</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>司馬博文 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">12/20/2023</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">1/19/2024</p>
      </div>
    </div>
      
    </div>
    
  <div>
    <div class="abstract">
      <div class="block-title">概要</div>
      数学者のために，PGM (Probabilistic Graphical Modelling) で用いられる代表的なモデル３つ（ベイジアンネットワーク，マルコフネットワーク，ファクターグラフ）を定義し，その性質を抽象的に説明する．これらは，複雑な高次元分布の分解を，計算機に理解可能な形で与える，計算幾科学的技術であるとみなせる．
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#歴史と導入" id="toc-歴史と導入" class="nav-link active" data-scroll-target="#歴史と導入"><span class="header-section-number">1</span> 歴史と導入</a>
  <ul class="collapse">
  <li><a href="#導入" id="toc-導入" class="nav-link" data-scroll-target="#導入"><span class="header-section-number">1.1</span> 導入</a></li>
  <li><a href="#確率的グラフィカルモデルの例" id="toc-確率的グラフィカルモデルの例" class="nav-link" data-scroll-target="#確率的グラフィカルモデルの例"><span class="header-section-number">1.2</span> 確率的グラフィカルモデルの例</a></li>
  <li><a href="#諸科学での知識表現の歴史" id="toc-諸科学での知識表現の歴史" class="nav-link" data-scroll-target="#諸科学での知識表現の歴史"><span class="header-section-number">1.3</span> 諸科学での知識表現の歴史</a></li>
  <li><a href="#sec-probabilistic-methods" id="toc-sec-probabilistic-methods" class="nav-link" data-scroll-target="#sec-probabilistic-methods"><span class="header-section-number">1.4</span> 人工知能分野での確率的モデリングの採用</a></li>
  <li><a href="#bayesian-network-の登場" id="toc-bayesian-network-の登場" class="nav-link" data-scroll-target="#bayesian-network-の登場"><span class="header-section-number">1.5</span> Bayesian Network の登場</a></li>
  <li><a href="#確率的グラフィカルモデリングの美点" id="toc-確率的グラフィカルモデリングの美点" class="nav-link" data-scroll-target="#確率的グラフィカルモデリングの美点"><span class="header-section-number">1.6</span> 確率的グラフィカルモデリングの美点</a></li>
  </ul></li>
  <li><a href="#代表的なグラフィカルモデル" id="toc-代表的なグラフィカルモデル" class="nav-link" data-scroll-target="#代表的なグラフィカルモデル"><span class="header-section-number">2</span> 代表的なグラフィカルモデル</a>
  <ul class="collapse">
  <li><a href="#sec-BN" id="toc-sec-BN" class="nav-link" data-scroll-target="#sec-BN"><span class="header-section-number">2.1</span> Bayesian Network</a></li>
  <li><a href="#sec-d-separation" id="toc-sec-d-separation" class="nav-link" data-scroll-target="#sec-d-separation"><span class="header-section-number">2.2</span> Bayesian Network の分離性</a></li>
  <li><a href="#markov-network" id="toc-markov-network" class="nav-link" data-scroll-target="#markov-network"><span class="header-section-number">2.3</span> Markov Network</a></li>
  <li><a href="#sec-Factor-Graph" id="toc-sec-Factor-Graph" class="nav-link" data-scroll-target="#sec-Factor-Graph"><span class="header-section-number">2.4</span> Factor Graph</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div class="hidden">
$$
<p>%%% 演算子 </p>
%%% 線型代数学
<p>%%% 複素解析学 %%% 集合と位相 </p>
<p>%%% 形式言語理論 %%% Graph Theory </p>
%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学
%%% 函数解析
%%% 積分論
<p>%%% Fourier解析 %%% 数値解析 </p>
%%% 確率論
<p>%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス </p>
<p>%%% 偏微分方程式 %%% 常微分方程式 %%% 統計力学 %%% 解析力学 </p>
%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計
<p>%%% 計量経済学 </p>
%%% 無限次元統計模型の理論
<p>%%% Banach Lattices </p>
<p>%%% 圏 %代数の圏 %Metric space &amp; Contraction maps %確率空間とMarkov核の圏 %Sober space &amp; continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 </p>
%%% SMC
%%% 括弧類
<p>%%% 予約語 </p>
<p>%%% 略記 </p>
<p>%%% 矢印類 $$</p>
</div>
<div class="hidden">
<p><span class="math display">\[
\DeclareMathOperator{\des}{des}
\DeclareMathOperator{\nd}{nd}
\DeclareMathOperator{\dsep}{d-sep}
\DeclareMathOperator{\sep}{sep}
\]</span></p>
</div>
<p><a href="../../../posts/2023/数理法務/法律家のための統計数理3.html">決定木</a>，<a href="../../../posts/2023/Surveys/SSM.html">状態空間モデル</a>，ニューラルネットワーク <span class="citation" data-cites="Rumelhart+1987">(<a href="#ref-Rumelhart+1987" role="doc-biblioref">Rumelhart et al., 1987</a>)</span>，構造方程式モデルはいずれもベイジアンネットワークの例と見れる．<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>（２次元以下の）<a href="../../../posts/2024/Computation/PGM2.html#sec-Ising-model">Ising 模型</a> はマルコフネットワークの例である．</p>
<p>以上は全て，確率的グラフィカルモデルの例である．</p>
<p>ベイジアンネットワークは，<a href="../../../posts/2023/Probability/MarkovCategory.html">Markov 圏</a> 上の図式のうち，特定のグラフ理論的な条件 <a href="#sec-DAG" class="quarto-xref">2.1.2</a> を満たすものと見れる．</p>
<p><span class="citation" data-cites="Wainwright-Jordan2008">(<a href="#ref-Wainwright-Jordan2008" role="doc-biblioref">Wainwright &amp; Jordan, 2008</a>)</span>, <span class="citation" data-cites="Chen2023">(<a href="#ref-Chen2023" role="doc-biblioref">Chen, 2023</a>)</span> も参考になるであろう．</p>
<section id="歴史と導入" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="歴史と導入"><span class="header-section-number">1</span> 歴史と導入</h2>
<section id="導入" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="導入"><span class="header-section-number">1.1</span> 導入</h3>
<p><strong>グラフィカルモデル</strong> とは，多くの変数からなるモデルを，グラフを用いて表現することで，各変数の間の依存性・独立性を明確に表すと同時に，確率モデルを端的に定義する語彙である．<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>この手法が特に肝要になるのが，自立して推論・意思決定を行うシステムの構築においてである．<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> これはこの分野が不確実性を定量的に扱う必要があり，それ故確率的モデリングを必要とするためである．<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<p>知識表現や系のモデリングのために横断的に用いられる手法が <strong>確率的グラフィカルモデリング</strong> である．「確率的」というのは確率論的・統計学的な手法の採用を指す．</p>
<p>世界に対する知識には不確実性がつきものであり，これを反映した表現がより現実に即したモデルを生むことから，近年盛んに研究・応用されている（第 <a href="#sec-probabilistic-methods" class="quarto-xref">1.4</a> 節）．<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<p>人間にとって視覚的にわかりやすいだけでなく，周辺化，極値の計算，条件付き確率の計算を高速化するという点で計算機にとっても極めてわかりやすい表示になる．<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<blockquote class="blockquote">
<p>I have approximate answers and possible beliefs with different degrees of uncertainty about different things, but I am not absolutely sure of anything. – <a href="https://www.youtube.com/watch?v=P-Qdl6Gbx0k">Richard Feynman</a></p>
</blockquote>
</section>
<section id="確率的グラフィカルモデルの例" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="確率的グラフィカルモデルの例"><span class="header-section-number">1.2</span> 確率的グラフィカルモデルの例</h3>
<p>確率的グラフィカルモデリングの例には，次のようなものがある：</p>
<ul>
<li><p>音声認識や天気予報の分野で，対象とは音声言語と地球の大気環境であるが，これらのモデルをグラフで表す際，<a href="../../../posts/2023/Surveys/SSM.html#sec-SSM">状態空間モデル</a> がよく用いられる．</p></li>
<li><p>特に状態空間モデルが，Gauss 確率変数とその間の線型な依存関係のみからなるとき，これを（部分的に観測される）線型力学系 または Kalman filter ともいう．状態空間モデルの潜在変数が離散的であるとき，歴史的には隠れ Markov モデルという名前で用いられてきた．<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p></li>
<li><p>医療診断では，複数の症状や検査結果，医学的指標との関連・相関・因果に関する知識を Bayesian Network （<a href="#sec-BN" class="quarto-xref">節&nbsp;2.1</a>） で表現する．</p></li>
<li><p>因果推論の分野で，<strong>構造的因果モデル</strong> は Bayesian Network で表される <span class="citation" data-cites="Pearl16-Primer">(<a href="#ref-Pearl16-Primer" role="doc-biblioref">Pearl et al., 2016</a>)</span>．この文脈では DAG とも，汎函数因果モデル <span class="citation" data-cites="Scholkopf2022">(<a href="#ref-Scholkopf2022" role="doc-biblioref">Schölkopf, 2022</a>)</span> とも呼ぶ．<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p></li>
</ul>
</section>
<section id="諸科学での知識表現の歴史" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="諸科学での知識表現の歴史"><span class="header-section-number">1.3</span> 諸科学での知識表現の歴史</h3>
<p>多くの科学分野において，知識表現の知識とは，特に因果関係に関する知識のことを指すようである．これを捉えるために，グラフを用いることは自然な発想であり，計算機の登場以前にも，純粋に人間が理解を深めるための用途に，歴史上極めて早い時期から用いられていた．</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="歴史^[[@Koller-Friedman2009 pp.12-14] 1.4節 など．]">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
歴史<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>高次元分布において，成分間の独立性をグラフを用いて表現しようという発想は，その計算機との親和性が見つかる前に，種々の科学分野で試みられていた．</p>
<ul>
<li><span class="citation" data-cites="Gibbs1902">(<a href="#ref-Gibbs1902" role="doc-biblioref">Gibbs, 1902</a>)</span> が統計力学の文脈で，相関粒子系の分布をグラフで表現した．</li>
<li><span class="citation" data-cites="Wright1918">(<a href="#ref-Wright1918" role="doc-biblioref">Wright, 1918</a>)</span> は骨格測定のデータを用いた因子分析で，（遺伝的な意味での）依存関係を，パス図と呼ばれる有向グラフを用いて表した．</li>
<li><span class="citation" data-cites="Wold1954">(<a href="#ref-Wold1954" role="doc-biblioref">H. Wold, 1954</a>)</span> とその教え子との <span class="citation" data-cites="Joreskog-Wold1981">(<a href="#ref-Joreskog-Wold1981" role="doc-biblioref">Jöreskog &amp; Wold, 1982</a>)</span>，さらに <span class="citation" data-cites="Blalock1971">(<a href="#ref-Blalock1971" role="doc-biblioref">Blalock&nbsp;Jr., 1971</a>)</span> が社会学において，因果をグラフを用いて表す因子分析法を <strong>構造方程式モデル</strong> (SEM: Structural Equation Model) の名前の下に普及させた．<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></li>
<li>経済学では特に <strong>操作変数法</strong> として独自の発展を遂げている．</li>
<li>その後 <span class="citation" data-cites="Wold-Strotz60">(<a href="#ref-Wold-Strotz60" role="doc-biblioref">H. O. A. Wold &amp; Strotz, 1960</a>)</span> は <span class="citation" data-cites="Pearl09-Causality">(<a href="#ref-Pearl09-Causality" role="doc-biblioref">Pearl, 2009</a>)</span> などの do-calculus に繋がっている．これはパス解析や構造方程式モデルのノンパラメトリックな拡張とも見れる．<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a></li>
<li>統計学でも <span class="citation" data-cites="Bartlett1935">(<a href="#ref-Bartlett1935" role="doc-biblioref">Bartlett, 1935</a>)</span> が分割表分析において変数同士の相関の研究をしたが，界隈が本格的に受け入れたのはやっと 1960 年代以降である．</li>
</ul>
</div>
</div>
</div>
</section>
<section id="sec-probabilistic-methods" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="sec-probabilistic-methods"><span class="header-section-number">1.4</span> 人工知能分野での確率的モデリングの採用</h3>
<p>人工知能分野が確率的手法を採用したのは，エキスパートシステムの構築が志向された 1960 年代であった．<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a></p>
<p>医療診断や油源探索における専門家に匹敵する判断力を持つアルゴリズムを構築する途上で，不確実性の度合いの定量化が必要となり，naive Bayes model と呼ばれる確率的モデルが採用された．特に <span class="citation" data-cites="Dombal+1972">(<a href="#ref-Dombal+1972" role="doc-biblioref">de&nbsp;Dombal et al., 1972</a>)</span> は限られた分野であるが人間を凌駕する診断正答率を示した．</p>
<p>だがこの確率的アプローチは，主にその計算複雑性から 1970 年代では冬の時代を経験することとなり，エキスパートシステムも production rule framework や <a href="https://ja.wikipedia.org/wiki/%E3%83%95%E3%82%A1%E3%82%B8%E3%82%A3%E8%AB%96%E7%90%86">ファジー論理</a> <span class="citation" data-cites="Zadeh1989">(<a href="#ref-Zadeh1989" role="doc-biblioref">Zadeh, 1989</a>)</span> など，確率論に代わって他のアーキテクチャが試みられるようになっていった．</p>
</section>
<section id="bayesian-network-の登場" class="level3" data-number="1.5">
<h3 data-number="1.5" class="anchored" data-anchor-id="bayesian-network-の登場"><span class="header-section-number">1.5</span> Bayesian Network の登場</h3>
<p>これを打開したのが</p>
<ol type="1">
<li><span class="citation" data-cites="Pearl88-IntelligentSystem">(<a href="#ref-Pearl88-IntelligentSystem" role="doc-biblioref">Pearl, 1988</a>)</span> による Bayesian network framework と，<span class="citation" data-cites="Lauritzen-Spiegelhalter1988">(<a href="#ref-Lauritzen-Spiegelhalter1988" role="doc-biblioref">Lauritzen &amp; Spiegelhalter, 1988</a>)</span> による効率的な推論手法という理論的発展．</li>
<li><span class="citation" data-cites="Heckerman+1992">(<a href="#ref-Heckerman+1992" role="doc-biblioref">Heckerman et al., 1992</a>)</span>, <span class="citation" data-cites="Heckerman-Nathwani1992">(<a href="#ref-Heckerman-Nathwani1992" role="doc-biblioref">Heckerman &amp; Nathwani, 1992</a>)</span> が Bayesian network を病理学標本に応用して大きな成功を挙げたこと．</li>
</ol>
<p>の2つである．これにより，確率的グラフィカルモデル，また一般に確率的アプローチが広く受け入れられるようになった．</p>
</section>
<section id="確率的グラフィカルモデリングの美点" class="level3" data-number="1.6">
<h3 data-number="1.6" class="anchored" data-anchor-id="確率的グラフィカルモデリングの美点"><span class="header-section-number">1.6</span> 確率的グラフィカルモデリングの美点</h3>
<p>確率的グラフィカルモデリングの美点は，人間（エキスパート）と計算機の協業を促進する共通言語としての働きが出来る点である．</p>
<ol type="1">
<li>人間と計算機の双方にとって解釈しやすい <strong>表現</strong> である．</li>
<li>確率的グラフィカルモデルで表現できる分布のクラスと，効率的に Bayes <strong>推論</strong> が可能な分布のクラスとが一致する．<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a></li>
<li>人間と計算機の双方がモデリングに参加できる．後者によるモデリングは，<strong>学習</strong> とも呼ばれることになる．<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a></li>
</ol>
<p>さらに，高次元分布 <span class="math inline">\(P\)</span> の成分間の依存関係を効率よく捉える手法であるため，その背後にあるグラフが判れば，グラフの分離性（ <a href="#sec-d-separation" class="quarto-xref">節&nbsp;2.2</a>, <a href="#sec-separation-in-markov-network" class="quarto-xref">節&nbsp;2.3.5</a> ）を判定するだけで，<span class="math inline">\(P\)</span> の独立性の情報を得ることが出来る．</p>
<p>他にも，グラフの構造を用いて，<span class="math inline">\(P\)</span> を効率的に表現し，本質的な次元を大幅に落として計算を効率化することもできる．</p>
</section>
</section>
<section id="代表的なグラフィカルモデル" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="代表的なグラフィカルモデル"><span class="header-section-number">2</span> 代表的なグラフィカルモデル</h2>
<p>知識のグラフ表現は，有向グラフを用いるか，無向グラフを用いるかによって大きく２つに大別できる．</p>
<section id="sec-BN" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="sec-BN"><span class="header-section-number">2.1</span> Bayesian Network</h3>
<section id="例naive-bayes-model" class="level4" data-number="2.1.1">
<h4 data-number="2.1.1" class="anchored" data-anchor-id="例naive-bayes-model"><span class="header-section-number">2.1.1</span> 例：naive Bayes model</h4>
<p><a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">naive Bayes model</a> は Idiot Bayes model とも呼ばれる Bayesian Network の簡単な例である．</p>
<p>これは <strong>クラス</strong> と呼ばれる離散潜在変数 <span class="math inline">\(C\in\{c^1,\cdots,c^k\}\)</span> を持つ次のようなモデルである．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="naiveBayes.svg" class="img-fluid figure-img"></p>
<figcaption>naive Bayes model</figcaption>
</figure>
</div>
<p>この際，グラフィカルモデルに共通する用語を確認する．</p>
<ul>
<li>クラスの実現値 <span class="math inline">\(c^i\)</span> を <strong>インスタンス</strong> と呼ぶ．</li>
<li>潜在変数の実現値が確定することを，<strong>観測</strong> の他に <strong>インスタンス化</strong> ともいう．</li>
<li>インスタンス化されたときに取る値は <strong>エビデンス</strong> とも呼ばれる．</li>
</ul>
<p>観測値 <span class="math inline">\(X_1,\cdots,X_n\)</span> は <strong>特徴</strong> (features) と呼ばれ，これはクラスを与えた下で互いに条件付き独立であるとする： <span class="math display">\[
(X_i\perp\!\!\!\perp\boldsymbol{X}_{-i}\mid C)\;(i\in[n]),
\]</span> <span class="math display">\[
\boldsymbol{X}_{-i}:=(X_{1:i-1},X_{i+1:n}).
\]</span></p>
<p>こうして得る階層モデルを <strong>naive Bayes model</strong> という．<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a> その結合密度は <span class="math display">\[
p(c,x_1,\cdots,x_n)=p(c)\prod_{i=1}^np(x_i|c)
\]</span> と表せる．</p>
</section>
<section id="sec-DAG" class="level4" data-number="2.1.2">
<h4 data-number="2.1.2" class="anchored" data-anchor-id="sec-DAG"><span class="header-section-number">2.1.2</span> DAG</h4>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 p.57]] （Bayesian Network structure）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定義<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a> （Bayesian Network structure）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>確率変数 <span class="math inline">\(\boldsymbol{X}:=(X_1,\cdots,X_n)\)</span> に関する <strong>Bayesian Network 構造</strong> とは，成分の全体 <span class="math inline">\(\mathcal{X}:=\{X_1,\cdots,X_n\}\)</span> を節集合とした <a href="https://ja.wikipedia.org/wiki/%E6%9C%89%E5%90%91%E9%9D%9E%E5%B7%A1%E5%9B%9E%E3%82%B0%E3%83%A9%E3%83%95"><strong>有向非循環グラフ</strong></a> (directed acyclic graph, DAG) <span class="math inline">\(\mathcal{G}=(\mathcal{X},\mathcal{E})\)</span> をいう．</p>
</div>
</div>
</div>
<p>Bayesian network は belief network とも呼ばれる．<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a> 決定分析で用いられる <a href="https://en.wikipedia.org/wiki/Influence_diagram">influence diagram</a> / decision network はその一般化である．</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="記法（親ノード，子孫ノード，非子孫ノード）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
記法（親ノード，子孫ノード，非子孫ノード）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>グラフ <span class="math inline">\(\mathcal{G}\)</span> において，</p>
<ul>
<li>節 <span class="math inline">\(X_i\)</span> からその親節の全体への対応を添字について表現したものを <span class="math display">\[
\pi:[n]\to P([n])
\]</span> で表す．</li>
<li>節 <span class="math inline">\(X_i\)</span> からその子節の全体への対応を添字について表現したものを <span class="math display">\[
\des:[n]\to P([n])
\]</span> で表す．</li>
<li>次の対応を <strong>非子孫ノード</strong> という： <span class="math display">\[
\nd(i):=[n]\setminus(\{i\}\cup\des(i)).
\]</span></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 p.57]] （Directed Local Markov Independence）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定義<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a> （Directed Local Markov Independence）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Bayesian Network 構造 <span class="math inline">\(\mathcal{G}\)</span> が表現する条件付き独立性 <span class="math display">\[
X_i\perp\!\!\!\perp(X_j)_{j\in\nd(i)}\mid (X_j)_{j\in\pi(i)}
\]</span> を <strong>局所依存性</strong> といい，その（論理式の）全体を <span class="math inline">\(\mathcal{I}_l(\mathcal{G})\)</span> で表す．</p>
</div>
</div>
</div>
<p>Bayesian Network が視覚的表現・記号論で，その表現する所の局所依存性が意味論であると言える．</p>
</section>
<section id="bayesian-network-の特徴付け" class="level4" data-number="2.1.3">
<h4 data-number="2.1.3" class="anchored" data-anchor-id="bayesian-network-の特徴付け"><span class="header-section-number">2.1.3</span> Bayesian Network の特徴付け</h4>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 p.60]] （Independence Assertions）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定義<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a> （Independence Assertions）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> をノードの集合 <span class="math inline">\(\mathcal{X}=\{X_1,\cdots,X_n\}\)</span> 上の確率分布とする．<span class="math inline">\((X_i)_{i=1}^n\sim P\)</span> に関して成立する条件付き独立性の主張 <span class="math display">\[
(X_i)_{i\in I}\perp\!\!\!\perp(X_j)_{j\in J}\mid (X_k)_{k\in K}
\]</span> <span class="math display">\[
I\sqcup J\sqcup K\subset[n]
\]</span> の（論理式の）全体を <strong><span class="math inline">\(P\)</span> が含意する条件付き独立性</strong> といい， <span class="math inline">\(\mathcal{I}(P)\)</span> で表す．</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 p.60]] （$I$-Map）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定義<a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a> （<span class="math inline">\(I\)</span>-Map）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(\mathcal{I}\)</span> を確率変数 <span class="math inline">\((X_1,\cdots,X_n)\)</span> の成分間の条件付き独立性に関する論理式の全体，<span class="math inline">\(\mathcal{K}\)</span> を DAG とする．<span class="math inline">\(\mathcal{K}\)</span> が <span class="math inline">\(\mathcal{I}\)</span> の <strong><span class="math inline">\(I\)</span>-map</strong> であるとは， <span class="math display">\[
\mathcal{I}(\mathcal{K})\subset\mathcal{I}
\]</span> を満たすことをいう．</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 p.62]] （factorize, chain rule, local probabilistic model, Bayesian Network）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定義<a href="#fn21" class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a> （factorize, chain rule, local probabilistic model, Bayesian Network）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(\mathcal{G}\)</span> を確率変数 <span class="math inline">\((X_1,\cdots,X_n)\)</span> に関する Bayesian Network 構造とする．</p>
<ol type="1">
<li>分布 <span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> が <span class="math inline">\(\mathcal{G}\)</span> に従って <strong>分解する</strong> とは，<span class="math inline">\((X_1,\cdots,X_n)\sim P\)</span> と仮定したとき，次が成り立つことをいう： <span class="math display">\[
\mathcal{L}[X_1,\cdots,X_n]=\prod^n_{i=1}\mathcal{L}[X_i|(X_j)_{j\in\pi(i)}].
\]</span></li>
<li>この式を Bayesian Network <span class="math inline">\(\mathcal{G}\)</span> の <strong>連鎖律</strong> といい，右辺の因子 <span class="math inline">\(\mathcal{L}[X_i|(X_j)_{j\in\pi(i)}]\)</span> の全体を 条件付き確率分布族 または <strong>局所モデル</strong> という．</li>
<li>Bayesian Network 構造 <span class="math inline">\(\mathcal{G}\)</span> とこれに沿って分解する分布 <span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> との組 <span class="math inline">\((\mathcal{G},P)\)</span> を，<strong>Bayesian Network</strong> という．</li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題^[[@Koller-Friedman2009 p.62] 定理3.1，定理3.2 p.63．[@Howard-Matheson1984] による．] （Bayesian Network の特徴付け）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題<a href="#fn22" class="footnote-ref" id="fnref22" role="doc-noteref"><sup>22</sup></a> （Bayesian Network の特徴付け）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(\mathcal{G}\)</span> を確率変数 <span class="math inline">\((X_1,\cdots,X_n)\)</span> に関する Bayesian Network 構造，<span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> を確率分布とする．このとき，次は同値：</p>
<ol type="1">
<li><span class="math inline">\(\mathcal{G}\)</span> が <span class="math inline">\(\mathcal{I}(P)\)</span> の <span class="math inline">\(I\)</span>-map である．</li>
<li><span class="math inline">\(P\)</span> は <span class="math inline">\(\mathcal{G}\)</span> に従って分解する．</li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="sec-d-separation" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="sec-d-separation"><span class="header-section-number">2.2</span> Bayesian Network の分離性</h3>
<p>確率的グラフィカルモデルにおいて肝要なのは，<strong>グラフ内に存在する統計的独立性の全てをハイライトする</strong> ことである．するとこれを用いて，分布の効率的な表現と，クエリーへの回答を効率的に行うことが出来る．<a href="#fn23" class="footnote-ref" id="fnref23" role="doc-noteref"><sup>23</sup></a></p>
<section id="節グラフの場合" class="level4" data-number="2.2.1">
<h4 data-number="2.2.1" class="anchored" data-anchor-id="節グラフの場合"><span class="header-section-number">2.2.1</span> ３節グラフの場合</h4>
<p>節が３つ <span class="math inline">\(X,Y,Z\)</span> の場合の DAG は大別して３通り存在する．この場合で「分離性」の概念を説明する．</p>
<p>３つの成分 <span class="math inline">\((X,Y,Z)\)</span> が依存関係にある状態で，<span class="math inline">\(Z\)</span> が観測された（インスタンス化された）とする．</p>
<p>その場合に，<span class="math inline">\(X,Y\)</span> 間の因果関係がどう変化するか？を考える．元々因果関係があったところから，<a href="#fn24" class="footnote-ref" id="fnref24" role="doc-noteref"><sup>24</sup></a> これが解消されるとき，<span class="math inline">\(X,Y\)</span> は <span class="math inline">\(Z\)</span> を介して <strong><span class="math inline">\(d\)</span>-分離</strong> であるという．<a href="#fn25" class="footnote-ref" id="fnref25" role="doc-noteref"><sup>25</sup></a></p>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="逐次結合の場合">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
逐次結合の場合
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>次のような逐次結合の場合，節 <span class="math inline">\(X,Y\)</span> は，節 <span class="math inline">\(Z\)</span> がインスタンス化されたとき <strong><span class="math inline">\(d\)</span>-分離</strong> である，という．</p>
<div class="cell" data-fig-width="1" data-layout-align="default">
<div class="cell-output-display">
<div id="fig-CausalTrail" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-CausalTrail-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<svg width="96" height="480" viewbox="0.00 0.00 62.00 188.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 184)">
<title>CausalTrail</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-184 58,-184 58,4 -4,4"></polygon>
<!-- X -->
<g id="node1" class="node">
<title>X</title>
<ellipse fill="none" stroke="black" cx="27" cy="-162" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="27" y="-157.8" font-family="Times,serif" font-size="14.00">X</text>
</g>
<!-- Z -->
<g id="node2" class="node">
<title>Z</title>
<ellipse fill="none" stroke="black" cx="27" cy="-90" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="27" y="-85.8" font-family="Times,serif" font-size="14.00">Z</text>
</g>
<!-- X&#45;&gt;Z -->
<g id="edge1" class="edge">
<title>X-&gt;Z</title>
<path fill="none" stroke="black" d="M27,-143.7C27,-135.98 27,-126.71 27,-118.11"></path>
<polygon fill="black" stroke="black" points="30.5,-118.1 27,-108.1 23.5,-118.1 30.5,-118.1"></polygon>
</g>
<!-- Y -->
<g id="node3" class="node">
<title>Y</title>
<ellipse fill="none" stroke="black" cx="27" cy="-18" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="27" y="-13.8" font-family="Times,serif" font-size="14.00">Y</text>
</g>
<!-- Z&#45;&gt;Y -->
<g id="edge2" class="edge">
<title>Z-&gt;Y</title>
<path fill="none" stroke="black" d="M27,-71.7C27,-63.98 27,-54.71 27,-46.11"></path>
<polygon fill="black" stroke="black" points="30.5,-46.1 27,-36.1 23.5,-46.1 30.5,-46.1"></polygon>
</g>
</g>
</svg>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-CausalTrail-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
図&nbsp;1: 逐次結合 (Causal Trail)
</figcaption>
</figure>
</div>
</div>
</div>
<p><span class="math inline">\(X\)</span> を勉強量，<span class="math inline">\(Z\)</span> を素点，<span class="math inline">\(Y\)</span> を GPA とするとき，<span class="math inline">\(Z\)</span> が観測されたならば，もはや勉強量は GPA に影響を与えない．ただし，相関は存在するだろうが．</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="分岐結合の場合">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
分岐結合の場合
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>次のような分岐結合の場合，節 <span class="math inline">\(X,Y\)</span> は，節 <span class="math inline">\(Z\)</span> がインスタンス化されたとき <strong><span class="math inline">\(d\)</span>-分離</strong> である，という．</p>
<div class="cell" data-fig-width="3" data-layout-align="default">
<div class="cell-output-display">
<div id="fig-CommonCause" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-CommonCause-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<svg width="288" height="480" viewbox="0.00 0.00 134.00 116.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 112)">
<title>CausalTrail</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-112 130,-112 130,4 -4,4"></polygon>
<!-- Z -->
<g id="node1" class="node">
<title>Z</title>
<ellipse fill="none" stroke="black" cx="63" cy="-90" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="63" y="-85.8" font-family="Times,serif" font-size="14.00">Z</text>
</g>
<!-- X -->
<g id="node2" class="node">
<title>X</title>
<ellipse fill="none" stroke="black" cx="27" cy="-18" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="27" y="-13.8" font-family="Times,serif" font-size="14.00">X</text>
</g>
<!-- Z&#45;&gt;X -->
<g id="edge1" class="edge">
<title>Z-&gt;X</title>
<path fill="none" stroke="black" d="M54.65,-72.76C50.29,-64.28 44.85,-53.71 39.96,-44.2"></path>
<polygon fill="black" stroke="black" points="42.99,-42.44 35.3,-35.15 36.77,-45.64 42.99,-42.44"></polygon>
</g>
<!-- Y -->
<g id="node3" class="node">
<title>Y</title>
<ellipse fill="none" stroke="black" cx="99" cy="-18" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="99" y="-13.8" font-family="Times,serif" font-size="14.00">Y</text>
</g>
<!-- Z&#45;&gt;Y -->
<g id="edge2" class="edge">
<title>Z-&gt;Y</title>
<path fill="none" stroke="black" d="M71.35,-72.76C75.71,-64.28 81.15,-53.71 86.04,-44.2"></path>
<polygon fill="black" stroke="black" points="89.23,-45.64 90.7,-35.15 83.01,-42.44 89.23,-45.64"></polygon>
</g>
</g>
</svg>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-CommonCause-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
図&nbsp;2: 分岐結合 (Common Cause)
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="合流結合の場合">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
合流結合の場合
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>次のような合流結合の場合，節 <span class="math inline">\(X,Y\)</span> は，節 <span class="math inline">\(Z\)</span> またはその子孫節がインスタンス化されなければ，節 <span class="math inline">\(Z\)</span> を介して <strong><span class="math inline">\(d\)</span>-分離</strong> である，という．</p>
<div class="cell" data-fig-width="3" data-layout-align="default">
<div class="cell-output-display">
<div id="fig-CommonEffect" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-CommonEffect-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<svg width="288" height="480" viewbox="0.00 0.00 134.00 116.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 112)">
<title>CausalTrail</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-112 130,-112 130,4 -4,4"></polygon>
<!-- X -->
<g id="node1" class="node">
<title>X</title>
<ellipse fill="none" stroke="black" cx="27" cy="-90" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="27" y="-85.8" font-family="Times,serif" font-size="14.00">X</text>
</g>
<!-- Z -->
<g id="node2" class="node">
<title>Z</title>
<ellipse fill="none" stroke="black" cx="63" cy="-18" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="63" y="-13.8" font-family="Times,serif" font-size="14.00">Z</text>
</g>
<!-- X&#45;&gt;Z -->
<g id="edge1" class="edge">
<title>X-&gt;Z</title>
<path fill="none" stroke="black" d="M35.35,-72.76C39.71,-64.28 45.15,-53.71 50.04,-44.2"></path>
<polygon fill="black" stroke="black" points="53.23,-45.64 54.7,-35.15 47.01,-42.44 53.23,-45.64"></polygon>
</g>
<!-- Y -->
<g id="node3" class="node">
<title>Y</title>
<ellipse fill="none" stroke="black" cx="99" cy="-90" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="99" y="-85.8" font-family="Times,serif" font-size="14.00">Y</text>
</g>
<!-- Y&#45;&gt;Z -->
<g id="edge2" class="edge">
<title>Y-&gt;Z</title>
<path fill="none" stroke="black" d="M90.65,-72.76C86.29,-64.28 80.85,-53.71 75.96,-44.2"></path>
<polygon fill="black" stroke="black" points="78.99,-42.44 71.3,-35.15 72.77,-45.64 78.99,-42.44"></polygon>
</g>
</g>
</svg>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-CommonEffect-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
図&nbsp;3: 合流結合 (Common Effect)
</figcaption>
</figure>
</div>
</div>
</div>
<p>この構造は <span class="math inline">\(v\)</span>-構造ともいう．<a href="#fn26" class="footnote-ref" id="fnref26" role="doc-noteref"><sup>26</sup></a> この場合，<span class="math inline">\(Z\)</span> が観測されたならば，<span class="math inline">\(X,Y\)</span> は因果関係を持つようになる．</p>
<p><span class="math inline">\(Z\)</span> が事象の有無で，<span class="math inline">\(X,Y\)</span> のいずれかが起こった時に <span class="math inline">\(Z\)</span> も起こるとしよう．いま <span class="math inline">\(Z\)</span> が起こったこと <span class="math inline">\(Z=1\)</span> が判明したとすると，<span class="math inline">\(X,Y\)</span> のいずれか一方も起こっている必要がある．従って，<span class="math inline">\(X=0\)</span> は <span class="math inline">\(Y=1\)</span> を要請するという因果関係が生じる．</p>
</div>
</div>
</div>
</section>
<section id="一般の-dag-の場合" class="level4" data-number="2.2.2">
<h4 data-number="2.2.2" class="anchored" data-anchor-id="一般の-dag-の場合"><span class="header-section-number">2.2.2</span> 一般の DAG の場合</h4>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 pp.71-72] 定義3.6, 3.7．] （active, $d$-Separated, Directed Global Markov Independencies）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定義<a href="#fn27" class="footnote-ref" id="fnref27" role="doc-noteref"><sup>27</sup></a> （active, <span class="math inline">\(d\)</span>-Separated, Directed Global Markov Independencies）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(\mathcal{G}\)</span> を Bayesian Network 構造，<span class="math inline">\(\boldsymbol{Z}\subset\mathcal{X}\)</span> を観測された節とする．</p>
<ol type="1">
<li>非有向道 <span class="math inline">\(X_1\rightleftharpoons\cdots\rightleftharpoons X_n\)</span> が <span class="math inline">\(\boldsymbol{Z}\)</span> の下でも <strong>active</strong> であるとは， 次の２条件を満たすことをいう：
<ol type="1">
<li><span class="math inline">\(\{X_i\}_{i=1}^n\cap\boldsymbol{Z}=\emptyset\)</span>．</li>
<li>任意の無向道内の合流結合 <span class="math inline">\(X_{i-1}\rightarrow X_i\leftarrow X_{i+1}\)</span> について，<span class="math inline">\(X_i\)</span> またはその子孫に <span class="math inline">\(\boldsymbol{Z}\)</span> の元が存在する．</li>
</ol></li>
<li><span class="math inline">\(\boldsymbol{X}\sqcup\boldsymbol{Y}\sqcup\boldsymbol{Z}\subset\mathcal{X}\)</span> を節の集合とする．<span class="math inline">\(\boldsymbol{X},\boldsymbol{Y}\)</span> が <span class="math inline">\(\boldsymbol{Z}\)</span> に関して <strong><span class="math inline">\(d\)</span>-分離</strong> であるとは，任意の <span class="math inline">\(X\in\boldsymbol{X}\)</span> と <span class="math inline">\(Y\in\boldsymbol{Y}\)</span> と，<span class="math inline">\(X,Y\)</span> を結ぶ無向道が，<span class="math inline">\(\boldsymbol{Z}\)</span> の下で active でないことをいう．このことを <span class="math inline">\(\dsep_\mathcal{G}(\boldsymbol{X};\boldsymbol{Y}|\boldsymbol{Z})\)</span> と表す．<a href="#fn28" class="footnote-ref" id="fnref28" role="doc-noteref"><sup>28</sup></a></li>
<li><span class="math inline">\(\mathcal{G}\)</span> 内の <span class="math inline">\(d\)</span>-分離な組 <span class="math inline">\((\boldsymbol{X},\boldsymbol{Y},\boldsymbol{Z})\)</span> が表す条件付き独立性の条件式の全体を <span class="math display">\[
\mathcal{I}(\mathcal{G}):=\left\{(\boldsymbol{X}\perp\!\!\!\perp\boldsymbol{Y}|\boldsymbol{Z})\mid\dsep_\mathcal{G}(\boldsymbol{X};\boldsymbol{Y}|\boldsymbol{Z})\right\}.
\]</span> この元を <strong>大域的独立性</strong> ともいう．</li>
</ol>
</div>
</div>
</div>
<p>局所依存性（ <a href="#sec-DAG" class="quarto-xref">節&nbsp;2.1.2</a> ）は <span class="math inline">\(d\)</span>-分離性の特別な場合であり，<span class="math inline">\(\mathcal{I}_l(\mathcal{G})\subset\mathcal{I}(\mathcal{G})\)</span> である．</p>
</section>
<section id="例" class="level4" data-number="2.2.3">
<h4 data-number="2.2.3" class="anchored" data-anchor-id="例"><span class="header-section-number">2.2.3</span> 例</h4>
<div class="cell" data-fig-width="1" data-layout-align="default">
<div class="cell-output-display">
<div id="fig-CommonEffect" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-CommonEffect-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<svg width="96" height="480" viewbox="0.00 0.00 134.00 188.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 184)">
<title>ExampleTrail</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-184 130,-184 130,4 -4,4"></polygon>
<!-- X -->
<g id="node1" class="node">
<title>X</title>
<ellipse fill="none" stroke="black" cx="27" cy="-162" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="27" y="-157.8" font-family="Times,serif" font-size="14.00">X</text>
</g>
<!-- A -->
<g id="node2" class="node">
<title>A</title>
<ellipse fill="none" stroke="black" cx="27" cy="-90" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="27" y="-85.8" font-family="Times,serif" font-size="14.00">A</text>
</g>
<!-- X&#45;&gt;A -->
<g id="edge1" class="edge">
<title>X-&gt;A</title>
<path fill="none" stroke="black" d="M27,-143.7C27,-135.98 27,-126.71 27,-118.11"></path>
<polygon fill="black" stroke="black" points="30.5,-118.1 27,-108.1 23.5,-118.1 30.5,-118.1"></polygon>
</g>
<!-- Z -->
<g id="node3" class="node">
<title>Z</title>
<ellipse fill="none" stroke="black" cx="63" cy="-18" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="63" y="-13.8" font-family="Times,serif" font-size="14.00">Z</text>
</g>
<!-- A&#45;&gt;Z -->
<g id="edge2" class="edge">
<title>A-&gt;Z</title>
<path fill="none" stroke="black" d="M35.35,-72.76C39.71,-64.28 45.15,-53.71 50.04,-44.2"></path>
<polygon fill="black" stroke="black" points="53.23,-45.64 54.7,-35.15 47.01,-42.44 53.23,-45.64"></polygon>
</g>
<!-- Y -->
<g id="node4" class="node">
<title>Y</title>
<ellipse fill="none" stroke="black" cx="99" cy="-162" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="99" y="-157.8" font-family="Times,serif" font-size="14.00">Y</text>
</g>
<!-- B -->
<g id="node5" class="node">
<title>B</title>
<ellipse fill="none" stroke="black" cx="99" cy="-90" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="99" y="-85.8" font-family="Times,serif" font-size="14.00">B</text>
</g>
<!-- Y&#45;&gt;B -->
<g id="edge3" class="edge">
<title>Y-&gt;B</title>
<path fill="none" stroke="black" d="M99,-143.7C99,-135.98 99,-126.71 99,-118.11"></path>
<polygon fill="black" stroke="black" points="102.5,-118.1 99,-108.1 95.5,-118.1 102.5,-118.1"></polygon>
</g>
<!-- B&#45;&gt;Z -->
<g id="edge4" class="edge">
<title>B-&gt;Z</title>
<path fill="none" stroke="black" d="M90.65,-72.76C86.29,-64.28 80.85,-53.71 75.96,-44.2"></path>
<polygon fill="black" stroke="black" points="78.99,-42.44 71.3,-35.15 72.77,-45.64 78.99,-42.44"></polygon>
</g>
</g>
</svg>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-CommonEffect-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
図&nbsp;4: 合流結合 (Common Effect)
</figcaption>
</figure>
</div>
</div>
</div>
<p>この Bayesian Network 構造は，いつ <span class="math inline">\(d\)</span>-分離になり，いつ <span class="math inline">\(d\)</span>-分離ではないか？</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="答え">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
答え
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>いずれも観測されない場合は <span class="math inline">\(d\)</span>-分離である．</li>
<li><span class="math inline">\(Z\)</span> が観測された場合，<span class="math inline">\(A,B\)</span> のいずれかも観測されていれば，やはり <span class="math inline">\(d\)</span>-分離である．</li>
</ul>
</div>
</div>
</div>
</section>
<section id="sec-characterization-of-d-separation" class="level4" data-number="2.2.4">
<h4 data-number="2.2.4" class="anchored" data-anchor-id="sec-characterization-of-d-separation"><span class="header-section-number">2.2.4</span> <span class="math inline">\(d\)</span>-分離性の特徴付け</h4>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題^[[@Koller-Friedman2009 pp.72-73] 定理3.3, 3.5．] （$d$-分離性の特徴付け）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題<a href="#fn29" class="footnote-ref" id="fnref29" role="doc-noteref"><sup>29</sup></a> （<span class="math inline">\(d\)</span>-分離性の特徴付け）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(\mathcal{G}\)</span> を Bayesian Network 構造，<span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> を確率分布とする．</p>
<ol type="1">
<li><span class="math inline">\(P\)</span> が <span class="math inline">\(\mathcal{G}\)</span> に沿って分解するならば，<span class="math inline">\(\mathcal{I}(\mathcal{G})\subset\mathcal{I}(P)\)</span>．</li>
<li><span class="math inline">\(\mathcal{H}\)</span> に沿って分解する殆ど全ての <span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> に関して，上の逆も成り立ち，特に等号が成立する．</li>
</ol>
</div>
</div>
</div>
<p><span class="math inline">\(\mathcal{G}\)</span> が定める分布族について，殆ど全ての分布が共通して持つ条件付き独立性の構造を，<span class="math inline">\(\mathcal{G}\)</span> から読み取れる <span class="math inline">\(d\)</span>-分離性によって発見できるということになる．</p>
<p>さらには，分布 <span class="math inline">\(P\)</span> の独立性の情報を知りたい場合，この背後にあるグラフ <span class="math inline">\(\mathcal{G}\)</span> を探し出して，<span class="math inline">\(d\)</span>-分離性を調べれば良い，ということでもであるのである．<a href="#fn30" class="footnote-ref" id="fnref30" role="doc-noteref"><sup>30</sup></a></p>
</section>
<section id="i-同値性" class="level4" data-number="2.2.5">
<h4 data-number="2.2.5" class="anchored" data-anchor-id="i-同値性"><span class="header-section-number">2.2.5</span> <span class="math inline">\(I\)</span>-同値性</h4>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 p.76] 定義3.9．] （$I$-Equivalence）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-15-contents" aria-controls="callout-15" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定義<a href="#fn31" class="footnote-ref" id="fnref31" role="doc-noteref"><sup>31</sup></a> （<span class="math inline">\(I\)</span>-Equivalence）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-15" class="callout-15-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>２つの Bayesian Network 構造 <span class="math inline">\(\mathcal{G},\mathcal{G}'\)</span> が <strong><span class="math inline">\(I\)</span>-同値</strong> であるとは，<span class="math inline">\(\mathcal{I}(\mathcal{G})=\mathcal{I}(\mathcal{G}')\)</span> が成り立つことをいう．</p>
</div>
</div>
</div>
<p><span class="math inline">\(I\)</span> は写像であるから，この関係は確かに Bayesian Network 構造の全体（果てには有向グラフの全体）に同値関係を定める．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題^[[@Koller-Friedman2009 p.77] 定理3.7．] （$I$-同値性の十分条件）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-16-contents" aria-controls="callout-16" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題<a href="#fn32" class="footnote-ref" id="fnref32" role="doc-noteref"><sup>32</sup></a> （<span class="math inline">\(I\)</span>-同値性の十分条件）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-16-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>２つの Bayesian Network 構造 <span class="math inline">\(\mathcal{G},\mathcal{G}'\)</span> が</p>
<ol type="1">
<li>同じスケルトンを持ち，<a href="#fn33" class="footnote-ref" id="fnref33" role="doc-noteref"><sup>33</sup></a></li>
<li>同じ <span class="math inline">\(v\)</span>-構造を持つ</li>
</ol>
<p>ならば，<span class="math inline">\(I\)</span>-同値である．</p>
</div>
</div>
</div>
<p>有向グラフ <span class="math inline">\(\mathcal{G}=(\mathcal{X},\mathcal{E})\)</span> の辺 <span class="math inline">\((X,Y)\in\mathcal{E}\)</span> が <strong>被覆されている</strong> とは， <span class="math display">\[
\pi(Y)=\pi(X)\cup\{X\}
\]</span> を満たすことをいう．</p>
<p>合流結合 <span class="math inline">\(X\rightarrow Z\leftarrow Y\)</span> において，辺 <span class="math inline">\(X\to Z\)</span> は被覆されていない．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題^[[@Koller-Friedman2009 p.77] 定理3.8．] （$I$-同値性の特徴付け）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-17-contents" aria-controls="callout-17" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題<a href="#fn34" class="footnote-ref" id="fnref34" role="doc-noteref"><sup>34</sup></a> （<span class="math inline">\(I\)</span>-同値性の特徴付け）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-17" class="callout-17-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>２つの Bayesian Network 構造 <span class="math inline">\(\mathcal{G},\mathcal{G}'\)</span> について，次は同値：</p>
<ol type="1">
<li><span class="math inline">\(\mathcal{G},\mathcal{G}'\)</span> は <span class="math inline">\(I\)</span>-同値である．</li>
<li><span class="math inline">\(\mathcal{G}\)</span> に <span class="math inline">\(I\)</span>-同値なグラフの列 <span class="math inline">\(\mathcal{G}=\mathcal{G}_0,\cdots,\mathcal{G}_m=\mathcal{G}'\)</span> であって，隣り合うグラフ <span class="math inline">\(\mathcal{G}_i,\mathcal{G}_{i+1}\;(i\in m)\)</span> 同士は，被覆されている辺の向きの反転しか違わないものが存在する．</li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="markov-network" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="markov-network"><span class="header-section-number">2.3</span> Markov Network</h3>
<section id="グラフ理論の準備" class="level4" data-number="2.3.1">
<h4 data-number="2.3.1" class="anchored" data-anchor-id="グラフ理論の準備"><span class="header-section-number">2.3.1</span> グラフ理論の準備</h4>
<p><span class="math inline">\(A\)</span> を集合とする． <span class="math display">\[
[A]^k:=\left\{B\in P(A)\mid\# B=k\right\}
\]</span> とする．無向グラフとは集合 <span class="math inline">\(V\)</span> と <span class="math inline">\(E\subset[V]^2\)</span> の組 <span class="math inline">\(G:=(V,E)\)</span> のことをいう．<a href="#fn35" class="footnote-ref" id="fnref35" role="doc-noteref"><sup>35</sup></a></p>
<p><strong>Markov Network 構造</strong> とは，任意の無向グラフをいう．</p>
<p>２つの節 <span class="math inline">\(x,y\in V\)</span> が <strong>隣接する</strong> (adjacent / neighbours) とは，<span class="math inline">\(\{x,y\}\in E\)</span> が成り立つことをいう．</p>
<p>無向グラフ <span class="math inline">\(G\)</span> が <strong>完備</strong> (complete) であるとは，任意の <span class="math inline">\(x,y\in V\)</span> について <span class="math inline">\(\{x,y\}\in E\)</span> が成り立つことをいう．このとき，頂点集合 <span class="math inline">\(V\)</span> は <strong>クリーク</strong> (clique) であるという．位数 <span class="math inline">\(n\)</span> の完備グラフは <span class="math inline">\(K^n\)</span> で表される．<a href="#fn36" class="footnote-ref" id="fnref36" role="doc-noteref"><sup>36</sup></a></p>
<p><span class="math inline">\(K^r\subset G\)</span> を満たす最大の数 <span class="math display">\[
\omega(G):=\left\{r\in\mathbb{N}\mid K^r\subset G\right\}
\]</span> を <strong>クリーク数</strong> といい，グラフの不変量となる．<a href="#fn37" class="footnote-ref" id="fnref37" role="doc-noteref"><sup>37</sup></a></p>
<p><a href="https://ja.wikipedia.org/wiki/%E5%BC%A6%E3%82%B0%E3%83%A9%E3%83%95"><strong>弦グラフ</strong></a> (chordal / triangulated graph) とは，任意の長さ４以上のサイクルが弦を持つグラフを言う．<a href="#fn38" class="footnote-ref" id="fnref38" role="doc-noteref"><sup>38</sup></a> 弦グラフが，Bayesian Network と Markov Network の双方により表現可能であるグラフのクラスに一致する．</p>
</section>
<section id="markov-network-と-markov-random-field" class="level4" data-number="2.3.2">
<h4 data-number="2.3.2" class="anchored" data-anchor-id="markov-network-と-markov-random-field"><span class="header-section-number">2.3.2</span> Markov Network と Markov Random Field</h4>
<p>マルコフネットワークは，２次元のマルコフ確率場に等価である．<a href="#fn39" class="footnote-ref" id="fnref39" role="doc-noteref"><sup>39</sup></a></p>
<p>後者は <a href="../../../posts/2024/Computation/PGM2.html#sec-Ising-model">Ising モデル</a> の一般化である．<a href="#fn40" class="footnote-ref" id="fnref40" role="doc-noteref"><sup>40</sup></a></p>
</section>
<section id="導入-1" class="level4" data-number="2.3.3">
<h4 data-number="2.3.3" class="anchored" data-anchor-id="導入-1"><span class="header-section-number">2.3.3</span> 導入</h4>
<p>Markov Network は相互作用に自然な双方向性がない場合でもモデリングを可能とする．</p>
<p>例えば，集合 <span class="math inline">\(\{A,B,C,D\}\)</span> 上の条件付き独立関係 <span class="math display">\[
\mathcal{I}:=\left\{\substack{A\perp\!\!\!\perp C|(B,D),\\B\perp\!\!\!\perp D|(A,C)}\right\}
\]</span> に関して，<span class="math inline">\(\mathcal{I}(\mathcal{G})=\mathcal{I}\)</span> を満たす Bayesian Network 構造 <span class="math inline">\(\mathcal{G}\)</span> は存在しない．</p>
<p>一方で，分岐結合と合流結合とを区別できないため，因果性のような方向を持った依存関係は表現できない．</p>
<p>Markov Network では，節の間に自然な順序構造がないため，分布の表示が難しくなり，より純粋にグラフの分解に頼ることになる．それゆえ，データからの構造学習も遥かに難しくなる．<a href="#fn41" class="footnote-ref" id="fnref41" role="doc-noteref"><sup>41</sup></a></p>
<p>Bayesian Network では条件付き確率密度のみで十分だったところを，これを一般化する概念である factor と呼ばれる概念によって達成する．</p>
<p>条件付き確率密度 <span class="math inline">\(p(x_1,\cdots,x_m|y_1,\cdots,y_k)\)</span> とは，形式的には，積空間 <span class="math inline">\(\prod_{i=1}^m\mathrm{Im}\,(X_i)\times\prod_{j=1}^k\mathrm{Im}\,(Y_j)\)</span> 上の（正規化された）関数である．一般に，確率変数の値域の積上の（正規化されているとは限らない）関数を <strong>ファクター</strong> と言う．</p>
</section>
<section id="ファクター" class="level4" data-number="2.3.4">
<h4 data-number="2.3.4" class="anchored" data-anchor-id="ファクター"><span class="header-section-number">2.3.4</span> ファクター</h4>
<p>確率変数の組 <span class="math inline">\(\boldsymbol{X}=(X_1,\cdots,X_n)\)</span> 上の <strong>ファクター</strong> とは，ある部分集合 <span class="math inline">\(\{n_1,\cdots,n_D\}\subset[n]\)</span> に対して，関数 <span class="math inline">\((X_{n_1},\cdots,X_{n_D})\)</span> の値域上に定義された関数 <span class="math display">\[
\phi:\prod_{i=1}^D\mathrm{Im}\,(X_{n_i})\to\mathbb{R}
\]</span> を言う．この定義域を <strong>スコープ</strong> と言う．<a href="#fn42" class="footnote-ref" id="fnref42" role="doc-noteref"><sup>42</sup></a></p>
<p>定義域 <span class="math inline">\(a,b\subset[n]\)</span> がかぶる２つのファクター <span class="math inline">\(\phi_1,\phi_2,a\cap b\ne\emptyset\)</span> が存在する場合，これらを接続して，<span class="math inline">\(\prod_{i\in a\cup b}\mathrm{Im}\,(X_i)\)</span> 上に定義された新たなファクターを作ることが出来る：<a href="#fn43" class="footnote-ref" id="fnref43" role="doc-noteref"><sup>43</sup></a> <span class="math display">\[
\phi_1\times\phi_2(X_{a\cup b}):=\phi_1(X_a)\phi_2(X_b).
\]</span></p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 p.108] 定義4.3．] （Gibbs distribution, factorization）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定義<a href="#fn44" class="footnote-ref" id="fnref44" role="doc-noteref"><sup>44</sup></a> （Gibbs distribution, factorization）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ol type="1">
<li>離散確率変数の組 <span class="math inline">\(\boldsymbol{X}=(X_1,\cdots,X_n)\)</span> とその上のファクター <span class="math display">\[
\Phi:=(\phi_1(\boldsymbol{D}_1),\cdots,\phi_m(\boldsymbol{D}_m))
\]</span> <span class="math display">\[
\boldsymbol{D}_j\subset\{X_i\}_{i=1}^n\quad(j\in[m])
\]</span> とが定める <span class="math inline">\(\prod_{i=1}^n\mathrm{Im}\,(X_i)\)</span> 上の <a href="https://en.wikipedia.org/wiki/Gibbs_measure"><strong>Gibbs 分布</strong></a> とは，密度 <span class="math display">\[
p_\Phi(\boldsymbol{x})=\frac{1}{Z}\prod_{j=1}^m\phi_j(\boldsymbol{D}_j)
\]</span> が定める分布をいう．ここで <span class="math inline">\(Z\)</span> は正規化定数であり，歴史的には <strong>分配関数</strong> と言う．<a href="#fn45" class="footnote-ref" id="fnref45" role="doc-noteref"><sup>45</sup></a></li>
<li>Gibbs 分布 <span class="math inline">\(p_\Phi\)</span> が Markov network <span class="math inline">\(\mathcal{H}=(\{X_i\}_{i=1}^n,\mathcal{E})\)</span> 上で <strong>分解する</strong> とは，任意の <span class="math inline">\(\mathcal{D}_j\subset\{X_i\}_{i=1}^n\;(j\in[m])\)</span> が <span class="math inline">\(\mathcal{H}\)</span> のクリークであることをいう．このとき，各ファクター <span class="math inline">\(\phi_1,\cdots,\phi_m\)</span> を <strong>clique potential</strong> という．</li>
</ol>
</div>
</div>
</div>
</section>
<section id="sec-separation-in-markov-network" class="level4" data-number="2.3.5">
<h4 data-number="2.3.5" class="anchored" data-anchor-id="sec-separation-in-markov-network"><span class="header-section-number">2.3.5</span> Markov Network の分離性</h4>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 pp.114-115] 定義4.8, 9．] （Global Markov Independence）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-19-contents" aria-controls="callout-19" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定義<a href="#fn46" class="footnote-ref" id="fnref46" role="doc-noteref"><sup>46</sup></a> （Global Markov Independence）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-19" class="callout-19-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(\mathcal{H}\)</span> を Markov network 構造とする．</p>
<ol type="1">
<li>道 <span class="math inline">\(X_1\rightleftharpoons\cdots\rightleftharpoons X_n\)</span> が <span class="math inline">\(\boldsymbol{Z}\subset\{X_i\}_{i=1}^n\)</span> が観測された下でも <strong>active</strong> であるとは，<span class="math inline">\(\{X_i\}_{i=1}^n\cap\boldsymbol{Z}=\emptyset\)</span> を満たすことをいう．</li>
<li>節集合 <span class="math inline">\(\boldsymbol{X},\boldsymbol{Y},\boldsymbol{Z}\)</span> について，<span class="math inline">\(\boldsymbol{Z}\)</span> が <span class="math inline">\(\boldsymbol{X},\boldsymbol{Y}\)</span> を <strong>分離</strong> するとは，任意の <span class="math inline">\(X\in\boldsymbol{X}\)</span> と <span class="math inline">\(Y\in\boldsymbol{Y}\)</span> と，<span class="math inline">\(X,Y\)</span> を結ぶ道が，<span class="math inline">\(\boldsymbol{Z}\)</span> の下で active でないことをいう．このことを <span class="math inline">\(\sep_\mathcal{H}(\boldsymbol{X};\boldsymbol{Y}|\boldsymbol{Z})\)</span> と表す．</li>
</ol>
<ul>
<li><span class="math inline">\(\mathcal{H}\)</span> 内の分離的な組 <span class="math inline">\((\boldsymbol{X},\boldsymbol{Y},\boldsymbol{Z})\)</span> が表す条件付き独立性の条件式の全体を <span class="math display">\[
\mathcal{I}(\mathcal{H}):=\left\{(\boldsymbol{X}\perp\!\!\!\perp\boldsymbol{Y}|\boldsymbol{Z})\mid\sep_\mathcal{H}(\boldsymbol{X};\boldsymbol{Y}|\boldsymbol{Z})\right\}
\]</span> で表す．この元を <strong>大域的独立性</strong> ともいう．</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定理^[[@Koller-Friedman2009 pp.116-117] 定理4.1，定理4.2．] [@Hammersley-Clifford1971]">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-20-contents" aria-controls="callout-20" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定理<a href="#fn47" class="footnote-ref" id="fnref47" role="doc-noteref"><sup>47</sup></a> <span class="citation" data-cites="Hammersley-Clifford1971">(<a href="#ref-Hammersley-Clifford1971" role="doc-biblioref">Hammersley &amp; Clifford, 1971</a>)</span>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-20" class="callout-20-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> をノードの集合 <span class="math inline">\(\mathcal{X}=\{X_1,\cdots,X_n\}\)</span> 上の確率分布，<span class="math inline">\(\mathcal{H}\)</span> を <span class="math inline">\(\mathcal{X}\)</span> 上の Markov network 構造とする．このとき 1. <span class="math inline">\(\Rightarrow\)</span> 2. が成り立ち，<span class="math inline">\(P\)</span> が <span class="math inline">\(\mathcal{X}\)</span> 全域を台に持つとき次は同値：</p>
<ol type="1">
<li><span class="math inline">\(\mathcal{H}\)</span> は <span class="math inline">\(P\)</span> の <span class="math inline">\(I\)</span>-map である：<span class="math inline">\(\mathcal{I}(\mathcal{H})\subset\mathcal{I}(P)\)</span>．</li>
<li><span class="math inline">\(P\)</span> は <span class="math inline">\(\mathcal{H}\)</span> に従って分解する Gibbs 分布である．</li>
</ol>
</div>
</div>
</div>
<p><span class="citation" data-cites="Besag1974">(<a href="#ref-Besag1974" role="doc-biblioref">Besag, 1974</a>)</span> はこの定理に別証明を付し，植物生態学における空間統計モデルに応用している．<a href="#fn48" class="footnote-ref" id="fnref48" role="doc-noteref"><sup>48</sup></a></p>
<p>Markov 確率場の結合分布を，条件付き分布の系から得ることは困難であるが，結局結合分布も Gibbs 分布になることが <span class="citation" data-cites="Hammersley-Clifford1971">(<a href="#ref-Hammersley-Clifford1971" role="doc-biblioref">Hammersley &amp; Clifford, 1971</a>)</span> の定理からわかるので，Gibbs 分布を通じて計算することができる．</p>
<p>この「条件付き分布から結合分布が復元できる」という知見が Gibbs sampling の基礎となった．<a href="#fn49" class="footnote-ref" id="fnref49" role="doc-noteref"><sup>49</sup></a> また統計的画像解析の基礎ともなった <span class="citation" data-cites="Grenander1983">(<a href="#ref-Grenander1983" role="doc-biblioref">Grenander, 1983</a>)</span>．</p>
<p>また <span class="citation" data-cites="Geman-Geman1984">(<a href="#ref-Geman-Geman1984" role="doc-biblioref">Geman &amp; Geman, 1984</a>)</span> は，Markov 確率場でモデリングをし，その最大事後確率 MAP (Maximum a Posteriori) を目的関数として最適化を行う，という MAP-MRF アプローチを創始した <span class="citation" data-cites="Li2009">(<a href="#ref-Li2009" role="doc-biblioref">Li, 2009, p. 2</a>)</span>．</p>
<p>さらに統計計算法の進展により，画像の低レイヤーな特徴を表現する（画像修復，物体発見など）だけでなく，高レイヤーな特徴（物体認識やマッチングなど）をも扱えることがわかっている <span class="citation" data-cites="Gidas1989">(<a href="#ref-Gidas1989" role="doc-biblioref">Gidas, 1989</a>)</span>, <span class="citation" data-cites="Li1991">(<a href="#ref-Li1991" role="doc-biblioref">Li, 1991</a>)</span>．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題^[[@Koller-Friedman2009 p.117] 定理4.3．] （分離性の特徴付け）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-21-contents" aria-controls="callout-21" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題<a href="#fn50" class="footnote-ref" id="fnref50" role="doc-noteref"><sup>50</sup></a> （分離性の特徴付け）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-21" class="callout-21-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(\mathcal{H}\)</span> を Markov network 構造，<span class="math inline">\(\{X\}\sqcup\{Y\}\sqcup\boldsymbol{Z}\subset\mathcal{X}\)</span> を節の集合とする．このとき，次が成り立つ：</p>
<ol type="1">
<li><span class="math inline">\(\mathcal{H}\)</span> 内で <span class="math inline">\(X,Y\)</span> は <span class="math inline">\(\boldsymbol{Z}\)</span> によって分離されないならば，ある <span class="math inline">\(\mathcal{H}\)</span> に沿って分解する分布 <span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> について，<span class="math inline">\(X\perp\!\!\!\perp Y|\boldsymbol{Z}\)</span> が成り立つ．</li>
<li><span class="math inline">\(\mathcal{H}\)</span> に沿って分解する殆ど全ての <span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> に関して，<span class="math inline">\(\mathcal{I}(\mathcal{H})=\mathcal{I}(P)\)</span> が成り立つ．</li>
</ol>
</div>
</div>
</div>
<p>Beysian Network （ <a href="#sec-characterization-of-d-separation" class="quarto-xref">節&nbsp;2.2.4</a> ）の場合と違い，1. の主張が，<span class="math inline">\(\mathcal{H}\)</span> に沿って分解する全ての分布 <span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> に関して成り立つとは限らない．</p>
<p>しかし，殆ど全ての <span class="math inline">\(\mathcal{H}\)</span> に沿って分解する分布 <span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> に関して成り立つ条件付き独立性は，グラフの構造から読み取れる．</p>
</section>
<section id="局所依存性" class="level4" data-number="2.3.6">
<h4 data-number="2.3.6" class="anchored" data-anchor-id="局所依存性"><span class="header-section-number">2.3.6</span> 局所依存性</h4>
<p>Bayesian Network の <span class="math inline">\(d\)</span>-分離性に対応する分離性の概念を導入し，大域的独立性の概念を定義した．</p>
<p>しかし，Bayesian Network の場合では有向グラフとしての構造からすぐに読み取れた局所依存性の概念は，Markov Network の場合では，グラフの構造からは読み取れない．</p>
<p>そして２通りの定義が考え得る．局所依存性は，大域的依存性のサブセットであることに注意．そして，台を全体 <span class="math inline">\(\mathcal{X}\)</span> に持つ分布については，大域的依存性も含めて３つの定義は全て同値である．<a href="#fn51" class="footnote-ref" id="fnref51" role="doc-noteref"><sup>51</sup></a></p>
</section>
</section>
<section id="sec-Factor-Graph" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="sec-Factor-Graph"><span class="header-section-number">2.4</span> Factor Graph</h3>
<p>Markov network は Gibbs 分布の依存性を十分に表現できているわけではなかった（ <a href="#sec-separation-in-markov-network" class="quarto-xref">節&nbsp;2.3.5</a> ）．これは特に，クリーク間の大小関係を把握できていないことに因る．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義^[[@Koller-Friedman2009 p.123] 4.4.1.1．] （Factor Graph）">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-22-contents" aria-controls="callout-22" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定義<a href="#fn52" class="footnote-ref" id="fnref52" role="doc-noteref"><sup>52</sup></a> （Factor Graph）
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-22" class="callout-22-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Markov newtork から，ファクターを表す節を（四角形で囲うなどして区別した形で）追加し，ファクターをそのスコープに入る変数と隣接するようにし，一方で変数を表す（元々の）節とファクターを表す節とが隣接しないように修正した <a href="https://ja.wikipedia.org/wiki/2%E9%83%A8%E3%82%B0%E3%83%A9%E3%83%95">２部グラフ</a> <span class="math inline">\(\mathcal{F}\)</span> を <a href="https://en.wikipedia.org/wiki/Factor_graph"><strong>因子グラフ</strong></a> という．</p>
<p>分布 <span class="math inline">\(P\in\mathcal{P}(\mathcal{X})\)</span> が <span class="math inline">\(\mathcal{F}\)</span> に関して <strong>分解する</strong> とは，<span class="math inline">\(\mathcal{F}\)</span> が定める確率変数の組とその上のファクターが定める Gibbs 分布であることをいう．</p>
</div>
</div>
</div>



</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-Balgi+2024" class="csl-entry" role="listitem">
Balgi, S., Daoud, A., Peña, J. M., Wodtke, G. T., &amp; Zhou, J. (2024). <em>Deep learning with DAGs</em>. <a href="https://arxiv.org/abs/2401.06864">https://arxiv.org/abs/2401.06864</a>
</div>
<div id="ref-Bartlett1935" class="csl-entry" role="listitem">
Bartlett, M. S. (1935). Contingency table interactions. <em>Supplement to the Journal of the Royal Statistical Society</em>, <em>2</em>(2), 246–252. <a href="https://www.jstor.org/stable/2983639">https://www.jstor.org/stable/2983639</a>
</div>
<div id="ref-Besag1974" class="csl-entry" role="listitem">
Besag, J. (1974). Spatial interaction and the statistical analysis of lattice systems. <em>Journal of the Royal Statistical Society. Series B (Methodological)</em>, <em>36</em>(2), 192–236. <a href="https://www.jstor.org/stable/2984812">https://www.jstor.org/stable/2984812</a>
</div>
<div id="ref-Bishop2006" class="csl-entry" role="listitem">
Bishop, C. M. (2006). <em>Pattern recognition and machine learning</em>. Springer New York. <a href="https://link.springer.com/book/9780387310732">https://link.springer.com/book/9780387310732</a>
</div>
<div id="ref-Bishop-Bishop2024" class="csl-entry" role="listitem">
Bishop, C. M., &amp; Bishop, H. (2024). <em>Deep learning: Foundations and concepts</em>. Springer Cham. <a href="https://link.springer.com/book/10.1007/978-3-031-45468-4">https://link.springer.com/book/10.1007/978-3-031-45468-4</a>
</div>
<div id="ref-Blalock1971" class="csl-entry" role="listitem">
Blalock&nbsp;Jr., H. (1971). <em><a href="">Causal models in the social sciences</a></em>. Chicago, Illinois: Aldine-Atheson.
</div>
<div id="ref-Chen2023" class="csl-entry" role="listitem">
Chen, L.-P. (2023). Estimation of graphical models: An overview of selected topics. <em>International Statistical Review</em>. <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/insr.12552">https://onlinelibrary.wiley.com/doi/abs/10.1111/insr.12552</a>
</div>
<div id="ref-Clark2018" class="csl-entry" role="listitem">
Clark, M. (2018). <em>Graphical &amp; latent variable modeling</em>. <a href="https://m-clark.github.io/sem/">https://m-clark.github.io/sem/</a>
</div>
<div id="ref-Dombal+1972" class="csl-entry" role="listitem">
de&nbsp;Dombal, F. T., Leaper, D. J., Staniland, J. R., McCann, A. P., &amp; Horrocks, J. C. (1972). Computer-aided diagnosis of acute abdominal pain. <em>The Britich Medical Journal</em>, <em>2</em>(5804), 9–13. <a href="https://www.jstor.org/stable/25418224">https://www.jstor.org/stable/25418224</a>
</div>
<div id="ref-Diestel2017" class="csl-entry" role="listitem">
Diestel, R. (2017). <em>Graph theory</em> (5th ed., Vol. 173). Springer Berlin Heidelberg. <a href="https://link.springer.com/book/10.1007/978-3-662-53622-3">https://link.springer.com/book/10.1007/978-3-662-53622-3</a>
</div>
<div id="ref-Geman-Geman1984" class="csl-entry" role="listitem">
Geman, S., &amp; Geman, D. (1984). Stochastic relaxation, gibbs distributions, and the bayesian restoration of images. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, <em>PAMI-6</em>(6), 721–741.
</div>
<div id="ref-Gibbs1902" class="csl-entry" role="listitem">
Gibbs, J. W. (1902). <em><a href="">Elementary principles in statistical mechanics: Developed with especial reference to the rational foundation of thermodynamics</a></em>. Charles Scribner’s Sons.
</div>
<div id="ref-Gidas1989" class="csl-entry" role="listitem">
Gidas, B. (1989). A renormalization group approach to image processing problems. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, <em>11</em>(2), 164–180. <a href="https://ieeexplore.ieee.org/document/16712">https://ieeexplore.ieee.org/document/16712</a>
</div>
<div id="ref-Grenander1983" class="csl-entry" role="listitem">
Grenander, U. (1983). <em><a href="">Tutorial in pattern theory</a></em>. Brown University.
</div>
<div id="ref-Hammersley-Clifford1971" class="csl-entry" role="listitem">
Hammersley, J., &amp; Clifford, P. (1971). <em>Markov fields on finite graphs and lattices</em>. <a href="https://ora.ox.ac.uk/objects/uuid:4ea849da-1511-4578-bb88-6a8d02f457a6">https://ora.ox.ac.uk/objects/uuid:4ea849da-1511-4578-bb88-6a8d02f457a6</a>
</div>
<div id="ref-Heckerman+1992" class="csl-entry" role="listitem">
Heckerman, D. E., Horvitz, E. J., &amp; Nathwani, B. N. (1992). Toward normative expert systems: Part i. The pathfinder project. <em>Methods of Information in Medicine</em>, <em>31</em>(2), 90–105. <a href="https://www.thieme-connect.com/products/ejournals/abstract/10.1055/s-0038-1634867">https://www.thieme-connect.com/products/ejournals/abstract/10.1055/s-0038-1634867</a>
</div>
<div id="ref-Heckerman-Nathwani1992" class="csl-entry" role="listitem">
Heckerman, D. E., &amp; Nathwani, B. N. (1992). <a href="">Toward normative expert systems. II. Probability-based representations for eﬃcient knowledge acquisition and inference</a>. <em>Methods of Information in Medicine</em>, <em>31</em>(2), 106–116.
</div>
<div id="ref-Howard-Matheson1984" class="csl-entry" role="listitem">
Howard, R. A., &amp; Matheson, J. E. (1984). (pp. 721–762). SDG Decision Systems.
</div>
<div id="ref-Jordan+1999" class="csl-entry" role="listitem">
Jordan, M. I., Ghahramani, Z., Jaakkola, T. S., &amp; Saul, L. K. (1999). An introduction to variational methods for graphical models. <em>Machine Learning</em>, <em>37</em>, 183–233. <a href="https://link.springer.com/article/10.1023/A:1007665907178">https://link.springer.com/article/10.1023/A:1007665907178</a>
</div>
<div id="ref-Joreskog70" class="csl-entry" role="listitem">
Jöreskog, K. G. (1970). A general method for analysis of covariance structures. <em>Biometrika</em>, <em>57</em>(2), 239–251. <a href="https://www.jstor.org/stable/2334833">https://www.jstor.org/stable/2334833</a>
</div>
<div id="ref-Joreskog-Wold1981" class="csl-entry" role="listitem">
Jöreskog, K. G., &amp; Wold, H. (1982). <em><a href="">Systems under indirect observation: Causality, structure, prediction</a></em>. Elsevier, Amsterdam.
</div>
<div id="ref-Kindermann-Snell1980" class="csl-entry" role="listitem">
Kindermann, R., &amp; Snell, J. L. (1980). <em>Markov random fields and their applications</em>. American Mathematical Society. <a href="https://www.ams.org/books/conm/001/">https://www.ams.org/books/conm/001/</a>
</div>
<div id="ref-Koller-Friedman2009" class="csl-entry" role="listitem">
Koller, D., &amp; Friedman, N. (2009). <em>Probabilistic graphical models</em>. MIT Press. <a href="https://mitpress.mit.edu/9780262013192/probabilistic-graphical-models/">https://mitpress.mit.edu/9780262013192/probabilistic-graphical-models/</a>
</div>
<div id="ref-Lauritzen-Spiegelhalter1988" class="csl-entry" role="listitem">
Lauritzen, S. L., &amp; Spiegelhalter, D. J. (1988). Local computations with probabilites on graphical structures and their application to expert systems. <em>Journal of the Royal Statistical Society. Series B (Methodological)</em>, <em>50</em>(2), 157–224. <a href="https://www.jstor.org/stable/2345762">https://www.jstor.org/stable/2345762</a>
</div>
<div id="ref-Li1991" class="csl-entry" role="listitem">
Li, S. Z. (1991). <em>Towards 3D vision from range images: An optimisation framework and parallel distributed networks</em> [PhD thesis, University of Surrey, Guildford Surrey, UK]. <a href="https://www.sciencedirect.com/science/article/pii/104996609290023V">https://www.sciencedirect.com/science/article/pii/104996609290023V</a>
</div>
<div id="ref-Li2009" class="csl-entry" role="listitem">
Li, S. Z. (2009). <em>Markov random field modeling in image analysis</em> (3rd ed.). Springer London. <a href="https://link.springer.com/book/10.1007/978-1-84800-279-1">https://link.springer.com/book/10.1007/978-1-84800-279-1</a>
</div>
<div id="ref-Murphy2023" class="csl-entry" role="listitem">
Murphy, K. P. (2023). <em>Probabilistic machine learning: Advanced topics</em>. MIT Press. <a href="http://probml.github.io/book2">http://probml.github.io/book2</a>
</div>
<div id="ref-Pearl88-IntelligentSystem" class="csl-entry" role="listitem">
Pearl, J. (1988). <em>Probabilistic reasoning in intelligent systems</em>. Morgan Kaufmann.
</div>
<div id="ref-Pearl09-Causality" class="csl-entry" role="listitem">
Pearl, J. (2009). <em>Causality: Models, reasoning and inference</em> (2nd ed.). 和訳は黒木学による『統計的因果推論―モデル・推論・推測』（共立出版，2009）; Cambridge University Press.
</div>
<div id="ref-Pearl16-Primer" class="csl-entry" role="listitem">
Pearl, J., Glymour, M., &amp; Jewell, N. P. (2016). <em>Causal inference in statistics: A primer</em>. 和訳は落海浩による『入門 統計的因果推論』（朝倉書店，2019）; Wiley.
</div>
<div id="ref-Robert-Casella2011" class="csl-entry" role="listitem">
Robert, C., &amp; Casella, G. (2011). A short history of markov chain monte carlo: Subjective recollections from incomplete data. <em>Statistical Science</em>, <em>26</em>(1), 102–115. <a href="http://www.jstor.org/stable/23059158">http://www.jstor.org/stable/23059158</a>
</div>
<div id="ref-Rumelhart+1987" class="csl-entry" role="listitem">
Rumelhart, D. E., Hinton, G. E., &amp; Williams, R. J. (1987). <em>Parallel distributed processing: Explorations in the microstructure of cognition: foundations</em> (D. E. Rumelhart &amp; J. L. McClelland, Eds.; pp. 318–362). MIT Press. <a href="https://mitpress.mit.edu/9780262680530/parallel-distributed-processing/">https://mitpress.mit.edu/9780262680530/parallel-distributed-processing/</a>
</div>
<div id="ref-Scholkopf2022" class="csl-entry" role="listitem">
Schölkopf, B. (2022). Causality for machine learning. In <em>Probabilistic and causal inference</em> (pp. 765–804). ACM. <a href="https://doi.org/10.1145/3501714.3501755">https://doi.org/10.1145/3501714.3501755</a>
</div>
<div id="ref-Sucar2021" class="csl-entry" role="listitem">
Sucar, L. E. (2021). <em>Probabilistic graphical models: Principles and applications</em> (2nd ed.). Springer London. <a href="https://link.springer.com/book/10.1007/978-1-4471-6699-3">https://link.springer.com/book/10.1007/978-1-4471-6699-3</a>
</div>
<div id="ref-Taroni+2014" class="csl-entry" role="listitem">
Taroni, F., Biedermann, A., Bozza, S., Garbolino, P., &amp; Aitken, C. (2014). <em>Bayesian networks for probabilistic inference and decision analysis in forensic science</em>. John Wiley &amp; Sons.
</div>
<div id="ref-Theodoridis2020" class="csl-entry" role="listitem">
Theodoridis, S. (2020). <em>Machine learning: A bayesian and optimization perspective</em> (2nd ed.). Academic Press. <a href="https://doi.org/10.1016/C2019-0-03772-7">https://doi.org/10.1016/C2019-0-03772-7</a>
</div>
<div id="ref-Wainwright-Jordan2008" class="csl-entry" role="listitem">
Wainwright, M. J., &amp; Jordan, M. I. (2008). Graphical models, exponential families, and variational inference. <em>Foundations and Trends in Machine Learning</em>, <em>1</em>(1-2), 1–305. <a href="https://www.nowpublishers.com/article/Details/MAL-001">https://www.nowpublishers.com/article/Details/MAL-001</a>
</div>
<div id="ref-Wold1954" class="csl-entry" role="listitem">
Wold, H. (1954). Causality and econometrics. <em>Econometrica</em>, <em>22</em>, 162–177. <a href="https://www.jstor.org/stable/1907540">https://www.jstor.org/stable/1907540</a>
</div>
<div id="ref-Wold-Strotz60" class="csl-entry" role="listitem">
Wold, H. O. A., &amp; Strotz, R. H. (1960). Recursive vs. Nonrecursive systems: An attempt at synthesis (part i of a triptych on causal chain systems). <em>Econometrica</em>, <em>28</em>(2), 417–427. <a href="https://www.jstor.org/stable/1907731">https://www.jstor.org/stable/1907731</a>
</div>
<div id="ref-Wright1918" class="csl-entry" role="listitem">
Wright, S. (1918). On the nature of size factors. <em>Genetics</em>, <em>3</em>(4), 367. <a href="https://academic.oup.com/genetics/article/3/4/367/5934526">https://academic.oup.com/genetics/article/3/4/367/5934526</a>
</div>
<div id="ref-Zadeh1989" class="csl-entry" role="listitem">
Zadeh, L. A. (1989). Knowledge representation in fuzzy logic. <em>IEEE Transactions on Knowledge and Data Engineering</em>, <em>1</em>(1), 89–100. <a href="https://ieeexplore.ieee.org/document/43406">https://ieeexplore.ieee.org/document/43406</a>
</div>
<div id="ref-須山敦志2019" class="csl-entry" role="listitem">
須山敦志. (2019). <em>ベイズ深層学習</em>. 講談社サイエンティフィク. <a href="https://www.kspub.co.jp/book/detail/5168707.html">https://www.kspub.co.jp/book/detail/5168707.html</a>
</div>
<div id="ref-黒木学-小林史明2012" class="csl-entry" role="listitem">
黒木学, &amp; 小林史明. (2012). 構造的因果モデルについて. <em>計量生物学</em>, <em>32</em>(2), 119–144. <a href="https://www.jstage.jst.go.jp/article/jjb/32/2/32_119/_article/-char/ja/">https://www.jstage.jst.go.jp/article/jjb/32/2/32_119/_article/-char/ja/</a>
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><span class="citation" data-cites="Taroni+2014">(<a href="#ref-Taroni+2014" role="doc-biblioref">Taroni et al., 2014, p. 35</a>)</span>，<span class="citation" data-cites="Sucar2021">(<a href="#ref-Sucar2021" role="doc-biblioref">Sucar, 2021, p. x</a>)</span>, <span class="citation" data-cites="Clark2018">(<a href="#ref-Clark2018" role="doc-biblioref">Clark, 2018</a>)</span> <a href="https://m-clark.github.io/sem/graphical-models.html">Graphical Models</a>．<span class="citation" data-cites="Jordan+1999">(<a href="#ref-Jordan+1999" role="doc-biblioref">Jordan et al., 1999, p. 191</a>)</span> は 3.2節で Neural Networks as Graphical Models を扱っている．<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 3</a>)</span> 1.2.1，<span class="citation" data-cites="Murphy2023">(<a href="#ref-Murphy2023" role="doc-biblioref">Murphy, 2023, p. 143</a>)</span> 第4章．<span class="citation" data-cites="Balgi+2024">(<a href="#ref-Balgi+2024" role="doc-biblioref">Balgi et al., 2024</a>)</span> “As non-parametric causal models, DAGs require no assumptions about the functional form of the hypothesized relationships.”<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 1</a>)</span> 1.1 Motivation．<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>一般に，特定のタスクに特化しながら，汎用性も持つエキスパートシステムを構築するためには，<a href="https://ja.wikipedia.org/wiki/%E5%AE%A3%E8%A8%80%E5%9E%8B%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0">宣言型の知識表現</a> が良い接近として用いられる <span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 1</a>)</span> 1.1 Motivation．declarative representation の他に model-based approach ともいう．これは対象となるシステムの構造に関する知識を，計算機が理解可能な形で表現するモデルベースな接近であり，「知識」と「推論」という異なるタスクを分離する点に妙がある．<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 2</a>)</span> 1.1 Motivation．Probabilistic models allow us to make this fact (= many systems cannot be specified deterministically.) explicit, and therefore often provide a model which is more faithful to reality.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p><span class="citation" data-cites="Theodoridis2020">(<a href="#ref-Theodoridis2020" role="doc-biblioref">Theodoridis, 2020, p. 772</a>)</span> なども参照．<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>同様の用語の使い分けをしているものは，<span class="citation" data-cites="Bishop-Bishop2024">(<a href="#ref-Bishop-Bishop2024" role="doc-biblioref">Bishop &amp; Bishop, 2024, p. 353</a>)</span>，<span class="citation" data-cites="Theodoridis2020">(<a href="#ref-Theodoridis2020" role="doc-biblioref">Theodoridis, 2020, p. 878</a>)</span> など．<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p><span class="citation" data-cites="Murphy2023">(<a href="#ref-Murphy2023" role="doc-biblioref">Murphy, 2023, p. 211</a>)</span> 4.7節．<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, pp. 12–14</a>)</span> 1.4節 など．<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>一般に，SEM は <span class="citation" data-cites="Joreskog70">(<a href="#ref-Joreskog70" role="doc-biblioref">Jöreskog, 1970</a>)</span> が発祥と見られており，潜在変数モデルにもパス解析を拡張したもの，と説明される <span class="citation" data-cites="Clark2018">(<a href="#ref-Clark2018" role="doc-biblioref">Clark, 2018</a>)</span>．<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p><span class="citation" data-cites="黒木学-小林史明2012">(<a href="#ref-黒木学-小林史明2012" role="doc-biblioref">黒木学 &amp; 小林史明, 2012</a>)</span> など．<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, pp. 12–14</a>)</span> 1.4節．<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, pp. 5–6</a>)</span> 1.2.2節．高次元分布が成分間に依存を持つことと，その依存を用いてコンパクトに低次元で表現可能であることとは殆ど等価な事実である．<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 6</a>)</span> 1.2.2節．“Probabilistic graphical models support a data-driven approach to model construction that is very eﬀective in practice.”<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p><span class="citation" data-cites="Bishop2006">(<a href="#ref-Bishop2006" role="doc-biblioref">Bishop, 2006, p. 46</a>)</span> などでも紹介されている．<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 57</a>)</span><a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p><span class="citation" data-cites="須山敦志2019">(<a href="#ref-須山敦志2019" role="doc-biblioref">須山敦志, 2019, p. 4</a>)</span>, <span class="citation" data-cites="Li2009">(<a href="#ref-Li2009" role="doc-biblioref">Li, 2009, p. 48</a>)</span>．<a href="https://en.wikipedia.org/wiki/Bayesian_network">Wikipedia</a> も参照．<a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 57</a>)</span><a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn19"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 60</a>)</span><a href="#fnref19" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 60</a>)</span><a href="#fnref20" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn21"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 62</a>)</span><a href="#fnref21" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn22"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 62</a>)</span> 定理3.1，定理3.2 p.63．<span class="citation" data-cites="Howard-Matheson1984">(<a href="#ref-Howard-Matheson1984" role="doc-biblioref">Howard &amp; Matheson, 1984</a>)</span> による．<a href="#fnref22" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn23"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 68</a>)</span><a href="#fnref23" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn24"><p>これを trail が active である，ともいう．<span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 71</a>)</span>．<a href="#fnref24" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn25"><p>この語は directed separation の略であり <span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 71</a>)</span>，和語では <strong>有向分離</strong> ともいう．<a href="#fnref25" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn26"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 71</a>)</span><a href="#fnref26" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn27"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, pp. 71–72</a>)</span> 定義3.6, 3.7．<a href="#fnref27" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn28"><p><span class="math inline">\(I(\boldsymbol{X},\boldsymbol{Y}|\boldsymbol{Z})_\mathcal{G}\)</span> と表すこともある．<a href="#fnref28" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn29"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, pp. 72–73</a>)</span> 定理3.3, 3.5．<a href="#fnref29" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn30"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 78</a>)</span> 3.4節 の内容．<a href="#fnref30" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn31"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 76</a>)</span> 定義3.9．<a href="#fnref31" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn32"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 77</a>)</span> 定理3.7．<a href="#fnref32" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn33"><p>有向グラフの <strong>スケルトン</strong> とは，同じ辺を持つ無向グラフのことである．<a href="#fnref33" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn34"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 77</a>)</span> 定理3.8．<a href="#fnref34" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn35"><p><span class="citation" data-cites="Diestel2017">(<a href="#ref-Diestel2017" role="doc-biblioref">Diestel, 2017, pp. 1–2</a>)</span> 参照．<a href="#fnref35" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn36"><p><span class="citation" data-cites="Diestel2017">(<a href="#ref-Diestel2017" role="doc-biblioref">Diestel, 2017, p. 3</a>)</span> 参照．<a href="#fnref36" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn37"><p><span class="citation" data-cites="Diestel2017">(<a href="#ref-Diestel2017" role="doc-biblioref">Diestel, 2017, p. 135</a>)</span> 参照．<a href="#fnref37" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn38"><p>すなわち，三角形以外の <a href="https://ja.wikipedia.org/wiki/%E8%AA%98%E5%B0%8E%E9%83%A8%E5%88%86%E3%82%B0%E3%83%A9%E3%83%95">誘導部分グラフ</a> を部分グラフに持たないグラフをいう．<span class="citation" data-cites="Diestel2017">(<a href="#ref-Diestel2017" role="doc-biblioref">Diestel, 2017, p. 135</a>)</span> 参照．<a href="#fnref38" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn39"><p><span class="citation" data-cites="Sucar2021">(<a href="#ref-Sucar2021" role="doc-biblioref">Sucar, 2021, p. 94</a>)</span> も参照．<span class="citation" data-cites="Li2009">(<a href="#ref-Li2009" role="doc-biblioref">Li, 2009, p. 47</a>)</span> は，pairwise なマルコフ確率場もマルコフネットワークと見れることを指摘している．pairwise とは非零なポテンシャルを持つクリークが二点集合になるマルコフ確率場をいう．<a href="#fnref39" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn40"><p><span class="citation" data-cites="Kindermann-Snell1980">(<a href="#ref-Kindermann-Snell1980" role="doc-biblioref">Kindermann &amp; Snell, 1980, p. 1</a>)</span><a href="#fnref40" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn41"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 106</a>)</span> 4.2節．<a href="#fnref41" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn42"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 104</a>)</span> 定義4.1．<a href="#fnref42" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn43"><p>ただし，<span class="math inline">\(\phi_1(X_a)\)</span> とは <span class="math inline">\(\phi_1((X_i)_{i\in a})\)</span> の略とした．<a href="#fnref43" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn44"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 108</a>)</span> 定義4.3．<a href="#fnref44" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn45"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 105</a>)</span> によると，当初統計物理学の分野の Markov 確率場の概念でこの用語が用いられたことが始まりとなっている．<a href="#fnref45" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn46"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, pp. 114–115</a>)</span> 定義4.8, 9．<a href="#fnref46" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn47"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, pp. 116–117</a>)</span> 定理4.1，定理4.2．<a href="#fnref47" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn48"><p><span class="citation" data-cites="Li2009">(<a href="#ref-Li2009" role="doc-biblioref">Li, 2009</a>)</span> の Rama Chellappa による foreword に “A big impetus to theoretical and practical considerations of 2D spatial interaction models, of which MRF’s form a subclass, was given by the seminal works of Julian Besag.” とある．“Labeling is also a natural representation for the study of MRF’s (Besag 1974).” は <span class="citation" data-cites="Li2009">(<a href="#ref-Li2009" role="doc-biblioref">Li, 2009, p. 3</a>)</span>．<a href="#fnref48" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn49"><p><span class="citation" data-cites="Robert-Casella2011">(<a href="#ref-Robert-Casella2011" role="doc-biblioref">Robert &amp; Casella, 2011</a>)</span> <span class="citation" data-cites="Li2009">(<a href="#ref-Li2009" role="doc-biblioref">Li, 2009, p. 1</a>)</span> も参照．<a href="#fnref49" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn50"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 117</a>)</span> 定理4.3．<a href="#fnref50" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn51"><p>これは台が縮退している場合は，自明な（決定論的な）独立性が生じてしまうためである．<a href="#fnref51" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn52"><p><span class="citation" data-cites="Koller-Friedman2009">(<a href="#ref-Koller-Friedman2009" role="doc-biblioref">Koller &amp; Friedman, 2009, p. 123</a>)</span> 4.4.1.1．<a href="#fnref52" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/162348\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="quarto-dev/quarto-web" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->




</body></html>