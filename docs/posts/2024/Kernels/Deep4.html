<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="司馬博文">

<title>Hirofumi Shiba - VAE：変分自己符号化器</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../profile.jpg" rel="icon" type="image/jpeg">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "?",
    "H"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-36GX2G6GLL"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-36GX2G6GLL', { 'anonymize_ip': true});
</script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Zen+Kurenaido&amp;display=swap" rel="stylesheet">

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=BIZ+UDPGothic&amp;display=swap" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Hirofumi Shiba - VAE：変分自己符号化器">
<meta property="og:description" content="変分自己符号化器 (VAE) は，データを周辺分布にもつ潜在変数モデルを変分 Bayes 推論によって学習するアルゴリズムである． 従来計算・近似が困難であった変分下界を，ニューラルネットワークによって近似するアプローチである． 学習されたベイズ潜在変数モデルからはサンプリングによって新たなデータを生成することができるため，深層生成モデルの一つに分類されることもある．">
<meta property="og:image" content="https://162348.github.io/posts/2024/Kernels/profile.jpg">
<meta property="og:site_name" content="Hirofumi Shiba">
<meta name="twitter:title" content="Hirofumi Shiba - VAE：変分自己符号化器">
<meta name="twitter:description" content="変分自己符号化器 (VAE) は，データを周辺分布にもつ潜在変数モデルを変分 Bayes 推論によって学習するアルゴリズムである． 従来計算・近似が困難であった変分下界を，ニューラルネットワークによって近似するアプローチである． 学習されたベイズ潜在変数モデルからはサンプリングによって新たなデータを生成することができるため，深層生成モデルの一つに分類されることもある．">
<meta name="twitter:image" content="https://162348.github.io/posts/2024/Kernels/profile.jpg">
<meta name="twitter:creator" content="@ano2math5">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Hirofumi Shiba</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Sessions.html"> 
<span class="menu-text">Sessions</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Slides.html"> 
<span class="menu-text">Slides</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Japanese.html"> 
<span class="menu-text">自己紹介</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
    <a href="https://github.com/162348/162348.github.io/" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">VAE：変分自己符号化器</h1>
            <p class="subtitle lead">深層生成モデル３</p>
                                <div class="quarto-categories">
                <div class="quarto-category">Deep</div>
                <div class="quarto-category">Sampling</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>司馬博文 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">2/18/2024</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">7/28/2024</p>
      </div>
    </div>
      
    </div>
    
  <div>
    <div class="abstract">
      <div class="block-title">概要</div>
      <p>変分自己符号化器 (VAE) は，データを周辺分布にもつ潜在変数モデルを変分 Bayes 推論によって学習するアルゴリズムである． 従来計算・近似が困難であった変分下界を，ニューラルネットワークによって近似するアプローチである． 学習されたベイズ潜在変数モデルからはサンプリングによって新たなデータを生成することができるため，深層生成モデルの一つに分類されることもある．</p>
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">目次</h2>
   
  <ul>
  <li><a href="#確率的勾配変分近似-sgvb" id="toc-確率的勾配変分近似-sgvb" class="nav-link active" data-scroll-target="#確率的勾配変分近似-sgvb"><span class="header-section-number">1</span> 確率的勾配変分近似 (SGVB)</a>
  <ul class="collapse">
  <li><a href="#導入" id="toc-導入" class="nav-link" data-scroll-target="#導入"><span class="header-section-number">1.1</span> 導入</a></li>
  <li><a href="#sgvb-のアイデア勾配の-monte-carlo-推定" id="toc-sgvb-のアイデア勾配の-monte-carlo-推定" class="nav-link" data-scroll-target="#sgvb-のアイデア勾配の-monte-carlo-推定"><span class="header-section-number">1.2</span> SGVB のアイデア：勾配の Monte Carlo 推定</a></li>
  <li><a href="#変分下界の復習" id="toc-変分下界の復習" class="nav-link" data-scroll-target="#変分下界の復習"><span class="header-section-number">1.3</span> 変分下界の復習</a></li>
  <li><a href="#sgvb-推定量" id="toc-sgvb-推定量" class="nav-link" data-scroll-target="#sgvb-推定量"><span class="header-section-number">1.4</span> SGVB 推定量</a></li>
  </ul></li>
  <li><a href="#sec-VAE" id="toc-sec-VAE" class="nav-link" data-scroll-target="#sec-VAE"><span class="header-section-number">2</span> 変分自己符号化器 (VAE) <span class="citation" data-cites="Kingma-Welling2014">(Kingma and Welling, 2014)</span></a>
  <ul class="collapse">
  <li><a href="#導入-1" id="toc-導入-1" class="nav-link" data-scroll-target="#導入-1"><span class="header-section-number">2.1</span> 導入</a></li>
  <li><a href="#sec-VQ-VAE" id="toc-sec-VQ-VAE" class="nav-link" data-scroll-target="#sec-VQ-VAE"><span class="header-section-number">2.2</span> VQ-VAE による画像の量子化</a></li>
  <li><a href="#wasserstein-vae-tolstikhin2018" id="toc-wasserstein-vae-tolstikhin2018" class="nav-link" data-scroll-target="#wasserstein-vae-tolstikhin2018"><span class="header-section-number">2.3</span> Wasserstein VAE <span class="citation" data-cites="Tolstikhin+2018">(Tolstikhin et al., 2018)</span></a></li>
  <li><a href="#beta-vae-higgins2017" id="toc-beta-vae-higgins2017" class="nav-link" data-scroll-target="#beta-vae-higgins2017"><span class="header-section-number">2.4</span> beta-VAE <span class="citation" data-cites="Higgins+2017">(Higgins et al., 2017)</span></a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="確率的勾配変分近似-sgvb" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="確率的勾配変分近似-sgvb"><span class="header-section-number">1</span> 確率的勾配変分近似 (SGVB)</h2>
<section id="導入" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="導入"><span class="header-section-number">1.1</span> 導入</h3>
<p>変分自己符号化器 (Variational Auto-encoder) （第 <a href="#sec-VAE" class="quarto-xref">2</a> ）では，</p>
<p>に入る前に，変分ベイズ法において勾配を用いた最適化を実行するための汎用手法である <strong>SGVB (Stochastic Gradient Variational Bayes)</strong> について説明する．</p>
<p>VAE は元々この SGVB という要素技術とセットで提案された <span class="citation" data-cites="Kingma-Welling2014">(<a href="#ref-Kingma-Welling2014" role="doc-biblioref">Kingma and Welling, 2014</a>)</span>．</p>
<p>変分近似をする分布族 <span class="math inline">\(\{q_\phi\}\)</span> としてニューラルネットを用いた場合が VAE であり，広く SGVB は，一般の連続な潜在変数を持った（有向）グラフィカルモデルに適用できる．</p>
</section>
<section id="sgvb-のアイデア勾配の-monte-carlo-推定" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="sgvb-のアイデア勾配の-monte-carlo-推定"><span class="header-section-number">1.2</span> SGVB のアイデア：勾配の Monte Carlo 推定</h3>
<p><a href="../../../posts/2024/Kernels/Deep3.html">GAN</a> 同様，生成モデリングは，潜在空間 <span class="math inline">\(Z\)</span> で条件付けた際の分布 <span class="math inline">\(p(x|z)\)</span> をモデリングすることに等しい．GAN は <span class="math inline">\(p(x|z)\)</span> を明示的に評価することを回避することで複雑な生成モデリングを達成していた．</p>
<p>一方で，（周辺）尤度の評価を完全に回避せずとも，<a href="../../../posts/2024/Computation/VI3.html">変分 Bayes 法</a> によるアプローチが可能である．<span class="math inline">\(p(x|z)\)</span> に分布族 <span class="math inline">\(q_\phi(x|z)\)</span> を導入し，真の分布 <span class="math inline">\(p\)</span> との KL-距離を最小にする <span class="math inline">\(\phi\in\Phi\)</span> を選ぶのである．</p>
<p>変分 Bayes ではこれを解析的に実行する必要があった．そのため，分布族 <span class="math inline">\(\{q_\phi\}\)</span> を指数分布族や共役分布族に限るか，平均場近似を用いるか，などの強い仮定が必要で，これが複雑な生成モデリングを妨げていた．<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>そこで，一般の分布族 <span class="math inline">\(\{q_\phi\}\)</span> に対して勾配情報を用いた最適化が実施できるように，変分下界 <span class="math inline">\(F(p_\theta,q_\phi)\)</span> 対する Monte Carlo 推定量を開発するのである．これが SGVB 推定量である．</p>
</section>
<section id="変分下界の復習" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="変分下界の復習"><span class="header-section-number">1.3</span> 変分下界の復習</h3>
<p>データ <span class="math inline">\(X\)</span> の生成過程に，モデル <span class="math inline">\(p_\theta(z)p_\theta(x|z)\)</span> を考える．これがニューラルネットワークによるモデルであるとすると，周辺尤度 <span class="math display">\[
p_\theta(x)=\int_\mathcal{Z}p_\theta(z)p_\theta(x|z)\,dz
\]</span> や事後分布 <span class="math inline">\(p_\theta(z|x)\)</span> の評価は容易でない．</p>
<p>そこで，<span class="math inline">\(p_\theta(z|x)\)</span> に対して，認識モデル <span class="math inline">\(\{q_\phi(z|x)\}_{\phi\in\Phi}\)</span> を導入する．VAE <a href="#sec-VAE" class="quarto-xref">2</a> では，これもニューラルネットワークとし，<span class="math inline">\((\theta,\phi)\in\Theta\times\Phi\)</span> を同時に SGD により学習することを考える．</p>
<p>潜在変数 <span class="math inline">\(Z\)</span> を情報源と見て，<span class="math inline">\(q_\theta(z|x)\)</span> を <strong>符号化器</strong> (encoder) と呼び，<span class="math inline">\(p_\theta(x|z)\)</span> を <strong>復号器</strong> (decoder) とも呼ぶ．</p>
<p>このとき，対数周辺尤度の変分下界は次のように表せるのであった：<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> <span class="math display">\[
\begin{align*}
    \log p_\theta(x)&amp;=\log\int_\mathcal{Z}p_\theta(x,z)\,dz\\
    &amp;=\log\int_\mathcal{Z}q_\phi(z)\frac{p_\theta(x,z)}{q_\phi(z)}\,dz\\
    &amp;\ge\int_\mathcal{Z}q_\phi(z)\log\frac{q_\theta(x|z)p_\theta(z)}{q_\phi(z)}\,dz\\
    &amp;=-\operatorname{KL}(q_\phi,p_\theta)+\int_\mathcal{Z}q_\phi(z)\log p_\theta(x|z)\,dz\\
    &amp;=:F(\theta,\phi;x)
\end{align*}
\]</span></p>
<p>この <span class="math inline">\(F\)</span> を <span class="math inline">\(\theta,\phi\)</span> に関して逐次的に最大化するのが変分 Bayes である．これを実行するために <span class="math inline">\(q_\phi\)</span> に平均場近似などをするのが旧来手法であるが，これ以上の近似をせずとも，<span class="math inline">\(F\)</span> の勾配の推定量を用いて，<span class="math inline">\(p_\theta,q_\phi\)</span> を同時に学習することが出来るというのである．</p>
</section>
<section id="sgvb-推定量" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="sgvb-推定量"><span class="header-section-number">1.4</span> SGVB 推定量</h3>
<p>例えば <span class="math inline">\(F\)</span> を <span class="math inline">\(\phi\)</span> に関して勾配情報から最大化する際に，勾配 <span class="math inline">\(D_\phi F\)</span> の Monte Carlo 推定量が利用できる．しかし，単に <span class="math inline">\(q_\phi(z|x)\)</span> からのサンプルを用いた crude Monte Carlo では，この推定量の分散は非常に大きい <span class="citation" data-cites="Paisley+2012">(<a href="#ref-Paisley+2012" role="doc-biblioref">Paisley et al., 2012</a>)</span>．</p>
<p>これを <strong>重点サンプリングの考え方により解決した</strong> のが <span class="math inline">\(D_\phi F,D_\theta F\)</span> に対する SGVB 推定量である．<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> <span class="citation" data-cites="Kingma-Welling2014">(<a href="#ref-Kingma-Welling2014" role="doc-biblioref">Kingma and Welling, 2014</a>)</span> では reparameterization trick と呼んでいる．</p>
<p>ある分布 <span class="math inline">\(P\in\mathcal{P}(E)\)</span> と可微分同相 <span class="math inline">\(g_\phi:E\times\mathcal{X}\to\mathcal{Z}\)</span> であって <span class="math display">\[
g_\phi(\epsilon,x)\sim q_\phi(z,x)\quad(\epsilon\sim P)
\]</span> を満たすものを見つけることができて，この <span class="math inline">\(P\)</span> を提案分布とする重点サンプリング推定量 <span class="math display">\[
\begin{align*}
    \operatorname{E}_{q_\phi}[f(Z)]&amp;=\operatorname{E}_{P}[f(g_\phi(\epsilon,x))]\\
    &amp;\simeq\frac{1}{M}\sum_{i=1}^Mf(g_\phi(\epsilon^i,x))
\end{align*}
\]</span> により，Monte Carlo 推定量の分散を減らすことができる．<span class="math inline">\(f=F\)</span> と取ることで SGVB 推定量を得る．</p>
<p>さらに，<span class="math inline">\(\mathcal{Z}\)</span> 上のモデル <span class="math inline">\(q_\phi(z),p_\theta(z)\)</span> とが <span class="math inline">\(d\)</span>-次元の正規分布であった場合， <span class="math display">\[
-\operatorname{KL}(q_\phi,p_\theta)=\frac{1}{2}\sum_{j=1}^d\biggr(1+\log(\sigma_j^2)-\mu_j^2-\sigma_j^2\biggl)
\]</span> と解析的に解けるので，結局 Monte Carlo 近似が必要なのは，再構成誤差を表す <span class="math display">\[
\int_\mathcal{Z}q_\phi(z)\log p_\theta(x|z)\,dz
\]</span> の部分だけである．</p>
<p>このような理由で，<span class="math inline">\(q_\phi(z),p_\theta(z)\)</span> は典型的には正規分布としてモデリングされる．</p>
</section>
</section>
<section id="sec-VAE" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="sec-VAE"><span class="header-section-number">2</span> 変分自己符号化器 (VAE) <span class="citation" data-cites="Kingma-Welling2014">(<a href="#ref-Kingma-Welling2014" role="doc-biblioref">Kingma and Welling, 2014</a>)</span></h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="VAE.png" class="img-fluid figure-img"></p>
<figcaption>Samples from a VQ-VAE Taken from Figure 6 <span class="citation" data-cites="Razavi+2019">(<a href="#ref-Razavi+2019" role="doc-biblioref">Razavi et al., 2019, p. 8</a>)</span></figcaption>
</figure>
</div>
<section id="導入-1" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="導入-1"><span class="header-section-number">2.1</span> 導入</h3>
<p>Variational Auto-encoder <span class="citation" data-cites="Kingma-Welling2014">(<a href="#ref-Kingma-Welling2014" role="doc-biblioref">Kingma and Welling, 2014</a>)</span>, <span class="citation" data-cites="Rezende+2014">(<a href="#ref-Rezende+2014" role="doc-biblioref">Rezende et al., 2014</a>)</span> も GAN と同じく，深層生成モデル <span class="math inline">\(p_\theta\)</span> にもう１つの深層ニューラルネットワーク <span class="math inline">\(q_\phi\)</span> を対置するが，このニューラルネット <span class="math inline">\(q_\phi\)</span> は GAN のように判別をするのではなく，近似推論によってデータ生成源を再構成しようとする <strong>認識モデル</strong> (recognition model) である．<span class="math inline">\(q_\phi\)</span> はエンコーダーとも呼ばれる．</p>
<p>この深層生成モデル <span class="math inline">\(p_\theta\)</span> と近似推論器 <span class="math inline">\(q_\phi\)</span> とを，同時に確率勾配降下法によって学習する <span class="citation" data-cites="Kingma-Welling2019">(<a href="#ref-Kingma-Welling2019" role="doc-biblioref">Kingma and Welling, 2019</a>)</span>．</p>
<p>VAE のエンコーダー <span class="math inline">\(q_\phi\)</span> は動画データの圧縮表現の学習 <span class="citation" data-cites="Brooks+2024">(<a href="#ref-Brooks+2024" role="doc-biblioref">Brooks et al., 2024</a>)</span> など，その他の生成モデルの構成要素としても用いられる．</p>
</section>
<section id="sec-VQ-VAE" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="sec-VQ-VAE"><span class="header-section-number">2.2</span> VQ-VAE による画像の量子化</h3>
<p>VAE は画像データの生成にも応用されており，その際のデータ圧縮の技術（連続データである画像を離散化するので，<strong>ベクトル量子化</strong> と呼ばれる）だけが取り出され，DALL-E <span class="citation" data-cites="Ramesh+2021">(<a href="#ref-Ramesh+2021" role="doc-biblioref">Ramesh et al., 2021</a>)</span> など，モデルの構成要素としても利用されている．</p>
<section id="vq-vae" class="level4" data-number="2.2.1">
<h4 data-number="2.2.1" class="anchored" data-anchor-id="vq-vae"><span class="header-section-number">2.2.1</span> VQ-VAE</h4>
<p>VQ-VAE <span class="citation" data-cites="vandenOord+2017">(<a href="#ref-vandenOord+2017" role="doc-biblioref">van&nbsp;den&nbsp;Oord et al., 2017</a>)</span>, <span class="citation" data-cites="Razavi+2019">(<a href="#ref-Razavi+2019" role="doc-biblioref">Razavi et al., 2019</a>)</span> は，自己符号化器の中間表現に <a href="../../../posts/2024/Computation/VI.html#sec-history">ベクトル量子化</a> を施し，JPEG <span class="citation" data-cites="Wallace1992">(<a href="#ref-Wallace1992" role="doc-biblioref">Wallace, 1992</a>)</span> のような画像データの圧縮を行うことで，不要な情報のモデリングを回避している．</p>
<p>実際，元データの 30 分の 1 以下のサイズで学習を行い，最終的にデコーダーを用いて殆ど歪みなく再構成できるという．</p>
<p>GAN は元データのうち，尤度が低い部分が無視され，サンプルの多様性が失われがちであったが，VQ-VAE はこの問題を解決している．また，GAN にはないようなモデル評価の指標が複数提案されている．</p>
</section>
<section id="連続緩和" class="level4" data-number="2.2.2">
<h4 data-number="2.2.2" class="anchored" data-anchor-id="連続緩和"><span class="header-section-number">2.2.2</span> 連続緩和</h4>
<p>質的変数のサンプリングにおいて，Gumbel 分布を提案分布として重点サンプリングを行うことが有効である．この reparametrization trick を Gumbel Max Trick <span class="citation" data-cites="Jang+2017">(<a href="#ref-Jang+2017" role="doc-biblioref">Jang et al., 2017</a>)</span> という．</p>
<p>Concrete (Continuous Relaxatino of Discrete) <span class="citation" data-cites="Maddison+2017">(<a href="#ref-Maddison+2017" role="doc-biblioref">Maddison et al., 2017</a>)</span> はこれを連続分布に拡張し，reparametrization trick に応用したものである．</p>
<p>これらの手法は VAE や <a href="https://openai.com/research/dall-e">DALL-E</a> <span class="citation" data-cites="Ramesh+2021">(<a href="#ref-Ramesh+2021" role="doc-biblioref">Ramesh et al., 2021</a>)</span> の訓練にも応用されている．</p>
</section>
<section id="codebook-collapse" class="level4" data-number="2.2.3">
<h4 data-number="2.2.3" class="anchored" data-anchor-id="codebook-collapse"><span class="header-section-number">2.2.3</span> Codebook collapse</h4>
<p>VQ-VAE は符号帳 (codebook) に冗長性が生まれ，符号帳の一部が使われなくなるという問題がある．これを解決するためには，符号帳への対応を softmax 関数を用いて軟化することが dVAE <span class="citation" data-cites="Ramesh+2021">(<a href="#ref-Ramesh+2021" role="doc-biblioref">Ramesh et al., 2021</a>)</span> として考えられている．</p>
<p>しかしこの dVAE も codebook collapse から完全に解放されるわけではない．これは softmax 関数の性質によると考えられ，実際，Dirichlet 事前分布を導入した Bayes モデルによって緩和される <span class="citation" data-cites="Baykal+2023">(<a href="#ref-Baykal+2023" role="doc-biblioref">Baykal et al., 2023</a>)</span>．</p>
<p>このような技術を <strong>エビデンス付き深層学習</strong> (EDL: Evidential Deep Learning) <span class="citation" data-cites="Sensoy+2018">(<a href="#ref-Sensoy+2018" role="doc-biblioref">Sensoy et al., 2018</a>)</span>, <span class="citation" data-cites="Amini+2020">(<a href="#ref-Amini+2020" role="doc-biblioref">Amini et al., 2020</a>)</span> という．<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
</section>
</section>
<section id="wasserstein-vae-tolstikhin2018" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="wasserstein-vae-tolstikhin2018"><span class="header-section-number">2.3</span> Wasserstein VAE <span class="citation" data-cites="Tolstikhin+2018">(<a href="#ref-Tolstikhin+2018" role="doc-biblioref">Tolstikhin et al., 2018</a>)</span></h3>
<p>VAE は GAN よりも画像生成時の解像度が劣るという問題がある．</p>
<p>これを，目的関数を Wasserstein 距離に基づいて再定式化することで解決できるというのが Wasserstein Auto-encoder <span class="citation" data-cites="Tolstikhin+2018">(<a href="#ref-Tolstikhin+2018" role="doc-biblioref">Tolstikhin et al., 2018</a>)</span> である．</p>
</section>
<section id="beta-vae-higgins2017" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="beta-vae-higgins2017"><span class="header-section-number">2.4</span> beta-VAE <span class="citation" data-cites="Higgins+2017">(<a href="#ref-Higgins+2017" role="doc-biblioref">Higgins et al., 2017</a>)</span></h3>
<p>VAE を画像の因子表現学習に用いる際に，解釈可能性を担保する教師なし学習手法である．</p>



</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-Amini+2020" class="csl-entry" role="listitem">
Amini, A., Schwarting, W., Soleimany, A., and Rus, D. (2020). <a href="https://arxiv.org/abs/1910.02600">Deep evidential regression</a>.
</div>
<div id="ref-Baykal+2023" class="csl-entry" role="listitem">
Baykal, G., Kandemir, M., and Unal, G. (2023). <a href="https://arxiv.org/abs/2310.05718">EdVAE: Mitigating codebook collapse with evidential discrete variational autoencoders</a>.
</div>
<div id="ref-Brooks+2024" class="csl-entry" role="listitem">
Brooks, T., Peebles, B., Holmes, C., DePue, W., Guo, Y., Jing, L., … Ramesh, A. (2024). <em>Video generation models as world simulators</em>. OpenAI. Retrieved from <a href="https://openai.com/research/video-generation-models-as-world-simulators">https://openai.com/research/video-generation-models-as-world-simulators</a>
</div>
<div id="ref-Geyer1996" class="csl-entry" role="listitem">
Geyer, C. (1996). <a href="https://www.taylorfrancis.com/books/mono/10.1201/b14835/markov-chain-monte-carlo-practice-david-spiegelhalter-gilks-richardson">Markov chain monte carlo in practice</a>. In W. R. Gilks, S. Richardson, and D. Spiegelhalter, editors, pages 241–258. Chapman; Hall.
</div>
<div id="ref-Higgins+2017" class="csl-entry" role="listitem">
Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Botvinick, M., … Lerchner, A. (2017). <a href="https://openreview.net/forum?id=Sy2fzU9gl">Beta-<span>VAE</span>: Learning basic visual concepts with a constrained variational framework</a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Jang+2017" class="csl-entry" role="listitem">
Jang, E., Gu, S., and Poole, B. (2017). <a href="https://openreview.net/forum?id=rkE3y85ee">Categorical reparameterization with gumbel-softmax</a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Kingma-Welling2014" class="csl-entry" role="listitem">
Kingma, D., and Welling, M. (2014). <a href="https://openreview.net/forum?id=33X9fd2-9FyZd">Auto-encoding variational bayes</a>. In <em>International conference on learning representations</em>,Vol. 2.
</div>
<div id="ref-Kingma-Welling2019" class="csl-entry" role="listitem">
Kingma, D., and Welling, M. (2019). <a href="https://www.nowpublishers.com/article/Details/MAL-056">An introduction to variational autoencoders</a>. <em>Foundations and Treands in Machine Learning</em>, <em>12</em>(4), 307–392.
</div>
<div id="ref-Maddison+2017" class="csl-entry" role="listitem">
Maddison, C. J., Mnih, A., and Teh, Y. W. (2017). <a href="https://openreview.net/forum?id=S1jE5L5gl">The concrete distribution: A continuous relaxation of discrete random variables</a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Paisley+2012" class="csl-entry" role="listitem">
Paisley, J., Blei, D. M., and Jordan, M. I. (2012). <a href="https://dl.acm.org/doi/10.5555/3042573.3042748">Variational bayesian inference with stochastic search</a>. In <em>Proceedings of the 29th international conference on machine learning</em>, pages 1363–1370.
</div>
<div id="ref-Ramesh+2021" class="csl-entry" role="listitem">
Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., … Sutskever, I. (2021). <a href="https://proceedings.mlr.press/v139/ramesh21a.html">Zero-shot text-to-image generation</a>. In M. Meila and T. Zhang, editors, <em>Proceedings of the 38th international conference on machine learning</em>,Vol. 139, pages 8821–8831. PMLR.
</div>
<div id="ref-Razavi+2019" class="csl-entry" role="listitem">
Razavi, A., van&nbsp;den&nbsp;Oord, A., and Vinyals, O. (2019). <a href="https://papers.nips.cc/paper_files/paper/2019/hash/5f8e2fa1718d1bbcadf1cd9c7a54fb8c-Abstract.html">Generating diverse high-fidelity images with VQ-VAE-2</a>. In <em>Advances in neural information processing systems</em>,Vol. 32.
</div>
<div id="ref-Rezende+2014" class="csl-entry" role="listitem">
Rezende, D. J., Mohamed, S., and Wierstra, D. (2014). <a href="https://proceedings.mlr.press/v32/rezende14.html">Approximate inference in deep generative models</a>. In <em>Proceedings of the 31st international conference on machine learning</em>,Vol. 32, pages 1278–1286.
</div>
<div id="ref-Robert-Casella2004" class="csl-entry" role="listitem">
Robert, C. P., and Casella, G. (2004). <em>Monte carlo statistical methods</em>. Springer New York.
</div>
<div id="ref-Sensoy+2018" class="csl-entry" role="listitem">
Sensoy, M., Kaplan, L., and Kandemir, M. (2018). <a href="https://proceedings.neurips.cc/paper_files/paper/2018/file/a981f2b708044d6fb4a71a1463242520-Paper.pdf">Evidential deep learning to quantify classification uncertainty</a>. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, <em>Advances in neural information processing systems</em>,Vol. 31. Curran Associates, Inc.
</div>
<div id="ref-Tolstikhin+2018" class="csl-entry" role="listitem">
Tolstikhin, I., Bousquet, O., Gelly, S., and Schoelkopf, B. (2018). <a href="https://openreview.net/forum?id=HkL7n1-0b">Wasserstein auto-encoders</a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-vandenOord+2017" class="csl-entry" role="listitem">
van&nbsp;den&nbsp;Oord, A., Vinyals, O., and Kavukcuoglu, K. (2017). <a href="https://papers.nips.cc/paper_files/paper/2017/hash/7a98af17e63a0ac09ce2e96d03992fbc-Abstract.html">Neural discrete representation learning</a>. In <em>Advances in neural information processing systems</em>,Vol. 30.
</div>
<div id="ref-Wallace1992" class="csl-entry" role="listitem">
Wallace, G. K. (1992). <a href="https://ieeexplore.ieee.org/document/125072">The JPEG still picture compression standard</a>. In <em>IEEE transactions on consumer electronics</em>,Vol. 38, page 1.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>なお，平均場近似も極めて困難な解析的計算を必要とする <span class="citation" data-cites="Kingma-Welling2014">(<a href="#ref-Kingma-Welling2014" role="doc-biblioref">Kingma and Welling, 2014</a>)</span>．<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><a href="../../../posts/2024/Computation/VI3.html#sec-ELBO">前稿</a> も参照．<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>最適化の文脈において，目的関数の評価が困難であるとき，Monte Carlo 推定量でこれを代替する際，重点サンプリングを用いると良いことは従来提案されている <span class="citation" data-cites="Geyer1996">(<a href="#ref-Geyer1996" role="doc-biblioref">Geyer, 1996</a>)</span>．<span class="citation" data-cites="Robert-Casella2004">(<a href="#ref-Robert-Casella2004" role="doc-biblioref">Robert and Casella, 2004, p. 203</a>)</span> も参照．<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><a href="https://deepsquare.jp/2020/12/deep-evidential-regression/">Present Square 記事</a>，<a href="https://gigazine.net/news/20201130-neural-network-trust/">GIGAZINE 記事</a> もある．<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
      for (let i=0; i<annoteTargets.length; i++) {
        const annoteTarget = annoteTargets[i];
        const targetCell = annoteTarget.getAttribute("data-target-cell");
        const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
        const contentFn = () => {
          const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          if (content) {
            const tipContent = content.cloneNode(true);
            tipContent.classList.add("code-annotation-tip-content");
            return tipContent.outerHTML;
          }
        }
        const config = {
          allowHTML: true,
          content: contentFn,
          onShow: (instance) => {
            selectCodeLines(instance.reference);
            instance.reference.classList.add('code-annotation-active');
            window.tippy.hideAll();
          },
          onHide: (instance) => {
            unselectCodeLines();
            instance.reference.classList.remove('code-annotation-active');
          },
          maxWidth: 300,
          delay: [50, 0],
          duration: [200, 0],
          offset: [5, 10],
          arrow: true,
          trigger: 'click',
          appendTo: function(el) {
            return el.parentElement.parentElement.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto',
          placement: 'right',
          positionFixed: true,
          popperOptions: {
            modifiers: [
            {
              name: 'flip',
              options: {
                flipVariations: false, // true by default
                allowedAutoPlacements: ['right'],
                fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
              },
            },
            {
              name: 'preventOverflow',
              options: {
                mainAxis: false,
                altAxis: false
              }
            }
            ]        
          }      
        };
        window.tippy(annoteTarget, config); 
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="162348/162348.github.io" data-repo-id="R_kgDOKlfKYQ" data-category="Announcements" data-category-id="DIC_kwDOKlfKYc4CgDmb" data-mapping="pathname" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" data-loading="lazy" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://162348.github.io/">
<p>Hirofumi Shiba</p>
</a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/162348/162348.github.io/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/ano2math5">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:shiba.hirofumi@ism.ac.jp">
      <i class="bi bi-envelope" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="../../../blog.xml">
      <i class="bi bi-rss" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>