<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="司馬博文">
<meta name="dcterms.date" content="2024-02-18">

<title>Hirofumi Shiba - 数学者のための深層学習４</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../profile.jpg" rel="icon" type="image/jpeg">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-36GX2G6GLL"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-36GX2G6GLL', { 'anonymize_ip': true});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Hirofumi Shiba - 数学者のための深層学習４">
<meta property="og:description" content="A Blog by a Bayesian Computation Researcher">
<meta property="og:image" content="https://162348.github.io/posts/2024/Kernels/VAE.png">
<meta property="og:site-name" content="Hirofumi Shiba">
<meta property="og:image:height" content="535">
<meta property="og:image:width" content="857">
<meta name="twitter:title" content="Hirofumi Shiba - 数学者のための深層学習４">
<meta name="twitter:description" content="深層生成モデルの１つ VAE は，統計モデルとしては変分 Bayes 推論アルゴリズムであり，変分下界をニューラルネットワークによって近似するというアプローチである．">
<meta name="twitter:image" content="https://162348.github.io/posts/2024/Kernels/VAE.png">
<meta name="twitter:image-height" content="535">
<meta name="twitter:image-width" content="857">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Hirofumi Shiba</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../recent.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Sessions.html" rel="" target="">
 <span class="menu-text">Sessions</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Japanese.html" rel="" target="">
 <span class="menu-text">日本語</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">数学者のための深層学習４</h1>
            <p class="subtitle lead">生成モデル VAE</p>
                                <div class="quarto-categories">
                <div class="quarto-category">Kernel</div>
                <div class="quarto-category">Math Notes</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>司馬博文 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 18, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  <div>
    <div class="abstract">
      <div class="abstract-title">概要</div>
      深層生成モデルの１つ VAE は，統計モデルとしては変分 Bayes 推論アルゴリズムであり，変分下界をニューラルネットワークによって近似するというアプローチである．
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#確率的勾配降下法による変分ベイズ-sgvb" id="toc-確率的勾配降下法による変分ベイズ-sgvb" class="nav-link active" data-scroll-target="#確率的勾配降下法による変分ベイズ-sgvb"><span class="header-section-number">1</span> 確率的勾配降下法による変分ベイズ (SGVB)</a>
  <ul class="collapse">
  <li><a href="#sgvb-のアイデア勾配の-monte-carlo-推定" id="toc-sgvb-のアイデア勾配の-monte-carlo-推定" class="nav-link" data-scroll-target="#sgvb-のアイデア勾配の-monte-carlo-推定"><span class="header-section-number">1.1</span> SGVB のアイデア：勾配の Monte Carlo 推定</a></li>
  <li><a href="#変分下界の復習" id="toc-変分下界の復習" class="nav-link" data-scroll-target="#変分下界の復習"><span class="header-section-number">1.2</span> 変分下界の復習</a></li>
  <li><a href="#sgvb-推定量" id="toc-sgvb-推定量" class="nav-link" data-scroll-target="#sgvb-推定量"><span class="header-section-number">1.3</span> SGVB 推定量</a></li>
  </ul></li>
  <li><a href="#sec-VAE" id="toc-sec-VAE" class="nav-link" data-scroll-target="#sec-VAE"><span class="header-section-number">2</span> VAE <span class="citation" data-cites="Kingma-Welling2014">(Kingma &amp; Welling, 2014)</span></a>
  <ul class="collapse">
  <li><a href="#導入" id="toc-導入" class="nav-link" data-scroll-target="#導入"><span class="header-section-number">2.1</span> 導入</a></li>
  <li><a href="#sec-VQ-VAE" id="toc-sec-VQ-VAE" class="nav-link" data-scroll-target="#sec-VQ-VAE"><span class="header-section-number">2.2</span> VQ-VAE</a></li>
  <li><a href="#連続緩和" id="toc-連続緩和" class="nav-link" data-scroll-target="#連続緩和"><span class="header-section-number">2.3</span> 連続緩和</a></li>
  <li><a href="#wasserstein-vae-tolstikhin2018" id="toc-wasserstein-vae-tolstikhin2018" class="nav-link" data-scroll-target="#wasserstein-vae-tolstikhin2018"><span class="header-section-number">2.4</span> Wasserstein VAE <span class="citation" data-cites="Tolstikhin+2018">(Tolstikhin et al., 2018)</span></a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<div class="hidden">
$$
<p>%%% 演算子 </p>
%%% 線型代数学
<p>%%% 複素解析学 %%% 集合と位相 </p>
<p>%%% 形式言語理論 %%% Graph Theory </p>
%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学
%%% 函数解析
%%% 積分論
<p>%%% Fourier解析 %%% 数値解析 </p>
%%% 確率論
<p>%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス </p>
<p>%%% 偏微分方程式 %%% 常微分方程式 %%% 統計力学 %%% 解析力学 </p>
%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計
<p>%%% 計量経済学 </p>
%%% 無限次元統計模型の理論
<p>%%% Banach Lattices </p>
<p>%%% 圏 %代数の圏 %Metric space &amp; Contraction maps %確率空間とMarkov核の圏 %Sober space &amp; continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 </p>
%%% SMC
%%% 括弧類
<p>%%% 予約語 </p>
<p>%%% 略記 </p>
<p>%%% 矢印類 $$</p>
</div>
<section id="確率的勾配降下法による変分ベイズ-sgvb" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="確率的勾配降下法による変分ベイズ-sgvb"><span class="header-section-number">1</span> 確率的勾配降下法による変分ベイズ (SGVB)</h2>
<p>変分自己符号化器 (Variational Auto-encoder) の説明に入る前に，変分ベイズ法において勾配を用いた最適化を実行するための汎用手法である <strong>SGVB (Stochastic Gradient Variational Bayes)</strong> について説明する．</p>
<p>VAE は元々この SGVB という要素技術とセットで提案された <span class="citation" data-cites="Kingma-Welling2014">(<a href="#ref-Kingma-Welling2014" role="doc-biblioref">Kingma &amp; Welling, 2014</a>)</span>．</p>
<p>変分近似をする分布族 <span class="math inline">\(\{q_\phi\}\)</span> としてニューラルネットを用いた場合が，VAE であり，広く SGVB は，一般の連続な潜在変数を持った（有向）グラフィカルモデルに適用できる．</p>
<section id="sgvb-のアイデア勾配の-monte-carlo-推定" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="sgvb-のアイデア勾配の-monte-carlo-推定"><span class="header-section-number">1.1</span> SGVB のアイデア：勾配の Monte Carlo 推定</h3>
<p><a href="../../../posts/2024/Kernels/Deep3.html">GAN</a> 同様，生成モデリングは，潜在空間 <span class="math inline">\(Z\)</span> で条件付けた際の分布 <span class="math inline">\(p(x|z)\)</span> をモデリングすることに等しい．GAN は <span class="math inline">\(p(x|z)\)</span> を明示的に評価することを回避することで複雑な生成モデリングを達成していた．</p>
<p>一方で，（周辺）尤度の評価を完全に回避せずとも，<a href="../../../posts/2024/Computation/VI3.html">変分 Bayes 法</a> によるアプローチが可能である．<span class="math inline">\(p(x|z)\)</span> に分布族 <span class="math inline">\(q_\phi(x|z)\)</span> を導入し，真の分布 <span class="math inline">\(p\)</span> との KL-距離を最小にする <span class="math inline">\(\phi\in\Phi\)</span> を選ぶのである．</p>
<p>変分 Bayes ではこれを解析的に実行する必要があった．そのため，分布族 <span class="math inline">\(\{q_\phi\}\)</span> を指数分布族や共役分布族に限るか，平均場近似を用いるか，などの強い仮定が必要で，これが複雑な生成モデリングを妨げていた．<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>そこで，一般の分布族 <span class="math inline">\(\{q_\phi\}\)</span> に対して勾配情報を用いた最適化が実施できるように，変分下界 <span class="math inline">\(F(p_\theta,q_\phi)\)</span> 対する Monte Carlo 推定量を開発するのである．これが SGVB 推定量である．</p>
</section>
<section id="変分下界の復習" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="変分下界の復習"><span class="header-section-number">1.2</span> 変分下界の復習</h3>
<p>データ <span class="math inline">\(X\)</span> の生成過程に，モデル <span class="math inline">\(p_\theta(z)p_\theta(x|z)\)</span> を考える．これがニューラルネットワークによるモデルであるとすると，周辺尤度 <span class="math display">\[
p_\theta(x)=\int_\mathcal{Z}p_\theta(z)p_\theta(x|z)\,dz
\]</span> や事後分布 <span class="math inline">\(p_\theta(z|x)\)</span> の評価は容易でない．</p>
<p>そこで，<span class="math inline">\(p_\theta(z|x)\)</span> に対して，認識モデル <span class="math inline">\(\{q_\phi(z|x)\}_{\phi\in\Phi}\)</span> を導入する．VAE <a href="#sec-VAE">2</a> では，これもニューラルネットワークとし，<span class="math inline">\((\theta,\phi)\in\Theta\times\Phi\)</span> を同時に SGD により学習することを考える．</p>
<p>潜在変数 <span class="math inline">\(Z\)</span> を情報源と見て，<span class="math inline">\(q_\theta(z|x)\)</span> を <strong>符号化器</strong> (encoder) と呼び，<span class="math inline">\(p_\theta(x|z)\)</span> を <strong>復号器</strong> (decoder) とも呼ぶ．</p>
<p>このとき，対数周辺尤度の変分下界は次のように表せるのであった：<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> <span class="math display">\[
\begin{align*}
    \log p_\theta(x)&amp;=\log\int_\mathcal{Z}p_\theta(x,z)\,dz\\
    &amp;=\log\int_\mathcal{Z}q_\phi(z)\frac{p_\theta(x,z)}{q_\phi(z)}\,dz\\
    &amp;\ge\int_\mathcal{Z}q_\phi(z)\log\frac{q_\theta(x|z)p_\theta(z)}{q_\phi(z)}\,dz\\
    &amp;=-\mathop{\mathrm{KL}}(q_\phi,p_\theta)+\int_\mathcal{Z}q_\phi(z)\log p_\theta(x|z)\,dz\\
    &amp;=:F(\theta,\phi;x)
\end{align*}
\]</span></p>
<p>この <span class="math inline">\(F\)</span> を <span class="math inline">\(\theta,\phi\)</span> に関して逐次的に最大化するのが変分 Bayes である．これを実行するために <span class="math inline">\(q_\phi\)</span> に平均場近似などをするのが旧来手法であるが，これ以上の近似をせずとも，<span class="math inline">\(F\)</span> の勾配の推定量を用いて，<span class="math inline">\(p_\theta,q_\phi\)</span> を同時に学習することが出来るというのである．</p>
</section>
<section id="sgvb-推定量" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="sgvb-推定量"><span class="header-section-number">1.3</span> SGVB 推定量</h3>
<p>例えば <span class="math inline">\(F\)</span> を <span class="math inline">\(\phi\)</span> に関して勾配情報から最大化する際に，勾配 <span class="math inline">\(D_\phi F\)</span> の Monte Carlo 推定量が利用できる．しかし，単に <span class="math inline">\(q_\phi(z|x)\)</span> からのサンプルを用いた crude Monte Carlo では，この推定量の分散は非常に大きい <span class="citation" data-cites="Paisley+2012">(<a href="#ref-Paisley+2012" role="doc-biblioref">Paisley et al., 2012</a>)</span>．</p>
<p>これを <strong>重点サンプリングの考え方により解決した</strong> のが <span class="math inline">\(D_\phi F,D_\theta F\)</span> に対する SGVB 推定量である．<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> <span class="citation" data-cites="Kingma-Welling2014">(<a href="#ref-Kingma-Welling2014" role="doc-biblioref">Kingma &amp; Welling, 2014</a>)</span> では reparameterization trick と呼んでいる．</p>
<p>ある分布 <span class="math inline">\(P\in\mathcal{P}(E)\)</span> と可微分同相 <span class="math inline">\(g_\phi:E\times\mathcal{X}\to\mathcal{Z}\)</span> であって <span class="math display">\[
g_\phi(\epsilon,x)\sim q_\phi(z,x)\quad(\epsilon\sim P)
\]</span> を満たすものを見つけることができて，この <span class="math inline">\(P\)</span> を提案分布とする重点サンプリング推定量 <span class="math display">\[
\begin{align*}
    \operatorname{E}_{q_\phi}[f(Z)]&amp;=\operatorname{E}_{P}[f(g_\phi(\epsilon,x))]\\
    &amp;\simeq\frac{1}{M}\sum_{i=1}^Mf(g_\phi(\epsilon^i,x))
\end{align*}
\]</span> により，Monte Carlo 推定量の分散を減らすことができる．<span class="math inline">\(f=F\)</span> と取ることで SGVB 推定量を得る．</p>
<p>さらに，<span class="math inline">\(\mathcal{Z}\)</span> 上のモデル <span class="math inline">\(q_\phi(z),p_\theta(z)\)</span> とが <span class="math inline">\(d\)</span>-次元の正規分布であった場合， <span class="math display">\[
-\mathop{\mathrm{KL}}(q_\phi,p_\theta)=\frac{1}{2}\sum_{j=1}^d\biggr(1+\log(\sigma_j^2)-\mu_j^2-\sigma_j^2\biggl)
\]</span> と解析的に解けるので，結局 Monte Carlo 近似が必要なのは，再構成誤差を表す <span class="math display">\[
\int_\mathcal{Z}q_\phi(z)\log p_\theta(x|z)\,dz
\]</span> の部分だけである．</p>
<p>このような理由で，<span class="math inline">\(q_\phi(z),p_\theta(z)\)</span> は典型的には正規分布としてモデリングされる．</p>
</section>
</section>
<section id="sec-VAE" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="sec-VAE"><span class="header-section-number">2</span> VAE <span class="citation" data-cites="Kingma-Welling2014">(<a href="#ref-Kingma-Welling2014" role="doc-biblioref">Kingma &amp; Welling, 2014</a>)</span></h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="VAE.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Samples from a VQ-VAE Taken from Figure 6 <span class="citation" data-cites="Razavi+2019">(<a href="#ref-Razavi+2019" role="doc-biblioref">Razavi et al., 2019, p. 8</a>)</span></figcaption>
</figure>
</div>
<section id="導入" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="導入"><span class="header-section-number">2.1</span> 導入</h3>
<p>Variational Auto-encoder <span class="citation" data-cites="Kingma-Welling2014">(<a href="#ref-Kingma-Welling2014" role="doc-biblioref">Kingma &amp; Welling, 2014</a>)</span>, <span class="citation" data-cites="Rezende+2014">(<a href="#ref-Rezende+2014" role="doc-biblioref">Rezende et al., 2014</a>)</span> も GAN と同じく，深層生成モデル <span class="math inline">\(p_\theta\)</span> にもう１つの深層ニューラルネットワーク <span class="math inline">\(q_\phi\)</span> を対置するが，このニューラルネット <span class="math inline">\(q_\phi\)</span> は GAN のように判別をするのではなく，近似推論によってデータ生成源を再構成しようとする <strong>認識モデル</strong> (recognition model) である．<span class="math inline">\(q_\phi\)</span> はエンコーダーとも呼ばれる．</p>
<p>この深層生成モデル <span class="math inline">\(p_\theta\)</span> と近似推論器 <span class="math inline">\(q_\phi\)</span> とを，同時に確率勾配降下法によって学習する <span class="citation" data-cites="Kingma-Welling2019">(<a href="#ref-Kingma-Welling2019" role="doc-biblioref">Kingma &amp; Welling, 2019</a>)</span>．</p>
<p>VAE のエンコーダー <span class="math inline">\(q_\phi\)</span> は動画データの圧縮表現の学習 <span class="citation" data-cites="Brooks+2024">(<a href="#ref-Brooks+2024" role="doc-biblioref">Brooks et al., 2024</a>)</span> など，その他の生成モデルの構成要素としても用いられる．</p>
</section>
<section id="sec-VQ-VAE" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="sec-VQ-VAE"><span class="header-section-number">2.2</span> VQ-VAE</h3>
<p>VAE は画像データの生成にも応用されている．</p>
<p>VQ-VAE <span class="citation" data-cites="vandenOord+2017">(<a href="#ref-vandenOord+2017" role="doc-biblioref">van&nbsp;den&nbsp;Oord et al., 2017</a>)</span>, <span class="citation" data-cites="Razavi+2019">(<a href="#ref-Razavi+2019" role="doc-biblioref">Razavi et al., 2019</a>)</span> は，自己符号化器の中間表現に <a href="../../../posts/2024/Computation/VI.html#sec-history">ベクトル量子化</a> を施し，JPEG <span class="citation" data-cites="Wallace1992">(<a href="#ref-Wallace1992" role="doc-biblioref">Wallace, 1992</a>)</span> のような画像データの圧縮を行うことで，不要な情報のモデリングを回避している．</p>
<p>実際，元データの 30 分の 1 以下のサイズで学習を行い，最終的にデコーダーを用いて殆ど歪みなく再構成できるという．</p>
<p>GAN は元データのうち，尤度が低い部分が無視され，サンプルの多様性が失われがちであったが，VQ-VAE はこの問題を解決している．また，GAN にはないようなモデル評価の指標が複数提案されている．</p>
</section>
<section id="連続緩和" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="連続緩和"><span class="header-section-number">2.3</span> 連続緩和</h3>
<p>質的変数のサンプリングにおいて，Gumbel 分布を提案分布として重点サンプリングを行うことが有効である．この reparametrization trick を Gumbel Max Trick <span class="citation" data-cites="Jang+2017">(<a href="#ref-Jang+2017" role="doc-biblioref">Jang et al., 2017</a>)</span> という．</p>
<p>Concrete (Continuous Relaxatino of Discrete) <span class="citation" data-cites="Maddison+2017">(<a href="#ref-Maddison+2017" role="doc-biblioref">Maddison et al., 2017</a>)</span> はこれを連続分布に拡張し，reparametrization trick に応用したものである．</p>
<p>これらの手法は VAE や <a href="https://openai.com/research/dall-e">DALL-E</a> <span class="citation" data-cites="Ramesh+2021">(<a href="#ref-Ramesh+2021" role="doc-biblioref">Ramesh et al., 2021</a>)</span> の訓練にも応用されている．</p>
</section>
<section id="wasserstein-vae-tolstikhin2018" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="wasserstein-vae-tolstikhin2018"><span class="header-section-number">2.4</span> Wasserstein VAE <span class="citation" data-cites="Tolstikhin+2018">(<a href="#ref-Tolstikhin+2018" role="doc-biblioref">Tolstikhin et al., 2018</a>)</span></h3>
<p>VAE は GAN よりも画像生成時の解像度が劣るという問題がある．</p>
<p>これを，目的関数を Wasserstein 距離に基づいて再定式化することで解決できるというのが Wasserstein Auto-encoder <span class="citation" data-cites="Tolstikhin+2018">(<a href="#ref-Tolstikhin+2018" role="doc-biblioref">Tolstikhin et al., 2018</a>)</span> である．</p>



</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="list">
<div id="ref-Brooks+2024" class="csl-entry" role="listitem">
Brooks, T., Peebles, B., Holmes, C., DePue, W., Guo, Y., Jing, L., Schnurr, D., Taylor, J., Luhman, T., Luhman, E., Ng, C. W. Y., Wang, R., &amp; Ramesh, A. (2024). <em>Video generation models as world simulators</em>. OpenAI. <a href="https://openai.com/research/video-generation-models-as-world-simulators">https://openai.com/research/video-generation-models-as-world-simulators</a>
</div>
<div id="ref-Geyer1996" class="csl-entry" role="listitem">
Geyer, C. (1996). <em>Markov chain monte carlo in practice</em> (W. R. Gilks, S. Richardson, &amp; D. Spiegelhalter, Eds.; pp. 241–258). Chapman; Hall. <a href="https://www.taylorfrancis.com/books/mono/10.1201/b14835/markov-chain-monte-carlo-practice-david-spiegelhalter-gilks-richardson">https://www.taylorfrancis.com/books/mono/10.1201/b14835/markov-chain-monte-carlo-practice-david-spiegelhalter-gilks-richardson</a>
</div>
<div id="ref-Jang+2017" class="csl-entry" role="listitem">
Jang, E., Gu, S., &amp; Poole, B. (2017). Categorical reparameterization with gumbel-softmax. <em>International Conference on Learning Representations</em>. <a href="https://openreview.net/forum?id=rkE3y85ee">https://openreview.net/forum?id=rkE3y85ee</a>
</div>
<div id="ref-Kingma-Welling2014" class="csl-entry" role="listitem">
Kingma, D. P., &amp; Welling, M. (2014). Auto-encoding variational bayes. <em>International Conference on Learning Representations</em>, <em>2</em>. <a href="https://openreview.net/forum?id=33X9fd2-9FyZd">https://openreview.net/forum?id=33X9fd2-9FyZd</a>
</div>
<div id="ref-Kingma-Welling2019" class="csl-entry" role="listitem">
Kingma, D. P., &amp; Welling, M. (2019). An introduction to variational autoencoders. <em>Foundations and Treands in Machine Learning</em>, <em>12</em>(4), 307–392. <a href="https://www.nowpublishers.com/article/Details/MAL-056">https://www.nowpublishers.com/article/Details/MAL-056</a>
</div>
<div id="ref-Maddison+2017" class="csl-entry" role="listitem">
Maddison, C. J., Mnih, A., &amp; Teh, Y. W. (2017). The concrete distribution: A continuous relaxation of discrete random variables. <em>International Conference on Learning Representations</em>. <a href="https://openreview.net/forum?id=S1jE5L5gl">https://openreview.net/forum?id=S1jE5L5gl</a>
</div>
<div id="ref-Paisley+2012" class="csl-entry" role="listitem">
Paisley, J., Blei, D. M., &amp; Jordan, M. I. (2012). Variational bayesian inference with stochastic search. <em>Proceedings of the 29th International Conference on Machine Learning</em>, 1363–1370. <a href="https://dl.acm.org/doi/10.5555/3042573.3042748">https://dl.acm.org/doi/10.5555/3042573.3042748</a>
</div>
<div id="ref-Ramesh+2021" class="csl-entry" role="listitem">
Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., &amp; Sutskever, I. (2021). Zero-shot text-to-image generation. In M. Meila &amp; T. Zhang (Eds.), <em>Proceedings of the 38th international conference on machine learning</em> (Vol. 139, pp. 8821–8831). PMLR. <a href="https://proceedings.mlr.press/v139/ramesh21a.html">https://proceedings.mlr.press/v139/ramesh21a.html</a>
</div>
<div id="ref-Razavi+2019" class="csl-entry" role="listitem">
Razavi, A., van&nbsp;den&nbsp;Oord, A., &amp; Vinyals, O. (2019). Generating diverse high-fidelity images with VQ-VAE-2. <em>Advances in Neural Information Processing Systems</em>, <em>32</em>. <a href="https://papers.nips.cc/paper_files/paper/2019/hash/5f8e2fa1718d1bbcadf1cd9c7a54fb8c-Abstract.html">https://papers.nips.cc/paper_files/paper/2019/hash/5f8e2fa1718d1bbcadf1cd9c7a54fb8c-Abstract.html</a>
</div>
<div id="ref-Rezende+2014" class="csl-entry" role="listitem">
Rezende, D. J., Mohamed, S., &amp; Wierstra, D. (2014). Approximate inference in deep generative models. <em>Proceedings of the 31st International Conference on Machine Learning</em>, <em>32</em>, 1278–1286. <a href="https://proceedings.mlr.press/v32/rezende14.html">https://proceedings.mlr.press/v32/rezende14.html</a>
</div>
<div id="ref-Robert-Casella2004" class="csl-entry" role="listitem">
Robert, C. P., &amp; Casella, G. (2004). <em>Monte carlo statistical methods</em> (2nd ed.). Springer New York.
</div>
<div id="ref-Tolstikhin+2018" class="csl-entry" role="listitem">
Tolstikhin, I., Bousquet, O., Gelly, S., &amp; Schoelkopf, B. (2018). Wasserstein auto-encoders. <em>International Conference on Learning Representations</em>. <a href="https://openreview.net/forum?id=HkL7n1-0b">https://openreview.net/forum?id=HkL7n1-0b</a>
</div>
<div id="ref-vandenOord+2017" class="csl-entry" role="listitem">
van&nbsp;den&nbsp;Oord, A., Vinyals, O., &amp; Kavukcuoglu, K. (2017). Neural discrete representation learning. <em>Advances in Neural Information Processing Systems</em>, <em>30</em>. <a href="https://papers.nips.cc/paper_files/paper/2017/hash/7a98af17e63a0ac09ce2e96d03992fbc-Abstract.html">https://papers.nips.cc/paper_files/paper/2017/hash/7a98af17e63a0ac09ce2e96d03992fbc-Abstract.html</a>
</div>
<div id="ref-Wallace1992" class="csl-entry" role="listitem">
Wallace, G. K. (1992). The JPEG still picture compression standard. <em>IEEE Transactions on Consumer Electronics</em>, <em>38</em>, 1. <a href="https://ieeexplore.ieee.org/document/125072">https://ieeexplore.ieee.org/document/125072</a>
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>なお，平均場近似も極めて困難な解析的計算を必要とする <span class="citation" data-cites="Kingma-Welling2014">(<a href="#ref-Kingma-Welling2014" role="doc-biblioref">Kingma &amp; Welling, 2014</a>)</span>．<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><a href="../../../posts/2024/Computation/VI3.html#sec-ELBO">前稿</a> も参照．<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>最適化の文脈において，目的関数の評価が困難であるとき，Monte Carlo 推定量でこれを代替する際，重点サンプリングを用いると良いことは従来提案されている <span class="citation" data-cites="Geyer1996">(<a href="#ref-Geyer1996" role="doc-biblioref">Geyer, 1996</a>)</span>．<span class="citation" data-cites="Robert-Casella2004">(<a href="#ref-Robert-Casella2004" role="doc-biblioref">Robert &amp; Casella, 2004, p. 203</a>)</span> も参照．<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="quarto-dev/quarto-web" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



</body></html>