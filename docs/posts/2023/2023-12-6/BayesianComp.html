<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Hirofumi Shiba">
<meta name="dcterms.date" content="2023-12-06">

<title>Ano2math5 - ベイズ計算とは何か | About Bayesian Computation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../profile.jpg" rel="icon" type="image/jpeg">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-36GX2G6GLL"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-36GX2G6GLL', { 'anonymize_ip': true});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Ano2math5 - ベイズ計算とは何か | About Bayesian Computation">
<meta property="og:description" content="A Blog by a Bayesian Computation Researcher">
<meta property="og:image" content="https://github.com/162348/posts/2023/2023-12-6/history.png">
<meta property="og:site-name" content="Ano2math5">
<meta property="og:image:height" content="400">
<meta property="og:image:width" content="1236">
<meta name="twitter:title" content="Ano2math5 - ベイズ計算とは何か | About Bayesian Computation">
<meta name="twitter:description" content="「ベイズ統計学」は一大トピックであるが，「ベイズ計算」という分野があることはそれほど周知のことではない．この分野の問題意識を，「ベイズ計算」分野の歴史と共に理解することを試みる．">
<meta name="twitter:image" content="https://github.com/162348/posts/2023/2023-12-6/history.png">
<meta name="twitter:image-height" content="400">
<meta name="twitter:image-width" content="1236">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Ano2math5</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../static/Lectures.html" rel="" target="">
 <span class="menu-text">Sessions</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">ベイズ計算とは何か | About Bayesian Computation</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Survey</div>
                <div class="quarto-category">Computation</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Hirofumi Shiba </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">December 6, 2023</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">December 9, 2023</p>
      </div>
    </div>
      
    </div>
    
  <div>
    <div class="abstract">
      <div class="abstract-title">概要</div>
      「ベイズ統計学」は一大トピックであるが，「ベイズ計算」という分野があることはそれほど周知のことではない．この分野の問題意識を，「ベイズ計算」分野の歴史と共に理解することを試みる．
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#ベイズ計算のベイズとは何者か" id="toc-ベイズ計算のベイズとは何者か" class="nav-link active" data-scroll-target="#ベイズ計算のベイズとは何者か"><span class="header-section-number">1</span> 「ベイズ計算」の「ベイズ」とは何者か？</a>
  <ul class="collapse">
  <li><a href="#ベイズまでの統計学の黎明" id="toc-ベイズまでの統計学の黎明" class="nav-link" data-scroll-target="#ベイズまでの統計学の黎明"><span class="header-section-number">1.1</span> ベイズまでの統計学の黎明</a>
  <ul class="collapse">
  <li><a href="#john-grauntの死亡表" id="toc-john-grauntの死亡表" class="nav-link" data-scroll-target="#john-grauntの死亡表"><span class="header-section-number">1.1.1</span> John Grauntの死亡表</a></li>
  <li><a href="#統計学への期待と希望" id="toc-統計学への期待と希望" class="nav-link" data-scroll-target="#統計学への期待と希望"><span class="header-section-number">1.1.2</span> 統計学への期待と希望</a></li>
  </ul></li>
  <li><a href="#ベイズが取り組んだ問題" id="toc-ベイズが取り組んだ問題" class="nav-link" data-scroll-target="#ベイズが取り組んだ問題"><span class="header-section-number">1.2</span> ベイズが取り組んだ問題</a></li>
  <li><a href="#ベイズのアイデア" id="toc-ベイズのアイデア" class="nav-link" data-scroll-target="#ベイズのアイデア"><span class="header-section-number">1.3</span> ベイズのアイデア</a></li>
  <li><a href="#sec-fundamental-problem-of-Bayes" id="toc-sec-fundamental-problem-of-Bayes" class="nav-link" data-scroll-target="#sec-fundamental-problem-of-Bayes"><span class="header-section-number">1.4</span> ベイズ統計学の基本問題</a></li>
  <li><a href="#sec-Laplace" id="toc-sec-Laplace" class="nav-link" data-scroll-target="#sec-Laplace"><span class="header-section-number">1.5</span> Laplaceの近似</a></li>
  <li><a href="#ベイズ統計学の長く苦しい時代" id="toc-ベイズ統計学の長く苦しい時代" class="nav-link" data-scroll-target="#ベイズ統計学の長く苦しい時代"><span class="header-section-number">1.6</span> ベイズ統計学の長く苦しい時代</a></li>
  <li><a href="#フランスでの確率論の歴史" id="toc-フランスでの確率論の歴史" class="nav-link" data-scroll-target="#フランスでの確率論の歴史"><span class="header-section-number">1.7</span> フランスでの確率論の歴史</a></li>
  </ul></li>
  <li><a href="#mcmcとsmcの発明" id="toc-mcmcとsmcの発明" class="nav-link" data-scroll-target="#mcmcとsmcの発明"><span class="header-section-number">2</span> MCMCとSMCの発明</a>
  <ul class="collapse">
  <li><a href="#マルコフ連鎖によるモンテカルロ法の発明" id="toc-マルコフ連鎖によるモンテカルロ法の発明" class="nav-link" data-scroll-target="#マルコフ連鎖によるモンテカルロ法の発明"><span class="header-section-number">2.1</span> マルコフ連鎖によるモンテカルロ法の発明</a></li>
  <li><a href="#重点サンプリング法の発明" id="toc-重点サンプリング法の発明" class="nav-link" data-scroll-target="#重点サンプリング法の発明"><span class="header-section-number">2.2</span> 重点サンプリング法の発明</a></li>
  <li><a href="#mcmcの普及とギブスサンプラー" id="toc-mcmcの普及とギブスサンプラー" class="nav-link" data-scroll-target="#mcmcの普及とギブスサンプラー"><span class="header-section-number">2.3</span> MCMCの普及とギブスサンプラー</a></li>
  </ul></li>
  <li><a href="#ベイズ統計学のこれから" id="toc-ベイズ統計学のこれから" class="nav-link" data-scroll-target="#ベイズ統計学のこれから"><span class="header-section-number">3</span> ベイズ統計学のこれから</a>
  <ul class="collapse">
  <li><a href="#擬似周辺尤度法" id="toc-擬似周辺尤度法" class="nav-link" data-scroll-target="#擬似周辺尤度法"><span class="header-section-number">3.1</span> 擬似周辺尤度法</a></li>
  <li><a href="#高次元問題に対処するmcmc" id="toc-高次元問題に対処するmcmc" class="nav-link" data-scroll-target="#高次元問題に対処するmcmc"><span class="header-section-number">3.2</span> 高次元問題に対処するMCMC</a></li>
  <li><a href="#近似ベイズ手法" id="toc-近似ベイズ手法" class="nav-link" data-scroll-target="#近似ベイズ手法"><span class="header-section-number">3.3</span> 近似ベイズ手法</a></li>
  <li><a href="#ベイズ統計モデリングが理論モデルの実証に役立つ" id="toc-ベイズ統計モデリングが理論モデルの実証に役立つ" class="nav-link" data-scroll-target="#ベイズ統計モデリングが理論モデルの実証に役立つ"><span class="header-section-number">3.4</span> ベイズ統計モデリングが理論モデルの実証に役立つ</a></li>
  <li><a href="#ベイズ因果推論" id="toc-ベイズ因果推論" class="nav-link" data-scroll-target="#ベイズ因果推論"><span class="header-section-number">3.5</span> ベイズ因果推論</a></li>
  <li><a href="#ベイズ学習" id="toc-ベイズ学習" class="nav-link" data-scroll-target="#ベイズ学習"><span class="header-section-number">3.6</span> ベイズ学習</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="history.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">History of Bayesian Computation <span class="citation" data-cites="Martin+2023-history">(<a href="#ref-Martin+2023-history" role="doc-biblioref">Martin et al., 2023, p. 4</a>)</span></figcaption>
</figure>
</div>
<section id="ベイズ計算のベイズとは何者か" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> 「ベイズ計算」の「ベイズ」とは何者か？</h1>
<blockquote class="blockquote">
<p>賭博，生命保険，確率論この三つの間には，その発生に切っても切れない因縁がある．この点を明確に摘出することは，統計学の黎明を知るのに不可欠であろう． <span class="citation" data-cites="北川敏男49-統計学の認識">(<a href="#ref-北川敏男49-統計学の認識" role="doc-biblioref">北川敏男, 1949</a>)</span></p>
</blockquote>
<blockquote class="blockquote">
<p>de Moivreを彼の著”Approximation”に，またBayesを彼の定理に導いた原因は，純然たる数学的なものというよりも，神学的及び社会学的のものであった． <span class="citation" data-cites="Pearson1926">(<a href="#ref-Pearson1926" role="doc-biblioref">Pearson, 1926</a>)</span></p>
</blockquote>
<section id="ベイズまでの統計学の黎明" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="ベイズまでの統計学の黎明"><span class="header-section-number">1.1</span> ベイズまでの統計学の黎明</h2>
<p>統計学の黎明を要請したものは，社会への不安であった．筆者に言わせれば，この社会への不安を直視したのがドイツ，数で解決しようとしたのがイギリスで，解決への筋道を確率論で基礎づけたのがフランスである．</p>
<p>17世紀初頭から何度も流行を繰り返し，遂に1665年にはロンドンの人口の1/4を死に至らしめた <a href="https://ja.wikipedia.org/wiki/%E3%83%AD%E3%83%B3%E3%83%89%E3%83%B3%E3%81%AE%E5%A4%A7%E7%96%AB%E7%97%85">ペストの大流行</a> は恐怖の対象であった．パンデミックは現代でも恐怖の対象であるが，当時はその全貌の把握が難しく，これが第一に切望された．月の運行による健康被害，国王の統治が疫病を引き起こす，などの俗見が流布していた時代である．しかし，「数」という解決手段は極めて功を奏した．</p>
<p>数による解決が他でもないイギリスから生まれたことは，Francis Bacon 1561-1626 に象徴される自然科学の風土，「Aristotelesの三段論法を通じて，経験的に因果関係を発見することで，我々は自然を理解できる」という希望が当時のイギリスには存在したことが挙げられる．</p>
<blockquote class="blockquote">
<p>海へ行け，きっと獲物があるぞという先輩がBaconであった．漁獲法一般の講義をする先生が，例えば後世のJ. S. Millの帰納論理学に相当するのである．統計学を作った漁師たちは，Mill先生の帰納法の論理学の講義などは，上の空で聞いた．そして各自の漁獲法を自らの浜で覚えたのである． <span class="citation" data-cites="北川敏男49-統計学の認識">(<a href="#ref-北川敏男49-統計学の認識" role="doc-biblioref">北川敏男, 1949, p. 12</a>)</span></p>
</blockquote>
<section id="john-grauntの死亡表" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="john-grauntの死亡表"><span class="header-section-number">1.1.1</span> John Grauntの死亡表</h3>
<p>最初にペスト流行の激しさの判定に寄与する人口状況を，数によって理解しようとしたのが <a href="https://en.wikipedia.org/wiki/John_Graunt">John Graunt</a> 1620-1674 であった．</p>
<p>当時の英国王立理学協会は<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> は，封建的な諸関係の崩壊解消と同時に，商品生産・貨幣による売買の全面支配によって貨幣的表現が富の大部分に侵入したことにより新たに誕生した市民階級が勢力を占めており，Grauntもこのような商人階級の出身である．</p>
<p>そのような身分のGrauntが英国王の推薦を受けて王立協会員の名誉を勝ち取った論文 <span class="citation" data-cites="Graunt1662">(<a href="#ref-Graunt1662" role="doc-biblioref">Graunt, 1662</a>)</span> は，ギルド発行の死亡統計 <a href="https://en.wikipedia.org/wiki/Bills_of_mortality">Bills of Mortality</a> と教会に蓄積していた統計資料<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> から統計的な処理を通じて世界初の「死亡表」を作成し，次の内容を初めて結論づけた．</p>
<ul>
<li>36%の幼児は６歳未満で死亡する．</li>
<li>洗礼数をみると，男女比は16:15くらいである．</li>
<li>都市の死亡率は地方より高い．</li>
<li>Londonの城外では死亡率は３倍である．</li>
</ul>
<p>加えてLondonの世帯数を3通りの方法で推算し，世帯数は5万であろうと結論づけた．なお，当時の俗見ではLondon人口は100万と言われていた．男女比は1:3と言われているものもある．</p>
<p>その後このような生命表はギルド的な共助制度の土壌の上で生命保険の成立としても結実した．</p>
</section>
<section id="統計学への期待と希望" class="level3" data-number="1.1.2">
<h3 data-number="1.1.2" class="anchored" data-anchor-id="統計学への期待と希望"><span class="header-section-number">1.1.2</span> 統計学への期待と希望</h3>
<p>このイギリスの数を使った解決は，<a href="https://ja.wikipedia.org/wiki/%E6%94%BF%E6%B2%BB%E7%AE%97%E8%A1%93">政治算術学派</a> と呼ばれ，海外への輸出が進んだ．</p>
<p>ドイツの牧師 <a href="https://ja.wikipedia.org/wiki/%E3%83%A8%E3%83%8F%E3%83%B3%E3%83%BB%E3%83%9A%E3%83%BC%E3%82%BF%E3%83%BC%E3%83%BB%E3%82%B8%E3%83%A5%E3%83%BC%E3%82%B9%E3%83%9F%E3%83%AB%E3%83%92">Johann Peter Süβmilch</a> 1707-1767 は Graunt に倣って，教会に蓄積していた統計資料を用い，出生率の性別比が長期的には女性1,000対男性1,050に収束することを発見した．</p>
<p>中でも特に，「たくさんのデータを集めると何かが見えてくる」ことに大きな希望を持ち，Grauntが教会の資料に注目したことをColumbusの新大陸発見になぞらえている．</p>
<blockquote class="blockquote">
<p>若し我々が家を一軒一軒数えていくならば，ある家では娘だけに，またある家では息子だけに，あるいはそうでなくとも，非常に不釣り合いな両者の配合にでくわすであろう．小さな社会や村落でも秩序的なものを認めることは，容易ではない．（中略）．かかる場合に，誰が，能く規則と秩序とに想達し得るだろう．所で，教会の記録はこの秩序の確認のための大きな手段である．それは教会用及び世俗用のためにすでに数世紀前から取られ，<strong>とくに宗教改革後はかなり正確にとられてきた</strong>．誰がそれを利用したか？その発見はアメリカ発見と同時に可能であったのだ．（中略）<strong>それをGrauntがなし得たのである</strong>． Süβmilch (1741) 『神の秩序』</p>
</blockquote>
<p>このようにSüβmilchは男児の出生率の方が高いことを神の存在証明と見なしたのであった．この宗教的な外被を取り去るには，確率論の登場をまたねばならなかったが，これにはさらにフランスの学派が合流するのを待つ必要があり，それには100年を要したのであった（ <a href="#sec-Laplace">節&nbsp;1.5</a> も参照）．</p>
</section>
</section>
<section id="ベイズが取り組んだ問題" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="ベイズが取り組んだ問題"><span class="header-section-number">1.2</span> ベイズが取り組んだ問題</h2>
<p>というわけで，<span class="math inline">\(i=1,\cdots,n\)</span> 番目の世帯の新生児が，男児である <span class="math inline">\(y_i=1\)</span> か女児である <span class="math inline">\(y_i=0\)</span> かのデータなどから，人口・疫病・国家動態に役立つ知識を引き出すことが当時の重要な問題意識であることをわかっていただけただろう．</p>
<p>時代が下り，やはりイギリスの牧師 <a href="https://ja.wikipedia.org/wiki/%E3%83%88%E3%83%BC%E3%83%9E%E3%82%B9%E3%83%BB%E3%83%99%E3%82%A4%E3%82%BA">Thomas Bayes</a> 1701-1761 の時代では，より抽象的な設定で統計的推定の問題が研究されていた．中でもBayesは，次のような「区間推定」の問題を考えていた．</p>
<div class="hidden">
$$
<p>%%% 演算子 </p>
%%% 線型代数学
<p>%%% 複素解析学 %%% 集合と位相 </p>
<p>%%% 形式言語理論 %%% Graph Theory </p>
%%% 多様体 %%% 代数 %%% 代数的位相幾何学 %%% 微分幾何学
%%% 函数解析
%%% 積分論
<p>%%% Fourier解析 %%% 数値解析 </p>
%%% 確率論
<p>%%% 情報理論 %%% 量子論 %%% 最適化 %%% 数理ファイナンス </p>
%%% 偏微分方程式
<p>%%% 常微分方程式 %%% 統計力学 %%% 解析力学 </p>
%%% 統計的因果推論 %%% 応用統計学 %%% 数理統計
<p>%%% 計量経済学 </p>
%%% 無限次元統計模型の理論
<p>%%% Banach Lattices </p>
<p>%%% 圏 %代数の圏 %Metric space &amp; Contraction maps %確率空間とMarkov核の圏 %Sober space &amp; continuous map %Category of open subsets %Category of sheave %Category of presheave, PSh(C)=[C^op,set]のこと %Convergence spaceの圏 %一様空間と一様連続写像の圏 %フレームとフレームの射 %その反対圏 %滑らかな多様体の圏 %Quiverの圏 </p>
%%% SMC
%%% 括弧類
<p>%%% 予約語 </p>
<p>%%% 略記 </p>
<p>%%% 矢印類 $$</p>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="ベイズが取り組んだ問題（現代語訳）">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
ベイズが取り組んだ問題（現代語訳）
</div>
</div>
<div class="callout-body-container callout-body">
<p>2値のデータ <span class="math inline">\(Y_i\in\{0,1\}\)</span> は，ある未知の「成功率」 <span class="math inline">\(\theta\in(0,1)\)</span> に従って， <span class="math display">\[
Y_i=\begin{cases}
1&amp;\text{確率 }\theta\text{ で}\\
0&amp;\text{残りの確率} 1-\theta\text{ で}
\end{cases}
\]</span> という値を取るとする．<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> このようなデータが独立に観測されて，標本 <span class="math inline">\(\boldsymbol{y}:=(y_1,\cdots,y_n)^\top\)</span> と得られているとする．神のみぞ知る，このデータ <span class="math inline">\(\boldsymbol{y}\)</span> を生み出した真の成功率 <span class="math inline">\(\theta\)</span> が区間 <span class="math inline">\((a,b)\subset(0,1)\)</span> に入っているという確率 <span class="math inline">\(\mathrm{P}[a&lt;\theta&lt;b|\boldsymbol{y}]\)</span> をどう見積もれば良いか？</p>
</div>
</div>
<p>以上，抽象的に述べたが，わかりやすいように引き続き <span class="math inline">\(Y_i\)</span> は性別で，<span class="math inline">\(\theta\)</span> は男児が生まれる確率 <span class="math inline">\(\theta=\mathrm{P}[Y_i=1]\)</span> だと解釈する．Bayes自身は「白線が引かれたテーブル上にボールを <span class="math inline">\(n\)</span> 個転がし，それぞれの領域に幾つのボールが入ったかの情報のみから，白線の位置を推定する」という定式化した <span class="citation" data-cites="Bayes1763">(<a href="#ref-Bayes1763" role="doc-biblioref">Bayes, 1763</a>)</span>, <a href="https://www.tcbegley.com/blog/posts/bayesian-billiards">こちらのサイト</a>も参照．</p>
</section>
<section id="ベイズのアイデア" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="ベイズのアイデア"><span class="header-section-number">1.3</span> ベイズのアイデア</h2>
<p>彼の発想は極めてシンプルである．</p>
<ol type="1">
<li>まず<strong>事前分布</strong> <span class="math inline">\(p(\theta)\)</span> と呼ばれる，最初の <span class="math inline">\(\theta\in(0,1)\)</span> に対する予想を自由に表現する．</li>
<li>この事前の信念をデータを用いて修正する形で，<strong>事後分布</strong> <span class="math inline">\(p(\theta|\boldsymbol{y})\)</span> を得る．これは「データ <span class="math inline">\(\boldsymbol{y}\)</span> が得られた，という条件の下で考えた条件付き分布」である．</li>
<li>この事後分布の形から区間推定を実行する．</li>
</ol>
<p>この3.の部分は，Bayesが特に区間推定に拘ったためのものであり，点推定でも良ければ次期予測でも良い．3.を自由に入れ替えても，1.と2.の部分が同じように動作するということ，これがベイズ統計学である．</p>
<p>また，読者は，パラメータ <span class="math inline">\(\theta\)</span> は「男児が生まれる確率」であるが，これ自体にも事前分布という「確率」<span class="math inline">\(p(\theta)\)</span> を導入することに戸惑うだろう．しかし，<strong>これがベイズ統計学の特徴である</strong>．「男児が生まれる確率 <span class="math inline">\(\theta\)</span>」だろうとなんだろうと，「わからない」と主観的に感じるあらゆる対象に，確率分布を導入する，これがベイズ統計学の枠組みの普遍性であり，無差別性であり，有用性を支えている．</p>
<div class="callout callout-style-default callout-note no-icon callout-titled" title="[@Bayes1763] の解決">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="citation" data-cites="Bayes1763">(<a href="#ref-Bayes1763" role="doc-biblioref">Bayes, 1763</a>)</span> の解決
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>まず，事前分布を設定する．Bayesは 「<span class="math inline">\(\theta\in(0,1)\)</span> は全く予想がつかない」「どんな <span class="math inline">\(\theta\)</span> もあり得る」という立場を取った．すなわち，どんな <span class="math inline">\(\theta\in(0,1)\)</span> に対しても，その「あり得る度」は一定だとしたのである．横軸を <span class="math inline">\(\theta\in(0,1)\)</span> の値，縦軸を「主観的にあり得ると思う度合い」として図で表すと次の通りである：</li>
</ol>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the range for x-axis</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Uniform distribution density function is constant</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.ones_like(x)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the graph</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">2</span>)) <span class="co"># Size suitable for a smartphone screen</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>plt.plot(x, y, label<span class="op">=</span><span class="st">'Uniform Distribution (0,1)'</span>, color<span class="op">=</span>(<span class="fl">0.35</span>, <span class="fl">0.71</span>, <span class="fl">0.73</span>, <span class="dv">1</span>))</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>plt.fill_between(x, y, color<span class="op">=</span>(<span class="fl">0.35</span>, <span class="fl">0.71</span>, <span class="fl">0.73</span>, <span class="fl">0.3</span>))</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="dv">0</span>, <span class="fl">1.5</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Density Function of Uniform Distribution on (0,1)'</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="BayesianComp_files/figure-html/cell-2-output-1.png" width="408" height="228"></p>
</div>
</div>
<p>これを一様分布という．このように，一様分布とは「どのような <span class="math inline">\(\theta\)</span> の値も同様に確からしい」という予想の表現である．</p>
<ol type="1">
<li>しかし，データ <span class="math inline">\(\boldsymbol{y}=(y_1,\cdots,y_n)^\top\)</span> が得られている今，どんな <span class="math inline">\(\theta\)</span> も等しく尤もらしいという訳ではない．そこで，「データ <span class="math inline">\(\boldsymbol{y}\)</span> に関する条件付き分布」を計算することとする．実は，簡単な確率の法則から，次の公式を得ることができる（<a href="../../../posts/2023/2023-12-6/法律家のための統計数理2.html#sec-Bayes-formula">講義ノート</a>も参照）：<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> <span id="eq-Bayes-formula"><span class="math display">\[
p(\theta|\boldsymbol{y})=\frac{p(\boldsymbol{y}|\theta)p(\theta)}{\int_\Theta p(\boldsymbol{y}|\theta)p(\theta)\,d\theta}
\tag{1}\]</span></span> この公式を用いて，条件付き分布 <span class="math inline">\(p(\theta|\boldsymbol{y})\)</span> を計算する．例えば <a href="https://www.e-stat.go.jp/dbview?sid=0003411595">日本の2021年の出生児性別のデータ</a> を用いると次のようになる．</li>
</ol>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> beta</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># パラメータの設定</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">811622</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>male <span class="op">=</span> <span class="dv">415903</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>female <span class="op">=</span> n <span class="op">-</span> male</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># ベータ分布のPDFを計算</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> beta.pdf(x, <span class="dv">1</span><span class="op">+</span>male, <span class="dv">1</span><span class="op">+</span>female)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co"># プロット</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">2</span>))</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>plt.plot(x, y, label<span class="op">=</span><span class="ss">f'Beta(</span><span class="sc">{</span><span class="dv">1</span><span class="op">+</span>male<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span><span class="dv">1</span><span class="op">+</span>female<span class="sc">}</span><span class="ss">)'</span>, color<span class="op">=</span>(<span class="fl">0.35</span>, <span class="fl">0.71</span>, <span class="fl">0.73</span>, <span class="dv">1</span>))</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>plt.fill_between(x, y, color<span class="op">=</span>(<span class="fl">0.35</span>, <span class="fl">0.71</span>, <span class="fl">0.73</span>, <span class="fl">0.3</span>))</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'p'</span>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>plt.xlim(<span class="fl">0.4</span>, <span class="fl">0.6</span>)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Probability Density'</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Bayesian Posterior Distribution'</span>)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="BayesianComp_files/figure-html/cell-3-output-1.png" width="310" height="228"></p>
</div>
</div>
<p>こうして極めて鋭い事後分布が出来た．<a href="#eq-Bayes-formula">式&nbsp;1</a> の妥当性を認めるならば，この図は「男児の方が女児よりも生まれる確率が高い」ことの証拠として，極めて説得的ではないだろうか？</p>
<ol start="3" type="1">
<li>では区間推定の例として，<span class="math inline">\((a,b)=(0.5,1.0)\)</span> として，「男児の方が女児よりも多い確率」を推定しよう．これは次を計算することになる： <span class="math display">\[
\begin{align*}
&amp;\mathrm{P}\left[\frac{1}{2}&lt;\theta&lt;1\right]\\
&amp;=\int^1_{\frac{1}{2}}p(Y_1,\cdots,Y_n|\theta)\,d\theta.
\end{align*}
\]</span></li>
</ol>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">sum</span>(y[<span class="dv">500</span>:<span class="dv">600</span>])<span class="op">/</span><span class="dv">1000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>1.003097768300707</code></pre>
</div>
</div>
<p>もはや丸め誤差により <span class="math inline">\(1\)</span> を越してしまっている．ほとんど確実に「男児の方が生まれる確率が高い」と結論づけて良いだろう．</p>
</div>
</div>
<p>この <span class="citation" data-cites="Bayes1763">(<a href="#ref-Bayes1763" role="doc-biblioref">Bayes, 1763</a>)</span> が実行したように，<strong>事後確率 <span class="math inline">\(p(\theta|Y_1,\cdots,Y_n)\)</span> をみて <span class="math inline">\(\theta\)</span> に関する推論をする</strong>，という立場からの統計的営み全体を，<strong>ベイズ統計学</strong>という．</p>
</section>
<section id="sec-fundamental-problem-of-Bayes" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="sec-fundamental-problem-of-Bayes"><span class="header-section-number">1.4</span> ベイズ統計学の基本問題</h2>
<p>事後確率を導く際に用いた <a href="#eq-Bayes-formula">式&nbsp;1</a> は<a href="../../../posts/2023/2023-12-6/法律家のための統計数理2.html#sec-Bayes-formula"><strong>Bayesの公式</strong></a>と呼ばれており，従ってベイズ統計学の最も肝要なパーツである．今回の場合では，Pythonコードをご覧になった方はわかったかもしれないが， <span class="math display">\[
p(\theta|\boldsymbol{y})=\frac{\theta^m(1-\theta)^{n-m}}{B(m+1,n-m+1)}
\]</span> となっており，これは <span class="math inline">\((0,1)\)</span> 上の <a href="../../../posts/2023/2023-11-24/Beta-Gamma.html">Beta分布</a> と呼ばれるものである．</p>
<p>現代のBayes統計学の多くの統計量は，ある関数 <span class="math inline">\(g:\Theta\to\mathbb{R}\)</span> を用いて <span id="eq-object-integral"><span class="math display">\[
\mathrm{E}[g(\theta)|\boldsymbol{y}]=\int_{\Theta}g(\theta)p(\theta|\boldsymbol{y})\,d\theta
\tag{2}\]</span></span> と表される．先ほどのBayesの区間推定の例では <span class="math inline">\(g=1_{(a,b)}\)</span> と取った場合に当たる．<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<p>実は，<strong>この最も簡単と思われる設定でも，この積分は殆ど計算できないのである</strong>．そのこともあってか，論文 <span class="citation" data-cites="Bayes1763">(<a href="#ref-Bayes1763" role="doc-biblioref">Bayes, 1763</a>)</span> は実はBayesの死後にRichard Priceによって投稿されたものであり，生前に自ら投稿・発表した訳ではなかった．<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> 当然，発表当時も全く注目を受けなかった <span class="citation" data-cites="Stigler1990">(<a href="#ref-Stigler1990" role="doc-biblioref">Stigler, 1990</a>)</span>．</p>
<blockquote class="blockquote">
<p>Hence, despite the analytical availability of <span class="math inline">\(p(\theta|\boldsymbol{y})\)</span> via (2)–“Bayes’ rule” as it is now known-—the quantity that was of interest to Bayes needed to be estimated, or <em>computed</em>. The quest for a computational solution to a Bayesian problem was thus born. <span class="citation" data-cites="Martin+2023-history">(<a href="#ref-Martin+2023-history" role="doc-biblioref">Martin et al., 2023, p. 2</a>)</span></p>
</blockquote>
<div class="callout callout-style-default callout-important no-icon callout-titled" title="ベイズ統計学の基本問題">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
ベイズ統計学の基本問題
</div>
</div>
<div class="callout-body-container callout-body">
<p>ベイズの枠組み</p>
<ol type="1">
<li>まず<strong>事前分布</strong> <span class="math inline">\(p(\theta)\)</span> と呼ばれる，最初の <span class="math inline">\(\theta\in(0,1)\)</span> に対する予想を自由に表現する．</li>
<li>この事前の信念をデータを用いて修正する形で，<strong>事後分布</strong> <span class="math inline">\(p(\theta|\boldsymbol{y})\)</span> を得る．</li>
</ol>
<p>は非常に自然で，特に確率分布を簡単にプロットできる現代では不確実性が明確に図示できるという美点がある．しかしながら，モデル <span class="math inline">\(p(\theta),p(\boldsymbol{y}|\theta)\)</span> の設定をいくら簡単にしても根本的に計算が困難で実行不可能なのである．これを解決する分野を<strong>ベイズ計算</strong>という．Bayesの論文 <span class="citation" data-cites="Bayes1763">(<a href="#ref-Bayes1763" role="doc-biblioref">Bayes, 1763</a>)</span> でも，計算法の開発が約半分を占めた．<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> このように，<strong>Bayes統計学は当初からBayes計算の問題を懐胎していた</strong>のである．</p>
<blockquote class="blockquote">
<p>In short, the implementation of all forms of Bayesian analysis relies heavily on numerical computation. <span class="citation" data-cites="Martin+2023-history">(<a href="#ref-Martin+2023-history" role="doc-biblioref">Martin et al., 2023, p. 2</a>)</span></p>
</blockquote>
</div>
</div>
</section>
<section id="sec-Laplace" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="sec-Laplace"><span class="header-section-number">1.5</span> Laplaceの近似</h2>
<p>Laplace 25歳時の初めての統計に関する著作 <span class="citation" data-cites="Laplace1774">(<a href="#ref-Laplace1774" role="doc-biblioref">Laplace, 1774</a>)</span> で，Bayesが解こうとしたものと全く同じ</p>
<p><span id="eq-Beta-integral"><span class="math display">\[\begin{align*}
    &amp;\mathrm{P}[a&lt;\theta&lt;b|\boldsymbol{y}]\\
    &amp;\quad=\frac{\int^b_a\theta^m(1-\theta)^{n-m}\,d\theta}{B(m+1,n-m+1)}
\end{align*} \tag{3}\]</span></span></p>
<p>という積分の計算の問題を，被積分関数を <span class="math display">\[
f(\theta):=\frac{\log p(\theta|\boldsymbol{y})}{n}
\]</span> を用いて指数関数の形に表すことで解いた：<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> <span class="math display">\[
\begin{align*}
    \mathrm{P}[a&lt;\theta&lt;b|\boldsymbol{y}]&amp;=\int^b_ap(\theta|\boldsymbol{y})\,d\theta\\
    &amp;=\int^b_ae^{nf(\theta)}\,d\theta
\end{align*}
\]</span> この形に変形することがどのように役立つかは，次の定理が説明してくれる：</p>
<div class="callout callout-style-default callout-tip callout-titled" title="定理（Laplace近似）">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定理（Laplace近似）
</div>
</div>
<div class="callout-body-container callout-body">
<p><a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> 関数 <span class="math inline">\(f:[a,b]\to\mathbb{R}\)</span> はただ一つの最大値を <span class="math inline">\(x_0\in(a,b)\)</span> で取り，<span class="math inline">\(f''(x_0)&gt;0\)</span> を満たすとする．このとき <span class="math inline">\(n\to\infty\)</span> の極限について， <span class="math display">\[
\int^b_ae^{nf(x)}\,dx\sim\sqrt{-\frac{2\pi}{nf''(x_0)}}e^{nf(x_0)}
\]</span></p>
</div>
</div>
<p>これを <span class="math inline">\(f\)</span> の二次近似について適用することで，あらゆる確率分布 <span class="math inline">\(p(\theta|\boldsymbol{y})\,d\theta\)</span> に関する積分 <a href="#eq-Beta-integral">式&nbsp;3</a> について，その正規近似の積分で近似できるのである．</p>
<p>この手法は現在のBayes計算手法のアイデアの源泉であり続けている <span class="citation" data-cites="Rue+2009">(<a href="#ref-Rue+2009" role="doc-biblioref">Rue et al., 2009</a>)</span>．</p>
</section>
<section id="ベイズ統計学の長く苦しい時代" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="ベイズ統計学の長く苦しい時代"><span class="header-section-number">1.6</span> ベイズ統計学の長く苦しい時代</h2>
<p>上述の「<span class="citation" data-cites="Bayes1763">(<a href="#ref-Bayes1763" role="doc-biblioref">Bayes, 1763</a>)</span> の手法は理念的に好ましかろうと，実際には実行不可能である」という問題は，Laplaceが普遍的な近似計算手法を開発したこと（ <a href="#sec-Laplace">節&nbsp;1.5</a> ）を除いて，計算機の発明と普及を待つ必要があった．その間実に2世紀超えである．</p>
<p>また，Laplaceの近似手法は普遍的であり，Bayesの最初の設定のような簡単な <span class="math inline">\(p(\theta|\boldsymbol{y})\)</span> と <span class="math inline">\(g=1_{(a,b)}\)</span> に限らずとも使えるという，ベイズ統計学にとって最も重要な特徴も備えていたが，パラメータ <span class="math inline">\(\theta\in(0,1)\)</span> の次元が1ではなくなると途端に使えなくなるという欠点がある．</p>
<blockquote class="blockquote">
<p>（前略）ベイズ統計学の有用性は以前から理解されていたが，この問題の抜本的な解決は1980年代まで待たざるを得なかった．<strong>それ以前は，ベイズの定理自体は18世紀に早々に発見されたにもかかわらず，長い間，確率の解釈，事前分布の設定，事後分布の計算の困難さのために哲学的議論に終始し，実用化にはほど遠かったのである</strong>．実用化の扉の鍵となったのは，一つは計算機の急速な発達，もう一つは計算集約的な画期的アルゴリズムの提案である． <span class="citation" data-cites="樋口知之2014">(<a href="#ref-樋口知之2014" role="doc-biblioref">樋口知之, 2014, p. 17</a>)</span></p>
</blockquote>
</section>
<section id="フランスでの確率論の歴史" class="level2" data-number="1.7">
<h2 data-number="1.7" class="anchored" data-anchor-id="フランスでの確率論の歴史"><span class="header-section-number">1.7</span> フランスでの確率論の歴史</h2>
<p>このように，Laplaceが，ベイズ統計学暗黒の時代の中で唯一の小さな前身を産んだ．それだけでなく，Laplaceは確率論最大の集大成を産んでおり，これが他でもないフランスから生まれたことにも相応の理由があった．</p>
<p>まず第一に，賭博の流行により，確率というものの理解と征服が嘱望された．</p>
<blockquote class="blockquote">
<p>その（確率論の）発展の動きを与えたものは，交易を賭ける商業資本家が占星術よりも確実な指導をこの学術に求めるという様な社会が基盤となって存在したことである．例えば，17世紀中葉のPascalとFermatの間の往復文書に取り扱われたカード遊びの数学的問題が，広く人々の関心を呼び起こした事情の裏には，至富の途を確実に求める商人たちの渇望が学問が外の世界にあったことを忘れてはならない． <span class="citation" data-cites="北川敏男49-統計学の認識">(<a href="#ref-北川敏男49-統計学の認識" role="doc-biblioref">北川敏男, 1949</a>)</span></p>
</blockquote>
<p>第二に，統計的現象を神学的な畏怖の対象と見るのではなく，自然科学による自然の理解と征服の文脈の最先端として理解する土壌がフランスにあったことが指摘できる．</p>
<blockquote class="blockquote">
<p>17, 18世紀の啓蒙的合理主義は，偶然的な事象に対しても数学的な取り扱いを行うことに特別の興味を持った．思想的にはこの時代精神こと確率論を発展させた最大の動力であった．その駆使する数学解析の多彩と合理主義の徹底とに於て，Laplaceの大著はよくこの時代を代表するものと言うべきであろう．</p>
</blockquote>
<blockquote class="blockquote">
<p>古典確率論の一応の完成は典雅に見えるであろう．<strong>だが人は，確率論のもった政治的，社会的意義を忘れてはならない</strong>．理知を一切の尺度として「代数学の炉火によって倫理学及び政治学を照さん」(<a href="https://ja.wikipedia.org/wiki/%E3%83%8B%E3%82%B3%E3%83%A9%E3%83%BB%E3%83%89%E3%83%BB%E3%82%B3%E3%83%B3%E3%83%89%E3%83%AB%E3%82%BB">Condorcet</a>) という時代精神，神の啓示に代らんとする確率論，それはフランス革命の思想的基礎に連関することを見失ってはならないのである． <span class="citation" data-cites="北川敏男49-統計学の認識">(<a href="#ref-北川敏男49-統計学の認識" role="doc-biblioref">北川敏男, 1949</a>)</span></p>
</blockquote>
</section>
</section>
<section id="mcmcとsmcの発明" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> MCMCとSMCの発明</h1>
<p>「積分が計算できない」というベイズ統計学の基本問題（ <a href="#sec-fundamental-problem-of-Bayes">節&nbsp;1.4</a> ）は，計算機の発達と普及と同時に，<strong>シミュレーションによる確率的アルゴリズムの開発</strong>によって根本的に解決された．</p>
<p>しかし，この解決法は必ずしもベイズ統計学のために考案されたわけではなく，むしろ物理学と第二次世界大戦とに深い関係があった．</p>
<p><span class="math display">\[
\mathrm{E}[g(\boldsymbol{\theta})|\boldsymbol{y}]=\int_{\Theta}g(\theta)p(\theta|\boldsymbol{y})\,d\theta
\]</span></p>
<blockquote class="blockquote">
<p>In fact, until Bayesians discovered MCMC, the only computational methodology that seemed to offer much chance of making practical Bayesian statistics practical was the portfolio of quadrature methods developed under Adrian Smith’s leadership at Nottingham (Naylor and Smith 1982; Smith et al.&nbsp;1985, 1987). <span class="citation" data-cites="Green+2015">(<a href="#ref-Green+2015" role="doc-biblioref">Green et al., 2015, p. 836</a>)</span></p>
</blockquote>
<section id="マルコフ連鎖によるモンテカルロ法の発明" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="マルコフ連鎖によるモンテカルロ法の発明"><span class="header-section-number">2.1</span> マルコフ連鎖によるモンテカルロ法の発明</h2>
<p>乱数のシミュレーションを用いた確率的なアルゴリズムをMonte Carlo法と総称する．このようなアルゴリズムが最初に生まれたのが，第二次世界大戦中の <a href="https://ja.wikipedia.org/wiki/%E3%83%AD%E3%82%B9%E3%82%A2%E3%83%A9%E3%83%A2%E3%82%B9%E5%9B%BD%E7%AB%8B%E7%A0%94%E7%A9%B6%E6%89%80">Los Alamos研究所</a> で進行中だった原爆開発計画である <a href="https://ja.wikipedia.org/wiki/%E3%83%9E%E3%83%B3%E3%83%8F%E3%83%83%E3%82%BF%E3%83%B3%E8%A8%88%E7%94%BB">Manhattan計画</a> においてである．当時の問題は，原子爆弾着火時におけるSchödinger作用素の基底状態のエネルギーを計算することにあった．抽象的には，<span class="math inline">\(p\)</span> を <span class="math inline">\(N\)</span> 個の粒子が従うBoltzmann分布として，積分 <a href="#eq-object-integral">式&nbsp;2</a> を計算することにあった：</p>
<p><span class="math display">\[
\mathrm{E}[g(\boldsymbol{\theta})]=\int_\Theta g(\boldsymbol{\theta})p(\boldsymbol{\theta})\,d\boldsymbol{\theta}
\]</span></p>
<p>ただし，</p>
<ol type="1">
<li>積分領域 <span class="math inline">\(\Theta\)</span> が <span class="math inline">\(2N\)</span> 次元というとてつもない高次元空間上であること</li>
<li>分布 <span class="math inline">\(p\)</span> は定数倍を除いてしか計算できない</li>
</ol>
<p>という，2つの大きな制約があった．1のために通常の数値積分法が使えず，また2により通常のMonte Carlo法を実行することも出来ない．そこで，Metropolisら当時のLos Alamosに集まった物理学者たちは新しい方法を考える必要があった．</p>
<p>最終的な解決 <span class="citation" data-cites="Metropolis+1953">(<a href="#ref-Metropolis+1953" role="doc-biblioref">Metropolis et al., 1953</a>)</span> は，Monte Carlo法の中でもとりわけ画期的な発想によるものであった．それは，<strong>Markov連鎖を用いる</strong>ということである．Markov連鎖とは（ある一定の条件を満たす）確率過程のクラスであり，<span class="math inline">\(p\)</span> から直接のシミュレーションが出来ない状況でも，<span class="math inline">\(p\)</span> に収束するようなMarkov連鎖を構成することは可能だったのである．</p>
<p>制約1と2は広く物理学，ベイズ統計学で見られる障壁であり，これをものともしない汎用アルゴリズムの発明は極めて大きなブレイクスルーであった．<span class="citation" data-cites="Dongarra-Sulliavn2000">(<a href="#ref-Dongarra-Sulliavn2000" role="doc-biblioref">Dongarra &amp; Sullivan, 2000</a>)</span> はMetropolisアルゴリズムを理学・工学分野に20世紀最大の影響を与えたアルゴリズムの1つとしている．</p>
</section>
<section id="重点サンプリング法の発明" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="重点サンプリング法の発明"><span class="header-section-number">2.2</span> 重点サンプリング法の発明</h2>
<p>実はManhattan計画に最中に，もう一つのサンプリング技法が生まれていた．厚い壁で中性子線とガンマ線がどのように吸収されるかに取り組んでいたグループにて，<a href="https://ja.wikipedia.org/wiki/%E3%83%8F%E3%83%BC%E3%83%9E%E3%83%B3%E3%83%BB%E3%82%AB%E3%83%BC%E3%83%B3">Herman Kahn</a> らが中心となり，<a href="#eq-object-integral">式&nbsp;2</a> の積分が <span class="math display">\[
\begin{align*}
    \mathrm{E}[g(\boldsymbol{\theta})]&amp;=\int_\Theta g(\boldsymbol{\theta})p(\boldsymbol{\theta})\,d\boldsymbol{\theta}\\
    &amp;=\int_\Theta\frac{g(\boldsymbol{\theta})p(\boldsymbol{\theta})}{q(\boldsymbol{\theta})}q(\boldsymbol{\theta})\,d\boldsymbol{\theta}
\end{align*}
\]</span> の式変形により，別の分布 <span class="math inline">\(q\)</span> からのサンプリングを通じて計算できる，という技法が利用された．彼らはこれに<strong>重点サンプリング法</strong>という名前をつけた．<a href="https://en.wikipedia.org/wiki/Gerald_Goertzel">Gerald Goertzel</a> による命名である可能性が高い <span class="citation" data-cites="Charly2022">(<a href="#ref-Charly2022" role="doc-biblioref">Andral, 2022</a>)</span>．</p>
<p>なお，当時は <span class="math inline">\(p\)</span> からのサンプリングを回避できるという点よりも，<span class="math inline">\(q\)</span> をうまく選ぶことにより元々の <span class="math inline">\(p\)</span> を用いたMonte Carlo積分法を適用するよりも近似の精度をあげることが出来るという点の方が注目された <span class="citation" data-cites="Hammersley-Handscomb1964">(<a href="#ref-Hammersley-Handscomb1964" role="doc-biblioref">Hammersley &amp; Handscomb, 1964</a>)</span>．</p>
<p>前節のMetropolis法が現代のMCMCの先駆けであるとしたら，この2つの美点を持った重点サンプリング法は，現代の <a href="../../../posts/2023/2023-11-25/ParticleFilter.html">SMC（粒子フィルター）</a> の先駆けであった．</p>
</section>
<section id="mcmcの普及とギブスサンプラー" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="mcmcの普及とギブスサンプラー"><span class="header-section-number">2.3</span> MCMCの普及とギブスサンプラー</h2>
<p>Metropolis法の発明から，すぐにMCMCの画期性が広く認識された訳ではなかった．特に，元々物理学の文脈で発明されたこともあり，統計学の文脈への応用が始まるには <span class="citation" data-cites="Hastings1970">(<a href="#ref-Hastings1970" role="doc-biblioref">Hastings, 1970</a>)</span> の仕事を待つ必要があった．</p>
<p>しかし1970年代とはマイクロプロセッサが開発されたばかりの時代であり，MCMCが実際の統計解析の現場で採用可能な計算手法になるとは夢にも思われなかった時代であったが，ここからたったの20年で現代人の生活は大きく変わることになる．</p>
<ol type="1">
<li>各人が安価に高性能なコンピュータを所有するようになった．</li>
<li>高次元分布からのサンプリングも可能になった．</li>
</ol>
<p>の2点が最後に加わることで，MCMCがベイズ計算法不動の金科玉条となった．</p>
<p>この2は計算機の性能の問題だけでなく，<strong>Gibbsサンプラー</strong>という新たなアルゴリズムの開発 <span class="citation" data-cites="Geman-Geman1984">(<a href="#ref-Geman-Geman1984" role="doc-biblioref">Geman &amp; Geman, 1984</a>)</span> によって実現された．<span class="math inline">\(\boldsymbol{\theta}=(\theta_1,\theta_2)^\top\)</span> と表されるとき，適切に定めた初期値 <span class="math inline">\(\theta_2^{(0)}\)</span> から初めて，条件付き分布からのサンプリング <span class="math display">\[
\theta_1^{(i)}\sim p_1(\theta_1^{(i)}|\theta_2^{(i-1)},\boldsymbol{y}),
\]</span> <span class="math display">\[
\theta_2^{(i)}\sim p_2(\theta_2^{(i)}|\theta_1^{(i)},\boldsymbol{y}),
\]</span> を繰り返すことで，最終的に <span class="math inline">\(\boldsymbol{\theta}^{(i)}:=(\theta_1^{(i)},\theta_2^{(i)})^\top\)</span> は全体として <span class="math inline">\(p(\boldsymbol{\theta}|\boldsymbol{y})\)</span> に従うように収束する，という技法である．</p>
<p>これにより，<span class="math inline">\(\boldsymbol{\theta}\)</span> 自体の次元が高く，直接のサンプリングが難しい場合でも，<span class="math inline">\(\boldsymbol{\theta}=(\theta_1,\theta_2,\cdots)\)</span> というように低次元変数の結合と理解することで，あるいは<strong>補助変数</strong>を追加してわざと問題を高次元化してでもそのような状況をうまく作り出すことで <span class="citation" data-cites="Tanner-Wong1987">(<a href="#ref-Tanner-Wong1987" role="doc-biblioref">Tanner &amp; Wong, 1987</a>)</span> ，部分的な低次元サンプリングから組み上げることが出来るようになった．</p>
<p>この点をはっきり強調して示し，統計学界隈に広く知らしめたのが <span class="citation" data-cites="Gelfand-Smith1990">(<a href="#ref-Gelfand-Smith1990" role="doc-biblioref">Gelfand &amp; Smith, 1990</a>)</span> であり，さらにその後も，このアイデアが <span class="citation" data-cites="Roberts-Rosenthal1999-SliceSampler">(<a href="#ref-Roberts-Rosenthal1999-SliceSampler" role="doc-biblioref">Roberts &amp; Rosenthal, 1999</a>)</span> のスライスサンプラーにつながっている．</p>
</section>
</section>
<section id="ベイズ統計学のこれから" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> ベイズ統計学のこれから</h1>
<p>更なる複雑なモデル・データに対応できるベイズ計算手法の開発が最も肝要な課題だと筆者は信じる．情報コミュニケーション技術が高度に発展した現代ならではの課題は，次の3つに大きく分類できる：</p>
<ol type="1">
<li>尤度不在推論：尤度が解析的に得られないほどに複雑なモデル</li>
<li><span class="math inline">\(\boldsymbol{\theta}\)</span> が高次元である：多くの変数を考慮に入れた高次元モデル</li>
<li><span class="math inline">\(\boldsymbol{y}\)</span> が高次元である：ビッグデータを用いた解析</li>
</ol>
<section id="擬似周辺尤度法" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="擬似周辺尤度法"><span class="header-section-number">3.1</span> 擬似周辺尤度法</h2>
<p>実は尤度 <span class="math inline">\(p(\boldsymbol{y}|\boldsymbol{\theta})\)</span> が解析的に得られない場合や計算が極めて困難になる場合でも，この不偏推定量があればMCMCを実行して事後分布を得るのに十分である <span class="citation" data-cites="Andrieu-Roberts2009">(<a href="#ref-Andrieu-Roberts2009" role="doc-biblioref">Andrieu &amp; Roberts, 2009</a>)</span>．この尤度 <span class="math inline">\(p(\boldsymbol{y}|\boldsymbol{\theta})\)</span> の不偏推定量を得るのに粒子フィルターを用いた場合を，特に<strong>粒子MCMC</strong>という <span class="citation" data-cites="Andrieu+2010-PMCMC">(<a href="#ref-Andrieu+2010-PMCMC" role="doc-biblioref">Andrieu et al., 2010</a>)</span>．</p>
<p>このときの不偏推定量の性能が最終的なMonte Carlo推定量に影響する．不偏推定量の分散を改善するには，サブルーチンである粒子フィルターの反復数を増やす必要がある．すると本体であるMCMCの反復数とのトレードオフが生じる．こうしてアルゴリズムの最適な調整が課題になる．</p>
</section>
<section id="高次元問題に対処するmcmc" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="高次元問題に対処するmcmc"><span class="header-section-number">3.2</span> 高次元問題に対処するMCMC</h2>
<p>ほとんどのMCMC手法は，データサイズやモデルのパラメータサイズの増加に対して，計算負荷が飛躍的に上昇する次元の呪いに苦しむ．これを克服する手法は<strong>scalability</strong>の名の下に盛んに研究されている <span class="citation" data-cites="鎌谷2021">(<a href="#ref-鎌谷2021" role="doc-biblioref">鎌谷研吾, 2021, p. 394</a>)</span>．</p>
<ol type="1">
<li>対象分布の探索を効率よく行う手法として，HMC (Hamiltonian Monte Carlo) 法が提案された <span class="citation" data-cites="Neal2011-HMC">(<a href="#ref-Neal2011-HMC" role="doc-biblioref">Neal, 2011</a>)</span>．他にも NUTS (No U-Turn Sampling) <span class="citation" data-cites="Hoffman-Gelman2014-NUTS">(<a href="#ref-Hoffman-Gelman2014-NUTS" role="doc-biblioref">Hoffman &amp; Gelman, 2014</a>)</span>, Metropolis-Adjusted Langevin Algorithm <span class="citation" data-cites="Roberts-Tweedie1996">(<a href="#ref-Roberts-Tweedie1996" role="doc-biblioref">Roberts &amp; Tweedie, 1996</a>)</span>, Stochastic Gradient MCMC <span class="citation" data-cites="Nemeth-Fearnhead2021">(<a href="#ref-Nemeth-Fearnhead2021" role="doc-biblioref">Nemeth &amp; Fearnhead, 2021</a>)</span>, PDMP (区分的確定なMCMC) <span class="citation" data-cites="Bierkens+2018-PDMC">(<a href="#ref-Bierkens+2018-PDMC" role="doc-biblioref">Bierkens et al., 2018</a>)</span>, <span class="citation" data-cites="Fearnhead+2018-PDMC">(<a href="#ref-Fearnhead+2018-PDMC" role="doc-biblioref">Fearnhead et al., 2018</a>)</span> とジグザグサンプラー <span class="citation" data-cites="Bierkens+2019-ZigZag">(<a href="#ref-Bierkens+2019-ZigZag" role="doc-biblioref">Bierkens et al., 2019</a>)</span> などがある，</li>
<li>より良い提案分布の選択法について，MH法の最適スケーリング法，適応的サンプリング，焼き戻しなどの手法がある．</li>
<li>並列計算による効率化の方向性には，並列MCMC，完全サンプリングなどの手法がある．</li>
<li>他の分散低減法に，Rao-Blackwell化 <span class="citation" data-cites="Casella-Robert1996">(<a href="#ref-Casella-Robert1996" role="doc-biblioref">Casella &amp; Robert, 1996</a>)</span>，操作変数法などがある．</li>
</ol>
</section>
<section id="近似ベイズ手法" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="近似ベイズ手法"><span class="header-section-number">3.3</span> 近似ベイズ手法</h2>
<p>上述までの手法はいずれもシミュレーションを十分多く行えば（理論的には）任意の精度で正しい値を得ることができるが，<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> その適用範囲やスケーラビリティが課題なのであった．そこで同時に，最初からある許容精度を定めた下での近似を実行することとし，代わりにより広い適用可能性と計算速度を得るための手法も探求されている．これを<strong>近似ベイズ法</strong>という．</p>
<p>一つのアプローチはシミュレーションによる方法である．これにはABC (Approximation Bayesian Computation) <span class="citation" data-cites="Tavare97-ABC-for-DNA">(<a href="#ref-Tavare97-ABC-for-DNA" role="doc-biblioref">Tavaré et al., 1997</a>)</span> と BSL (Bayesian synthetic likelihood) <span class="citation" data-cites="Price2018-BSL">(<a href="#ref-Price2018-BSL" role="doc-biblioref">Price et al., 2018</a>)</span> の2つの手法があるが，いずれもデータ生成過程（モデル）の複雑性と高次元性という２つの障壁が併存したときでも使える手法である．ABCではまず事後分布 <span class="math inline">\(p(\boldsymbol{\theta}|\boldsymbol{y})\)</span> をある低次元な要約統計量 <span class="math inline">\(S:\mathcal{Y}\to\mathbb{R}^d\)</span> を用いて <span class="math inline">\(p(\boldsymbol{\theta}|S(\boldsymbol{y}))\)</span> で近似し，さらに尤度 <span class="math inline">\(p(\boldsymbol{y}|\boldsymbol{\theta})\)</span> を直接評価することは回避し，シミュレーションのみを用いて <span class="math inline">\(p(\boldsymbol{\theta}|S(\boldsymbol{y}))\)</span> を推定する．BSLはさらに尤度 <span class="math inline">\(p(S(\boldsymbol{y})|\boldsymbol{\theta})\)</span> にパラメトリックな仮定をおく．</p>
<p>第二に最適化による方法がある．変分ベイズ手法とは，これは大きなパラメトリックモデル <span class="math inline">\(\{q^*(\boldsymbol{\theta})\}\)</span> の中から <span class="math inline">\(p(\boldsymbol{\theta}|\boldsymbol{y})\)</span> に最も近いものを選ぶ手法である．一方で INLA (integrated nested Laplace approximation) とは，Laplaceの近似（ <a href="#sec-Laplace">節&nbsp;1.5</a> ）に最適化を組み合わせて高次元の問題にも対応する．</p>
<p>ABCでは逐次モンテカルロ法も大きな役割を果たしており，ABC-SMC <span class="citation" data-cites="Sisson+2007">(<a href="#ref-Sisson+2007" role="doc-biblioref">Sisson et al., 2007</a>)</span>，ABCフィルタリング <span class="citation" data-cites="Jasra+2012-ABCFiltering">(<a href="#ref-Jasra+2012-ABCFiltering" role="doc-biblioref">Jasra et al., 2012</a>)</span>，更には変分Bayes法への応用 <span class="citation" data-cites="Tran+2017">(<a href="#ref-Tran+2017" role="doc-biblioref">Tran et al., 2017</a>)</span> なども進んでいる．</p>
<p>変分Bayesの枠組みでは，モデルの誤想定に頑健な手法の開発も試みられている <span class="citation" data-cites="Wang-Blei2019">(<a href="#ref-Wang-Blei2019" role="doc-biblioref">Wang &amp; Blei, 2019</a>)</span>．</p>
</section>
<section id="ベイズ統計モデリングが理論モデルの実証に役立つ" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="ベイズ統計モデリングが理論モデルの実証に役立つ"><span class="header-section-number">3.4</span> ベイズ統計モデリングが理論モデルの実証に役立つ</h2>
<p>ベイズモデリングの有用性は，（上述のベイズ計算の問題を除けば）どんなに複雑で大規模なモデルでも，統一的な思想と方法で対応できる点にある．</p>
<blockquote class="blockquote">
<p>メカニズムを明示的に表現した数理社会学の数理モデルを，論理的に飛躍することなくダイレクトに統計モデルへと接続できるベイズ統計モデリングは，理論モデルベースの実証研究と相性のよい，たいへん便利な方法と言えるだろう． <span class="citation" data-cites="浜田宏2022">(<a href="#ref-浜田宏2022" role="doc-biblioref">浜田宏, 2022, p. 137</a>)</span></p>
</blockquote>
<p>MCMCの開発とパッケージへの実装と安価で高性能な計算機が普及してからベイズ統計学の興隆は目覚ましく，現在ではベイズ統計学は統計学に関する論文の1割強を占め，諸科学分野全体に浸透しつつあるが，経済学・心理学への応用は早かったのに比べて，政治科学・社会科学への応用は遅れ気味であり，社会学での使用はまだ稀であると言える <span class="citation" data-cites="Lynch-Bartlett2019">(<a href="#ref-Lynch-Bartlett2019" role="doc-biblioref">Lynch &amp; Bartlett, 2019</a>)</span>．</p>
</section>
<section id="ベイズ因果推論" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="ベイズ因果推論"><span class="header-section-number">3.5</span> ベイズ因果推論</h2>
</section>
<section id="ベイズ学習" class="level2" data-number="3.6">




</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">3.6 ベイズ学習</h2><div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="list">
<div id="ref-Charly2022" class="csl-entry" role="listitem">
Andral, C. (2022). <em>An attempt to trace the birth of importance sampling</em>. <a href="https://arxiv.org/abs/2206.12286">https://arxiv.org/abs/2206.12286</a>
</div>
<div id="ref-Andrieu+2010-PMCMC" class="csl-entry" role="listitem">
Andrieu, C., Doucet, A., &amp; Holenstein, R. (2010). Particle markov chain monte carlo methods. <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em>, <em>72</em>(3), 269–342.
</div>
<div id="ref-Andrieu-Roberts2009" class="csl-entry" role="listitem">
Andrieu, C., &amp; Roberts, G. O. (2009). The pseudo-marginal approach for efficient monte carlo computations. <em>The Annals of Statistics</em>, <em>37</em>(2), 697–725.
</div>
<div id="ref-Bayes1763" class="csl-entry" role="listitem">
Bayes, T. (1763). An essay towards solving a problem in the doctrine of chances. By the late rev. Mr. Bayes, f. R. S. Communicated by mr. Price, in a letter to john canton, a. M. F. R. s. <em>Philosophical Transactions</em>, <em>53</em>(1763), 370–418. <a href="https://www.jstor.org/stable/105741">https://www.jstor.org/stable/105741</a>
</div>
<div id="ref-Bierkens+2018-PDMC" class="csl-entry" role="listitem">
Bierkens, J., Bouchard-Côté, A., Doucet, A., Duncan, A. B., Fearnhead, P., Lienart, T., Roberts, G., &amp; Vollmer, S. J. (2018). Piecewise deterministic markov processes for scalable monte carlo on restricted domains. <em>Statistics &amp; Probability Letters</em>, <em>136</em>, 148–154.
</div>
<div id="ref-Bierkens+2019-ZigZag" class="csl-entry" role="listitem">
Bierkens, J., Fearnhead, P., &amp; Roberts, G. (2019). The zig-zag process and super-efficient sampling for bayesian analysis of big data. <em>The Annals of Statistics</em>, <em>47</em>(3), 1288–1320.
</div>
<div id="ref-Casella-Robert1996" class="csl-entry" role="listitem">
Casella, G., &amp; Robert, C. P. (1996). Rao-blackwellisation of sampling schemes. <em>Biometrika</em>, <em>83</em>(1), 81–94.
</div>
<div id="ref-Dongarra-Sulliavn2000" class="csl-entry" role="listitem">
Dongarra, J., &amp; Sullivan, F. (2000). Guest editors introduction to the top 10 algorithms. <em>Computing in Science &amp; Engineering</em>, <em>2</em>, 22–23.
</div>
<div id="ref-Fearnhead+2018-PDMC" class="csl-entry" role="listitem">
Fearnhead, P., Bierkens, J., Pollock, M., &amp; Roberts, G. O. (2018). Piecewise deterministic markov processes for continuous-time monte carlo. <em>Statistical Science</em>, <em>33</em>(3), 386–412.
</div>
<div id="ref-Gelfand-Smith1990" class="csl-entry" role="listitem">
Gelfand, A. E., &amp; Smith, A. F. M. (1990). Sampling-based approaches to calculating marginal densities. <em>Journal of the American Statistical Association</em>, <em>85</em>(410), 398–409.
</div>
<div id="ref-Geman-Geman1984" class="csl-entry" role="listitem">
Geman, S., &amp; Geman, D. (1984). Stochastic relaxation, gibbs distributions, and the bayesian restoration of images. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, <em>PAMI-6</em>(6), 721–741.
</div>
<div id="ref-Graunt1662" class="csl-entry" role="listitem">
Graunt, J. (1662). <em>Natural and political observations mentioned in following index, and made upon the bills of mortality</em>.
</div>
<div id="ref-Green+2015" class="csl-entry" role="listitem">
Green, P. J., Łatuszyński, K., Pereyra, M., &amp; Robert, C. P. (2015). Bayesian computation: A summary of the current state, and samples backwards and forwards. <em>Statistics and Computing</em>, <em>25</em>(4), 835–862. <a href="https://link.springer.com/article/10.1007/s11222-015-9574-5">https://link.springer.com/article/10.1007/s11222-015-9574-5</a>
</div>
<div id="ref-Hammersley-Handscomb1964" class="csl-entry" role="listitem">
Hammersley, J. M., &amp; Handscomb, D. C. (1964). <em>Monte carlo methods</em>. Springer Dordrecht.
</div>
<div id="ref-Hastings1970" class="csl-entry" role="listitem">
Hastings, W. K. (1970). Monte carlo sampling methods using markov chains and their applications. <em>Biometrika</em>, <em>57</em>(1), 97–109. <a href="https://www.jstor.org/stable/2334940">https://www.jstor.org/stable/2334940</a>
</div>
<div id="ref-Hoffman-Gelman2014-NUTS" class="csl-entry" role="listitem">
Hoffman, M. D., &amp; Gelman, A. (2014). The no-u-turn sampler: Adaptively setting path lengths in hamiltonian monte carlo. <em>Journal of Machine Learning Research</em>, <em>15</em>, 1593–1623.
</div>
<div id="ref-Jasra+2012-ABCFiltering" class="csl-entry" role="listitem">
Jasra, A., Singh, S. S., Martin, J. S., &amp; McCoy, E. (2012). Filtergin via approximate bayesian computation. <em>Statistics and Computing</em>, <em>22</em>, 1223–1237. <a href="https://link.springer.com/article/10.1007/s11222-010-9185-0">https://link.springer.com/article/10.1007/s11222-010-9185-0</a>
</div>
<div id="ref-Laplace1774" class="csl-entry" role="listitem">
Laplace, P. S. (1774). Mémoire sur la probabilité des causes par les évènemens. <em>Mémoires de Mathématique Et de Physique Presentés à l’Académie Royale Des Sciences, Par Divers Savans, &amp; Lûs Dans Ses Assemblées</em>, <em>6</em>, 621–656.
</div>
<div id="ref-Lynch-Bartlett2019" class="csl-entry" role="listitem">
Lynch, S. M., &amp; Bartlett, B. (2019). Bayesian statistics in sociology: Past, present, and future. <em>Annual Review of Sociology</em>, <em>45</em>, 47–68. <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-soc-073018-022457">https://www.annualreviews.org/doi/abs/10.1146/annurev-soc-073018-022457</a>
</div>
<div id="ref-Martin+2023-history" class="csl-entry" role="listitem">
Martin, G. M., Fraizier, D. T., &amp; Robert, C. P. (2023). Computing bayes: From then ‘til now. <em>Statistical Science</em>, <em>Advanced Publication</em>, 1–17.
</div>
<div id="ref-Metropolis+1953" class="csl-entry" role="listitem">
Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., &amp; Teller, E. (1953). Equation of state calculations by fast computing machines. <em>The Journal of Chemical Physics</em>, <em>21</em>(6), 1087–1092.
</div>
<div id="ref-Neal2011-HMC" class="csl-entry" role="listitem">
Neal, R. M. (2011). (S. Brooks, A. Gelman, G. Jones, &amp; X.-L. Meng, Eds.; pp. 113–162). Chapman; Hall/CRC.
</div>
<div id="ref-Nemeth-Fearnhead2021" class="csl-entry" role="listitem">
Nemeth, C., &amp; Fearnhead, P. (2021). Stochastic gradient markov chain monte carlo. <em>Journal of the American Statistical Association</em>, <em>116</em>(533), 433–450.
</div>
<div id="ref-Pearson1926" class="csl-entry" role="listitem">
Pearson, K. (1926). Letters to editor. <em>Nature</em>, <em>117</em>(2946), 551–552.
</div>
<div id="ref-Price2018-BSL" class="csl-entry" role="listitem">
Price, L. F., Drovandi, C. C., Lee, A., &amp; Nott, D. J. (2018). Bayesian synthetic likelihood. <em>Journal of Computational and Graphical Statistics</em>, <em>27</em>(1), 1–11. <a href="https://www.tandfonline.com/doi/abs/10.1080/10618600.2017.1302882">https://www.tandfonline.com/doi/abs/10.1080/10618600.2017.1302882</a>
</div>
<div id="ref-Roberts-Rosenthal1999-SliceSampler" class="csl-entry" role="listitem">
Roberts, G. O., &amp; Rosenthal, J. S. (1999). Convergence of slice sampler markov chains. <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em>, <em>61</em>(3).
</div>
<div id="ref-Roberts-Tweedie1996" class="csl-entry" role="listitem">
Roberts, G. O., &amp; Tweedie, R. L. (1996). Exponential convergence of langevin distributions and their discrete approximations. <em>Bernoulli</em>, <em>2</em>(4), 341–363.
</div>
<div id="ref-Rue+2009" class="csl-entry" role="listitem">
Rue, H., Martino, S., &amp; Chopin, N. (2009). Approximate bayesian inference for latent gaussian models by using integrated nested laplace approximations. <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em>, <em>71</em>(2), 319–392. <a href="https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1467-9868.2008.00700.x">https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1467-9868.2008.00700.x</a>
</div>
<div id="ref-Sisson+2007" class="csl-entry" role="listitem">
Sisson, S. A., Fan, Y., &amp; Tanaka, M. M. (2007). Sequential monte carlo without likelihood. <em>PNAS (Proceedings of the National Academy of Sciences of the United States of America)</em>, <em>104</em>(6), 1760–1765. <a href="https://www.pnas.org/doi/full/10.1073/pnas.0607208104">https://www.pnas.org/doi/full/10.1073/pnas.0607208104</a>
</div>
<div id="ref-Stigler1990" class="csl-entry" role="listitem">
Stigler, S. M. (1990). <em>The history of statistics: The measurement of uncertainty before 1990</em>. Harvard University Press.
</div>
<div id="ref-Tanner-Wong1987" class="csl-entry" role="listitem">
Tanner, M. A., &amp; Wong, W. H. (1987). The calculation of posterior distributions by data augmentation. <em>Journal of the American Statistical Association</em>, <em>82</em>(398).
</div>
<div id="ref-Tavare97-ABC-for-DNA" class="csl-entry" role="listitem">
Tavaré, S., Balding, D. J., Griffiths, R. C., &amp; Donnelly, P. (1997). Inferring coalescence times from DNA sequence data. <em>Genetics</em>, <em>145</em>(2), 505–518.
</div>
<div id="ref-Tran+2017" class="csl-entry" role="listitem">
Tran, M.-N., Nott, D. J., &amp; Kohn, R. (2017). Variational bayes with intractable likelihood. <em>Journal of Computational and Graphical Statistics</em>, <em>26</em>(4), 873–882.
</div>
<div id="ref-Wang-Blei2019" class="csl-entry" role="listitem">
Wang, Y., &amp; Blei, D. M. (2019). Variational bayes under model misspecification. <em>Proceedings of the 33rd International Conference on Neural Information Processing Systems</em>, <em>1198</em>, 13379–13389.
</div>
<div id="ref-北川敏男49-統計学の認識" class="csl-entry" role="listitem">
北川敏男. (1949). <em>統計学の認識</em>. 白揚社.
</div>
<div id="ref-樋口知之2014" class="csl-entry" role="listitem">
樋口知之. (2014). 統計数理の誕生とその広がり. <em>横幹</em>, <em>8</em>(1), 14–21. <a href="https://www.jstage.jst.go.jp/article/trafst/8/1/8_14/_article/-char/ja/">https://www.jstage.jst.go.jp/article/trafst/8/1/8_14/_article/-char/ja/</a>
</div>
<div id="ref-浜田宏2022" class="csl-entry" role="listitem">
浜田宏. (2022). ベイズで広がる数理社会学の世界. <em>理論と方法</em>, <em>37</em>(1), 124–137. <a href="https://www.jstage.jst.go.jp/article/ojjams/37/1/37_124/_article/-char/ja/">https://www.jstage.jst.go.jp/article/ojjams/37/1/37_124/_article/-char/ja/</a>
</div>
<div id="ref-鎌谷2021" class="csl-entry" role="listitem">
鎌谷研吾. (2021). マルコフ連鎖モンテカルロ法における平均回帰. <em>日本統計学会誌</em>, <em>50</em>(2), 381–402. <a href="https://www.jstage.jst.go.jp/article/jjssj/50/2/50_381/_article/-char/ja/">https://www.jstage.jst.go.jp/article/jjssj/50/2/50_381/_article/-char/ja/</a>
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>正式名称をThe Royal Society for the Improvement of Natural Knowledge by Experimentという<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>当局の人間に死亡を報告する義務は全くなかった。その代わり、それぞれの教区では2人かそれ以上の死体を調査し、死因を決定する義務を負う調査員を任命していた。「調査員」は死亡を報告する毎に遺族より少額の手数料を徴収する資格が与えられていたので、教区では任命しなければ貧困のため救貧税による支援が必要となりそうな人間を割り当てていた。（<a href="https://ja.wikipedia.org/wiki/%E3%83%AD%E3%83%B3%E3%83%89%E3%83%B3%E3%81%AE%E5%A4%A7%E7%96%AB%E7%97%85">Wikipediaページより</a>）<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>これは統計的モデルとしてBernoulli分布 <span class="math inline">\(Y_i|\theta\overset{\mathrm{i.i.d.}}{\sim}\mathrm{Ber}(\theta)\)</span> を仮定するということである．<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>各 <span class="math inline">\(\theta\)</span> の下で目の前のデータ <span class="math inline">\(Y_1,\cdots,Y_n\)</span> が生成される確率 <span class="math inline">\(p(Y_1,\cdots,Y_n|\theta)\)</span> が低いということは，「その <span class="math inline">\(\theta\)</span> から生成されたデータである確率は低い」という逆の発想ができる．そこで <span class="math inline">\(p(Y_1,\cdots,Y_n|\theta)\)</span> という条件付き確率を<strong>尤度</strong>ともいう．<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>さらに，<span class="math inline">\(g(\theta)=\theta^p\)</span> と取った場合，事後積率という統計量になる．等に <span class="math inline">\(p=1\)</span> の場合が事後平均である．<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>なお，1763に出版されたものはPriceによる補遺も付いた短縮版であり，全文は1974年に出版された．<span class="citation" data-cites="Stigler1990">(<a href="#ref-Stigler1990" role="doc-biblioref">Stigler, 1990</a>)</span><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>pp.376-403 がBayesの論文の本論の内容であり pp.399-403 で計算法を３つのルールにまとめているが，その導出部は一部「長すぎるから掲載を省略する」とされている．<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>一方で，Bayesの逆確率の問題への言及自体は，Laplaceの後年の1781年の著作<em>Mémoire sur les probabilités</em>へのCondorcetによる序文で初めて登場する <span class="citation" data-cites="Martin+2023-history">(<a href="#ref-Martin+2023-history" role="doc-biblioref">Martin et al., 2023, p. 5</a>)</span>．<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p><a href="https://golem.ph.utexas.edu/category/2021/10/stirlings_formula.html">nCatLab</a> 参照．<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>この性質を指して，approximateの対義語としてexactという形容詞で表現される．<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>