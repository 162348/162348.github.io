<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Hirofumi Shiba</title>
<link>https://162348.github.io/blog.html</link>
<atom:link href="https://162348.github.io/blog.xml" rel="self" type="application/rss+xml"/>
<description>A Blog by a Bayesian Computation Researcher</description>
<image>
<url>https://162348.github.io/assets/categories.png</url>
<title>Hirofumi Shiba</title>
<link>https://162348.github.io/blog.html</link>
</image>
<generator>quarto-1.4.552</generator>
<lastBuildDate>Mon, 23 Sep 2024 15:00:00 GMT</lastBuildDate>
<item>
  <title>ベイズデータ解析４</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Survey/Survey4.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="関連記事" class="level2 unnumbered unlisted">
<h2 class="unnumbered unlisted anchored" data-anchor-id="関連記事">関連記事</h2>
<div id="listing-lst-survey" class="listing quarto-float quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Statistics,Bayesian" data-listing-date-sort="1727017200000" data-listing-file-modified-sort="1727270702903" data-listing-date-modified-sort="1727103600000" data-listing-reading-time-sort="3" data-listing-word-count-sort="501">
<a href="../../../posts/2024/Survey/Survey1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<!-- img(9CEB782EFEE6)[progressive=false, height=150px]:posts/2024/Survey/Survey1.html -->
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズデータ解析１
</h5>
<div class="card-subtitle listing-subtitle">
分散分析
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-23
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Statistics" data-listing-date-sort="1727017200000" data-listing-file-modified-sort="1727270702903" data-listing-date-modified-sort="1727017200000" data-listing-reading-time-sort="1" data-listing-word-count-sort="69">
<a href="../../../posts/2024/Survey/Survey2.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<!-- img(9CEB782EFEE6)[progressive=false, height=150px]:posts/2024/Survey/Survey2.html -->
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズデータ解析２
</h5>
<div class="card-subtitle listing-subtitle">
平均処置効果の推定
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-23
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Bayesian" data-listing-date-sort="1727103600000" data-listing-file-modified-sort="1727337923426" data-listing-date-modified-sort="1727190000000" data-listing-reading-time-sort="4" data-listing-word-count-sort="722">
<a href="../../../posts/2024/Survey/Survey3.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<!-- img(9CEB782EFEE6)[progressive=false, height=150px]:posts/2024/Survey/Survey3.html -->
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズデータ解析３
</h5>
<div class="card-subtitle listing-subtitle">
標本調査データと欠測データの扱い
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-24
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>
<section id="非確率標本とは何か" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="非確率標本とは何か"><span class="header-section-number">1</span> 非確率標本とは何か？</h2>
<blockquote class="blockquote">
<p>Generally speaking, these designs have not been explored in detail by survey researchers even though they are frequently used in other applied research ﬁelds. <span class="citation" data-cites="Baker+2013">(Baker et al., 2013, p. 91)</span></p>
</blockquote>
<p>母集団 <img src="https://latex.codecogs.com/png.latex?%5BN%5D"> から部分集合 <img src="https://latex.codecogs.com/png.latex?S%5Csubset%5BN%5D"> が標本として抽出されたとする．</p>
<section id="非確率抽出" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="非確率抽出"><span class="header-section-number">1.1</span> 非確率抽出</h3>
<p>この手続きは<a href="https://www.e-stat.go.jp/classifications/terms/90/00/4937">確率抽出</a> (probability sampling) ではないものとする．</p>
<p>確率標本とは <img src="https://latex.codecogs.com/png.latex?%5BN%5D"> の部分集合の全体 <img src="https://latex.codecogs.com/png.latex?P(%5BN%5D)"> 上の既知の確率分布に従っているとみなせる標本で，さらに何人も標本に選ばれる確率が零でないもの <img src="https://latex.codecogs.com/png.latex?%0A%5Cpi_i:=%5Coperatorname%7BP%7D%5Bi%5Cin%20S%5D%3E0%0A"> をいう．詳しくは，<a href="../../../posts/2024/Survey/Survey3.html#sec-probability-sample">前稿</a> も参照．</p>
<p>すなわち，<img src="https://latex.codecogs.com/png.latex?S%5Cin%5Cmathcal%7BL%7D(%5COmega;P(%5BN%5D))"> の従う分布が未知であったり，抽出計画上絶対に標本に入り得ない単位が存在する場合をいう．</p>
</section>
<section id="例" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="例"><span class="header-section-number">1.2</span> 例</h3>
<p>母集団 <img src="https://latex.codecogs.com/png.latex?%5BN%5D"> を国民全体だとした場合，確率抽出は国勢調査規模の営為によってのみしか達成し得ない．</p>
<p>多くの科学分野で実施されるような，特定の学校の学生や特定の地域の構成員を対象としたサンプル　<a href="https://en.wikipedia.org/wiki/Convenience_sampling"><strong>便宜的標本</strong></a> (convenience sample) は全て非確率標本に分類されることになる．</p>
<p>また多くのウェブアンケート代行業者は，事前にアンケートに協力することを約束したユーザーのプールからランダムに抽出して実行する．このような，自主的な応募によって得られたパネルを opt-in panel / panel of volunteers といい，ここからのサンプルもまた便宜的（二段階抽出）標本である．</p>
<p>そのほかの非確率的標本の例については，<span class="citation" data-cites="AAOR2013">(Section 3 AAOR, 2013)</span> を参照．</p>
</section>
<section id="データ統合" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="データ統合"><span class="header-section-number">1.3</span> データ統合</h3>
<p>このような非確率標本単体では出来ることが限られているかもしれないが，補助情報と組み合わせてモデルを立てることで統計的推論を試みることができる．</p>
<div class="table-responsive-sm">
<table class="table-hover table">
<caption>典型的なデータの例</caption>
<colgroup>
<col style="width: 10%">
<col style="width: 70%">
<col style="width: 10%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Sample</th>
<th style="text-align: center;">Design</th>
<th style="text-align: center;">X</th>
<th style="text-align: center;">Y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">A</td>
<td style="text-align: center;">Probability</td>
<td style="text-align: center;">X</td>
<td style="text-align: center;"><span class="color-unite">missing</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">B</td>
<td style="text-align: center;">Nonprobability</td>
<td style="text-align: center;">X</td>
<td style="text-align: center;">Y</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="バイアス低減" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="バイアス低減"><span class="header-section-number">1.4</span> バイアス低減</h3>
<p>各単位 <img src="https://latex.codecogs.com/png.latex?i%5Cin%5BN%5D"> が標本に包含される確率 <img src="https://latex.codecogs.com/png.latex?%0A%5Cpi_i:=%5Coperatorname%7BP%7D%5Bi%5Cin%20S%5D,%5Cqquad%20i%5Cin%20%5BN%5D,%0A"> が未知である場合でも，母集団 <img src="https://latex.codecogs.com/png.latex?%5BN%5D"> 上で <img src="https://latex.codecogs.com/png.latex?%0A%5Cpi_i%5E%7B-1%7D%5C,%5Cpropto%5C,x_i%5E%5Ctop%5Clambda,%5Cqquad%20i%5Cin%5BN%5D,%0A"> を満たす補助変数 <img src="https://latex.codecogs.com/png.latex?x_i%5C;(i%5Cin%5BN%5D)"> が利用可能ならば，推定のバイアスを低減することが可能である．</p>
</section>
<section id="傾向スコア" class="level3" data-number="1.5">
<h3 data-number="1.5" class="anchored" data-anchor-id="傾向スコア"><span class="header-section-number">1.5</span> 傾向スコア</h3>
<p>したがって <img src="https://latex.codecogs.com/png.latex?%5Cpi_i"> を推定することが問題になる．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cdelta_i:=1_S(i)"> が <img src="https://latex.codecogs.com/png.latex?%5Cdelta_i=1"> を満たすときのみ <img src="https://latex.codecogs.com/png.latex?y_i"> が観測されるとすると，</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cpi(x):=%5Coperatorname%7BP%7D%5B%5Cdelta=1%7CX=x%5D%0A"> を <strong>傾向スコア</strong> (propensity score) <span class="citation" data-cites="Rosenbaum-Rubin1983">(Rosenbaum and Rubin, 1983)</span> という．</p>
<p>傾向スコアを推定することで確率標本の議論に帰着させるというアプローチは quasi-randomization approach とも呼ばれる <span class="citation" data-cites="Elliott-Valliant2017">(Elliott and Valliant, 2017)</span>．</p>
</section>
</section>
<section id="校正推定量" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="校正推定量"><span class="header-section-number">2</span> 校正推定量</h2>
<section id="確率標本に対する校正推定量" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="確率標本に対する校正推定量"><span class="header-section-number">2.1</span> 確率標本に対する校正推定量</h3>
<p>GREG モデルと呼ばれる超母集団模型 <span id="eq-super-population-model"><img src="https://latex.codecogs.com/png.latex?%0Ay_i=x_i%5E%5Ctop%5Cbeta+e_i,%5Cqquad%20e_i%5Coverset%7B%5Ctext%7Biid%7D%7D%7B%5Csim%7D(0,c_i(x_i)%5Csigma%5E2),%0A%5Ctag%7B1%7D"></span> を仮定する．校正条件 <span id="eq-calibration-condition"><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi%5Cin%20S%7D%5Comega_ix_i=%5Csum_%7Bi=1%7D%5ENx_i%0A%5Ctag%7B2%7D"></span> を満たす荷重 <img src="https://latex.codecogs.com/png.latex?(%5Comega_i)"> を用いた線型推定量 <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%7B%5Cmathrm%7Bcal%7D%7D:=%5Csum_%7Bi%5Cin%20S%7D%5Comega_iy_i%0A"> を <strong>校正推定量</strong> (calibration estimator) といい，抽出計画が <strong>無視可能</strong> (ignorable) である限り <img src="https://latex.codecogs.com/png.latex?Y"> の不偏推定量になる．</p>
<p>ここまでは <a href="../../../posts/2024/Survey/Survey3.html">前稿</a> で見た通りである．</p>
</section>
<section id="非確率標本に対する校正推定量" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="非確率標本に対する校正推定量"><span class="header-section-number">2.2</span> 非確率標本に対する校正推定量</h3>
<p>こうなると <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bi=1%7D%5ENx_i"> が判明・推定すれば良いので，校正推定量に関しては <a href="../../../posts/2024/Survey/Survey3.html#sec-calibration-estimator-for-missing-data">欠測データに対する対処</a> と同様に，傾向スコアの推定を通じて非確率標本に対応することができる．</p>
<p>これには超母集団模型 (1) に加えて，傾向スコア <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BP%7D%5B%5Cdelta=1%7CX=x%5D=:%5Cpi(x)%0A"> に対してもモデル <img src="https://latex.codecogs.com/png.latex?(%5Cpi_%5Cphi)"> をおく必要がある．</p>
<p>このとき，<img src="https://latex.codecogs.com/png.latex?G%5Cin%20C%5E2(%5Cmathbb%7BR%7D)"> を強凸関数，<img src="https://latex.codecogs.com/png.latex?g:=G'"> として <img src="https://latex.codecogs.com/png.latex?%0AQ(%5Comega):=%5Csum_%7Bi%5Cin%20S%7DG(%5Comega_i)c_i(x_i)%0A"> を，校正条件 (2) と完全情報の下で最尤推定された <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7B%5Cphi%7D"> を用いて推定した傾向スコア <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7B%5Cpi%7D_i:=%5Cpi(%5Cwidehat%7B%5Cphi%7D(x_i))"> に関して <span id="eq-debiasing-constraint"><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi%5Cin%20S%7D%5Comega_ig(%5Cwidehat%7B%5Cpi%7D_i%5E%7B-1%7D)c_i=%5Csum_%7Bi=1%7D%5ENg(%5Cwidehat%7B%5Cpi%7D_i%5E%7B-1%7D)c_i(x_i)%0A%5Ctag%7B3%7D"></span> を満たす中で最小化する荷重 <img src="https://latex.codecogs.com/png.latex?(%5Comega_i)"> を用いた校正推定量は，二重頑健性を持つ．</p>
<p>制約 (3) は選択バイアスを抑える役割を持ち，脱偏倚制約 (de-biasing constraint) とも呼ばれる <span class="citation" data-cites="Kim2024">(Kim, 2024, p. 198)</span>．</p>
</section>
</section>


<div id="quarto-appendix" class="default"><section id="文献案内" class="level2 appendix" data-number="3"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3</span> 文献案内</h2><div class="quarto-appendix-contents">

<p><span class="citation" data-cites="Kim2024">(Kim, 2024)</span> を最も参考にした．他によく読んだものは <span class="citation" data-cites="AAOR2013">(AAOR, 2013)</span>, <span class="citation" data-cites="Elliott-Valliant2017">(Elliott and Valliant, 2017)</span>．</p>
<p>セミパラメトリック推定に関する日本語文献は <span class="citation" data-cites="逸見昌之2014">(逸見昌之, 2014)</span>．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-AAOR2013" class="csl-entry">
AAOR. (2013). <em>Report of the AAPOR task force on non-probability sampling</em>. American Association for Public Opinion Research.
</div>
<div id="ref-Baker+2013" class="csl-entry">
Baker, R., Brick, J. M., Bates, N. A., Battaglia, M., Couper, M. P., Dever, J. A., … Tourangeau, R. (2013). <a href="https://doi.org/10.1093/jssam/smt008"><span class="nocase">Summary Report of the AAPOR Task Force on Non-probability Sampling</span></a>. <em>Journal of Survey Statistics and Methodology</em>, <em>1</em>(2), 90–143.
</div>
<div id="ref-Elliott-Valliant2017" class="csl-entry">
Elliott, M. R., and Valliant, R. (2017). <a href="http://www.jstor.org/stable/26408228">Inference for nonprobability samples</a>. <em>Statistical Science</em>, <em>32</em>(2), 249–264.
</div>
<div id="ref-Kim2024" class="csl-entry">
Kim, J. K. (2024). <a href="https://arxiv.org/abs/2401.07625">Statistics in survey sampling</a>.
</div>
<div id="ref-Rosenbaum-Rubin1983" class="csl-entry">
Rosenbaum, P. R., and Rubin, D. B. (1983). <a href="https://doi.org/10.1093/biomet/70.1.41"><span class="nocase">The Central Role of the Propensity Score in Observational Studies for Causal Effects</span></a>. <em>Biometrika</em>, <em>70</em>(1), 41–55.
</div>
<div id="ref-逸見昌之2014" class="csl-entry">
逸見昌之. (2014). <a href="https://www.ism.ac.jp/editsec/toukei/pdf/62-1-103.pdf">欠測データに対するセミパラメトリックな解析法――その理論的背景について――</a>. <em>統計数理</em>, <em>62</em>(1), 103–122.
</div>
</div></section></div> ]]></description>
  <category>Statistics</category>
  <category>Bayesian</category>
  <guid>https://162348.github.io/posts/2024/Survey/Survey4.html</guid>
  <pubDate>Mon, 23 Sep 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title>ベイズデータ解析３</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Survey/Survey3.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="関連記事" class="level2 unnumbered unlisted">
<h2 class="unnumbered unlisted anchored" data-anchor-id="関連記事">関連記事</h2>
<div id="listing-lst-survey" class="listing quarto-float quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Statistics,Bayesian" data-listing-date-sort="1727017200000" data-listing-file-modified-sort="1727270702903" data-listing-date-modified-sort="1727103600000" data-listing-reading-time-sort="3" data-listing-word-count-sort="501">
<a href="../../../posts/2024/Survey/Survey1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<!-- img(9CEB782EFEE6)[progressive=false, height=150px]:posts/2024/Survey/Survey1.html -->
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズデータ解析１
</h5>
<div class="card-subtitle listing-subtitle">
分散分析
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-23
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Statistics" data-listing-date-sort="1727017200000" data-listing-file-modified-sort="1727270702903" data-listing-date-modified-sort="1727017200000" data-listing-reading-time-sort="1" data-listing-word-count-sort="69">
<a href="../../../posts/2024/Survey/Survey2.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<!-- img(9CEB782EFEE6)[progressive=false, height=150px]:posts/2024/Survey/Survey2.html -->
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズデータ解析２
</h5>
<div class="card-subtitle listing-subtitle">
平均処置効果の推定
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-23
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Bayesian" data-listing-date-sort="1727103600000" data-listing-file-modified-sort="1727338996232" data-listing-date-modified-sort="1727190000000" data-listing-reading-time-sort="1" data-listing-word-count-sort="178">
<a href="../../../posts/2024/Survey/Survey4.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<!-- img(9CEB782EFEE6)[progressive=false, height=150px]:posts/2024/Survey/Survey4.html -->
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズデータ解析４
</h5>
<div class="card-subtitle listing-subtitle">
アンケートデータ・非確率標本の解析
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-24
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>
<section id="有限標本論" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="有限標本論"><span class="header-section-number">1</span> 有限標本論</h2>
<section id="sec-probability-sample" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="sec-probability-sample"><span class="header-section-number">1.1</span> 設定</h3>
<p><img src="https://latex.codecogs.com/png.latex?%5BN%5D"> を母集団とする．<img src="https://latex.codecogs.com/png.latex?%5BN%5D"> の部分集合の全体 <img src="https://latex.codecogs.com/png.latex?P(%5BN%5D)"> 上の確率分布を <strong>抽出計画</strong> (sampling design) といい，ある既知の抽出分布に従って得られる標本 <img src="https://latex.codecogs.com/png.latex?S%5Csubset%5BN%5D"> を <strong>確率標本</strong> (probability sample) という．<a href="https://www.e-stat.go.jp/classifications/terms/90/00/4937">日本語では <strong>無作為抽出標本</strong> などとも呼ばれる</a>．</p>
<p>この設定では，<strong>包含確率</strong> <img src="https://latex.codecogs.com/png.latex?%0A%5Cpi_i:=%5Coperatorname%7BP%7D%5Bi%5Cin%20S%5D%0A"> が定まる．</p>
<p>先ほど，<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BP%7D(%5BN%5D)"> 上の確率変数を確率標本と呼ぶとしたが，正確に <img src="https://latex.codecogs.com/png.latex?S"> が <strong>確率標本</strong> と呼ばれるためには，<img src="https://latex.codecogs.com/png.latex?%5Cpi_i%3E0"> が母集団 <img src="https://latex.codecogs.com/png.latex?i%5Cin%5BN%5D"> の全域で成り立つことが必要である <span class="citation" data-cites="Kim2024">(Kim, 2024, p. 12)</span>．</p>
</section>
<section id="horvitz-thompson-推定量" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="horvitz-thompson-推定量"><span class="header-section-number">1.2</span> Horvitz-Thompson 推定量</h3>
<p>確率標本 <img src="https://latex.codecogs.com/png.latex?S%5Cin%5Cmathcal%7BL%7D(%5COmega;%5Cmathcal%7BP%7D(%5BN%5D))"> に対しては，ある量 <img src="https://latex.codecogs.com/png.latex?y"> についての母集団の総和 <img src="https://latex.codecogs.com/png.latex?%0AY:=%5Csum_%7Bi=1%7D%5ENy_i%0A"> が <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%5Cmathrm%7BHT%7D:=%5Csum_%7Bi%5Cin%20S%7D%5Cfrac%7By_i%7D%7B%5Cpi_i%7D%0A"> により不偏推定できる．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7BY%7D_%5Cmathrm%7BHT%7D"> は <span class="citation" data-cites="Horvitz-Thompson1952">(Horvitz and Thompson, 1952)</span> 推定量と呼ばれる．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="[@Sen1953]-[@Yates-Grundy1953]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="citation" data-cites="Sen1953">(Sen, 1953)</span>-<span class="citation" data-cites="Yates-Grundy1953">(Yates and Grundy, 1953)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7BV%7D%5B%5Cwidehat%7BY%7D_%5Cmathrm%7BHT%7D%5D=%5Csum_%7Bi,j=1%7D%5EN%5Cbiggr(%5Cpi_%7Bij%7D-%5Cpi_i%5Cpi_j%5Cbiggl)%5Cfrac%7By_iy_j%7D%7B%5Cpi_i%5Cpi_j%7D.%0A"></p>
</div>
</div>
</section>
<section id="効率の改善に向けて" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="効率の改善に向けて"><span class="header-section-number">1.3</span> 効率の改善に向けて</h3>
<p>HT 推定量は確率標本 <img src="https://latex.codecogs.com/png.latex?S"> の分布，すなわち抽出計画に依らずに不偏性を持つ．</p>
<p>これを計画不偏性 (design-unbiasedness) というが，この性質を持つ線型な推定量は HT に限られる．</p>
<p>しかし，HT 推定量はいつでも分散が最小というわけではない．</p>
<p>抽出計画に関する情報を用いて，分散を低減することができる．</p>
<p>特に，HT 推定量の荷重 <img src="https://latex.codecogs.com/png.latex?%5Cpi_i%5E%7B-1%7D"> を，補助変数 <img src="https://latex.codecogs.com/png.latex?x_i"> に関する <strong>外部一致性</strong> <img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi%5Cin%20S%7Dw_ix_i=%5Coverline%7Bx%7D%0A"> を保ちながら新しいものに変更するものが多く考えられた．</p>
</section>
<section id="比による修正" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="比による修正"><span class="header-section-number">1.4</span> 比による修正</h3>
<p>ある別の変数 <img src="https://latex.codecogs.com/png.latex?x_i%5Cin%5Cmathbb%7BR%7D"> については母集団の総和 <img src="https://latex.codecogs.com/png.latex?%0AX:=%5Csum_%7Bi=1%7D%5ENx_i%0A"> が既知であるとする．</p>
<p>このとき，<img src="https://latex.codecogs.com/png.latex?X"> の HT 推定量から，真の値 <img src="https://latex.codecogs.com/png.latex?X"> との「ズレ方」を用いて，<img src="https://latex.codecogs.com/png.latex?Y"> の推定量を「校正」することができる．</p>
<p>もっとも直感的には <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%7B%5Cmathrm%7BR%7D%7D:=%5Cwidehat%7BY%7D_%5Cmathrm%7BHT%7D%5Cfrac%7BX%7D%7B%5Cwidehat%7BX%7D_%5Cmathrm%7BHT%7D%7D%0A"> とできるだろう．</p>
<p>この推定量は ratio estimator などと呼ばれ，性能の代わりにバイアスが生じてしまう．</p>
<p>一般に，<img src="https://latex.codecogs.com/png.latex?X,Y"> が正の相関を持つとき，大きな分散低減が得られる <span class="citation" data-cites="Kim2024">(Kim, 2024, p. 92)</span>．</p>
<p><img src="https://latex.codecogs.com/png.latex?x_i=1"> と取った場合を Hajék 推定量ともいう．Hajék 推定量が HT 推定量よりも推奨される状況が <span class="citation" data-cites="Sarndal+1992">(Särndal et al., 1992, p. 182)</span> にリストされている．</p>
</section>
<section id="sec-regression-estimator" class="level3" data-number="1.5">
<h3 data-number="1.5" class="anchored" data-anchor-id="sec-regression-estimator"><span class="header-section-number">1.5</span> 回帰推定量</h3>
<p>回帰推定量では一般の共変量 <img src="https://latex.codecogs.com/png.latex?x_i%5Cin%5Cmathbb%7BR%7D%5Ep"> が，総和 <img src="https://latex.codecogs.com/png.latex?%0AX:=%5Csum_%7Bi%5Cin%5BN%5D%7Dx_i%0A"> が既知である限り利用される．</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7By%7D_i:=x_i%5E%5Ctop%5Cwidehat%7BB%7D,%5Cqquad%5Cwidehat%7BB%7D:=%5Cleft(%5Csum_%7Bi%5Cin%20S%7D%5Cpi_i%5E%7B-1%7Dx_ix_i%5E%5Ctop%5Cright)%5E%7B-1%7D%5Csum_%7Bi%5Cin%20S%7D%5Cpi_i%5E%7B-1%7Dx_iy_i%0A"> の総和が，<img src="https://latex.codecogs.com/png.latex?Y"> に対する <strong>回帰推定量</strong> (regression estimator) と呼ばれる．</p>
<p>これは <img src="https://latex.codecogs.com/png.latex?(y_i)%5Cin%5Cmathbb%7BR%7D%5En"> に関する線型推定量になっている．加えて， <span id="eq-external-consistency"><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi%5Cin%20S%7Dw_ix_i=%5Coverline%7Bx%7D%0A%5Ctag%7B1%7D"></span> を満たす荷重 <img src="https://latex.codecogs.com/png.latex?%0Aw_i:=%5Coverline%7BX%7D%5E%5Ctop%5Cleft(%5Csum_%7Bi%5Cin%20S%7D%5Cpi_i%5E%7B-1%7Dx_ix_i%5E%5Ctop%5Cright)%5E%7B-1%7D%5Cpi_i%5E%7B-1%7Dx_i%0A"> に関して， <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%7B%5Cmathrm%7Breg%7D%7D=%5Csum_%7Bi%5Cin%20S%7Dw_iy_i%0A"> という形の線型推定量になっている．</p>
<p>式 (1) を <strong>外部一致性</strong> (external consistency)，または <strong>校正条件</strong> (calibration / benchmarking property) <span class="citation" data-cites="Deville-Sarndal1992">(Deville and Särndal, 1992)</span> という．</p>
<p>回帰推定量は抽出計画に依らず一致性を持ち，<img src="https://latex.codecogs.com/png.latex?X,Y"> の間の相関の絶対値が大きいほど，分散低減効果が高くなる <span class="citation" data-cites="Kim2024">(Kim, 2024, p. 95)</span>．<sup>1</sup></p>
</section>
<section id="事後層別化" class="level3" data-number="1.6">
<h3 data-number="1.6" class="anchored" data-anchor-id="事後層別化"><span class="header-section-number">1.6</span> 事後層別化</h3>
<p><strong>事後層別化</strong> (post-stratification / stratification after selection) は標本抽出の結果を見て標本を層別化する手法であるが，回帰推定量の特別な場合と見れる．</p>
<p>母集団が <img src="https://latex.codecogs.com/png.latex?G"> 個の層に分けられるとする：<img src="https://latex.codecogs.com/png.latex?N=N_1+%5Ccdots+N_G">．</p>
<p>このとき，<img src="https://latex.codecogs.com/png.latex?i%5Cin%5BN%5D"> 番目の単位が層 <img src="https://latex.codecogs.com/png.latex?g%5Cin%5BG%5D"> に属するかどうかの指示変数 <img src="https://latex.codecogs.com/png.latex?x_%7Big%7D%5Cin2"> のベクトル <img src="https://latex.codecogs.com/png.latex?x_i:=(x_%7Bi1%7D,%5Ccdots,x_%7BiG%7D)%5E%5Ctop%5Cin2%5EG"> に関する回帰推定量 <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%20%20%5Cwidehat%7BY%7D_%7B%5Cmathrm%7Bpost%7D%7D&amp;:=%5Csum_%7Bi=1%7D%5ENx_i%5E%5Ctop%5Cleft(%5Csum_%7Bi%5Cin%20S%7D%5Cpi_i%5E%7B-1%7Dx_ix_i%5E%5Ctop%5Cright)%5E%7B-1%7D%5Csum_%7Bi%5Cin%20S%7D%5Cpi_i%5E%7B-1%7Dx_iy_i%5C%5C%0A%20%20&amp;=%5Csum_%7Bg=1%7D%5EG%5Csum_%7Bi%5Cin%20S_g%7D%5Cpi_i%5E%7B-1%7D%5Cfrac%7BN_g%7D%7B%5Cwidehat%7BN%7D_g%7Dy_i,%5Cqquad%5Cwidehat%7BN%7D_g:=%5Csum_%7Bi%5Cin%20S%7D%5Cpi_i%5E%7B-1%7Dx_%7Big%7D.%0A%5Cend%7Balign*%7D"> を事後層別化推定量という．</p>
<p>MRP (Multilevel Regression and Post-stratification) <span class="citation" data-cites="Gelman-Little1997">(Gelman and Little, 1997)</span>, <span class="citation" data-cites="Gelman2014">(Gelman, 2014)</span> は事後層別化の階層モデル・縮小推定版である．</p>
</section>
<section id="ランキング法繰り返し比例的フィッティング法" class="level3" data-number="1.7">
<h3 data-number="1.7" class="anchored" data-anchor-id="ランキング法繰り返し比例的フィッティング法"><span class="header-section-number">1.7</span> ランキング法／繰り返し比例的フィッティング法</h3>
<p><span class="citation" data-cites="Deming-Stephan1940">(Deming and Stephan, 1940)</span> では 1940 年の国勢調査の結果の分析を考えていた．</p>
<p>特に，基本的な情報は全数調査されるが，詳細な情報は標本調査でしか得られない状況下で，母集団の <img src="https://latex.codecogs.com/png.latex?I%5Ctimes%20J"> 分割表の各セル <img src="https://latex.codecogs.com/png.latex?U_%7Bij%7D"> の値 <img src="https://latex.codecogs.com/png.latex?N_%7Bij%7D"> の推定を考えていた．</p>
<p>ただし，周辺和 <img src="https://latex.codecogs.com/png.latex?N_%7Bi-%7D,N_%7B-j%7D"> は全数調査で得られているとする．</p>
<p>このとき，<img src="https://latex.codecogs.com/png.latex?N_%7Bij%7D"> の推定量の候補として <img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7Bn_%7Bij%7D%7D%7Bn_%7Bi-%7D%7DN_i,%5Cquad%5Cfrac%7Bn_%7Bij%7D%7D%7Bn_%7B-j%7D%7DN_%7B-j%7D,%5Cquad%5Cfrac%7Bn_%7Bij%7D%7D%7Bn%7DN%0A"> の３つが考えられる．３番目が良いと考えるかもしれないが，その結果得られる分割表は周辺和を保存しない．</p>
<p>この問題は次のような形でも現れる：指示変数 <img src="https://latex.codecogs.com/png.latex?%0Ax_k=(x_%7B1-k%7D,%5Ccdots,x_%7BI-k%7D,x_%7B-1k%7D,%5Ccdots,x_%7B-Jk%7D),%5Cqquad%20x_%7Bijk%7D:=1_%7BU_%7Bij%7D%7D(k),%0A"> に基づく事後層別化推定量 <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%7B%5Cmathrm%7Bpost%7D%7D=%5Csum_%7Bi%5Cin%20S%7D%5Cpi_i%5E%7B-1%7Dg_i(S)y_i,%5Cqquad%20g_i(S):=%5Cleft(%5Csum_%7Bk=1%7D%5ENx_k%5Cright)%5E%5Ctop%5Cleft(%5Csum_%7Bk%5Cin%20S%7D%5Cpi_k%5E%7B-1%7Dx_kx_k%5E%5Ctop%5Cright)%5E%7B-1%7Dx_i%0A"> を考えたいが，これが <img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7Brank%7D%5Cleft(%5Csum_%7Bk%5Cin%20S%7D%5Cpi_k%5E%7B-1%7Dx_kx_k%5E%5Ctop%5Cright)=I+J-1"> であるため，一意な表示を持たない．</p>
<p><img src="https://latex.codecogs.com/png.latex?g_i(S)"> の候補のうち，次を満たす <img src="https://latex.codecogs.com/png.latex?g_i"> を選ぶことが目標である： <span id="eq-column"><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bk%5Cin%20S%7D%5Cfrac%7Bg_k%7D%7B%5Cpi_k%7Dx_%7Bi-k%7D=%5Csum_%7Bk=1%7D%5ENx_%7Bi-k%7D=N_%7Bi-%7D,%0A%5Ctag%7B2%7D"></span> <span id="eq-row"><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bk%5Cin%20S%7D%5Cfrac%7Bg_k%7D%7B%5Cpi_k%7Dx_%7B-jk%7D=%5Csum_%7Bk=1%7D%5ENx_%7B-jk%7D=N_%7B-j%7D.%0A%5Ctag%7B3%7D"></span></p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="[Iterative Proportional Fitting / Ranking algorithm @Deming-Stephan1940]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="citation" data-cites="Deming-Stephan1940">(Iterative Proportional Fitting / Ranking algorithm Deming and Stephan, 1940)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?g%5E%7B(0)%7D_k%5Cgets1"> と初期化する．</li>
<li><img src="https://latex.codecogs.com/png.latex?x_%7Bi-k%7D=1"> すなわち <img src="https://latex.codecogs.com/png.latex?k%5Cin%20U_%7Bi-%7D"> であるとき， <img src="https://latex.codecogs.com/png.latex?%0A%20%20g%5E%7B(t+1)%7D_k%5Cgets%20g_k%5E%7B(t)%7D%5Cfrac%7B%5Csum_%7Bk=1%7D%5ENx_%7Bi-k%7D%7D%7B%5Csum_%7Bk%5Cin%20S%7D%5Cfrac%7Bg%5E%7B(t)%7D_k%7D%7B%5Cpi_k%7Dx_%7Bi-k%7D%7D.%0A%20%20"> これにより条件 (2) が満たされる．</li>
<li><img src="https://latex.codecogs.com/png.latex?z_%7B-jk%7D=1"> すなわち <img src="https://latex.codecogs.com/png.latex?k%5Cin%20U_%7B-j%7D"> であるとき， <img src="https://latex.codecogs.com/png.latex?%0A%20%20g%5E%7B(t+2)%7D_k%5Cgets%20g_k%5E%7B(t+1)%7D%5Cfrac%7B%5Csum_%7Bk=1%7D%5ENx_%7B-jk%7D%7D%7B%5Csum_%7Bk%5Cin%20S%7D%5Cfrac%7Bg%5E%7B(t+1)%7D_k%7D%7B%5Cpi_k%7Dx_%7B-jk%7D%7D.%0A%20%20"> これにより条件 (3) が満たされる．</li>
<li>収束するまで繰り返す．</li>
</ol>
</div>
</div>
<p>これは特定の目的関数を最小化することに等しい．<span class="citation" data-cites="Deming-Stephan1940">(Deming and Stephan, 1940, p. 428)</span>, <span class="citation" data-cites="Zieschang1990">(Zieschang, 1990)</span>, <span class="citation" data-cites="Deville-Sarndal1993">(Jean-Claude Deville and Sautory, 1993)</span> も参照．</p>
</section>
<section id="差分推定量" class="level3" data-number="1.8">
<h3 data-number="1.8" class="anchored" data-anchor-id="差分推定量"><span class="header-section-number">1.8</span> 差分推定量</h3>
<p>補助的な量 <img src="https://latex.codecogs.com/png.latex?y_i%5E%7B(0)%7D"> が母集団全体で観測されている場合， <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%7B%5Cmathrm%7Bdiff%7D%7D:=%5Csum_%7Bi=1%7D%5ENy_i%5E%7B(0)%7D+%5Csum_%7Bi%5Cin%20S%7D%5Cpi_i%5E%7B-1%7D%5Cleft(y_i-y_i%5E%7B(0)%7D%5Cright)%0A"> は <strong>差分推定量</strong> (difference estimator) と呼ばれる．</p>
<p>HT 推定量同様不偏であるが，分散の値は変化し，特に <img src="https://latex.codecogs.com/png.latex?y_i%5E%7B(0)%7D"> が <img src="https://latex.codecogs.com/png.latex?y_i"> の良い近似であるほど分散が小さくなる <span class="citation" data-cites="Kim2024">(Kim, 2024, p. 99)</span>．</p>
<p>この <img src="https://latex.codecogs.com/png.latex?y_i"> の proxy とも言える量 <img src="https://latex.codecogs.com/png.latex?y_i%5E%7B(0)%7D"> を，他の共変量 <img src="https://latex.codecogs.com/png.latex?x_i"> から回帰により構成することで，回帰推定量（第 1.5 節）よりも複雑な <img src="https://latex.codecogs.com/png.latex?x_i,y_i"> 関係もうまく取り込んだ分散低減が可能になる．</p>
<p>これを <strong>model-assisted estimation</strong> という．</p>
</section>
<section id="一般化最小二乗法-gls" class="level3" data-number="1.9">
<h3 data-number="1.9" class="anchored" data-anchor-id="一般化最小二乗法-gls"><span class="header-section-number">1.9</span> 一般化最小二乗法 (GLS)</h3>
<p>まず母集団 <img src="https://latex.codecogs.com/png.latex?%5BN%5D"> にモデルを当てはめる： <span id="eq-superpopulation-model"><img src="https://latex.codecogs.com/png.latex?%0Ay_i=x_i%5E%5Ctop%5Cbeta+%5Cepsilon_i,%5Cqquad%5Cepsilon_i%5Coverset%7B%5Ctext%7Biid%7D%7D%7B%5Csim%7D(0,c_i(x_i)%5Csigma%5E2).%0A%5Ctag%7B4%7D"></span> このように母集団に置かれるモデルを <strong>超母集団モデル</strong> (superpopulation model) <span class="citation" data-cites="Isaki-Fuller1982">(Isaki and Fuller, 1982)</span> ともいう．特に式 (4) の Gauss-Markov 型の超母集団モデルを <strong>一般化回帰モデル</strong> (GREG: Generalized Regression) ともいう．</p>
<p>これを解いて得る推定量 <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7By%7D_i=x_i%5E%5Ctop%5Cwidehat%7B%5Cbeta%7D_c"> の総和として得られる推定量 <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%7B%5Cmathrm%7BP%7D%7D:=%5Csum_%7Bi=1%7D%5EN%5Cwidehat%7By%7D_i%0A"> を <strong>射影推定量</strong> (projection estimator) という．</p>
<p>仮に GREG モデルで <img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7Bc_i%7D%7B%5Cpi_i%7D%5Cparallel%20x_i%0A"> が成り立つならば，内部バイアス校正 (IBC: Internally Biased Calibration) <span class="citation" data-cites="Firth-Bennett1998">(Firth and Bennett, 1998)</span> 条件 <img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi%5Cin%20S%7D%5Cfrac%7B1%7D%7B%5Cpi_i%7D(y_i-%5Cwidehat%7By%7D_i)=0%0A"> が成り立つ．これは射影推定量が抽出計画に依らずに一致性を持つための十分条件である．</p>
<p>そうでない場合でも， <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%7B%5Cmathrm%7BGREG%7D%7D:=%5Cwidehat%7BY%7D_%5Cmathrm%7BHT%7D+%5Cbiggr(X-%5Cwidehat%7BX%7D_%5Cmathrm%7BHT%7D%5Cbiggl)%5E%5Ctop%5Cwidehat%7B%5Cbeta%7D_c%0A"> は計画一致性を持つ．これは <strong>一般化回帰推定量</strong> (GREG: Generalized Regression Estimator) または計量経済学において GLS (Generalized Least Squares) <span class="citation" data-cites="Aitken1936">(Aitken, 1936)</span> と呼ばれる．<sup>2</sup></p>
<p>これは，次の表示を持つためである： <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%7B%5Cmathrm%7BGREG%7D%7D=%5Csum_%7Bi%5Cin%20S%7D%5Cwidehat%7B%5Comega%7D_iy_i,%5Cqquad%5Cwidehat%7B%5Comega%7D_i:=%5Cpi_i%5E%7B-1%7D+%5Cleft(X-%5Cwidehat%7BX%7D_%5Cmathrm%7BHT%7D%5Cright)%5E%5Ctop%5Cleft(%5Csum_%7Bi%5Cin%20S%7D%5Cfrac%7B1%7D%7Bc_i%7Dx_ix_i%5E%5Ctop%5Cright)%5E%7B-1%7D%5Cfrac%7Bx_i%7D%7Bc_i%7D.%0A"> この荷重 <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7B%5Comega%7D_i"> は，<strong>校正条件</strong> (calibration constraint) （式 (1) との違いに注意）を満たすものの中で <img src="https://latex.codecogs.com/png.latex?%0AQ(%5Comega):=%5Csum_%7Bi%5Cin%20S%7D(%5Comega_i-d_i)%5E2c_i,%5Cqquad%20d_i:=%5Cpi_i%5E%7B-1%7D,%5Cquad%5Coperatorname%7Bsubject%20to%7D%5Csum_%7Bi%5Cin%20S%7D%5Comega_ix_i=%5Csum_%7Bi=1%7D%5ENx_i.%0A"> を最小にするものとも特徴付けられる．</p>
</section>
<section id="校正推定量" class="level3" data-number="1.10">
<h3 data-number="1.10" class="anchored" data-anchor-id="校正推定量"><span class="header-section-number">1.10</span> 校正推定量</h3>
<p>一般に，校正条件制約を満たす <img src="https://latex.codecogs.com/png.latex?(%5Comega_i)"> のうち，特定の目的関数 <img src="https://latex.codecogs.com/png.latex?Q"> を最小にするものを <strong>校正荷重</strong> (calibration weight)，校正荷重に関する線型推定量を <strong>校正推定量</strong> (calibration estimator) という <span class="citation" data-cites="Kim2024">(Kim, 2024, p. 103)</span>．</p>
<p>特に， <img src="https://latex.codecogs.com/png.latex?%0AQ(%5Comega)=%5Csum_%7Bi%5Cin%20S%7D%5Comega_i%5E2c_i%0A"> を最小化するものは <strong>最適校正推定量</strong> と呼ばれる <span class="citation" data-cites="Kim2024">(Kim, 2024, p. 110)</span>．</p>
<p>一般に，有限母集団に対する確率標本からの一様最小分散不偏推定量 (UMVUE) は存在しない <span class="citation" data-cites="Godambe-Joshi1965">(Godambe and Joshi, 1965)</span> が，GREG 推定量は「期待漸近分散」の下界を達成する <span class="citation" data-cites="Isaki-Fuller1982">(Isaki and Fuller, 1982)</span>．</p>
<p>しかし校正推定量は，超母集団モデル (4) が誤特定されている場合に GREG 推定量より良い性能を示す <span class="citation" data-cites="Kim2024">(Kim, 2024, p. 112)</span>．</p>
<p>校正荷重を見つける他の方法には，<strong>モデル校正</strong> (model calibration) <span class="citation" data-cites="Wu-Sitter2001">(Wu and Sitter, 2001)</span> がある．この方法では校正条件制約を，超母集団モデルに基づいて別の形のものにする．</p>
</section>
</section>
<section id="欠測データの扱い" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="欠測データの扱い"><span class="header-section-number">2</span> 欠測データの扱い</h2>
<section id="はじめに" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="はじめに"><span class="header-section-number">2.1</span> はじめに</h3>
<p>観測単位が欠測している場合 (unit nonresponse)，call-back / follow-up 調査を行うか，それができない場合は次の２つの対処が可能である：</p>
<ol type="1">
<li>欠測メカニズムを抑える共変量は見えている場合（MAR 条件），傾向スコア推定量が利用可能（第 2.2 節）．これは欠測メカニズムのモデリングに基づく．</li>
<li>一般の校正推定量に対しても，</li>
</ol>
<p>単位欠測の場合は，２段階の標本抽出と状況が似ているのである．</p>
<p>一方で，項目が欠測している場合 (item nonresponse)，<strong>代入法</strong> (imputation) が用いられる．<sup>3</sup></p>
<p>現状は多重代入法（第 2.7 節）が主流であると言える <span class="citation" data-cites="vanBuuren2018">(S. van Buuren, 2018)</span>．</p>
</section>
<section id="sec-propensity-score" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="sec-propensity-score"><span class="header-section-number">2.2</span> 傾向スコア推定量</h3>
<p>標本の観測 <img src="https://latex.codecogs.com/png.latex?Y_i"> は，<img src="https://latex.codecogs.com/png.latex?%5Cdelta_i=0"> のとき欠損しているとする．</p>
<section id="mar-条件欠測のメカニズムを抑える共変量が観測できている" class="level4" data-number="2.2.1">
<h4 data-number="2.2.1" class="anchored" data-anchor-id="mar-条件欠測のメカニズムを抑える共変量が観測できている"><span class="header-section-number">2.2.1</span> MAR 条件：欠測のメカニズムを抑える共変量が観測できている</h4>
<p>加えて，標本全体についてある変数 <img src="https://latex.codecogs.com/png.latex?X"> が観測できており，これについて次の条件が成り立つとする：</p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="[MAR condition @Rubin1976]^[最も古典的な形のものであり，母集団上の条件であることから，population MAR とも呼ばれる．母集団上の MAR と抽出計画の無視可能性 [@Sugden-Smith1984] との２条件が成り立つとき，標本の MAR が成り立つ [@Berg+2016]．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="citation" data-cites="Rubin1976">(MAR condition Rubin, 1976)</span><sup>4</sup>
</div>
</div>
<div class="callout-body-container callout-body">
<p>欠測の指示変数 <img src="https://latex.codecogs.com/png.latex?%5Cdelta"> について， <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BP%7D%5B%5Cdelta=1%7CX,Y%5D=%5Coperatorname%7BP%7D%5B%5Cdelta=1%7CX%5D=:p(X)%0A"> が成り立つ．</p>
</div>
</div>
<p>これは条件付き独立性 <img src="https://latex.codecogs.com/png.latex?%5Cdelta%5Cperp%5C!%5C!%5C!%5Cperp%20Y%5Cmid%20X"> よりも弱い条件で，MAR (Missing At Random) の条件と呼ばれる．<sup>5</sup></p>
</section>
<section id="欠測メカニズムの推定" class="level4" data-number="2.2.2">
<h4 data-number="2.2.2" class="anchored" data-anchor-id="欠測メカニズムの推定"><span class="header-section-number">2.2.2</span> 欠測メカニズムの推定</h4>
<p>欠測確率 <img src="https://latex.codecogs.com/png.latex?p(x):=%5Coperatorname%7BP%7D%5B%5Cdelta=1%7CX=x%5D"> にノンパラメトリックなモデル <img src="https://latex.codecogs.com/png.latex?p_%5Cphi(x)"> を課したとする．</p>
<p>このとき，パラメータ <img src="https://latex.codecogs.com/png.latex?%5Cphi"> は擬似最尤推定量 <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7B%5Cphi%7D"> により一致推定をすることができる．</p>
</section>
<section id="傾向スコア推定量" class="level4" data-number="2.2.3">
<h4 data-number="2.2.3" class="anchored" data-anchor-id="傾向スコア推定量"><span class="header-section-number">2.2.3</span> 傾向スコア推定量</h4>
<p>仮に母平均 <img src="https://latex.codecogs.com/png.latex?%0AY:=%5Csum_%7Bi=1%7D%5ENy_i%0A"> が推定対象であったとしよう．</p>
<p>このとき，推定された <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7B%5Cphi%7D"> を元に，次の推定量が構成できる：</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%5Cmathrm%7BPS%7D:=%5Csum_%7Bi%5Cin%5Cdelta%5E%7B-1%7D(1)%7D%5Cfrac%7B1%7D%7B%5Cpi_i%7D%5Cfrac%7By_i%7D%7Bp_%7B%5Cwidehat%7B%5Cphi%7D%7D(x_i)%7D.%0A"></p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題（傾向スコア推定量の一致性）^[[@Kim2024 p.154] 定理12.1も参照．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題（傾向スコア推定量の一致性）<sup>6</sup>
</div>
</div>
<div class="callout-body-container callout-body">
<p>欠測確率 <img src="https://latex.codecogs.com/png.latex?p"> のモデル <img src="https://latex.codecogs.com/png.latex?p_%5Cphi(x)"> の特定に成功しているとき，ある正則性に関する条件が満たされる限り，傾向スコア推定量 <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7BY%7D_%5Cmathrm%7BPS%7D"> は一致推定量に <img src="https://latex.codecogs.com/png.latex?n%5E%7B-1%7D"> のオーダーで漸近する．</p>
</div>
</div>
</section>
</section>
<section id="sec-calibration-estimator-for-missing-data" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="sec-calibration-estimator-for-missing-data"><span class="header-section-number">2.3</span> 校正推定量</h3>
<p>ある校正荷重 <img src="https://latex.codecogs.com/png.latex?(d_i)"> に関して，計画一致性を持つ推定量 <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D=%5Csum_%7Bi%5Cin%20S%7Dd_iy_i%0A"> を考えているが，単位欠測により特定の <img src="https://latex.codecogs.com/png.latex?y_i"> が得られず，計算できないものとする．</p>
<p>この場合でも，応答があった部分標本 <img src="https://latex.codecogs.com/png.latex?%0AS_R:=%5Cdelta%5E%7B-1%7D(1)%0A"> 上の校正推定量 <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%5Comega:=%5Csum_%7Bi%5Cin%20S_R%7D%5Comega_iy_i%0A"> であって，欠測メカニズム <img src="https://latex.codecogs.com/png.latex?p(x)"> の特定か，または超母集団モデル <img src="https://latex.codecogs.com/png.latex?%0Ay_i=x_i%5E%5Ctop%5Cbeta+%5Cepsilon_i,%5Cqquad%5Cepsilon_i%5Coverset%7B%5Ctext%7Biid%7D%7D%7B%5Csim%7D(0,c_i%5Csigma%5E2)%0A"> の特定に成功すれば一致性を持つ，二重頑健なものを構成できる <span class="citation" data-cites="Kim-Haziza2014">(Kim and Haziza, 2014)</span>．</p>
</section>
<section id="代入法" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="代入法"><span class="header-section-number">2.4</span> 代入法</h3>
<p>項目非反応がある場合，代入値を <img src="https://latex.codecogs.com/png.latex?y_i%5E*"> として <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%7B%5Cmathrm%7BI%7D%7D:=%5Csum_%7Bi%5Cin%20S%7D%5Cfrac%7B1%7D%7B%5Cpi_i%7D%5Cbiggr(%5Cdelta_iy_i+(1-%5Cdelta_i)y_i%5E*%5Cbiggl)%0A"> による推定が試みられる．</p>
<p>代入 <img src="https://latex.codecogs.com/png.latex?y_i%5E*"> を行うことでリストワイズの削除をするよりも効率を上げることができる．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="[代入推定量の不偏性 @Kim2024 p.162]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="citation" data-cites="Kim2024">(代入推定量の不偏性 Kim, 2024, p. 162)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D%5BY%5E*%7C%5Cdelta=0%5D=%5Coperatorname%7BE%7D%5BY%7C%5Cdelta=1%5D%0A"> が成り立つならば，<img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7BY%7D_%5Cmathrm%7BI%7D"> は不偏推定量である．</p>
</div>
</div>
<p>この条件は，標本内で MAR 条件が成り立つとき： <img src="https://latex.codecogs.com/png.latex?%0AY%7C(X,%5Cdelta=1)=Y%7C(X,%5Cdelta=0)%0A"> <img src="https://latex.codecogs.com/png.latex?Y%5E*"> を <img src="https://latex.codecogs.com/png.latex?Y%7C(X,%5Cdelta=1)"> からのサンプリングで代入すれば達成される．</p>
<p>換言すれば代入法において，欠測の原因 <img src="https://latex.codecogs.com/png.latex?X"> を突き止め，欠測したグループにおける <img src="https://latex.codecogs.com/png.latex?Y"> の値 <img src="https://latex.codecogs.com/png.latex?Y%7C(X,%5Cdelta=1)"> にモデルを立て，そこからサンプリングをすることを目指す．</p>
</section>
<section id="回帰による代入" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="回帰による代入"><span class="header-section-number">2.5</span> 回帰による代入</h3>
<p>共変量により母集団を <img src="https://latex.codecogs.com/png.latex?%5BN%5D=N_1+%5Ccdots+N_G"> 個のグループに分け， <span id="eq-semiparametric-model"><img src="https://latex.codecogs.com/png.latex?%0AY_i=X_i%5E%5Ctop%5Cbeta+%5Cepsilon_i,%5Cqquad%5Cepsilon_i%5Coverset%7B%5Ctext%7Biid%7D%7D%7B%5Csim%7D(0,%5Csigma%5E2)%0A%5Ctag%7B5%7D"></span> というセミパラメトリック回帰モデルを考える．</p>
<p>推定されたモデルを用いて，<img src="https://latex.codecogs.com/png.latex?%5Cepsilon_i%5E*%5Csim(0,%5Csigma%5E2)"> を残差 <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7Bep%7D_i:=y_i-x_i%5E%5Ctop%5Cwidehat%7B%5Cbeta%7D%0A"> の分布から（リ）サンプリングし， <img src="https://latex.codecogs.com/png.latex?%0Ay_i%5E*%5Cgets%20x_i%5E%5Ctop%5Cwidehat%7B%5Cbeta%7D+%5Cepsilon_i%5E*%0A"> を代入値とする．</p>
<p>以上の手続きは <strong>確率的回帰代入法</strong> (stochastic regression imputation) と呼ばれる．</p>
<p>conditional mean imputation などの Least squares method も同様の考え方に基づく <span class="citation" data-cites="Little1992">(Little, 1992)</span>．</p>
</section>
<section id="モデルベースの代入法" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="モデルベースの代入法"><span class="header-section-number">2.6</span> モデルベースの代入法</h3>
<p>回帰による代入におけるモデル (5) を，単なる Gauss-Markov モデルに限らず一般の統計モデルに取り替えることを考える．</p>
<p>具体的には，<img src="https://latex.codecogs.com/png.latex?Y%7CX"> の尤度を <img src="https://latex.codecogs.com/png.latex?f_%5Ctheta(y%7Cx)"> としてモデリングをし，これを <img src="https://latex.codecogs.com/png.latex?%0A%5Cell(%5Ctheta):=%5Csum_%7Bi%5Cin%20S%7Dw_i%5Cdelta_i%5Clog%20f_%5Ctheta(y_i%7Cx_i)%0A"> の最大化によって <img src="https://latex.codecogs.com/png.latex?M">-推定する．<sup>7</sup> ただし，<img src="https://latex.codecogs.com/png.latex?w_i"> は <img src="https://latex.codecogs.com/png.latex?Y"> の計画一致性を持つ校正推定量を定める校正荷重であるとする．</p>
<p>最終的に学習されたモデル <img src="https://latex.codecogs.com/png.latex?f_%5Ctheta(y%7Cx_i)"> からのサンプリングによって代入値 <img src="https://latex.codecogs.com/png.latex?y_i%5E*"> を生成する．</p>
<p>このモデル <img src="https://latex.codecogs.com/png.latex?f_%5Ctheta(y%7Cx_i)"> を当てはまりの度合いを見ながらベイズ推論によって得る方法もよく取られるようになっている <span class="citation" data-cites="Enders+2020">(C. K. Enders et al., 2020)</span>．</p>
</section>
<section id="sec-MI" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="sec-MI"><span class="header-section-number">2.7</span> 多重代入法</h3>
<p>多重代入法では，モデルベースの代入法をさらに推し進める．</p>
<p>本来の推定量 <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D=%5Csum_%7Bi%5Cin%20S%7Dw_iy_i%0A"> を代入推定量 <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BY%7D_%5Cmathrm%7BI%7D=%5Csum_%7Bi%5Cin%20S%7Dw_i%5Cbiggr(%5Cdelta_iy_i+(1-%5Cdelta_i)y_i%5E*%5Cbiggl),%5Cqquad%20y_i%5E*%5Csim%20f_%5Ctheta(y_i%7Cx_i)%0A"> で模倣する際，ベイズ事後分布で <img src="https://latex.codecogs.com/png.latex?%0Ay_i%5E*%5Csim%20f(y_i%7Cy_%7B%5Ctext%7Bobs%7D%7D)%0A"> によって補間することが理想的である．</p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="[Multiple Imputation @Rubin1978MI]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="citation" data-cites="Rubin1978MI">(Multiple Imputation Rubin, 1978)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>事後予測分布から補間値を <img src="https://latex.codecogs.com/png.latex?M"> 個生成する： <img src="https://latex.codecogs.com/png.latex?%0A%20%20y_i%5E%7B(j)%7D%5Csim%20f(y_i%7Cy_%7B%5Ctext%7Bobs%7D%7D),%5Cqquad%20j%5Cin%5BM%5D.%0A%20%20"></li>
<li>それぞれの補間値について推定量 <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7BY%7D%5E%7B(j)%7D"> を計算し，その平均を最終的な推定値とする： <img src="https://latex.codecogs.com/png.latex?%5Cnewcommand%7B%5CMI%7D%7B%5Cmathrm%7BMI%7D%7D%0A%20%20%5Cwidehat%7BY%7D_%5CMI:=%5Cfrac%7B1%7D%7BM%7D%5Csum_%7Bj=1%7D%5EM%5Cwidehat%7BY%7D%5E%7B(j)%7D.%0A%20%20"></li>
</ol>
</div>
</div>
<p><span class="citation" data-cites="Royston-White2011">(Royston and White, 2011)</span> は <img src="https://latex.codecogs.com/png.latex?M%5Capprox10%5E3"> を推奨している．</p>
</section>
<section id="連鎖方程式による多重代入" class="level3" data-number="2.8">
<h3 data-number="2.8" class="anchored" data-anchor-id="連鎖方程式による多重代入"><span class="header-section-number">2.8</span> 連鎖方程式による多重代入</h3>
<p>多重代入法において事後予測分布から補間値を生成することは，<img src="https://latex.codecogs.com/png.latex?Y"> に関してモデルを立てる必要があるためネックになりがちである．</p>
<p><strong>相互条件付き識別性</strong> (FCS: Fully Conditional Specification) <span class="citation" data-cites="vanBuuren+2006">(S. Van Buuren and Rubin, 2006)</span> が成り立つモデルについては，モデルの具体的な形に依らない Gibbs サンプラーによるサンプリングが可能になる．</p>
<p>これを <strong>連鎖方程式による多重代入</strong> (MICE: Multiple Imputation by Chained Equations) <span class="citation" data-cites="vanBuuren-Groothuis-Oudshoorn2011">(Stef van Buuren and Groothuis-Oudshoorn, 2011)</span> といい，R 言語 <code>mice</code> パッケージで実装されている．</p>
<blockquote class="blockquote">
<p>その実用性も相まってか，近年の Lancet 誌，New England Journal of Medicine 誌のレビューでは，欠測データの取り扱いに最も多く用いられている手法は MICE であるという報告もある<span class="citation" data-cites="Rezvan+2015">(Hayati Rezvan et al., 2015)</span>．<br> <span class="citation" data-cites="野間久史2017">(久史, 2017, p. 75)</span></p>
</blockquote>
</section>
<section id="その他の代入法" class="level3" data-number="2.9">
<h3 data-number="2.9" class="anchored" data-anchor-id="その他の代入法"><span class="header-section-number">2.9</span> その他の代入法</h3>
<p>ランダムな欠損ではなく，計画された大規模な欠損がある場合は，two-phase sampling の考え方を応用することができる <span class="citation" data-cites="Kim2024">(Kim, 2024, p. 173)</span>．</p>
<p>なお，全ての代入法はモデル <img src="https://latex.codecogs.com/png.latex?Y%7C(X,%5Cdelta)"> の特定を間違えると，<img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7BY%7D"> の不偏性が失われることに注意 <span class="citation" data-cites="Rezvan+2015">(Hayati Rezvan et al., 2015)</span>．</p>
</section>
<section id="代入をしない" class="level3" data-number="2.10">
<h3 data-number="2.10" class="anchored" data-anchor-id="代入をしない"><span class="header-section-number">2.10</span> 代入をしない</h3>
<p>代入をせず，欠測しているなら欠測したままで最尤推定を実行することも考えられる．</p>
<p>このアプローチは <strong>完全情報最尤推定</strong> (FIML: Full Information Maximum Likelihood)，より最近では　pairwise likelihood estimation とも呼ばれる．<sup>8</sup></p>
<p>この「最尤推定量」は MAR の下で一致性と漸近正規性を持つ．<sup>9</sup></p>
<p>ただし，推定されたモデルから，欠測値を代入してから結果を出してももちろん良い．ベイズの観点からは，モデルの平均を取ってから予測することに当たる．<sup>10</sup></p>
<p><span class="citation" data-cites="vanBuuren2018">(1.6節 S. van Buuren, 2018)</span> も参照．</p>
</section>
<section id="欠測値をどう扱うべきか" class="level3" data-number="2.11">
<h3 data-number="2.11" class="anchored" data-anchor-id="欠測値をどう扱うべきか"><span class="header-section-number">2.11</span> 欠測値をどう扱うべきか？</h3>
<p>いつでも多重代入法を使えば良いというものではない．例えば <img src="https://latex.codecogs.com/png.latex?(X,Y)"> の関数関係が知りたい回帰分析の状況下で被説明変数 <img src="https://latex.codecogs.com/png.latex?Y"> の欠損は，これを無視してリストワイズ消去をした complete-case analysis が代入法と等価になる．<sup>11</sup></p>
<p>他にも complete-case analysis や代入をしない方がむしろ適切な場合は多い <span class="citation" data-cites="vanBuuren2018">(2.7節 S. van Buuren, 2018)</span>．</p>
</section>
</section>



<div id="quarto-appendix" class="default"><section id="終わりに" class="level2 appendix" data-number="3"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3</span> 終わりに</h2><div class="quarto-appendix-contents">



</div></section><section id="多重代入法について" class="level3 appendix" data-number="3.1"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3.1</span> 多重代入法について</h2><div class="quarto-appendix-contents">

<p>パッケージに実装される都合上，多重代入法はパラメトリックな手法であるという言説があるが，必ずしもそうである必要はない．この場合，傾向スコア推定量や校正推定量がセミパラメトリックな手法と呼ばれる．</p>
<p>また多重代入法が代入に使われたのちに，後続の解析は全く違うモデルが使われることもあり，このような場合は整合性 (congeniality) <span class="citation" data-cites="Meng1994">(Meng, 1994)</span> の議論が必要になる．</p>
<p>いずれの場合も，多重代入法の「代入法」としての側面が強調されるあまり理論的背景が捨象され，また多重代入法の実際の使われ方が使用可能なパッケージでの実装方式に強く依存され，元来の手法の数理的本体が見失われている状況と言うことができるだろう．</p>
<blockquote class="blockquote">
<p>Bayesian inference draws no distinction between missing data and parameters; both are uncertain, and they have a joint posterior distribution, conditional on observed data. <span class="citation" data-cites="BDA">(Chapter 18 Gelman et al., 2014, p. 449)</span></p>
</blockquote>
</div></section><section id="mar-について" class="level3 appendix" data-number="3.2"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3.2</span> MAR について</h2><div class="quarto-appendix-contents">

<p>MAR は現行で最も緩い条件である．</p>
<p>そして，MAR が成立しているかは確認したがく，感度分析などが推奨される <span class="citation" data-cites="逸見昌之2014">(逸見昌之, 2014)</span>．</p>
<p>欠測するかどうか <img src="https://latex.codecogs.com/png.latex?%5Cdelta"> が，欠測する所の値 <img src="https://latex.codecogs.com/png.latex?Y"> に依存している場合，これを MNAR という．この場合のセミパラメトリック最適な推定法は <span class="citation" data-cites="Morikawa-Kim2021">(Morikawa and Kim, 2021)</span> などが提案されている．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Aitken1936" class="csl-entry">
Aitken, A. C. (1936). <a href="https://doi.org/10.1017/S0370164600014346">IV.—on least squares and linear combination of observations</a>. <em>Proceedings of the Royal Society of Edinburgh</em>, <em>55</em>, 42–48.
</div>
<div id="ref-Berg+2016" class="csl-entry">
Berg, E., Kim, J.-K., and Skinner, C. (2016). <a href="https://doi.org/10.1093/jssam/smw032"><span>Imputation Under Informative Sampling</span></a>. <em>Journal of Survey Statistics and Methodology</em>, <em>4</em>(4), 436–462.
</div>
<div id="ref-vanBuuren2018" class="csl-entry">
Buuren, S. van. (2018). <em><a href="https://stefvanbuuren.name/fimd/"><span class="nocase">Flexible Imputation of Missing Data</span></a></em>. Boca Raton, FL.: CRC Press.
</div>
<div id="ref-vanBuuren-Groothuis-Oudshoorn2011" class="csl-entry">
Buuren, Stef van, and Groothuis-Oudshoorn, K. (2011). <a href="https://doi.org/10.18637/jss.v045.i03">Mice: Multivariate imputation by chained equations in r</a>. <em>Journal of Statistical Software</em>, <em>45</em>(3), 1–67.
</div>
<div id="ref-Deming-Stephan1940" class="csl-entry">
Deming, W. E., and Stephan, F. F. (1940). <a href="http://www.jstor.org/stable/2235722">On a least squares adjustment of a sampled frequency table when the expected marginal totals are known</a>. <em>The Annals of Mathematical Statistics</em>, <em>11</em>(4), 427–444.
</div>
<div id="ref-Deville-Sarndal1992" class="csl-entry">
Deville, J.-C., and Särndal, C.-E. (1992). <a href="https://doi.org/10.1080/01621459.1992.10475217">Calibration estimators in survey sampling</a>. <em>Journal of the American Statistical Association</em>, <em>87</em>(418), 376–382.
</div>
<div id="ref-Enders+2001" class="csl-entry">
Enders, Craig K., and Bandalos, D. L. (2001). <a href="https://doi.org/10.1207/S15328007SEM0803\_5">The relative performance of full information maximum likelihood estimation for missing data in structural equation models</a>. <em>Structural Equation Modeling: A Multidisciplinary Journal</em>, <em>8</em>(3), 430–457.
</div>
<div id="ref-Enders+2020" class="csl-entry">
Enders, C. K., Du, H., and Keller, B. T. (2020). <a href="https://psycnet.apa.org/doi/10.1037/met0000228"><span class="nocase">A Model-based Imputation Procedure for Multilevel Regression Models with Random Coefficients, Interaction Effects, and Nonlinear Terms</span></a>. <em>Psychological Methods</em>, <em>25</em>(1), 88–112.
</div>
<div id="ref-Firth-Bennett1998" class="csl-entry">
Firth, D., and Bennett, K. E. (1998). <a href="https://doi.org/10.1111/1467-9868.00105">Robust models in probability sampling</a>. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <em>60</em>(1), 3–21.
</div>
<div id="ref-Gelman2014" class="csl-entry">
Gelman, A. (2014). <a href="https://doi.org/10.1214/13-STS458"><span class="nocase">How Bayesian Analysis Cracked the Red-State, Blue-State Problem</span></a>. <em>Statistical Science</em>, <em>29</em>(1), 26–35.
</div>
<div id="ref-BDA" class="csl-entry">
Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., and Rubin, D. B. (2014). <em><a href="http://www.stat.columbia.edu/~gelman/book/">Bayesian data analysis</a></em>. Boca Raton : CRC Press.
</div>
<div id="ref-Gelman-Little1997" class="csl-entry">
Gelman, A., and Little, T. (1997). <a href="https://www150.statcan.gc.ca/n1/en/catalogue/12-001-X19970023616">Poststratification into many categories using hierarchical logistic regression</a>. <em>Survey Methodology</em>, (1997002).
</div>
<div id="ref-Godambe-Joshi1965" class="csl-entry">
Godambe, V. P., and Joshi, V. M. (1965). <a href="http://www.jstor.org/stable/2239112">Admissibility and bayes estimation in sampling finite populations. i</a>. <em>The Annals of Mathematical Statistics</em>, <em>36</em>(6), 1707–1722.
</div>
<div id="ref-Rezvan+2015" class="csl-entry">
Hayati Rezvan, P., Lee, K. J., and Simpson, J. A. (2015). <a href="https://doi.org/10.1186/s12874-015-0022-1">The rise of multiple imputation: A review of the reporting and implementation of the method in medical research</a>. <em>BMC Medical Research Methodology</em>, <em>15</em>(1), 30.
</div>
<div id="ref-Horvitz-Thompson1952" class="csl-entry">
Horvitz, D. G., and Thompson, D. J. (1952). <a href="https://doi.org/10.1080/01621459.1952.10483446">A generalization of sampling without replacement from a finite universe</a>. <em>Journal of the American Statistical Association</em>, <em>47</em>(260), 663–685.
</div>
<div id="ref-Isaki-Fuller1982" class="csl-entry">
Isaki, C. T., and Fuller, W. A. (1982). <a href="https://doi.org/10.1080/01621459.1982.10477770">Survey design under the regression superpopulation model</a>. <em>Journal of the American Statistical Association</em>, <em>77</em>(377), 89–96.
</div>
<div id="ref-Deville-Sarndal1993" class="csl-entry">
Jean-Claude Deville, C.-E. S., and Sautory, O. (1993). <a href="https://doi.org/10.1080/01621459.1993.10476369">Generalized raking procedures in survey sampling</a>. <em>Journal of the American Statistical Association</em>, <em>88</em>(423), 1013–1020.
</div>
<div id="ref-Kim2024" class="csl-entry">
Kim, J. K. (2024). <a href="https://arxiv.org/abs/2401.07625">Statistics in survey sampling</a>.
</div>
<div id="ref-Kim-Haziza2014" class="csl-entry">
Kim, J. K., and Haziza, D. (2014). <a href="http://www.jstor.org/stable/26432548">DOUBLY ROBUST INFERENCE WITH MISSING DATA IN SURVEY SAMPLING</a>. <em>Statistica Sinica</em>, <em>24</em>(1), 375–394.
</div>
<div id="ref-Little1992" class="csl-entry">
Little, R. J. A. (1992). <a href="https://doi.org/10.1080/01621459.1992.10476282">Regression with missing x’s: A review</a>. <em>Journal of the American Statistical Association</em>, <em>87</em>(420), 1227–1237.
</div>
<div id="ref-Meng1994" class="csl-entry">
Meng, X.-L. (1994). <a href="https://doi.org/10.1214/ss/1177010269"><span class="nocase">Multiple-Imputation Inferences with Uncongenial Sources of Input</span></a>. <em>Statistical Science</em>, <em>9</em>(4), 538–558.
</div>
<div id="ref-Morikawa-Kim2021" class="csl-entry">
Morikawa, K., and Kim, J. K. (2021). <a href="https://doi.org/10.1214/21-AOS2070"><span class="nocase">Semiparametric optimal estimation with nonignorable nonresponse data</span></a>. <em>The Annals of Statistics</em>, <em>49</em>(5), 2991–3014.
</div>
<div id="ref-Royston-White2011" class="csl-entry">
Royston, P., and White, I. R. (2011). <a href="https://doi.org/10.18637/jss.v045.i04">Multiple imputation by chained equations (MICE): Implementation in stata</a>. <em>Journal of Statistical Software</em>, <em>45</em>(4), 1–20.
</div>
<div id="ref-Rubin1976" class="csl-entry">
Rubin, D. B. (1976). <a href="http://www.jstor.org/stable/2335739">Inference and missing data</a>. <em>Biometrika</em>, <em>63</em>(3), 581–592.
</div>
<div id="ref-Rubin1978MI" class="csl-entry">
Rubin, D. B. (1978). <a href="http://www.asasrms.org/Proceedings/y1978f.html">Multiple imputations in sample surveys - a phenomenological bayesian approach to nonresponse</a>. <em>Proceedings of the Survey Research Methods Section, ASA</em>, 20–28.
</div>
<div id="ref-vanBuuren+2006" class="csl-entry">
S. Van Buuren, C. G. M. G.-O., J. P. L. Brand, and Rubin, D. B. (2006). <a href="https://doi.org/10.1080/10629360600810434">Fully conditional specification in multivariate imputation</a>. <em>Journal of Statistical Computation and Simulation</em>, <em>76</em>(12), 1049–1064.
</div>
<div id="ref-Sarndal+1992" class="csl-entry">
Särndal, C.-E., Swensson, B., and Wretman, J. (1992). <em><a href="https://link.springer.com/book/9780387406206">Model assisted survey sampling</a></em>. Springer New York.
</div>
<div id="ref-Sen1953" class="csl-entry">
Sen, A. R. (1953). <a href="">On the estimate of the variance in sampling with varying probabilities</a>. <em>Journal of the Indian Society of Agricultural Statistics</em>, <em>5</em>, 119–127.
</div>
<div id="ref-Sugden-Smith1984" class="csl-entry">
Sugden, R. A., and Smith, T. M. F. (1984). <a href="https://doi.org/10.1093/biomet/71.3.495"><span class="nocase">Ignorable and informative designs in survey sampling inference</span></a>. <em>Biometrika</em>, <em>71</em>(3), 495–506.
</div>
<div id="ref-Wu-Sitter2001" class="csl-entry">
Wu, C., and Sitter, R. R. (2001). <a href="https://doi.org/10.1198/016214501750333054">A model-calibration approach to using complete auxiliary information from survey data</a>. <em>Journal of the American Statistical Association</em>, <em>96</em>(453), 185–193.
</div>
<div id="ref-Yates-Grundy1953" class="csl-entry">
Yates, F., and Grundy, P. M. (1953). <a href="https://doi.org/10.1111/j.2517-6161.1953.tb00140.x">Selection without replacement from within strata with probability proportional to size</a>. <em>Journal of the Royal Statistical Society: Series B (Methodological)</em>, <em>15</em>(2), 253–261.
</div>
<div id="ref-Zieschang1990" class="csl-entry">
Zieschang, K. D. (1990). <a href="http://www.jstor.org/stable/2289595">Sample weighting methods and estimation of totals in the consumer expenditure survey</a>. <em>Journal of the American Statistical Association</em>, <em>85</em>(412), 986–1001.
</div>
<div id="ref-野間久史2017" class="csl-entry">
久史. (2017). <a href="https://doi.org/10.5023/jappstat.46.67">連鎖方程式による多重代入法</a>. <em>応用統計学</em>, <em>46</em>(2), 67–86.
</div>
<div id="ref-狩野裕2019" class="csl-entry">
狩野裕. (2019). <a href="https://doi.org/10.11329/jjssj.48.199">欠測データ解析のmissとmyth</a>. <em>日本統計学会誌</em>, <em>48</em>(2), 199–214.
</div>
<div id="ref-逸見昌之2014" class="csl-entry">
逸見昌之. (2014). <a href="https://www.ism.ac.jp/editsec/toukei/pdf/62-1-103.pdf">欠測データに対するセミパラメトリックな解析法――その理論的背景について――</a>. <em>統計数理</em>, <em>62</em>(1), 103–122.
</div>
<div id="ref-高井啓二+2016" class="csl-entry">
高井啓二, 星野崇宏, and 野間久史. (2016). <em><a href="https://www.iwanami.co.jp/book/b260306.html">欠測データの統計科学：医学と社会科学への応用</a></em>,Vol. 1. 岩波書店.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>この抽出計画に依らない性質を以て，<span class="citation" data-cites="Sarndal+1992">(Särndal et al., 1992)</span> は model-assisted 推定量と呼んでいる．model-dependent 推定量とは対照的である．↩︎</p></li>
<li id="fn2"><p>この２つの類似性は <span class="citation" data-cites="Zieschang1990">(Zieschang, 1990)</span> が指摘している．一般の回帰分析の設定下では <a href="https://en.wikipedia.org/wiki/Generalized_least_squares">“GLS is more efficient than OLS under heteroscedasticity (also spelled heteroskedasticity) or autocorrelation”</a> などと説明される．↩︎</p></li>
<li id="fn3"><p>総務省統計局では，Imputation の訳語として「補定」を用いる．↩︎</p></li>
<li id="fn4"><p>最も古典的な形のものであり，母集団上の条件であることから，population MAR とも呼ばれる．母集団上の MAR と抽出計画の無視可能性 <span class="citation" data-cites="Sugden-Smith1984">(Sugden and Smith, 1984)</span> との２条件が成り立つとき，標本の MAR が成り立つ <span class="citation" data-cites="Berg+2016">(Berg et al., 2016)</span>．↩︎</p></li>
<li id="fn5"><p><img src="https://latex.codecogs.com/png.latex?Y%5Cto%20X%5Cto%5Cdelta"> が Markov 連鎖をなす，とも換言できる．↩︎</p></li>
<li id="fn6"><p><span class="citation" data-cites="Kim2024">(Kim, 2024, p. 154)</span> 定理12.1も参照．↩︎</p></li>
<li id="fn7"><p>一方で，重み付き推定方程式として理解することもできる．<span class="citation" data-cites="高井啓二+2016">(5.2節 高井啓二 et al., 2016, p. 163)</span>．↩︎</p></li>
<li id="fn8"><p>完全情報最尤推定の言葉は初期の構造方程式モデリングプログラム AMOS に組み込まれて有名になっていた <span class="citation" data-cites="Enders+2001">(Craig K. Enders and Bandalos, 2001)</span>．直接尤度 (direct likelihood) または観測尤度 (observed likelihood) の方法ともいう <span class="citation" data-cites="狩野裕2019">(狩野裕, 2019)</span>．<strong>完全尤度</strong> (full likelihood) の用語は <span class="citation" data-cites="高井啓二+2016">(高井啓二 et al., 2016)</span> など．↩︎</p></li>
<li id="fn9"><p><span class="citation" data-cites="狩野裕2019">(狩野裕, 2019)</span> に素晴らしい解説がある．日本語の文献としては <span class="citation" data-cites="高井啓二+2016">(高井啓二 et al., 2016)</span> もあり，第５章で推定方程式の観点から解説されている．↩︎</p></li>
<li id="fn10"><p>そういえば Bayes 的な integral out に関して doubly robust という考え方はないのか？doubly robust の Bayesian counterpart はなんだろう？↩︎</p></li>
<li id="fn11"><p>従って一致性を持つ．<span class="citation" data-cites="高井啓二+2016">(高井啓二 et al., 2016)</span> はこの点を強調している．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Statistics</category>
  <category>Bayesian</category>
  <guid>https://162348.github.io/posts/2024/Survey/Survey3.html</guid>
  <pubDate>Mon, 23 Sep 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title>ベイズデータ解析１</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Survey/Survey1.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="関連記事" class="level2 unnumbered unlisted">
<h2 class="unnumbered unlisted anchored" data-anchor-id="関連記事">関連記事</h2>
<div id="listing-lst-survey" class="listing quarto-float quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Bayesian,MCMC,R,Stan,Statistics" data-listing-date-sort="1715439600000" data-listing-file-modified-sort="1727270702902" data-listing-date-modified-sort="1726066800000" data-listing-reading-time-sort="8" data-listing-word-count-sort="1505">
<a href="../../../posts/2024/Computation/brms.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Computation/brms_files/figure-html/unnamed-chunk-4-1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
R によるベイズ混合モデリング入門
</h5>
<div class="card-subtitle listing-subtitle">
brms を用いた混合効果モデリング入門
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-05-12
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Statistics" data-listing-date-sort="1727017200000" data-listing-file-modified-sort="1727270702903" data-listing-date-modified-sort="1727017200000" data-listing-reading-time-sort="1" data-listing-word-count-sort="69">
<a href="../../../posts/2024/Survey/Survey2.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://162348.github.io/posts/2024/Stat/MeanOfGaussian.svg" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズデータ解析２
</h5>
<div class="card-subtitle listing-subtitle">
平均処置効果の推定
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-23
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Bayesian" data-listing-date-sort="1727103600000" data-listing-file-modified-sort="1727337923426" data-listing-date-modified-sort="1727190000000" data-listing-reading-time-sort="4" data-listing-word-count-sort="722">
<a href="../../../posts/2024/Survey/Survey3.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://162348.github.io/posts/2024/Computation/brms_files/figure-html/unnamed-chunk-4-1.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ベイズデータ解析３
</h5>
<div class="card-subtitle listing-subtitle">
標本調査データと欠測データの扱い
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-09-24
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>
<section id="分散分析" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="分散分析"><span class="header-section-number">1</span> 分散分析</h2>
<section id="はじめに" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="はじめに"><span class="header-section-number">1.1</span> はじめに</h3>
<p>分散分析 (ANOVA: Analysis of Variance) は標本がある因子 <img src="https://latex.codecogs.com/png.latex?A,B,%5Ccdots"> によって層別されている場合に，層間の平均効果 <img src="https://latex.codecogs.com/png.latex?%5Cmu_i"> に差があるかどうかを検定する手法である： <img src="https://latex.codecogs.com/png.latex?%0AH_0:%5Cmu_1=%5Ccdots=%5Cmu_p%5Cquad%5Ctext%7Bv.s.%7D%5Cquad%20H_1:%5Cexists_%7Bi,j%5Cin%5Bp%5D%7D%5C;%5Cmu_i%5Cne%5Cmu_j.%0A"></p>
<p>因子 <img src="https://latex.codecogs.com/png.latex?A,B,%5Ccdots"> の個数に関して，<img src="https://latex.codecogs.com/png.latex?A"> のみの場合を一元配置分散分析，<img src="https://latex.codecogs.com/png.latex?A,B"> の場合を二元配置分散分析などという．</p>
<p>観測のモデルには <strong>線型 Gauss</strong> の仮定が置かれる．例えば一元配置である場合， <span id="eq-ANOVA"><img src="https://latex.codecogs.com/png.latex?%0AY_%7Bij%7D=%5Cmu_i+%5Cepsilon_%7Bij%7D,%5Cqquad%20i%5Cin%5Bp%5D,j%5Cin%5Bn_i%5D,%5Cepsilon_%7Bij%7D%5Csim%5Cmathrm%7BN%7D(0,%5Csigma%5E2),%0A%5Ctag%7B1%7D"></span> というモデルが仮定されていることに注意．これは変量効果モデルとも呼ばれる形である．</p>
<p>二元配置では <img src="https://latex.codecogs.com/png.latex?%0AY_%7Bij%7D=%5Cmu+%5Calpha_i+%5Cbeta_j+%5Cepsilon_%7Bij%7D%0A"> となり，集団は２つの軸 <img src="https://latex.codecogs.com/png.latex?A,B"> で層別されており（分割表の状態），それぞれの因子からの効果 <img src="https://latex.codecogs.com/png.latex?%5Calpha_i,%5Cbeta_j"> が説明変数に加法的に加えられる．</p>
</section>
<section id="分散分析の抽象的な説明" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="分散分析の抽象的な説明"><span class="header-section-number">1.2</span> 分散分析の抽象的な説明</h3>
<p>分散分析では観測 <img src="https://latex.codecogs.com/png.latex?Y_%7Bij%7D"> の変動のうち，<img src="https://latex.codecogs.com/png.latex?H_0"> の仮定の下で説明されなかった部分（残差） <img src="https://latex.codecogs.com/png.latex?R_1%5E2"> と，そもそも線型 Gauss 模型 (1) では説明しきれない部分 <img src="https://latex.codecogs.com/png.latex?R_0%5E2"> とに関して， <img src="https://latex.codecogs.com/png.latex?%0AF:=%5Cfrac%7B(R%5E2_1-R%5E2_0)/q%7D%7BR%5E2_0/(n-r)%7D%0A"> を考える．ただし，<img src="https://latex.codecogs.com/png.latex?r:=%5Coperatorname%7Brank%7D(X)"> はデータの自由度とした．</p>
<p>この <img src="https://latex.codecogs.com/png.latex?F"> は，各群への所属表すダミー変数を用いた回帰分析の残差 <img src="https://latex.codecogs.com/png.latex?R_0"> と，各群への所属を考慮しない回帰分析による残差 <img src="https://latex.codecogs.com/png.latex?R_1"> とを，自由度を考慮して比を取った形をしている．</p>
<p>この <img src="https://latex.codecogs.com/png.latex?F"> は一般に非心 F-分布に従い，仮定 <img src="https://latex.codecogs.com/png.latex?H_0"> が成り立つときのみ中心 F-分布 <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BF%7D(q,n-r)"> に従う．</p>
<p>これは各群への所属情報に何の情報量もない場合には，<img src="https://latex.codecogs.com/png.latex?F"> が<u>同じ平均を持つ</u>正規確率変数の自乗和の比になるためである．</p>
<p>この <img src="https://latex.codecogs.com/png.latex?F"> を検定統計量として仮設検定を実行するのが (repeated measures) ANOVA である．</p>
</section>
<section id="gauss-markov-の仮定" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="gauss-markov-の仮定"><span class="header-section-number">1.3</span> Gauss-Markov の仮定</h3>
<p>「標本が正規分布に従う母集団からの独立標本である」という帰無仮説を持つ検定に，<span class="citation" data-cites="Shapiro-Wilk1965">(Shapiro and Wilk, 1965)</span> の検定などがある．</p>
<p>探索的な方法には Q-Q plot などがある．<span class="citation" data-cites="vandenBergh+2020">(Don van den Bergh and Wagenmakers, 2020)</span> も参照．</p>
<p>等分散の仮定をチェックする検定には <span class="citation" data-cites="Mauchly1940">(Mauchly, 1940)</span> の検定や <span class="citation" data-cites="Brown-Forsythe1974">(Brown and Forsythe, 1974)</span> の検定などがある．</p>
<p>仮にこれらの仮定が破られた場合は，<span class="citation" data-cites="Kruskal-Wallis1952">(Kruskal and Wallis, 1952)</span> 検定などのランクベースの ANOVA 手法を用いることができる．<sup>1</sup></p>
<p>ただし，検定はデータの一側面しか伝えていない．例えば，データが帰無仮説をどれほど支持しているかの尺度は検定では得られない．</p>
<p>それゆえ，ANOVA などのモデルの仮定を確認するためには，検定だけでなく他の探索的手法と組み合わせることが推奨される．<span class="citation" data-cites="Tijmstra2018">(Tijmstra, 2018)</span> も参照．</p>
</section>
<section id="検定に対する注意喚起" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="検定に対する注意喚起"><span class="header-section-number">1.4</span> 「検定」に対する注意喚起</h3>
<p>一方で ANOVA を含めた検定は一面のみを強調する構造となっており，一連の統計解析の中で自然な位置付けを持つものでない．</p>
<p>特に，<img src="https://latex.codecogs.com/png.latex?p">-値による仮設検定は「データが不十分であることにより判断ができない」ことと，「データと帰無仮説は激しく矛盾する」こととを区別できない．この意味でも限定的な情報量しか持たない．</p>
<p>例えば <img src="https://latex.codecogs.com/png.latex?p">-値が小さく帰無仮説が棄却されたとしても，<img src="https://latex.codecogs.com/png.latex?p">-値はモデルの変化に対して頑健ではないかもしれず，実際はほとんど帰無仮説が成り立つことが真実かもしれない．</p>
<p>このような全貌を探索的に捉えるためには，検定を金科玉条とするのではなく，広くモデル比較・モデル選択の観点からアプローチすることが大切である．同様のことが <span class="citation" data-cites="Rouder+2016">(Rouder et al., 2016)</span> でも論じられている．</p>
<p>ANOVA は，特に大規模なものが，現在でも実験心理学などの分野で広く用いられている．これは心理学では多くの因子 <img src="https://latex.codecogs.com/png.latex?A,B,C,%5Ccdots"> が存在し，それぞれが複雑な関係にあるためである．</p>
<p>しかし推定法も従来の <img src="https://latex.codecogs.com/png.latex?F">-検定を用いたのではその力を十分に発揮できない．解決は丁寧な階層モデリングとベイズによる探索的な解析にある．<sup>2</sup></p>
<blockquote class="blockquote">
<p>”if you have a complicated data structure and are trying to set up a model, it can help to use multilevel modeling”—not just a simple unitswithin-groups structure but a more general approach with crossed factors where appropriate. This is the way that researchers in psychology use ANOVA, but <strong>they are often ill-served by the classical framework of mean squares and F-tests</strong>. We hope that our estimation-oriented approach will allow the powerful tools of Bayesian modeling to be used for the applied goals of inference about large numbers of structured parameters. <span class="citation" data-cites="Gelman2005">(Gelman, 2005, p. 53)</span></p>
</blockquote>
</section>
</section>
<section id="ベイズ分散分析" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="ベイズ分散分析"><span class="header-section-number">2</span> ベイズ分散分析</h2>
<section id="はじめに-1" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="はじめに-1"><span class="header-section-number">2.1</span> はじめに</h3>
<p>ベイズ分散分析 <span class="citation" data-cites="Rouder+2012">(Rouder et al., 2012)</span>, <span class="citation" data-cites="Rouder+2016">(Rouder et al., 2016)</span> では，検定の代わりに Bayes 因子を用いたモデル比較を行う．</p>
<p>特に <span class="citation" data-cites="Rouder+2012">(Rouder et al., 2012)</span> は標準的な事前分布の選択について議論している．</p>
</section>
<section id="考え方" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="考え方"><span class="header-section-number">2.2</span> 考え方</h3>
<p>ベイズ的な仮設検定は <span class="citation" data-cites="Jeffreys1961">(Jeffreys, 1961)</span> に源流を持つ．一般に，位置母数の事前分布に Cauchy 分布を用いることは <span class="citation" data-cites="Jeffreys1961">(5.3節 Jeffreys, 1961)</span> に源流を持つ．このことについては <span class="citation" data-cites="Robert+2009">(Robert et al., 2009)</span> も参照．</p>
<p>同一の人物を繰り返し測定し， <img src="https://latex.codecogs.com/png.latex?%0AY_i%5Coverset%7B%5Ctext%7Biid%7D%7D%7B%5Csim%7D%5Cmathrm%7BN%7D(%5Cmu,%5Csigma%5E2),%5Cqquad%20i%5Cin%5Bn%5D,%0A"> に従って何らかの処置効果 <img src="https://latex.codecogs.com/png.latex?Y_i"> 観測するとし，帰無仮説 <img src="https://latex.codecogs.com/png.latex?%5Cmu=0"> の妥当性を議論したいとする．</p>
<p>この際，まずは効果サイズ (effect size) <span class="citation" data-cites="Cohen1988">(Cohen, 1988)</span> <img src="https://latex.codecogs.com/png.latex?%5Cdelta:=%5Cmu/%5Csigma"> という無次元量にパラメータを変換し，これを Cauchy 分布と比較することを考える： <img src="https://latex.codecogs.com/png.latex?%0AM_0:%5Cdelta=0%5Cquad%5Ctext%7Bv.s.%7D%5Cquad%20M_1:%5Cdelta%5Csim%5Cmathrm%7BC%7D(0,1)%0A"></p>
<p>実際，この Cauchy 分布というのは変換 <img src="https://latex.codecogs.com/png.latex?J(%5Cnu,%5Csigma):=%5Cfrac%7B%5Cmu%5E2%7D%7B%5Csigma%5E2%7D"> を通じて <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D"> 上の Jeffreys 事前分布（この場合は Lebesgue 測度に一致）に（ほとんど）等価になる．</p>
<p>この２つのモデル <img src="https://latex.codecogs.com/png.latex?M_0,M_1"> の残りの仮定は共通の Jeffreys の事前分布 <img src="https://latex.codecogs.com/png.latex?p(%5Csigma%5E2)%5C,%5Cpropto%5C,%5Csigma%5E%7B-2%7D"> で共通とし，Bayes 因子を比較する．</p>
<p>この値を検定統計量のように扱うとき，これを Jeffreys の名前に <span class="citation" data-cites="Zellner-Siow1980">(Zellner and Siow, 1980)</span> を加えて <strong>JZS 因子</strong> <span class="citation" data-cites="Bayarri-Darcia-Donato2007">(Bayarri and García-Donato, 2007)</span> という．</p>
</section>
<section id="p-値との違い" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="p-値との違い"><span class="header-section-number">2.3</span> <img src="https://latex.codecogs.com/png.latex?p">-値との違い</h3>
<p>JZS 因子は <img src="https://latex.codecogs.com/png.latex?p">-値と比較して，サンプルサイズが大きいほど保守的になる傾向がある．<span class="citation" data-cites="Wetzels+2011">(Wetzels et al., 2011)</span> は 2007 年に特定の実験心理学雑誌に投稿された 855 件の t-検定に対して，JZS 因子と <img src="https://latex.codecogs.com/png.latex?p">-値との値を報告してこれを観察している．</p>
<p><span class="citation" data-cites="vandenBergh+2023">(Bergh et al., 2023)</span> は実例を用いて，特に複雑な心理学実験において，２つの解析手法はときに全く違う結論を導くことを例証している．</p>
<p>また JZS 因子は <img src="https://latex.codecogs.com/png.latex?N%5Cto%5Cinfty"> の極限で，<img src="https://latex.codecogs.com/png.latex?%5Cdelta%5Cne0"> であった場合は <img src="https://latex.codecogs.com/png.latex?%5Cinfty"> に発散し，<img src="https://latex.codecogs.com/png.latex?%5Cdelta=0"> であった場合は <img src="https://latex.codecogs.com/png.latex?1"> に収束するという性質を持つ．</p>
</section>
<section id="anova-でのベイズ化" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="anova-でのベイズ化"><span class="header-section-number">2.4</span> ANOVA でのベイズ化</h3>
<p>１元配置 ANOVA のモデルを次のように表す： <span id="eq-Bayesian-ANOVA"><img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BY%7D=%5Cmu%5Cboldsymbol%7B1%7D_n+%5Csigma%5Cboldsymbol%7BX%7D%5Cboldsymbol%7B%5Ctheta%7D+%5Cboldsymbol%7B%5Cepsilon%7D,%5Cqquad%5Cboldsymbol%7B%5Cepsilon%7D%7C%5Csigma%5E2%5Csim%5Cmathrm%7BN%7D(%5Cboldsymbol%7B0%7D,%5Csigma%5E2I_n).%0A%5Ctag%7B2%7D"></span> 各水準 <img src="https://latex.codecogs.com/png.latex?i%5Cin%5Bp%5D"> に属するデータの数を <img src="https://latex.codecogs.com/png.latex?n_i"> とすると <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BX%7D=%5Cbegin%7Bpmatrix%7D%0A%5Cboldsymbol%7B1%7D_%7Bn_1%7D%20&amp;%20%5Cboldsymbol%7B0%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cboldsymbol%7B0%7D%5C%5C%0A%5Cboldsymbol%7B0%7D%20&amp;%20%5Cboldsymbol%7B1%7D_%7Bn_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cboldsymbol%7B0%7D%5C%5C%0A%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%5C%5C%0A%5Cboldsymbol%7B0%7D%20&amp;%20%5Cboldsymbol%7B0%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cboldsymbol%7B1%7D_%7Bn_p%7D%0A%5Cend%7Bpmatrix%7D,%5Cqquad%5Cboldsymbol%7B%5Ctheta%7D=%5Cbegin%7Bpmatrix%7D%0A%5Cmu_1%5C%5C%0A%5Cmu_2%5C%5C%0A%5Cvdots%5C%5C%0A%5Cmu_p%0A%5Cend%7Bpmatrix%7D.%0A"> となる．</p>
<p>すると，<img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Ctheta%7D=0"> の場合のモデルが帰無仮説に対応する．</p>
<p>対立仮説としては，<img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Ctheta%7D"> 上に次の <img src="https://latex.codecogs.com/png.latex?g">-prior を定める： <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7B%5Ctheta%7D%5Csim%5Cmathrm%7BN%7D(%5Cboldsymbol%7B0%7D,G),%5Cqquad%20G=%5Cmathrm%7Bdiag%7D(g_1,%5Ccdots,g_p),%5Cqquad%20g_i%5Coverset%7B%5Ctext%7Biid%7D%7D%7B%5Csim%7D%5Cchi%5E%7B-2%7D(1).%0A"> これは各 <img src="https://latex.codecogs.com/png.latex?%5Cmu_i"> に対して独立な Cauchy 事前分布を仮定している．</p>
<p><span class="citation" data-cites="Zellner-Siow1980">(Zellner and Siow, 1980)</span> の事前分布 <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7B%5Ctheta%7D%7Cg%5Csim%5Cmathrm%7BN%7D(%5Cboldsymbol%7B0%7D,g(%5Cboldsymbol%7BX%7D%5E%5Ctop%5Cboldsymbol%7BX%7D/n)%5E%7B-1%7DI_p)%0A"> や一般の <img src="https://latex.codecogs.com/png.latex?g">-prior との違いとして，スケール因子 <img src="https://latex.codecogs.com/png.latex?(%5Cboldsymbol%7BX%7D%5E%5Ctop%5Cboldsymbol%7BX%7D/n)%5E%7B-1%7D"> がない形であるのは，ANOVA の説明変数 <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BX%7D"> が離散変数であるためである．</p>
</section>
<section id="anova-でのベイズ因子" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="anova-でのベイズ因子"><span class="header-section-number">2.5</span> ANOVA でのベイズ因子</h3>
<p>以上のモデルを，帰無仮説に対立させる「デフォルトモデル」として提案したのが <span class="citation" data-cites="Rouder+2012">(Rouder et al., 2012)</span> である．</p>
<p>特に <img src="https://latex.codecogs.com/png.latex?G=gI_p"> の場合は，結果として得られるベイズ因子は１次元の積分のみを含むため，簡単な数値積分アルゴリズムによって計算可能である．</p>
</section>
<section id="多元配置ベイズ-anova" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="多元配置ベイズ-anova"><span class="header-section-number">2.6</span> 多元配置ベイズ ANOVA</h3>
<p>ひとまず <span class="citation" data-cites="Rouder+2012">(Section 8 Rouder et al., 2012)</span> を参照．</p>
</section>
<section id="ベイズ因子に関する注意喚起" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="ベイズ因子に関する注意喚起"><span class="header-section-number">2.7</span> 「ベイズ因子」に関する注意喚起</h3>
<p>ベイズ因子を含め，周辺尤度 <img src="https://latex.codecogs.com/png.latex?p(%5Ctheta%7Cy)"> （エビデンスともいう）を用いた指標は，モデルの仮定に対して感度が高い <span class="citation" data-cites="Robert2016">(Robert, 2016)</span>, <span class="citation" data-cites="Kamary+2018">(Kamary et al., 2018)</span>．</p>
<p>そのため「モデルのデータへの当てはまりの良さを１つの指標にまとめた値」としては少し心許ない．</p>
<p>加えて，帰無仮説に対立させる仮説を構成して，二項対立の構造に持ち込むことは，自然なデータ解析のワークフローに必ずしも入ってこない．</p>
<p>ベイズ推論の仮定で得られる事後分布から，特定の仮説 <img src="https://latex.codecogs.com/png.latex?H:%5Ctheta=%5Ctheta_0"> がまともかを評価する方法の方が，探索的データ解析の観点からは含意が多いことも多い．</p>
</section>
</section>
<section id="ベイズ推論に基づく方法" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="ベイズ推論に基づく方法"><span class="header-section-number">3</span> ベイズ推論に基づく方法</h2>
<section id="はじめに-2" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="はじめに-2"><span class="header-section-number">3.1</span> はじめに</h3>
<p>ANOVA とベイズ ANOVA の究極的な目標は，平均が一致する <img src="https://latex.codecogs.com/png.latex?%0AH_0:%5Cmu_1=%5Ccdots=%5Cmu_p%0A"> という仮説がデータからどれほど支持されるか／されないかを評価することにある．</p>
<p>最も直接的な方法は，パラメータ空間上に描かれる事後分布を見ることである．信用区間を報告し，帰無仮説がそのどこに位置するかを見ても良いだろう．</p>
</section>
<section id="事後予測によるモデル検証" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="事後予測によるモデル検証"><span class="header-section-number">3.2</span> 事後予測によるモデル検証</h3>
<p>このように，ベイズ事後分布やそのサンプルを通じたモデル検証方法は posterior predictive check <span class="citation" data-cites="Gelman-Shalizi2013">(Gelman and Shalizi, 2013)</span> と呼ばれ，これを多角的に行うことが一つの理想形とされている <span class="citation" data-cites="Gelman+2020">(Gelman et al., 2020)</span>．</p>
<p>同様に <span class="citation" data-cites="Kruschke2015">(Kruschke, 2015)</span> では，モデル (2) の形を一般化線型モデルの特別な場合と見て推定し，ANOVA をモデル比較の観点から適切に実行する方法を論じている．</p>
<p>このように，ANOVA を適切に扱うには，階層モデルとしての取り扱いが欠かせない．同様の議論は <span class="citation" data-cites="Gelman2005">(Gelman, 2005)</span> でも展開されている．</p>
<p>ここでは，以下の節で帰無仮説 <img src="https://latex.codecogs.com/png.latex?H_0"> の妥当性を詳細に評価するための方法を見ていく．</p>
</section>
<section id="ベイズ事後-p-値" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="ベイズ事後-p-値"><span class="header-section-number">3.3</span> ベイズ事後 <img src="https://latex.codecogs.com/png.latex?p">-値</h3>
<p>Bayes 因子の他に，検定統計量に対するベイズ事後予測分布を導出し，その裾確率を評価して <img src="https://latex.codecogs.com/png.latex?p">-値の代替とする方法もある．</p>
<p>これは <strong>事後予測 <img src="https://latex.codecogs.com/png.latex?p">-値</strong> (posterior predictive <img src="https://latex.codecogs.com/png.latex?p">-value) <span class="citation" data-cites="BDA">(Gelman et al., 2014, p. 146)</span> と呼ばれる．</p>
</section>
<section id="rope-region-of-practical-equivalence" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="rope-region-of-practical-equivalence"><span class="header-section-number">3.4</span> ROPE (Region of Practical Equivalence)</h3>
<p>ROPE は帰無仮説 <img src="https://latex.codecogs.com/png.latex?H_0"> と区別がつかないとする区間である．</p>
<p>帰無仮説が <img src="https://latex.codecogs.com/png.latex?H_0:%5Ctheta=%5Ctheta_0"> という形をしていた場合，ほとんどの場合 <img src="https://latex.codecogs.com/png.latex?%5Ctheta=%5Ctheta_0+0.1"> でも事実上変化はない．</p>
<p>このように，帰無仮説と同一視してしまう範囲を <strong>ROPE</strong> <span class="citation" data-cites="Kruschke2015">(Kruschke, 2015, p. 336)</span> という．</p>
<section id="hdr-の使用" class="level4" data-number="3.4.1">
<h4 data-number="3.4.1" class="anchored" data-anchor-id="hdr-の使用"><span class="header-section-number">3.4.1</span> HDR の使用</h4>
<p>この ROPE が 95% <a href="https://ja.wikipedia.org/wiki/信用区間"><strong>最高密度信用領域</strong></a> (HDR: Highest Density Region) と互いに素になるときに，「棄却」されたとする．</p>
<p>ただし，最高密度信用領域とは 95% 信用区間＝95% の事後確率を持つ領域のうち，面積が最も小さいもののことを言う．</p>
<p>この方法では，逆に HDR が ROPE を完全に含む場合，帰無仮説を「採択」するという積極的な意思決定も可能である．</p>
<p>ROPE と同様の考え方は，ベイズによる実験計画法でも range of equivalence <span class="citation" data-cites="Freedman+1984">(Freedman et al., 1984)</span>, <span class="citation" data-cites="Spiegelhalter+1994">(Spiegelhalter et al., 1994)</span> の名前で用いられてきた歴史がある．</p>
</section>
<section id="rope-の確率" class="level4" data-number="3.4.2">
<h4 data-number="3.4.2" class="anchored" data-anchor-id="rope-の確率"><span class="header-section-number">3.4.2</span> ROPE の確率</h4>
<p>または，事後確率ぶんぷが ROPE 内にどれほどの確率を与えるかを見ることもできる <span class="citation" data-cites="Kruschke2018">(Kruschke, 2018)</span>．</p>
<p>ROPE の応用と実装は <span class="citation" data-cites="Kelter2022">(Kelter, 2022)</span> も参照．</p>
</section>
</section>
</section>
<section id="ベイズ統計解析に関する文献案内" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="ベイズ統計解析に関する文献案内"><span class="header-section-number">4</span> ベイズ統計解析に関する文献案内</h2>
<p>応用分野の研究者に対する「なぜベイズを使うのか？」に対する端的な回答として，「統計的有意性」などの「わかりやすい」指標に飛びついた結果，真のデータの声を聞かずに自分の見たいものを見始めてしまうと言うことが少なく，「自己欺瞞に陥りにくい」という美点があることは，<a href="../../../posts/2024/AI/BAI.html">ベイズ機械学習の稿</a> でも触れた．</p>
<p><img src="https://latex.codecogs.com/png.latex?p">-値はそのような欺瞞を生む代用例であり，使用を禁止すべきとの声 <span class="citation" data-cites="McShane+2019">(Blakeley B. McShane and Tackett, 2019)</span> もある．その論拠は大まかに次のとおりである．</p>
<p>そもそも <img src="https://latex.codecogs.com/png.latex?p">-値とは，「帰無仮説を採用したモデルはデータへの当てはまりの度合いが悪い」ということを言っているだけであり，<img src="https://latex.codecogs.com/png.latex?p">-値が十分に低ければそれ以上の情報は引き出せない．</p>
<p>当然 <img src="https://latex.codecogs.com/png.latex?p">-値が <img src="https://latex.codecogs.com/png.latex?0.01"> であることと <img src="https://latex.codecogs.com/png.latex?0.00001"> であることは質的に全く変わらない <span class="citation" data-cites="BDA">(Gelman et al., 2014, p. 150)</span>．</p>
<p>そのことに加え <img src="https://latex.codecogs.com/png.latex?p">-値は必ずしも頑健な指標ではなく，帰無仮説を少し摂動させただけで <img src="https://latex.codecogs.com/png.latex?p"> 値が大きくなってしまうかもしれない．そのような場合は結局ほとんど帰無的であり，「統計的有意性」はほとんど無意味になってしまう．同様の議論が <span class="citation" data-cites="Gelman-Stern2006">(Gelman and Stern, 2006)</span> で展開されている．</p>
<p>このような現状への対処として，応用分野の研究者にもベイズ統計学は根本的な解決法として広く推奨される <span class="citation" data-cites="Dienes-Mclatchie2018">(Dienes and Mclatchie, 2018)</span>．<span class="citation" data-cites="Wagenmakers+2016">(Wagenmakers et al., 2016)</span> はその旨を２つの実例を通じて簡潔に実証しており，同時にベイズ統計学の考え方に対する洗練された導入を行なっている．</p>
<p><span class="citation" data-cites="vandenBergh+2020">(Don van den Bergh and Wagenmakers, 2020)</span> は分散分析をベイズの方法によって実行する手引きを，特に JASP を用いて実演している．</p>
<p>JASP のベイズ ANOVA のエンジンは R パッケージ <code>BayesFactor</code> (<a href="https://cran.r-project.org/web/packages/BayesFactor/index.html">CRAN</a> / <a href="https://github.com/richarddmorey/BayesFactor">GitHub</a>) を用いている．<code>BayesFactor</code> では大規模な <img src="https://latex.codecogs.com/png.latex?M">-元配置 ANOVA モデルにおいても Bayes 因子を用いたモデル比較を行うことができる．</p>
<p>ベイズ ANOVA の R パッケージとしては <code>bayesanova</code> (<a href="https://cran.r-project.org/web/packages/bayesanova/index.html">CRAN</a> / <a href="https://github.com/cran/bayesanova">GitHub</a>) <span class="citation" data-cites="Kelter2022">(Kelter, 2022)</span> もある．これは検定に似た行為を根本的に排除して Gauss 混合モデルとして Gibbs サンプラーによるベイズ推定を実行し，ROPE (Region of Practical Equivalence) <span class="citation" data-cites="Kruschke2015">(Kruschke, 2015, p. 336)</span> <span class="citation" data-cites="Kruschke2018">(Kruschke, 2018)</span> を用いたモデル比較を行う．</p>
<p>もちろんこのような完全なモデリングを行うことが理想かもしれないが，従来の ANOVA になれきっている研究者にとっては，Bayesian ANOVA に手を伸ばしてみることが次のステップとして大変良いだろう．</p>
<p>また別の角度からの「ベイズを使うべき理由」としての説得的な議論としては，ベイズ階層モデリングは ANOVA の正統進化という理解 <span class="citation" data-cites="Gelman2005">(Gelman, 2005)</span> ができるという向きもある．</p>
<p>以上の立場は <span class="citation" data-cites="BDA">(Gelman et al., 2014)</span> や <span class="citation" data-cites="Kruschke2015">(Kruschke, 2015)</span> などの標準的なベイズデータ解析の教科書でも一貫している．</p>
</section>



<div id="quarto-appendix" class="default"><section id="その他の文献案内" class="level2 appendix" data-number="5"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">5</span> その他の文献案内</h2><div class="quarto-appendix-contents">

<p>F-検定については <span class="citation" data-cites="吉田朋広2006-数理統計">(吉田朋広, 2006)</span> を参考にした．</p>
<p>ANOVA の歴史については <span class="citation" data-cites="Tweney2014">(Tweney, 2014)</span> を参照．(repeated measures) ANOVA は多重線型回帰のうち説明変数が離散変数である場合に相当するという理解は，一般化線型モデルの発展と普及に伴って理解が広がった．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Bayarri-Darcia-Donato2007" class="csl-entry">
Bayarri, M. J., and García-Donato, G. (2007). <a href="https://doi.org/10.1093/biomet/asm014"><span class="nocase">Extending conventional priors for testing general hypotheses in linear models</span></a>. <em>Biometrika</em>, <em>94</em>(1), 135–152.
</div>
<div id="ref-vandenBergh+2023" class="csl-entry">
Bergh, D. van den, Wagenmakers, E.-J., and Aust, F. (2023). <a href="https://doi.org/10.1177/25152459231168024">Bayesian repeated-measures analysis of variance: An updated methodology implemented in JASP</a>. <em>Advances in Methods and Practices in Psychological Science</em>, <em>6</em>(2), 25152459231168024.
</div>
<div id="ref-McShane+2019" class="csl-entry">
Blakeley B. McShane, A. G., David Gal, and Tackett, J. L. (2019). <a href="https://doi.org/10.1080/00031305.2018.1527253">Abandon statistical significance</a>. <em>The American Statistician</em>, <em>73</em>(sup1), 235–245.
</div>
<div id="ref-Brown-Forsythe1974" class="csl-entry">
Brown, M. B., and Forsythe, A. B. (1974). <a href="https://doi.org/10.1080/01621459.1974.10482955">Robust tests for the equality of variances</a>. <em>Journal of the American Statistical Association</em>, <em>69</em>(346), 364–367.
</div>
<div id="ref-Cohen1988" class="csl-entry">
Cohen, J. (1988). <em><a href="https://doi.org/10.4324/9780203771587">Statistical power analysis for the behavioral sciences</a></em>. Routledge.
</div>
<div id="ref-Dienes-Mclatchie2018" class="csl-entry">
Dienes, Z., and Mclatchie, N. (2018). <a href="https://doi.org/10.3758/s13423-017-1266-z">Four reasons to prefer bayesian analyses over significance testing</a>. <em>Psychonomic Bulletin &amp; Review</em>, <em>25</em>(1), 207–218.
</div>
<div id="ref-vandenBergh+2020" class="csl-entry">
Don van den Bergh, M. M., Johnny van Doorn, and Wagenmakers, E.-J. (2020). <a href="https://doi.org/10.3917/anpsy1.201.0073"><span class="nocase">A Tutorial on Conducting and Interpreting a Bayesian ANOVA in JASP</span></a>. <em>L’Année Psychologique</em>, <em>120</em>, 73–96.
</div>
<div id="ref-Freedman+1984" class="csl-entry">
Freedman, L. S., Lowe, D., and Macaskill, P. (1984). <a href="http://www.jstor.org/stable/2530902">Stopping rules for clinical trials incorporating clinical opinion</a>. <em>Biometrics</em>, <em>40</em>(3), 575–586.
</div>
<div id="ref-Gelman2005" class="csl-entry">
Gelman, A. (2005). <a href="https://doi.org/10.1214/009053604000001048"><span class="nocase">Analysis of variance—why it is more important than ever</span></a>. <em>The Annals of Statistics</em>, <em>33</em>(1), 1–53.
</div>
<div id="ref-BDA" class="csl-entry">
Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., and Rubin, D. B. (2014). <em><a href="http://www.stat.columbia.edu/~gelman/book/">Bayesian data analysis</a></em>. Boca Raton : CRC Press.
</div>
<div id="ref-Gelman-Shalizi2013" class="csl-entry">
Gelman, A., and Shalizi, C. R. (2013). <a href="https://doi.org/10.1111/j.2044-8317.2011.02037.x">Philosophy and the practice of bayesian statistics</a>. <em>British Journal of Mathematical and Statistical Psychology</em>, <em>66</em>(1), 8–38.
</div>
<div id="ref-Gelman-Stern2006" class="csl-entry">
Gelman, A., and Stern, H. (2006). <a href="https://doi.org/10.1198/000313006X152649">The difference between <span>“significant”</span> and <span>“not significant”</span> is not itself statistically significant</a>. <em>The American Statistician</em>, <em>60</em>(4), 328–331.
</div>
<div id="ref-Gelman+2020" class="csl-entry">
Gelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., … Modrák, M. (2020). <a href="https://arxiv.org/abs/2011.01808">Bayesian workflow</a>.
</div>
<div id="ref-Jeffreys1961" class="csl-entry">
Jeffreys, H. (1961). <em><a href="https://doi.org/10.1093/oso/9780198503682.001.0001">Theory of probability</a></em>. Oxford University Press.
</div>
<div id="ref-Kamary+2018" class="csl-entry">
Kamary, K., Mengersen, K., Robert, C. P., and Rousseau, J. (2018). <a href="https://arxiv.org/abs/1412.2044">Testing hypotheses via a mixture estimation model</a>.
</div>
<div id="ref-Kelter2022" class="csl-entry">
Kelter, R. (2022). Bayesanova: An r package for bayesian inference in the analysis of variance via markov chain monte carlo in gaussian mixture models. <em>The R Journal</em>, <em>14</em>, 54–78.
</div>
<div id="ref-Kruschke2015" class="csl-entry">
Kruschke, J. K. (2015). <em><a href="https://www.sciencedirect.com/book/9780124058880/doing-bayesian-data-analysis">Doing bayesian data analysis: A tutorial with r, JAGS, and stan</a></em>. London ; Tokyo : Academic Press.
</div>
<div id="ref-Kruschke2018" class="csl-entry">
Kruschke, J. K. (2018). <a href="https://doi.org/10.1177/2515245918771304">Rejecting or accepting parameter values in bayesian estimation</a>. <em>Advances in Methods and Practices in Psychological Science</em>, <em>1</em>(2), 270–280.
</div>
<div id="ref-Kruskal-Wallis1952" class="csl-entry">
Kruskal, W. H., and Wallis, W. A. (1952). <a href="https://doi.org/10.1080/01621459.1952.10483441">Use of ranks in one-criterion variance analysis</a>. <em>Journal of the American Statistical Association</em>, <em>47</em>(260), 583–621.
</div>
<div id="ref-Mauchly1940" class="csl-entry">
Mauchly, J. W. (1940). <a href="http://www.jstor.org/stable/2235878">Significance test for sphericity of a normal n-variate distribution</a>. <em>The Annals of Mathematical Statistics</em>, <em>11</em>(2), 204–209.
</div>
<div id="ref-Robert2016" class="csl-entry">
Robert, C. P. (2016). <a href="https://doi.org/10.1016/j.jmp.2015.08.002">The expected demise of the bayes factor</a>. <em>Journal of Mathematical Psychology</em>, <em>72</em>, 33–37.
</div>
<div id="ref-Robert+2009" class="csl-entry">
Robert, C. P., Chopin, N., and Rousseau, J. (2009). <a href="https://doi.org/10.1214/09-STS284"><span class="nocase">Harold Jeffreys’s Theory of Probability Revisited</span></a>. <em>Statistical Science</em>, <em>24</em>(2), 141–172.
</div>
<div id="ref-Rouder+2016" class="csl-entry">
Rouder, J. N., Engelhardt, C. R., McCabe, S., and Morey, R. D. (2016). <a href="https://doi.org/10.3758/s13423-016-1026-5">Model comparison in ANOVA</a>. <em>Psychonomic Bulletin &amp; Review</em>, <em>23</em>(6), 1779–1786.
</div>
<div id="ref-Rouder+2012" class="csl-entry">
Rouder, J. N., Morey, R. D., Speckman, P. L., and Province, J. M. (2012). <a href="https://doi.org/10.1016/j.jmp.2012.08.001">Default bayes factors for ANOVA designs</a>. <em>Journal of Mathematical Psychology</em>, <em>56</em>(5), 356–374.
</div>
<div id="ref-Shapiro-Wilk1965" class="csl-entry">
Shapiro, S. S., and Wilk, M. B. (1965). <a href="https://doi.org/10.1093/biomet/52.3-4.591"><span class="nocase">An analysis of variance test for normality (complete samples)†</span></a>. <em>Biometrika</em>, <em>52</em>(3-4), 591–611.
</div>
<div id="ref-Spiegelhalter+1994" class="csl-entry">
Spiegelhalter, D. J., Freedman, L. S., and Parmar, M. K. B. (1994). <a href="https://doi.org/10.2307/2983527">Bayesian approaches to randomized trials</a>. <em>Journal of the Royal Statistical Society: Series A (Statistics in Society)</em>, <em>157</em>(3), 357–387.
</div>
<div id="ref-Tijmstra2018" class="csl-entry">
Tijmstra, J. (2018). <a href="https://doi.org/10.3758/s13423-018-1447-4">Why checking model assumptions using null hypothesis significance tests does not suffice: A plea for plausibility</a>. <em>Psychonomic Bulletin &amp; Review</em>, <em>25</em>(2), 548–559.
</div>
<div id="ref-Tweney2014" class="csl-entry">
Tweney, R. D. (2014). <a href="https://doi.org/10.1002/9781118445112.stat06304">History of analysis of variance</a>. In <em>Wiley StatsRef: Statistics reference online</em>. John Wiley &amp; Sons, Ltd.
</div>
<div id="ref-Wagenmakers+2016" class="csl-entry">
Wagenmakers, E.-J., Morey, R. D., and Lee, M. D. (2016). <a href="https://doi.org/10.1177/0963721416643289">Bayesian benefits for the pragmatic researcher</a>. <em>Current Directions in Psychological Science</em>, <em>25</em>(3), 169–176.
</div>
<div id="ref-Wetzels+2011" class="csl-entry">
Wetzels, R., Matzke, D., Lee, M. D., Rouder, J. N., Iverson, G. J., and Wagenmakers, E.-J. (2011). <a href="https://doi.org/10.1177/1745691611406923">Statistical evidence in experimental psychology: An empirical comparison using 855 t tests</a>. <em>Perspectives on Psychological Science</em>, <em>6</em>(3), 291–298.
</div>
<div id="ref-Zellner-Siow1980" class="csl-entry">
Zellner, A., and Siow, A. (1980). <a href="https://doi.org/10.1007/BF02888369">Posterior odds ratios for selected regression hypotheses</a>. <em>Trabajos de Estadistica Y de Investigacion Operativa</em>, <em>31</em>(1), 585–603.
</div>
<div id="ref-吉田朋広2006-数理統計" class="csl-entry">
吉田朋広. (2006). <em>数理統計学</em>,Vol. 21. 朝倉書店.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>もちろん，Stan などの確率的プログラミング言語を用いた完全なベイズモデリングはいつでも実行可能である．↩︎</p></li>
<li id="fn2"><p>そして因子分析を通じて，記述統計学の正統進化であるということもできる！？ ANOVA の歴史については <span class="citation" data-cites="Tweney2014">(Tweney, 2014)</span> も参照．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Statistics</category>
  <category>Bayesian</category>
  <guid>https://162348.github.io/posts/2024/Survey/Survey1.html</guid>
  <pubDate>Sun, 22 Sep 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title>R 上の Stan インターフェイス</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/R/Stan2.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<div id="listing-lst-stan" class="listing quarto-float quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Process,MCMC,R,Stan,YUIMA,Bayesian" data-listing-date-sort="1715439600000" data-listing-file-modified-sort="1727007847960" data-listing-date-modified-sort="1726758000000" data-listing-reading-time-sort="5" data-listing-word-count-sort="952">
<a href="../../../posts/2024/R/adastan.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/R/Files/adastan1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
SDE のベイズ推定入門
</h5>
<div class="card-subtitle listing-subtitle">
YUIMA と Stan を用いた確率過程のベイズ推定入門
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-05-12
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Bayesian,Computation,Stan" data-listing-date-sort="1715871600000" data-listing-file-modified-sort="1727007847916" data-listing-date-modified-sort="1726498800000" data-listing-reading-time-sort="3" data-listing-word-count-sort="554">
<a href="../../../posts/2024/R/Stan1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/R/Files/Stan.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Stan 入門
</h5>
<div class="card-subtitle listing-subtitle">
rstan による Stan の利用
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-05-17
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Stan,R,YUIMA,Process" data-listing-date-sort="1715871600000" data-listing-file-modified-sort="1727007847941" data-listing-date-modified-sort="1726498800000" data-listing-reading-time-sort="5" data-listing-word-count-sort="859">
<a href="../../../posts/2024/R/YUIMA.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://162348.github.io/posts/2024/R/Files/YUIMA.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
YUIMA 入門
</h5>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-05-17
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
<section id="概観" class="level2 unlisted unnumbered">
<h2 class="unlisted unnumbered anchored" data-anchor-id="概観">概観</h2>
<p><code>RStan</code> は <code>Rcpp</code> や <code>inline</code> といったパッケージにより C++ を R から呼び出すことで，Stan とのインターフェイスを実現している．</p>
<p>一方で <code>CmdStanR</code> は <code>CmdStan</code> という Stan のコマンドラインインターフェイスを R から呼び出すことで，Stan とのインターフェイスを実現している．</p>
</section>
<section id="rstan-パッケージ" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="rstan-パッケージ"><span class="header-section-number">1</span> <code>RStan</code> パッケージ</h2>
<section id="はじめるために" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="はじめるために"><span class="header-section-number">1.1</span> はじめるために</h3>
<p><a href="https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started">RStan Getting Started</a> に従って実行します．</p>
<section id="インストール" class="level4" data-number="1.1.1">
<h4 data-number="1.1.1" class="anchored" data-anchor-id="インストール"><span class="header-section-number">1.1.1</span> インストール</h4>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="すでにインストールされており，再インストールしたい場合">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
すでにインストールされており，再インストールしたい場合
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">packageVersion</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rstan"</span>)</span></code></pre></div>
<p>を実行してすでに存在する場合は，次を実行します</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">remove.packages</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rstan"</span>)</span>
<span id="cb2-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.exists</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".RData"</span>)) <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.remove</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".RData"</span>)</span></code></pre></div>
</div>
</div>
</div>
<p>ほとんどの場合，次の１行でインストールできます：</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">install.packages</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rstan"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">repos =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://cloud.r-project.org/"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">dependencies =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>)</span></code></pre></div>
</section>
<section id="rstan-の利用のためにはc-コンパイラが必要" class="level4" data-number="1.1.2">
<h4 data-number="1.1.2" class="anchored" data-anchor-id="rstan-の利用のためにはc-コンパイラが必要"><span class="header-section-number">1.1.2</span> <code>RStan</code> の利用のためには，<code>c++</code> コンパイラが必要</h4>
<p>XCode コマンドラインツールをインストールすることにより，<code>/Library/Developer/CommandLineTools/usr/bin</code> に <code>clang++</code> がインストールされます．</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb4-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">clang</span>++ <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-v</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-E</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-x</span> c++ /dev/null</span></code></pre></div>
<p>現在では，<a href="https://mac.thecoatlessprofessor.com/macrtools/"><code>macrtools</code></a> を通じて <code>C++</code> コンパイラを R 内でインストールすることもできます．</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="コンパイラ最適化 (MacOS)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
コンパイラ最適化 (MacOS)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><a href="https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started">RStan Getting Started</a> の <a href="https://github.com/stan-dev/rstan/wiki/Configuring-C---Toolchain-for-Mac">Configuring C Toolchain for Mac</a> では，次のようなコンパイラの最適化が推奨されています：</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1">dotR <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.path</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Sys.getenv</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HOME"</span>), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".R"</span>)</span>
<span id="cb5-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.exists</span>(dotR)) <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dir.create</span>(dotR)</span>
<span id="cb5-3">M <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.path</span>(dotR, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Makevars"</span>)</span>
<span id="cb5-4"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.exists</span>(M)) <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.create</span>(M)</span>
<span id="cb5-5">arch <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ifelse</span>(R.version<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>arch <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"aarch64"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"arm64"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"x86_64"</span>)</span>
<span id="cb5-6"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cat</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">paste</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">CXX17FLAGS += -O3 -mtune=native -arch"</span>, arch, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"-ftemplate-depth-256"</span>),</span>
<span id="cb5-7">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">file =</span> M, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sep =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">append =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span></code></pre></div>
<p>これにより <code>~/.R/Makevars</code> に次のような行が追加されます：</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb6-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">CXX17FLAGS</span> += <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-O3</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-mtune</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>native <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-arch</span> arm64 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-ftemplate-depth-256</span></span></code></pre></div>
</div>
</div>
</div>
</section>
<section id="検証" class="level4" data-number="1.1.3">
<h4 data-number="1.1.3" class="anchored" data-anchor-id="検証"><span class="header-section-number">1.1.3</span> 検証</h4>
<p>次のコードが実行されれば，インストールは成功しています．</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">example</span>(stan_model, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">package =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rstan"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">run.dontrun =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>)</span></code></pre></div>
</section>
</section>
<section id="stan-関数" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="stan-関数"><span class="header-section-number">1.2</span> <code>stan</code> 関数</h3>
<p>RStan パッケージの本体は <code>stan</code> 関数である：</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">stan</span>(file, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">model_name =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"anon_model"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">model_code =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fit =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span>,</span>
<span id="cb8-2">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pars =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span>,</span>
<span id="cb8-3">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">chains =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">iter =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2000</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">warmup =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">floor</span>(iter<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">thin =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,</span>
<span id="cb8-4">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">init =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"random"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">seed =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sample.int</span>(.Machine<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>integer.max, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),</span>
<span id="cb8-5">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">algorithm =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"NUTS"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HMC"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Fixed_param"</span>),</span>
<span id="cb8-6">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">control =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sample_file =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">diagnostic_file =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>,</span>
<span id="cb8-7">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">save_dso =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">verbose =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">include =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>,</span>
<span id="cb8-8">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">cores =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">getOption</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mc.cores"</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>L),</span>
<span id="cb8-9">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">open_progress =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">interactive</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;&amp;</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">isatty</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">stdout</span>()) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;&amp;</span></span>
<span id="cb8-10">                  <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">identical</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Sys.getenv</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RSTUDIO"</span>), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1"</span>),</span>
<span id="cb8-11">  ...,</span>
<span id="cb8-12">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">boost_lib =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">eigen_lib =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span></span>
<span id="cb8-13">  )</span></code></pre></div>
<section id="モデルの受け渡し" class="level4" data-number="1.2.1">
<h4 data-number="1.2.1" class="anchored" data-anchor-id="モデルの受け渡し"><span class="header-section-number">1.2.1</span> モデルの受け渡し</h4>
<p><code>model_code=""</code> が Stan モデルを定義するコードを，文字列として直接受け渡すための引数である．</p>
<p>返り値はフィット済みの <code>stanfit</code> オブジェクトである．</p>
<p>他の方法は次のとおり：</p>
<ul>
<li><code>file</code> としてファイルへのパスを渡す</li>
<li>フィット済みの <code>stanfit</code> オブジェクトを <code>fit</code> 引数として渡す</li>
</ul>
</section>
<section id="重要な引数" class="level4" data-number="1.2.2">
<h4 data-number="1.2.2" class="anchored" data-anchor-id="重要な引数"><span class="header-section-number">1.2.2</span> 重要な引数</h4>
<ul>
<li><code>data</code>：データを与える．<code>list</code> 型．</li>
<li><code>iter</code>：繰り返し回数．デフォルトは <code>2000</code>．</li>
<li><code>chains</code>：チェイン数．デフォルトは <code>4</code>．</li>
</ul>
</section>
<section id="stanfit-オブジェクト" class="level4" data-number="1.2.3">
<h4 data-number="1.2.3" class="anchored" data-anchor-id="stanfit-オブジェクト"><span class="header-section-number">1.2.3</span> <code>stanfit</code> オブジェクト</h4>
<p><code>stan</code> 関数は Stan モデルを C++ に変換して実行し，結果を <code>stanfit</code> オブジェクトとして返す．</p>
<p>これに対して <code>print</code>, <code>summary</code>, <code>plot</code> などのメソッドが利用可能である．</p>
<p>さらに，次の様にして MCMC サンプルを取り出すことができる：</p>
<ul>
<li><code>as.array</code> メソッドを用いて MCMC サンプルを <code>array</code> 型で取り出す</li>
<li><code>extract</code> メソッドを用いて MCMC サンプルを <code>list</code> 型で取り出す</li>
<li><code>posterior</code> ライブラリの <code>as_draws_df</code> メソッドを用いて MCMC サンプルを <code>df</code> 型で取り出す．種々のデータ型 <code>&lt;format&gt;</code> に対して <code>as_draws_&lt;format&gt;</code> が存在する．</li>
</ul>
<p>取り出した MCMC サンプルは <code>bayesplot</code> パッケージの <code>mcmc_trace</code>, <code>mcmc_dens</code> などの関数を用いて可視化することができる．</p>
</section>
<section id="例１軌道と事後分布の可視化" class="level4" data-number="1.2.4">
<h4 data-number="1.2.4" class="anchored" data-anchor-id="例１軌道と事後分布の可視化"><span class="header-section-number">1.2.4</span> 例１：軌道と事後分布の可視化</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1">scode <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb9-2"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">parameters {</span></span>
<span id="cb9-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  array[2] real y;</span></span>
<span id="cb9-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb9-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">model {</span></span>
<span id="cb9-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  y[1] ~ normal(0, 1);</span></span>
<span id="cb9-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  y[2] ~ double_exponential(0, 2);</span></span>
<span id="cb9-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb9-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb9-10">fit <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">stan</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">model_code =</span> scode, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">iter =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">chains =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">verbose =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(bayesplot)</span>
<span id="cb10-2"></span>
<span id="cb10-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mcmc_trace</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.array</span>(fit), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pars =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y[1]"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y[2]"</span>))</span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/R/Stan2_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption>軌道のプロット</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mcmc_dens</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.array</span>(fit), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pars =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y[1]"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"y[2]"</span>))</span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/R/Stan2_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption>密度のプロット</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="例２確率過程の統計推測" class="level4" data-number="1.2.5">
<h4 data-number="1.2.5" class="anchored" data-anchor-id="例２確率過程の統計推測"><span class="header-section-number">1.2.5</span> 例２：確率過程の統計推測</h4>
<p>OU 過程</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AdX_t=%5Ctheta(%5Cmu-X_t)%5C,dt+%5Csigma%5C,dW_t%0A"></p>
<p>に対して，<code>stan</code> 関数でベイズ推定を実行してみます．</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(yuima)</span>
<span id="cb12-2">model <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">setModel</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">drift =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"theta*(mu-X)"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">diffusion =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sigma"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">state.variable =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"X"</span>)</span></code></pre></div>
</div>
<p>パラメータは <span id="eq-sde-param"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bpmatrix%7D%5Ctheta%5C%5C%5Cmu%5C%5C%5Csigma%5Cend%7Bpmatrix%7D%0A=%0A%5Cbegin%7Bpmatrix%7D1%5C%5C0%5C%5C0.5%5Cend%7Bpmatrix%7D%0A%5Ctag%7B1%7D"></span> として YUIMA を用いてシミュレーションをし，そのデータを与えてパラメータが復元できるかをみます．</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(rstan)</span>
<span id="cb13-2">excode <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"data {</span></span>
<span id="cb13-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            int N;</span></span>
<span id="cb13-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            real x[N+1];</span></span>
<span id="cb13-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            real h;</span></span>
<span id="cb13-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          }</span></span>
<span id="cb13-7"></span>
<span id="cb13-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          parameters {</span></span>
<span id="cb13-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            real theta;</span></span>
<span id="cb13-10"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            real mu;</span></span>
<span id="cb13-11"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            real&lt;lower=0&gt; sigma;</span></span>
<span id="cb13-12"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          }</span></span>
<span id="cb13-13"></span>
<span id="cb13-14"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          model {</span></span>
<span id="cb13-15"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            x[1] ~ normal(0,1);</span></span>
<span id="cb13-16"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            for(n in 2:(N+1)){</span></span>
<span id="cb13-17"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">              x[n] ~ normal(x[n-1] + theta * (mu - x[n-1]) * h,  sqrt(h) * sigma);</span></span>
<span id="cb13-18"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            }</span></span>
<span id="cb13-19"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          }"</span></span>
<span id="cb13-20"></span>
<span id="cb13-21">sampling <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">setSampling</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">Initial =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">Terminal =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">n =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span>
<span id="cb13-22">yuima <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">setYuima</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">model =</span> model, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sampling =</span> sampling)</span>
<span id="cb13-23">simulation <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">simulate</span>(yuima, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">true.parameter =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">theta =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mu =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sigma =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xinit =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rnorm</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb13-24">sde_dat <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">N =</span>  yuima<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>sampling<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>n,</span>
<span id="cb13-25">                  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.numeric</span>(simulation<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>data<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>original.data),</span>
<span id="cb13-26">                  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">h=</span>yuima<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>sampling<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>Terminal<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>yuima<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>sampling<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>n)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># シミュレーション結果</span></span>
<span id="cb14-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(simulation)</span></code></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/R/Stan2_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ベイズ推定</span></span>
<span id="cb15-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rstan_options</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">auto_write =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>)</span>
<span id="cb15-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">options</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mc.cores =</span> parallel<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">detectCores</span>())</span>
<span id="cb15-4"></span>
<span id="cb15-5">fit <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">stan</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">model_code=</span>excode, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> sde_dat, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">iter =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">chains =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">print</span>(fit)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Inference for Stan model: anon_model.
4 chains, each with iter=1000; warmup=500; thin=1; 
post-warmup draws per chain=500, total post-warmup draws=2000.

         mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat
theta    0.89    0.25 1.01   -0.44    0.07    0.59    1.70    3.27    17 1.14
mu       0.02    0.27 3.59   -5.90   -0.15    0.12    0.42    7.23   178 1.02
sigma    0.50    0.00 0.01    0.48    0.49    0.50    0.51    0.52   108 1.07
lp__  3105.37    0.14 1.23 3102.48 3104.76 3105.46 3106.29 3107.15    80 1.06

Samples were drawn using NUTS(diag_e) at Thu Sep 19 16:46:14 2024.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).</code></pre>
</div>
</div>
<p>パラメータ (1) がよく推定できていることがわかる．特に <img src="https://latex.codecogs.com/png.latex?%5Csigma"> が安定して推定できている：</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(fit)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>ci_level: 0.8 (80% intervals)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>outer_level: 0.95 (95% intervals)</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/R/Stan2_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bayesplot"</span>)</span>
<span id="cb21-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rstanarm"</span>)</span>
<span id="cb21-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ggplot2"</span>)</span>
<span id="cb21-4"></span>
<span id="cb21-5">posterior <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.matrix</span>(fit)</span>
<span id="cb21-6">plot_title <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggtitle</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Posterior distributions"</span>,</span>
<span id="cb21-7">                      <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"with medians and 80% intervals"</span>)</span>
<span id="cb21-8"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mcmc_areas</span>(posterior,</span>
<span id="cb21-9">           <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pars =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"theta"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mu"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sigma"</span>),</span>
<span id="cb21-10">           <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">prob =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> plot_title</span></code></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/R/Stan2_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="トラブルシューティング" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="トラブルシューティング"><span class="header-section-number">1.3</span> トラブルシューティング</h3>
<section id="cmath-が見つからない" class="level4" data-number="1.3.1">
<h4 data-number="1.3.1" class="anchored" data-anchor-id="cmath-が見つからない"><span class="header-section-number">1.3.1</span> <code>cmath</code> が見つからない</h4>
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1">Quitting from lines <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">329-343</span> (adastan.qmd) </span>
<span id="cb22-2"></span>
<span id="cb22-3"> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">compileCode</span>(f, code, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">language =</span> language, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">verbose =</span> verbose) でエラー<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> </span>
<span id="cb22-4">  using C<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">++</span> compiler<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> ‘Apple clang version <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>.<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span> (clang<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">-1600</span>.<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>.<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">26.3</span>)’using C<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">++</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">17</span>using SDK<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> ‘MacOSX15.<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span>sdk’In file included from <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span>built<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>In file included from <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Library<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Frameworks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>R.framework<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Versions<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.3</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>arm64<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Resources<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>library<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>StanHeaders<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>include<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>stan<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>math<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>prim<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>fun<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Eigen.hpp<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">22</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>In file included from <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Library<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Frameworks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>R.framework<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Versions<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.3</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>arm64<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Resources<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>library<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>RcppEigen<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>include<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Eigen<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Dense<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>In file included from <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Library<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Frameworks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>R.framework<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Versions<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.3</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>arm64<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Resources<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>library<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>RcppEigen<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>include<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Eigen<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Core<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">19</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">/</span>Library<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Frameworks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>R.framework<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Versions<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.3</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>arm64<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Resources<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>library<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>RcppEigen<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>include<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Eigen<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>src<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Core<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>util<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Macros.h<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">679</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> fatal error<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cmath'</span> file not found  <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">679</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#include &lt;cmath&gt;      |          ^~~~~~~1 error generated.make: *** [file2546221168fc.o] Error 1</span></span>
<span id="cb22-5"> 呼び出し<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>  .main ... cxxfunctionplus <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">&lt;</span>Anonymous<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">-&gt;</span> cxxfunction <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">-&gt;</span> compileCode</span>
<span id="cb22-6"> 追加情報<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>  警告メッセージ<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> </span>
<span id="cb22-7"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>  パッケージ <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'rstan'</span> はバージョン <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>.<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3.1</span> の R の下で造られました  </span>
<span id="cb22-8"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>  パッケージ <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bayesplot'</span> はバージョン <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>.<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3.1</span> の R の下で造られました  </span>
<span id="cb22-9"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>  パッケージ <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'rstanarm'</span> はバージョン <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>.<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3.1</span> の R の下で造られました  </span>
<span id="cb22-10"></span>
<span id="cb22-11"></span>
<span id="cb22-12">Quitting from lines <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">329-343</span> (adastan.qmd) </span>
<span id="cb22-13"> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sink</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">type =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"output"</span>) でエラー<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>  コネクションが不正です </span>
<span id="cb22-14"> 呼び出し<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>  .main ... eval <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">-&gt;</span> stan <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">-&gt;</span> stan_model <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">-&gt;</span> cxxfunctionplus <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">-&gt;</span> sink</span>
<span id="cb22-15"> 実行が停止されました </span></code></pre></div>
<p>大変長く書いてあるが，要は <code>fatal error: 'cmath' file not found</code> である．</p>
<p>筆者の場合は純粋な <code>clang++</code> の問題であった：</p>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb23-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">❯</span> echo <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#include &lt;cmath&gt;</span></span>
<span id="cb23-2"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">#include &lt;iostream&gt;</span></span>
<span id="cb23-3"></span>
<span id="cb23-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">int main() {</span></span>
<span id="cb23-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    double result = std::sqrt(16.0);</span></span>
<span id="cb23-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    std::cout &lt;&lt; "The square root of 16 is " &lt;&lt; result &lt;&lt; std::endl;</span></span>
<span id="cb23-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    return 0;</span></span>
<span id="cb23-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">}'</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> test.cpp</span>
<span id="cb23-9"></span>
<span id="cb23-10"></span>
<span id="cb23-11"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">~</span></span>
<span id="cb23-12"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">❯</span> clang++ <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-std</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>c++17 test.cpp <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-o</span> test</span>
<span id="cb23-13"></span>
<span id="cb23-14"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">test.cpp:1:10:</span> fatal error: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cmath'</span> file not found</span>
<span id="cb23-15">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">1</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">|</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#include &lt;cmath&gt;</span></span>
<span id="cb23-16">      <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">|</span>          <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">^~~~~~~</span></span>
<span id="cb23-17"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">1</span> error generated.</span></code></pre></div>
<p>このような場合は，まず Xcode の再インストールをすると良い．</p>
<div class="sourceCode" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb24-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">softwareupdate</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--list</span></span></code></pre></div>
<p>の出力を用いて，次のようにする：</p>
<div class="sourceCode" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb25-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">softwareupdate</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-i</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Command Line Tools (macOS High Sierra version 10.13) for Xcode-10.1"</span></span></code></pre></div>
<p>または次のようにする：</p>
<div class="sourceCode" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb26-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> rm <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-rf</span> /Library/Developer/CommandLineTools</span>
<span id="cb26-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">xcode-select</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--install</span></span></code></pre></div>
</section>
</section>
</section>
<section id="cmdstanr-パッケージ" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="cmdstanr-パッケージ"><span class="header-section-number">2</span> <code>CmdStanR</code> パッケージ</h2>
<p><code>CmdStanPy</code>, <code>CmdStanR</code> はいずれも Stan のインターフェースである．</p>
<p><code>CmdStanR</code> は <code>R6</code> オブジェクトを用いており，大変現代的な実装を持っている．</p>
<section id="はじめるために-1" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="はじめるために-1"><span class="header-section-number">2.1</span> はじめるために</h3>
<p><a href="https://mc-stan.org/cmdstanr/articles/cmdstanr.html">Getting Started with CmdStanR</a> に従って実行します．</p>
<section id="インストール-1" class="level4" data-number="2.1.1">
<h4 data-number="2.1.1" class="anchored" data-anchor-id="インストール-1"><span class="header-section-number">2.1.1</span> インストール</h4>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">install.packages</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cmdstanr"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">repos =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'https://stan-dev.r-universe.dev'</span>, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">getOption</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"repos"</span>)))</span></code></pre></div>
</section>
<section id="cmdstanr-の利用のためにはcmdstan-が必要" class="level4" data-number="2.1.2">
<h4 data-number="2.1.2" class="anchored" data-anchor-id="cmdstanr-の利用のためにはcmdstan-が必要"><span class="header-section-number">2.1.2</span> <code>CmdStanR</code> の利用のためには，<code>CmdStan</code> が必要</h4>
<p><code>CmdStanR</code> を<a href="../../../posts/2024/R/Stan1.html#sec-installing-cmdstan">直接インストールすることもできます</a>が，<code>CmdStanR</code> 内部からインストールすることもできます．</p>
<div class="sourceCode" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">install_cmdstan</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">cores =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span></code></pre></div>
<div class="cell">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cmdstan_version</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "2.35.0"</code></pre>
</div>
</div>
<p>多くの場合，自動で <code>CMDSTAN</code> 環境変数にパスが設定されます．次のいずれかの方法で確認できます：</p>
<div class="sourceCode" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Sys.getenv</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CMDSTAN"</span>)</span>
<span id="cb31-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cmdstan_path</span>()</span></code></pre></div>
<p><code>CmdStanR</code> の美点の一つは，<code>install_cmdstan()</code> により <code>CmdStan</code> をアップデートすることで最新の Stan を R から簡単に利用できることである．</p>
<p>一方で <code>RStan</code> はパッケージ自体のアップデートを待つ必要がある．</p>
</section>
</section>
<section id="モデル定義" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="モデル定義"><span class="header-section-number">2.2</span> モデル定義</h3>
<p><code>cmdstan_model()</code> 関数は，Stan 言語による記述されたモデル定義を，C++ コードにコンパイルし，その結果を <code>R6</code> オブジェクトとして返す．<sup>1</sup></p>
<div class="sourceCode" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cmdstan_model</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">stan_file =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">exe_file =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">compile =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>, ...)</span></code></pre></div>
<p>返り値は <code>CmdStanModel</code> オブジェクトである．ただし <code>R6</code> オブジェクトでもあり，<code>R6</code> 流のメソッドの呼び方 <code>$</code> が使える．</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1">file <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.path</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cmdstan_path</span>(), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"examples"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bernoulli"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bernoulli.stan"</span>)</span>
<span id="cb33-2">mod <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cmdstan_model</span>(file)</span></code></pre></div>
</div>
<p>Stan 言語による定義は次のようにして確認できる：</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1">mod<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">print</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>data {
  int&lt;lower=0&gt; N;
  array[N] int&lt;lower=0, upper=1&gt; y;
}
parameters {
  real&lt;lower=0, upper=1&gt; theta;
}
model {
  theta ~ beta(1, 1); // uniform prior on interval 0,1
  y ~ bernoulli(theta);
}</code></pre>
</div>
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">names</span>(mod<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">variables</span>())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "parameters"             "included_files"         "data"                  
[4] "transformed_parameters" "generated_quantities"  </code></pre>
</div>
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">names</span>(mod<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">variables</span>()<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>transformed_parameters)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>character(0)</code></pre>
</div>
</div>
<p>元となったファイルのパスも <code>stan_file()</code>, <code>exe_file()</code> で確認できる．</p>
</section>
<section id="stan-コードの操作" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="stan-コードの操作"><span class="header-section-number">2.3</span> Stan コードの操作</h3>
<p><code>write_stan_file()</code> 関数は Stan コードをファイルに書き出すことができる：</p>
<div class="sourceCode" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">write_stan_file</span>(</span>
<span id="cb40-2">  code,</span>
<span id="cb40-3">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">dir =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">getOption</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cmdstanr_write_stan_file_dir"</span>, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">tempdir</span>()),</span>
<span id="cb40-4">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">basename =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>,</span>
<span id="cb40-5">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">force_overwrite =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>,</span>
<span id="cb40-6">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">hash_salt =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span></span>
<span id="cb40-7">)</span></code></pre></div>
<p>グローバル環境変数が設定されていない限り，<code>tempdir()</code> で一時ファイルが作成される．これは R セッションの終了とともに削除される．</p>
<div class="sourceCode" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1">stan_file_variables <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">write_stan_file</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb41-2"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">data {</span></span>
<span id="cb41-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  int&lt;lower=1&gt; J;</span></span>
<span id="cb41-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  vector&lt;lower=0&gt;[J] sigma;</span></span>
<span id="cb41-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  vector[J] y;</span></span>
<span id="cb41-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb41-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">parameters {</span></span>
<span id="cb41-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  real mu;</span></span>
<span id="cb41-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  real&lt;lower=0&gt; tau;</span></span>
<span id="cb41-10"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  vector[J] theta_raw;</span></span>
<span id="cb41-11"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb41-12"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">transformed parameters {</span></span>
<span id="cb41-13"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  vector[J] theta = mu + tau * theta_raw;</span></span>
<span id="cb41-14"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb41-15"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">model {</span></span>
<span id="cb41-16"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  target += normal_lpdf(tau | 0, 10);</span></span>
<span id="cb41-17"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  target += normal_lpdf(mu | 0, 10);</span></span>
<span id="cb41-18"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  target += normal_lpdf(theta_raw | 0, 1);</span></span>
<span id="cb41-19"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  target += normal_lpdf(y | theta, sigma);</span></span>
<span id="cb41-20"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb41-21"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb41-22">mod_v <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cmdstan_model</span>(stan_file_variables)</span>
<span id="cb41-23">variables <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> mod_v<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">variables</span>()</span></code></pre></div>
</section>
<section id="サンプリング" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="サンプリング"><span class="header-section-number">2.4</span> サンプリング</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1">data_list <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">N =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb42-2"></span>
<span id="cb42-3">fit <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> mod<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sample</span>(</span>
<span id="cb42-4">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> data_list,</span>
<span id="cb42-5">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">seed =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">123</span>,</span>
<span id="cb42-6">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">chains =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,</span>
<span id="cb42-7">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">parallel_chains =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,</span>
<span id="cb42-8">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">refresh =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># print update every 1000 iters</span></span>
<span id="cb42-9">)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running MCMC with 4 parallel chains...

Chain 1 Iteration:    1 / 2000 [  0%]  (Warmup) 
Chain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) 
Chain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) 
Chain 1 Iteration: 2000 / 2000 [100%]  (Sampling) 
Chain 2 Iteration:    1 / 2000 [  0%]  (Warmup) 
Chain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) 
Chain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) 
Chain 2 Iteration: 2000 / 2000 [100%]  (Sampling) 
Chain 3 Iteration:    1 / 2000 [  0%]  (Warmup) 
Chain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) 
Chain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) 
Chain 3 Iteration: 2000 / 2000 [100%]  (Sampling) 
Chain 4 Iteration:    1 / 2000 [  0%]  (Warmup) 
Chain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) 
Chain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) 
Chain 4 Iteration: 2000 / 2000 [100%]  (Sampling) 
Chain 1 finished in 0.0 seconds.
Chain 2 finished in 0.0 seconds.
Chain 3 finished in 0.0 seconds.
Chain 4 finished in 0.0 seconds.

All 4 chains finished successfully.
Mean chain execution time: 0.0 seconds.
Total execution time: 0.2 seconds.</code></pre>
</div>
</div>
<p>返り値 <code>fit</code> は <code>CmdStanMCMC</code> オブジェクトであり，<code>summary()</code> などのメソッドが使用可能である．</p>
<p><code>summary()</code> メソッドは，<code>posterior</code> パッケージのメソッド <code>summarise_draws()</code> を自動で使うようになっている．</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1">fit<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summary</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 10
  variable   mean median    sd   mad      q5    q95  rhat ess_bulk ess_tail
  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
1 lp__     -7.30  -7.00  0.797 0.345 -8.86   -6.75   1.00    1923.    2017.
2 theta     0.257  0.241 0.124 0.127  0.0800  0.485  1.00    1232.    1477.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1">fit<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summary</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">variables =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"theta"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lp__"</span>), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mean"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sd"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 3
  variable   mean    sd
  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;
1 theta     0.257 0.124
2 lp__     -7.30  0.797</code></pre>
</div>
</div>
<p>同様にして <code>draws()</code> メソッドで <code>bayesplot</code> パッケージが呼び出される．</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mcmc_hist</span>(fit<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">draws</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"theta"</span>))</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/R/Stan2_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
</section>
</section>



<div id="quarto-appendix" class="default"><section id="文献紹介" class="level2 appendix" data-number="3"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3</span> 文献紹介</h2><div class="quarto-appendix-contents">




</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>実際には，最初に <code>CmdStanModel</code> オブジェクトを生成し，<code>compile()</code> メソッドを呼び出している．これが <code>compile = TRUE</code> フラッグの存在意義である．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Bayesian</category>
  <category>Computation</category>
  <category>Stan</category>
  <category>R</category>
  <guid>https://162348.github.io/posts/2024/R/Stan2.html</guid>
  <pubDate>Wed, 18 Sep 2024 15:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/R/Files/adastan.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>拡散過程の時間反転</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Samplers/DD1.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="命題" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="命題"><span class="header-section-number">1</span> 命題</h2>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="[命題 @Haussmann-Pardoux1986]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="citation" data-cites="Haussmann-Pardoux1986">(命題 Haussmann and Pardoux, 1986)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Brown 運動 <img src="https://latex.codecogs.com/png.latex?%5C%7BB_t%5C%7D%5Csubset%5Cmathcal%7BL%7D(%5COmega;%5Cmathbb%7BR%7D%5Ed)"> と可測関数 <img src="https://latex.codecogs.com/png.latex?b:%5B0,1%5D%5Ctimes%5Cmathbb%7BR%7D%5Ed%5Cto%5Cmathbb%7BR%7D%5Ed,%5Csigma:%5B0,1%5D%5Ctimes%5Cmathbb%7BR%7D%5Ed%5Cto%20M_d(%5Cmathbb%7BR%7D)"> に関して， <img src="https://latex.codecogs.com/png.latex?%0AdX_t=b_t(X_t)%5C,dt+%5Csigma_t(X_t)%5C,dB_t,%5Cqquad%20t%5Cin%5B0,1%5D,%0A"> を Markov 過程とする．さらに次の３条件を仮定する：</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?b_t,%5Csigma_t"> は <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5Ed"> 上局所 Lipschitz 連続で，線型増大条件を満たす： <img src="https://latex.codecogs.com/png.latex?%0A%20%20%5Clvert%20b_t(x)%5Crvert+%5Clvert%5Csigma_t(x)%5Crvert%5Cle%20K(1+%5Clvert%20x%5Crvert),%5Cqquad%20x%5Cin%5Cmathbb%7BR%7D%5Ed,K%3E0.%0A%20%20"></li>
<li><img src="https://latex.codecogs.com/png.latex?X_0"> は密度 <img src="https://latex.codecogs.com/png.latex?p_0"> をもち，ある <img src="https://latex.codecogs.com/png.latex?%5Clambda%3C0"> について次を満たす： <img src="https://latex.codecogs.com/png.latex?%0A%20%20p_0%5Cin%20L%5E2((1+%5Clvert%20x%5Crvert%5E2)%5E%5Clambda%5C,dx).%0A%20%20"></li>
<li><img src="https://latex.codecogs.com/png.latex?a:=%5Csigma%5Csigma%5E%5Ctop"> は一様に正定値である <img src="https://latex.codecogs.com/png.latex?%0A%20%20a_t(x)%5Cge%5Calpha%20I_d%0A%20%20"> であるか，<img src="https://latex.codecogs.com/png.latex?%5Calpha%5E%7Bij%7D_%7Bx_ix_j%7D%5Cin%20L%5E%5Cinfty((0,1)%5Ctimes%5Cmathbb%7BR%7D%5Ed)"> である．</li>
</ul>
<p>このとき，時間反転 <img src="https://latex.codecogs.com/png.latex?%5Coverline%7BX%7D_t:=X_%7B1-t%7D"> の分布は次の SDE の解である： <img src="https://latex.codecogs.com/png.latex?%0Ad%5Coverline%7BX%7D_t=%5Coverline%7Bb%7D_t(%5Coverline%7BX%7D_t)%5C,dt+%5Coverline%7B%5Csigma%7D_t(%5Coverline%7BX%7D_t)%5C,d%5Coverline%7BB%7D_t,%5Cqquad%20t%5Cin%5B0,1%5D.%0A"> ただし，<img src="https://latex.codecogs.com/png.latex?(B_t)"> も Brown 運動で， <img src="https://latex.codecogs.com/png.latex?%0A%5Coverline%7Bb%7D%5Ei_t(x)=-b_%7B1-t%7D%5Ei(x)+%5Csum_%7Bj=1%7D%5Ed%5Cfrac%7B%5Cbiggr(a%5E%7Bij%7D_%7B1-t%7D(x)p_%7B1-t%7D(x)%5Cbiggl)_%7Bx_j%7D%7D%7Bp_%7B1-t%7D(x)%7D,%0A"> <img src="https://latex.codecogs.com/png.latex?%0A%5Coverline%7Ba%7D%5E%7Bij%7D_t(x)=a%5E%7Bij%7D_%7B1-t%7D(x),%5Cqquad%5Coverline%7B%5Csigma%7D%5E%7Bij%7D_t(x)=%5Csigma%5E%7Bij%7D_%7B1-t%7D(x).%0A"></p>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="系">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
系
</div>
</div>
<div class="callout-body-container callout-body">
<p>前の命題の３条件を満たす，ドリフト係数 <img src="https://latex.codecogs.com/png.latex?%5Csigma"> が <img src="https://latex.codecogs.com/png.latex?x%5Cin%5Cmathbb%7BR%7D%5Ed"> に依らない SDE <img src="https://latex.codecogs.com/png.latex?%0AdX_t=b_t(X_t)%5C,dt+%5Csigma_t%5C,dB_t,%5Cqquad%20t%5Cin%5B0,1%5D,%0A"> を考える．この <img src="https://latex.codecogs.com/png.latex?(X)_%7Bt%5Cin%5B0,1%5D%7D"> の時間反転は，<img src="https://latex.codecogs.com/png.latex?a_t:=%5Csigma_t%5Csigma%5E%5Ctop_t"> に関して <img src="https://latex.codecogs.com/png.latex?%0Ad%5Coverline%7BX%7D_t=%5Cbiggr(-b_%7B1-t%7D(%5Coverline%7BX%7D_t)+a_%7B1-t%7D%5Cnabla_x%5Clog%20p_%7B1-t%7D(%5Coverline%7BX%7D_t)%5Cbiggl)%5C,dt+%5Csigma_%7B1-t%7D%5C,d%5Coverline%7BB%7D_t,%5Cqquad%5Coverline%7BX%7D_0=X_1,%0A"> と分布同等になる．</p>
</div>
</div>
<p>SGM <span class="citation" data-cites="Song-Ermon2019">(Song and Ermon, 2019)</span>, <span class="citation" data-cites="Song+2021ICLR">(Song et al., 2021)</span> は， <span id="eq-OU"><img src="https://latex.codecogs.com/png.latex?%0Ab_t(x)=-x,%5Cqquad%5Csigma_t=%5Csqrt%7B2%7D,%0A%5Ctag%7B1%7D"></span> と設定し，<img src="https://latex.codecogs.com/png.latex?(X_t)"> を OU 過程とした．これは <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BN%7D_d(0,I_d)"> に全変動距離・Wasserstein 距離・<img src="https://latex.codecogs.com/png.latex?%5Cchi%5E2">-距離で<a href="../../../posts/2024/Process/Langevin.html">指数収束する</a>．</p>
<p>従って，この時間反転を <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BN%7D_d(0,I_d)"> からスタートさせることで，データ分布 <img src="https://latex.codecogs.com/png.latex?p_0"> からのサンプリングが可能になる．</p>
<p>しかしこのアイデアを実行するためには，スコア <img src="https://latex.codecogs.com/png.latex?%5Cnabla_x%5Clog%20p_%7B1-t%7D(X_t)"> の項を何らかの方法で推定する方法が必要である．</p>
</section>
<section id="スコアマッチングへの応用" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="スコアマッチングへの応用"><span class="header-section-number">2</span> スコアマッチングへの応用</h2>
<section id="はじめに" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="はじめに"><span class="header-section-number">2.1</span> はじめに</h3>
<p><a href="../../../posts/2024/Samplers/EBM.html#sec-DSM">Denoising Score Matching</a> <span class="citation" data-cites="Vincent2011">(Vincent, 2011)</span> を初めとして，<a href="../../../posts/2024/Samplers/NF3.html#sec-GFM">Generalized Flow Matching</a> <span class="citation" data-cites="Isobe+2024">(Isobe et al., 2024)</span> や Functional Flow Matching <span class="citation" data-cites="Kerrigan+2024">(Kerrigan et al., 2024)</span> は，次のような目的関数を持っている： <span id="eq-DSM-loss"><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D(%5Ctheta)=%5Coperatorname%7BE%7D%5Cbiggl%5B%5Cbiggl%7Cs_%5Ctheta(%5Cwidetilde%7BX%7D)-%5Cfrac%7BX-%5Cwidetilde%7BX%7D%7D%7B%5Csigma%5E2%7D%5Cbiggr%7C%5E2%5Cbiggr%5D,%5Cqquad%20X%5Csim%20p_0,%5Cwidetilde%7BX%7D%5Csim%20p_0*%5Cmathrm%7BN%7D(0,%5Csigma%5E2I_d).%0A%5Ctag%7B2%7D"></span></p>
<p>これはデータ <img src="https://latex.codecogs.com/png.latex?X%5Csim%20p_0"> と，それに独立な Gauss ノイズを印加したもの <img src="https://latex.codecogs.com/png.latex?%5Cwidetilde%7BX%7D"> との差分を目標としてスコアネットワーク <img src="https://latex.codecogs.com/png.latex?s_%5Ctheta"> を学習している．</p>
</section>
<section id="デノイジング過程としての見方" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="デノイジング過程としての見方"><span class="header-section-number">2.2</span> デノイジング過程としての見方</h3>
<p>データにノイズを印加する過程は，<img src="https://latex.codecogs.com/png.latex?b_t=0,%5Csigma_t=I_d"> とした SDE <img src="https://latex.codecogs.com/png.latex?%0AdX_t=dB_t,%5Cqquad%20t%5Cin%5B0,1%5D,X_0%5Csim%20p_0,%0A"> で <img src="https://latex.codecogs.com/png.latex?t=0"> から <img src="https://latex.codecogs.com/png.latex?t=%5Csigma%5E2"> まで輸送することにあたる： <img src="https://latex.codecogs.com/png.latex?%0AX_%5Csigma%5E2=X_0+(B_%7B%5Csigma%5E2%7D-B_0)%5Coverset%7B%5Ctext%7Bd%7D%7D%7B=%7D%5Cwidetilde%7BX%7D.%0A"> この時間反転は <img src="https://latex.codecogs.com/png.latex?%0Ad%5Coverline%7BX%7D_t=%5Cnabla_x%5Clog%20p_%7B1-t%7D(%5Coverline%7BX%7D_t)%5C,dt+d%5Coverline%7BB%7D_t,%5Cqquad%5Coverline%7BX%7D_0=X_1,%0A"> と分布同等になる．</p>
<p>この時間反転過程 <img src="https://latex.codecogs.com/png.latex?(%5Coverline%7BX%7D_t)"> は <img src="https://latex.codecogs.com/png.latex?%5Coverline%7BX%7D_%7B1-%5Csigma%5E2%7D=%5Cwidetilde%7BX%7D"> を <img src="https://latex.codecogs.com/png.latex?%5Coverline%7BX%7D_1=X"> まで運ぶが，この際に <img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cll1"> ならば次の関係を示唆する： <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%20%20%20%20X&amp;%5Coverset%7B%5Ctext%7Bd%7D%7D%7B=%7D%5Cwidetilde%7BX%7D+%5Cint%5E1_%7B1-%5Csigma%5E2%7D%5Cnabla_x%5Clog%20p_%7B1-t%7D(%5Coverline%7BX%7D_t)%5C,dt+%5Cepsilon%5C%5C%0A%20%20%20%20&amp;%5Capprox%5Cwidetilde%7BX%7D+%5Csigma%5E2%5Cnabla_x%5Clog%20p_0(X)+%5Cepsilon,%5Cqquad%5Cepsilon%5Csim%5Cmathrm%7BN%7D(0,%5Csigma%5E2I_d).%0A%5Cend%7Balign*%7D"> <img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cto0"> の極限で次の等号が成り立つ： <img src="https://latex.codecogs.com/png.latex?%0A%5Clim_%7B%5Csigma%5Cto0%7D%5Cfrac%7BX-%5Cwidetilde%7BX%7D%7D%7B%5Csigma%5E2%7D%5Coverset%7B%5Ctext%7Bd%7D%7D%7B=%7D%5Cnabla_x%5Clog%20p_0(X).%0A"></p>
</section>
<section id="sec-Tweedie-formula" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="sec-Tweedie-formula"><span class="header-section-number">2.3</span> Tweedie の式</h3>
<p>実は同様の式は，<img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cto0"> の極限で漸近的にではなく正の <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2%3E0"> に関しても，次の意味で成り立つ：</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?X%5Csim%20p_0,%5Cwidetilde%7BX%7D%5Csim%20p_0*%5Cmathrm%7BN%7D(0,%5Csigma%5E2I_d)=:%5Cwidetilde%7Bp%7D_0"> とする．このとき，次が成り立つ： <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D%5BX%7C%5Cwidetilde%7BX%7D=%5Cwidetilde%7Bx%7D%5D=%5Cwidetilde%7Bx%7D+%5Csigma%5E2%5Cnabla_%7B%5Cwidetilde%7Bx%7D%7D%5Clog%20%5Cwidetilde%7Bp%7D_0(%5Cwidetilde%7Bx%7D).%0A"></p>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled" title="証明">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
証明
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>一般に，<img src="https://latex.codecogs.com/png.latex?%5Cphi_%5Csigma"> を <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BN%7D_d(0,%5Csigma%5E2I_d)"> の密度関数とすると， <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D%5BX%7C%5Cwidetilde%7BX%7D=%5Cwidetilde%7Bx%7D%5D=%5Cint_%7B%5Cmathbb%7BR%7D%5Ed%7Dxp_0(x)%5Cphi_%5Csigma(%5Cwidetilde%7Bx%7D-x)%5C,dx%0A"> より， <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D%5BX%7C%5Cwidetilde%7BX%7D=%5Cwidetilde%7Bx%7D%5D-%5Cwidetilde%7Bx%7D=%5Cint_%7B%5Cmathbb%7BR%7D%5Ed%7D(x-%5Cwidetilde%7Bx%7D)p_0(x)%5Cphi_%5Csigma(%5Cwidetilde%7Bx%7D-x)%5C,dx.%0A"></p>
<p>一方で， <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%20%20%20%20&amp;%5Cqquad%5Cnabla_%7B%5Cwidetilde%7Bx%7D%7D%5Clog%5Cleft(%5Cint_%7B%5Cmathbb%7BR%7D%5Ed%7Dp_0(x)%5Cphi_%5Csigma(%5Cwidetilde%7Bx%7D-x)%5C,dx%5Cright)%5C%5C%0A%20%20%20%20&amp;=%5Cfrac%7B%5Cint_%7B%5Cmathbb%7BR%7D%5Ed%7Dp_0(x)%5Cnabla_%7B%5Cwidetilde%7Bx%7D%7D%5Cphi_%5Csigma(%5Cwidetilde%7Bx%7D-x)%5C,dx%7D%7B%5Cint_%7B%5Cmathbb%7BR%7D%5Ed%7Dp_0(x)%5Cphi_%5Csigma(%5Cwidetilde%7Bx%7D-x)%5C,dx%7D%5C%5C%0A%20%20%20%20&amp;=%5Cint_%7B%5Cmathbb%7BR%7D%5Ed%7Dp_0(x)%5Cphi_%5Csigma(%5Cwidetilde%7Bx%7D-x)%5Cfrac%7Bx-%5Cwidetilde%7Bx%7D%7D%7B%5Csigma%5E2%7D%5C,dx%5C%5C%0A%20%20%20%20&amp;=%5Cfrac%7B%5Coperatorname%7BE%7D%5BX%7C%5Cwidetilde%7BX%7D=%5Cwidetilde%7Bx%7D%5D-%5Cwidetilde%7Bx%7D%7D%7B%5Csigma%5E2%7D.%0A%5Cend%7Balign*%7D"></p>
</div>
</div>
</div>
<p>すなわち，<img src="https://latex.codecogs.com/png.latex?%5Cwidetilde%7BX%7D"> から <img src="https://latex.codecogs.com/png.latex?X"> を不偏推定しようとすることで，スコア <img src="https://latex.codecogs.com/png.latex?%5Cnabla_%7B%5Cwidetilde%7Bx%7D%7D%5Clog%5Cwidetilde%7Bp%7D(%5Cwidetilde%7Bx%7D)"> を学習することができるのである．</p>
<p>ただし，学習されるスコアは，データ分布 <img src="https://latex.codecogs.com/png.latex?p_0"> のものではなく，ノイズ分布 <img src="https://latex.codecogs.com/png.latex?%5Cwidetilde%7Bp%7D_0"> のものであることに注意．</p>
<p>これが，デノイジングスコアマッチングの目的関数 (2) の背後にある動機付けである．</p>
</section>
</section>
<section id="確率的局所化" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="確率的局所化"><span class="header-section-number">3</span> 確率的局所化</h2>
<section id="ou-過程による-sgm" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="ou-過程による-sgm"><span class="header-section-number">3.1</span> OU 過程による SGM</h3>
<p>OU 過程の例 (1) に戻ろう．OU 過程 <img src="https://latex.codecogs.com/png.latex?%0AdX_t=-X_t%5C,dt+%5Csqrt%7B2%7D%5C,dB_t%0A"> の時間反転は次と分布同等である： <span id="eq-OU-reverse"><img src="https://latex.codecogs.com/png.latex?%0Ad%5Coverline%7BX%7D_t=%5Cbiggr(%5Coverline%7BX%7D_t+2%5Cnabla_x%5Clog%20p_%7B1-t%7D(%5Coverline%7BX%7D_t)%5Cbiggl)%5C,dt+%5Csqrt%7B2%7D%5C,d%5Coverline%7BB%7D_t,%5Cqquad%5Coverline%7BX%7D_0=X_1.%0A%5Ctag%7B3%7D"></span></p>
<p>OU 過程 <img src="https://latex.codecogs.com/png.latex?(X_t)"> は <img src="https://latex.codecogs.com/png.latex?%0AX_t%5Coverset%7B%5Ctext%7Bd%7D%7D%7B=%7De%5E%7B-t%7DX_0+%5Csqrt%7B1-e%5E%7B-2t%7D%7D%5Cepsilon,%5Cqquad%20X_0%5Csim%20p_0,%5Cepsilon%5Csim%5Cmathrm%7BN%7D_d(0,I_d)%0A"> という遷移半群を持っているため，<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D%5BX_t%5D=%5Cmathcal%7BL%7D%5Be%5E%7B-t%7DX_0%5D*%5Cmathrm%7BN%7D_d(0,1-e%5E%7B-2t%7D)"> であることから，Tweedie の式 2.3 より <img src="https://latex.codecogs.com/png.latex?%0A%5Cnabla_x%5Clog%20p_t(x_t)=%5Cfrac%7B%5Coperatorname%7BE%7D%5Be%5E%7B-t%7DX_0%7CX_t=x_t%5D-x_t%7D%7B1-e%5E%7B-2t%7D%7D%0A"> を得る．従ってこのスコアを式 (3) に代入し， <img src="https://latex.codecogs.com/png.latex?%0Am_t(x_t):=%5Coperatorname%7BE%7D%5BX_0%7CtX_0+%5Csqrt%7Bt%7D%5Cepsilon=x_t%5D,%5Cqquad%20X_0%5Csim%20p_0,%5Cepsilon%5Csim%5Cmathrm%7BN%7D_d(0,I_d),%0A"> とおき， <img src="https://latex.codecogs.com/png.latex?%0A%5Ctau(t)=%5Cfrac%7B1%7D%7Be%5E%7B2t%7D-1%7D%0A"> の変数変換を施すと OU 過程の時間反転 (3) は次のように書き直せる： <span id="eq-OU-reverse-2"><img src="https://latex.codecogs.com/png.latex?%0Ad%5Coverline%7BY%7D_%5Ctau=%5Cbiggr(-%5Cfrac%7B1+%5Ctau%7D%7B%5Ctau(1+%5Ctau)%7D%5Coverline%7BY%7D_%5Ctau+%5Cfrac%7B1%7D%7B%5Csqrt%7B%5Ctau(1+%5Ctau)%7D%7Dm_%5Ctau%5Cleft(%5Csqrt%7B%5Ctau(1+%5Ctau)%7D%5Coverline%7BY%7D_%5Ctau%5Cright)%5Cbiggl)%5C,d%5Ctau+%5Cfrac%7B1%7D%7B%5Csqrt%7B%5Ctau(1+%5Ctau)%7D%7D%5C,d%5Coverline%7BB%7D_%5Ctau.%0A%5Ctag%7B4%7D"></span></p>
<p>これが <a href="../../../posts/2024/Samplers/SB1.html">denoising diffusion</a> である．</p>
</section>
<section id="もう一つのサンプリング法" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="もう一つのサンプリング法"><span class="header-section-number">3.2</span> もう一つのサンプリング法</h3>
<p><strong>確率的局所化</strong> (stochastic localization) は初め，<span class="citation" data-cites="Eldan2013">(Eldan, 2013)</span> が高次元空間内の等方的な凸体上での等周不等式を示すために構成した半マルチンゲールが基になっている．</p>
<p>確率的局所化においては，<img src="https://latex.codecogs.com/png.latex?p_0"> からのあるサンプル <img src="https://latex.codecogs.com/png.latex?x_0"> に対して，その <strong>観測過程</strong> <img src="https://latex.codecogs.com/png.latex?(Y_t)"> と呼ばれる <img src="https://latex.codecogs.com/png.latex?x_0"> のノイズ付きの観測を考える．ただし，<img src="https://latex.codecogs.com/png.latex?Y_t"> は時間が進むごとに <img src="https://latex.codecogs.com/png.latex?x_0"> に関する情報量が増えるとする．<sup>1</sup></p>
<p>例えば <img src="https://latex.codecogs.com/png.latex?%0AY_t=tx_0+B_t,%5Cqquad%20t%5Cin%5Cmathbb%7BR%7D_+,%0A"> という場合である．<img src="https://latex.codecogs.com/png.latex?B_t"> というノイズは印加されているが，<img src="https://latex.codecogs.com/png.latex?x_0"> というメッセージの内容がどんどん大きくなるため，Signal-to-noise 比は増大していく．</p>
<p>この場合については，<img src="https://latex.codecogs.com/png.latex?p_0"> が有限な二次の積率を持つならば， <img src="https://latex.codecogs.com/png.latex?%0AdY_%5Ctau=m_%5Ctau(Y_%5Ctau)%5C,d%5Ctau+dB'_%5Ctau%0A"> という SDE の解と分布同等である <span class="citation" data-cites="Liptser-Shiryaev2001-Statistics">(Liptser and Shiryaev, 2001)</span>．</p>
<p>これは式 (4) で与えた OU 過程の時間反転 <img src="https://latex.codecogs.com/png.latex?(%5Coverline%7BY%7D_%5Ctau)"> に関して，<img src="https://latex.codecogs.com/png.latex?Y_%5Ctau=%5Csqrt%7B%5Ctau(1+%5Ctau)%7D%5Coverline%7BY%7D_%5Ctau"> の関係を持つ．</p>
</section>
<section id="確率的局所化-1" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="確率的局所化-1"><span class="header-section-number">3.3</span> 確率的局所化</h3>
<p>実は <img src="https://latex.codecogs.com/png.latex?(Y_t)"> は， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmu_t:=%5Cmathcal%7BL%7D%5BX_0%7CY_t%5D%0A"> として定まる <img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7BP%7D(%5Cmathbb%7BR%7D%5Ed)">-値の確率過程 <img src="https://latex.codecogs.com/png.latex?%5C%7B%5Cmu_t%5C%7D%5Csubset%5Cmathcal%7BL%7D(%5COmega;%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed))"> について，次の性質を持つ： <img src="https://latex.codecogs.com/png.latex?%0A%5Cmu_0=%5Cmathcal%7BL%7D%5BX_0%5D=p_0%5C,d%5Cell_d,%5Cqquad%5Cmu_t%5CRightarrow%5Cdelta_%7Bx_0%7D%5Cqquad%20t%5Cto%5Cinfty,%0A"></p>
<p>実は上述のサンプリング法は，このような <img src="https://latex.codecogs.com/png.latex?p_0%5C,d%5Cell_d"> から <img src="https://latex.codecogs.com/png.latex?%5Cdelta_%7BX_0%7D%5C;(X_0%5Csim%20p_0)"> への確率過程が与えられるごとに構成できる．</p>
<p>実際，最も簡単には，重心 <img src="https://latex.codecogs.com/png.latex?%0AM_t:=%5Cint_%7B%5Cmathbb%7BR%7D%5Ed%7Dx%5C,%5Cmu_t(dx)%0A"> を計算すれば，<img src="https://latex.codecogs.com/png.latex?M_t"> は <img src="https://latex.codecogs.com/png.latex?t%5Cto%5Cinfty"> の極限で <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D%5BX_0%5D"> に収束する．</p>
<p>これが <strong>確率的局所化</strong> である．</p>
<p>確率的局所化に基づいたサンプラーは <span class="citation" data-cites="Alaoui+2022">(Alaoui et al., 2022)</span> により <a href="../../../posts/2024/Nature/StatisticalMechanics1.html#sec-SK-model">Sherrington-Kirkpatrick 模型</a> の Gibbs 分布からのサンプリングに適用され，<span class="citation" data-cites="Montanari-Wu2024">(Montanari and Wu, 2023)</span> でさらにベイズ統計への応用のために拡張されている．</p>
<p>また，最良の雑音除去拡散モデルの収束証明は確率的局所化に基づいた証明によって与えられている <span class="citation" data-cites="Benton+2024">(Benton et al., 2024)</span>．</p>
</section>
</section>
<section id="関連ページ" class="level2 unnumbered unlisted">
<h2 class="unnumbered unlisted anchored" data-anchor-id="関連ページ">関連ページ</h2>
<div id="listing-lst-listing" class="listing quarto-float quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Deep,Process,Sampling" data-listing-date-sort="1707836400000" data-listing-file-modified-sort="1727007848002" data-listing-date-modified-sort="1724338800000" data-listing-reading-time-sort="5" data-listing-word-count-sort="826">
<a href="../../../posts/2024/Samplers/Diffusion.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/DDPM_outputs.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
拡散模型
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル６
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Process,Sampling,P(X)" data-listing-date-sort="1722610800000" data-listing-file-modified-sort="1727007848140" data-listing-date-modified-sort="1724598000000" data-listing-reading-time-sort="3" data-listing-word-count-sort="470">
<a href="../../../posts/2024/Samplers/SB1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://162348.github.io/posts/2024/Samplers/Files/linear/output.gif" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
分布道の学習としての生成モデリング
</h5>
<div class="card-subtitle listing-subtitle">
Denoising Diffusion から Schrödinger Bridge へ
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-03
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Deep,Nature,Sampling" data-listing-date-sort="1711724400000" data-listing-file-modified-sort="1727007848003" data-listing-date-modified-sort="1722438000000" data-listing-reading-time-sort="5" data-listing-word-count-sort="880">
<a href="../../../posts/2024/Samplers/EBM.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/NCL/thumb_checkerboard.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
エネルギーベースモデル
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル５
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-03-30
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>



<div id="quarto-appendix" class="default"><section id="文献紹介" class="level2 appendix" data-number="4"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">4</span> 文献紹介</h2><div class="quarto-appendix-contents">

<p><span class="citation" data-cites="Anderson1982">(Anderson, 1982)</span> では Fokker-Planck 方程式の解に対する条件の言葉で時間反転命題を与えている．また，時間反転も，元の Brown 運動 <img src="https://latex.codecogs.com/png.latex?B_t"> と独立な Brown 運動 <img src="https://latex.codecogs.com/png.latex?%5Coverline%7BB%7D_t"> に関する SDE ではなく，その時間反転 <img src="https://latex.codecogs.com/png.latex?%5Cwidetilde%7BB%7D_t:=B_%7B1-t%7D"> に関する SDE で与えている．</p>
<p><a href="https://alexxthiery.github.io/posts/reverse_and_tweedie/reverse_and_tweedie.html#ref-efron2011tweedie">Aleandre Thiéry のブログ記事</a> や <a href="https://drive.google.com/file/d/1ipWPVNBpFy5GlQqXtSbbhB0gAJUld-yd/view">鈴木大慈氏のスライド</a>，<a href="https://metaphor.ethz.ch/x/2024/fs/401-4634-24L/">Montanari の講義資料</a> も参照．</p>
<p>Tweedie の式は <span class="citation" data-cites="Robbins1956">(Robbins, 1956)</span> によって命名されている．<span class="citation" data-cites="Efron2011">(Efron, 2011)</span> では選択バイアスが存在する状況における経験ベイズ法に応用している．</p>
<p>確率的局所化については <span class="citation" data-cites="Montanari2023">(Montanari, 2023)</span> を参考にした．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Alaoui+2022" class="csl-entry">
Alaoui, A. E., Montanari, A., and Sellke, M. (2022). <a href="https://doi.org/10.1109/FOCS54457.2022.00038">Sampling from the sherrington-kirkpatrick gibbs measure via algorithmic stochastic localization</a>. In <em>2022 IEEE 63rd annual symposium on foundations of computer science (FOCS)</em>, pages 323–334.
</div>
<div id="ref-Anderson1982" class="csl-entry">
Anderson, B. D. O. (1982). <a href="https://doi.org/10.1016/0304-4149(82)90051-5">Reverse-time diffusion equation models</a>. <em>Stochastic Processes and Their Applications</em>, <em>12</em>(3), 313–326.
</div>
<div id="ref-Benton+2024" class="csl-entry">
Benton, J., Bortoli, V. D., Doucet, A., and Deligiannidis, G. (2024). <a href="https://arxiv.org/abs/2308.03686">Nearly <img src="https://latex.codecogs.com/png.latex?d">-linear convergence bounds for diffusion models via stochastic localization</a>.
</div>
<div id="ref-Efron2011" class="csl-entry">
Efron, B. (2011). <a href="http://www.jstor.org/stable/23239562">Tweedie’s formula and selection bias</a>. <em>Journal of the American Statistical Association</em>, <em>106</em>(496), 1602–1614.
</div>
<div id="ref-Eldan2013" class="csl-entry">
Eldan, R. (2013). <a href="https://doi.org/10.1007/s00039-013-0214-y"><span class="nocase">Thin Shell Implies Spectral Gap Up to Polylog via a Stochastic Localization Scheme</span></a>. <em>Geometric and Functional Analysis</em>, <em>23</em>(2), 532–569.
</div>
<div id="ref-Haussmann-Pardoux1986" class="csl-entry">
Haussmann, U. G., and Pardoux, E. (1986). <a href="https://doi.org/10.1214/aop/1176992362"><span class="nocase">Time Reversal of Diffusions</span></a>. <em>The Annals of Probability</em>, <em>14</em>(4), 1188–1205.
</div>
<div id="ref-Isobe+2024" class="csl-entry">
Isobe, N., Koyama, M., Zhang, J., Hayashi, K., and Fukumizu, K. (2024). <a href="https://arxiv.org/abs/2402.18839">Extended flow matching: A method of conditional generation with generalized continuity equation</a>.
</div>
<div id="ref-Kerrigan+2024" class="csl-entry">
Kerrigan, G., Migliorini, G., and Smyth, P. (2024). <a href="https://proceedings.mlr.press/v238/kerrigan24a.html">Functional flow matching</a>. In S. Dasgupta, S. Mandt, and Y. Li, editors, <em>Proceedings of the 27th international conference on artificial intelligence and statistics</em>,Vol. 238, pages 3934–3942. PMLR.
</div>
<div id="ref-Liptser-Shiryaev2001-Statistics" class="csl-entry">
Liptser, R. S., and Shiryaev, A. N. (2001). <em>Statistics of random processes i: General theory</em>. Original Russian edition published by Nauka, Moscow, 1974; Springer Berlin, Heidelberg.
</div>
<div id="ref-Montanari2023" class="csl-entry">
Montanari, A. (2023). <a href="https://arxiv.org/abs/2305.10690">Sampling, diffusions, and stochastic localization</a>.
</div>
<div id="ref-Montanari-Wu2024" class="csl-entry">
Montanari, A., and Wu, Y. (2023). <a href="https://arxiv.org/abs/2304.11449">Posterior sampling from the spiked models via diffusion processes</a>.
</div>
<div id="ref-Robbins1956" class="csl-entry">
Robbins, H. (1956). <a href="https://projecteuclid.org/ebooks/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-Third-Berkeley-Symposium-on-Mathematical-Statistics-and-Probability/chapter/An-Empirical-Bayes-Approach-to-Statistics/bsmsp/1200512992"><span class="nocase">An Empirical Bayes Approach to Statistics</span></a>. In <em>Proceedings of the third berkeley symposium on mathematical statistics and probability</em>,Vol. 1, pages 157–163.
</div>
<div id="ref-Song-Ermon2019" class="csl-entry">
Song, Y., and Ermon, S. (2019). <a href="https://proceedings.neurips.cc/paper_files/paper/2019/file/3001ef257407d5a371a96dcd947c7d93-Paper.pdf"><span class="nocase">Generative Modeling by Estimating Gradients of the Data Distribution</span></a>. In H. Wallach, H. Larochelle, A. Beygelzimer, F. dAlché-Buc, E. Fox, and R. Garnett, editors, <em>Advances in neural information processing systems</em>,Vol. 32. Curran Associates, Inc.
</div>
<div id="ref-Song+2021ICLR" class="csl-entry">
Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B. (2021). <a href="https://openreview.net/forum?id=PxTIG12RRHS"><span class="nocase">Score-Based Generative Modeling through Stochastic Differential Equations</span></a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Vincent2011" class="csl-entry">
Vincent, P. (2011). <a href="https://direct.mit.edu/neco/article/23/7/1661/7677/A-Connection-Between-Score-Matching-and-Denoising">A connection between score matching and denoising autoencoders</a>. <em>Neural Computation</em>, <em>23</em>(7), 1661–1674.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>例えば，<img src="https://latex.codecogs.com/png.latex?x_*,Y_%7Bt_2%7D,Y_%7Bt_1%7D"> が長さ３の Markov 連鎖をなす，などの意味で．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Process</category>
  <category>Sampling</category>
  <guid>https://162348.github.io/posts/2024/Samplers/DD1.html</guid>
  <pubDate>Sun, 25 Aug 2024 15:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Samplers/Files/DSM.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>Skilling-Hutchinson の跡推定量</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Probability/Trace.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="命題" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="命題"><span class="header-section-number">1</span> 命題</h2>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="[@Skilling1989]-[@Hutchinson1990]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="citation" data-cites="Skilling1989">(Skilling, 1989)</span>-<span class="citation" data-cites="Hutchinson1990">(Hutchinson, 1990)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p>任意の正方行列 <img src="https://latex.codecogs.com/png.latex?A%5Cin%20M_n(%5Cmathbb%7BR%7D)"> と，<img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BV%7D%5BX%5D=I_n"> を満たす確率ベクトル <img src="https://latex.codecogs.com/png.latex?X%5Cin%5Cmathcal%7BL%7D(%5COmega;%5Cmathbb%7BR%7D%5En)"> について，</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BTr%7D(A)=%5Coperatorname%7BE%7D%5BX%5E%5Ctop%20AX%5D.%0A"></p>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled" title="証明">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
証明
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?%0AX%5E%5Ctop%20AX=%5Coperatorname%7BTr%7D(AXX%5E%5Ctop)%0A"> に注意する．これは，一般に <img src="https://latex.codecogs.com/png.latex?x,y%5Cin%5Cmathbb%7BR%7D%5En"> に対して <img src="https://latex.codecogs.com/png.latex?%0Ayx%5E%5Ctop=%5Cbegin%7Bpmatrix%7Dy_1%5C%5C%5Cvdots%5C%5Cy_n%5Cend%7Bpmatrix%7D(x_1%5C;%5Ccdots%5C;x_n)=%5Cbegin%7Bpmatrix%7Dy_1x_1&amp;%5Ccdots&amp;y_1x_n%5C%5C%5Cvdots&amp;%5Cddots&amp;%5Cvdots%5C%5Cy_nx_1&amp;%5Ccdots&amp;y_nx_n%5Cend%7Bpmatrix%7D%0A"> <img src="https://latex.codecogs.com/png.latex?%0A%5Ctherefore%5Cqquad%5Coperatorname%7BTr%7D(yx%5E%5Ctop)=x%5E%5Ctop%20y%0A"> が成り立つためである．</p>
<p>よって，次のように計算できる：</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%20%20%20%20%5Coperatorname%7BE%7D%5BX%5E%5Ctop%20AX%5D&amp;=%5Coperatorname%7BE%7D%5B%5Coperatorname%7BTr%7D(AXX%5E%5Ctop)%5D%5C%5C%0A%20%20%20%20&amp;=%5Coperatorname%7BTr%7D(%5Coperatorname%7BE%7D%5BAXX%5E%5Ctop%5D)%5C%5C%0A%20%20%20%20&amp;=%5Coperatorname%7BTr%7D(A%5Coperatorname%7BE%7D%5BXX%5E%5Ctop%5D)=%5Coperatorname%7BTr%7D(A).%0A%5Cend%7Balign*%7D"></p>
</div>
</div>
</div>
<p><span class="citation" data-cites="Hutchinson1990">(Hutchinson, 1990)</span> では <img src="https://latex.codecogs.com/png.latex?A"> を対称行列に，<img src="https://latex.codecogs.com/png.latex?X"> を中心化された確率変数に限って示されている．</p>
<p><span class="citation" data-cites="Skilling1989">(Skilling, 1989)</span> では <span class="citation" data-cites="Hutchinson1990">(Hutchinson, 1990)</span> のように命題の形では提示していないが，同様の推定量を提案しており，これと一般化跡 (generalized trace) と Chebyshev 多項式の議論を通じて，<img src="https://latex.codecogs.com/png.latex?A"> のスペクトルのベイズ推定を議論している．</p>
</section>
<section id="推定量の性質" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="推定量の性質"><span class="header-section-number">2</span> 推定量の性質</h2>
<p>実用上，<img src="https://latex.codecogs.com/png.latex?X"> の分布は標準 Gauss や Rademacher 分布などが用いられる．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題（推定量の分散）">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題（推定量の分散）
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?A%5Cin%20S_n(%5Cmathbb%7BR%7D)"> を対称行列とする．</p>
<ol type="1">
<li><p><img src="https://latex.codecogs.com/png.latex?X%5Csim%5Cmathrm%7BN%7D(0,I_n)"> のとき， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7BV%7D%5BX%5E%5Ctop%20AX%5D=2%5Coperatorname%7BTr%7D(A%5E2)=2%5C%7CA%5C%7C%5E2_%5Cmathrm%7BHS%7D.%0A"></p></li>
<li><p><img src="https://latex.codecogs.com/png.latex?X%5Csim%5Cmathrm%7BRad%7D%5E%7B%5Cotimes%20n%7D"> のとき， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7BV%7D%5BX%5E%5Ctop%20AX%5D=2%5Csum_%7Bi%5Cne%20j%7Da_%7Bij%7D%5E2.%0A"></p></li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled" title="証明^[[@Hutchinson1990 p.437], [@Avron-Toledo2011 補題9], [@Adams+2018 命題4.2] も参照．]">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
証明<sup>1</sup>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?A%5Cin%20S_n(%5Cmathbb%7BR%7D)"> が正定値対称であるとき，ある直交行列 <img src="https://latex.codecogs.com/png.latex?U%5Cin%20O_n(%5Cmathbb%7BR%7D)"> と対角行列 <img src="https://latex.codecogs.com/png.latex?%5CLambda=%5Cmathrm%7Bdiag%7D(%5Clambda_1,%5Cdots,%5Clambda_n)"> が存在して， <img src="https://latex.codecogs.com/png.latex?%0AA=U%5CLambda%20U%5E%5Ctop.%0A"> <img src="https://latex.codecogs.com/png.latex?Y:=U%5E%5Ctop%20X"> と定めるとやはり <img src="https://latex.codecogs.com/png.latex?Y%5Csim%5Cmathrm%7BN%7D(0,I_n)"> であり， <img src="https://latex.codecogs.com/png.latex?%0AX%5E%5Ctop%20AX=X%5E%5Ctop%20U%5CLambda%20U%5E%5Ctop%20X=Y%5E%5Ctop%5CLambda%20Y,%0A"> <img src="https://latex.codecogs.com/png.latex?%0A%5Ctherefore%5Cqquad%5Cmathrm%7BV%7D%5BX%5E%5Ctop%20AX%5D=2%5Csum_%7Bi=1%7D%5En%5Clambda_i%5E2=2%5Coperatorname%7BTr%7D(%5CLambda%5E2)=2%5Coperatorname%7BTr%7D(A%5E2).%0A"></li>
<li>一般の <img src="https://latex.codecogs.com/png.latex?X%5Cin%5Cmathcal%7BL%7D(%5COmega;%5Cmathbb%7BR%7D%5En)"> に関して， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7BV%7D%5BX%5E%5Ctop%20AX%5D=%5Csum_%7Bi,j,k,l=1%7D%5Ena_%7Bij%7Da_%7Bkl%7D%5Cbiggr(%5Coperatorname%7BE%7D%5BX_iX_jX_kX_l%5D-%5Coperatorname%7BE%7D%5BX_iX_j%5D%5Coperatorname%7BE%7D%5BX_kX_l%5D%5Cbiggl).%0A"></li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="系">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
系
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?A"> が対称行列で <img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7BE%7D%5BX%5D=0"> であるとき，<img src="https://latex.codecogs.com/png.latex?X"> は Rademacher とした場合が最小分散不偏推定量を定める <span class="citation" data-cites="Hutchinson1990">(Hutchinson, 1990, p. 命題1)</span>．</p>
</div>
</div>
</section>
<section id="応用" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="応用"><span class="header-section-number">3</span> 応用</h2>
<div id="listing-lst-listing" class="listing quarto-float quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Deep,Sampling" data-listing-date-sort="1707836400000" data-listing-file-modified-sort="1727007848134" data-listing-date-modified-sort="1723993200000" data-listing-reading-time-sort="3" data-listing-word-count-sort="450">
<a href="../../../posts/2024/Samplers/NF.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_result.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
正規化流
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル４
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Deep,Sampling,P(X)" data-listing-date-sort="1707836400000" data-listing-file-modified-sort="1727007848139" data-listing-date-modified-sort="1724770800000" data-listing-reading-time-sort="4" data-listing-word-count-sort="794">
<a href="../../../posts/2024/Samplers/NF1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/linear/output.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ニューラル常微分方程式
</h5>
<div class="card-subtitle listing-subtitle">
シミュレーションなしの拡散モデルとしての連続正規化流
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Deep,Nature,Sampling" data-listing-date-sort="1711724400000" data-listing-file-modified-sort="1727007848003" data-listing-date-modified-sort="1722438000000" data-listing-reading-time-sort="5" data-listing-word-count-sort="880">
<a href="../../../posts/2024/Samplers/EBM.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/NCL/thumb_checkerboard.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
エネルギーベースモデル
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル５
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-03-30
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
<ul>
<li><a href="../../../posts/2024/Samplers/NF.html#sec-Hutchinson">残差フロー (residual flow)</a> では Jacobian の推定が焦点になる．これに Skilling-Hutchinson の跡推定量を用いることができる．</li>
<li><a href="../../../posts/2024/Samplers/NF1.html">Neural ODE</a> において，Jacobian の跡 <img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7BTr%7D(J_%7BF_t%7D(x_t))"> の計算は Skilling-Hutchinson の跡推定量を用いれば <img src="https://latex.codecogs.com/png.latex?O(d)"> で済む <span class="citation" data-cites="Grathwohl+2019">(Grathwohl et al., 2019)</span>．</li>
<li><a href="../../../posts/2024/Samplers/EBM.html#sec-SSM">Sliced Score Matching</a> の目的関数は，Skilling-Hutchinson の跡推定量により Jacobian <img src="https://latex.codecogs.com/png.latex?Ds_%5Ctheta"> を推定したスコアマッチングと解釈できる．</li>
</ul>
</section>



<div id="quarto-appendix" class="default"><section id="文献紹介" class="level2 appendix" data-number="4"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">4</span> 文献紹介</h2><div class="quarto-appendix-contents">

<!-- [@Grathwohl+2019] も参考にした． -->
<p><span class="citation" data-cites="Adams+2018">(Adams et al., 2018)</span> では <span class="citation" data-cites="Skilling1989">(Skilling, 1989)</span> の研究を踏襲し，大規模行列のスペクトル（密度）推定に向けて，Skilling-Hutchinson の跡推定量の拡張が議論されている．</p>
<p><span class="citation" data-cites="Meyer+2021">(Meyer et al., n.d.)</span> では Skilling-Hutchinson の跡推定量を改良したアルゴリズムが提案されている．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Adams+2018" class="csl-entry">
Adams, R. P., Pennington, J., Johnson, M. J., Smith, J., Ovadia, Y., Patton, B., and Saunderson, J. (2018). <a href="https://arxiv.org/abs/1802.03451">Estimating the spectral density of large implicit matrices</a>.
</div>
<div id="ref-Avron-Toledo2011" class="csl-entry">
Avron, H., and Toledo, S. (2011). <a href="https://doi.org/10.1145/1944345.1944349">Randomized algorithms for estimating the trace of an implicit symmetric positive semi-definite matrix</a>. <em>J. ACM</em>, <em>58</em>(2).
</div>
<div id="ref-Grathwohl+2019" class="csl-entry">
Grathwohl, W., Chen, R. T. Q., Bettencourt, J., and Duvenaud, D. (2019). <a href="https://openreview.net/forum?id=rJxgknCcK7"><span class="nocase">Scalable Reversible Generative Models with Free-form Continuous Dynamics</span></a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Hutchinson1990" class="csl-entry">
Hutchinson, M. F. (1990). <a href="https://doi.org/10.1080/03610919008812866"><span class="nocase">A Stochastic Estimator of the Trace of the Influence Matrix for Laplacian Smoothing Splines</span></a>. <em>Communications in Statistics - Simulation and Computation</em>, <em>19</em>(2), 433–450. doi: 10.1080/03610919008812866.
</div>
<div id="ref-Meyer+2021" class="csl-entry">
Meyer, R. A., Musco, C., Musco, C., and Woodruff, D. P. (n.d.). <a href="https://doi.org/10.1137/1.9781611976496.16">Hutch++: Optimal stochastic trace estimation</a>. In <em>2021 symposium on simplicity in algorithms (SOSA)</em>, pages 142–155.
</div>
<div id="ref-Skilling1989" class="csl-entry">
Skilling, J. (1989). <a href="https://doi.org/10.1007/978-94-015-7860-8_48">The eigenvalues of mega-dimensional matrices</a>. In J. Skilling, editor, <em>Maximum entropy and bayesian methods: Cambridge, england, 1988</em>, pages 455–466. Dordrecht: Springer Netherlands.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><span class="citation" data-cites="Hutchinson1990">(Hutchinson, 1990, p. 437)</span>, <span class="citation" data-cites="Avron-Toledo2011">(Avron and Toledo, 2011, p. 補題9)</span>, <span class="citation" data-cites="Adams+2018">(Adams et al., 2018, p. 命題4.2)</span> も参照．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Probability</category>
  <category>Functional Analysis</category>
  <guid>https://162348.github.io/posts/2024/Probability/Trace.html</guid>
  <pubDate>Mon, 19 Aug 2024 15:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Probability/Images/Skilling-Hutchinson.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>ニューラル常微分方程式</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Samplers/NF4.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="関連ページ" class="level3 unnumbered unlisted">
<h3 class="unnumbered unlisted anchored" data-anchor-id="関連ページ">関連ページ</h3>
<div id="listing-flow-listing" class="quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Deep,Sampling" data-listing-date-sort="1707836400000" data-listing-file-modified-sort="1727007848134" data-listing-date-modified-sort="1723993200000" data-listing-reading-time-sort="3" data-listing-word-count-sort="450">
<a href="../../../posts/2024/Samplers/NF.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_result.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
正規化流
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル４
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Deep,Sampling,P(X)" data-listing-date-sort="1707836400000" data-listing-file-modified-sort="1727007848139" data-listing-date-modified-sort="1724770800000" data-listing-reading-time-sort="4" data-listing-word-count-sort="794">
<a href="../../../posts/2024/Samplers/NF1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/linear/output.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ニューラル常微分方程式
</h5>
<div class="card-subtitle listing-subtitle">
シミュレーションなしの拡散モデルとしての連続正規化流
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Deep,Sampling,Python" data-listing-date-sort="1722610800000" data-listing-file-modified-sort="1727007848139" data-listing-date-modified-sort="1723993200000" data-listing-reading-time-sort="10" data-listing-word-count-sort="1863">
<a href="../../../posts/2024/Samplers/NF2.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/NF/Glow_output.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
正規化流
</h5>
<div class="card-subtitle listing-subtitle">
<code>normflows</code> によるハンズオン
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-03
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>
<section id="事前準備" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="事前準備"><span class="header-section-number">1</span> 事前準備</h2>
<div id="3960ed9a" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> math</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> IPython.display <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> clear_output</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm_notebook <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> tqdm</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> mpl</span>
<span id="cb1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-8"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>matplotlib inline</span>
<span id="cb1-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-10">sns.color_palette(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bright"</span>)</span>
<span id="cb1-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> mpl</span>
<span id="cb1-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.cm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> cm</span>
<span id="cb1-13"></span>
<span id="cb1-14"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-15"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Tensor</span>
<span id="cb1-16"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> nn</span>
<span id="cb1-17"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.nn  <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> functional <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> F</span>
<span id="cb1-18"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.autograd <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Variable</span>
<span id="cb1-19"></span>
<span id="cb1-20">use_cuda <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cuda.is_available()</span></code></pre></div>
</details>
</div>
<p>まずは ODE ソルバーを用意する．これはどのようなものでも NODE のサブルーチンとして使うことができる．</p>
<div id="9c14e270" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> ode_solve(z0, t0, t1, f):</span>
<span id="cb2-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Simplest Euler ODE initial value solver</span></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb2-5">    h_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span></span>
<span id="cb2-6">    n_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> math.ceil((<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>(t1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> t0)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>h_max).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>().item())</span>
<span id="cb2-7"></span>
<span id="cb2-8">    h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (t1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> t0)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>n_steps</span>
<span id="cb2-9">    t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t0</span>
<span id="cb2-10">    z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z0</span>
<span id="cb2-11"></span>
<span id="cb2-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i_step <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n_steps):</span>
<span id="cb2-13">        z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> f(z, t)</span>
<span id="cb2-14">        t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> h</span>
<span id="cb2-15">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> z</span></code></pre></div>
</div>
<p>NODE では，<img src="https://latex.codecogs.com/png.latex?D_%7Bx%7DL_t"> と <img src="https://latex.codecogs.com/png.latex?D_%5Ctheta%20L_t"> とは随伴状態 <img src="https://latex.codecogs.com/png.latex?a(t)"> に関する ODE で得られる．</p>
<p>この ODE の係数を事前に自動微分を通じて計算しておくための親クラスを定義する：</p>
<div id="b003fdd6" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> ODEF(nn.Module):</span>
<span id="cb3-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> forward_with_grad(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, z, t, grad_outputs):</span>
<span id="cb3-3">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Compute f and a df/dz, a df/dp, a df/dt"""</span></span>
<span id="cb3-4">        batch_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb3-5"></span>
<span id="cb3-6">        out <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.forward(z, t)</span>
<span id="cb3-7"></span>
<span id="cb3-8">        a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> grad_outputs</span>
<span id="cb3-9">        adfdz, adfdt, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>adfdp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.autograd.grad(</span>
<span id="cb3-10">            (out,), (z, t) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.parameters()), grad_outputs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(a),</span>
<span id="cb3-11">            allow_unused<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, retain_graph<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb3-12">        )</span>
<span id="cb3-13">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># grad method automatically sums gradients for batch items, we have to expand them back</span></span>
<span id="cb3-14">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> adfdp <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb3-15">            adfdp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([p_grad.flatten() <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> p_grad <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> adfdp]).unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb3-16">            adfdp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfdp.expand(batch_size, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> batch_size</span>
<span id="cb3-17">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> adfdt <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb3-18">            adfdt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfdt.expand(batch_size, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> batch_size</span>
<span id="cb3-19">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> out, adfdz, adfdt, adfdp</span>
<span id="cb3-20"></span>
<span id="cb3-21">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> flatten_parameters(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb3-22">        p_shapes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb3-23">        flat_parameters <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb3-24">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> p <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.parameters():</span>
<span id="cb3-25">            p_shapes.append(p.size())</span>
<span id="cb3-26">            flat_parameters.append(p.flatten())</span>
<span id="cb3-27">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> torch.cat(flat_parameters)</span></code></pre></div>
</div>
</section>
<section id="neural-ode-の実装" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="neural-ode-の実装"><span class="header-section-number">2</span> Neural ODE の実装</h2>
<p>Neural ODE では誤差逆伝播の代わりに随伴感度法を用いる．</p>
<p>これは <code>torch.nn.Module</code> を継承したクラスとしては定義できないため，<code>torch.autograd.Function</code> を継承したクラスとして定義する：</p>
<div id="02ec01a1" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> ODEAdjoint(torch.autograd.Function):</span>
<span id="cb4-2">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@staticmethod</span></span>
<span id="cb4-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> forward(ctx, z0, t, flat_parameters, func):</span>
<span id="cb4-4">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(func, ODEF)</span>
<span id="cb4-5">        bs, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>z_shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z0.size()</span>
<span id="cb4-6">        time_len <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t.size(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb4-7"></span>
<span id="cb4-8">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb4-9">            z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(time_len, bs, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>z_shape).to(z0)</span>
<span id="cb4-10">            z[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z0</span>
<span id="cb4-11">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i_t <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(time_len <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>):</span>
<span id="cb4-12">                z0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ode_solve(z0, t[i_t], t[i_t<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], func)</span>
<span id="cb4-13">                z[i_t<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z0</span>
<span id="cb4-14"></span>
<span id="cb4-15">        ctx.func <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> func</span>
<span id="cb4-16">        ctx.save_for_backward(t, z.clone(), flat_parameters)</span>
<span id="cb4-17">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> z</span>
<span id="cb4-18"></span>
<span id="cb4-19">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@staticmethod</span></span>
<span id="cb4-20">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> backward(ctx, dLdz):</span>
<span id="cb4-21">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb4-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        dLdz shape: time_len, batch_size, *z_shape</span></span>
<span id="cb4-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb4-24">        func <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ctx.func</span>
<span id="cb4-25">        t, z, flat_parameters <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ctx.saved_tensors</span>
<span id="cb4-26">        time_len, bs, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>z_shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z.size()</span>
<span id="cb4-27">        n_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.prod(z_shape)</span>
<span id="cb4-28">        n_params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> flat_parameters.size(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb4-29"></span>
<span id="cb4-30">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Dynamics of augmented system to be calculated backwards in time</span></span>
<span id="cb4-31">        <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> augmented_dynamics(aug_z_i, t_i):</span>
<span id="cb4-32">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb4-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            tensors here are temporal slices</span></span>
<span id="cb4-34"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            t_i - is tensor with size: bs, 1</span></span>
<span id="cb4-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            aug_z_i - is tensor with size: bs, n_dim*2 + n_params + 1</span></span>
<span id="cb4-36"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            """</span></span>
<span id="cb4-37">            z_i, a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> aug_z_i[:, :n_dim], aug_z_i[:, n_dim:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>n_dim]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ignore parameters and time</span></span>
<span id="cb4-38"></span>
<span id="cb4-39">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Unflatten z and a</span></span>
<span id="cb4-40">            z_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z_i.view(bs, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>z_shape)</span>
<span id="cb4-41">            a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a.view(bs, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>z_shape)</span>
<span id="cb4-42">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.set_grad_enabled(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>):</span>
<span id="cb4-43">                t_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t_i.detach().requires_grad_(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb4-44">                z_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z_i.detach().requires_grad_(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb4-45">                func_eval, adfdz, adfdt, adfdp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> func.forward_with_grad(z_i, t_i, grad_outputs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>a)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># bs, *z_shape</span></span>
<span id="cb4-46">                adfdz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfdz.to(z_i) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> adfdz <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> torch.zeros(bs, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>z_shape).to(z_i)</span>
<span id="cb4-47">                adfdp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfdp.to(z_i) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> adfdp <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> torch.zeros(bs, n_params).to(z_i)</span>
<span id="cb4-48">                adfdt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfdt.to(z_i) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> adfdt <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> torch.zeros(bs, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).to(z_i)</span>
<span id="cb4-49"></span>
<span id="cb4-50">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Flatten f and adfdz</span></span>
<span id="cb4-51">            func_eval <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> func_eval.view(bs, n_dim)</span>
<span id="cb4-52">            adfdz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfdz.view(bs, n_dim)</span>
<span id="cb4-53">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> torch.cat((func_eval, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>adfdz, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>adfdp, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>adfdt), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-54"></span>
<span id="cb4-55">        dLdz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dLdz.view(time_len, bs, n_dim)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># flatten dLdz for convenience</span></span>
<span id="cb4-56">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb4-57">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## Create placeholders for output gradients</span></span>
<span id="cb4-58">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prev computed backwards adjoints to be adjusted by direct gradients</span></span>
<span id="cb4-59">            adj_z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(bs, n_dim).to(dLdz)</span>
<span id="cb4-60">            adj_p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(bs, n_params).to(dLdz)</span>
<span id="cb4-61">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># In contrast to z and p we need to return gradients for all times</span></span>
<span id="cb4-62">            adj_t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(time_len, bs, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).to(dLdz)</span>
<span id="cb4-63"></span>
<span id="cb4-64">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i_t <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(time_len<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>):</span>
<span id="cb4-65">                z_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z[i_t]</span>
<span id="cb4-66">                t_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t[i_t]</span>
<span id="cb4-67">                f_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> func(z_i, t_i).view(bs, n_dim)</span>
<span id="cb4-68"></span>
<span id="cb4-69">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute direct gradients</span></span>
<span id="cb4-70">                dLdz_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dLdz[i_t]</span>
<span id="cb4-71">                dLdt_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.bmm(torch.transpose(dLdz_i.unsqueeze(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), f_i.unsqueeze(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb4-72"></span>
<span id="cb4-73">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adjusting adjoints with direct gradients</span></span>
<span id="cb4-74">                adj_z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> dLdz_i</span>
<span id="cb4-75">                adj_t[i_t] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adj_t[i_t] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> dLdt_i</span>
<span id="cb4-76"></span>
<span id="cb4-77">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pack augmented variable</span></span>
<span id="cb4-78">                aug_z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat((z_i.view(bs, n_dim), adj_z, torch.zeros(bs, n_params).to(z), adj_t[i_t]), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-79"></span>
<span id="cb4-80">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Solve augmented system backwards</span></span>
<span id="cb4-81">                aug_ans <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ode_solve(aug_z, t_i, t[i_t<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], augmented_dynamics)</span>
<span id="cb4-82"></span>
<span id="cb4-83">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Unpack solved backwards augmented system</span></span>
<span id="cb4-84">                adj_z[:] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> aug_ans[:, n_dim:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>n_dim]</span>
<span id="cb4-85">                adj_p[:] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> aug_ans[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>n_dim:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>n_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> n_params]</span>
<span id="cb4-86">                adj_t[i_t<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> aug_ans[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>n_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> n_params:]</span>
<span id="cb4-87"></span>
<span id="cb4-88">                <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">del</span> aug_z, aug_ans</span>
<span id="cb4-89"></span>
<span id="cb4-90">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## Adjust 0 time adjoint with direct gradients</span></span>
<span id="cb4-91">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute direct gradients</span></span>
<span id="cb4-92">            dLdz_0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dLdz[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb4-93">            dLdt_0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.bmm(torch.transpose(dLdz_0.unsqueeze(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), f_i.unsqueeze(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb4-94"></span>
<span id="cb4-95">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adjust adjoints</span></span>
<span id="cb4-96">            adj_z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> dLdz_0</span>
<span id="cb4-97">            adj_t[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adj_t[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> dLdt_0</span>
<span id="cb4-98">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> adj_z.view(bs, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>z_shape), adj_t, adj_p, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span></code></pre></div>
</div>
<p>これを <code>nn.Module</code> クラスとしてラップすることで，準備完了である：</p>
<div id="b47f65c3" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> NeuralODE(nn.Module):</span>
<span id="cb5-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, func):</span>
<span id="cb5-3">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(NeuralODE, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb5-4">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(func, ODEF)</span>
<span id="cb5-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.func <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> func</span>
<span id="cb5-6"></span>
<span id="cb5-7">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, z0, t<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Tensor([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span>]), return_whole_sequence<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>):</span>
<span id="cb5-8">        t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t.to(z0)</span>
<span id="cb5-9">        z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ODEAdjoint.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(z0, t, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.func.flatten_parameters(), <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.func)</span>
<span id="cb5-10">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> return_whole_sequence:</span>
<span id="cb5-11">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> z</span>
<span id="cb5-12">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb5-13">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> z[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
</div>
</section>
<section id="ダイナミクスの再現" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="ダイナミクスの再現"><span class="header-section-number">3</span> ダイナミクスの再現</h2>
<section id="線型ダイナミクス" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="線型ダイナミクス"><span class="header-section-number">3.1</span> 線型ダイナミクス</h3>
<p>簡単な線型ダイナミクスを，線型なダイナミクスで学習する．</p>
<div id="5ff41c1d" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> LinearODEF(ODEF):</span>
<span id="cb6-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, W):</span>
<span id="cb6-3">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(LinearODEF, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb6-4">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, bias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb6-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin.weight <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Parameter(W)</span>
<span id="cb6-6"></span>
<span id="cb6-7">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x, t):</span>
<span id="cb6-8">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin(x)</span>
<span id="cb6-9"></span>
<span id="cb6-10"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> SpiralFunctionExample(LinearODEF):</span>
<span id="cb6-11">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb6-12">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(SpiralFunctionExample, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(Tensor([[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span>], [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>]]))</span>
<span id="cb6-13"></span>
<span id="cb6-14"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> RandomLinearODEF(LinearODEF):</span>
<span id="cb6-15">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb6-16">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># super(RandomLinearODEF, self).__init__(torch.randn(2, 2)/2.)</span></span>
<span id="cb6-17">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(RandomLinearODEF, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(Tensor([[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>], [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>]]))</span>
<span id="cb6-18"></span>
<span id="cb6-19"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> to_np(x):</span>
<span id="cb6-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> x.detach().cpu().numpy()</span></code></pre></div>
</div>
<div id="9c7f3f65" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> plot_trajectories(obs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, times<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, trajs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, save<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>)):</span>
<span id="cb7-2">    plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>figsize)</span>
<span id="cb7-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> obs <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb7-4">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> times <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb7-5">            times <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(obs)</span>
<span id="cb7-6">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> o, t <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span>(obs, times):</span>
<span id="cb7-7">            o, t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> to_np(o), to_np(t)</span>
<span id="cb7-8">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> b_i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(o.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]):</span>
<span id="cb7-9">                plt.scatter(o[:, b_i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], o[:, b_i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>t[:, b_i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cm.plasma)</span>
<span id="cb7-10"></span>
<span id="cb7-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> trajs <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb7-12">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> z <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> trajs:</span>
<span id="cb7-13">            z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> to_np(z)</span>
<span id="cb7-14">            plt.plot(z[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], z[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], lw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>)</span>
<span id="cb7-15">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> save <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb7-16">            plt.savefig(save)</span>
<span id="cb7-17">    plt.show()</span>
<span id="cb7-18"></span>
<span id="cb7-19"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> conduct_experiment(ode_true, ode_trained, n_steps, name, plot_freq<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>):</span>
<span id="cb7-20">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create data</span></span>
<span id="cb7-21">    z0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Variable(torch.Tensor([[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>]]))</span>
<span id="cb7-22"></span>
<span id="cb7-23">    t_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">6.29</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span></span>
<span id="cb7-24">    n_points <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span></span>
<span id="cb7-25"></span>
<span id="cb7-26">    index_np <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, n_points, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.int64)</span>
<span id="cb7-27">    index_np <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.hstack([index_np[:, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]])</span>
<span id="cb7-28">    times_np <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, t_max, num<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_points)</span>
<span id="cb7-29">    times_np <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.hstack([times_np[:, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]])</span>
<span id="cb7-30"></span>
<span id="cb7-31">    times <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.from_numpy(times_np[:, :, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]).to(z0)</span>
<span id="cb7-32">    obs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ode_true(z0, times, return_whole_sequence<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>).detach()</span>
<span id="cb7-33">    obs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> obs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> torch.randn_like(obs) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span></span>
<span id="cb7-34"></span>
<span id="cb7-35">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get trajectory of random timespan</span></span>
<span id="cb7-36">    min_delta_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb7-37">    max_delta_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.0</span></span>
<span id="cb7-38">    max_points_num <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span></span>
<span id="cb7-39">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> create_batch():</span>
<span id="cb7-40">        t0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.uniform(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, t_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> max_delta_time)</span>
<span id="cb7-41">        t1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.random.uniform(min_delta_time, max_delta_time)</span>
<span id="cb7-42"></span>
<span id="cb7-43">        idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sorted</span>(np.random.permutation(index_np[(times_np <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> t0) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> (times_np <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> t1)])[:max_points_num])</span>
<span id="cb7-44"></span>
<span id="cb7-45">        obs_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> obs[idx]</span>
<span id="cb7-46">        ts_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> times[idx]</span>
<span id="cb7-47">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> obs_, ts_</span>
<span id="cb7-48"></span>
<span id="cb7-49">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Train Neural ODE</span></span>
<span id="cb7-50">    optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.optim.Adam(ode_trained.parameters(), lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>lr)</span>
<span id="cb7-51">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n_steps):</span>
<span id="cb7-52">        obs_, ts_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> create_batch()</span>
<span id="cb7-53"></span>
<span id="cb7-54">        z_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ode_trained(obs_[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], ts_, return_whole_sequence<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb7-55">        loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> F.mse_loss(z_, obs_.detach())</span>
<span id="cb7-56"></span>
<span id="cb7-57">        optimizer.zero_grad()</span>
<span id="cb7-58">        loss.backward(retain_graph<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb7-59">        optimizer.step()</span>
<span id="cb7-60"></span>
<span id="cb7-61">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> plot_freq <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb7-62">            z_p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ode_trained(z0, times, return_whole_sequence<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb7-63"></span>
<span id="cb7-64">            plot_trajectories(obs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[obs], times<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[times], trajs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[z_p], save<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Files/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span>plot_freq<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.png"</span>)</span>
<span id="cb7-65">            clear_output(wait<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div>
</div>
<div id="ec1bf5c6" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">ode_true <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> NeuralODE(SpiralFunctionExample())</span>
<span id="cb8-2">ode_trained <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> NeuralODE(RandomLinearODEF())</span>
<span id="cb8-3">conduct_experiment(ode_true, ode_trained, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"linear"</span>)</span></code></pre></div>
</div>
<p>ImageMagick により git 生成した結果は次の通り：</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb9-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">convert</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-delay</span> 10 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-loop</span> 0 <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$(</span><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">{</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">..</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">49</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">}</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">;</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">do</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">echo</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$i</span>.png<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">;</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">done</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">)</span> output.gif</span></code></pre></div>
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/linear/output.gif" class="img-fluid"></p>
</section>
<section id="非線型ダイナミクス" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="非線型ダイナミクス"><span class="header-section-number">3.2</span> 非線型ダイナミクス</h3>
<p>今回は非線型のダイナミクスを，<a href="https://pytorch.org/docs/stable/generated/torch.nn.ELU.html">ELU</a> を備えた一層のニューラルネットワークで学習する：</p>
<div id="ea8e3b83" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> TestODEF(ODEF):</span>
<span id="cb10-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, A, B, x0):</span>
<span id="cb10-3">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(TestODEF, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb10-4">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.A <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, bias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb10-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.A.weight <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Parameter(A)</span>
<span id="cb10-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.B <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, bias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb10-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.B.weight <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Parameter(B)</span>
<span id="cb10-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.x0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Parameter(x0)</span>
<span id="cb10-9"></span>
<span id="cb10-10">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x, t):</span>
<span id="cb10-11">        xTx0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.x0, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb10-12">        dxdt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.sigmoid(xTx0) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.A(x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.x0) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> torch.sigmoid(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>xTx0) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.B(x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.x0)</span>
<span id="cb10-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> dxdt</span>
<span id="cb10-14"></span>
<span id="cb10-15"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> NNODEF(ODEF):</span>
<span id="cb10-16">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, in_dim, hid_dim, time_invariant<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>):</span>
<span id="cb10-17">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(NNODEF, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb10-18">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.time_invariant <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time_invariant</span>
<span id="cb10-19"></span>
<span id="cb10-20">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> time_invariant:</span>
<span id="cb10-21">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(in_dim, hid_dim)</span>
<span id="cb10-22">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb10-23">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(in_dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, hid_dim)</span>
<span id="cb10-24">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(hid_dim, hid_dim)</span>
<span id="cb10-25">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(hid_dim, in_dim)</span>
<span id="cb10-26">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.elu <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.ELU(inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-27"></span>
<span id="cb10-28">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x, t):</span>
<span id="cb10-29">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.time_invariant:</span>
<span id="cb10-30">            x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat((x, t), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb10-31"></span>
<span id="cb10-32">        h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.elu(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin1(x))</span>
<span id="cb10-33">        h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.elu(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin2(h))</span>
<span id="cb10-34">        out <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lin3(h)</span>
<span id="cb10-35">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> out</span></code></pre></div>
</div>
<div id="d8b02904" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">func <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> TestODEF(Tensor([[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>], [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>]]), Tensor([[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span>], [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>]]), Tensor([[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span>]]))</span>
<span id="cb11-2">ode_true <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> NeuralODE(func)</span>
<span id="cb11-3"></span>
<span id="cb11-4">func <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> NNODEF(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>, time_invariant<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb11-5">ode_trained <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> NeuralODE(func)</span>
<span id="cb11-6"></span>
<span id="cb11-7">conduct_experiment(ode_true, ode_trained, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3000</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"nonlinear"</span>, plot_freq<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>, lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.001</span>)</span></code></pre></div>
</div>
<p>逡巡を繰り返して学習する様子がよく伺える．学習率を <code>lr=0.001</code> としているが，<code>lr=0.01</code> でも <code>lr=0.005</code> でも，学習が非常に良い線まで行ってもすぐに初期値よりもカオスなダイナミクスに戻ってしまう挙動がよく見られた．</p>
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/nonlinear/output.gif" class="img-fluid"></p>
</section>
</section>


<div id="quarto-appendix" class="default"><section id="文献紹介" class="level2 appendix" data-number="4"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">4</span> 文献紹介</h2><div class="quarto-appendix-contents">

<p><a href="https://msurtsukov.github.io/Neural-ODE/">Mikhail Surtsukov 氏</a>によるチュートリアルが，<a href="https://github.com/msurtsukov/neural-ode?tab=readme-ov-file">このレポジトリ</a>で公開されている．</p>
<p>FFJORD <span class="citation" data-cites="Grathwohl+2019">(Grathwohl et al., 2019)</span> の実装は，<a href="https://github.com/rtqichen/ffjord">このレポジトリ</a>で公開されている．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Grathwohl+2019" class="csl-entry">
Grathwohl, W., Chen, R. T. Q., Bettencourt, J., and Duvenaud, D. (2019). <a href="https://openreview.net/forum?id=rJxgknCcK7"><span class="nocase">Scalable Reversible Generative Models with Free-form Continuous Dynamics</span></a>. In <em>International conference on learning representations</em>.
</div>
</div></section></div> ]]></description>
  <category>Deep</category>
  <category>Sampling</category>
  <category>Python</category>
  <guid>https://162348.github.io/posts/2024/Samplers/NF4.html</guid>
  <pubDate>Mon, 19 Aug 2024 15:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Samplers/Files/nonlinear/output.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>階層モデル再論</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Kernels/HierarchicalModel.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="はじめに" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="はじめに">はじめに</h2>
<p>潜在変数模型とはどうやらとんでもなく広い射程を持った対象であるようである．</p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="潜在変数モデルとは……">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
潜在変数モデルとは……
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>心理学，経済学をはじめとして多くの分野で中心的に扱われてきたモデルである（<a href="https://ja.wikipedia.org/wiki/共分散構造分析">構造方程式モデル</a>，因子分析，同時方程式モデル，<a href="../../../posts/2024/Computation/PGM1.html">Probabilistic Graphical Model</a> など）．</li>
<li>ベイズ統計学では <strong>階層モデル</strong> (hierarchical model) として極めて重要な役割を果たす．</li>
<li>生成モデリング（<a href="../../../posts/2024/Kernels/Deep4.html">VAE</a>, <a href="../../../posts/2024/Samplers/EBM.html">EBM</a>, <a href="../../../posts/2024/Samplers/Diffusion.html">Diffusion</a>, <a href="../../../posts/2024/Kernels/Deep3.html">GAN</a>）も，観測変数上の周辺分布がデータ分布に近づくように潜在変数模型を学習する方法である．</li>
<li>表現学習や独立成分分析だけでなく，脳も潜在変数模型に基いてメンタルモデルを構成しているという仮説もある（<a href="../../../posts/2024/Kernels/NCL.html#sec-InfoMax">InfoMax に関する稿</a>も参照）．</li>
<li>情報理論において，通信路は潜在変数模型としてモデリングできる．この方向には，潜在変数模型は数学的には確率空間の圏上の図式であるとして研究されている <span class="citation" data-cites="Perrone2024">(Perrone, 2024)</span>．</li>
</ol>
</div>
</div>
<p>このように種々の文脈で登場する潜在変数模型であるが，<u><strong>それぞれの文脈において「潜在変数」の果たす役割は全く違う</strong></u>．</p>
<p>しかし，数学的には全く同じ枠組みで記述できる．従って，そのように扱うことは一定の価値を持つだろう．</p>
<p>実際，近年になり，これから本稿で解説するように，潜在変数モデルの観点から心理学，経済学，環境科学，遺伝学，信号処理，逆問題，社会学，政治科学，マーケティング分野で独自に発展した手法が，特定の手法の特別な場合と見れるという理解が進み，手法の交流と知見の交換が進んでいる．</p>
</section>
<section id="本稿の目的" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="本稿の目的">本稿の目的</h2>
<p>本稿では主成分分析，因子分析，構造方程式モデリング，混合モデル，独立成分分析を，<u>潜在変数モデルとして解釈し，図式で理解する</u>．</p>
<p>確率変数を丸つきの大文字で表し，<img src="https://latex.codecogs.com/png.latex?X%5Ei,Y%5Ei"> は観測変数，<img src="https://latex.codecogs.com/png.latex?Z%5Ei"> は潜在変数を表す．矢印は <a href="../../../posts/2024/Probability/Kernel.html">確率核</a> を表す．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/MM.svg" class="img-fluid figure-img"></p>
<figcaption>混合モデル（第 4 節）</figcaption>
</figure>
</div>
<p>種々の <strong>多変量解析法</strong> を（ベイズ）階層モデルとして統一的に理解すると同時に，それぞれの文脈での「使い方の違い」に注目することを目指す．</p>
</section>
<section id="sec-PCA" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="sec-PCA"><span class="header-section-number">1</span> 主成分分析 (PCA)</h2>
<section id="はじめに-1" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="はじめに-1"><span class="header-section-number">1.1</span> はじめに</h3>
<p>主成分分析では，<img src="https://latex.codecogs.com/png.latex?p"> 次元のデータ <img src="https://latex.codecogs.com/png.latex?%5C%7Bx_i%5C%7D_%7Bi=1%7D%5En%5Csubset%5Cmathbb%7BR%7D%5Ep"> の各成分を，より少数の潜在変数を持った１層の線型 Gauss 模型</p>
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/PCA.svg" class="img-fluid"></p>
<p>で説明しようとする．<sup>1</sup></p>
<p>歴史的に主成分分析は，おろした垂線の足の二乗距離和の意味でコストが最小になるような線型射影を求める問題 <span class="citation" data-cites="Pearson01-PCA">(Pearson, 1901)</span> として最初に登場し，値の分散が最大となるような線型射影を求める問題 <span class="citation" data-cites="Hotelling33-PCA">(Hotelling, 1933)</span> として PCA の名前がつき，心理学分野，特に psychometrika で取り上げられて大きく発展した．</p>
<p>このような潜在変数モデルとしての見方は probabilistic PCA <span class="citation" data-cites="Tipping-Bishop1999">(Tipping and Bishop, 1999)</span> / SPCA (Sensible PCA) <span class="citation" data-cites="Roweis1997">(Roweis, 1997)</span> として，因子分析から逆輸入する形で初めて自覚された見方である（第 2.3.1 節も参照）．</p>
<p>確率的な見地から見れば，正規性を仮定した変数 <img src="https://latex.codecogs.com/png.latex?Z%5E1,%5Ccdots,Z%5Er"> の事前分布が互いに独立なデルタ分布に縮退している場合が古典的な PCA である <span class="citation" data-cites="Roweis1997">(Roweis, 1997)</span>．</p>
<p>いずれの場合も追加の過程なくしてモデルは識別可能性がなく，後続タスクに応じて種々の制約を追加することで所望の解を得る，という動的な使い方がなされる．</p>
<p>以降，<img src="https://latex.codecogs.com/png.latex?X%5Cin%5Cmathcal%7BL%7D(%5COmega;%5Cmathbb%7BR%7D%5Ep),Z%5Cin%5Cmathcal%7BL%7D(%5COmega;%5Cmathbb%7BR%7D%5Er)"> を確率変数， <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BX%7D=(x_i%5Ej)%5Cin%20M_%7Bn,p%7D(%5Cmathbb%7BR%7D),%5Cboldsymbol%7BZ%7D=(z_i%5Ej)%5Cin%20M_%7Bn,r%7D(%5Cmathbb%7BR%7D)%0A"> を行列することに注意．</p>
</section>
<section id="概要" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="概要"><span class="header-section-number">1.2</span> 概要</h3>
<p>PCA ではデータ行列を <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BX%7D:=%5Cbegin%7Bpmatrix%7Dx_1%5E%5Ctop%5C%5C%5Cvdots%5C%5Cx_n%5E%5Ctop%5Cend%7Bpmatrix%7D%5Cin%20M_%7Bn,p%7D(%5Cmathbb%7BR%7D)%0A"> で定めたとき，データ次元 <img src="https://latex.codecogs.com/png.latex?p"> より小さい数の成分 <img src="https://latex.codecogs.com/png.latex?r"> で説明しようとする： <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BX%7D%5Capprox%5Cboldsymbol%7BZ%7DC%5E%5Ctop,%5Cqquad%5Cboldsymbol%7BZ%7D:=%5Cbegin%7Bpmatrix%7Dz_1%5E%5Ctop%5C%5C%5Cvdots%5C%5Cz_n%5E%5Ctop%5Cend%7Bpmatrix%7D%5Cin%20M_%7Bn,r%7D(%5Cmathbb%7BR%7D),C%5Cin%20M_%7Bp,r%7D(%5Cmathbb%7BR%7D).%0A"></p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li>古典的には，<img src="https://latex.codecogs.com/png.latex?z_%7Bij%7D"> を（主成分）<strong>得点</strong> (score)，<img src="https://latex.codecogs.com/png.latex?Z%5Ei"> を <strong>合成変量</strong>，<img src="https://latex.codecogs.com/png.latex?c_%7Bij%7D"> を <strong>負荷量</strong> (loading) ともいう <span class="citation" data-cites="足立-山本2024">(足立浩平 and 山本倫生, 2024)</span>．</li>
<li>機械学習では <img src="https://latex.codecogs.com/png.latex?Z%5E1,%5Ccdots,Z%5Er"> を <strong>潜在因子</strong>，<img src="https://latex.codecogs.com/png.latex?W%5Cin%20M_%7Bpr%7D(%5Cmathbb%7BR%7D)"> を <strong>荷重</strong> (weight) ともいう <span class="citation" data-cites="Murphy2022">(Murphy, 2022)</span>．</li>
</ul>
</div>
</div>
</div>
<p>この問題は <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BX%7D"> の <a href="../../../posts/2024/FunctionalAnalysis/SVD.html">特異値分解</a> (SVD) <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BX%7D=U%5CSigma%20V%5E%5Ctop"> により解ける： <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BZ%7D=U%5CSigma_%7B1:r%7D%5E%5Calpha%20A=%5Cboldsymbol%7BX%7D(%5Cunderbrace%7BV%5CSigma%5E%7B%5Calpha-1%7D_%7B1:r%7DA%7D_%7B=:W%7D),%5Cqquad%20C:=V%5CSigma_%7B1:r%7D%5E%7B1-%5Calpha%7D(A%5E%7B-1%7D)%5E%5Ctop.%0A"> ただし，<img src="https://latex.codecogs.com/png.latex?%5Calpha%5Cin%5Cmathbb%7BR%7D,A%5Cin%5Cmathrm%7BGL%7D_p(%5Cmathbb%7BR%7D)"> は任意である．この解は，特異値分解の性質により，残差を Hilbert-Schmidt ノルムの意味で最小にする： <span id="eq-PCA-objective"><img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_C%5C%7C%5Cboldsymbol%7BX%7D-%5Cboldsymbol%7BZ%7DC%5E%5Ctop%5C%7C_%5Cmathrm%7BHS%7D=%5Cmin_C%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi=1%7D%5En%5Clvert%20x_i-Cz_i%5Crvert%5E2=%5Csigma_%7Br+1%7D%0A%5Ctag%7B1%7D"></span> この目的関数は復元誤差とも理解できる．ただし，<img src="https://latex.codecogs.com/png.latex?%5Csigma_%7Br+1%7D"> は行列 <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BZ%7DC"> の第 <img src="https://latex.codecogs.com/png.latex?r+1"> 特異値である．</p>
</section>
<section id="主成分分散最大化" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="主成分分散最大化"><span class="header-section-number">1.3</span> 主成分分散最大化</h3>
<p>荷重行列 <img src="https://latex.codecogs.com/png.latex?W"> が <img src="https://latex.codecogs.com/png.latex?W%5E%5Ctop%20W=I_r"> を満たすという制約条件を追加すると，目的関数 (1) は潜在変数の分散を最大にすることと等価になる： <span id="eq-PCA-objective2"><img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname*%7Bargmin%7D_%7BW%7D%5C%7C%5Cboldsymbol%7BX%7D-%5Cboldsymbol%7BZ%7DW%5C%7C_%5Cmathrm%7BHS%7D=%5Coperatorname*%7Bargmin%7D_W%5Coperatorname%7BTr%7D((%5Cboldsymbol%7BX%7DW)%5E%5Ctop%5Cboldsymbol%7BX%7DW).%0A%5Ctag%7B2%7D"></span></p>
<p>すなわち，<img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BZ%7D=%5Cboldsymbol%7BX%7DW"> の変動が差大になるようにすれば良い．</p>
<p>そのためには，確率変数 <img src="https://latex.codecogs.com/png.latex?X"> のデータ行列 <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BX%7D"> から計算した経験共分散行列 <img src="https://latex.codecogs.com/png.latex?S%5Cin%20M_%7Bp%7D(%5Cmathbb%7BR%7D)_+"> の固有ベクトルのうち，対応する固有値が大きいものから <img src="https://latex.codecogs.com/png.latex?w_1,%5Ccdots,w_r"> として荷重行列とすれば良い： <img src="https://latex.codecogs.com/png.latex?%0AW:=(w_1%5C;%5Ccdots%5C;w_r).%0A"></p>
<p>実はこれは解の１つに過ぎず，<img src="https://latex.codecogs.com/png.latex?W"> に右から直交行列を乗じて「回転」させたものは全て解になる．上の解は追加の条件 <img src="https://latex.codecogs.com/png.latex?Z%5E%5Ctop%20Z=I_r"> を課すことで特定される．</p>
</section>
<section id="計算上の注意" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="計算上の注意"><span class="header-section-number">1.4</span> 計算上の注意</h3>
<p>各次元に関する長さのスケールを揃えるために，PCA を始める前にデータを正規化しておくか，または共分散行列 <img src="https://latex.codecogs.com/png.latex?S"> の代わりに，相関行列を用いるべきである．</p>
<p>また，実際に最適化や相関行列の固有値分解をすることはなく，基本的に SVD の方が <img src="https://latex.codecogs.com/png.latex?O(np%5E2)+O(p%5E3)"> と高速である <span class="citation" data-cites="Unkel-Trendafilov2010">(Unkel and Trendafilov, 2010)</span>．</p>
<p>さらに次元 <img src="https://latex.codecogs.com/png.latex?p"> が高い場合は，<strong>確率的 SVD</strong> <span class="citation" data-cites="Halko+2011">(Halko et al., 2011)</span>, <span class="citation" data-cites="Drineas+2016">(Drineas and Mahoney, 2016)</span> を用いてさらに <img src="https://latex.codecogs.com/png.latex?O(nr%5E2)+(r%5E3)"> まで削減できる．このような手法は確率的数値解析と呼ばれる <span class="citation" data-cites="Murray+2023">(Murray et al., 2023)</span>．</p>
</section>
<section id="sec-dimension-reduction" class="level3" data-number="1.5">
<h3 data-number="1.5" class="anchored" data-anchor-id="sec-dimension-reduction"><span class="header-section-number">1.5</span> 線型射影による次元縮約</h3>
<p><img src="https://latex.codecogs.com/png.latex?W%5E%5Ctop%20W=I_r"> の仮定の下で，PCA の目的関数 (1) は，潜在変数の分散最大化 (2) と見れるのだった．</p>
<p>これは同じ仮定の下で，データ変数 <img src="https://latex.codecogs.com/png.latex?X"> の最小誤差の線型射影を求める問題とも見れる： <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname*%7Bargmin%7D_W%5C%7C%5Cboldsymbol%7BX%7D-%5Cboldsymbol%7BZ%7DW%5C%7C_%5Cmathrm%7BHS%7D=%5Coperatorname*%7Bargmin%7D_W%5C%7C%5Cboldsymbol%7BX%7D-%5Cboldsymbol%7BX%7DWW%5E%5Ctop%5C%7C_%5Cmathrm%7BHS%7D.%0A"></p>
<p>なお，一般の行列 <img src="https://latex.codecogs.com/png.latex?A"> について <img src="https://latex.codecogs.com/png.latex?P_A=A(A%5E%7B-1%7DA)%5E+A%5E%5Ctop"> は <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BIm%7D%5C,A"> 上の直交射影になる．<img src="https://latex.codecogs.com/png.latex?A"> が直交行列であるとき，<img src="https://latex.codecogs.com/png.latex?P_A=AA%5E%5Ctop"> が成り立つ．</p>
</section>
<section id="因子分析志向の主成分分析" class="level3" data-number="1.6">
<h3 data-number="1.6" class="anchored" data-anchor-id="因子分析志向の主成分分析"><span class="header-section-number">1.6</span> 因子分析志向の主成分分析</h3>
<p>因子分析では，<img src="https://latex.codecogs.com/png.latex?Z%5E1,%5Ccdots,Z%5Er"> を対等な因子と見て，それぞれのデータへの影響を調べたい．このような場合は， <img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B1%7D%7Bn%7D%5Cboldsymbol%7BZ%7D%5E%5Ctop%5Cboldsymbol%7BZ%7D=I_r%0A"> が自然な制約になる．この際の解は，直交行列 <img src="https://latex.codecogs.com/png.latex?T%5Cin%20O_r(%5Cmathbb%7BR%7D)"> の違いを除いて， <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BZ%7D=%5Csqrt%7Bn%7DUT,%5Cqquad%20C=%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%7D%7DV%5CSigma_%7B1:r%7DT,%5Cqquad%20W=%5Csqrt%7Bn%7DV%5CSigma_%7B1:r%7D%5E%7B-1%7DT,%0A"> まで確定する．</p>
<p>しばしば，追加の仮定 <img src="https://latex.codecogs.com/png.latex?%0AC%5E%5Ctop%20C=%5Cmathrm%7Bdiag%7D(%5Crho_%7B1:r%7D),%5Cqquad%20%5Crho_1%5Cge%5Ccdots%5Cge%5Crho_r%5Cge0%0A"> を課して得られる一意な解 <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BZ%7D=%5Csqrt%7Bn%7DU,%5Cqquad%20C=%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%7D%7DV%5CSigma_%7B1:r%7D,%5Cqquad%20W=%5Csqrt%7Bn%7DV%5CSigma_%7B1:r%7D%5E%7B-1%7D,%0A"> を <strong>初期解</strong> と呼び，これを「回転」させることで他の解が探索され，所望の分解を探す．</p>
<p>因子分析では <span class="citation" data-cites="Thurstone1947">(Thurstone, 1947)</span> 以来，種々の回転法とアルゴリズムが蓄積している <span class="citation" data-cites="足立-山本2024">(足立浩平 and 山本倫生, 2024)</span>．一般にこの文脈では，<span class="citation" data-cites="Thurstone1947">(Thurstone, 1947)</span> にいう「単純構造」を達成した，解釈が容易な因子をドメイン知識に基づいて構成することを目指す．この「単純構造」とは，現代でいう一種の disentangled factor と理解できる．</p>
</section>
</section>
<section id="sec-FA" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="sec-FA"><span class="header-section-number">2</span> 因子分析 (FA)</h2>
<section id="はじめに-2" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="はじめに-2"><span class="header-section-number">2.1</span> はじめに</h3>
<p>主成分分析が「低階数近似」ならば，因子分析は「高階数近似」というべきである <span class="citation" data-cites="足立浩平2023">(足立浩平, 2023)</span>．</p>
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/FA.svg" class="img-fluid"></p>
<p>より正確には，因子分析は，観測の各次元 <img src="https://latex.codecogs.com/png.latex?X%5E1,%5Ccdots,X%5Ep"> ごとに「独自因子」<img src="https://latex.codecogs.com/png.latex?Z%5E1,%5Ccdots,Z%5Ep"> を想定しつつ，全観測に共通する「共通因子」<img src="https://latex.codecogs.com/png.latex?F%5E1,%5Ccdots,F%5Er"> をどのように抽出できるかを考える，という志向性を持つ：</p>
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/FA2.svg" class="img-fluid"></p>
<p>この意味では，FA は独自因子 <img src="https://latex.codecogs.com/png.latex?U%5E1,%5Ccdots,U%5Ep"> を追加した PCA とも理解できる．</p>
<p>歴史的には <span class="citation" data-cites="Spearman1904">(Spearman, 1904)</span> が古典テスト理論の文脈で <img src="https://latex.codecogs.com/png.latex?r=1"> の因子分析を，<span class="citation" data-cites="Thurstone1947">(Thurstone, 1947)</span> が一般の <img src="https://latex.codecogs.com/png.latex?1%5Cle%20r%3Cp"> の場合の因子分析を「回転」の手法と共に導入した．</p>
<p>さらに興味深いことに，FA では PCA をはじめとした多くの多変量分析手法と違い，<span class="citation" data-cites="Lawley1942">(Lawley, 1942)</span>, <span class="citation" data-cites="Anderson-Rubin1956">(Anderson and Rubin, 1956)</span> らにより，初期から確率的な扱いが発展した手法である <span class="citation" data-cites="足立-山本2024">(足立浩平 and 山本倫生, 2024)</span>．</p>
<p>FA に倣う形で，PCA にも確率論的なアプローチが導入された <span class="citation" data-cites="Tipping-Bishop1999">(Tipping and Bishop, 1999)</span>, <span class="citation" data-cites="Roweis1997">(Roweis, 1997)</span>．</p>
</section>
<section id="概要-1" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="概要-1"><span class="header-section-number">2.2</span> 概要</h3>
<p>FA では <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BZ%7D=(%5Cboldsymbol%7BF%7D%5C;%5Cboldsymbol%7BU%7D)%5Cin%20M_%7Bn,r+p%7D(%5Cmathbb%7BR%7D)"> の分解に基づき， <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BX%7D%5Capprox%5Cboldsymbol%7BF%7DA%5E%5Ctop+%5Cboldsymbol%7BU%7D%5CPsi%5E%7B1/2%7D,%5Cqquad%20A%5Cin%20M_%7Br,p%7D(%5Cmathbb%7BR%7D),%5CPsi=%5Cmathrm%7Bdiag%7D(%5Cpsi_1,%5Ccdots,%5Cpsi_p)%5Cin%20M_p(%5Cmathbb%7BR%7D),%0A"> によってデータ行列 <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BX%7D%5Cin%20M_%7Bn,p%7D(%5Cmathbb%7BR%7D)"> を説明しようとする．<sup>2</sup></p>
<p>PCA よりさらに識別可能性は絶望的であるが，FA では潜在変数の解釈可能性担保のため，次の仮定を課す： <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7B1%7D_n%5E%5Ctop%5Cboldsymbol%7BF%7D=%5Cboldsymbol%7B0%7D_r,%5Cqquad%20%5Cboldsymbol%7B1%7D_n%5E%5Ctop%5Cboldsymbol%7BU%7D=%5Cboldsymbol%7B0%7D_p,%0A"> <img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7BF%7D%5E%5Ctop%5Cboldsymbol%7BF%7D=n%5Cboldsymbol%7BI%7D_r,%5Cqquad%20%5Cboldsymbol%7BU%7D%5E%5Ctop%5Cboldsymbol%7BU%7D=n%5Cboldsymbol%7BI%7D_p,%5Cqquad%5Cboldsymbol%7BF%7D%5E%5Ctop%5Cboldsymbol%7BU%7D=O.%0A"> すなわち，推定される確率変数 <img src="https://latex.codecogs.com/png.latex?F,U"> が標準化されていて互いに無相関であるように誘導する．</p>
<p>また，<img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BU%7D"> の経験分散が <img src="https://latex.codecogs.com/png.latex?%5CPsi"> になることに注意．</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li>古典的には，<img src="https://latex.codecogs.com/png.latex?f_%7Bij%7D"> を共通因子，<img src="https://latex.codecogs.com/png.latex?%5Cpsi_j"> を独自因子の <strong>得点</strong> (score)，<img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> を <strong>負荷量</strong> (loading) ともいう <span class="citation" data-cites="足立-山本2024">(足立浩平 and 山本倫生, 2024)</span>．</li>
<li>機械学習では <img src="https://latex.codecogs.com/png.latex?Z%5E1,%5Ccdots,Z%5Er"> を <strong>潜在因子</strong>，<img src="https://latex.codecogs.com/png.latex?W%5Cin%20M_%7Bpr%7D(%5Cmathbb%7BR%7D)"> を <strong>荷重</strong> (weight) ともいう <span class="citation" data-cites="Murphy2022">(Murphy, 2022)</span>．</li>
</ul>
</div>
</div>
</div>
<p>この問題は，<img src="https://latex.codecogs.com/png.latex?C:=(A%5C;%5CPsi%5E%7B1/2%7D)"> と定めると，PCA と同じ問題 (1) に帰着される： <img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_C%5C%7C%5Cboldsymbol%7BX%7D-%5Cboldsymbol%7BZ%7DC%5E%5Ctop%5C%7C_%5Cmathrm%7BHS%7D.%0A"></p>
<p>これはやはり特異値分解により解くことができる <span class="citation" data-cites="DeLeeuw04-SimultaneousEstimationOfEFA">(De Leeuw, 2004)</span>．</p>
<p>解は直交行列による回転を除いても，やはり一意に定まらないようである．</p>
</section>
<section id="確率的アプローチ" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="確率的アプローチ"><span class="header-section-number">2.3</span> 確率的アプローチ</h3>
<p>ここで， <img src="https://latex.codecogs.com/png.latex?%0AU:=%5Cbegin%7Bpmatrix%7DU%5E1%5C%5C%5Cvdots%5C%5CU%5Ep%5Cend%7Bpmatrix%7D%5Cin%5Cmathcal%7BL%7D(%5COmega;%5Cmathbb%7BR%7D%5Ep),%5Cqquad%20F:=%5Cbegin%7Bpmatrix%7DF%5E1%5C%5C%5Cvdots%5C%5CF%5Er%5Cend%7Bpmatrix%7D%5Cin%5Cmathcal%7BL%7D(%5COmega;%5Cmathbb%7BR%7D%5Er),%0A"> を確率変数とすると， <span id="eq-probabilistic-FA"><img src="https://latex.codecogs.com/png.latex?%0AX%5Capprox%20AF+%5CPsi%5E%7B1/2%7DU%0A%5Ctag%7B3%7D"></span> によって <img src="https://latex.codecogs.com/png.latex?X"> に確率モデルが誘導されることになる．</p>
<section id="sec-PPCA" class="level4" data-number="2.3.1">
<h4 data-number="2.3.1" class="anchored" data-anchor-id="sec-PPCA"><span class="header-section-number">2.3.1</span> 正規性の仮定</h4>
<p><img src="https://latex.codecogs.com/png.latex?U,F"> に正規性の仮定をおけば，このモデルは EM アルゴリズムなどを用いて最尤推定できる <span class="citation" data-cites="Rubin-Thayer1982">(Rubin and Thayer, 1982)</span>, <span class="citation" data-cites="Ghahramani-Hinton1996">(Ghahramani and Hinton, 1996)</span>．このような最尤推定のアプローチは <span class="citation" data-cites="Lawley1942">(Lawley, 1942)</span> から考えられていた．</p>
<p>この見方が PCA にも応用された．追加の仮定 <img src="https://latex.codecogs.com/png.latex?%0AA%5E%5Ctop%20A=I_%7Br%7D,%5Cqquad%20%5CPsi=%5Csigma%5E2I_p,%0A"> の下での FA への確率論的アプローチを probabilistic PCA <span class="citation" data-cites="Tipping-Bishop1999">(Tipping and Bishop, 1999)</span> / SPCA (Sensible PCA) <span class="citation" data-cites="Roweis1997">(Roweis, 1997)</span> という．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cto0"> の極限で古典的 PCA が回復される．</p>
</section>
<section id="共分散構造分析" class="level4" data-number="2.3.2">
<h4 data-number="2.3.2" class="anchored" data-anchor-id="共分散構造分析"><span class="header-section-number">2.3.2</span> 共分散構造分析</h4>
<p>一方で，分布の仮定は課さず，<img src="https://latex.codecogs.com/png.latex?X"> の経験分散 <img src="https://latex.codecogs.com/png.latex?S"> を，式 (3) の右辺の共分散 <img src="https://latex.codecogs.com/png.latex?%0A%5CSigma:=AA%5E%5Ctop+%5CPsi%0A"> となるべく近づけるように学習する方法もある．</p>
<p>例えば <span class="citation" data-cites="Harman-Jones1966">(Harman and Jones, 1966)</span>, <span class="citation" data-cites="Harman-Fukuda1966">(Harman and Fukuda, 1966)</span> では，Hilbert-Schmidt ノルム <img src="https://latex.codecogs.com/png.latex?%5C%7CS-%5CSigma%5C%7C_%5Cmathrm%7BHS%7D"> の最小化することで解を探索する方法が考慮された．</p>
<p>このように，データの共分散行列を低階数近似するアプローチは <strong>共分散構造分析</strong> <span class="citation" data-cites="Bock-Bargmann1966">(Bock and Bargmann, 1966)</span> ともいう．</p>
<p>さらに，確率論的なアプローチは一般の構造方程式モデル (SEM, 次節 3 参照) へと発展 <span class="citation" data-cites="Joreskog70">(Karl Gustav Jöreskog, 1970)</span>, <span class="citation" data-cites="Sorbom1974">(Sörbom, 1974)</span>, <span class="citation" data-cites="Joreskog1978">(Karl G. Jöreskog, 1978)</span> し，現状，共分散構造分析は SEM の特別な場合と解される．<sup>3</sup></p>
</section>
</section>
<section id="スパース推定" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="スパース推定"><span class="header-section-number">2.4</span> スパース推定</h3>
<p>FA のモデルは識別可能とは程遠く，解釈可能性が重要である．<span class="citation" data-cites="Thurstone1947">(Thurstone, 1947)</span> は因子付加行列が「単純構造」を持つことを一つの指標としたが，現代的にはスパース推定の言葉で与えられた <strong>完全単純構造</strong> <span class="citation" data-cites="Bernaards-Jennrich2003">(Bernaards and Jennrich, 2003)</span> を仮定することが増えてきた．</p>
<p><strong>スパース PCA</strong> <span class="citation" data-cites="Zou+2006">(Zou et al., 2006)</span>, <span class="citation" data-cites="Jolliffe+2003">(Ian T Jolliffe and Uddin, 2003)</span> では，従来の SVD + 回転ではなく，LASSO 様の <img src="https://latex.codecogs.com/png.latex?L%5E1">-正則化項によって，解釈可能な因子付加行列を得ようとする．最終的に得られる目的関数は elastic net <span class="citation" data-cites="Zou-Hastie2005">(Zou and Hastie, 2005)</span> 様になる．</p>
<p>等価だが，自動関連度決定 (ARD) を用いた <strong>Bayesian PCA</strong> <span class="citation" data-cites="Bishop1998">(Bishop, 1998)</span>, <span class="citation" data-cites="Archambeau-Bach2008">(Archambeau and Bach, 2008)</span> や spike-and-slab <span class="citation" data-cites="Rattray+2009">(Rattray et al., 2009)</span> など，スパース性を促す事前分布を用いることもできる．</p>
</section>
<section id="sec-other-priors-FA" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="sec-other-priors-FA"><span class="header-section-number">2.5</span> その他の事前分布</h3>
<p>非正規な事前分布（特に Laplace 分布やロジスティック分布などの裾の重いもの）を用いることで，モデルが識別可能性を回復することがある．</p>
<p>このように，<a href="../../../posts/2024/Kernels/NCL.html#sec-identifiability">一般の設定で潜在変数モデルが識別可能になるための条件が，非線型独立分析の分野で提案されている</a> <span class="citation" data-cites="Khemakhem+2020">(Khemakhem et al., 2020)</span>．</p>
<section id="gamma-分布" class="level4" data-number="2.5.1">
<h4 data-number="2.5.1" class="anchored" data-anchor-id="gamma-分布"><span class="header-section-number">2.5.1</span> Gamma 分布</h4>
<p>また，Gamma 事前分布は非負かつスパースな表現を促進し，カウントデータとよく用いられる <span class="citation" data-cites="Canny2004">(Canny, 2004)</span>．</p>
<p>これは環境科学分野の Positive Matrix Factorization <span class="citation" data-cites="Paatero-Tapper1994">(Paatero and Tapper, 1994)</span> や信号処理分野の Nonnegative Matrix Factorization (NMF) <span class="citation" data-cites="Lee-Seung1999">(Lee and Seung, 1999)</span> の，確率論的な一般化と見れる <span class="citation" data-cites="Buntine-Jakulin2006">(Buntine and Jakulin, 2006)</span>．</p>
</section>
<section id="dirichlet-分布" class="level4" data-number="2.5.2">
<h4 data-number="2.5.2" class="anchored" data-anchor-id="dirichlet-分布"><span class="header-section-number">2.5.2</span> Dirichlet 分布</h4>
<p>また，Dirichlet 事前分布を用いることで，潜在変数 <img src="https://latex.codecogs.com/png.latex?Z%5Cin%5Cmathcal%7BL%7D(%5COmega;%5Cmathbb%7BR%7D%5Er)"> に <img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi=1%7D%5ErZ%5Ei=1%0A"> が課されるため，「各次元への依存度」のような意味づけが可能になる．これは政治学における空間分析において，「どの立場への傾倒が強いか」を推定することにも用いられる <span class="citation" data-cites="Buntine-Jakulin2006">(Buntine and Jakulin, 2006)</span>．</p>
<p>このモデルは multinomial PCA <span class="citation" data-cites="Buntine-Jakulin2006">(Buntine and Jakulin, 2006)</span> の他に，遺伝学で admixture <span class="citation" data-cites="Pritchard+2000">(Pritchard et al., 2000)</span>，simplex factor analysis <span class="citation" data-cites="Bhattacharya-Dunson2012">(Bhattacharya and Dunson, 2012)</span>, 科学出版で mixed-membership model <span class="citation" data-cites="Erosheva+2004">(Erosheva et al., 2004)</span>，マーケティングで user rating profile model <span class="citation" data-cites="Marlin2003">(Marlin, 2003)</span> など，種々の分野で独立に提案されている．</p>
</section>
</section>
<section id="非線型化" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="非線型化"><span class="header-section-number">2.6</span> 非線型化</h3>
<p>FA の一般化の方向性として，正規性の緩和の他に，線型性の緩和があり得る．</p>
<p>MCMC による推論 <span class="citation" data-cites="Hoffman2017">(Hoffman, 2017)</span> をすることも，または指数型分布 <span class="citation" data-cites="Collins+2001">(Collins et al., 2001)</span> への拡張や，VAE による非線型化を通じて変分推論をすることも考えられる．</p>
<p><a href="../../../posts/2024/Kernels/Deep4.html#sec-AE">自己符号化器</a> は，まさに非線型な潜在変数モデルに対する最尤推定を行っており，４層以上のニューラルネットワークを用いることで PCA を非線型化して一般化することができる．<sup>4</sup></p>
<p>また，カーネル法と Gauss 過程により非線型化することもできる <span class="citation" data-cites="Lawrence2005">(Lawrence, 2005)</span>．</p>
</section>
<section id="sec-MixFA" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="sec-MixFA"><span class="header-section-number">2.7</span> 混合モデリング</h3>
<p>複数の線型 Gauss 因子分析モデルの重ね合わせとみなす <strong>mixture of factor analysers</strong> <span class="citation" data-cites="Ghahramani-Hinton1996">(Ghahramani and Hinton, 1996)</span> も単純ながら表現が高く，EM アルゴリズムや SGD <span class="citation" data-cites="Ricahrdson-Weiss2018">(Richardson and Weiss, 2018)</span>, <span class="citation" data-cites="Zong+2018">(Zong et al., 2018)</span> によって推定できる．</p>
<p><span class="citation" data-cites="Ricahrdson-Weiss2018">(Richardson and Weiss, 2018)</span> では生成モデルとしての性能も GAN と劣らないこと，VAE や GAN などの生成モデルよりも分布へのフィッティングが良いことを報告している．</p>
<p>さらにこのアプローチはノンパラメトリックベイズ法につながる．この方法では，例えば <span class="citation" data-cites="Paisley-Carin2009">(Paisley and Carin, 2009)</span> では Beta 過程事前分布をおき，Gibbs サンプラーで推論することで，混合数 <img src="https://latex.codecogs.com/png.latex?K"> も同時に自動で決定できる．</p>
</section>
</section>
<section id="sec-SEM" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="sec-SEM"><span class="header-section-number">3</span> 構造方程式モデリング (SEM)</h2>
<section id="はじめに-3" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="はじめに-3"><span class="header-section-number">3.1</span> はじめに</h3>
<p><span class="citation" data-cites="Joreskog1969">(K. G. Jöreskog, 1969)</span> は因子分析モデルを潜在変数モデルとして，事前情報を取り入れるなど柔軟に用いた．</p>
<p>特に，データを（現代でいう）訓練データと検証データに分けて，因子分析により推定された潜在変数間の関数関係を検定するための方法を提案し <span class="citation" data-cites="Joreskog-Lawley1968">(K. G. Jöreskog and Lawley, 1968)</span>，これを <strong>検証的因子分析</strong> (Confirmatory FA) と呼び，それ以前の手法に <strong>探索的因子分析</strong> というレトロニムを与えた．<sup>5</sup></p>
<p>最終的に，潜在変数同士により一般的な関数関係も考慮したものなど多くの潜在変数モデルが，共分散構造に基づいた非線型数値最適化を推論エンジンとして統一的に推定できることに辿り着いた．<sup>6</sup></p>
<p>このことに加えて，潜在変数間の関数関係に適切な仮定をおくことで，因果推論・高次の因子分析・分散分析など従来考慮されなかった新たなタスクにも適用可能であることも了解された <span class="citation" data-cites="Joreskog1978">(Karl G. Jöreskog, 1978)</span>, <span class="citation" data-cites="Bentler1980">(Bentler, 1980)</span>．<sup>7</sup></p>
<p>現代では特徴抽出，生成，表現学習にも用いられていると思うと感慨である．</p>
<p>これを <strong>共分散構造分析</strong> または <strong>構造方程式モデリング</strong> (SEM: Structural Equation Modeling) という．<sup>8</sup> 心理学の文脈では，潜在変数のことを <strong>構成概念</strong> (construct) と呼び，潜在変数間は無関係とした従来の因果分析モデルを <strong>測定方程式</strong> と呼ぶ．<sup>9</sup></p>
</section>
<section id="sec-PLS" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="sec-PLS"><span class="header-section-number">3.2</span> 部分最小自乗モデル (PLS)</h3>
<p>PLS (Partial Least Square) モデル <span class="citation" data-cites="Joreskog-Wold1982">(K. G. Jöreskog and Wold, 1982)</span>, <span class="citation" data-cites="Gustafsson2001">(Gustafsson, 2001)</span> では，次のような潜在変数モデルを用いて，２つの構成概念間の因果関係を評価しようとする <span class="citation" data-cites="豊田秀樹1991">(豊田秀樹, 1991)</span>：</p>
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/PLS.svg" class="img-fluid"></p>
<p>なお，パス図において，潜在変数から観測変数に矢印が伸びている場合，これは影響的指標と呼ばれ，観測のモデルと解され，誤差が入ることが想定される <span class="citation" data-cites="豊田秀樹1991">(豊田秀樹, 1991)</span>．<sup>10</sup> 逆の矢印は形成的指標という．</p>
<p>すなわち，PLS では，<img src="https://latex.codecogs.com/png.latex?X%5E1,X%5E2,X%5E3,%5Ccdots"> には，<img src="https://latex.codecogs.com/png.latex?Z%5E1,Z%5E2,%5Ccdots"> とは独立な独自因子が作用していると仮定されている．</p>
<p>このような仮定は，<img src="https://latex.codecogs.com/png.latex?Y%5E1,Y%5E2,%5Ccdots"> を被説明変数として，教師あり PCA <span class="citation" data-cites="Yu+2006">(Yu et al., 2006)</span> に有用である．</p>
<p>というのも，被説明変数のうち必ずしも <img src="https://latex.codecogs.com/png.latex?Y%5E1,Y%5E2,%5Ccdots"> に関係する要素が全てとは限らないために，<img src="https://latex.codecogs.com/png.latex?Z%5E1,Z%5E2"> の間で間接的に回帰分析を行いたい場合に自然な設定である <span class="citation" data-cites="Nounou+2002">(Nounou et al., 2002)</span>．</p>
</section>
<section id="構造方程式モデリングの発展" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="構造方程式モデリングの発展"><span class="header-section-number">3.3</span> 構造方程式モデリングの発展</h3>
<p>PLS において，潜在変数から構成概念への矢印が全て影響的であった場合，これは潜在因子の間に関係が仮定されていることを除いて，（探索的）因子分析と等価になる．</p>
<p>一般に，SEM は，潜在変数同士の関数関係も考慮した因子分析モデルだと理解できる．</p>
<p>このようなモデルは，社会学において <strong>多重指標分析</strong> と呼ばれていたモデルに相当し <span class="citation" data-cites="白倉幸男1984">(白倉幸男, 1984)</span> <span class="citation" data-cites="清水和秋1989">(清水和秋, 1989)</span>，経済学において <strong>同時方程式モデル</strong> と呼ばれていたモデルに相当する <span class="citation" data-cites="Bentler1980">(Bentler, 1980)</span>．<sup>11</sup></p>
<p>加えて，心理学・行動計量学においても，多くの既存の多変量解析法（因子分析，パス解析，二段階抽出モデル，潜在構造分析，項目反応モデルな）はいずれも SEM の特殊な形だと解釈できることが自覚された <span class="citation" data-cites="McArdle1984">(McArdle, 1984)</span>, <span class="citation" data-cites="Muthen2002">(Muthén, 2002)</span>．</p>
<p>こうして SEM の名と LISREL プログラムの下で，多くの社会科学分野で使われていたモデルが，形式的にはほとんど等価であるという了解が形成されていった．</p>
<p>このことから，SEM は第二世代の多変量解析 <span class="citation" data-cites="Fornell1985">(Fornell, 1985)</span> とも評される．<sup>12</sup></p>
</section>
<section id="計算統計学という要素" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="計算統計学という要素"><span class="header-section-number">3.4</span> 計算統計学という要素</h3>
<p>構造方程式モデリングが普及した理由の一つとして，計算機統計学の発展とうまく合流した点が見逃せない．</p>
<p>そもそも Jöreskog は，因子分析を研究していた時期 <span class="citation" data-cites="Joreskog1966">(Karl G. Jöreskog, 1966)</span> <span class="citation" data-cites="Joreskog1967a">(K. G. Jöreskog, 1967)</span> から，数値的な解法とコンピュータプログラムの開発にも重点を置いていた．特に，因子分析モデルを，<a href="https://ja.wikipedia.org/wiki/DFP法">DFP 法</a> に基づいて数値的に最尤推定する方法を提案した <span class="citation" data-cites="Joreskog1967a">(K. G. Jöreskog, 1967)</span>．</p>
<p>SEM も，コンピュータプログラム LISREL (LInear Structural RELationships) <span class="citation" data-cites="Joreskog-vanThillo1972">(Jőreskog and Thiilo, 1972)</span> の存在が，広い分野の人口に膾炙した要因として大きい <span class="citation" data-cites="清水和秋1989">(清水和秋, 1989)</span>, <span class="citation" data-cites="Grimm-Yarnold2016">(Grimm and Yarnold, 2016)</span>．</p>
<p>構造方程式モデルがどのように因子分析，因果分析，共分散構造分析を統合し，LISREL プログラムと共に発展していたかは，<span class="citation" data-cites="清水和秋1994">(清水和秋, 1994)</span> に大変わかりやすくまとまっている</p>
</section>
<section id="sec-CCA" class="level3" data-number="3.5">
<h3 data-number="3.5" class="anchored" data-anchor-id="sec-CCA"><span class="header-section-number">3.5</span> 正準相関分析 (CCA)</h3>
<p>正準相関分析 <span class="citation" data-cites="Hotelling36">(Hotelling, 1936)</span> においては，２つの構成概念の間は相関関係で結び，すべての観測は形成的な影響を及ぼすとする（観測誤差は想定しない） <span class="citation" data-cites="豊田秀樹1991">(豊田秀樹, 1991)</span>：</p>
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/CCA.svg" class="img-fluid"></p>
<p>このモデルでは <img src="https://latex.codecogs.com/png.latex?X%5E1,X%5E2,X%5E3"> とその潜在要因 <img src="https://latex.codecogs.com/png.latex?Z%5E1">，<img src="https://latex.codecogs.com/png.latex?X%5E4,X%5E5"> とその潜在要因 <img src="https://latex.codecogs.com/png.latex?Z%5E2"> とを完全に対等に扱い，その間の関係を理解しようとする．</p>
<p>例えばマルチモーダル学習において，<img src="https://latex.codecogs.com/png.latex?X,Y"> が類似したタスクに関するデータという場合に応用がある <span class="citation" data-cites="岩瀬-中山2016">(岩瀬智亮 and 中山英樹, 2016)</span>．また，PLS と共に特徴抽出にも用いられる <span class="citation" data-cites="Sun+2009">(Sun et al., 2009)</span>．</p>
<p>複数の標本に対して同時に実行する主成分分析ともみなせるが，別々に PCA を実行した場合と違い「共通要因」を抽出することに志向がある <span class="citation" data-cites="赤穂昭太郎2013">(赤穂昭太郎, 2013)</span>．</p>
<p>なお，正準相関分析が，このような確率論的解釈ができることは <span class="citation" data-cites="Bach-Jordan2005">(Bach and Jordan, 2005)</span> で自覚されたことである．</p>
<p>この潜在変数モデルとしての観点から，<img src="https://latex.codecogs.com/png.latex?Z%5E3,Z%5E4,%5Ccdots"> がある GCCA (Generalized CCA) <span class="citation" data-cites="Horst1961">(Horst, 1961)</span>，指数分布族の場合 <span class="citation" data-cites="Klami+2010">(Klami et al., 2010)</span>，ニューラルネットワークにより非線型にした DCCA <span class="citation" data-cites="Andrew+2013">(Andrew et al., 2013)</span>，さらに変分推論する場合 <span class="citation" data-cites="Wang+2017">(Wang et al., 2017)</span>, <span class="citation" data-cites="Suzuki+2017">(Suzuki et al., 2017)</span> に拡張されている．</p>
<p>質的データをダミーベクトルに変換して（一般化）正準相関分析を行う，質的データの解析法を <strong>対応分析</strong> (correspondence analysis) または <strong>数量化第III類</strong> ともいう．<sup>13</sup></p>
</section>
</section>
<section id="sec-MM" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="sec-MM"><span class="header-section-number">4</span> 混合モデル (MM)</h2>
<section id="はじめに-4" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="はじめに-4"><span class="header-section-number">4.1</span> はじめに</h3>
<p>混合モデルは，次のようなたいへん基本的な設定であるが，第 2.7 節で見たように，例えば因子分析モデルと組み合わせることで極めて豊かな表現力を持つ．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/MM.svg" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>混合モデルは SEM の別の選択肢としても使える．また，ランダム効果要因を明示的にモデルに組み込む意味で，一般線型モデルの確率論的な拡張と考えることもできる <span class="citation" data-cites="狩野裕2002">(狩野裕, 2002)</span>．<sup>14</sup></p>
</section>
<section id="正規混合モデル-gmm" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="正規混合モデル-gmm"><span class="header-section-number">4.2</span> 正規混合モデル (GMM)</h3>
<p><img src="https://latex.codecogs.com/png.latex?Z%5Cin%5Cmathcal%7BL%7D(%5COmega;%5BK%5D)"> は <img src="https://latex.codecogs.com/png.latex?%0A%5BK%5D=%5C%7B1,%5Ccdots,K%5C%7D%0A"> に値を取る離散確率変数で，確率核 <img src="https://latex.codecogs.com/png.latex?Z%5Cto%20X"> が <img src="https://latex.codecogs.com/png.latex?%0Ap(x%7Cz=k)%5C,dx=%5Cmathrm%7BN%7D_p(%5Cmu_k,%5CSigma_k)%0A"> と表せる場合，<img src="https://latex.codecogs.com/png.latex?X"> に課される仮定を <strong>正規混合モデル</strong> (GMM: Gaussian Mixture Model) という．</p>
<p><img src="https://latex.codecogs.com/png.latex?Z%5Csim%5Cmathrm%7BU%7D(%5BK%5D),%5CSigma_k=I"> の場合，これは <a href="../../../posts/2024/Computation/VI2.html#sec-EM-and-K-means"><img src="https://latex.codecogs.com/png.latex?K">-平均クラスタリングに等価</a> なモデルとなる．</p>
<p>これは SGD により訓練をすることで，生成のタスクにおいても GAN に匹敵する性能も持つ <span class="citation" data-cites="Ricahrdson-Weiss2018">(Richardson and Weiss, 2018)</span>．</p>
<p>また，デノイジングや deblurring, inpainting, super-resolution などの画像逆問題は，巨大な GMM の潜在変数の推定として理解できる <span class="citation" data-cites="Zoran-Weiss2011">(Zoran and Weiss, 2011)</span>, <span class="citation" data-cites="Papyam-Elad2016">(Papyan and Elad, 2016)</span>．</p>
</section>
<section id="正規スケール混合モデル-gsm" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="正規スケール混合モデル-gsm"><span class="header-section-number">4.3</span> 正規スケール混合モデル (GSM)</h3>
<p>Gaussian scale mixture モデルとは， <img src="https://latex.codecogs.com/png.latex?%0Ap(x%7Cz)%5C,dx=%5Cmathrm%7BN%7D_p(0,%5Csigma_0%5E2z)%0A"> で定まる階層モデルである．</p>
<p>このモデルは，<img src="https://latex.codecogs.com/png.latex?Z"> の分布により，種々の（特に裾の重い）分布を表せる：</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?Z%5Csim%5Cmathrm%7BBer%7D(%5Cpi)"> のときを spike and slab 分布という： <img src="https://latex.codecogs.com/png.latex?%0Ap(x)%5C,dx=%5Cpi%5Cmathrm%7BN%7D(0,%5Csigma_0%5E2)+(1-%5Cpi)%5Cdelta_0.%0A"></li>
<li><img src="https://latex.codecogs.com/png.latex?Z%5Csim%5Cmathrm%7BC%7D(1)_+"> のとき，<strong>馬蹄分布</strong> <span class="citation" data-cites="Carvalho+2010">(Carvalho et al., 2010)</span> という．<sup>15</sup></li>
</ol>
</div>
</div>
</div>
</section>
<section id="潜在-dirichlet-配分-lda" class="level3" data-number="4.4">
<h3 data-number="4.4" class="anchored" data-anchor-id="潜在-dirichlet-配分-lda"><span class="header-section-number">4.4</span> 潜在 Dirichlet 配分 (LDA)</h3>
<section id="はじめに-5" class="level4" data-number="4.4.1">
<h4 data-number="4.4.1" class="anchored" data-anchor-id="はじめに-5"><span class="header-section-number">4.4.1</span> はじめに</h4>
<p>文書の埋め込み・数値表現を得るために，単語 <img src="https://latex.codecogs.com/png.latex?i%5Cin%5BM%5D"> が文書 <img src="https://latex.codecogs.com/png.latex?j%5Cin%5BN%5D"> に現れた回数をカウントした行列 <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BC%7D%5Cin%20M_%7BMN%7D(%5Cmathbb%7BN%7D)"> を通じた主成分分析が用いることも考えられる．</p>
<p>これを <strong>潜在意味索引</strong> (LSI: Latent Semantic Indexing) <span class="citation" data-cites="Deerwester+1990">(Deerwester et al., 1990)</span> と呼ぶ．得られた低次元埋め込みを文書検索 (document retrieval) などに用いることもできる．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7BC%7D"> の列も単語とし，帯幅 <img src="https://latex.codecogs.com/png.latex?h%3E0"> を決めて，<img src="https://latex.codecogs.com/png.latex?h"> 文字以内に単語 <img src="https://latex.codecogs.com/png.latex?i,j%5Cin%5BM%5D"> が共起した回数を <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D"> とすると，全く同様の手続きが，単語の埋め込みに応用できる．これを <a href="https://ja.wikipedia.org/wiki/潜在意味解析"><strong>潜在意味解析</strong></a> (LSA: Latent Semantic Analysis) <span class="citation" data-cites="Deerwester+1990">(Deerwester et al., 1990)</span> と呼ぶ．</p>
</section>
<section id="sec-PLSI" class="level4" data-number="4.4.2">
<h4 data-number="4.4.2" class="anchored" data-anchor-id="sec-PLSI"><span class="header-section-number">4.4.2</span> 確率的潜在意味索引 (PLSI)</h4>
<p><span class="citation" data-cites="Hofmann1999">(Hofmann, 1999)</span> による pLSI または aspect model は LSI を確率モデル，特に混合モデルとして解釈し直したものである．</p>
<p>単語数よりも少ない数の <strong>トピック</strong> <img src="https://latex.codecogs.com/png.latex?Z"> というものがあり，これが単語を決めている，というモデルを想定した．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/PLSI.svg" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>このモデルを通じて，トピック <img src="https://latex.codecogs.com/png.latex?Z"> の分布（あるいは，現代的には <img src="https://latex.codecogs.com/png.latex?%5CTheta"> の値）を「文書」の特徴量とする，というアイデアである．</p>
</section>
<section id="sec-LDA" class="level4" data-number="4.4.3">
<h4 data-number="4.4.3" class="anchored" data-anchor-id="sec-LDA"><span class="header-section-number">4.4.3</span> Dirichlet 事前分布の追加</h4>
<p>変数 <img src="https://latex.codecogs.com/png.latex?%5CTheta"> に Dirichlet 事前分布を追加し，完全なベイズの見方を提示したのが Latent Dirichlet Allocation <span class="citation" data-cites="Blei+2003">(Blei et al., 2003)</span> である．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5CTheta"> を文書，<img src="https://latex.codecogs.com/png.latex?Z"> トピック，<img src="https://latex.codecogs.com/png.latex?W"> をトピックごとの語彙デッキとする．</p>
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/LDA.svg" class="img-fluid"></p>
<p>最終的に，トピック <img src="https://latex.codecogs.com/png.latex?Z"> とその人の語彙 <img src="https://latex.codecogs.com/png.latex?W"> が合わさって，単語 <img src="https://latex.codecogs.com/png.latex?X"> が観測されるというモデルが考えられている．</p>
</section>
<section id="確率的トピックモデル" class="level4" data-number="4.4.4">
<h4 data-number="4.4.4" class="anchored" data-anchor-id="確率的トピックモデル"><span class="header-section-number">4.4.4</span> 確率的トピックモデル</h4>
<p>自然言語処理において，単語分布のモデリングの潜在変数は <strong>トピック</strong> と呼ばれて，これを確率的にモデリングする手法は PTM (Probabilistic Topic Model) <span class="citation" data-cites="Blei2012">(Blei, 2012)</span> と呼ばれている．</p>
<p>「トピック」は短い文章の中でも激しく移り変わることが知られている <span class="citation" data-cites="Church-Gale1991">(Church and Gale, 1991)</span>．</p>
<p>そのため，LDA では，<img src="https://latex.codecogs.com/png.latex?%5CTheta"> の事前分布と <img src="https://latex.codecogs.com/png.latex?W"> の事前分布は， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7BDirichlet%7D(%5Calpha%5Cboldsymbol%7B1%7D),%5Cqquad%5Calpha%3E0,%0A"> という形で，極めて小さい <img src="https://latex.codecogs.com/png.latex?%5Calpha%3E0"> を設定し，特定のトピックがどの文書に現れるかは極めてスパースになるようにモデリングをする．</p>
</section>
<section id="推論" class="level4" data-number="4.4.5">
<h4 data-number="4.4.5" class="anchored" data-anchor-id="推論"><span class="header-section-number">4.4.5</span> 推論</h4>
<p>LDA の推論手法には変分推論 <span class="citation" data-cites="Blei+2003">(Blei et al., 2003)</span> や Gibbs サンプリング <span class="citation" data-cites="Griffith-Steyvers2004">(T. L. Griffiths and Steyvers, 2004)</span>，そしてスペクトルに基づく方法 <span class="citation" data-cites="Arova+2013">(Arora et al., 2013)</span> がある．</p>
<p>トピック数の決定には，尤度を <a href="../../../posts/Surveys/SMCSamplers.html#sec-AIS">焼なまし重点サンプリング</a> で計算する方法 <span class="citation" data-cites="Wallach+2009">(Wallach et al., 2009)</span> の他，ノンパラメトリックベイズ法も用いられる <span class="citation" data-cites="Teh+2006">(Yee Whye Teh and Blei, 2006)</span>．</p>
</section>
<section id="時系列化" class="level4" data-number="4.4.6">
<h4 data-number="4.4.6" class="anchored" data-anchor-id="時系列化"><span class="header-section-number">4.4.6</span> 時系列化</h4>
<p>単語の並びは明らかな方向性があり，対照的なモデリングはこの消息を取り逃がしていると考えられる．</p>
<p>そこで，トピックの移り変わりを捉えるモデルとして dynamic topic model <span class="citation" data-cites="Blei+2006">(Blei and Lafferty, 2006)</span> がある．これは Kalman 平滑化と変分推論を組み合わせている様である．</p>
<p>また単語の時系列構造を捉えるために，LDA に隠れ Markov モデルを組み合わせた LDA-HMM <span class="citation" data-cites="Griffiths+2004">(T. Griffiths et al., 2004)</span> が提案された．TopicRNN <span class="citation" data-cites="Dieng+2017">(Dieng et al., 2017)</span> ではより長距離の相関を捉えるために，<a href="../../../posts/2024/Kernels/Deep.html#sec-RNN2">RNN</a> と組み合わせている．</p>
</section>
</section>
<section id="sec-SSM" class="level3" data-number="4.5">
<h3 data-number="4.5" class="anchored" data-anchor-id="sec-SSM"><span class="header-section-number">4.5</span> 状態空間モデル (SSM)</h3>
<section id="概要-2" class="level4" data-number="4.5.1">
<h4 data-number="4.5.1" class="anchored" data-anchor-id="概要-2"><span class="header-section-number">4.5.1</span> 概要</h4>
<p>状態空間モデル (State Space Model) は，混合モデルの時系列化と捉えられる：</p>
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/SSM.svg" class="img-fluid"></p>
<p>潜在変数 <img src="https://latex.codecogs.com/png.latex?X_t"> が離散的である場合は特に <strong>隠れ Markov モデル</strong> (HMM: Hidden Markov Model) <span class="citation" data-cites="Baum-Petrie1966">(Baum and Petrie, 1966)</span> と呼ばれる．</p>
<p>HMM に関しては早くから EM 様の推定手法 <strong>Baum-Welch アルゴリズム</strong> <span class="citation" data-cites="Baum-Eagon1967">(Baum and Eagon, 1967)</span>, <span class="citation" data-cites="Baum+1970">(Baum et al., 1970)</span> が提案されているが，データサイズが大きい場合は SGD が用いられる．Blocked Gibbs サンプラー <span class="citation" data-cites="Scott2002">(Scott, 2002)</span> や，潜在変数を消去して，周辺尤度に関してスペクトル法／テンソル分解 <span class="citation" data-cites="Hsu+2012">(Hsu et al., 2012)</span>, <span class="citation" data-cites="Anandkumar+2012">(Animashree Anandkumar et al., 2012)</span>, <span class="citation" data-cites="Anandkumar+2015">(Anima Anandkumar et al., 2015)</span>, <span class="citation" data-cites="Obermeyer+2019">(Obermeyer et al., 2019)</span> を実行するなどの代替手法がある．</p>
</section>
<section id="sec-S4" class="level4" data-number="4.5.2">
<h4 data-number="4.5.2" class="anchored" data-anchor-id="sec-S4"><span class="header-section-number">4.5.2</span> 構造的状態系列モデル (S4)</h4>
<p>S4 (Structured State Space Sequence) <span class="citation" data-cites="Gu+2022">(Gu et al., 2022)</span>, <span class="citation" data-cites="Gu+2020">(Gu et al., 2020)</span>, <span class="citation" data-cites="Goel+2022">(Goel et al., 2022)</span> とは，時系列を深層ニューラルネットワークの力でモデリングするために，線型 Gauss で単純な SMM を上下にスタックし深層にしたものである．各層は LSSL (Linear State Space Layer) と呼ばれる．</p>
<p>さらに長距離の依存性に耐えるために，S5 <span class="citation" data-cites="Smith+2023">(Smith et al., 2023)</span> や Mamba <span class="citation" data-cites="Gu-Dao2024">(Gu and Dao, 2024)</span> が提案されている．後者では，選択的に記憶を忘却できるような「選択」機構 (S6: Selective SSM) を導入している．</p>
</section>
</section>
</section>
<section id="sec-ICA" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="sec-ICA"><span class="header-section-number">5</span> 独立成分分析 (ICA)</h2>
<section id="はじめに-6" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="はじめに-6"><span class="header-section-number">5.1</span> はじめに</h3>
<p>（線型）独立成分分析で用いるモデルは，PCA や FA のそれと全く変わらず，線型変換 <img src="https://latex.codecogs.com/png.latex?x_n=Az_n"> でデータを説明しようとする：</p>
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/ICA.svg" class="img-fluid"></p>
<p>ただし，潜在変数 <img src="https://latex.codecogs.com/png.latex?Z%5E1,%5Ccdots,Z%5Er"> は互いに <strong>独立</strong> であるという「真の構造」が強く想定される場合に使われる．</p>
<p>加えて，モデルの <strong>識別可能性</strong> を重視する．このために，（独立）因子分析（第 2.5 節）で考えたように，正規分布より裾の重い事前分布を導入することで，モデルの識別可能性を確約する．<sup>16</sup></p>
<p>この意味で，確率モデルとしては PCA / FA に等価であるが，典型的な ICA の文脈では <img src="https://latex.codecogs.com/png.latex?Z%5E1,%5Ccdots,Z%5Er"> は非正規確率変数であり，<img src="https://latex.codecogs.com/png.latex?A"> を生成荷重や混合行列，<img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> を <strong>認識荷重</strong> (recognition weight) などという．</p>
</section>
<section id="推定手法" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="推定手法"><span class="header-section-number">5.2</span> 推定手法</h3>
<p>最初に <a href="https://ja.wikipedia.org/wiki/ブラインド信号源分離">音源分離</a> について適用された <span class="citation" data-cites="Bell-Sejnowski1995">(Bell and Sejnowski, 1995)</span> では，<img src="https://latex.codecogs.com/png.latex?X"> と <img src="https://latex.codecogs.com/png.latex?Z"> の相互情報量の最大化が目指された．</p>
<p>最尤推定は EM アルゴリズムの他に近似 Newton 法で実行されることもあり，fast ICA <span class="citation" data-cites="Hyvarinen-Oja2000">(Hyvärinen and Oja, 2000)</span> と呼ばれる．</p>
<p>また古典的には，探索的データ解析で考案された <strong>射影追跡</strong> (PP: Projection Pursuit) <span class="citation" data-cites="Friedman-Tukey1974">(Friedman and Tukey, 1974)</span> みたく，学習される <img src="https://latex.codecogs.com/png.latex?Z"> の分布が Gauss からなるべく遠いように学習することも考えられた．</p>
<p>disentangled な表現を学習したい場面では，<img src="https://latex.codecogs.com/png.latex?Z"> の成分同士の相関が最小になるように学習される； <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BKL%7D%5Cleft(%5Coperatorname%7BP%7D%5EZ,%5Cbigotimes_%7Bj=1%7D%5Er%5Coperatorname%7BP%7D%5E%7BZ_j%7D%5Cright).%0A"></p>
<p>最小情報コピュラに基づく方法も提案されている <span class="citation" data-cites="Bedford+2016">(Bedford et al., 2016)</span>, <span class="citation" data-cites="Sei-Yano2024">(Sei and Yano, 2024)</span>．</p>
<p>他にも表現学習や認知科学の文脈を踏襲して，<a href="../../../posts/2024/Kernels/NCL.html#sec-InfoMax">InfoMax</a> やスパース符号化などの原則がある．</p>
</section>
<section id="非線型化-1" class="level3" data-number="5.3">
<h3 data-number="5.3" class="anchored" data-anchor-id="非線型化-1"><span class="header-section-number">5.3</span> 非線型化</h3>
<p><a href="../../../posts/2024/Kernels/NCL.html">非線型独立成分分析は，表現学習の文脈でも研究されている</a>．</p>
</section>
</section>
<section id="おわりに" class="level2 unnumbered unlisted">
<h2 class="unnumbered unlisted anchored" data-anchor-id="おわりに">おわりに</h2>
<p>現代の深層生成モデルは，いずれも非線型な潜在変数モデルであると理解できる．</p>
<p>その意味で，次の記事は全て，本稿の続きであり，本稿は現代の機械学習の壮大な序章としても理解できる．</p>
<div id="listing-kernel-listing" class="quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Deep" data-listing-date-sort="1722178800000" data-listing-file-modified-sort="1723479691530" data-listing-date-modified-sort="1723388400000" data-listing-reading-time-sort="2" data-listing-word-count-sort="385">
<a href="../../../posts/2024/Kernels/NCL.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Kernels/Images/contrastive_repr4.jpeg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
表現学習と非線型独立成分分析
</h5>
<div class="card-subtitle listing-subtitle">
「データ理解」に向けた深層潜在変数モデル
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-07-29
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Deep,Nature,Statistics,Geometry" data-listing-date-sort="1722265200000" data-listing-file-modified-sort="1727007847871" data-listing-date-modified-sort="1723647600000" data-listing-reading-time-sort="3" data-listing-word-count-sort="597">
<a href="../../../posts/2024/Kernels/Manifold.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Kernels/Images/UMAPvSNE.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
非線型な次元縮約法の概観
</h5>
<div class="card-subtitle listing-subtitle">
最古にして最難のタスクと多様体学習
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-07-30
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Deep,Survey" data-listing-date-sort="1707577200000" data-listing-file-modified-sort="1727007847868" data-listing-date-modified-sort="1722178800000" data-listing-reading-time-sort="5" data-listing-word-count-sort="883">
<a href="../../../posts/2024/Kernels/Deep.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Kernels/Images/AE.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
数学者のための深層学習概観
</h5>
<div class="card-subtitle listing-subtitle">
歴史と導入
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-11
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
<p>非線形性の他に本稿で扱わなかったものは深層モデルである．</p>
<p>だがそもそも，現代のニューラルネットワークが深層化したのは，単純で可微分なモジュール性を保ちながら表現力を高めるためのトリックであり，確率論的には本稿で扱ったモデルと等価であるはずである．</p>
<p>ニューラルネットワークの他にも，計算のために深層化したモデルを考える場面は多い．例えばアニーリングを用いた <a href="../../../posts/Surveys/SMCSamplers.html">SMC サンプラー</a> は，グラフカルモデル <img src="https://latex.codecogs.com/png.latex?Z%5Cto%20X"> の潜在変数 <img src="https://latex.codecogs.com/png.latex?Z"> の推定を，人工的に時系列構造を見出して状態空間モデル 4.5 にあてはめてサンプリングしやすくする方法と言える．</p>
<p>しかし，<a href="../../../posts/2024/Probability/Kernel.html">確率核は射をなす</a>のだから，全てのモデルは本質的には一層であるとみなすこともできるのである．</p>
<p>この見方をとった方が計算効率が上がるという例もある．例えば <span class="citation" data-cites="Chen+2024">(Chen et al., 2024)</span> では，トランスフォーマーの注意機構をランダム Fourier 特徴写像で近似し，<a href="../../../posts/2024/Kernels/Kernel.html#sec-RFF">Monte Carlo 法によって元のモデルと等価な計算を安価に行っている</a>．</p>
<p><a href="https://puniupa.github.io/posts/2024/AI/BAI.html">ベイズ機械学習</a> や <a href="https://puniupa.github.io/posts/2024/AI/TDL.html">位相的機械学習</a> をはじめとした，丁寧なモデルへの理解が，これからも手法への統一した視点からの理解と，応用分野を横断した相互理解を促進してくれるのではないかと，筆者は意気込んでいる．</p>
</section>




<div id="quarto-appendix" class="default"><section id="扱ったモデル一覧" class="level2 appendix unnumbered"><h2 class="anchored quarto-appendix-heading">扱ったモデル一覧</h2><div class="quarto-appendix-contents">

<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row quarto-layout-valign-bottom">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/PCA.svg" class="img-fluid figure-img"></p>
<figcaption>PCA</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/FA.svg" class="img-fluid figure-img"></p>
<figcaption>FA</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-bottom">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/PLS.svg" class="img-fluid figure-img"></p>
<figcaption>PLS</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/CCA.svg" class="img-fluid figure-img"></p>
<figcaption>CCA</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-bottom">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/PLSI.svg" class="img-fluid figure-img"></p>
<figcaption>PLSI</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/LDA.svg" class="img-fluid figure-img"></p>
<figcaption>LDA</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-bottom">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/SSM.svg" class="img-fluid figure-img"></p>
<figcaption>SSM</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/ICA.svg" class="img-fluid figure-img"></p>
<figcaption>ICA</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/HierarchicalModels.png" class="img-fluid figure-img"></p>
<figcaption><span class="citation" data-cites="Murphy2023">(Murphy, 2023, p. 920)</span> より，本稿で扱ったモデルのいくつかを含んだ，数式による一覧表．すでに図式による解説を受けた後だと，より見やすいだろう．<img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7BCat%7D(c%7C%5Cboldsymbol%7B%5Cpi%7D)"> は確率ベクトル <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Cpi%7D"> が定める質量関数を表す．</figcaption>
</figure>
</div>
</div></section><section id="付録" class="level2 unnumbered appendix"><h2 class="anchored quarto-appendix-heading">付録</h2><div class="quarto-appendix-contents">

<p>ここでは，歴史を感じる引用をいくつか紹介したい．</p>
<blockquote class="blockquote">
<p>心理測定学 (psychometrics) における因子分析，計量経済学 (econometrics) における同時方程式モデル (simultaneous equation models), そして生物測定学 (biometrics) におけるパス解析 (path analysis) を，共分散構造分析の下に統一化することが可能となった契機は，潜在変数 (latent variables) の概念である <span class="citation" data-cites="Bentler1980">(Bentler, 1980)</span>．<span class="citation" data-cites="清水和秋1989">(清水和秋, 1989)</span></p>
</blockquote>
<p>そして，異分野横断の知見交流が進んだ契機の一つは，LISREL プログラムの存在であった．<span class="citation" data-cites="清水和秋1994">(清水和秋, 1994)</span> では，ETS での安定した研究環境が LISREL の継続的な保守を可能にして最終的には WINDOWS 上でも安定して提供され，これを用いることを通じて異分野を巻き込みながら構造方程式モデリングが発展していった様子が詳細に解説されている．LISREL はバージョン VI まである．</p>
<blockquote class="blockquote">
<p>紹介した文献からもわかるように，この分野は最近になってやっと日本では注目されてようになってきた。 このように日本へのこの方法論の導入が遅れた理由の一つはソフト流通の問題にあると筆者は考えている。青木 (1988) や土田 (1988) が述べているように， LISREL は大型計算機の場合， アメリカ産のコンビュータでしかサポートしてくれないとのことである。<span class="citation" data-cites="清水和秋1989">(清水和秋, 1989)</span></p>
</blockquote>
<p>そして現代はというと，計算機統計学と機械学習が先行し（過ぎ）ていると思える．</p>
<p>もしその通りならば，種々の科学への応用とそれぞれ固有の課題への特殊化が，これからの未来を彩ってくれるのかもしれない．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Anandkumar+2015" class="csl-entry">
Anandkumar, Anima, Ge, R., Hsu, D., Kakade, S. M., and Telgarsky, M. (2015). Tensor decompositions for learning latent variable models (a survey for ALT). In K. Chaudhuri, C. GENTILE, and S. Zilles, editors, <em>Algorithmic learning theory</em>, pages 19–38. Cham: Springer International Publishing.
</div>
<div id="ref-Anandkumar+2012" class="csl-entry">
Anandkumar, Animashree, Hsu, D., and Kakade, S. M. (2012). <a href="https://proceedings.mlr.press/v23/anandkumar12.html">A method of moments for mixture models and hidden markov models</a>. In S. Mannor, N. Srebro, and R. C. Williamson, editors, <em>Proceedings of the 25th annual conference on learning theory</em>,Vol. 23, pages 33.1–33.34. Edinburgh, Scotland: PMLR.
</div>
<div id="ref-Anderson-Rubin1956" class="csl-entry">
Anderson, T. W., and Rubin, H. (1956). <a href="https://projecteuclid.org/proceedings/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-Third-Berkeley-Symposium-on-Mathematical-Statistics-and/Chapter/Statistical-Inference-in-Factor-Analysis/bsmsp/1200511860">Statistical inference in factor analysis</a>. In <em>Proceedings of the thrid berkeley symposium on mathematical statistics and probability</em>,Vol. 5, pages 111–150.
</div>
<div id="ref-Andrew+2013" class="csl-entry">
Andrew, G., Arora, R., Bilmes, J., and Livescu, K. (2013). <a href="https://proceedings.mlr.press/v28/andrew13.html">Deep canonical correlation analysis</a>. In S. Dasgupta and D. McAllester, editors, <em>Proceedings of the 30th international conference on machine learning</em>,Vol. 28, pages 1247–1255. Atlanta, Georgia, USA: PMLR.
</div>
<div id="ref-Archambeau-Bach2008" class="csl-entry">
Archambeau, C., and Bach, F. (2008). <a href="https://proceedings.neurips.cc/paper_files/paper/2008/file/d93ed5b6db83be78efb0d05ae420158e-Paper.pdf">Sparse probabilistic projections</a>. In D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, <em>Advances in neural information processing systems</em>,Vol. 21. Curran Associates, Inc.
</div>
<div id="ref-Arova+2013" class="csl-entry">
Arora, S., Ge, R., Halpern, Y., Mimno, D., Moitra, A., Sontag, D., … Zhu, M. (2013). <a href="https://proceedings.mlr.press/v28/arora13.html">A practical algorithm for topic modeling with provable guarantees</a>. In S. Dasgupta and D. McAllester, editors, <em>Proceedings of the 30th international conference on machine learning</em>,Vol. 28, pages 280–288. Atlanta, Georgia, USA: PMLR.
</div>
<div id="ref-Asher83-Causal" class="csl-entry">
Asher, H. B. (1983). <em>Causal modelling</em>,Vol. 3. 和訳は心理学者広瀬弘忠による『因果分析法』（朝倉書店，1980）; SAGE Publications, Inc.
</div>
<div id="ref-Bach-Jordan2005" class="csl-entry">
Bach, F. R., and Jordan, M. I. (2005). <em>A probabilistic interpretation of canonical correlation analysis</em>. University of California, Berkeley. Retrieved from <a href="https://statistics.berkeley.edu/tech-reports/688">https://statistics.berkeley.edu/tech-reports/688</a>
</div>
<div id="ref-Baum-Eagon1967" class="csl-entry">
Baum, L. E., and Eagon, J. A. (1967). An inequality with applications to statistical estimation for probabilistic functions of markov processes and to a model for ecology. <em>Bulletin of the American Mathematical Society</em>, <em>73</em>(3), 360–363.
</div>
<div id="ref-Baum-Petrie1966" class="csl-entry">
Baum, L. E., and Petrie, T. (1966). Statistical inference for probabilistic functions of finite state markov chains. <em>The Annals of Mathematical Statistics</em>, <em>37</em>(6), 1554–1563.
</div>
<div id="ref-Baum+1970" class="csl-entry">
Baum, L. E., Petrie, T., Soules, G., and Weiss, N. (1970). <a href="http://www.jstor.org/stable/2239727">A maximization technique occurring in the statistical analysis of probabilistic functions of markov chains</a>. <em>The Annals of Mathematical Statistics</em>, <em>41</em>(1), 164–171.
</div>
<div id="ref-Bedford+2016" class="csl-entry">
Bedford, T., Daneshkhah, A., and Wilson, K. J. (2016). <a href="https://doi.org/10.1111/risa.12471">Approximate uncertainty modeling in risk analysis with vine copulas</a>. <em>Risk Analysis</em>, <em>36</em>(4), 792–815.
</div>
<div id="ref-Bell-Sejnowski1995" class="csl-entry">
Bell, A. J., and Sejnowski, T. J. (1995). <a href="https://doi.org/10.1162/neco.1995.7.6.1129"><span class="nocase">An Information-Maximization Approach to Blind Separation and Blind Deconvolution</span></a>. <em>Neural Computation</em>, <em>7</em>(6), 1129–1159.
</div>
<div id="ref-Bentler1980" class="csl-entry">
Bentler, P. M. (1980). <a href="https://doi.org/10.1146/annurev.ps.31.020180.002223">Multivariate analysis with latent variables: Causal modeling</a>. <em>Annual Review of Psychology</em>, <em>31</em>(Volume 31, 1980), 419–456. Journal Article.
</div>
<div id="ref-Bernaards-Jennrich2003" class="csl-entry">
Bernaards, C. A., and Jennrich, R. I. (2003). <a href="https://doi.org/10.1007/BF02295613">Orthomax rotation and perfect simple structure</a>. <em>Psychometrika</em>, <em>68</em>(4), 585–588.
</div>
<div id="ref-Bhattacharya-Dunson2012" class="csl-entry">
Bhattacharya, A., and Dunson, D. B. (2012). <a href="https://doi.org/10.1080/01621459.2011.646934">Simplex factor models for multivariate unordered categorical data</a>. <em>Journal of the American Statistical Association</em>, <em>107</em>(497), 362–377.
</div>
<div id="ref-Bishop1998" class="csl-entry">
Bishop, C. (1998). <a href="https://proceedings.neurips.cc/paper_files/paper/1998/file/c88d8d0a6097754525e02c2246d8d27f-Paper.pdf">Bayesian PCA</a>. In M. Kearns, S. Solla, and D. Cohn, editors, <em>Advances in neural information processing systems</em>,Vol. 11. MIT Press.
</div>
<div id="ref-Blei2012" class="csl-entry">
Blei, D. M. (2012). <a href="https://doi.org/10.1145/2133806.2133826">Probabilistic topic models</a>. <em>Commun. ACM</em>, <em>55</em>(4), 77–84.
</div>
<div id="ref-Blei+2006" class="csl-entry">
Blei, D. M., and Lafferty, J. D. (2006). <a href="https://doi.org/10.1145/1143844.1143859">Dynamic topic models</a>. In <em>Proceedings of the 23rd international conference on machine learning</em>, pages 113–120. New York, NY, USA: Association for Computing Machinery.
</div>
<div id="ref-Blei+2003" class="csl-entry">
Blei, D. M., Ng, A. Y., and Jordan, M. I. (2003). <a href="https://www.jmlr.org/papers/v3/blei03a.html"><span>Latent Dirichlet Allocation</span></a>. <em>Journal of Machine Learning Research</em>, <em>3</em>, 993–1022.
</div>
<div id="ref-Bock-Bargmann1966" class="csl-entry">
Bock, R. D., and Bargmann, R. E. (1966). <a href="https://doi.org/10.1007/BF02289521">Analysis of covariance structures</a>. <em>Psychometrika</em>, <em>31</em>(4), 507–534.
</div>
<div id="ref-Buntine-Jakulin2006" class="csl-entry">
Buntine, W., and Jakulin, A. (2006). Discrete component analysis. In C. Saunders, M. Grobelnik, S. Gunn, and J. Shawe-Taylor, editors, <em>Subspace, latent structure and feature selection</em>, pages 1–33. Berlin, Heidelberg: Springer Berlin Heidelberg.
</div>
<div id="ref-Canny2004" class="csl-entry">
Canny, J. (2004). <a href="https://doi.org/10.1145/1008992.1009016">GaP: A factor model for discrete data</a>. In <em>Proceedings of the 27th annual international ACM SIGIR conference on research and development in information retrieval</em>, pages 122–129. New York, NY, USA: Association for Computing Machinery.
</div>
<div id="ref-Carvalho+2010" class="csl-entry">
Carvalho, C. M., Polson, N. G., and Scott, J. G. (2010). <a href="https://doi.org/10.1093/biomet/asq017"><span class="nocase">The horseshoe estimator for sparse signals</span></a>. <em>Biometrika</em>, <em>97</em>(2), 465–480.
</div>
<div id="ref-Chen+2024" class="csl-entry">
Chen, H., Liu, Z., Wang, X., Tian, Y., and Wang, Y. (2024). <a href="https://arxiv.org/abs/2403.19928">DiJiang: Efficient large language models through compact kernelization</a>.
</div>
<div id="ref-Church-Gale1991" class="csl-entry">
Church, K. W., and Gale, W. A. (1991). <a href="https://doi.org/10.1007/BF01889984">Probability scoring for spelling correction</a>. <em>Statistics and Computing</em>, <em>1</em>(2), 93–103.
</div>
<div id="ref-Collins+2001" class="csl-entry">
Collins, M., Dasgupta, S., and Schapire, R. E. (2001). <a href="https://proceedings.neurips.cc/paper_files/paper/2001/file/f410588e48dc83f2822a880a68f78923-Paper.pdf">A generalization of principal components analysis to the exponential family</a>. In T. Dietterich, S. Becker, and Z. Ghahramani, editors, <em>Advances in neural information processing systems</em>,Vol. 14. MIT Press.
</div>
<div id="ref-DeLeeuw04-SimultaneousEstimationOfEFA" class="csl-entry">
De Leeuw, J. (2004). <a href="https://doi.org/10.1007/978-1-4020-1958-6_7">Least squares optimal scaling of partially observed linear systems</a>. In <em>Recent developments on structural equation models</em>. Springer Dordrecht.
</div>
<div id="ref-Deerwester+1990" class="csl-entry">
Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., and Harshman, R. (1990). <a href="https://doi.org/10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9">Indexing by latent semantic analysis</a>. <em>Journal of the American Society for Information Science</em>, <em>41</em>(6), 391–407.
</div>
<div id="ref-Dieng+2017" class="csl-entry">
Dieng, A. B., Wang, C., Gao, J., and Paisley, J. (2017). <a href="https://openreview.net/forum?id=rJbbOLcex">Topic<span>RNN</span>: A recurrent neural network with long-range semantic dependency</a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Drineas+2016" class="csl-entry">
Drineas, P., and Mahoney, M. W. (2016). <a href="https://doi.org/10.1145/2842602">RandNLA: Randomized numerical linear algebra</a>. <em>Commun. ACM</em>, <em>59</em>(6), 80–90.
</div>
<div id="ref-Erosheva+2004" class="csl-entry">
Erosheva, E., Fienberg, S., and Lafferty, J. (2004). <a href="https://doi.org/10.1073/pnas.0307760101">Mixed-membership models of scientific publications</a>. <em>Proceedings of the National Academy of Sciences</em>, <em>101</em>(suppl_1), 5220–5227.
</div>
<div id="ref-Fornell1985" class="csl-entry">
Fornell, C. (1985). <em>A second generation of multivariate analysis: Classification of methods and implications for marketing research</em>. Business, Stephen M. Ross School, University of Michigan. Retrieved from <a href="https://hdl.handle.net/2027.42/35621">https://hdl.handle.net/2027.42/35621</a>
</div>
<div id="ref-Friedman-Tukey1974" class="csl-entry">
Friedman, J. H., and Tukey, J. W. (1974). <a href="https://doi.org/10.1109/T-C.1974.224051">A projection pursuit algorithm for exploratory data analysis</a>. <em>IEEE Transactions on Computers</em>, <em>C-23</em>(9), 881–890.
</div>
<div id="ref-Ghahramani-Hinton1996" class="csl-entry">
Ghahramani, Z., and Hinton, G. E. (1996). <em>The EM algorithm for mixtures of factor analyzers</em>. Department of Computer Science, University of Toronto. Retrieved from <a href="https://www.cs.toronto.edu/~hinton/absps/tr96-1.html">https://www.cs.toronto.edu/~hinton/absps/tr96-1.html</a>
</div>
<div id="ref-Ghojogh+2022" class="csl-entry">
Ghojogh, B., Ghodsi, A., Karray, F., and Crowley, M. (2022). <a href="https://arxiv.org/abs/2101.00734">Factor analysis, probabilistic principal component analysis, variational inference, and variational autoencoder: Tutorial and survey</a>.
</div>
<div id="ref-Goel+2022" class="csl-entry">
Goel, K., Gu, A., Donahue, C., and Re, C. (2022). <a href="https://proceedings.mlr.press/v162/goel22a.html">It’s raw! <span>A</span>udio generation with state-space models</a>. In K. Chaudhuri, S. Jegelka, L. Song, C. Szepesvari, G. Niu, and S. Sabato, editors, <em>Proceedings of the 39th international conference on machine learning</em>,Vol. 162, pages 7616–7633. PMLR.
</div>
<div id="ref-Griffith-Steyvers2004" class="csl-entry">
Griffiths, T. L., and Steyvers, M. (2004). <a href="https://doi.org/10.1073/pnas.0307752101">Finding scientific topics</a>. <em>Proceedings of the National Academy of Sciences</em>, <em>101</em>(suppl_1), 5228–5235.
</div>
<div id="ref-Griffiths+2004" class="csl-entry">
Griffiths, T., Steyvers, M., Blei, D., and Tenenbaum, J. (2004). <a href="https://proceedings.neurips.cc/paper_files/paper/2004/file/ef0917ea498b1665ad6c701057155abe-Paper.pdf">Integrating topics and syntax</a>. In L. Saul, Y. Weiss, and L. Bottou, editors, <em>Advances in neural information processing systems</em>,Vol. 17. MIT Press.
</div>
<div id="ref-Grimm-Yarnold2016" class="csl-entry">
Grimm, L. G., and Yarnold, P. R. (2016). <em>研究論文を読み解くための多変量解析入門 応用篇</em>. Reading and Understanding MORE Multivariate Statistics (2020) の翻訳書; 北大路書房.
</div>
<div id="ref-Gu-Dao2024" class="csl-entry">
Gu, A., and Dao, T. (2024). <a href="https://arxiv.org/abs/2312.00752">Mamba: Linear-time sequence modeling with selective state spaces</a>.
</div>
<div id="ref-Gu+2020" class="csl-entry">
Gu, A., Dao, T., Ermon, S., Rudra, A., and Ré, C. (2020). <a href="https://proceedings.neurips.cc/paper_files/paper/2020/file/102f0bb6efb3a6128a3c750dd16729be-Paper.pdf">HiPPO: Recurrent memory with optimal polynomial projections</a>. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, <em>Advances in neural information processing systems</em>,Vol. 33, pages 1474–1487. Curran Associates, Inc.
</div>
<div id="ref-Gu+2022" class="csl-entry">
Gu, A., Goel, K., and Re, C. (2022). <a href="https://openreview.net/forum?id=uYLFoz1vlAC">Efficiently modeling long sequences with structured state spaces</a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Gustafsson2001" class="csl-entry">
Gustafsson, M. G. (2001). <a href="https://doi.org/10.1021/ci0003909">A probabilistic derivation of the partial least-squares algorithm</a>. <em>Journal of Chemical Information and Computer Sciences</em>, <em>41</em>(2), 288–294. doi: 10.1021/ci0003909.
</div>
<div id="ref-Halko+2011" class="csl-entry">
Halko, N., Martinsson, P. G., and Tropp, J. A. (2011). <a href="https://doi.org/10.1137/090771806">Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions</a>. <em>SIAM Review</em>, <em>53</em>(2), 217–288.
</div>
<div id="ref-Harman-Fukuda1966" class="csl-entry">
Harman, H. H., and Fukuda, Y. (1966). <a href="https://doi.org/10.1007/BF02289525">Resolution of the heywood case in the minres solution</a>. <em>Psychometrika</em>, <em>31</em>(4), 563–571.
</div>
<div id="ref-Harman-Jones1966" class="csl-entry">
Harman, H. H., and Jones, W. H. (1966). <a href="https://doi.org/10.1007/BF02289468">Factor analysis by minimizing residuals (minres)</a>. <em>Psychometrika</em>, <em>31</em>(3), 351–368.
</div>
<div id="ref-Hoffman2017" class="csl-entry">
Hoffman, M. D. (2017). <a href="https://proceedings.mlr.press/v70/hoffman17a.html">Learning deep latent <span>G</span>aussian models with <span>M</span>arkov chain <span>M</span>onte <span>C</span>arlo</a>. In D. Precup and Y. W. Teh, editors, <em>Proceedings of the 34th international conference on machine learning</em>,Vol. 70, pages 1510–1519. PMLR.
</div>
<div id="ref-Hofmann1999" class="csl-entry">
Hofmann, T. (1999). <a href="https://doi.org/10.1145/312624.312649">Probabilistic latent semantic indexing</a>. In <em>Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval</em>, pages 50–57. New York, NY, USA: Association for Computing Machinery.
</div>
<div id="ref-Horst1961" class="csl-entry">
Horst, P. (1961). <a href="https://doi.org/10.1002/1097-4679(196110)17:4<331::AID-JCLP2270170402>3.0.CO;2-D">Generalized canonical correlations and their applications to experimental data</a>. <em>Journal of Clinical Psychology</em>, <em>17</em>(4), 331–347.
</div>
<div id="ref-Hotelling33-PCA" class="csl-entry">
Hotelling, H. (1933). <a href="https://psycnet.apa.org/doi/10.1037/h0071325">Analysis of a complex of statistical variables into principal components</a>. <em>Journal of Educational Psychology</em>, <em>24</em>(6), 417–441.
</div>
<div id="ref-Hotelling36" class="csl-entry">
Hotelling, H. (1936). <a href="https://www.jstor.org/stable/2333955">Relations between two sets of variates</a>. <em>Biometrika</em>, <em>27</em>(3/4), 321–377.
</div>
<div id="ref-Hsu+2012" class="csl-entry">
Hsu, D., Kakade, S. M., and Zhang, T. (2012). <a href="https://doi.org/10.1016/j.jcss.2011.12.025">A spectral algorithm for learning hidden markov models</a>. <em>Journal of Computer and System Sciences</em>, <em>78</em>(5), 1460–1480.
</div>
<div id="ref-Hyvarinen-Oja2000" class="csl-entry">
Hyvärinen, A., and Oja, E. (2000). <a href="https://doi.org/10.1016/S0893-6080(00)00026-5">Independent component analysis: Algorithms and applications</a>. <em>Neural Networks</em>, <em>13</em>(4), 411–430.
</div>
<div id="ref-Jolliffe+2003" class="csl-entry">
Ian T Jolliffe, N. T. T., and Uddin, M. (2003). <a href="https://doi.org/10.1198/1061860032148">A modified principal component technique based on the LASSO</a>. <em>Journal of Computational and Graphical Statistics</em>, <em>12</em>(3), 531–547.
</div>
<div id="ref-Joreskog1966" class="csl-entry">
Jöreskog, Karl G. (1966). <em>UMLFA: A computer program for unrestricted maximum likelihood factor analysis</em>. ETS. Retrieved from <a href="https://www.ets.org/research/policy_research_reports/publications/report/1966/iazh.html">https://www.ets.org/research/policy_research_reports/publications/report/1966/iazh.html</a>
</div>
<div id="ref-Joreskog1967a" class="csl-entry">
Jöreskog, K. G. (1967). <a href="https://doi.org/10.1007/BF02289658">Some contributions to maximum likelihood factor analysis</a>. <em>Psychometrika</em>, <em>32</em>(4), 443–482.
</div>
<div id="ref-Joreskog1969" class="csl-entry">
Jöreskog, K. G. (1969). <a href="https://doi.org/10.1007/BF02289343">A general approach to confirmatory maximum likelihood factor analysis</a>. <em>Psychometrika</em>, <em>34</em>(2), 183–202.
</div>
<div id="ref-Joreskog70" class="csl-entry">
Jöreskog, Karl Gustav. (1970). <a href="https://www.jstor.org/stable/2334833">A general method for analysis of covariance structures</a>. <em>Biometrika</em>, <em>57</em>(2), 239–251.
</div>
<div id="ref-Joreskog1978" class="csl-entry">
Jöreskog, Karl G. (1978). <a href="https://doi.org/10.1007/BF02293808">Structural analysis of covariance and correlation matrices</a>. <em>Psychometrika</em>, <em>43</em>(4), 443–477.
</div>
<div id="ref-Joreskog-Lawley1968" class="csl-entry">
Jöreskog, K. G., and Lawley, D. N. (1968). <a href="https://doi.org/10.1111/j.2044-8317.1968.tb00399.x">New methods in maximum likelihood factor analysis</a>. <em>British Journal of Mathematical and Statistical Psychology</em>, <em>21</em>(1), 85–96.
</div>
<div id="ref-Joreskog-Wold1982" class="csl-entry">
Jöreskog, K. G., and Wold, H. (1982). Systems under indirect observation: Causality, structure, prediction. In, pages 263–270. North-Holland.
</div>
<div id="ref-Joreskog-vanThillo1972" class="csl-entry">
Jőreskog, K. G., and Thiilo, M. van. (1972). <a href="https://doi.org/10.1002/j.2333-8504.1972.tb00827.x"><span class="nocase">LISREL: A General Computer Program for Estimating a Linear Structural Equation System Involving Multiple Indicators of Unmeasured Variables</span></a>. <em>ETS Research Bulletin Series</em>, <em>1972</em>(2), i–71.
</div>
<div id="ref-Khemakhem+2020" class="csl-entry">
Khemakhem, I., Kingma, D., Monti, R., and Hyvarinen, A. (2020). <a href="https://proceedings.mlr.press/v108/khemakhem20a.html">Variational autoencoders and nonlinear ICA: A unifying framework</a>. In S. Chiappa and R. Calandra, editors, <em>Proceedings of the twenty third international conference on artificial intelligence and statistics</em>,Vol. 108, pages 2207–2217. PMLR.
</div>
<div id="ref-Klami+2010" class="csl-entry">
Klami, A., Virtanen, S., and Kaski, S. (2010). Bayesian exponential family projections for coupled data sources. In <em>Proceedings of the twenty-sixth conference on uncertainty in artificial intelligence</em>, pages 286–293. Arlington, Virginia, USA: AUAI Press.
</div>
<div id="ref-Lawley1942" class="csl-entry">
Lawley, D. N. (1942). <a href="https://doi.org/10.1017/S0080454100006178">XIV.—further investigations in factor estimation</a>. <em>Proceedings of the Royal Society of Edinburgh. Section A. Mathematical and Physical Sciences</em>, <em>61</em>(2), 176–185.
</div>
<div id="ref-Lawrence2005" class="csl-entry">
Lawrence, N. (2005). <a href="http://jmlr.org/papers/v6/lawrence05a.html">Probabilistic non-linear principal component analysis with gaussian process latent variable models</a>. <em>Journal of Machine Learning Research</em>, <em>6</em>(60), 1783–1816.
</div>
<div id="ref-Lee-Seung1999" class="csl-entry">
Lee, D. D., and Seung, H. S. (1999). <a href="https://doi.org/10.1038/44565">Learning the parts of objects by non-negative matrix factorization</a>. <em>Nature</em>, <em>401</em>(6755), 788–791.
</div>
<div id="ref-Marlin2003" class="csl-entry">
Marlin, B. M. (2003). <a href="https://proceedings.neurips.cc/paper_files/paper/2003/file/269d837afada308dd4aeab28ca2d57e4-Paper.pdf">Modeling user rating profiles for collaborative filtering</a>. In S. Thrun, L. Saul, and B. Schölkopf, editors, <em>Advances in neural information processing systems</em>,Vol. 16. MIT Press.
</div>
<div id="ref-McArdle1984" class="csl-entry">
McArdle, J. J. (1984). <a href="https://doi.org/10.1080/00273171.1984.9676927">On the madness in his method: R. B. Cattell’s contributions to structural equation modeling</a>. <em>Multivariate Behavioral Research</em>, <em>19</em>(2-3), 245–267.
</div>
<div id="ref-Murphy2022" class="csl-entry">
Murphy, K. P. (2022). <em><a href="https://probml.github.io/pml-book/book1.html">Probabilistic machine learning: An introduction</a></em>. MIT Press.
</div>
<div id="ref-Murphy2023" class="csl-entry">
Murphy, K. P. (2023). <em><a href="http://probml.github.io/book2">Probabilistic machine learning: Advanced topics</a></em>. MIT Press.
</div>
<div id="ref-Murray+2023" class="csl-entry">
Murray, R., Demmel, J., Mahoney, M. W., Erichson, N. B., Melnichenko, M., Malik, O. A., … Dongarra, J. (2023). <em>Randomized numerical linear algebra: A perspective on the field with an eye to software</em> (No. UCB/EECS-2023-19). Retrieved from <a href="http://www2.eecs.berkeley.edu/Pubs/TechRpts/2023/EECS-2023-19.html">http://www2.eecs.berkeley.edu/Pubs/TechRpts/2023/EECS-2023-19.html</a>
</div>
<div id="ref-Muthen2002" class="csl-entry">
Muthén, B. O. (2002). <a href="https://doi.org/10.2333/bhmk.29.81"><span>Beyond SEM: General Latent Variable Modeling</span></a>. <em>Behaviormetrika</em>, <em>29</em>(1), 81–117.
</div>
<div id="ref-Nounou+2002" class="csl-entry">
Nounou, M. N., Bakshi, B. R., Goel, P. K., and Shen, X. (2002). <a href="https://doi.org/10.1002/aic.690480818">Process modeling by bayesian latent variable regression</a>. <em>AIChE Journal</em>, <em>48</em>(8), 1775–1793.
</div>
<div id="ref-Obermeyer+2019" class="csl-entry">
Obermeyer, F., Bingham, E., Jankowiak, M., Pradhan, N., Chiu, J., Rush, A., and Goodman, N. (2019). <a href="https://proceedings.mlr.press/v97/obermeyer19a.html">Tensor variable elimination for plated factor graphs</a>. In K. Chaudhuri and R. Salakhutdinov, editors, <em>Proceedings of the 36th international conference on machine learning</em>,Vol. 97, pages 4871–4880. PMLR.
</div>
<div id="ref-Paatero-Tapper1994" class="csl-entry">
Paatero, P., and Tapper, U. (1994). <a href="https://doi.org/10.1002/env.3170050203">Positive matrix factorization: A non-negative factor model with optimal utilization of error estimates of data values</a>. <em>Environmetrics</em>, <em>5</em>(2), 111–126.
</div>
<div id="ref-Paisley-Carin2009" class="csl-entry">
Paisley, J., and Carin, L. (2009). <a href="https://doi.org/10.1145/1553374.1553474">Nonparametric factor analysis with beta process priors</a>. In <em>Proceedings of the 26th annual international conference on machine learning</em>, pages 777–784. New York, NY, USA: Association for Computing Machinery.
</div>
<div id="ref-Papyam-Elad2016" class="csl-entry">
Papyan, V., and Elad, M. (2016). <a href="https://doi.org/10.1109/TIP.2015.2499698">Multi-scale patch-based image restoration</a>. <em>IEEE Transactions on Image Processing</em>, <em>25</em>(1), 249–261.
</div>
<div id="ref-Pearson01-PCA" class="csl-entry">
Pearson, K. (1901). <a href="https://www.tandfonline.com/doi/abs/10.1080/14786440109462720">On lines and planes of closest fit to systems of points in space</a>. <em>Philosophical Magazine</em>, <em>2</em>(11), 559–572.
</div>
<div id="ref-Perrone2024" class="csl-entry">
Perrone, P. (2024). <a href="https://doi.org/10.1109/TIT.2023.3328825"><span class="nocase">Markov Categories and Entropy</span></a>. <em>IEEE Transactions on Information Theory</em>, <em>70</em>(3), 1671–1692.
</div>
<div id="ref-Pritchard+2000" class="csl-entry">
Pritchard, J. K., Stephens, M., and Donnelly, P. (2000). <a href="https://doi.org/10.1093/genetics/155.2.945"><span class="nocase">Inference of Population Structure Using Multilocus Genotype Data</span></a>. <em>Genetics</em>, <em>155</em>(2), 945–959.
</div>
<div id="ref-Rattray+2009" class="csl-entry">
Rattray, M., Stegle, O., Sharp, K., and Winn, J. (2009). <a href="https://doi.org/10.1088/1742-6596/197/1/012002">Inference algorithms and learning theory for bayesian sparse factor analysis</a>. <em>Journal of Physics: Conference Series</em>, <em>197</em>(1), 012002.
</div>
<div id="ref-Ricahrdson-Weiss2018" class="csl-entry">
Richardson, E., and Weiss, Y. (2018). <a href="https://proceedings.neurips.cc/paper_files/paper/2018/file/0172d289da48c48de8c5ebf3de9f7ee1-Paper.pdf">On GANs and GMMs</a>. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, <em>Advances in neural information processing systems</em>,Vol. 31. Curran Associates, Inc.
</div>
<div id="ref-Roweis1997" class="csl-entry">
Roweis, S. (1997). <a href="https://proceedings.neurips.cc/paper_files/paper/1997/file/d9731321ef4e063ebbee79298fa36f56-Paper.pdf">EM algorithms for PCA and SPCA</a>. In M. Jordan, M. Kearns, and S. Solla, editors, <em>Advances in neural information processing systems</em>,Vol. 10. MIT Press.
</div>
<div id="ref-Rubin-Thayer1982" class="csl-entry">
Rubin, D. B., and Thayer, D. T. (1982). <a href="https://doi.org/10.1007/BF02293851">EM algorithms for ML factor analysis</a>. <em>Psychometrika</em>, <em>47</em>(1), 69–76.
</div>
<div id="ref-Scott2002" class="csl-entry">
Scott, S. L. (2002). <a href="https://doi.org/10.1198/016214502753479464">Bayesian methods for hidden markov models</a>. <em>Journal of the American Statistical Association</em>, <em>97</em>(457), 337–351.
</div>
<div id="ref-Sei-Yano2024" class="csl-entry">
Sei, T., and Yano, K. (2024). <a href="https://doi.org/10.3150/23-BEJ1687"><span class="nocase">Minimum information dependence modeling</span></a>. <em>Bernoulli</em>, <em>30</em>(4), 2623–2643.
</div>
<div id="ref-Herbert-Simon57-ModelsOfMan" class="csl-entry">
Simon, H. (1957). <em>Models of man; social and rational.</em> Wiley.
</div>
<div id="ref-Smith+2023" class="csl-entry">
Smith, J. T. H., Warrington, A., and Linderman, S. (2023). <a href="https://openreview.net/forum?id=Ai8Hw3AXqks">Simplified state space layers for sequence modeling</a>. In <em>The eleventh international conference on learning representations</em>.
</div>
<div id="ref-Socan2003" class="csl-entry">
Socan, G. (2003). <em>The incremental value of rank factor analysis</em> (PhD thesis). Rijksuniversiteit Groningen.
</div>
<div id="ref-Sorbom1974" class="csl-entry">
Sörbom, D. (1974). <a href="https://doi.org/10.1111/j.2044-8317.1974.tb00543.x"><span class="nocase">A General Method for Studying Differences in Factor Means and Factor Structure between Groups</span></a>. <em>British Journal of Mathematical and Statistical Psychology</em>, <em>27</em>(2), 229–239.
</div>
<div id="ref-Spearman1904" class="csl-entry">
Spearman, C. (1904). <a href="https://psycnet.apa.org/doi/10.2307/1412107">’General intelligence,’ objectively determined and measured</a>. <em>The American Journal of Psychology</em>, <em>15</em>(2), 201–293.
</div>
<div id="ref-Sun+2009" class="csl-entry">
Sun, L., Ji, S., Yu, S., and Ye, J. (2009). On the equivalence between canonical correlation analysis and orthonormalized partial least squares. In <em>Proceedings of the 21st international joint conference on artificial intelligence</em>, pages 1230–1235. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc.
</div>
<div id="ref-Suzuki+2017" class="csl-entry">
Suzuki, M., Nakayama, K., and Matsuo, Y. (2017). <a href="https://openreview.net/forum?id=Hk8rlUqge">Joint multimodal learning with deep generative models</a>.
</div>
<div id="ref-Thurstone1947" class="csl-entry">
Thurstone, L. L. (1947). <em><a href="">Multiple factor analysis</a></em>. University of Chicago Press.
</div>
<div id="ref-Tipping-Bishop1999" class="csl-entry">
Tipping, M. E., and Bishop, C. M. (1999). <a href="https://www.jstor.org/stable/2680726">Probabilistic principle component analysis</a>. <em>Journal of the Royal Statistical Society. Series B (Statistical Methodology)</em>, <em>61</em>(3), 611–622.
</div>
<div id="ref-Unkel-Trendafilov2010" class="csl-entry">
Unkel, S., and Trendafilov, N. T. (2010). <a href="https://doi.org/10.1111/j.1751-5823.2010.00120.x">Simultaneous parameter estimation in exploratory factor analysis: An expository review</a>. <em>International Statistical Review</em>, <em>78</em>(3), 363–382.
</div>
<div id="ref-Wallach+2009" class="csl-entry">
Wallach, H. M., Murray, I., Salakhutdinov, R., and Mimno, D. (2009). <a href="https://doi.org/10.1145/1553374.1553515">Evaluation methods for topic models</a>. In <em>Proceedings of the 26th annual international conference on machine learning</em>, pages 1105–1112. New York, NY, USA: Association for Computing Machinery.
</div>
<div id="ref-Wang+2017" class="csl-entry">
Wang, W., Yan, X., Lee, H., and Livescu, K. (2017). <a href="https://openreview.net/forum?id=H1Heentlx">Deep variational canonical correlation analysis</a>.
</div>
<div id="ref-Wright1918" class="csl-entry">
Wright, S. (1918). <a href="https://academic.oup.com/genetics/article/3/4/367/5934526">On the nature of size factors</a>. <em>Genetics</em>, <em>3</em>(4), 367.
</div>
<div id="ref-Wright1921" class="csl-entry">
Wright, S. (1921). Correlation and causation. <em>Journal of Agricultural Reserach</em>, <em>20</em>, 557–585.
</div>
<div id="ref-Teh+2006" class="csl-entry">
Yee Whye Teh, M. J. B., Michael I Jordan, and Blei, D. M. (2006). <a href="https://doi.org/10.1198/016214506000000302">Hierarchical dirichlet processes</a>. <em>Journal of the American Statistical Association</em>, <em>101</em>(476), 1566–1581.
</div>
<div id="ref-Yu+2006" class="csl-entry">
Yu, S., Yu, K., Tresp, V., Kriegel, H.-P., and Wu, M. (2006). <a href="https://doi.org/10.1145/1150402.1150454">Supervised probabilistic principal component analysis</a>. In <em>Proceedings of the 12th ACM SIGKDD international conference on knowledge discovery and data mining</em>, pages 464–473. New York, NY, USA: Association for Computing Machinery.
</div>
<div id="ref-Zong+2018" class="csl-entry">
Zong, B., Song, Q., Min, M. R., Cheng, W., Lumezanu, C., Cho, D., and Chen, H. (2018). <a href="https://openreview.net/forum?id=BJJLHbb0-">Deep autoencoding gaussian mixture model for unsupervised anomaly detection</a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Zoran-Weiss2011" class="csl-entry">
Zoran, D., and Weiss, Y. (2011). <a href="https://doi.org/10.1109/ICCV.2011.6126278">From learning models of natural image patches to whole image restoration</a>. In <em>2011 international conference on computer vision</em>, pages 479–486.
</div>
<div id="ref-Zou-Hastie2005" class="csl-entry">
Zou, H., and Hastie, T. (2005). <a href="https://doi.org/10.1111/j.1467-9868.2005.00503.x"><span class="nocase">Regularization and Variable Selection Via the Elastic Net</span></a>. <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em>, <em>67</em>(2), 301–320.
</div>
<div id="ref-Zou+2006" class="csl-entry">
Zou, H., Hastie, T., and Tibshirani, R. (2006). <a href="http://www.jstor.org/stable/27594179">Sparse principal component analysis</a>. <em>Journal of Computational and Graphical Statistics</em>, <em>15</em>(2), 265–286.
</div>
<div id="ref-岩瀬-中山2016" class="csl-entry">
岩瀬智亮, and 中山英樹. (2016). <a href="http://id.nii.ac.jp/1001/00162588/">深層一般化正準相関分析</a>. <em>情報処理学会第78回全国大会講演論文集</em>, <em>2016</em>(1), 183–184.
</div>
<div id="ref-星野崇宏+2005" class="csl-entry">
星野崇宏, 岡田謙介, and 前田忠彦. (2005). <a href="https://doi.org/10.2333/jbhmk.32.209">構造方程式モデリングにおける適合度指標とモデル改善について : 展望とシミュレーション研究による新たな知見</a>. <em>行動計量学</em>, <em>32</em>(2), 209–235.
</div>
<div id="ref-江口真透1999" class="csl-entry">
江口真透. (1999). <a href="http://hdl.handle.net/10787/295">概パラメトリック推測 － 柔らかなモデルの構築 －</a>. <em>統計数理</em>, <em>47</em>(1), 29–48.
</div>
<div id="ref-清水和秋1989" class="csl-entry">
清水和秋. (1989). <a href="http://hdl.handle.net/10112/13348">検証的因子分析，LISRELそしてRAMの概要</a>. <em>関西大学社会学部紀要</em>, <em>20</em>(2), 61–86.
</div>
<div id="ref-清水和秋1994" class="csl-entry">
清水和秋. (1994). <a href="http://hdl.handle.net/10112/13345">JöreskogとSörbomによるコンピュータ・プログラムと構造方程式モデル</a>. <em>関西大学社会学部紀要</em>, <em>25</em>(3), 1–41.
</div>
<div id="ref-狩野裕2002" class="csl-entry">
狩野裕. (2002). <a href="https://doi.org/10.2333/jbhmk.29.138">構造方程式モデリングは，因子分析，分散分析，パス解析の すべてにとって代わるのか？</a>. <em>行動計量学</em>, <em>29</em>(2), 138–159.
</div>
<div id="ref-統計科学のフロンティア5" class="csl-entry">
甘利俊一，狩野裕，佐藤俊哉，松山裕，竹内啓，石黒真木夫. (2002). <em><a href="https://www.iwanami.co.jp/book/b260371.html">多変量解析の展開：隠れた構造と因果を推理する</a></em>,Vol. 5. 岩波書店.
</div>
<div id="ref-白倉幸男1984" class="csl-entry">
白倉幸男. (1984). <a href="https://doi.org/10.18910/4301">多重指標線形構造モデルとその応用 : 研究ノート</a>. <em>大阪大学人間科学部紀要</em>, <em>10</em>, 25–45.
</div>
<div id="ref-豊田秀樹1991" class="csl-entry">
豊田秀樹. (1991). <a href="https://doi.org/10.5926/jjep1953.39.4_467">共分散構造分析の下位モデルとその適用例</a>. <em>教育心理学研究</em>, <em>39</em>(4), 467–478.
</div>
<div id="ref-豊田秀樹1992" class="csl-entry">
豊田秀樹. (1992). <em><a href="https://www.utp.or.jp/book/b302422.html">SASによる共分散構造分析</a></em>,Vol. 3. 東京大学出版会.
</div>
<div id="ref-豊田秀樹2007" class="csl-entry">
豊田秀樹. (2007). <em>共分散構造分析［理論編］</em>. 朝倉書店.
</div>
<div id="ref-赤穂昭太郎2013" class="csl-entry">
赤穂昭太郎. (2013). <a href="https://doi.org/10.3902/jnns.20.62">正準相関分析入門</a>. <em>日本神経回路学会誌</em>, <em>20</em>(2), 62–72.
</div>
<div id="ref-足立浩平2023" class="csl-entry">
足立浩平. (2023). 50歳を超えてから始めた因子分析. <em>日本行動計量学会報</em>, <em>177</em>.
</div>
<div id="ref-足立浩平+2019" class="csl-entry">
足立浩平, 伊藤真道, and 宇野光平. (2019). <a href="https://doi.org/10.20551/jscswabun.32.1_61">行列分解に基づく因子分析とその新展開</a>. <em>計算機統計学</em>, <em>32</em>(1), 61–77.
</div>
<div id="ref-足立-山本2024" class="csl-entry">
足立浩平, and 山本倫生. (2024). <em><a href="https://www.kyoritsu-pub.co.jp/book/b10085699.html">主成分分析と因子分析―特異値分解を出発点として―</a></em>. 共立出版.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>図を見やすくするために，<img src="https://latex.codecogs.com/png.latex?X%5E1%5Cto%20X%5E%7Bp-1%7D"> や <img src="https://latex.codecogs.com/png.latex?X%5E2%5Cto%20X%5Ep"> などは省略している．↩︎</p></li>
<li id="fn2"><p><span class="citation" data-cites="足立-山本2024">(足立浩平 and 山本倫生, 2024)</span>, <span class="citation" data-cites="足立浩平2023">(足立浩平, 2023)</span> によると，この行列分解による定式化は Henk A. K. Kiers によるもので，初出は同大学からの博士論文 <span class="citation" data-cites="Socan2003">(Socan, 2003)</span> が最初ではないか，とのこと．この見方を MDFA (Matrix Decomposition Factor Analysis) と呼ぶ．<span class="citation" data-cites="足立浩平+2019">(足立浩平 et al., 2019)</span> も参照．↩︎</p></li>
<li id="fn3"><p>ただし，<span class="citation" data-cites="星野崇宏+2005">(星野崇宏 et al., 2005)</span> は SEM をより一般的とし，共分散構造分析とは観測変数が連続な場合の下位モデルである，と解している．↩︎</p></li>
<li id="fn4"><p><span class="citation" data-cites="江口真透1999">(江口真透, 1999)</span> 第３節に，PCA をニューラルネットワークにより近似的に実行する方法が紹介されている．<span class="citation" data-cites="Ghojogh+2022">(Ghojogh et al., 2022)</span> はサーベイを与えている．↩︎</p></li>
<li id="fn5"><p><span class="citation" data-cites="豊田秀樹1992">(豊田秀樹, 1992)</span> では CFA を確認的因子分析と呼んでいる．<span class="citation" data-cites="豊田秀樹1991">(豊田秀樹, 1991)</span> では，古典テスト理論を確認的因子分析の下位モデルとして紹介している．また，このような因果関係の確認的方法は，社会学における <span class="citation" data-cites="Herbert-Simon57-ModelsOfMan">(Simon, 1957)</span> の基準などが知られていた．↩︎</p></li>
<li id="fn6"><p><span class="citation" data-cites="Joreskog70">(Karl Gustav Jöreskog, 1970)</span> は具体的なモデルを例に取り，彼の検証的因果分析が，パス解析 <span class="citation" data-cites="Wright1918">(Wright, 1918)</span>, <span class="citation" data-cites="Wright1921">(Wright, 1921)</span> のように因果分析に応用できることを示した結果だと言える <span class="citation" data-cites="Asher83-Causal">(Asher, 1983)</span>．この観点から，パス解析は「検証的因果推論」と表現することもできる <span class="citation" data-cites="統計科学のフロンティア5">(甘利俊一，狩野裕，佐藤俊哉，松山裕，竹内啓，石黒真木夫, 2002, p. 73)</span>．↩︎</p></li>
<li id="fn7"><p><span class="citation" data-cites="狩野裕2002">(狩野裕, 2002)</span> は SEM の射程と得意・不得意を分析している．↩︎</p></li>
<li id="fn8"><p>現代ではコンピュータの力により，新たに「生成」「表現学習」というタスクが加わったと思うと，感慨深い．↩︎</p></li>
<li id="fn9"><p><span class="citation" data-cites="清水和秋1989">(清水和秋, 1989)</span>, <span class="citation" data-cites="豊田秀樹1992">(豊田秀樹, 1992)</span>, <span class="citation" data-cites="統計科学のフロンティア5">(甘利俊一，狩野裕，佐藤俊哉，松山裕，竹内啓，石黒真木夫, 2002, p. 82)</span> も参照．↩︎</p></li>
<li id="fn10"><p>また，パス図では観測変数は四角で囲むべきであるが，ここでは省略した．↩︎</p></li>
<li id="fn11"><p>同時方程式は潜在変数を持たない模型で，経済学におけるパス解析の継承と見れる <span class="citation" data-cites="豊田秀樹2007">(豊田秀樹, 2007)</span>．特に Keynes 経済学におけるマクロな経済計画の発想で，<a href="https://ja.wikipedia.org/wiki/コウルズ財団">Cowles 委員会</a> により 1940 年代から 1950 年代にかけて盛んに研究された．↩︎</p></li>
<li id="fn12"><p>多変量解析の高級言語とか形容することもあるという．構造方程式モデリングについては，<span class="citation" data-cites="豊田秀樹1991">(豊田秀樹, 1991)</span>, <span class="citation" data-cites="狩野裕2002">(狩野裕, 2002)</span> も参照．↩︎</p></li>
<li id="fn13"><p>オランダ学派を中心に等質性分析とも呼ぶ．↩︎</p></li>
<li id="fn14"><p>ただし，SEM は共分散構造，混合モデルは平均構造に分析の焦点がある，という志向の違いもある．<span class="citation" data-cites="狩野裕2002">(狩野裕, 2002)</span> も参照．↩︎</p></li>
<li id="fn15"><p><img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BC%7D(%5Csigma)_+"> は Cauchy 分布 <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BC%7D(0,%5Csigma)"> を <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D_+"> 上に制限したものである．truncated Cauchy または half-Cauchy という．↩︎</p></li>
<li id="fn16"><p><span class="citation" data-cites="Hyvarinen-Oja2000">(Hyvärinen and Oja, 2000)</span> では，<span class="citation" data-cites="Bell-Sejnowski1995">(Bell and Sejnowski, 1995)</span> のように測定誤差を考えない場合を ICA といい，誤差も入る一般の場合を IFA (Independent Factor Analysis) と呼び分けている．<span class="citation" data-cites="統計科学のフロンティア5">(甘利俊一，狩野裕，佐藤俊哉，松山裕，竹内啓，石黒真木夫, 2002, p. 110)</span> も参照．「これを回転の不定性という．因子分析はさまざまな考察によって，この不定性を解消しようとする．独立成分分析は，非正規性を仮定すれば，この不定性が消えることを示したものとも言える」<span class="citation" data-cites="統計科学のフロンティア5">(甘利俊一，狩野裕，佐藤俊哉，松山裕，竹内啓，石黒真木夫, 2002, p. 13)</span>．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Statistics</category>
  <category>Kernel</category>
  <category>Probability</category>
  <category>Bayesian</category>
  <guid>https://162348.github.io/posts/2024/Kernels/HierarchicalModel.html</guid>
  <pubDate>Sun, 11 Aug 2024 15:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Kernels/Images/MM.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>特異値分解</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/FunctionalAnalysis/SVD.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="特異値分解" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="特異値分解"><span class="header-section-number">1</span> 特異値分解</h2>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題（特異値分解）^[[@Eckart-Young1936 p.213 Theorem 1], [@Strang16 p.372] など．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題（特異値分解）<sup>1</sup>
</div>
</div>
<div class="callout-body-container callout-body">
<p>任意の行列 <img src="https://latex.codecogs.com/png.latex?A%5Cin%20M_%7Bn,p%7D(%5Cmathbb%7BR%7D),r:=%5Coperatorname%7Brank%7D(A)"> について，直交行列 <img src="https://latex.codecogs.com/png.latex?U%5Cin%20O_n(%5Cmathbb%7BR%7D),V%5Cin%20O_p(%5Cmathbb%7BR%7D)"> と非負実数 <img src="https://latex.codecogs.com/png.latex?%5Csigma_1%5Cge%5Ccdots%5Cge%5Csigma_r%3E0"> が存在して，次が成り立つ： <img src="https://latex.codecogs.com/png.latex?%0AA=U%5CSigma%20V%5E%5Ctop,%5Cqquad%5CSigma:=%5Cbegin%7Bbmatrix%7DD&amp;O_%7Br,p-r%7D%5C%5CO_%7Bn-r,r%7D&amp;O_%7Bn-r,p-r%7D%5Cend%7Bbmatrix%7D,%5Cquad%20D:=%5Cmathrm%7Bdiag%7D(%5Csigma_1,%5Ccdots,%5Csigma_r).%0A"> <img src="https://latex.codecogs.com/png.latex?D"> を <strong>特異値行列</strong>，の対角要素を <strong>特異値</strong> と呼ぶ．<sup>2</sup></p>
</div>
</div>
<p><span class="citation" data-cites="Sylvester1889">(Sylvester, 1889)</span> は特異値を正準乗数 (canonical multipliers) と呼んでいた．Sylvester は特異値分解を独立に再発見した一人で，歴史上最初の特異値分解は <span class="citation" data-cites="Beltrami1873">(Beltrami, 1873)</span> が与えたものだとされている．より詳しい歴史については <span class="citation" data-cites="Stewart1993">(Stewart, 1993)</span> 参照．</p>
<div class="callout callout-style-default callout-note no-icon callout-titled" title="証明">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
証明
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p>まず <img src="https://latex.codecogs.com/png.latex?v_1,%5Ccdots,v_r%5Cin%5Cmathbb%7BR%7D%5En"> を，<img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop%20A"> の固有ベクトルからなる正規直交系として取る． このとき <img src="https://latex.codecogs.com/png.latex?v_1,%5Ccdots,v_r"> は <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BIm%7D%5C,(A%5E%5Ctop)"> の像の基底である． <img src="https://latex.codecogs.com/png.latex?v_1,%5Ccdots,v_r"> が <img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop%20A"> の固有ベクトルであることが必要であることは， <img src="https://latex.codecogs.com/png.latex?%0AA%5E%5Ctop%20A=(U%5CSigma%20V%5E%5Ctop)%5E%5Ctop(U%5CSigma%20V%5E%5Ctop)=V%5CSigma%5E%5Ctop%20U%5E%5Ctop%20U%5CSigma%20V%5E%5Ctop=V(%5CSigma%5E%5Ctop%5CSigma)V%0A"> となることからわかり，<img src="https://latex.codecogs.com/png.latex?%5Csigma_1%5E2,%5Ccdots,%5Csigma_r%5E2"> が <img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop%20A"> の固有値である． （従って <img src="https://latex.codecogs.com/png.latex?AA%5E%5Ctop"> の固有値でもある）．</p></li>
<li><p>続いて，条件 <img src="https://latex.codecogs.com/png.latex?Av_i=%5Csigma_iu_i%5C;(i%5Cin%5Br%5D)"> によって，<img src="https://latex.codecogs.com/png.latex?u_1,%5Ccdots,u_r"> を定める．するとこれらは直交し， <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BIm%7D%5C,(A)"> の基底をなす．さらに，<img src="https://latex.codecogs.com/png.latex?AA%5E%5Ctop"> の固有ベクトルでもある．</p>
<p>このことは次のように示せる：</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0Au_i%5E%5Ctop%20u_j&amp;=%5Cleft(%5Cfrac%7BAv_i%7D%7B%5Csigma_i%7D%5Cright)%5E%5Ctop%5Cleft(%5Cfrac%7BAv_j%7D%7B%5Csigma_j%7D%5Cright)=%5Cfrac%7Bv_i%5E%5Ctop%20A%5E%5Ctop%20Av_j%7D%7B%5Csigma_i%5Csigma_j%7D=%5Cfrac%7B%5Csigma_j%5E2%7D%7B%5Csigma_i%5Csigma_j%7Dv_i%5E%5Ctop%20v_j=0,%5Cqquad%20i%5Cne%20j.%0A%5Cend%7Balign*%7D"></p>
<p><img src="https://latex.codecogs.com/png.latex?%5Clangle%20u_1,%5Ccdots,u_r%5Crangle%5Csubset%5Cmathrm%7BIm%7D%5C,(A)"> であることと，正規直交することから線型独立でもあり，これらが <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BIm%7D%5C,(A)"> の基底であることがわかる． さらに，任意の <img src="https://latex.codecogs.com/png.latex?i%5Cin%5Br%5D"> について， <img src="https://latex.codecogs.com/png.latex?%0AAA%5E%5Ctop%20u_i=%5Cfrac%7BAA%5E%5Ctop%20Au_i%7D%7B%5Csigma_i%7D=%5Csigma_iAv_i=%5Csigma_i%5E2u_i,%5Cqquad%20i%5Cin%5Br%5D.%0A"> なお，<img src="https://latex.codecogs.com/png.latex?Av_i=%5Csigma_iu_i"> が必要であることは，<img src="https://latex.codecogs.com/png.latex?v_1,%5Ccdots,v_r"> の正規直交性から， <img src="https://latex.codecogs.com/png.latex?%0AAv_i=%5Cbiggr(u_1%5Csigma_1v_1%5E%5Ctop+%5Ccdots+u_r%5Csigma_rv_r%5E%5Ctop%5Cbiggl)v_i=u_i%5Csigma_i%0A"> からわかる．</p></li>
<li><p><img src="https://latex.codecogs.com/png.latex?v_1,%5Ccdots,v_r"> の正規直交な延長であって，<img src="https://latex.codecogs.com/png.latex?v_%7Br+1%7D,%5Ccdots,v_n"> が <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BKer%7D%5C;(A)"> の基底になるもの，<img src="https://latex.codecogs.com/png.latex?u_1,%5Ccdots,u_r"> の正規直交な延長であって，<img src="https://latex.codecogs.com/png.latex?u_%7Br+1%7D,%5Ccdots,u_m"> が <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BKer%7D%5C;(A%5E%5Ctop)"> の基底になるものが取れる． これは，核と余像，像と余核が直交するためである． これについて，<img src="https://latex.codecogs.com/png.latex?A=U%5CSigma%20V%5E%5Ctop"> が成り立つ．</p></li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-default callout-warning no-icon callout-titled" title="系">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
系
</div>
</div>
<div class="callout-body-container callout-body">
<p>以上の証明から，次のこともわかる：</p>
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?A"> の特異値は，<img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop%20A"> の固有値の正の平方根に等しい．</li>
<li><img src="https://latex.codecogs.com/png.latex?V"> の列ベクトルは <img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop%20A"> の固有ベクトルであり，<img src="https://latex.codecogs.com/png.latex?U"> の列ベクトルは <img src="https://latex.codecogs.com/png.latex?AA%5E%5Ctop"> の固有ベクトルになる．</li>
</ol>
</div>
</div>
</section>
<section id="低階数近似" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="低階数近似"><span class="header-section-number">2</span> 低階数近似</h2>
<p><img src="https://latex.codecogs.com/png.latex?(n,p)">-行列の全体 <img src="https://latex.codecogs.com/png.latex?M_%7Bn,p%7D(%5Cmathbb%7BC%7D)"> は <a href="../../../static/Notations.html#subsec-linear-space">Hilbert-Schmidt 内積</a> <img src="https://latex.codecogs.com/png.latex?%0A(B%20%5C,%7C%5C,A)_%5Cmathrm%7BHS%7D:=%5Coperatorname%7BTr%7D(A%5E*B)=%5Csum_%7Bi=1%7D%5Em%5Csum_%7Bj=1%7D%5Ena_%7Bij%7Db_%7Bij%7D%0A"> に関して Hilbert 空間をなす．<img src="https://latex.codecogs.com/png.latex?M_%7Bn,p%7D(%5Cmathbb%7BR%7D)"> はこの閉部分空間をなす．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題 [@Eckart-Young1936]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題 <span class="citation" data-cites="Eckart-Young1936">(Eckart and Young, 1936)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?A%5Cin%20M_%7Bn,p%7D(%5Cmathbb%7BR%7D)"> を行列，<img src="https://latex.codecogs.com/png.latex?0%5Cle%20r%5Cle%20n%5Clor%20p"> を自然数とする．ランク <img src="https://latex.codecogs.com/png.latex?r"> の行列 <img src="https://latex.codecogs.com/png.latex?%5Cwidetilde%7BA%7D%5Cin%20M_%7Bn,p%7D(%5Cmathbb%7BR%7D)"> のうち，<img src="https://latex.codecogs.com/png.latex?A"> に最も近いものは <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidetilde%7BA%7D:=U%5CSigma_%7B1:r%7DV%5E%5Ctop=%5Coperatorname*%7Bargmin%7D_%7B%5Coperatorname%7Brank%7D(%5Cwidetilde%7BA%7D)=r%7D%5C%7CA-%5Cwidetilde%7BA%7D%5C%7C_%5Cmathrm%7BHS%7D%0A"> が与える．ただし，<img src="https://latex.codecogs.com/png.latex?%5CSigma_%7B1:r%7D=%5Cmathrm%7Bdiag%7D(%5Csigma_1,%5Ccdots,%5Csigma_r,0,%5Ccdots,0)"> とした．</p>
</div>
</div>
<p>またこのときの残差は，残った特異値のうち最大のもの <img src="https://latex.codecogs.com/png.latex?%0A%5C%7CA-%5Cwidetilde%7BA%7D%5C%7C_%5Cmathrm%7BHS%7D=%5Csigma_%7Br+1%7D%0A"> が与える．<sup>3</sup></p>
</section>
<section id="一般化逆行列" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="一般化逆行列"><span class="header-section-number">3</span> 一般化逆行列</h2>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題 [@Moore1920]-[@Penrose1955]^[[@柳井-竹内-一般逆行列] も参照．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題 <span class="citation" data-cites="Moore1920">(Moore, 1920)</span>-<span class="citation" data-cites="Penrose1955">(Penrose, 1955)</span><sup>4</sup>
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?A%5Cin%20M_%7Bmn%7D(%5Cmathbb%7BR%7D)"> について，次の３条件を満たす行列 <img src="https://latex.codecogs.com/png.latex?A%5E+%5Cin%20M_%7Bnm%7D(%5Cmathbb%7BR%7D)"> は一意的に定まる：</p>
<ol type="a">
<li>反射型一般可逆行列：<img src="https://latex.codecogs.com/png.latex?AA%5E+A=A,A%5E+AA%5E+=A%5E+"></li>
<li>最小ノルム型：<img src="https://latex.codecogs.com/png.latex?A%5E+A"> は自己共役である：<img src="https://latex.codecogs.com/png.latex?(A%5E+A)%5E%5Ctop=A%5E+A"></li>
<li>最小誤差型：<img src="https://latex.codecogs.com/png.latex?AA%5E+"> も自己共役である：<img src="https://latex.codecogs.com/png.latex?(AA%5E+)%5E%5Ctop=AA%5E+"></li>
</ol>
<p>これを <strong>Moore-Penrose の一般化逆行列</strong> という．</p>
</div>
</div>
<p>任意の行列 <img src="https://latex.codecogs.com/png.latex?A%5Cin%20M_%7Bn,p%7D(%5Cmathbb%7BR%7D)"> の一般化逆行列は，直交行列 <img src="https://latex.codecogs.com/png.latex?V,U"> で座標変換を施したところで逆行列を取り，これを再び <img src="https://latex.codecogs.com/png.latex?V,U"> で変換し直したものに等しい：</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題（一般化逆の特徴付け）^[[@柳井-竹内-一般逆行列 定理5.6], [@Strang16 p.395] も参照．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題（一般化逆の特徴付け）<sup>5</sup>
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?A%5Cin%20M_%7Bn,p%7D(%5Cmathbb%7BR%7D)"> の一般化逆行列は次のように表せる： <img src="https://latex.codecogs.com/png.latex?%0AA%5E+=V%5CSigma%5E%7B-1%7DU%5E%5Ctop,%5Cqquad%20%5CSigma%5E%7B-1%7D=%5Cbegin%7Bbmatrix%7DD%5E%7B-1%7D&amp;O_%7Br,p-r%7D%5C%5CO_%7Bn-r,r%7D&amp;O_%7Bn-r,p-r%7D%5Cend%7Bbmatrix%7D.%0A"></p>
</div>
</div>
</section>



<div id="quarto-appendix" class="default"><section id="関連ページ" class="level2 unnumbered unlisted appendix"><h2 class="anchored quarto-appendix-heading">関連ページ</h2><div class="quarto-appendix-contents">

<div id="listing-related-articles-listing" class="quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Statistics,Kernel,Probability,Bayesian" data-listing-date-sort="1723388400000" data-listing-file-modified-sort="1723700397339" data-listing-date-modified-sort="1723561200000" data-listing-reading-time-sort="6" data-listing-word-count-sort="1067">
<a href="../../../posts/2024/Kernels/HierarchicalModel.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Kernels/Images/MM.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
階層モデル再論
</h5>
<div class="card-subtitle listing-subtitle">
多変量解析から機械学習へ
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-12
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Deep,Nature,Statistics,Geometry" data-listing-date-sort="1722265200000" data-listing-file-modified-sort="1723897275473" data-listing-date-modified-sort="1723647600000" data-listing-reading-time-sort="3" data-listing-word-count-sort="583">
<a href="../../../posts/2024/Kernels/Manifold.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Kernels/Images/UMAPvSNE.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
非線型な次元縮約法の概観
</h5>
<div class="card-subtitle listing-subtitle">
最古にして最難のタスクと多様体学習
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-07-30
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Kernel" data-listing-date-sort="1723215600000" data-listing-file-modified-sort="1723700397341" data-listing-date-modified-sort="1723302000000" data-listing-reading-time-sort="3" data-listing-word-count-sort="577">
<a href="../../../posts/2024/Kernels/Kernel.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Kernels/Images/Gibbs.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
カーネル法の概観
</h5>
<div class="card-subtitle listing-subtitle">
半正定値カーネルから距離学習まで
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-10
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Beltrami1873" class="csl-entry">
Beltrami, E. (1873). <a href="https://gallica.bnf.fr/ark:/12148/bpt6k99434d/f442">Sulle funzioni bilineari</a>. <em>Giornale Di Matematiche Ad Uso Degli Studenti Delle Universita</em>, <em>11</em>, 98–106.
</div>
<div id="ref-Eckart-Young1936" class="csl-entry">
Eckart, C., and Young, G. (1936). <a href="https://doi.org/10.1007/BF02288367">The approximation of one matrix by another of lower rank</a>. <em>Psychometrika</em>, <em>1</em>(3), 211–218.
</div>
<div id="ref-Moore1920" class="csl-entry">
Moore, E. H. (1920). <a href="https://doi.org/10.1090%2FS0002-9904-1920-03322-7">On the reciprocal of the general algebraic matrix</a>. <em>Bulletin of the American Mathematical Society</em>, <em>26</em>(9), 394–395.
</div>
<div id="ref-Penrose1955" class="csl-entry">
Penrose, R. (1955). <a href="https://doi.org/10.1017/S0305004100030401">A generalized inverse for matrices</a>. <em>Mathematical Proceedings of the Cambridge Philosophical Society</em>, <em>51</em>(3), 406–413.
</div>
<div id="ref-Stewart1993" class="csl-entry">
Stewart, G. W. (1993). <a href="https://doi.org/10.1137/1035134">On the early history of the singular value decomposition</a>. <em>SIAM Review</em>, <em>35</em>(4), 551–566.
</div>
<div id="ref-Strang16" class="csl-entry">
Strang, G. (2016). <em>Introduction to linear algebra</em>. Wellesley-Cambridge Press.
</div>
<div id="ref-Sylvester1889" class="csl-entry">
Sylvester, J. J. (1889). <a href="https://books.google.co.jp/books?id=cxRKAQAAMAAJ&amp;pg=PA1&amp;hl=ja&amp;source=gbs_toc_r&amp;cad=2#v=onepage&amp;q&amp;f=false">On the reduction of a bilinear quantic of the <img src="https://latex.codecogs.com/png.latex?n">-th order to the form of a sum of <img src="https://latex.codecogs.com/png.latex?n"> products by a double orthogonal substitution</a>. <em>The Messenger of Mathematics</em>, <em>18</em>, 42–46.
</div>
<div id="ref-柳井-竹内-一般逆行列" class="csl-entry">
柳井晴夫，竹内啓. (1983). <em>射影行列・一般逆行列・特異値分解</em>,Vol. 10. 2018年に新装版が出版されている; 東京大学出版会.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><span class="citation" data-cites="Eckart-Young1936">(Eckart and Young, 1936, p. 213 Theorem 1)</span>, <span class="citation" data-cites="Strang16">(Strang, 2016, p. 372)</span> など．↩︎</p></li>
<li id="fn2"><p><span class="citation" data-cites="Eckart-Young1936">(Eckart and Young, 1936, p. 214)</span> によると，以前はにより正準乗数 (canonical multipliers) と呼ばれていた．↩︎</p></li>
<li id="fn3"><p><img src="https://latex.codecogs.com/png.latex?r%5Cge%5Coperatorname%7Brank%7D(A)"> であるとき，<img src="https://latex.codecogs.com/png.latex?%5Csigma_%7Br+1%7D=0"> とする．<span class="citation" data-cites="Strang16">(Strang, 2016, p. 394)</span> も参照．↩︎</p></li>
<li id="fn4"><p><span class="citation" data-cites="柳井-竹内-一般逆行列">(柳井晴夫，竹内啓, 1983)</span> も参照．↩︎</p></li>
<li id="fn5"><p><span class="citation" data-cites="柳井-竹内-一般逆行列">(柳井晴夫，竹内啓, 1983, p. 定理5.6)</span>, <span class="citation" data-cites="Strang16">(Strang, 2016, p. 395)</span> も参照．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Functional Analysis</category>
  <guid>https://162348.github.io/posts/2024/FunctionalAnalysis/SVD.html</guid>
  <pubDate>Sun, 11 Aug 2024 15:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/FunctionalAnalysis/Images/SVD.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>カーネル法の概観</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Kernels/Kernel.html</link>
  <description><![CDATA[ 





<section id="関連ページ" class="level2 unnumbered unlisted">
<h2 class="unnumbered unlisted anchored" data-anchor-id="関連ページ">関連ページ</h2>
<div id="listing-kernel-listing" class="quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Bayesian,Kernel,Python" data-listing-date-sort="1707577200000" data-listing-file-modified-sort="1723378435042" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="3" data-listing-word-count-sort="592">
<a href="../../../posts/2024/Kernels/GP.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/docs/posts/2024/Kernels/GP_files/figure-html/cell-10-output-1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Gauss 過程を用いた統計解析
</h5>
<div class="card-subtitle listing-subtitle">
実践編（回帰と分類）
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-11
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Bayesian,Kernel,Process" data-listing-date-sort="1707577200000" data-listing-file-modified-sort="1723364367142" data-listing-date-modified-sort="1723042800000" data-listing-reading-time-sort="2" data-listing-word-count-sort="216">
<a href="../../../posts/2024/Kernels/GP2.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Kernels/Images/Gibbs.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Gauss 過程を用いたベイズ推論
</h5>
<div class="card-subtitle listing-subtitle">
理論編
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-11
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Kernel" data-listing-date-sort="1699282800000" data-listing-file-modified-sort="1723694113124" data-listing-date-modified-sort="1710342000000" data-listing-reading-time-sort="2" data-listing-word-count-sort="256">
<a href="../../../posts/2023/KernelMethods/KernelMethods4Mathematicians.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2023/KernelMethods/KernelMethods.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
数学者のためのカーネル法概観
</h5>
<div class="card-subtitle listing-subtitle">
カーネル PCA と SVM を例として
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2023-11-07
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="3" data-categories="Kernel" data-listing-date-sort="1710342000000" data-listing-file-modified-sort="1723208781093" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="1" data-listing-word-count-sort="48">
<a href="../../../posts/2024/Kernels/Kernel1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<div class="listing-item-img-placeholder card-img-top" style="height: 150px;">&nbsp;</div>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
カーネル法１
</h5>
<div class="card-subtitle listing-subtitle">
カーネル平均埋め込み
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-03-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="4" data-categories="Deep,Nature,Statistics,Geometry" data-listing-date-sort="1722265200000" data-listing-file-modified-sort="1727007847871" data-listing-date-modified-sort="1723647600000" data-listing-reading-time-sort="3" data-listing-word-count-sort="597">
<a href="../../../posts/2024/Kernels/Manifold.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Kernels/Images/UMAPvSNE.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
非線型な次元縮約法の概観
</h5>
<div class="card-subtitle listing-subtitle">
最古にして最難のタスクと多様体学習
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-07-30
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="5" data-categories="Deep" data-listing-date-sort="1722178800000" data-listing-file-modified-sort="1723479691530" data-listing-date-modified-sort="1723388400000" data-listing-reading-time-sort="2" data-listing-word-count-sort="385">
<a href="../../../posts/2024/Kernels/NCL.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Kernels/Images/contrastive_repr4.jpeg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
表現学習と非線型独立成分分析
</h5>
<div class="card-subtitle listing-subtitle">
「データ理解」に向けた深層潜在変数モデル
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-07-29
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
</section>
<section id="半正定値カーネル" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> 半正定値カーネル</h1>
<section id="はじめに" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="はじめに"><span class="header-section-number">1.1</span> はじめに</h2>
<p>カーネル法は，カーネルの選択と構成が第一歩になる．</p>
<p>例えば <a href="../../../posts/2024/Kernels/GP2.html">Gauss 過程</a> は，平均関数と共分散関数＝正定値カーネルを定めるごとに定まる．従って Gauss 過程回帰などを実行する前には，適切な事前 Gauss 過程を定める半正定値カーネルを選ぶ必要がある．</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義（正定値核関数）^[[@Murphy2022 p.565] 17.1節は，半正定値核のことを Mercer 核とも呼んでいる．]">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定義（正定値核関数）<sup>1</sup>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>一般に <strong>核</strong> とは，可測関数 <img src="https://latex.codecogs.com/png.latex?E,F"> の間の写像 <img src="https://latex.codecogs.com/png.latex?K:E%5Cto%5Cmathcal%7BS%7D(F)"> をいう．ただし，<img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BS%7D(F)"> は <img src="https://latex.codecogs.com/png.latex?F"> 上の符号付き測度全体の集合とする．</p>
<p>特に <img src="https://latex.codecogs.com/png.latex?F"> 上の確率測度の全体 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BP%7D(F)"> に値を取る核を <a href="../../../posts/2024/Probability/Kernel.html"><strong>確率核</strong></a> という．</p>
<p><strong>核（関数）</strong> とは，<img src="https://latex.codecogs.com/png.latex?F"> 上に自然な <img src="https://latex.codecogs.com/png.latex?%5Csigma">-有限測度 <img src="https://latex.codecogs.com/png.latex?%5Cnu%5Cin%5Cmathcal%7BS%7D(F)"> がある際に，次を満たす積分核 <img src="https://latex.codecogs.com/png.latex?k:E%5Ctimes%20F%5Cto%5Cmathbb%7BR%7D"> をいう： <img src="https://latex.codecogs.com/png.latex?%0AK(x,A)=%5Cint_A%20k(x,y)%5C,d%5Cnu(y).%0A"></p>
<p><strong>正定値核</strong> とは，この積分核 <img src="https://latex.codecogs.com/png.latex?k"> であって，さらに半正定値関数でもあるものをいう．</p>
<p>以降，本稿でカーネルと言った場合，積分核となる関数 <img src="https://latex.codecogs.com/png.latex?k:E%5Ctimes%20F%5Cto%5Cmathbb%7BR%7D"> を指す．一般のカーネルについては，<a href="../../../posts/2024/Probability/Kernel.html">確率核の稿</a>を参照．</p>
</div>
</div>
</div>
</section>
<section id="定常カーネル" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="定常カーネル"><span class="header-section-number">1.2</span> 定常カーネル</h2>
<p>距離空間 <img src="https://latex.codecogs.com/png.latex?(T,d)"> 上の Gauss 過程 <img src="https://latex.codecogs.com/png.latex?(X_t)"> が定常的である場合，共分散関数 <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7BC%7D(s,t):=%5Coperatorname%7BE%7D%5Cbiggl%5B(X_s-%5Coperatorname%7BE%7D%5BX_s%5D)(X_t-%5Coperatorname%7BE%7D%5BX_t%5D)%5Cbiggr%5D,%5Cqquad%20s,t%5Cin%20T%0A"> は距離 <img src="https://latex.codecogs.com/png.latex?d(s,t)"> のみの関数になる．</p>
<p>このような半正定値関数 <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BC%7D"> の例を <img src="https://latex.codecogs.com/png.latex?T=%5Cmathbb%7BR%7D%5Ed"> として挙げる．</p>
<section id="poisson-核" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="poisson-核"><span class="header-section-number">1.2.1</span> Poisson 核</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義 (Poisson kernel)">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定義 (Poisson kernel)
</div>
</div>
<div class="callout-body-container callout-body">
<p>（<img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5Ed"> 上の）Poisson 核とは，Cauchy 分布 <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BC%7D(0,%5Cell%5E%7B-1%7D)"> の特性関数 <img src="https://latex.codecogs.com/png.latex?%0AK(x,y;%5Cell)=%5Cexp%5Cleft(-%5Cfrac%7B%5C%7Cx-y%5C%7C_1%7D%7B%5Cell%7D%5Cright)%0A"> をいう．</p>
</div>
</div>
</section>
<section id="sec-Gauss-kernel" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="sec-Gauss-kernel"><span class="header-section-number">1.2.2</span> Gauss 核</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義 (Gaussian Radial Basis Function kernel / Squared Exponential kernel)^[RBF は [@持橋-大羽2019 p.68]，SE は [@Rasmussen-Williams2006 p.14] の用語．[@Murphy2023] では両方が併記されている．Gaussian kernel とも呼ばれる．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定義 (Gaussian Radial Basis Function kernel / Squared Exponential kernel)<sup>2</sup>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Gauss 核（動径基底関数カーネルともいう）とは，Gauss 分布 <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BN%7D(0,%5Cell%5E%7B-2%7D)"> の特性関数 <img src="https://latex.codecogs.com/png.latex?%0AK(x,y;%5Cell):=%5Cexp%5Cleft(-%5Cfrac%7B%5Clvert%20x-y%5Crvert%5E2%7D%7B2%5Cell%5E2%7D%5Cright)%0A"> をいう．<sup>3</sup></p>
</div>
</div>
<p><a href="https://en.wikipedia.org/wiki/Radial_basis_function">Radial Basis Function</a> とは動径 <img src="https://latex.codecogs.com/png.latex?r=%5Clvert%20x%5Crvert"> の関数であることをいう．RBF カーネルと言ったとき特に Gauss 核を指すことが多いが，これは混乱を招く．<span class="citation" data-cites="Murphy2023">(Murphy, 2023)</span> では Squared Exponential kernel の語が使われているが，ここでは Gauss 核と呼ぶ．</p>
</section>
<section id="sec-ARD-kernel" class="level3" data-number="1.2.3">
<h3 data-number="1.2.3" class="anchored" data-anchor-id="sec-ARD-kernel"><span class="header-section-number">1.2.3</span> 関連度自動決定核 (ARD)</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="定義 (ARD: Autonatic Relevance Determination)^[[@MacKay1994], [@Neal1996 p.16] なども参照．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
定義 (ARD: Autonatic Relevance Determination)<sup>4</sup>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Gauss カーネルの Euclid ノルムを Mahalanobis ノルムに変更したもの <img src="https://latex.codecogs.com/png.latex?%0AK(r;%5CSigma,%5Csigma%5E2)=%5Csigma%5E2%5Cexp%5Cleft(-%5Cfrac%7Br%5E%5Ctop%5CSigma%5E%7B-1%7Dr%7D%7B2%7D%5Cright)%0A"> を関連度自動決定カーネルともいう．</p>
</div>
</div>
<p>そもそも関連度自動決定 <span class="citation" data-cites="MacKay1994">(MacKay, 1994)</span>, <span class="citation" data-cites="Neal1996">(Neal, 1996, p. 16)</span> またはスパースベイズ学習 <span class="citation" data-cites="Tipping2001">(Tipping, 2001)</span> とは，ニューラルネットワークの最初のレイヤーの荷重をスパースにするために分散不定の正規分布を事前分布として導入する，という技法である <span class="citation" data-cites="Loeliger+2016">(Loeliger et al., 2016)</span>．</p>
<p>一般に出力をスパースにするためのフレームワークとしても活用され，ARD 核はその最たる例である．</p>
</section>
<section id="matérn-核" class="level3" data-number="1.2.4">
<h3 data-number="1.2.4" class="anchored" data-anchor-id="matérn-核"><span class="header-section-number">1.2.4</span> Matérn 核</h3>
<p>ARD 核は軟化性能を持つため，見本道は無限回微分可能になってしまう．</p>
<p>これが不適な状況下では，<a href="https://en.wikipedia.org/wiki/Mat%C3%A9rn_covariance_function">Matérn 核</a> <img src="https://latex.codecogs.com/png.latex?%0AK(r;%5Cnu,%5Cell)=%5Cfrac%7B2%5E%7B1-%5Cnu%7D%7D%7B%5CGamma(%5Cnu)%7D%5Cleft(%5Cfrac%7B%5Csqrt%7B2%5Cnu%7Dr%7D%7B%5Cell%7D%5Cright)%5E%5Cnu%20K_%5Cnu%5Cleft(%5Cfrac%7B%5Csqrt%7B2%5Cnu%7Dr%7D%7B%5Cell%7D%5Cright)%0A"> などが用いられることがある．ただし，<img src="https://latex.codecogs.com/png.latex?K_%5Cnu"> は修正 Bessel 関数とする．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cnu"> は滑らか度を決定し，見本道は <img src="https://latex.codecogs.com/png.latex?%5Clfloor%5Cnu%5Crfloor"> 階 <img src="https://latex.codecogs.com/png.latex?L%5E2">-微分可能になる．<img src="https://latex.codecogs.com/png.latex?%5Cnu%5Cto%5Cinfty"> の極限で Gauss 核に収束する．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cnu=1/2"> の場合 <img src="https://latex.codecogs.com/png.latex?%0AK(r;1/2,%5Cell)=%5Cexp%5Cleft(-%5Cfrac%7Br%7D%7B%5Cell%7D%5Cright)%0A"> であり，対応する Gauss 過程は <a href="../../../posts/2024/Process/OU1.html">Ornstein-Uhlenbeck 過程</a> である．</p>
</section>
<section id="定常スペクトル核" class="level3" data-number="1.2.5">
<h3 data-number="1.2.5" class="anchored" data-anchor-id="定常スペクトル核"><span class="header-section-number">1.2.5</span> 定常スペクトル核</h3>
<p>任意の（定常な）正定値関数は，ある関数 <img src="https://latex.codecogs.com/png.latex?p"> に関して <span id="eq-spectral-decomposition"><img src="https://latex.codecogs.com/png.latex?%0AK(r)=%5Cint_%7B%5Cmathbb%7BR%7D%5Ed%7Dp(%5Comega)e%5E%7Bi%5Comega%5E%5Ctop%20r%7D%5C,d%5Comega%0A%5Ctag%7B1%7D"></span> と表せる．この <img src="https://latex.codecogs.com/png.latex?p"> は <strong>スペクトル密度</strong> という．</p>
<p><img src="https://latex.codecogs.com/png.latex?K"> が RBF 核であるとき，<img src="https://latex.codecogs.com/png.latex?p"> もそうなる： <img src="https://latex.codecogs.com/png.latex?%0Ap(%5Comega)=%5Csqrt%7B2%5Cpi%5Cell%5E2%7D%5Cexp%5Cbiggr(-2%5Cpi%5E2%5Comega%5E2%5Cell%5E2%5Cbiggl).%0A"></p>
<p>この対応を用いて，スペクトル密度 <img src="https://latex.codecogs.com/png.latex?p"> をデザインすることで，様々な正定値カーネルを得ることが出来る．</p>
<p>例えば spectral mixture kernel <span class="citation" data-cites="Wilson-Adams2013">(Wilson and Adams, 2013)</span> では，スケール母数と位置母数とについて RBF 核の混合を考えることで，新たな正定値カーネルを構成する．</p>
</section>
</section>
<section id="非定常カーネル" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="非定常カーネル"><span class="header-section-number">1.3</span> 非定常カーネル</h2>
<p>環境統計学などにおいて，空間相関の仕方が時間的に変化していくという設定がよくある．</p>
<p>このような場合は，一般の２変数の半正定値カーネル関数を考えることが有用である．</p>
<section id="多項式核" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="多項式核"><span class="header-section-number">1.3.1</span> 多項式核</h3>
<p><img src="https://latex.codecogs.com/png.latex?%0AK(x,y)=(x%5E%5Ctop%20y+c)%5EM%0A"> は非斉次項 <img src="https://latex.codecogs.com/png.latex?c"> を持つ，<img src="https://latex.codecogs.com/png.latex?M"> 次の多項式核と呼ばれる．</p>
</section>
<section id="gibbs-核" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="gibbs-核"><span class="header-section-number">1.3.2</span> Gibbs 核</h3>
<p>Gibbs 核 <span class="citation" data-cites="Gibbs1997">(Gibbs, 1997)</span> は，ハイパーパラメータ <img src="https://latex.codecogs.com/png.latex?%5Csigma,%5Cell"> を入力に依存するようにした RBF 核である： <img src="https://latex.codecogs.com/png.latex?%0AK(x,y)=%5Csigma(x)%5Csigma(y)%5Csqrt%7B%5Cfrac%7B2%5Cell(x)%5Cell(y)%7D%7B%5Cell(x)%5E2+%5Cell(y)%5E2%7D%7D%5Cexp%5Cleft(-%5Cfrac%7B%5Clvert%20x-y%5Crvert%5E2%7D%7B%5Cell(x)%5E2+%5Cell(y)%5E2%7D%5Cright).%0A"></p>
<p>このようにすることで，<img src="https://latex.codecogs.com/png.latex?%5Csigma,%5Cell"> を別の Gauss 過程でモデリングし，階層モデルを考えることもできる <span class="citation" data-cites="Heinonen+2016">(Heinonen et al., 2016)</span>．</p>
</section>
<section id="スペクトル核-remes2017" class="level3" data-number="1.3.3">
<h3 data-number="1.3.3" class="anchored" data-anchor-id="スペクトル核-remes2017"><span class="header-section-number">1.3.3</span> スペクトル核 <span class="citation" data-cites="Remes+2017">(Remes et al., 2017)</span></h3>
<p>正定値核は Fourier 変換を通じて，スペクトル密度によって指定することもできる（Bochner の定理）．</p>
<p>この手法は，非定常核に対しても <span class="citation" data-cites="Remes+2017">(Remes et al., 2017)</span> が拡張している．</p>
</section>
</section>
<section id="位相空間上の核" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="位相空間上の核"><span class="header-section-number">1.4</span> 位相空間上の核</h2>
<p>文章上の string kernel <span class="citation" data-cites="Lodhi+2002">(Lodhi et al., 2002)</span> やグラフ上の graph kernel <span class="citation" data-cites="Kriege+2020">(Kriege et al., 2020)</span> も考えられている．</p>
<section id="乱歩核" class="level3" data-number="1.4.1">
<h3 data-number="1.4.1" class="anchored" data-anchor-id="乱歩核"><span class="header-section-number">1.4.1</span> 乱歩核</h3>
<p><span class="citation" data-cites="Borgwardt+2006">(Borgwardt et al., 2006)</span> は random walk kernel を提案しており，<img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5Ed"> へ埋め込まれるようなものの計算量は <img src="https://latex.codecogs.com/png.latex?O(n%5E3d)"> である．</p>
</section>
</section>
<section id="weisfeiler-lehman-核" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="weisfeiler-lehman-核"><span class="header-section-number">1.5</span> Weisfeiler-Lehman 核</h2>
<p>さらに効率の良いカーネルとして Weisfeiler-Lehman カーネル <span class="citation" data-cites="Shervashidze+2011">(Shervashidze et al., 2011)</span> もある．</p>
</section>
<section id="核の構成" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="核の構成"><span class="header-section-number">1.6</span> 核の構成</h2>
<section id="半正定値核のなす正錐" class="level3" data-number="1.6.1">
<h3 data-number="1.6.1" class="anchored" data-anchor-id="半正定値核のなす正錐"><span class="header-section-number">1.6.1</span> 半正定値核のなす正錐</h3>
<p>半正定値核は <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BMap%7D(T%5E2,%5Cmathbb%7BR%7D)"> 上で閉凸錐をなす．すなわち， <img src="https://latex.codecogs.com/png.latex?%0Ac_1K_1+c_2K_2,%5Cqquad%20c_1,c_2%5Cge0,%0A"> とその各点収束極限は再び半正定値核である．</p>
</section>
<section id="sec-KDE" class="level3" data-number="1.6.2">
<h3 data-number="1.6.2" class="anchored" data-anchor-id="sec-KDE"><span class="header-section-number">1.6.2</span> カーネル密度推定量 (KDE)</h3>
<p>データ <img src="https://latex.codecogs.com/png.latex?%5C%7Bx_n%5C%7D%5Csubset%5Cmathcal%7BX%7D"> と半正定値核 <img src="https://latex.codecogs.com/png.latex?K"> に対して， <img src="https://latex.codecogs.com/png.latex?%0Ap(x%7C%5C%7Bx_n%5C%7D)=%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bn=1%7D%5ENK_%5Cell(x,x_n)%0A"> は再び半正定値核である．これを <strong>Parzen 窓推定量</strong> または <strong>カーネル密度推定量</strong> という．</p>
<p>これはデータの経験分布と確率核 <img src="https://latex.codecogs.com/png.latex?K"> との畳み込みになっている．<img src="https://latex.codecogs.com/png.latex?K"> として Gauss 核を用いると，これはデータ分布の軟化として使え，<a href="../../../posts/2024/Samplers/EBM.html#sec-RSM">デノイジングスコアマッチング</a>などに応用を持つ．</p>
<p>ただし，<img src="https://latex.codecogs.com/png.latex?%5Cell"> は <strong>幅</strong> (bandwidth) とよばれるハイパーパラメータである．例えば <img src="https://latex.codecogs.com/png.latex?K"> が動径 <img src="https://latex.codecogs.com/png.latex?r"> の関数であるとき， <img src="https://latex.codecogs.com/png.latex?%0AK_%5Cell(r):=%5Cfrac%7B1%7D%7B%5Cell%7DK%5Cleft(%5Cfrac%7Br%7D%7B%5Cell%7D%5Cright)%0A"> などと導入できる．</p>
</section>
<section id="カーネル回帰" class="level3" data-number="1.6.3">
<h3 data-number="1.6.3" class="anchored" data-anchor-id="カーネル回帰"><span class="header-section-number">1.6.3</span> カーネル回帰</h3>
<p>データが <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D=%5C%7B(x_i,y_i)%5C%7D_%7Bi=1%7D%5En"> という形で与えられ，平均 <img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7BE%7D%5BY%7CX,%5Cmathcal%7BD%7D%5D"> を推定することを考える．</p>
<p>この際，まず結合密度を次の形で推定する： <img src="https://latex.codecogs.com/png.latex?%0Ap(y,x%7C%5Cmathcal%7BD%7D)=%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi=1%7D%5EnK_%5Cell(x,x_i)K_%5Cell(y,y_i)%0A"> これを用いると，次のように平均が推定できる： <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D%5BY%7CX,%5Cmathcal%7BD%7D%5D=%5Cint_%7B%5Cmathcal%7BY%7D%7D%20yp(y%7CX,%5Cmathcal%7BD%7D)%5C,dy=%5Csum_%7Bi=1%7D%5Eny_iw_i(x),%5Cqquad%20w_i(x):=%5Cfrac%7BK_%5Cell(x,x_i)%7D%7B%5Csum_%7Bj=1%7D%5EnK_%5Cell(x,x_j)%7D.%0A"></p>
<p>この手続きを，カーネル回帰 / カーネル平滑化 / <span class="citation" data-cites="Nadaraya1964">(Nadaraya, 1964)</span>-<span class="citation" data-cites="Watson1964">(Watson, 1964)</span> 推定量という．</p>
</section>
<section id="局所線型回帰-llr" class="level3" data-number="1.6.4">
<h3 data-number="1.6.4" class="anchored" data-anchor-id="局所線型回帰-llr"><span class="header-section-number">1.6.4</span> 局所線型回帰 (LLR)</h3>
<p>カーネル回帰では <img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7BE%7D%5BY%7CX,%5Cmathcal%7BD%7D%5D"> を，<img src="https://latex.codecogs.com/png.latex?%5C%7By_i%5C%7D"> の適切な線型和として予測していた．</p>
<p>代わりに， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmu(x):=%5Cmin_%7B%5Cbeta%7D%5Csum_%7Bi=1%7D%5En%5Cbiggr(y_i-%5Cbeta%5E%5Ctop%5Cphi(x_i)%5Cbiggl)%5E2K_%5Cell(x,x_i)%0A"> によって <img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7BE%7D%5BY%7CX,%5Cmathcal%7BD%7D%5D"> を予測することを，局所線型回帰 (locally linear regression) または <a href="https://en.wikipedia.org/wiki/Local_regression">LOWESS (Locally Weighted Scatterplot Smoothing)</a> <span class="citation" data-cites="Cleveland1979">(Cleveland, 1979)</span>, <span class="citation" data-cites="Cleveland-Devlin1988">(Cleveland and Devlin, 1988)</span>，または <a href="https://en.wikipedia.org/wiki/Savitzky%E2%80%93Golay_filter">Savitsky-Golay フィルター</a> <span class="citation" data-cites="Savitzky-Golay1964">(Savitzky and Golay, 1964)</span> という．</p>
</section>
<section id="半正定値構成" class="level3" data-number="1.6.5">
<h3 data-number="1.6.5" class="anchored" data-anchor-id="半正定値構成"><span class="header-section-number">1.6.5</span> 半正定値構成</h3>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="命題">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
命題
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?K:T%5E2%5Cto%5Cmathbb%7BC%7D"> を半正定値，<img src="https://latex.codecogs.com/png.latex?f:%5Cmathcal%7BX%7D%5Cto%5Cmathbb%7BC%7D"> を関数とする． <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidetilde%7BK%7D(x,y):=f(x)K(x,y)%5Coverline%7Bf(y)%7D%0A"> は再び半正定値である．</p>
</div>
</div>
</section>
<section id="核の押し出し" class="level3" data-number="1.6.6">
<h3 data-number="1.6.6" class="anchored" data-anchor-id="核の押し出し"><span class="header-section-number">1.6.6</span> 核の押し出し</h3>
<p><img src="https://latex.codecogs.com/png.latex?S%5E1%5Csimeq%5B0,2%5Cpi)"> 上の確率分布は，方向データとして，海洋学における波の方向，気象学における風向のモデリングに応用を持つ．</p>
<p>全射 <img src="https://latex.codecogs.com/png.latex?%5Cpi:%5Cmathbb%7BR%7D%5Ctwoheadrightarrow%20S%5E1"> に従って，<img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D">-値の Gauss 過程を，方向データ値の Gauss 過程に押し出すことが出来る <span class="citation" data-cites="Jona-Lasinio+2012">(Jona-Lasinio et al., 2012)</span>．</p>
<p>これに伴い，<img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D">-値の核 <img src="https://latex.codecogs.com/png.latex?K:%5Cmathbb%7BR%7D%5Cto%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D)"> を <img src="https://latex.codecogs.com/png.latex?S%5E1">-値に押し出すこともできる： <img src="https://latex.codecogs.com/png.latex?%0A%5Cpi_*K:%5Cmathbb%7BR%7D%5Cto%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D)%5Cxrightarrow%7B%5Cpi_*%7D%5Cmathcal%7BP%7D(S%5E1).%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cpi"> による Gauss 分布の押し出し <img src="https://latex.codecogs.com/png.latex?%5Cpi_*%5Cmathrm%7BN%7D_1(%5Cmu,%5Csigma%5E2)"> は <a href="https://en.wikipedia.org/wiki/Wrapped_normal_distribution">wrapped normal distribution</a> と呼ばれている．これに対応し，この Gauss 過程は wrapped Gaussian process と呼ばれている <span class="citation" data-cites="Jona-Lasinio+2012">(Jona-Lasinio et al., 2012)</span>．</p>
</section>
</section>
<section id="sec-RFF" class="level2" data-number="1.7">
<h2 data-number="1.7" class="anchored" data-anchor-id="sec-RFF"><span class="header-section-number">1.7</span> 核の Monte Carlo 近似</h2>
<section id="カーネルの近似" class="level3" data-number="1.7.1">
<h3 data-number="1.7.1" class="anchored" data-anchor-id="カーネルの近似"><span class="header-section-number">1.7.1</span> カーネルの近似</h3>
<p>以上，種々のカーネル関数を紹介してきたが，これらはデータに関して効率的に計算される必要がある．</p>
<p>特に潜在空間上での Gram 行列の逆行列または Cholesky 分解を計算する <img src="https://latex.codecogs.com/png.latex?O(n%5E3)"> の複雑性が難点である <span class="citation" data-cites="Liu+2020">(Liu et al., 2020)</span>．</p>
<p>このデータ数 <img src="https://latex.codecogs.com/png.latex?n"> に関してスケールしない点が従来カーネル法の難点とされてきたが，これはランダムなカーネル関数を用いた Monte Carlo 近似によって高速化できる．<img src="https://latex.codecogs.com/png.latex?m"> 個のランダムに選択された基底関数を用いれば，Monte Carlo 誤差を許して計算量は <img src="https://latex.codecogs.com/png.latex?O(nm+m%5E3)"> にまで圧縮できる．</p>
</section>
<section id="random-fourier-features" class="level3" data-number="1.7.2">
<h3 data-number="1.7.2" class="anchored" data-anchor-id="random-fourier-features"><span class="header-section-number">1.7.2</span> Random Fourier Features</h3>
<p>正定値核のスペクトル表現 (1) を通じて，核の値 <img src="https://latex.codecogs.com/png.latex?K(x,y)"> を Monte Carlo 近似をすることが出来る．</p>
<p>例えば <img src="https://latex.codecogs.com/png.latex?K"> が RBF 核であるとき，<img src="https://latex.codecogs.com/png.latex?p"> は正規密度になるから，Gauss 確率変数からのサンプリングを通じてこれを実現できる： <img src="https://latex.codecogs.com/png.latex?%0AK(x,y)%5Capprox%5Cphi(x)%5E%5Ctop%5Cphi(y),%5Cqquad%20%5Cphi(x):=%5Csqrt%7B%5Cfrac%7B1%7D%7BD%7D%7D%5Cbegin%7Bpmatrix%7D%5Csin(Z%5E%5Ctop%20x)%5C%5C%5Ccos(Z%5E%5Ctop%20x)%5Cend%7Bpmatrix%7D,Z=(z_%7Bij%7D),z_%7Bij%7D%5Coverset%7B%5Ctext%7Biid%7D%7D%7B%5Csim%7D%5Cmathrm%7BN%7D(0,%5Csigma%5E%7B-2%7D).%0A"></p>
<p>これは核の値 <img src="https://latex.codecogs.com/png.latex?K(x,y)"> を，逆に（ランダムに定まる）特徴ベクトル <img src="https://latex.codecogs.com/png.latex?%5Cphi(x),%5Cphi(y)"> の値を通じて計算しているため，Random Fourier Features <span class="citation" data-cites="Rahimi-Recht2007">(Rahimi and Recht, 2007)</span>, <span class="citation" data-cites="Sutherland-Schneider2015">(Sutherland and Schneider, 2015)</span>，または Random Kitchen Sinks <span class="citation" data-cites="Rahimi-Recht2008">(Rahimi and Recht, 2008)</span> と呼ばれる．</p>
<p><img src="https://latex.codecogs.com/png.latex?Z"> の行を互いに直交するように取ることで，Monte Carlo 推定の精度が上がる．これを orthogonal random features <span class="citation" data-cites="Yu+2016">(Yu et al., 2016)</span> と呼ぶ．</p>
</section>
</section>
</section>
<section id="sec-metric-learning" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> 距離学習</h1>
<section id="はじめに-1" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="はじめに-1"><span class="header-section-number">2.1</span> はじめに</h2>
<p>２つのデータ点 <img src="https://latex.codecogs.com/png.latex?x_1,x_2%5Cin%5Cmathcal%7BX%7D"> に対して，その意味論的な距離 <img src="https://latex.codecogs.com/png.latex?d(x_1,x_2)"> を学習することを考える．</p>
<p>これはある種の表現学習として，分類，クラスタリング，<a href="../../../posts/2024/Kernels/Manifold.html">次元縮約</a> などの事前タスクとしても重要である．顔認識など，computer vision への応用が大きい．</p>
<p>古典的には，<img src="https://latex.codecogs.com/png.latex?K">-近傍分類器と対置させ，これが最大の精度を発揮するような距離を学習することが考えられる</p>
<p>また，ニューラルネットワークにより埋め込み <img src="https://latex.codecogs.com/png.latex?f:%5Cmathcal%7BX%7D%5Chookrightarrow%5Cmathbb%7BR%7D%5Ed"> を構成し，その後 <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5Ed"> 上の Euclid 距離を <img src="https://latex.codecogs.com/png.latex?d"> として用いるとき，これを <strong>深層距離学習</strong> (deep metric learning) という．</p>
<p>深層距離学習では距離学習自体が下流タスクとなっており，その性能が深層埋め込み <img src="https://latex.codecogs.com/png.latex?f"> に依存している．実際，深層距離学習の性能は芳しいと言えないことが知られている <span class="citation" data-cites="Musgrave+2020">(Musgrave et al., 2020)</span>．</p>
</section>
<section id="k-近傍分類" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="k-近傍分類"><span class="header-section-number">2.2</span> <img src="https://latex.codecogs.com/png.latex?K">-近傍分類</h2>
<p>ラベル付きデータ <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D=%5C%7B(x_i,y_i)%5C%7D%5Csubset%5Cmathcal%7BX%7D%5Ctimes%5BC%5D"> が与えられているとする．</p>
<p><img src="https://latex.codecogs.com/png.latex?K">-近傍分類法は，「<img src="https://latex.codecogs.com/png.latex?x"> の近傍上位 <img src="https://latex.codecogs.com/png.latex?K"> 個のデータに訊いてみる」という方法であり，こうして得る事後確率 <img src="https://latex.codecogs.com/png.latex?%0Ap(y=c%7Cx,%5Cmathcal%7BD%7D)=%5Cfrac%7B1%7D%7BK%7D%5Csum_%7Bi%5Cin%5Cmathcal%7BD%7D_K(x)%7D1_%7B%5Cleft%5C%7By_i=c%5Cright%5C%7D%7D%0A"> から <img src="https://latex.codecogs.com/png.latex?x"> のラベルを予測する．</p>
<p>この事後分布をさらにクラスタリングに用いたものが <a href="../../../posts/2024/Computation/VI.html"><img src="https://latex.codecogs.com/png.latex?K">-平均法</a> <span class="citation" data-cites="MacQueen1967">(MacQueen, 1967)</span>, <span class="citation" data-cites="Lloyd1982">(Lloyd, 1982)</span> である</p>
<p><a href="https://ja.wikipedia.org/wiki/K近傍法"><img src="https://latex.codecogs.com/png.latex?K">-近傍法</a>はそのシンプルな発想に拘らず一致性と，良い収束レートを持つ <span class="citation" data-cites="Chaudhuri-DasGupta2014">(Chaudhuri and Dasgupta, 2014)</span>．</p>
<p>一様カーネル <img src="https://latex.codecogs.com/png.latex?%0AK(r;%5Cell):=%5Cfrac%7B1%7D%7B2%5Cell%7D1_%7B%5B0,%5Cell%5D%7D(r)%0A"> が定める密度推定量を，どの</p>
</section>
<section id="mahalanobis-距離の学習" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="mahalanobis-距離の学習"><span class="header-section-number">2.3</span> Mahalanobis 距離の学習</h2>
<p><img src="https://latex.codecogs.com/png.latex?%0Ad(x_1,x_2;M):=%5Csqrt%7B(x_1-x_2)%5E%5Ctop%20M(x_1-x_2)%7D%0A"> というパラメトリックモデルを過程し，<img src="https://latex.codecogs.com/png.latex?M"> を学習することを考える．</p>
<section id="大マージン最近傍-lmnn-weinberger2005" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="大マージン最近傍-lmnn-weinberger2005"><span class="header-section-number">2.3.1</span> 大マージン最近傍 <span class="citation" data-cites="Weinberger+2005">(LMNN, Kilian Q. Weinberger et al., 2005)</span></h3>
<p>Large margin nearest neighbor (LMNN) <span class="citation" data-cites="Weinberger+2005">(Kilian Q. Weinberger et al., 2005)</span>, <span class="citation" data-cites="Weinberger-Saul2009">(Kilian Q. Weinberger and Saul, 2009)</span> は，<img src="https://latex.codecogs.com/png.latex?K">-近傍分類器による後続タスクが最も精度が良くなるように <img src="https://latex.codecogs.com/png.latex?M"> を学習する方法をいう．</p>
<p>各データ番号 <img src="https://latex.codecogs.com/png.latex?i%5Cin%5Bn%5D"> に対して，これと似ているデータ番号の集合 <img src="https://latex.codecogs.com/png.latex?N_i%5Csubset%5Bn%5D"> が与えられているとする（ラベルが同一であるデータ点など）．これに対して，<img src="https://latex.codecogs.com/png.latex?%5Clambda%5Cin(0,1),m%5Cge0"> をハイパーパラメータとして， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D(M):=(1-%5Clambda)%5Cmathcal%7BL%7D%5E-(M)+%5Clambda%5Cmathcal%7BL%7D%5E+(M),%5Cqquad%5Clambda%5Cin(0,1),%0A"> <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D%5E-(M):=%5Csum_%7Bi=1%7D%5En%5Csum_%7Bj%5Cin%20N_i%7Dd(x_i,x_j;M)%5E2,%5Cquad%5Cmathcal%7BL%7D%5E+(M):=%5Csum_%7Bi=1%7D%5En%5Csum_%7Bj%5Cin%20N_i%7D%5Csum_%7Bk=1%7D%5EN%5Cdelta_%7Bik%7D%5Cbiggr(m+d(x_i,x_j;M)%5E2-d(x_i,x_k;M)%5E2%5Cbiggl)%5E2,%0A"> を最小化するように <img src="https://latex.codecogs.com/png.latex?M"> を学習する．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D"> は凸関数であるため，半正定値計画法が適用できる．また，<img src="https://latex.codecogs.com/png.latex?M:=W%5E%5Ctop%20W"> によりパラメータ変換をして，<img src="https://latex.codecogs.com/png.latex?W"> に関して解くことで，問題の凸性を失う代わりに次元数を削減できる．</p>
</section>
<section id="sec-NCA" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="sec-NCA"><span class="header-section-number">2.3.2</span> 近傍成分分析 <span class="citation" data-cites="Goldberger+2004">(NCA, Goldberger et al., 2004)</span></h3>
<p>近傍成分分析 (NCA: Neighborhood Component Analysis) <span class="citation" data-cites="Goldberger+2004">(Goldberger et al., 2004)</span> では <img src="https://latex.codecogs.com/png.latex?W"> を学習する．</p>
<p>類似度行列 <img src="https://latex.codecogs.com/png.latex?W"> に関して，<a href="../../../posts/2024/Kernels/Manifold.html#sec-SNE">確率的近傍埋め込み</a> でも使うモデル <img src="https://latex.codecogs.com/png.latex?%0Ap_%7Bij%7D%5EW:=%5Cfrac%7B%5Cexp%5Cleft(-%5Clvert%20Wx_i-Wx_j%5Crvert%5E2%5Cright)%7D%7B%5Csum_%7Bk%5Cneq%20i%7D%5Cexp%5Cleft(-%5Clvert%20Wx_i-Wx_k%5Crvert%5E2%5Cright)%7D%0A"> を考える．各 <img src="https://latex.codecogs.com/png.latex?i%5Cin%5Bn%5D"> について，<img src="https://latex.codecogs.com/png.latex?x_i"> 以外のデータから <img src="https://latex.codecogs.com/png.latex?x_j"> のラベルを <img src="https://latex.codecogs.com/png.latex?1">-近傍分類器で正しく予測する確率が最大になるように， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D(W):=1-%5Cfrac%7B1%7D%7BN%7DJ(W),%5Cquad%20J(W):=%5Csum_%7Bi=1%7D%5En%5Csum_%7B(i,j)%5Cin%20E%7Dp_%7Bij%7D%5EW%0A"> を最小化するように学習する．ただし，辺の集合 <img src="https://latex.codecogs.com/png.latex?E"> は，ラベルの同じデータを結ぶとした．</p>
</section>
</section>
<section id="sec-deep-metric-learning" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="sec-deep-metric-learning"><span class="header-section-number">2.4</span> 深層距離学習</h2>
<section id="分類に基づく目的関数" class="level3" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="分類に基づく目的関数"><span class="header-section-number">2.4.1</span> 分類に基づく目的関数</h3>
<p>深層距離学習では目的関数の設定が重要である．</p>
<p>最も初等的には，自己符号化器などで分類問題を解き，その内部表現（よく最後から２層目を用いる）での Euclid 距離を距離関数に用いる方法がある．</p>
<p>しかし，距離の情報を学習するために，分類タスクは弱すぎるようである．</p>
</section>
<section id="者比較に基づく目的関数" class="level3" data-number="2.4.2">
<h3 data-number="2.4.2" class="anchored" data-anchor-id="者比較に基づく目的関数"><span class="header-section-number">2.4.2</span> ２者比較に基づく目的関数</h3>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D(%5Ctheta;x_i,x_j):=%5Cdelta_%7By_i,y_j%7Dd(z_i,z_j)%5E2+(1-%5Cdelta_%7By_i,y_j%7D)%5Cbiggr(m-d(z_i,z_j)%5E2%5Cbiggl)_+,%5Cqquad%20z_i=f_%5Ctheta(x_i)%0A"> という損失関数は <strong>対照的損失</strong> (contrastive loss) <span class="citation" data-cites="Chopra+2005">(Chopra et al., 2005)</span> と呼ばれる．</p>
<p>この損失はラベル <img src="https://latex.codecogs.com/png.latex?y_i,y_j"> が同一のデータ <img src="https://latex.codecogs.com/png.latex?x_i,x_j"> の潜在表現の距離を近づけ，ラベルが異なるデータは <img src="https://latex.codecogs.com/png.latex?m"> 以上は話すように埋め込み <img src="https://latex.codecogs.com/png.latex?f_%5Ctheta"> を学習する．</p>
<p>この際に用いるニューラルネットワークは，同時に２つの入力 <img src="https://latex.codecogs.com/png.latex?x_i,x_j"> をとって学習することから，<strong>双子ネットワーク</strong> (Siamese network) とも呼ばれる．</p>
</section>
<section id="sec-triplet-loss" class="level3" data-number="2.4.3">
<h3 data-number="2.4.3" class="anchored" data-anchor-id="sec-triplet-loss"><span class="header-section-number">2.4.3</span> ３者比較に基づく目的関数</h3>
<p>この方法は直ちに三子損失 (triplet loss) <span class="citation" data-cites="Schroff+2015">(Schroff et al., 2015)</span>，<img src="https://latex.codecogs.com/png.latex?n">-ペア損失 (<img src="https://latex.codecogs.com/png.latex?n">-pair loss) <span class="citation" data-cites="Sohn2016">(Sohn, 2016)</span>, <span class="citation" data-cites="Oord+2018">(Oord et al., 2018)</span> に拡張された．</p>
<p>このことにより，<img src="https://latex.codecogs.com/png.latex?x_i,x_j"> の「近さ」のスケールと「遠さ」のスケールが一致し，安定した結果が得られる．</p>
<p>三子損失は，各データ <img src="https://latex.codecogs.com/png.latex?x_i"> に対して，「似ている」ペア <img src="https://latex.codecogs.com/png.latex?x_i%5E+"> と「似ていない」ペア <img src="https://latex.codecogs.com/png.latex?x_i%5E-"> を事前に選び， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D(%5Ctheta;x_i,x_i%5E+,x_i%5E-):=%5Cbiggr(d_%5Ctheta(x_i,x_i%5E+)%5E2-d_%5Ctheta(x_i,x_i%5E-)%5E2+m%5Cbiggl)_+,%5Cqquad%20m%5Cin%5Cmathbb%7BR%7D%0A"> と定められる．このとき，<img src="https://latex.codecogs.com/png.latex?x_i"> は参照点 (anchor) と呼ばれる．</p>
<p>この方法は <img src="https://latex.codecogs.com/png.latex?x_i%5E+,x_i%5E-"> を選ばなければいけないが，その分拡張性に優れる．<a href="../../../posts/2024/Kernels/NCL.html">ノイズ対照学習</a> の稿も参照．</p>
<p><img src="https://latex.codecogs.com/png.latex?n">-ペア損失では，負のデータ <img src="https://latex.codecogs.com/png.latex?x_i%5E-"> をさらに増やす．これは <span class="citation" data-cites="Oord+2019">(Oord et al., 2019 Contrastive Predictive Coding)</span> にて，<a href="../../../posts/2024/Kernels/NCL.html#sec-CPC">InfoMax の観点から表現学習に用いられたもの</a>と一致する．</p>
</section>
<section id="者比較の加速" class="level3" data-number="2.4.4">
<h3 data-number="2.4.4" class="anchored" data-anchor-id="者比較の加速"><span class="header-section-number">2.4.4</span> ３者比較の加速</h3>
<p>負の例 <img src="https://latex.codecogs.com/png.latex?x_i%5E-"> を特に情報量が高いもの <span class="citation" data-cites="Faghri+2018">(hard negatives, Faghri et al., 2018)</span> を選ぶことで，学習を加速させることができる．</p>
<p>これは，３者損失を提案した Google の <a href="https://en.wikipedia.org/wiki/FaceNet">FaceNet</a> <span class="citation" data-cites="Schroff+2015">(Schroff et al., 2015)</span> で考えられた戦略である．</p>
<p>クラスラベルが得られる場合，各クラスから代表的なデータを選んでおくことで <img src="https://latex.codecogs.com/png.latex?O(n)"> にまで加速できる <span class="citation" data-cites="Movshovitz-Attias+2017">(Movshovitz-Attias et al., 2017)</span>．この代表点は固定して１つに定める必要はなく，ソフトな形で選べる <span class="citation" data-cites="Qian+2019">(Qian et al., 2019)</span>．</p>
</section>
</section>
</section>



<div id="quarto-appendix" class="default"><section id="終わりに" class="level1 appendix" data-number="3"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3</span> 終わりに</h2><div class="quarto-appendix-contents">

<p>ここで扱った深層距離学習は，現代的には<a href="../../../posts/2024/Kernels/NCL.html">表現学習</a>として更なる発展を見ている．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Borgwardt+2006" class="csl-entry">
Borgwardt, K., Schraudolph, N., and Vishwanathan, S. v. n. (2006). <a href="https://proceedings.neurips.cc/paper_files/paper/2006/file/e37b08dd3015330dcbb5d6663667b8b8-Paper.pdf">Fast computation of graph kernels</a>. In B. Schölkopf, J. Platt, and T. Hoffman, editors, <em>Advances in neural information processing systems</em>,Vol. 19. MIT Press.
</div>
<div id="ref-Chaudhuri-DasGupta2014" class="csl-entry">
Chaudhuri, K., and Dasgupta, S. (2014). <a href="https://proceedings.neurips.cc/paper_files/paper/2014/file/db957c626a8cd7a27231adfbf51e20eb-Paper.pdf">Rates of convergence for nearest neighbor classification</a>. In Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K. Q. Weinberger, editors, <em>Advances in neural information processing systems</em>,Vol. 27. Curran Associates, Inc.
</div>
<div id="ref-Chopra+2005" class="csl-entry">
Chopra, S., Hadsell, R., and LeCun, Y. (2005). <a href="https://doi.org/10.1109/CVPR.2005.202">Learning a similarity metric discriminatively, with application to face verification</a>. <em>2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05)</em>, <em>1</em>, 539–546.
</div>
<div id="ref-Cleveland1979" class="csl-entry">
Cleveland, W. S. (1979). <a href="https://doi.org/10.1080/01621459.1979.10481038">Robust locally weighted regression and smoothing scatterplots</a>. <em>Journal of the American Statistical Association</em>, <em>74</em>(368), 829–836.
</div>
<div id="ref-Cleveland-Devlin1988" class="csl-entry">
Cleveland, W. S., and Devlin, S. J. (1988). <a href="https://doi.org/10.1080/01621459.1988.10478639">Locally weighted regression: An approach to regression analysis by local fitting</a>. <em>Journal of the American Statistical Association</em>, <em>83</em>(403), 596–610.
</div>
<div id="ref-Faghri+2018" class="csl-entry">
Faghri, F., Fleet, D. J., Kiros, J. R., and Fidler, S. (2018). <a href="https://arxiv.org/abs/1707.05612">VSE++: Improving visual-semantic embeddings with hard negatives</a>.
</div>
<div id="ref-Gibbs1997" class="csl-entry">
Gibbs, M. N. (1997). <em>Bayesian gaussian process regression and classification</em> (PhD thesis). Cambridge University. Retrieved from <a href="https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=b5a0c62c8d7cf51137bfb079947b8393c00ed169">https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=b5a0c62c8d7cf51137bfb079947b8393c00ed169</a>
</div>
<div id="ref-Goldberger+2004" class="csl-entry">
Goldberger, J., Hinton, G. E., Roweis, S., and Salakhutdinov, R. R. (2004). <a href="https://proceedings.neurips.cc/paper_files/paper/2004/file/42fe880812925e520249e808937738d2-Paper.pdf">Neighbourhood components analysis</a>. In L. Saul, Y. Weiss, and L. Bottou, editors, <em>Advances in neural information processing systems</em>,Vol. 17. MIT Press.
</div>
<div id="ref-Heinonen+2016" class="csl-entry">
Heinonen, M., Mannerström, H., Rousu, J., Kaski, S., and Lähdesmäki, H. (2016). <a href="https://proceedings.mlr.press/v51/heinonen16.html">Non-stationary gaussian process regression with hamiltonian monte carlo</a>. In A. Gretton and C. C. Robert, editors, <em>Proceedings of the 19th international conference on artificial intelligence and statistics</em>,Vol. 51, pages 732–740. Cadiz, Spain: PMLR.
</div>
<div id="ref-Jona-Lasinio+2012" class="csl-entry">
Jona-Lasinio, G., Gelfand, A., and Jona-Lasinio, M. (2012). <a href="http://www.jstor.org/stable/41713483">SPATIAL ANALYSIS OF WAVE DIRECTION DATA USING WRAPPED GAUSSIAN PROCESSES</a>. <em>The Annals of Applied Statistics</em>, <em>6</em>(4), 1478–1498.
</div>
<div id="ref-Kriege+2020" class="csl-entry">
Kriege, N. M., Johansson, F. D., and Morris, C. (2020). <a href="https://doi.org/10.1007/s41109-019-0195-3">A survey on graph kernels</a>. <em>Applied Network Science</em>, <em>5</em>(1), 6.
</div>
<div id="ref-Liu+2020" class="csl-entry">
Liu, H., Ong, Y.-S., Shen, X., and Cai, J. (2020). <a href="https://doi.org/10.1109/TNNLS.2019.2957109">When gaussian process meets big data: A review of scalable GPs</a>. <em>IEEE Transactions on Neural Networks and Learning Systems</em>, <em>31</em>(11), 4405–4423.
</div>
<div id="ref-Lloyd1982" class="csl-entry">
Lloyd, S. (1982). <a href="https://ieeexplore.ieee.org/document/1056489">Least squares quantization in PCM</a>. <em>IEEE Transactions on Information Theory</em>, <em>28</em>(2), 129–137.
</div>
<div id="ref-Lodhi+2002" class="csl-entry">
Lodhi, H., Saunders, C., Shawe-Taylor, J., Cristianini, N., and Watkins, C. (2002). <a href="https://www.jmlr.org/papers/v2/lodhi02a.html">Text classification using string kernels</a>. <em>Journal of Machine Learning Research</em>, <em>2</em>, 419–444.
</div>
<div id="ref-Loeliger+2016" class="csl-entry">
Loeliger, H.-A., Bruderer, L., Malmberg, H., Wadehn, F., and Zalmai, N. (2016). <a href="https://doi.org/10.1109/ITA.2016.7888168">On sparsity by NUV-EM, gaussian message passing, and kalman smoothing</a>. In <em>2016 information theory and applications workshop (ITA)</em>, pages 1–10.
</div>
<div id="ref-MacKay1994" class="csl-entry">
MacKay, D. J. C. (1994). <em>Bayesian nonlinear modeling for the prediction competition</em> (No. 2),Vol. 100. American Society of Heating, Refrigerating,; Air Conditioning Engineers (ASHRAE). Retrieved from <a href="https://www.osti.gov/biblio/33309">https://www.osti.gov/biblio/33309</a>
</div>
<div id="ref-MacQueen1967" class="csl-entry">
MacQueen, J. (1967). <a href="https://projecteuclid.org/ebooks/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-Fifth-Berkeley-Symposium-on-Mathematical-Statistics-and/chapter/Some-methods-for-classification-and-analysis-of-multivariate-observations/bsmsp/1200512992">Some methods for classification and analysis of multivariate observations</a>. In <em>Proceedings of the fifth berkeley symposium on mathematical statistics and probability</em>,Vol. 1, pages 281–297.
</div>
<div id="ref-Movshovitz-Attias+2017" class="csl-entry">
Movshovitz-Attias, Y., Toshev, A., Leung, T. K., Ioffe, S., and Singh, S. (2017). <a href="https://doi.org/10.1109/ICCV.2017.47">No fuss distance metric learning using proxies</a>. In <em>2017 IEEE international conference on computer vision (ICCV)</em>, pages 360–368. Los Alamitos, CA, USA: IEEE Computer Society.
</div>
<div id="ref-Murphy2022" class="csl-entry">
Murphy, K. P. (2022). <em><a href="https://probml.github.io/pml-book/book1.html">Probabilistic machine learning: An introduction</a></em>. MIT Press.
</div>
<div id="ref-Murphy2023" class="csl-entry">
Murphy, K. P. (2023). <em><a href="http://probml.github.io/book2">Probabilistic machine learning: Advanced topics</a></em>. MIT Press.
</div>
<div id="ref-Musgrave+2020" class="csl-entry">
Musgrave, K., Belongie, S., and Lim, S.-N. (2020). A metric learning reality check. In A. Vedaldi, H. Bischof, T. Brox, and J.-M. Frahm, editors, <em>Computer vision – ECCV 2020</em>, pages 681–699. Cham: Springer International Publishing.
</div>
<div id="ref-Nadaraya1964" class="csl-entry">
Nadaraya, E. A. (1964). <a href="https://doi.org/10.1137/1109020">On estimating regression</a>. <em>Theory of Probability &amp; Its Applications</em>, <em>9</em>(1), 141–142.
</div>
<div id="ref-Neal1996" class="csl-entry">
Neal, R. M. (1996). <em><a href="https://link.springer.com/book/10.1007/978-1-4612-0745-0">Bayesian learning for neural networks</a></em>,Vol. 118. Springer New York.
</div>
<div id="ref-Oord+2018" class="csl-entry">
Oord, A. van den, Li, Y., Babuschkin, I., Simonyan, K., Vinyals, O., Kavukcuoglu, K., … Hassabis, D. (2018). <a href="https://proceedings.mlr.press/v80/oord18a.html">Parallel <span>W</span>ave<span>N</span>et: Fast high-fidelity speech synthesis</a>. In J. Dy and A. Krause, editors, <em>Proceedings of the 35th international conference on machine learning</em>,Vol. 80, pages 3918–3926. PMLR.
</div>
<div id="ref-Oord+2019" class="csl-entry">
Oord, A. van den, Li, Y., and Vinyals, O. (2019). <a href="https://arxiv.org/abs/1807.03748">Representation learning with contrastive predictive coding</a>.
</div>
<div id="ref-Qian+2019" class="csl-entry">
Qian, Q., Shang, L., Sun, B., Hu, J., Li, H., and Jin, R. (2019). <a href="https://openaccess.thecvf.com/content_ICCV_2019/html/Qian_SoftTriple_Loss_Deep_Metric_Learning_Without_Triplet_Sampling_ICCV_2019_paper.html">SoftTriple loss: Deep metric learning without triplet sampling</a>. In <em>Proceedings of the IEEE/CVF international conference on computer vision (ICCV)</em>.
</div>
<div id="ref-Rahimi-Recht2007" class="csl-entry">
Rahimi, A., and Recht, B. (2007). <a href="https://proceedings.neurips.cc/paper_files/paper/2007/file/013a006f03dbc5392effeb8f18fda755-Paper.pdf">Random features for large-scale kernel machines</a>. In J. Platt, D. Koller, Y. Singer, and S. Roweis, editors, <em>Advances in neural information processing systems</em>,Vol. 20. Curran Associates, Inc.
</div>
<div id="ref-Rahimi-Recht2008" class="csl-entry">
Rahimi, A., and Recht, B. (2008). <a href="https://proceedings.neurips.cc/paper_files/paper/2008/file/0efe32849d230d7f53049ddc4a4b0c60-Paper.pdf">Weighted sums of random kitchen sinks: Replacing minimization with randomization in learning</a>. In D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, <em>Advances in neural information processing systems</em>,Vol. 21. Curran Associates, Inc.
</div>
<div id="ref-Rasmussen-Williams2006" class="csl-entry">
Rasmussen, C. E., and Williams, C. K. I. (2006). <em><a href="https://direct.mit.edu/books/book/2320/Gaussian-Processes-for-Machine-Learning">Gaussian processes for machine learning</a></em>. The MIT Press.
</div>
<div id="ref-Remes+2017" class="csl-entry">
Remes, S., Heinonen, M., and Kaski, S. (2017). <a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/c65d7bd70fe3e5e3a2f3de681edc193d-Paper.pdf">Non-stationary spectral kernels</a>. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, <em>Advances in neural information processing systems</em>,Vol. 30. Curran Associates, Inc.
</div>
<div id="ref-Savitzky-Golay1964" class="csl-entry">
Savitzky, Abraham., and Golay, M. J. E. (1964). <a href="https://doi.org/10.1021/ac60214a047">Smoothing and differentiation of data by simplified least squares procedures.</a> <em>Analytical Chemistry</em>, <em>36</em>(8), 1627–1639. doi: 10.1021/ac60214a047.
</div>
<div id="ref-Schroff+2015" class="csl-entry">
Schroff, F., Kalenichenko, D., and Philbin, J. (2015). <a href="https://openaccess.thecvf.com/content_cvpr_2015/html/Schroff_FaceNet_A_Unified_2015_CVPR_paper.html">FaceNet: A unified embedding for face recognition and clustering</a>. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR)</em>.
</div>
<div id="ref-Shervashidze+2011" class="csl-entry">
Shervashidze, N., Schweitzer, P., Leeuwen, E. J. van, Mehlhorn, K., and Borgwardt, K. M. (2011). <a href="http://jmlr.org/papers/v12/shervashidze11a.html">Weisfeiler-lehman graph kernels</a>. <em>Journal of Machine Learning Research</em>, <em>12</em>(77), 2539–2561.
</div>
<div id="ref-Sohn2016" class="csl-entry">
Sohn, K. (2016). <a href="https://proceedings.neurips.cc/paper_files/paper/2016/file/6b180037abbebea991d8b1232f8a8ca9-Paper.pdf">Improved deep metric learning with multi-class n-pair loss objective</a>. In D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett, editors, <em>Advances in neural information processing systems</em>,Vol. 29. Curran Associates, Inc.
</div>
<div id="ref-Sutherland-Schneider2015" class="csl-entry">
Sutherland, D. J., and Schneider, J. (2015). On the error of random fourier features. In <em>Proceedings of the thirty-first conference on uncertainty in artificial intelligence</em>, pages 862–871. Arlington, Virginia, USA: AUAI Press.
</div>
<div id="ref-Tipping2001" class="csl-entry">
Tipping, M. E. (2001). <a href="https://www.jmlr.org/papers/v1/tipping01a.html">Sparse bayesian learning and the relevance vector machine</a>. <em>Journal of Machine Learning Research</em>, <em>1</em>, 211–244.
</div>
<div id="ref-Watson1964" class="csl-entry">
Watson, G. S. (1964). <a href="http://www.jstor.org/stable/25049340">Smooth regression analysis</a>. <em>Sankhyā: The Indian Journal of Statistics, Series A (1961-2002)</em>, <em>26</em>(4), 359–372.
</div>
<div id="ref-Weinberger+2005" class="csl-entry">
Weinberger, Kilian Q., Blitzer, J., and Saul, L. (2005). <a href="https://proceedings.neurips.cc/paper_files/paper/2005/file/a7f592cef8b130a6967a90617db5681b-Paper.pdf">Distance metric learning for large margin nearest neighbor classification</a>. In Y. Weiss, B. Schölkopf, and J. Platt, editors, <em>Advances in neural information processing systems</em>,Vol. 18. MIT Press.
</div>
<div id="ref-Weinberger-Saul2009" class="csl-entry">
Weinberger, Kilian Q., and Saul, L. K. (2009). <a href="http://jmlr.org/papers/v10/weinberger09a.html">Distance metric learning for large margin nearest neighbor classification</a>. <em>Journal of Machine Learning Research</em>, <em>10</em>(9), 207–244.
</div>
<div id="ref-Wilson-Adams2013" class="csl-entry">
Wilson, A., and Adams, R. (2013). <a href="https://proceedings.mlr.press/v28/wilson13.html">Gaussian process kernels for pattern discovery and extrapolation</a>. In S. Dasgupta and D. McAllester, editors, <em>Proceedings of the 30th international conference on machine learning</em>,Vol. 28, pages 1067–1075. Atlanta, Georgia, USA: PMLR.
</div>
<div id="ref-Yu+2016" class="csl-entry">
Yu, F. X. X., Suresh, A. T., Choromanski, K. M., Holtmann-Rice, D. N., and Kumar, S. (2016). <a href="https://proceedings.neurips.cc/paper_files/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf">Orthogonal random features</a>. In D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett, editors, <em>Advances in neural information processing systems</em>,Vol. 29. Curran Associates, Inc.
</div>
<div id="ref-持橋-大羽2019" class="csl-entry">
持橋大地, and 大羽成征. (2019). <em><a href="https://www.kspub.co.jp/book/detail/1529267.html">ガウス過程と機械学習</a></em>. 講談社.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><span class="citation" data-cites="Murphy2022">(Murphy, 2022, p. 565)</span> 17.1節は，半正定値核のことを Mercer 核とも呼んでいる．↩︎</p></li>
<li id="fn2"><p>RBF は <span class="citation" data-cites="持橋-大羽2019">(持橋大地 and 大羽成征, 2019, p. 68)</span>，SE は <span class="citation" data-cites="Rasmussen-Williams2006">(Rasmussen and Williams, 2006, p. 14)</span> の用語．<span class="citation" data-cites="Murphy2023">(Murphy, 2023)</span> では両方が併記されている．Gaussian kernel とも呼ばれる．↩︎</p></li>
<li id="fn3"><p>他のパラメータの入れ方もある．例えば <a href="https://gpy.readthedocs.io/en/deploy/GPy.kern.src.html#GPy.kern.src.rbf.RBF"><code>GPy</code> での実装</a> は <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2%5Cexp%5Cleft(-%5Cfrac%7Br%5E2%7D%7B2%7D%5Cright)"> を採用している．Fourier 変換や偏微分方程式論の文脈では <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B1%7D%7B(4%5Cpi%20t)%5E%7Bd/2%7D%7D%5Cexp%5Cleft(-%5Cfrac%7Br%5E2%7D%7B4%7D%5Cright)"> も良く用いられる．これは熱方程式の基本解になるためである．↩︎</p></li>
<li id="fn4"><p><span class="citation" data-cites="MacKay1994">(MacKay, 1994)</span>, <span class="citation" data-cites="Neal1996">(Neal, 1996, p. 16)</span> なども参照．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Kernel</category>
  <guid>https://162348.github.io/posts/2024/Kernels/Kernel.html</guid>
  <pubDate>Fri, 09 Aug 2024 15:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Kernels/Images/Gibbs.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>フローベース模型による条件付き生成</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Samplers/NF3.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="関連ページ" class="level3 unnumbered unlisted">
<h3 class="unnumbered unlisted anchored" data-anchor-id="関連ページ">関連ページ</h3>
<div id="listing-diffusion-listing" class="quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Deep,Process,Sampling" data-listing-date-sort="1707836400000" data-listing-file-modified-sort="1727007848002" data-listing-date-modified-sort="1724338800000" data-listing-reading-time-sort="5" data-listing-word-count-sort="826">
<a href="../../../posts/2024/Samplers/Diffusion.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/DDPM_outputs.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
拡散模型
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル６
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Deep,Sampling,P(X)" data-listing-date-sort="1707836400000" data-listing-file-modified-sort="1727007848139" data-listing-date-modified-sort="1724770800000" data-listing-reading-time-sort="4" data-listing-word-count-sort="794">
<a href="../../../posts/2024/Samplers/NF1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/linear/output.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ニューラル常微分方程式
</h5>
<div class="card-subtitle listing-subtitle">
シミュレーションなしの拡散モデルとしての連続正規化流
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Deep,Nature,Sampling" data-listing-date-sort="1711724400000" data-listing-file-modified-sort="1727007848003" data-listing-date-modified-sort="1722438000000" data-listing-reading-time-sort="5" data-listing-word-count-sort="880">
<a href="../../../posts/2024/Samplers/EBM.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/NCL/thumb_checkerboard.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
エネルギーベースモデル
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル５
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-03-30
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>
<section id="誘導" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="誘導"><span class="header-section-number">1</span> 誘導</h2>
<p>拡散模型の美点には，条件付けが可能で拡張性に優れているという点もある．</p>
<p>実際，拡散模型の出現後，Conditional VAE <span class="citation" data-cites="Kingma+2014">(Kingma et al., 2014)</span> などの従来手法を凌駕する条件付き生成が可能であることが直ちに理解された．</p>
<p><img src="https://latex.codecogs.com/png.latex?C"> がクラスラベルなどの離散変数である場合，「誘導」による条件付き生成が初めに考えられた．</p>
<section id="はじめに" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="はじめに"><span class="header-section-number">1.1</span> はじめに</h3>
<p>「誘導」ではまず，DDPM <span class="citation" data-cites="Ho+2020">(Ho et al., 2020)</span> でタイムステップ <img src="https://latex.codecogs.com/png.latex?t"> を positional encoding したようにして，プロンプト <img src="https://latex.codecogs.com/png.latex?c"> をデータに埋め込む．<sup>1</sup></p>
<p>そしてデータ <img src="https://latex.codecogs.com/png.latex?X"> とそのラベル <img src="https://latex.codecogs.com/png.latex?C"> に対して，条件付き分布 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D%5BX%7CC%5D"> をモデリングする．</p>
<p>しかしこのアプローチの問題は，ラベル <img src="https://latex.codecogs.com/png.latex?C"> が不確実な場合などは，この情報を無視して普通の <img src="https://latex.codecogs.com/png.latex?X"> が生成されてしまいがちであることである．</p>
<p>そこで目的関数に，条件付き分布 <img src="https://latex.codecogs.com/png.latex?X%7CC"> の正確性を期すような追加のデザインをする．これが「誘導」である．</p>
</section>
<section id="条件付きスコア場" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="条件付きスコア場"><span class="header-section-number">1.2</span> 条件付きスコア場</h3>
<p>条件付き分布 <img src="https://latex.codecogs.com/png.latex?p(x%7Cc)"> を学習することを考える．</p>
<p>このとき <img src="https://latex.codecogs.com/png.latex?p(x%7Cc)"> のスコアは，Bayes の定理から次のように表せる： <img src="https://latex.codecogs.com/png.latex?%0A%5Clog%20p(x%7Cc)=%5Clog%20p(c%7Cx)+%5Clog%20p(x)-%5Clog%20p(c),%0A"> <span id="eq-conditioned-score"><img src="https://latex.codecogs.com/png.latex?%0A%5Ctherefore%5Cqquad%5Cnabla_x%5Clog%20p(x%7Cc)=%5Cnabla_x%5Clog%20p(x)+%5Cnabla_x%5Clog%20p(c%7Cx).%0A%5Ctag%7B1%7D"></span></p>
<p>すなわち，条件付き確率 <img src="https://latex.codecogs.com/png.latex?p(x%7Cc)"> のスコア場は，条件なしのスコア場 <img src="https://latex.codecogs.com/png.latex?%5Cnabla_x%5Clog%20p(x)"> と，分類器のスコア場 <img src="https://latex.codecogs.com/png.latex?%5Cnabla_x%5Clog%20p(c%7Cx)"> の重ね合わせになる．</p>
</section>
<section id="sec-CG" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="sec-CG"><span class="header-section-number">1.3</span> 分類器による誘導 (CG)</h3>
<p>式 (1) から，<img src="https://latex.codecogs.com/png.latex?%5Cnabla_x%5Clog%20p(x%7Cc)"> が計算できる分類器 <img src="https://latex.codecogs.com/png.latex?p(c%7Cx)"> を新たに訓練すれば，既存のモデル <img src="https://latex.codecogs.com/png.latex?%5Cnabla_x%5Clog%20p(x)"> から，サンプリング方法を変えるだけで条件付き生成ができる．</p>
<p>これを <strong>CG: Classifier Guidance</strong> <span class="citation" data-cites="Dhariwal-Nichol2021">(Dhariwal and Nichol, 2021)</span> といい，サンプリング中に各ステップで少しずつ <img src="https://latex.codecogs.com/png.latex?x_t"> が <img src="https://latex.codecogs.com/png.latex?p(x_t%7Cc)"> に近づくように「誘導」されていく．</p>
<p>さらに，<img src="https://latex.codecogs.com/png.latex?c"> が無視されがちな場合も見越して，誘導スケール (guidance scale) という新たなハイパーパラメータ <img src="https://latex.codecogs.com/png.latex?%5Clambda%5Cge0"> を導入し，次のスコア <span id="eq-CG-score"><img src="https://latex.codecogs.com/png.latex?%0A%5Cnabla_x%5Clog%20p(x)+%5Clambda%5Cnabla_x%5Clog%20p(c%7Cx).%0A%5Ctag%7B2%7D"></span> からサンプリングすることも考えられる．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Clambda%3E1"> としどんどん大きくしていくと，クラスラベル <img src="https://latex.codecogs.com/png.latex?c"> に「典型的な」サンプルが生成される傾向にある．</p>
</section>
<section id="分類器なしの誘導" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="分類器なしの誘導"><span class="header-section-number">1.4</span> 分類器なしの誘導</h3>
<p>CG はいわばアドホックな方法であり，外部の分類器 <img src="https://latex.codecogs.com/png.latex?p(c%7Cx)"> に頼らない方法を考えたい．</p>
<p>そのためには，式 (2) から <img src="https://latex.codecogs.com/png.latex?p(c%7Cx)"> を消去して <span id="eq-CFG-score"><img src="https://latex.codecogs.com/png.latex?%0A%5Clambda%5Cnabla_x%5Clog%20p(x%7Cc)+(1-%5Clambda)%5Cnabla_x%5Clog%20p(x)%0A%5Ctag%7B3%7D"></span> とみて，<img src="https://latex.codecogs.com/png.latex?p(x%7Cc),p(x)"> のいずれもデータから学ぶ．</p>
<p>このアプローチを <strong>Classifier-Free Diffusion Guidance</strong> <span class="citation" data-cites="Ho-Salimans2021">(Ho and Salimans, 2021)</span> という．</p>
<p>その際は，新たなクラスラベル <img src="https://latex.codecogs.com/png.latex?%5Cemptyset"> を導入して <img src="https://latex.codecogs.com/png.latex?%0Ap(x)=p(x%7C%5Cemptyset)%0A"> とみなすことで，<img src="https://latex.codecogs.com/png.latex?p(x%7Cc),p(x)"> を同一の <a href="../../../posts/2024/Samplers/Diffusion.html#sec-score-network">スコアネットワーク</a> でモデリングする．</p>
<p>データセット内にランダムに1から2割の画像をクラスラベル <img src="https://latex.codecogs.com/png.latex?%5Cemptyset"> と設定することで，これを実現する．</p>
<p>同様の方法を，スコアマッチングではなくフローマッチングを行うことを <span class="citation" data-cites="Dao+2023">(Dao et al., 2023)</span>, <span class="citation" data-cites="Zheng+2023GuidedFlow">(Q. Zheng et al., 2023)</span> が提案している．</p>
<p>この方法は，追加の分類器の訓練が必要ないだけでなく，サンプリングのクオリティも向上する <span class="citation" data-cites="Nichol+2022">(Nichol et al., 2022)</span>, <span class="citation" data-cites="Saharia+2022SIGGRAPH">(Saharia, Chan, Chang, et al., 2022)</span>．これは分類タスクで訓練されたスコア <img src="https://latex.codecogs.com/png.latex?%5Clog%20p(c%7Cx)"> はどう訓練してもスコアネットワークで学習したスコア (3) に匹敵する「良い」勾配が得られないためである．</p>
</section>
<section id="高解像度画像生成への応用" class="level3" data-number="1.5">
<h3 data-number="1.5" class="anchored" data-anchor-id="高解像度画像生成への応用"><span class="header-section-number">1.5</span> 高解像度画像生成への応用</h3>
<section id="sec-CascadedGeneration" class="level4" data-number="1.5.1">
<h4 data-number="1.5.1" class="anchored" data-anchor-id="sec-CascadedGeneration"><span class="header-section-number">1.5.1</span> Cascaded Generation</h4>
<p>条件付き生成の技術はそのままで，最終的なクオリティを向上させるためには，Cascading <span class="citation" data-cites="Ho+2022">(Ho et al., 2022)</span> が使用可能である．</p>
<p>これは，画像生成は <img src="https://latex.codecogs.com/png.latex?x"> の解像度が低い状態で行い，この低解像度画像を次の条件付き拡散モデルの条件付け <img src="https://latex.codecogs.com/png.latex?c"> として，条件付き生成を <strong>高解像度化</strong> (super-resolution) に用いるものである <span class="citation" data-cites="Saharia+2023">(Saharia et al., 2023)</span>．</p>
<p>この方法の美点は，条件付き生成器をたくさんスタックしたのちに，拡散模型間の段階でも Gauss ノイズや blur を印加することで，さらに最終的なクオリティが上げられるという <span class="citation" data-cites="Ho+2022">(Ho et al., 2022)</span>．これを <strong>conditioning augmentation</strong> と呼んでいる．</p>
<p>この方法は最初から高解像度での生成を目指して大規模な単一の拡散模型を設計するよりも大きく計算コストを削減できる．</p>
<p>Google も <a href="https://imagen.research.google/">Imagen</a> <span class="citation" data-cites="Saharia+2022">(Saharia, Chan, Saxena, et al., 2022)</span> でこのアーキテクチャを用いている．</p>
</section>
<section id="self-conditioning-chen2023analogbits" class="level4" data-number="1.5.2">
<h4 data-number="1.5.2" class="anchored" data-anchor-id="self-conditioning-chen2023analogbits"><span class="header-section-number">1.5.2</span> Self-Conditioning <span class="citation" data-cites="Chen+2023AnalogBits">(T. Chen et al., 2023)</span></h4>
<p>拡散モデルを自己再帰的に用い，自身の前回の出力を今回の入力として逐次的にサンプリングを繰り返すことで，サンプリングのクオリティをさらに向上する自己条件づけが <span class="citation" data-cites="Chen+2023AnalogBits">(T. Chen et al., 2023)</span> で提案された．</p>
<p>この方法は RoseTTAFold Diffusion <span class="citation" data-cites="Watson+2023">(Watson et al., 2023)</span> によるたんぱく質構造生成でも用いられている：</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/RFDiff.gif" class="img-fluid figure-img"></p>
<figcaption>RFdiffusion generating a novel protein that binds to the insulin receptor. Taken from <a href="https://www.bakerlab.org/2023/07/11/diffusion-model-for-protein-design/">Baker Lab HP</a></figcaption>
</figure>
</div>
</section>
</section>
</section>
<section id="sec-2" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="sec-2"><span class="header-section-number">2</span> フローマッチングによる連続な条件付け</h2>
<section id="sec-CCG" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="sec-CCG"><span class="header-section-number">2.1</span> 連続な条件付き生成</h3>
<p>連続な変数に対する条件付き確率からの生成は CcGAN <span class="citation" data-cites="Ding+2021">(Ding et al., 2021)</span> などでも試みられていた．</p>
<p>AlphaFold 3 <span class="citation" data-cites="Abramson+2024">(Abramson et al., 2024)</span> や RoseTTAFold Diffusion <span class="citation" data-cites="Watson+2023">(Watson et al., 2023)</span>, <span class="citation" data-cites="Krishna+2024">(Krishna et al., 2024)</span> など，たんぱく質構造生成模型において拡散モデルが用いられている理由も，高精度な条件付き生成が可能であることが大きいという．</p>
<p>このことに加えて連続な変数に対する条件付けを可能にすることは，拡散モデルの拡張性をさらに高めることになる．</p>
<p>そもそも拡散モデルは <a href="../../../posts/2024/Samplers/NF1.html#sec-FM">連続時間正規化流</a> (CNF) と合流し，フローマッチング（第 2.2 節）によりノイズ分布 <img src="https://latex.codecogs.com/png.latex?P_0"> をデータ分布 <img src="https://latex.codecogs.com/png.latex?P_1"> に変換する曲線 <img src="https://latex.codecogs.com/png.latex?%5C%7BP_t%5C%7D_%7Bt%5Cin%5B0,1%5D%7D%5Csubset%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)"> を直接学習するように発展した．</p>
<p>この方法では，新たな条件付け変数 <img src="https://latex.codecogs.com/png.latex?c%5Cin%5B0,1%5D%5Ek"> に対して，連続写像 <img src="https://latex.codecogs.com/png.latex?%0AP_%7Bt,c%7D:%5B0,1%5D%5Ctimes%5B0,1%5D%5Ek%5Cto%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)%0A"> を学習するようにフローマッチングを拡張できれば，連続な条件付き生成が可能になることになる．</p>
<p>これを行列値ベクトル場の理論を通じて達成するのが <strong>拡張フローマッチング</strong> (EFM: Extended Flow Matching) <span class="citation" data-cites="Isobe+2024">(Isobe et al., 2024)</span> である．</p>
<p>このようなフローマッチングの拡張は <span class="citation" data-cites="Chen-Lipman2024">(R. T. Q. Chen and Lipman, 2024)</span> でも考えられている．</p>
</section>
<section id="sec-FM" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="sec-FM"><span class="header-section-number">2.2</span> フローマッチング (FM)</h3>
<p>２つの確率分布 <img src="https://latex.codecogs.com/png.latex?P_0,P_1%5Cin%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)"> を結ぶ曲線を <img src="https://latex.codecogs.com/png.latex?%0A(P_t)=((%5Cphi_t)_*P_0)_%7Bt%5Cin%5B0,1%5D%7D%5Cin%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5B0,1%5D%7D%0A"> の形で学習することを考える．</p>
<p>そのための１つのアプローチとして，<a href="https://ja.wikipedia.org/wiki/連続の方程式">連続方程式</a> というPDE <span id="eq-CE"><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%5Cpartial%20p_t%7D%7B%5Cpartial%20t%7D+%5Coperatorname%7Bdiv%7D(F_tp_t)=0.%0A%5Ctag%7B4%7D"></span> を満たすベクトル場 <img src="https://latex.codecogs.com/png.latex?F_t"> を学習し，これが定めるフローを <img src="https://latex.codecogs.com/png.latex?(%5Cphi_t)"> とすることがある：</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%5Cpartial%20%5Cphi_t(x)%7D%7B%5Cpartial%20t%7D=F_t(%5Cphi_t(x)).%0A"></p>
<p>このような <img src="https://latex.codecogs.com/png.latex?F_t"> が１つ既知であり，<img src="https://latex.codecogs.com/png.latex?p_t"> から自由にサンプリングできる場合は， <span id="eq-FM-objective"><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D_%7B%5Cmathrm%7BFM%7D%7D(%5Ctheta)=%5Coperatorname%7BE%7D%5Cbiggl%5B%5Cbiggl%7CF_%5Ctheta(X_T,T)-F_T(X_T)%5Cbiggr%7C%5E2%5Cbiggr%5D,%5Cqquad%20T%5Csim%5Cmathrm%7BU%7D(%5B0,1%5D),X_T%5Csim%20p_T,%0A%5Ctag%7B5%7D"></span> の最小化によってベクトル場 <img src="https://latex.codecogs.com/png.latex?F_t"> が学習できる．これを <strong>フローマッチング</strong> (FM: Flow Matching) の目的関数という．</p>
</section>
<section id="条件付きフローマッチング-cfm" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="条件付きフローマッチング-cfm"><span class="header-section-number">2.3</span> 条件付きフローマッチング (CFM)</h3>
<p>仮に <img src="https://latex.codecogs.com/png.latex?p_t"> が <img src="https://latex.codecogs.com/png.latex?%0Ap_t(x)=%5Cint_%5COmega%20p_t(x%7Cc)q(c)%5C,dc,%5Cqquad%5COmega%5Csubset%5Cmathbb%7BR%7D%5Ek,%0A"> という <img src="https://latex.codecogs.com/png.latex?p_%7Bt,c%7D(x):=p_t(x%7Cc)"> の <img src="https://latex.codecogs.com/png.latex?q">-混合としての展開を通じて得られているとする．</p>
<p>この場合，<img src="https://latex.codecogs.com/png.latex?(p_%7Bt,c%7D)"> を生成するベクトル場 <img src="https://latex.codecogs.com/png.latex?F_t(x%7Cc)"> が特定できれば， <span id="eq-marginal-VF"><img src="https://latex.codecogs.com/png.latex?%0AF_t(x):=%5Coperatorname%7BE%7D%5Cleft%5B%5Cfrac%7BF_t(x%7CU)p_t(x%7CU)%7D%7Bp_t(x)%7D%5Cright%5D%0A%5Ctag%7B6%7D"></span> が <img src="https://latex.codecogs.com/png.latex?(p_t)"> を生成する <span class="citation" data-cites="Lipman+2023">(定理1 Lipman et al., 2023)</span>, <span class="citation" data-cites="Tong+2024">(定理3.1 Tong et al., 2024)</span>．</p>
<p>従って，<img src="https://latex.codecogs.com/png.latex?F_t"> を学習するには FM 目的関数 (5) の代わりに <span id="eq-CFM-objective"><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D_%7B%5Cmathrm%7BCFM%7D%7D(%5Ctheta)=%5Coperatorname%7BE%7D%5Cbiggl%5B%5Cbiggl%7CF_%5Ctheta(X_T,T)-F_T(X%7CC)%5Cbiggr%7C%5E2%5Cbiggr%5D,%5Cqquad%20C%5Csim%20q,%0A%5Ctag%7B7%7D"></span> の最小化によっても <img src="https://latex.codecogs.com/png.latex?F_t(x%7Cc)"> が学習できる．これを <strong>条件付きフローマッチング</strong> (CFM: Conditional Flow Matching) の目的関数という．</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="$P_0$ が Gauss 分布である場合 [@Lipman+2023]">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<img src="https://latex.codecogs.com/png.latex?P_0"> が Gauss 分布である場合 <span class="citation" data-cites="Lipman+2023">(Lipman et al., 2023)</span>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?P_0=%5Cmathrm%7BN%7D_d(0,I_d)"> をノイズ分布，<img src="https://latex.codecogs.com/png.latex?P_1"> を一般のデータ分布とする．</p>
<p>ただし，誤差を許して，<img src="https://latex.codecogs.com/png.latex?P_1*%5Cmathrm%7BN%7D_d(0,%5Csigma%5E2I_d)"> を改めて真のデータ分布とする．</p>
<p>このように定式化することで，各データ点 <img src="https://latex.codecogs.com/png.latex?c%5Cin%5C%7Bx_i%5C%7D_%7Bi=1%7D%5En"> で条件づければ， <img src="https://latex.codecogs.com/png.latex?%0AP_%7B0,c%7D:=P_0(-%7Cc)=%5Cmathrm%7BN%7D_d(0,I_d),%5Cqquad%20P_%7B1,c%7D:=P_1(-%7Cc)=%5Cmathrm%7BN%7D_d(0,%5Csigma%5E2I_d),%0A"> の間を結ぶ曲線 <img src="https://latex.codecogs.com/png.latex?(P_%7Bt,c%7D)_%7Bt%5Cin%5B0,1%5D,c%5Cin%5C%7Bx_i%5C%7D_%7Bi=1%7D%5En%7D"> を学習する問題となる．</p>
<p>実は <img src="https://latex.codecogs.com/png.latex?P_%7B0,c%7D,P_%7B1,c%7D"> が Gauss 分布であることにより，この問題はすでに <span class="citation" data-cites="McCann1997">(McCann, 1997, p. 159)</span> によって解かれており，最適輸送は <img src="https://latex.codecogs.com/png.latex?%0AP_%7Bt,c%7D=%5Cmathrm%7BN%7D_d%5Cbiggr(tc,(t%5Csigma-t+1)%5E2I_d%5Cbiggl),%5Cqquad%20F_t(x%7Cc)=%5Cfrac%7Bc-(1-%5Csigma)x%7D%7B1-(1-%5Csigma)t%7D,%0A"> によって与えられる．</p>
</div>
</div>
</div>
<p>しかし，各 <img src="https://latex.codecogs.com/png.latex?(P_%7Bt,c%7D)_%7Bt%5Cin%5B0,1%5D%7D"> が最適輸送になっていても，式 (6) で定まる <img src="https://latex.codecogs.com/png.latex?(P_t)_%7Bt%5Cin%5B0,1%5D%7D"> が最適輸送になるとは限らない．</p>
</section>
<section id="最適輸送-cfm-ot-cfm" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="最適輸送-cfm-ot-cfm"><span class="header-section-number">2.4</span> 最適輸送 CFM (OT-CFM)</h3>
<p>ここで形式的に，条件付ける変数 <img src="https://latex.codecogs.com/png.latex?c"> は <a href="../../../posts/2024/Probability/Coupling.html">カップリング</a> <img src="https://latex.codecogs.com/png.latex?%5Cpi%5Cin%20C(P_0,P_1)"> に従う <img src="https://latex.codecogs.com/png.latex?C%5Csim%5Cpi"> とする： <img src="https://latex.codecogs.com/png.latex?%0AC(P_0,P_1):=%5Cleft%5C%7B%5Cpi%5Cin%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed%5Ctimes%5Cmathbb%7BR%7D%5Ed)%5C:%5Cmiddle%7C%5C:%5Cbegin%7Barray%7D%7Bl%7D(%5Cmathrm%7Bpr%7D_1)_*%5Cpi=P_0,%5C%5C(%5Cmathrm%7Bpr%7D_2)_*%5Cpi=P_1%5Cend%7Barray%7D%5Cright%5C%7D.%0A"></p>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="$P_0$ も一般の分布である場合 [I-CFM @Tong+2024]">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<img src="https://latex.codecogs.com/png.latex?P_0"> も一般の分布である場合 <span class="citation" data-cites="Tong+2024">(I-CFM Tong et al., 2024)</span>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?Q_0,Q_1"> は未知のデータ分布で， <img src="https://latex.codecogs.com/png.latex?%0AP_1=Q_1*%5Cmathrm%7BN%7D_d(0,%5Csigma%5E2I_d),%5Cqquad%20P_0=Q_0*%5Cmathrm%7BN%7D_d(0,%5Csigma%5E2I_d),%0A"> の間を架橋したいとする．このとき， <img src="https://latex.codecogs.com/png.latex?%0A%5Cpi:=Q_0%5Cotimes%20Q_1%0A"> と定めると， <img src="https://latex.codecogs.com/png.latex?%0AP_%7Bt,c%7D=%5Cmathrm%7BN%7D_d%5Cbiggr(tc_1+(1-t)c_0,%5Csigma%5E2I_d%5Cbiggl),%5Cqquad%20F_t(x%7Cc)=c_1-c_0,%0A"> が <img src="https://latex.codecogs.com/png.latex?P_0,P_1"> の間の輸送を定める <span class="citation" data-cites="Tong+2024">(命題3.3 Tong et al., 2024)</span>．</p>
<p>加えて，<img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cto0"> の極限において，学習される輸送 <img src="https://latex.codecogs.com/png.latex?(P_t)"> は <img src="https://latex.codecogs.com/png.latex?Q_0,Q_1"> の間の輸送になる．</p>
<p>これは <span class="citation" data-cites="Lipman+2023">(Lipman et al., 2023)</span> の例の，<img src="https://latex.codecogs.com/png.latex?P_0,P_1"> を対称に扱った拡張と見れる．</p>
<p>また，<img src="https://latex.codecogs.com/png.latex?P_%7Bt,c%7D"> が <img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cto0"> とした Delta 測度である場合が Rectified Flow <span class="citation" data-cites="Liu+2023-Flow">(Liu et al., 2023)</span> に当たる．</p>
<p>この方法を拡張し，例えば平均を線型関数 <img src="https://latex.codecogs.com/png.latex?m(t)=tc_1+(1-t)c_0"> の代わりに <img src="https://latex.codecogs.com/png.latex?%0Am(t)=%5Ccos%5Cleft(%5Cfrac%7B%5Cpi%20t%7D%7B2%7D%5Cright)c_0+%5Csin%5Cleft(%5Cfrac%7B%5Cpi%20t%7D%7B2%7D%5Cright)c_1%0A"> とした場合が Stochastic Interpolant <span class="citation" data-cites="Albergo-Vanden-Eijnden2023">(Albergo and Vanden-Eijnden, 2023)</span> に当たる．</p>
</div>
</div>
</div>
<p>その中でも特に，<img src="https://latex.codecogs.com/png.latex?%5Cpi"> を 2-Wasserstein 距離に関する最適輸送計画 <img src="https://latex.codecogs.com/png.latex?%0A%5Cpi:=%5Coperatorname*%7Bargmin%7D_%7B%5Cpi%5Cin%20C(P_0,P_1)%7D%5Coperatorname%7BE%7D%5B%5Clvert%20X-Y%5Crvert%5E2%5D%0A"> であるとする．</p>
<p>このとき， <img src="https://latex.codecogs.com/png.latex?%0AP_%7Bt,c%7D=%5Cmathrm%7BN%7D_d%5Cbiggr(tc_1+(1-t)c_0,%5Csigma%5E2I_d%5Cbiggl),%5Cqquad%20F_t(x%7Cc)=c_1-c_0,%0A"> を <img src="https://latex.codecogs.com/png.latex?C%5Csim%5Cpi"> に関して周辺化した輸送 <img src="https://latex.codecogs.com/png.latex?(P_t)%5Cin%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5B0,1%5D%7D"> は，<img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cto0"> の極限で（動的な）最適輸送になる <span class="citation" data-cites="Tong+2024">(命題3.4 Tong et al., 2024)</span>．</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled" title="Schrödinger Bridge のシミュレーション [SB-CFM @Tong+2024]">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Schrödinger Bridge のシミュレーション <span class="citation" data-cites="Tong+2024">(SB-CFM Tong et al., 2024)</span>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cpi_%7B2%5Csigma%5E2%7D:=%5Coperatorname*%7Bargmin%7D_%7B%5Cpi%5Cin%20C(P_0,P_1)%7D%5Cbiggr(%5Coperatorname%7BE%7D%5B%5Clvert%20X-Y%5Crvert%5E2%5D+2%5Csigma%5E2H(%5Cpi)%5Cbiggl)%0A"> を，エントロピー正則化項 <img src="https://latex.codecogs.com/png.latex?2%5Csigma%5E2"> を持ったエントロピー最適輸送計画とする．</p>
<p>このとき，各点を結んだ Broanian bridge <img src="https://latex.codecogs.com/png.latex?%0AP_%7Bt,c%7D:=%5Cmathrm%7BN%7D%5Cbiggr(tc_1+(1-t)c_0,t(1-t)%5Csigma%5E2I_d%5Cbiggl),%0A"> <img src="https://latex.codecogs.com/png.latex?%0AF_t(x%7Cc):=%5Cfrac%7B1-2t%7D%7B2t(1-t)%7D%5Cbiggr(x-(tc_1+(1-t)c_0)%5Cbiggl)+(c_1-c_0),%0A"> の周辺化 <img src="https://latex.codecogs.com/png.latex?(P_t)%5Cin%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5B0,1%5D%7D"> は，標準 Brown 運動を <img src="https://latex.codecogs.com/png.latex?%5Csigma"> だけスケールした分布 <img src="https://latex.codecogs.com/png.latex?W"> に対する Schrödinger bridge <img src="https://latex.codecogs.com/png.latex?%0A%5Cpi%5E*:=%5Coperatorname*%7Bargmin%7D_%7B%5Csubstack%7B%5Cmu_0=P_0%5C%5C%5Cmu_1=P_1%7D%7D%5Coperatorname%7BKL%7D(%5Cmu,W)%0A"> と分布同等になる <span class="citation" data-cites="Tong+2024">(定理3.5 Tong et al., 2024)</span>．</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cto0"> の極限が OT-CFM であり，<img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cto%5Cinfty"> の極限が I-CFM である．</p>
</div>
</div>
</div>
<p>訓練時は，CFM の目的関数 (7) を計算するために <img src="https://latex.codecogs.com/png.latex?(X_0,X_1)%5Csim%5Cpi"> というサンプリングが必要になる．データサイズが大きい場合には，これにミニバッチ最適輸送 <span class="citation" data-cites="Fatras+2021">(Fatras et al., 2021)</span> を用いることができる．</p>
<p>このように，２つの分布 <img src="https://latex.codecogs.com/png.latex?P_0,P_1"> を単に独立カップリングと見るのではなく，依存関係があった場合にはそれも考慮してなるべくダイナミクスが直線になるように誘導する方法 Multisample Flow Matching として <span class="citation" data-cites="Pooladian+2023">(Pooladian et al., 2023)</span> も考えている．</p>
</section>
<section id="sec-OT-CFM-in-GFM-perspective" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="sec-OT-CFM-in-GFM-perspective"><span class="header-section-number">2.5</span> <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5B0,1%5D%7D"> 上の最適化としての見方</h3>
<p>実は OT-CFM は，２つの確率密度 <img src="https://latex.codecogs.com/png.latex?p_0,p_1"> を結ぶ曲線 <img src="https://latex.codecogs.com/png.latex?(p_t)%5Cin%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5B0,1%5D%7D"> の中で，<strong>Dirichlet エネルギー</strong> <img src="https://latex.codecogs.com/png.latex?%0AD(p):=%5Cinf_%7B(p,F)%7D%5Cfrac%7B1%7D%7B2%7D%5Cint_%7B%5B0,1%5D%5Ctimes%5Cmathbb%7BR%7D%5Ed%7D%5Clvert%20F_t(x)%5Crvert%5E2p_t(x)%5C,dxdt%0A"> を最小化する曲線 <img src="https://latex.codecogs.com/png.latex?(p_t)"> を学習していると見れる <span class="citation" data-cites="Isobe+2024">(Isobe et al., 2024)</span>．ただし，<img src="https://latex.codecogs.com/png.latex?(p,F)"> は連続方程式 (4) を満たす密度とベクトル場の組とした．</p>
<p>条件付きフローマッチングでは，このような曲線 <img src="https://latex.codecogs.com/png.latex?(p_t)"> を次の方法で構成していた．</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<ol type="1">
<li>ある決定論的なダイナミクス <img src="https://latex.codecogs.com/png.latex?%5Cpsi_c:%5B0,1%5D%5Cto%5Cmathbb%7BR%7D%5Ed"> を定める．<sup>2</sup></li>
<li><img src="https://latex.codecogs.com/png.latex?Q%5Cin%5Cmathcal%7BP%7D(C%5E1(%5B0,1%5D;%5Cmathbb%7BR%7D%5Ed))"> を確率測度とする．</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cpsi,Q"> から， <img src="https://latex.codecogs.com/png.latex?%0AP%5EQ:=%5Coperatorname%7BE%7D_%7B%5Cpsi%5Csim%20Q%7D%5B%5Cdelta_%5Cpsi%5D%0A"> によって確率測度の曲線 <img src="https://latex.codecogs.com/png.latex?(P%5EQ_t)%5Cin%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5B0,1%5D%7D"> を定める．</li>
</ol>
</div>
</div>
</div>
<p>実は Dirichlet 汎函数 <img src="https://latex.codecogs.com/png.latex?D:%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5B0,1%5D%7D%5Cto%5Cmathbb%7BR%7D_+"> が凸であるために，このように構成される <img src="https://latex.codecogs.com/png.latex?(p_t)"> の中での最適解は，<img src="https://latex.codecogs.com/png.latex?Q%5Cin%5Cmathcal%7BP%7D(C%5E1(%5B0,1%5D;%5Cmathbb%7BR%7D%5Ed))"> の全体で探す必要はなく，線型なダイナミクス <img src="https://latex.codecogs.com/png.latex?%0A%5Cpsi_c(t)=tc_1+(1-t)c_0,%5Cqquad%20c=(c_0,c_1)%5Cin%5Cmathbb%7BR%7D%5Ed%5Ctimes%5Cmathbb%7BR%7D%5Ed,%0A"> の重ね合わせの形でのみ探せば良い <span class="citation" data-cites="Brenier2003">(Brenier, 2003)</span>．</p>
<p>従って，<img src="https://latex.codecogs.com/png.latex?(X_0,X_1)"> の分布の全体 <img src="https://latex.codecogs.com/png.latex?C(P_0,P_1)"> のみについてパラメータづけをして探せば良い．さらにこの場合， <img src="https://latex.codecogs.com/png.latex?%0AF_t(x%7Cc)=%5Cfrac%7B%5Cpartial%20%5Cpsi_c(t)%7D%7B%5Cpartial%20t%7D=c_1-c_0%0A"> であるから，<img src="https://latex.codecogs.com/png.latex?D(P)=2W_2(P_0,P_1)%5E2"> の最小化は <img src="https://latex.codecogs.com/png.latex?P_0,P_1"> の 2-Wasserstein 最適な輸送計画 <img src="https://latex.codecogs.com/png.latex?%5Cpi%5E*"> の探索に等価になる．</p>
<p>これが OT-CFM の <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BP%7D(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5B0,1%5D%7D"> 上の最適化としての解釈である．同時に，条件付きフローマッチングの目的関数 (7) の他に，<a href="../../../posts/2024/Samplers/EBM.html#sec-DSM">DSM</a> 様の目的関数 <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D%5Cbiggl%5B%5Cbiggl%7CF_T(%5Cpsi(T))-%5Cpartial_t%5Cpsi_C(T)%5Cbiggr%7C%5E2%5Cbiggr%5D,%5Cqquad%20T%5Csim%5Cmathrm%7BU%7D(%5B0,1%5D),C%5Csim%5Cpi%5E*,%0A"> の最小化点としてもベクトル場 <img src="https://latex.codecogs.com/png.latex?F_t"> が学習できる．</p>
</section>
<section id="sec-GFM" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="sec-GFM"><span class="header-section-number">2.6</span> 拡張フローマッチング (GFM)</h3>
<p>前節での観察は次のように要約できる：</p>
<div class="callout callout-style-simple callout-important no-icon callout-titled" title="OT-CFM の Dirichlet 汎函数最小化としての特徴付け">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
OT-CFM の Dirichlet 汎函数最小化としての特徴付け
</div>
</div>
<div class="callout-body-container callout-body">
<p>OT-CFM は，条件付きフローマッチングに対して，Dirichlet エネルギーの言葉で帰納バイアスを導入することで，最適輸送を学習するための方法論である．</p>
</div>
</div>
<p>こう考えると，Dirichlet エネルギーの言葉で他の帰納バイアスを導入することが考えられる．</p>
<p>ここで条件付けの議論（第 2.1 節）に戻ってくる．最適輸送のための <img src="https://latex.codecogs.com/png.latex?c=(c_0,c_1)%5Cin%5Cmathbb%7BR%7D%5E%7B2d%7D"> に限らず，一般の <img src="https://latex.codecogs.com/png.latex?c%5Cin%5Cmathbb%7BR%7D%5Ek"> に対して連続に条件付けされるように拡張したい．</p>
<p>これは，<img src="https://latex.codecogs.com/png.latex?(F_t),(p_t)"> の添字を <img src="https://latex.codecogs.com/png.latex?t%5Cin%5B0,1%5D"> から <img src="https://latex.codecogs.com/png.latex?%5Cxi%5Cin%5B0,1%5D%5Ctimes%5Cmathbb%7BR%7D%5Ek"> に拡張することで達成される．</p>
<p>これは新たな <img src="https://latex.codecogs.com/png.latex?(F_%5Cxi),(p_%5Cxi)"> を <img src="https://latex.codecogs.com/png.latex?M_%7Bdk%7D(%5Cmathbb%7BR%7D)">-値の行列値ベクトル場 <img src="https://latex.codecogs.com/png.latex?(F_t)"> とベクトル値密度 <img src="https://latex.codecogs.com/png.latex?(p_t)"> と見ることに等価である．すると，<strong>一般化連続方程式</strong> <span class="citation" data-cites="Brenier2003">(Brenier, 2003)</span>, <span class="citation" data-cites="Lavenant2019">(Lavenant, 2019)</span> <img src="https://latex.codecogs.com/png.latex?%0A%5Cnabla_%5Cxi%20p_%5Cxi(x)+%5Coperatorname%7Bdiv%7D_x(p_%5Cxi%20u_%5Cxi)=0%0A"> の理論を用いれば，全く同様の枠組みで可能になる <span class="citation" data-cites="Isobe+2024">(命題1 Isobe et al., 2024)</span>．</p>
<p>これが <strong>拡張フローマッチング</strong> (EFM: Extended Flow Matching) <span class="citation" data-cites="Isobe+2024">(Isobe et al., 2024)</span> である．</p>
</section>
<section id="gfm-の無限次元最適化" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="gfm-の無限次元最適化"><span class="header-section-number">2.7</span> GFM の無限次元最適化</h3>
<p>ただし，拡張 Dirichlet エネルギー <span class="citation" data-cites="Lavenant2019">(Lavenant, 2019)</span> <img src="https://latex.codecogs.com/png.latex?%0AD(P):=%5Cinf_%7B(p,F)%7D%5Cfrac%7B1%7D%7B2%7D%5Cint_%7B%5B0,1%5D%5Ctimes%5Cmathbb%7BR%7D%5Ek%5Ctimes%5Cmathbb%7BR%7D%5Ed%7D%5Clvert%20F_%5Cxi(x)%5Crvert%5E2p_%5Cxi(x)%5C,dxd%5Cxi%0A"> の第 2.5 節の形での最小化点は，もはや線型なダイナミクスの重ね合わせとは限らない．</p>
<p>すると無限次元最適化になってしまうため，適切な <a href="../../../posts/2023/KernelMethods/KernelMethods4Mathematicians.html">RKHS</a> <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BF%7D%5Csubset%5Cmathrm%7BMap%7D(%5B0,1%5D%5Ctimes%5Cmathbb%7BR%7D%5Ek;%5Cmathbb%7BR%7D%5Ed)"> 内で探すことが必要である： <img src="https://latex.codecogs.com/png.latex?%0A%5Cpsi=%5Cphi_%7Bx_%7B%5Cpartial%5CXi%7D%7D%5Cin%5Coperatorname*%7Bargmin%7D_%7Bf%5Cin%5Cmathcal%7BF%7D%7D%5Csum_%7B%5Cxi%5Cin%5Cpartial%5CXi%7D%5Clvert%20f(%5Cxi)-x_%5Cxi%5Crvert%5E2.%0A"> ただし，<img src="https://latex.codecogs.com/png.latex?%5Cpartial%5CXi%5Coverset%7B%5Ctext%7Bfinite%7D%7D%7B%5Csubset%7D%5B0,1%5D%5Ctimes%5Cmathbb%7BR%7D%5Ek"> は境界条件が与えられる点の有限集合で，<img src="https://latex.codecogs.com/png.latex?x_%5Cxi%5Cin%5Cmathbb%7BR%7D%5Ed"> はその点での値である．</p>
<p><img src="https://latex.codecogs.com/png.latex?(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5Clvert%5Cpartial%5CXi%5Crvert%7D"> 上での結合分布 <img src="https://latex.codecogs.com/png.latex?%5Cpi"> が与えられたならば， <img src="https://latex.codecogs.com/png.latex?%0A%5Cinf_%7BQ%5Cin%5Cmathcal%7BP%7D(C%5E1(%5B0,1%5D%5Ctimes%5Cmathbb%7BR%7D%5Ek;%5Cmathbb%7BR%7D%5Ed))%7DD(P%5EQ)%5Cle%5Cinf_%5Cpi%5Cint_%7B(%5Cmathbb%7BR%7D%5Ed)%5E%7B%5Clvert%5Cpartial%5CXi%5Crvert%7D%7D%5Clvert%5Cnabla_%5Cxi%5Cphi_%7Bx_%7B%5Cpartial%5CXi%7D%7D%5Crvert%5E2%5Cpi(dx_%5Cxi)%0A"> という評価が得られるが，この右辺は最適輸送の形になっており，最小値が適切な周辺分布とコスト関数 <img src="https://latex.codecogs.com/png.latex?%0Ac(x_%7B%5Cpartial%5CXi%7D):=%5Cint_%7B%5B0,1%5D%5Ctimes%5Cmathbb%7BR%7D%5Ek%7D%5Clvert%5Cnabla_%5Cxi%5Cphi_%7Bx_%7B%5Cpartial%5CXi%7D%7D(%5Cxi)%5Crvert%5E2%5C,d%5Cxi%0A"> が定める輸送計画問題になっている．</p>
<p>この解 <img src="https://latex.codecogs.com/png.latex?%5Cpi%5E*"> をミニバッチ最適輸送で解きながら，目的関数 <img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D%5Cbiggl%5B%5Cbiggl%7CF_T(%5Cpsi(T))-%5Cnabla_%5Cxi%5Cphi_%7Bx_%7B%5Cpartial%5CXi%7D%7D%5Cbiggr%7C%5E2%5Cbiggr%5D,%5Cqquad%20T%5Csim%5Cmathrm%7BU%7D(%5B0,1%5D),x_%7B%5Cpartial%5CXi%7D%5Csim%5Cpi%5E*,%0A"> の最小化点としてベクトル場 <img src="https://latex.codecogs.com/png.latex?F_t"> を学習することができる <span class="citation" data-cites="Isobe+2024">(定理4 Isobe et al., 2024)</span>．</p>
<p>これを <span class="citation" data-cites="Isobe+2024">(Isobe et al., 2024)</span> は MMOT-EFM と呼んでいる．</p>
</section>
</section>



<div id="quarto-appendix" class="default"><section id="文献紹介" class="level2 appendix" data-number="3"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3</span> 文献紹介</h2><div class="quarto-appendix-contents">

<p>本記事の後半第 2 節は，<span class="citation" data-cites="Tong+2024">(Tong et al., 2024)</span>, <span class="citation" data-cites="Isobe+2024">(Isobe et al., 2024)</span> の解説である．</p>
<p>前半の内容に関して，メンダコ氏によるブログ記事 <a href="https://horomary.hatenablog.com/entry/2024/06/30/211033">AlphaFold の進化史</a> は AlphaFold3 が丁寧に解説されている．</p>
<p>当該ブログは丁寧に書かれており，大変おすすめできる．</p>
<blockquote class="blockquote">
<p>Alphafold3とは長大な条件付けネットワークを備えた全原子拡散生成モデルであると前述したとおり、Alphafold3では必須入力としてタンパク質配列を、任意入力として核酸配列、SMILES形式で表現された低分子リガンド、金属イオンなどを長大な条件付けネットワークに入力することで、拡散モデルへの条件付けベクトルを作成します。</p>
</blockquote>
<blockquote class="blockquote">
<p>DeepLearningで大規模分子の構造分布を予測するなんて数年前には考えられませんでしたが、拡散モデルによってすでに現実になりつつあります。一例として Distributional GraphormerというMicrosoft Researchの研究 <span class="citation" data-cites="Zheng+2024">(S. Zheng et al., 2024)</span> を紹介します。</p>
</blockquote>
<p>続きはぜひ，<a href="https://horomary.hatenablog.com/entry/2024/06/30/211033#AlphaFold3-2024">メンダコ氏のブログ</a>でお読みください．</p>
<p><span class="citation" data-cites="Dao+2023">(Dao et al., 2023)</span> のプロジェクトページは <a href="https://vinairesearch.github.io/LFM/">こちら</a>．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Abramson+2024" class="csl-entry">
Abramson, J., Adler, J., Dunger, J., Evans, R., Green, T., Pritzel, A., … Jumper, J. M. (2024). <a href="https://doi.org/10.1038/s41586-024-07487-w">Accurate structure prediction of biomolecular interactions with AlphaFold 3</a>. <em>Nature</em>, <em>630</em>(8016), 493–500.
</div>
<div id="ref-Albergo-Vanden-Eijnden2023" class="csl-entry">
Albergo, M. S., and Vanden-Eijnden, E. (2023). <a href="https://openreview.net/forum?id=li7qeBbCR1t"><span class="nocase">Building Normalizing Flows with Stochastic Interpolants</span></a>. In <em>The eleventh international conference on learning representations</em>.
</div>
<div id="ref-Brenier2003" class="csl-entry">
Brenier, Y. (2003). <a href="https://doi.org/10.1007/978-3-540-44857-0_4">Extended monge-kantorovich theory</a>. In <em>Optimal transportation and applications: Lectures given at the c.i.m.e. Summer school, held in martina franca, italy, september 2-8, 2001</em>, pages 91–121. Berlin, Heidelberg: Springer Berlin Heidelberg.
</div>
<div id="ref-Chen-Lipman2024" class="csl-entry">
Chen, R. T. Q., and Lipman, Y. (2024). <a href="https://openreview.net/forum?id=g7ohDlTITL">Flow matching on general geometries</a>. In <em>The twelfth international conference on learning representations</em>.
</div>
<div id="ref-Chen+2023AnalogBits" class="csl-entry">
Chen, T., ZHANG, R., and Hinton, G. (2023). <a href="https://openreview.net/forum?id=3itjR9QxFw">Analog bits: Generating discrete data using diffusion models with self-conditioning</a>. In <em>The eleventh international conference on learning representations</em>.
</div>
<div id="ref-Dao+2023" class="csl-entry">
Dao, Q., Phung, H., Nguyen, B., and Tran, A. (2023). <a href="https://arxiv.org/abs/2307.08698">Flow matching in latent space</a>.
</div>
<div id="ref-Dhariwal-Nichol2021" class="csl-entry">
Dhariwal, P., and Nichol, A. Q. (2021). <a href="https://openreview.net/forum?id=AAWuCvzaVt">Diffusion models beat <span>GAN</span>s on image synthesis</a>. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan, editors, <em>Advances in neural information processing systems</em>.
</div>
<div id="ref-Ding+2021" class="csl-entry">
Ding, X., Wang, Y., Xu, Z., Welch, W. J., and Wang, Z. J. (2021). <a href="https://openreview.net/forum?id=PrzjugOsDeE">Cc<span>{</span>GAN<span>}</span>: Continuous conditional generative adversarial networks for image generation</a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Fatras+2021" class="csl-entry">
Fatras, K., Zine, Y., Majewski, S., Flamary, R., Gribonval, R., and Courty, N. (2021). <a href="https://arxiv.org/abs/2101.01792">Minibatch optimal transport distances; analysis and applications</a>.
</div>
<div id="ref-Ho+2020" class="csl-entry">
Ho, J., Jain, A., and Abbeel, P. (2020). <a href="https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html"><span>Denoising Diffusion Probabilistic Models</span></a>. In <em>Advances in neural information processing systems</em>,Vol. 33.
</div>
<div id="ref-Ho+2022" class="csl-entry">
Ho, J., Saharia, C., Chan, W., Fleet, D. J., Norouzi, M., and Salimans, T. (2022). <a href="http://jmlr.org/papers/v23/21-0635.html">Cascaded diffusion models for high fidelity image generation</a>. <em>Journal of Machine Learning Research</em>, <em>23</em>(47), 1–33.
</div>
<div id="ref-Ho-Salimans2021" class="csl-entry">
Ho, J., and Salimans, T. (2021). <a href="https://openreview.net/forum?id=qw8AKxfYbI">Classifier-free diffusion guidance</a>. In <em>NeurIPS 2021 workshop on deep generative models and downstream applications</em>.
</div>
<div id="ref-Isobe+2024" class="csl-entry">
Isobe, N., Koyama, M., Zhang, J., Hayashi, K., and Fukumizu, K. (2024). <a href="https://arxiv.org/abs/2402.18839">Extended flow matching: A method of conditional generation with generalized continuity equation</a>.
</div>
<div id="ref-Kingma+2014" class="csl-entry">
Kingma, D. P., Mohamed, S., Jimenez Rezende, D., and Welling, M. (2014). <a href="https://proceedings.neurips.cc/paper_files/paper/2014/file/d523773c6b194f37b938d340d5d02232-Paper.pdf"><span class="nocase">Semi-supervised Learning with Deep Generative Models</span></a>. In Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K. Q. Weinberger, editors, <em>Advances in neural information processing systems</em>,Vol. 27. Curran Associates, Inc.
</div>
<div id="ref-Krishna+2024" class="csl-entry">
Krishna, R., Wang, J., Ahern, W., Sturmfels, P., Venkatesh, P., Kalvet, I., … Baker, D. (2024). <a href="https://doi.org/10.1126/science.adl2528">Generalized biomolecular modeling and design with RoseTTAFold all-atom</a>. <em>Science</em>, <em>384</em>(6693), eadl2528.
</div>
<div id="ref-Lavenant2019" class="csl-entry">
Lavenant, H. (2019). <a href="https://doi.org/10.1016/j.jfa.2019.05.003">Harmonic mappings valued in the wasserstein space</a>. <em>Journal of Functional Analysis</em>, <em>277</em>(3), 688–785.
</div>
<div id="ref-Lipman+2023" class="csl-entry">
Lipman, Y., Chen, R. T. Q., Ben-Hamu, H., Nickel, M., and Le, M. (2023). <a href="https://openreview.net/forum?id=PqvMRDCJT9t">Flow matching for generative modeling</a>. In <em>The eleventh international conference on learning representations</em>.
</div>
<div id="ref-Liu+2023-Flow" class="csl-entry">
Liu, X., Gong, C., and liu, qiang. (2023). <a href="https://openreview.net/forum?id=XVjTT1nw5z">Flow straight and fast: Learning to generate and transfer data with rectified flow</a>. In <em>The eleventh international conference on learning representations</em>.
</div>
<div id="ref-McCann1997" class="csl-entry">
McCann, R. J. (1997). <a href="https://doi.org/10.1006/aima.1997.1634">A convexity principle for interacting gases</a>. <em>Advances in Mathematics</em>, <em>128</em>(1), 153–179.
</div>
<div id="ref-Nichol+2022" class="csl-entry">
Nichol, A. Q., Dhariwal, P., Ramesh, A., Shyam, P., Mishkin, P., Mcgrew, B., … Chen, M. (2022). <a href="https://proceedings.mlr.press/v162/nichol22a.html"><span>GLIDE</span>: Towards photorealistic image generation and editing with text-guided diffusion models</a>. In K. Chaudhuri, S. Jegelka, L. Song, C. Szepesvari, G. Niu, and S. Sabato, editors, <em>Proceedings of the 39th international conference on machine learning</em>,Vol. 162, pages 16784–16804. PMLR.
</div>
<div id="ref-Pooladian+2023" class="csl-entry">
Pooladian, A.-A., Ben-Hamu, H., Domingo-Enrich, C., Amos, B., Lipman, Y., and Chen, R. T. Q. (2023). <a href="https://proceedings.mlr.press/v202/pooladian23a.html">Multisample flow matching: Straightening flows with minibatch couplings</a>. In A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett, editors, <em>Proceedings of the 40th international conference on machine learning</em>,Vol. 202, pages 28100–28127. PMLR.
</div>
<div id="ref-Saharia+2022SIGGRAPH" class="csl-entry">
Saharia, C., Chan, W., Chang, H., Lee, C. A., Ho, J., Salimans, T., … Norouzi, M. (2022). <a href="https://openreview.net/forum?id=FPGs276lUeq"><span class="nocase">Palette: Image-to-Image Diffusion Models</span></a>.
</div>
<div id="ref-Saharia+2022" class="csl-entry">
Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E., … Norouzi, M. (2022). <a href="https://openreview.net/forum?id=08Yk-n5l2Al">Photorealistic text-to-image diffusion models with deep language understanding</a>. In A. H. Oh, A. Agarwal, D. Belgrave, and K. Cho, editors, <em>Advances in neural information processing systems</em>.
</div>
<div id="ref-Saharia+2023" class="csl-entry">
Saharia, C., Ho, J., Chan, W., Salimans, T., Fleet, D. J., and Norouzi, M. (2023). <a href="https://doi.org/10.1109/TPAMI.2022.3204461">Image super-resolution via iterative refinement</a>. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, <em>45</em>(4), 4713–4726.
</div>
<div id="ref-Tong+2024" class="csl-entry">
Tong, A., FATRAS, K., Malkin, N., Huguet, G., Zhang, Y., Rector-Brooks, J., … Bengio, Y. (2024). <a href="https://openreview.net/forum?id=CD9Snc73AW"><span class="nocase">Improving and Generalizing Flow-Based Generative Models with Minibatch Optimal Transport</span></a>. <em>Transactions on Machine Learning Research</em>.
</div>
<div id="ref-Watson+2023" class="csl-entry">
Watson, J. L., Juergens, D., Bennett, N. R., Trippe, B. L., Yim, J., Eisenach, H. E., … Baker, D. (2023). <a href="https://doi.org/10.1038/s41586-023-06415-8">De novo design of protein structure and function with RFdiffusion</a>. <em>Nature</em>, <em>620</em>(7976), 1089–1100.
</div>
<div id="ref-Zheng+2023GuidedFlow" class="csl-entry">
Zheng, Q., Le, M., Shaul, N., Lipman, Y., Grover, A., and Chen, R. T. Q. (2023). <a href="https://arxiv.org/abs/2311.13443">Guided flows for generative modeling and decision making</a>.
</div>
<div id="ref-Zheng+2024" class="csl-entry">
Zheng, S., He, J., Liu, C., Shi, Y., Lu, Z., Feng, W., … Liu, T.-Y. (2024). <a href="https://doi.org/10.1038/s42256-024-00837-3">Predicting equilibrium distributions for molecular systems with deep learning</a>. <em>Nature Machine Intelligence</em>, <em>6</em>(5), 558–567.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><img src="https://latex.codecogs.com/png.latex?c"> が <img src="https://latex.codecogs.com/png.latex?x_t"> と同じ画像である場合は，<span class="citation" data-cites="Ho+2022">(Ho et al., 2022)</span> のように <img src="https://latex.codecogs.com/png.latex?x_t"> にそのまま連結することも考えられる．↩︎</p></li>
<li id="fn2"><p>すべての <img src="https://latex.codecogs.com/png.latex?(P_%7Bt,c%7D)_%7Bt%5Cin%5B0,1%5D%7D"> は <img src="https://latex.codecogs.com/png.latex?%5Csigma%5Cto0"> の極限で決定論的なダイナミクスを定めていた．これを <img src="https://latex.codecogs.com/png.latex?%5Cpsi_c(t)"> と表すこととする．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Deep</category>
  <category>Sampling</category>
  <category>P(X)</category>
  <guid>https://162348.github.io/posts/2024/Samplers/NF3.html</guid>
  <pubDate>Fri, 09 Aug 2024 15:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Samplers/Files/RFDiff.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>離散空間上のフローベース模型</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Samplers/DiscreteDiffusion.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<div id="listing-diffusion-listing" class="quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Deep,Sampling,P(X)" data-listing-date-sort="1707836400000" data-listing-file-modified-sort="1727007848139" data-listing-date-modified-sort="1724770800000" data-listing-reading-time-sort="4" data-listing-word-count-sort="794">
<a href="../../../posts/2024/Samplers/NF1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/linear/output.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ニューラル常微分方程式
</h5>
<div class="card-subtitle listing-subtitle">
シミュレーションなしの拡散モデルとしての連続正規化流
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Deep,Sampling,P(X)" data-listing-date-sort="1723215600000" data-listing-file-modified-sort="1727007848140" data-listing-date-modified-sort="1724684400000" data-listing-reading-time-sort="3" data-listing-word-count-sort="582">
<a href="../../../posts/2024/Samplers/NF3.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/RFDiff.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
フローベース模型による条件付き生成
</h5>
<div class="card-subtitle listing-subtitle">
誘導からフローマッチングへ
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-10
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Deep,Sampling,Python" data-listing-date-sort="1722524400000" data-listing-file-modified-sort="1727007848001" data-listing-date-modified-sort="1722783600000" data-listing-reading-time-sort="15" data-listing-word-count-sort="2810">
<a href="../../../posts/2024/Samplers/DDPM.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://162348.github.io/posts/2024/Samplers/DDPM_files/figure-html/fig-encoding-output-1.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
拡散模型の実装
</h5>
<div class="card-subtitle listing-subtitle">
<code>PyTorch</code>によるハンズオン
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-02
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="3" data-categories="Deep,Process,Sampling" data-listing-date-sort="1707836400000" data-listing-file-modified-sort="1727007848002" data-listing-date-modified-sort="1724338800000" data-listing-reading-time-sort="5" data-listing-word-count-sort="826">
<a href="../../../posts/2024/Samplers/Diffusion.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/DDPM_outputs.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
拡散模型
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル６
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="4" data-categories="Process,Sampling,P(X)" data-listing-date-sort="1722610800000" data-listing-file-modified-sort="1727007848140" data-listing-date-modified-sort="1724598000000" data-listing-reading-time-sort="3" data-listing-word-count-sort="470">
<a href="../../../posts/2024/Samplers/SB1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://162348.github.io/posts/2024/Samplers/Files/linear/output.gif" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
分布道の学習としての生成モデリング
</h5>
<div class="card-subtitle listing-subtitle">
Denoising Diffusion から Schrödinger Bridge へ
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-03
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="5" data-categories="Sampling,Process" data-listing-date-sort="1722610800000" data-listing-file-modified-sort="1727007848140" data-listing-date-modified-sort="1724598000000" data-listing-reading-time-sort="2" data-listing-word-count-sort="287">
<a href="../../../posts/2024/Samplers/SB2.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/unnormalized_target.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
雑音除去拡散サンプラー
</h5>
<div class="card-subtitle listing-subtitle">
拡散モデルによるベイズ計算
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-03
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
<section id="sec-D3PM" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="sec-D3PM"><span class="header-section-number">1</span> 離散雑音除去拡散模型 (D3PM) <span class="citation" data-cites="Austin+2021">(Austin et al., 2021)</span></h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://github.com/cloneofsimo/d3pm/blob/main/contents/best.gif"><img src="https://162348.github.io/posts/2024/Samplers/Files/best.gif" class="img-fluid figure-img" alt="Minimal Implementation of a D3PM by Simo Ryu (Ryu, 2024) (Tap to image to visit his repository)"></a></p>
<figcaption>Minimal Implementation of a D3PM by Simo Ryu <span class="citation" data-cites="Simo2024">(Ryu, 2024)</span> (Tap to image to visit his repository)</figcaption>
</figure>
</div>
<section id="はじめに" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="はじめに"><span class="header-section-number">1.1</span> はじめに</h3>
<p>離散データ上のフローベースのサンプリング法として，Argmax Flows と Multinomial Diffusion が <span class="citation" data-cites="Hoogeboom+2021">(Hoogeboom et al., 2021)</span> により提案された．</p>
<p>D3PM <span class="citation" data-cites="Austin+2021">(Austin et al., 2021)</span> はこの拡張として提案されたものである．</p>
<p>その結果，D3PM は BERT <span class="citation" data-cites="Lewis+2020-BART">(Lewis et al., 2020)</span> などのマスク付き言語モデルと等価になる．</p>
</section>
<section id="ノイズ過程" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="ノイズ過程"><span class="header-section-number">1.2</span> ノイズ過程</h3>
<section id="設計意図" class="level4" data-number="1.2.1">
<h4 data-number="1.2.1" class="anchored" data-anchor-id="設計意図"><span class="header-section-number">1.2.1</span> 設計意図</h4>
<p>効率的な訓練のために，</p>
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?q(x_t%7Cx_0)"> からシミュレーション可能</li>
<li><img src="https://latex.codecogs.com/png.latex?q(x_%7Bt-1%7D%7Cx_t,x_0)"> が評価可能</li>
</ol>
<p>であるとする．これにより， <img src="https://latex.codecogs.com/png.latex?%0AL_%7Bt-1%7D(x_0):=%5Cint_%5Cmathcal%7BX%7D%5Coperatorname%7BKL%7D%5Cbiggr(q(x_%7Bt-1%7D%7Cx_t,x_0),p_%5Ctheta(x_%7Bt-1%7D%7Cx_t)%5Cbiggl)%5C,q(x_t%7Cx_0)%5C,dx_t%0A"><br>
の Monte Carlo 近似が可能になる．</p>
<p><img src="https://latex.codecogs.com/png.latex?p(x_T)=q(x_T%7Cx_0)"> を一様分布など，簡単にシミュレーション可能な分布とする．</p>
</section>
<section id="実装" class="level4" data-number="1.2.2">
<h4 data-number="1.2.2" class="anchored" data-anchor-id="実装"><span class="header-section-number">1.2.2</span> 実装</h4>
<p><img src="https://latex.codecogs.com/png.latex?x_0%5Cin%5Cmathcal%7BX%7D"> は，<img src="https://latex.codecogs.com/png.latex?%5BK%5D">-値の離散ベクトル <img src="https://latex.codecogs.com/png.latex?x_0%5E%7B(i)%7D"> が <img src="https://latex.codecogs.com/png.latex?D"> 個集まったものとする．ただし，<img src="https://latex.codecogs.com/png.latex?x_0%5E%7B(i)%7D"> は one-hot encoding による横ベクトルとする．</p>
<p>すると，ある確率行列 <img src="https://latex.codecogs.com/png.latex?Q_t"> に関して， <img src="https://latex.codecogs.com/png.latex?%0AQ(-%7Cx_%7Bt-1%7D)=x_%7Bt-1%7DQ_t=%5Ccdots=x_0Q_1%5Ccdots%20Q_t%0A"> と表せる．右辺の第 <img src="https://latex.codecogs.com/png.latex?i"> 行は，次 <img src="https://latex.codecogs.com/png.latex?k%5Cin%5BK%5D"> の状態に至る確率を表す確率ベクトルとなっている．</p>
<p>するとこの逆は，ベイズの定理より <img src="https://latex.codecogs.com/png.latex?%0Aq(x_%7Bt-1%7D%7Cx_t,x_0)=%5Cfrac%7Bq(x_t%7Cx_%7Bt-1%7D,x_0)q(x_%7Bt-1%7D%7Cx_0)%7D%7Bq(x_t%7Cx_0)%7D%0A"> <img src="https://latex.codecogs.com/png.latex?%0AQ(-%7Cx_t,x_0)=%0A"></p>
</section>
<section id="核-q-の取り方" class="level4" data-number="1.2.3">
<h4 data-number="1.2.3" class="anchored" data-anchor-id="核-q-の取り方"><span class="header-section-number">1.2.3</span> 核 <img src="https://latex.codecogs.com/png.latex?Q"> の取り方</h4>
<p><img src="https://latex.codecogs.com/png.latex?%0AQ_t:=(1-%5Cbeta_t)I_K+%5Cfrac%7B%5Cbeta_t%7D%7BK%7D%0A"> と取った場合を一様核という．</p>
<p>または，<img src="https://latex.codecogs.com/png.latex?Q_t"> として <strong>脱落核</strong> を取ることもできる．これは１つの点 <img src="https://latex.codecogs.com/png.latex?m%5Cin%5BK%5D"> を吸収点とする方法である： <img src="https://latex.codecogs.com/png.latex?%0A(Q_t)_%7Bij%7D:=%5Cbegin%7Bcases%7D1&amp;i=j=m,%5C%5C%0A1-%5Cbeta_t&amp;i=j%5Cin%5BK%5D%5Csetminus%5C%7Bm%5C%7D%5C%5C%0A%5Cbeta_t&amp;%5Cmathrm%7Botherwise%7D%0A%5Cend%7Bcases%7D%0A"></p>
</section>
</section>
<section id="除去過程" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="除去過程"><span class="header-section-number">1.3</span> 除去過程</h3>
<p><img src="https://latex.codecogs.com/png.latex?p_%5Ctheta(x_%7Bt-1%7D%7Cx_t)"> をモデリングするのではなく，<img src="https://latex.codecogs.com/png.latex?%5Cwidetilde%7Bp%7D_%5Ctheta(x_0%7Cx_t)"> をモデリングし， <img src="https://latex.codecogs.com/png.latex?%0Ap_%5Ctheta(x_%7Bt-1%7D%7Cx_t)%5C,%5Cpropto%5C,%5Csum_%7B%5Cwidetilde%7Bx%7D_0%5Cin%5BK%5D%7Dq(x_%7Bt-1%7D%7Cx_t,%5Cwidetilde%7Bx%7D_0)%5Cwidetilde%7Bp%7D_%5Ctheta(%5Cwidetilde%7Bx%7D_0%7Cx_t)%0A"> は間接的にモデリングする．</p>
<p>これにより，ステップ数を小さく取った場合でも，<img src="https://latex.codecogs.com/png.latex?k"> ステップをまとめて <img src="https://latex.codecogs.com/png.latex?p_%5Ctheta(x_%7Bt-k%7D%7Cx_t)"> をいきなりサンプリングするということも十分に可能になるためである．</p>
</section>
<section id="bert-devlin2019-との対応" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="bert-devlin2019-との対応"><span class="header-section-number">1.4</span> BERT <span class="citation" data-cites="Devlin+2019">(Devlin et al., 2019)</span> との対応</h3>
<p><img src="https://latex.codecogs.com/png.latex?Q_t"> として，一様核と脱落核を重ね合わせたとする．</p>
<p>すなわち，各トークンを各ステップで <img src="https://latex.codecogs.com/png.latex?%5Calpha=10%5C%25"> でマスクし，<img src="https://latex.codecogs.com/png.latex?%5Cbeta=5%5C%25"> で一様にリサンプリングし，これを元に戻す逆過程を学習する．</p>
<p>これは BERT <span class="citation" data-cites="Devlin+2019">(Devlin et al., 2019)</span> と全く同じ目的関数を定める．</p>
<p>MaskGIT (Masked Generative Image Transformer) <span class="citation" data-cites="Chang+2022">(Chang et al., 2022)</span> も，画像をベクトル量子化した後に，全く同様の要領でマスク・リサンプリングをし，これを回復しようとする．これはトランスフォーマーなどの自己回帰的モデルを用いて逐次的に生成するより，サンプリングがはるかに速くなるという．</p>
</section>
</section>


<div id="quarto-appendix" class="default"><section id="参考文献" class="level2 appendix" data-number="2"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">2</span> 参考文献</h2><div class="quarto-appendix-contents">

<p><span class="citation" data-cites="Simo2024">(Ryu, 2024)</span> に素晴らしい教育的リポジトリがある．D3PM の 425 行での PyTorch での実装を提供している．</p>
<p><span class="citation" data-cites="Campbell+2024">(Campbell et al., 2024)</span> は最新の論文の一つである．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Austin+2021" class="csl-entry">
Austin, J., Johnson, D. D., Ho, J., Tarlow, D., and Berg, R. van den. (2021). <a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/958c530554f78bcd8e97125b70e6973d-Paper.pdf">Structured denoising diffusion models in discrete state-spaces</a>. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P. S. Liang, and J. W. Vaughan, editors, <em>Advances in neural information processing systems</em>,Vol. 34, pages 17981–17993. Curran Associates, Inc.
</div>
<div id="ref-Campbell+2024" class="csl-entry">
Campbell, A., Yim, J., Barzilay, R., Rainforth, T., and Jaakkola, T. (2024). <a href="https://arxiv.org/abs/2402.04997">Generative flows on discrete state-spaces: Enabling multimodal flows with applications to protein co-design</a>.
</div>
<div id="ref-Chang+2022" class="csl-entry">
Chang, H., Zhang, H., Jiang, L., Liu, C., and Freeman, W. T. (2022). MaskGIT: Masked generative image transformer. In <em>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR)</em>, pages 11315–11325.
</div>
<div id="ref-Devlin+2019" class="csl-entry">
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2019). <a href="https://aclanthology.org/N19-1423/">BERT: Pre-training of deep bidirectional transformers for language understanding</a>. In <em>Proceedings of the 2019 conference of the north american chapter of the association for computational linguistics: Human language technologies</em>,Vol. 1, pages 4171–4186.
</div>
<div id="ref-Hoogeboom+2021" class="csl-entry">
Hoogeboom, E., Nielsen, D., Jaini, P., Forré, P., and Welling, M. (2021). <a href="https://openreview.net/forum?id=6nbpPqUCIi7">Argmax flows and multinomial diffusion: Learning categorical distributions</a>. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan, editors, <em>Advances in neural information processing systems</em>.
</div>
<div id="ref-Lewis+2020-BART" class="csl-entry">
Lewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., … Zettlemoyer, L. (2020). <a href="https://doi.org/10.18653/v1/2020.acl-main.703"><span>BART</span>: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</a>. In D. Jurafsky, J. Chai, N. Schluter, and J. Tetreault, editors, <em>Proceedings of the 58th annual meeting of the association for computational linguistics</em>, pages 7871–7880. Online: Association for Computational Linguistics.
</div>
<div id="ref-Simo2024" class="csl-entry">
Ryu, S. (2024). <a href="https://github.com/cloneofsimo/d3pm">Minimal implementation of a D3PM (structured denoising diffusion models in discrete state-spaces), in pytorch</a>.
</div>
</div></section></div> ]]></description>
  <category>Deep</category>
  <category>Sampling</category>
  <category>Nature</category>
  <guid>https://162348.github.io/posts/2024/Samplers/DiscreteDiffusion.html</guid>
  <pubDate>Thu, 08 Aug 2024 15:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Samplers/Files/best.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Neural Network 訓練の加速</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Samplers/DDPM1.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/docs/posts/2024/Samplers/DDPM_files/figure-html/fig-encoding-output-1.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption><a href="../../../posts/2024/Samplers/DDPM.html">前稿：拡散模型の実装――PyTorch によるハンズオン</a></figcaption>
</figure>
</div>
<section id="問題点と改善したいこと" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="問題点と改善したいこと"><span class="header-section-number">1</span> 問題点と改善したいこと</h2>
<p>データセットの読み込みの段階において，次のコードがある：</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">kwargs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'num_workers'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pin_memory'</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'prefetch_factor'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>}</span>
<span id="cb1-2">train_loader <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataLoader(dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_dataset, batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_batch_size, shuffle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs)</span>
<span id="cb1-3">test_loader  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataLoader(dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>test_dataset,  batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>inference_batch_size, shuffle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs)</span></code></pre></div>
<p>これはデータセット（今回は<code>MNIST</code>）を読み込み，iterable 型としての仕様を可能にするためのコードである．</p>
<p>上述の通りのコードだとエポック 18 で <code>RuntimeError: Shared memory manager connection has timed out</code> を得たが，<code>num_workers=0</code> とするとエラーが発生しなかった．</p>
<p>しかし，<code>num_workers=0</code> （デフォルト設定）とすると，デフォルトの単一プロセス処理が実行されるため，並列による高速化の恩恵を受けられない．その結果，１エポック 12 分以上なので，40 時間以上をかける必要が出てきた（寝てる間もディスプレイをオフにするだけでスリープさせず，回し続ける）．</p>
<div class="callout callout-style-simple callout-important no-icon callout-titled" title="今回の目標">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
今回の目標
</div>
</div>
<div class="callout-body-container callout-body">
<p>うまく並列処理をするようなコードに書き直すことで，ローカル環境でも１日以内で実行できるようにしたい．</p>
</div>
</div>
</section>
<section id="dataloader-の引数について" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="dataloader-の引数について"><span class="header-section-number">2</span> <code>DataLoader</code> の引数について</h2>
<p><a href="https://pytorch.org/docs/stable/data.html"><code>DataLoader</code> メソッドのドキュメント</a> を参照すると，</p>
<section id="num_workers" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="num_workers"><span class="header-section-number">2.1</span> <code>num_workers</code></h3>
<p>は正整数に設定されると，その数だけ並列に動く ‘worker’ が起動され，マルチプロセス処理が実行される．</p>
<p>しかし，子プロセスも同等のメモリを占めるため，値が大きすぎるとランタイムエラーが発生する（<a href="https://github.com/pytorch/pytorch/issues/13246#issuecomment-905703662">issue #13246</a> 参照）．</p>
<p>さらに，この際の並列処理は Python の <code>multiprocessing</code> パッケージによるもので，Windows と MacOS では（Unix 系のような <code>fork()</code> ではなく） <code>spawn()</code> が呼ばれる．これは別のインタープリターを開始するため，コードの大部分を <code>if __name__ == "__main__":</code> で囲まない限り，同じコードを何回も実行することとなり，ランタイムエラーが出現することとなる．</p>
</section>
<section id="pin_memeory" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="pin_memeory"><span class="header-section-number">2.2</span> <code>pin_memeory</code></h3>
<p>しかし，CUDA 上のテンソルオブジェクトを並列処理で共有することは非推奨であり，その際は自動メモリ固定 (automatic memory pinning) を行う必要がある．</p>
<p>pinned memory とは page-locked メモリとも呼ばれ，通常の pageable メモリより転送速度が速いという．</p>
<p>さて，paging とはなんだろうか？（一旦後回し）</p>
</section>
<section id="prefetch_factor" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="prefetch_factor"><span class="header-section-number">2.3</span> <code>prefetch_factor</code></h3>
<p>は各 <code>worker</code> が取ってきてストックしておくバッチの数である．</p>
<p>すなわち，<code>num_workers * prefetch_factor</code> だけデータをメモリに読み込んでおくことになる．</p>
</section>
</section>
<section id="高速化法" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="高速化法"><span class="header-section-number">3</span> 高速化法</h2>
<section id="google-colab-の利用" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="google-colab-の利用"><span class="header-section-number">3.1</span> Google Colab の利用</h3>
<p>結局この方法でトレーニングをし，<a href="../../../posts/2024/Samplers/DDPM.html">前稿</a> を完成させたのであった．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/A100.png" class="img-fluid figure-img"></p>
<figcaption>A100（8/6/2024 時点）</figcaption>
</figure>
</div>
<p>A100 が税込 1,494,000 円であったが，これを利用すると１エポック 22 秒で実行できた．</p>
</section>
<section id="torch.nn.dataparallel-の使用" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="torch.nn.dataparallel-の使用"><span class="header-section-number">3.2</span> <code>torch.nn.DataParallel</code> の使用</h3>
<p>自分のローカルマシンは CUDA がないため利用できないが，ある場合は <code>PyTorch</code> のモジュールで並列処理が可能である．<sup>1</sup></p>
</section>
</section>
<section id="mps-で本当に高速になっているのか" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="mps-で本当に高速になっているのか"><span class="header-section-number">4</span> <code>mps</code> で本当に高速になっているのか？</h2>
<p>アップルは <a href="https://developer.apple.com/jp/metal/">Metal</a> という計算 API を提供しており，これが Apple Silicon で利用できる．</p>
<div id="42adf36d" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb2-2">DEVICE <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.device(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mps"</span>)</span>
<span id="cb2-3">train_batch_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span></span>
<span id="cb2-4">epochs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div>
</div>
<p>とし，１エポックにかかる時間を比較する．その他の設定は前節と同様．</p>
<div id="46f74797" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Start training DDPMs..."</span>)</span>
<span id="cb3-2">model.train()</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> time</span>
<span id="cb3-5"></span>
<span id="cb3-6">start_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time()</span>
<span id="cb3-7"></span>
<span id="cb3-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> epoch <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(epochs):</span>
<span id="cb3-9">    noise_prediction_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb3-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> batch_idx, (x, _) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> tqdm(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(train_loader), total<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train_loader)):</span>
<span id="cb3-11">        optimizer.zero_grad()</span>
<span id="cb3-12"></span>
<span id="cb3-13">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.to(DEVICE)</span>
<span id="cb3-14">        </span>
<span id="cb3-15">        noisy_input, epsilon, pred_epsilon <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> diffusion(x)</span>
<span id="cb3-16">        loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> denoising_loss(pred_epsilon, epsilon)</span>
<span id="cb3-17">        </span>
<span id="cb3-18">        noise_prediction_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> loss.item()</span>
<span id="cb3-19">        </span>
<span id="cb3-20">        loss.backward()</span>
<span id="cb3-21">        optimizer.step()</span>
<span id="cb3-22">        </span>
<span id="cb3-23">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\t</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Epoch"</span>, epoch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"complete!"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\t</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Denoising Loss: "</span>, noise_prediction_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> batch_idx)</span>
<span id="cb3-24">    </span>
<span id="cb3-25">total_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> start_time</span>
<span id="cb3-26"></span>
<span id="cb3-27"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Finish!! Total time: "</span>, total_time)</span></code></pre></div>
</div>
<p>12:58 であった．一方で，CPU でも訓練してみる．</p>
<div id="a0cce554" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">DEVICE <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.device(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cpu"</span>)</span>
<span id="cb4-2">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Denoiser(image_resolution<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>img_size,</span>
<span id="cb4-3">                    hidden_dims<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>hidden_dims, </span>
<span id="cb4-4">                    diffusion_time_embedding_dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>timestep_embedding_dim, </span>
<span id="cb4-5">                    n_times<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_timesteps).to(DEVICE)</span>
<span id="cb4-6">diffusion <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Diffusion(model, image_resolution<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>img_size, n_times<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_timesteps, beta_minmax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>beta_minmax, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>DEVICE).to(DEVICE)</span>
<span id="cb4-7"></span>
<span id="cb4-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Start training DDPMs..."</span>)</span>
<span id="cb4-9">model.train()</span>
<span id="cb4-10"></span>
<span id="cb4-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> time</span>
<span id="cb4-12"></span>
<span id="cb4-13">start_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time()</span>
<span id="cb4-14"></span>
<span id="cb4-15"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> epoch <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(epochs):</span>
<span id="cb4-16">    noise_prediction_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb4-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> batch_idx, (x, _) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> tqdm(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(train_loader), total<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train_loader)):</span>
<span id="cb4-18">        optimizer.zero_grad()</span>
<span id="cb4-19"></span>
<span id="cb4-20">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.to(DEVICE)</span>
<span id="cb4-21">        </span>
<span id="cb4-22">        noisy_input, epsilon, pred_epsilon <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> diffusion(x)</span>
<span id="cb4-23">        loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> denoising_loss(pred_epsilon, epsilon)</span>
<span id="cb4-24">        </span>
<span id="cb4-25">        noise_prediction_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> loss.item()</span>
<span id="cb4-26">        </span>
<span id="cb4-27">        loss.backward()</span>
<span id="cb4-28">        optimizer.step()</span>
<span id="cb4-29">        </span>
<span id="cb4-30">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\t</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Epoch"</span>, epoch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"complete!"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\t</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Denoising Loss: "</span>, noise_prediction_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> batch_idx)</span>
<span id="cb4-31">    </span>
<span id="cb4-32">total_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> start_time</span>
<span id="cb4-33"></span>
<span id="cb4-34"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Finish!! Total time: "</span>, total_time)</span></code></pre></div>
</div>
<p>１時間越え！</p>
</section>



<div id="quarto-appendix" class="default"><section id="終わりに" class="level2 appendix" data-number="5"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">5</span> 終わりに</h2><div class="quarto-appendix-contents">

<p>あまりに時間がかかるので，本記事は <code>eval: false</code> としておく．</p>


</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><a href="https://qiita.com/m__k/items/87b3b1da15f35321ecf5">PyTorchでGPUを並列で使えるようにするtorch.nn.DataParallelのメモ</a> などを参照した．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Deep</category>
  <category>Python</category>
  <guid>https://162348.github.io/posts/2024/Samplers/DDPM1.html</guid>
  <pubDate>Mon, 05 Aug 2024 15:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Samplers/Files/fig-generation3-output-1.png" medium="image" type="image/png" height="142" width="144"/>
</item>
<item>
  <title>エネルギーベースモデルのノイズ対照学習</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Samplers/EBM2.html</link>
  <description><![CDATA[ 





<section id="関連ページ" class="level3 unnumbered unlisted">
<h3 class="unnumbered unlisted anchored" data-anchor-id="関連ページ">関連ページ</h3>
<div id="listing-lst-listing" class="listing quarto-float quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Deep,Nature,Sampling" data-listing-date-sort="1711724400000" data-listing-file-modified-sort="1727007848003" data-listing-date-modified-sort="1722438000000" data-listing-reading-time-sort="5" data-listing-word-count-sort="880">
<a href="../../../posts/2024/Samplers/EBM.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/NCL/thumb_checkerboard.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
エネルギーベースモデル
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル５
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-03-30
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Deep,Python" data-listing-date-sort="1722524400000" data-listing-file-modified-sort="1727007848003" data-listing-date-modified-sort="1724252400000" data-listing-reading-time-sort="4" data-listing-word-count-sort="784">
<a href="../../../posts/2024/Samplers/EBM1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/swiss_roll.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
スコアマッチング
</h5>
<div class="card-subtitle listing-subtitle">
JAX によるハンズオン
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-02
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Kernel" data-listing-date-sort="1723215600000" data-listing-file-modified-sort="1727007847870" data-listing-date-modified-sort="1723302000000" data-listing-reading-time-sort="3" data-listing-word-count-sort="582">
<a href="../../../posts/2024/Kernels/Kernel.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Kernels/Images/Gibbs.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
カーネル法の概観
</h5>
<div class="card-subtitle listing-subtitle">
半正定値カーネルから距離学習まで
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-10
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>
<section id="モデル定義" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="モデル定義"><span class="header-section-number">1</span> モデル定義</h2>
<div id="76e8355d" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.nn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> nn</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ------------------------------</span></span>
<span id="cb1-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ENERGY-BASED MODEL</span></span>
<span id="cb1-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ------------------------------</span></span>
<span id="cb1-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> EBM(nn.Module):</span>
<span id="cb1-8">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>):</span>
<span id="cb1-9">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(EBM, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb1-10">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The normalizing constant logZ(θ)        </span></span>
<span id="cb1-11">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Parameter(torch.tensor([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span>], requires_grad<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>))</span>
<span id="cb1-12"></span>
<span id="cb1-13">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.f <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Sequential(</span>
<span id="cb1-14">            nn.Linear(dim, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>),</span>
<span id="cb1-15">            nn.LeakyReLU(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>),</span>
<span id="cb1-16">            nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>),</span>
<span id="cb1-17">            nn.LeakyReLU(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>),</span>
<span id="cb1-18">            nn.Linear(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),</span>
<span id="cb1-19">            )</span>
<span id="cb1-20"></span>
<span id="cb1-21">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x):</span>
<span id="cb1-22">        log_p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.f(x) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.c</span>
<span id="cb1-23">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> log_p</span></code></pre></div>
</div>
</section>
<section id="事前準備" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="事前準備"><span class="header-section-number">2</span> 事前準備</h2>
<div id="6808abe1" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> math</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb2-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.nn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> nn</span>
<span id="cb2-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.utils.data <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DataLoader</span>
<span id="cb2-6"></span>
<span id="cb2-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib</span>
<span id="cb2-8">matplotlib.use(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Agg'</span>)</span>
<span id="cb2-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb2-10"></span>
<span id="cb2-11"></span>
<span id="cb2-12"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> value(energy, noise, x, gen):</span>
<span id="cb2-13">    logp_x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> energy(x)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># logp(x)</span></span>
<span id="cb2-14">    logq_x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> noise.log_prob(x).unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># logq(x)</span></span>
<span id="cb2-15">    logp_gen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> energy(gen)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># logp(x̃)</span></span>
<span id="cb2-16">    logq_gen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> noise.log_prob(gen).unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># logq(x̃)</span></span>
<span id="cb2-17"></span>
<span id="cb2-18">    value_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> logp_x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> torch.logsumexp(torch.cat([logp_x, logq_x], dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, keepdim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># log[p(x)/(p(x) + q(x))]</span></span>
<span id="cb2-19">    value_gen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> logq_gen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> torch.logsumexp(torch.cat([logp_gen, logq_gen], dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, keepdim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># log[q(x̃)/(p(x̃) + q(x̃))]</span></span>
<span id="cb2-20"></span>
<span id="cb2-21">    v <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> value_data.mean() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> value_gen.mean()</span>
<span id="cb2-22"></span>
<span id="cb2-23">    r_x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.sigmoid(logp_x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> logq_x)</span>
<span id="cb2-24">    r_gen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.sigmoid(logq_gen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> logp_gen)</span>
<span id="cb2-25"></span>
<span id="cb2-26">    acc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ((r_x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (r_gen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()).cpu().numpy() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(x) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(gen))</span>
<span id="cb2-27"></span>
<span id="cb2-28">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>v,  acc</span>
<span id="cb2-29"></span>
<span id="cb2-30"></span>
<span id="cb2-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#-------------------------------------------</span></span>
<span id="cb2-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># DATA</span></span>
<span id="cb2-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#-------------------------------------------</span></span>
<span id="cb2-34"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> get_data(args):</span>
<span id="cb2-35">    dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sample_2d_data(dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>args.dataset, n_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>args.samples)</span>
<span id="cb2-36">    dataloader  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataLoader(dataset, batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>args.batch, shuffle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb2-37">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> dataset, dataloader</span>
<span id="cb2-38"></span>
<span id="cb2-39"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> sample_2d_data(dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'8gaussians'</span>, n_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50000</span>):</span>
<span id="cb2-40">    </span>
<span id="cb2-41">    z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn(n_samples, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb2-42"></span>
<span id="cb2-43">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'8gaussians'</span>:</span>
<span id="cb2-44">        scale <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb2-45">        sq2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>math.sqrt(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb2-46">        centers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>), (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>), (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), (sq2,sq2), (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>sq2,sq2), (sq2,<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>sq2), (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>sq2,<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>sq2)]</span>
<span id="cb2-47">        centers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor([(scale <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x, scale <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> y) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> x,y <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> centers])</span>
<span id="cb2-48">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> sq2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> centers[torch.randint(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(centers), size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(n_samples,))])</span>
<span id="cb2-49"></span>
<span id="cb2-50">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">elif</span> dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2spirals'</span>:</span>
<span id="cb2-51">        n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.sqrt(torch.rand(n_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">540</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> math.pi) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">360</span></span>
<span id="cb2-52">        d1x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> torch.cos(n) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> torch.rand(n_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span></span>
<span id="cb2-53">        d1y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>   torch.sin(n) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> torch.rand(n_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span></span>
<span id="cb2-54">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([torch.stack([ d1x,  d1y], dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),</span>
<span id="cb2-55">                       torch.stack([<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>d1x, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>d1y], dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)], dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span></span>
<span id="cb2-56">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>z</span>
<span id="cb2-57"></span>
<span id="cb2-58">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">elif</span> dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'checkerboard'</span>:</span>
<span id="cb2-59">        x1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.rand(n_samples) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb2-60">        x2_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.rand(n_samples) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> torch.randint(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, (n_samples,), dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb2-61">        x2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x2_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> x1.floor() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb2-62">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> torch.stack([x1, x2], dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb2-63"></span>
<span id="cb2-64">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">elif</span> dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'rings'</span>:</span>
<span id="cb2-65">        n_samples4 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n_samples3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n_samples2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb2-66">        n_samples1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> n_samples4 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> n_samples3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> n_samples2</span>
<span id="cb2-67"></span>
<span id="cb2-68">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># so as not to have the first point = last point, set endpoint=False in np; here shifted by one</span></span>
<span id="cb2-69">        linspace4 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> math.pi, n_samples4 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)[:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb2-70">        linspace3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> math.pi, n_samples3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)[:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb2-71">        linspace2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> math.pi, n_samples2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)[:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb2-72">        linspace1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> math.pi, n_samples1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)[:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb2-73"></span>
<span id="cb2-74">        circ4_x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cos(linspace4)</span>
<span id="cb2-75">        circ4_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.sin(linspace4)</span>
<span id="cb2-76">        circ3_x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cos(linspace4) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.75</span></span>
<span id="cb2-77">        circ3_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.sin(linspace3) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.75</span></span>
<span id="cb2-78">        circ2_x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cos(linspace2) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span></span>
<span id="cb2-79">        circ2_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.sin(linspace2) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span></span>
<span id="cb2-80">        circ1_x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cos(linspace1) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span></span>
<span id="cb2-81">        circ1_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.sin(linspace1) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span></span>
<span id="cb2-82"></span>
<span id="cb2-83">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.stack([torch.cat([circ4_x, circ3_x, circ2_x, circ1_x]),</span>
<span id="cb2-84">                         torch.cat([circ4_y, circ3_y, circ2_y, circ1_y])], dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3.0</span></span>
<span id="cb2-85"></span>
<span id="cb2-86">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># random sample</span></span>
<span id="cb2-87">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x[torch.randint(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, n_samples, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(n_samples,))]</span>
<span id="cb2-88"></span>
<span id="cb2-89">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add noise</span></span>
<span id="cb2-90">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> torch.normal(mean<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.zeros_like(x), std<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.08</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>torch.ones_like(x))</span>
<span id="cb2-91"></span>
<span id="cb2-92">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">elif</span> dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pinwheel"</span>:</span>
<span id="cb2-93">        rng <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.RandomState()</span>
<span id="cb2-94">        radial_std <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span></span>
<span id="cb2-95">        tangential_std <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span></span>
<span id="cb2-96">        num_classes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span></span>
<span id="cb2-97">        num_per_class <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span></span>
<span id="cb2-98">        rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span></span>
<span id="cb2-99">        rads <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.pi, num_classes, endpoint<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb2-100"></span>
<span id="cb2-101">        features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rng.randn(num_classes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>num_per_class, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb2-102">            <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.array([radial_std, tangential_std])</span>
<span id="cb2-103">        features[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span></span>
<span id="cb2-104">        labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.repeat(np.arange(num_classes), num_per_class)</span>
<span id="cb2-105"></span>
<span id="cb2-106">        angles <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rads[labels] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.exp(features[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb2-107">        rotations <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.stack([np.cos(angles), <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>np.sin(angles), np.sin(angles), np.cos(angles)])</span>
<span id="cb2-108">        rotations <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.reshape(rotations.T, (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))</span>
<span id="cb2-109">        </span>
<span id="cb2-110">        data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> rng.permutation(np.einsum(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ti,tij-&gt;tj"</span>, features, rotations))</span>
<span id="cb2-111">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> torch.as_tensor(data, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float32)</span>
<span id="cb2-112"></span>
<span id="cb2-113">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb2-114">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">RuntimeError</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Invalid `dataset` to sample from.'</span>)</span></code></pre></div>
</details>
</div>
<div id="1a2c9ac8" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># --------------------</span></span>
<span id="cb3-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plotting</span></span>
<span id="cb3-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># --------------------</span></span>
<span id="cb3-4"></span>
<span id="cb3-5"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@torch.no_grad</span>()</span>
<span id="cb3-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> plot(dataset, energy, noise, epoch, device):</span>
<span id="cb3-7">    n_pts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span></span>
<span id="cb3-8">    range_lim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb3-9"></span>
<span id="cb3-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># construct test points</span></span>
<span id="cb3-11">    test_grid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> setup_grid(range_lim, n_pts, device)</span>
<span id="cb3-12"></span>
<span id="cb3-13">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plot</span></span>
<span id="cb3-14">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># fig, axs = plt.subplots(1, 3, figsize=(12,4.3), subplot_kw={'aspect': 'equal'})</span></span>
<span id="cb3-15">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plot_samples(dataset, axs[0], range_lim, n_pts)</span></span>
<span id="cb3-16">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plot_noise(noise, axs[1], test_grid, n_pts)</span></span>
<span id="cb3-17">    fig, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>), subplot_kw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'aspect'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>})</span>
<span id="cb3-18">    plot_energy(energy, ax, test_grid, n_pts)</span>
<span id="cb3-19"></span>
<span id="cb3-20">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># format</span></span>
<span id="cb3-21">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> ax <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> plt.gcf().axes: format_ax(ax, range_lim)</span>
<span id="cb3-22">    plt.tight_layout()</span>
<span id="cb3-23"></span>
<span id="cb3-24">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># save</span></span>
<span id="cb3-25">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Saving image to images/....'</span>)</span>
<span id="cb3-26">    plt.savefig(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'images/epoch_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">.png'</span>.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(epoch))</span>
<span id="cb3-27">    plt.close()</span>
<span id="cb3-28"></span>
<span id="cb3-29"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> setup_grid(range_lim, n_pts, device):</span>
<span id="cb3-30">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>range_lim, range_lim, n_pts)</span>
<span id="cb3-31">    xx, yy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.meshgrid((x, x), indexing<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ij'</span>)</span>
<span id="cb3-32">    zz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.stack((xx.flatten(), yy.flatten()), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-33">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> xx, yy, zz.to(device)</span>
<span id="cb3-34"></span>
<span id="cb3-35"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> plot_samples(dataset, ax, range_lim, n_pts):</span>
<span id="cb3-36">    samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dataset.numpy()</span>
<span id="cb3-37">    ax.hist2d(samples[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], samples[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>range_lim, range_lim], [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>range_lim, range_lim]], bins<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_pts, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plt.cm.jet)</span>
<span id="cb3-38">    ax.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Target samples'</span>)</span>
<span id="cb3-39"></span>
<span id="cb3-40"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> plot_energy(energy, ax, test_grid, n_pts):</span>
<span id="cb3-41">    xx, yy, zz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> test_grid</span>
<span id="cb3-42">    log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> energy(zz)</span>
<span id="cb3-43">    prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> log_prob.exp().cpu()</span>
<span id="cb3-44">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plot</span></span>
<span id="cb3-45">    ax.pcolormesh(xx.numpy(), yy.numpy(), prob.view(n_pts,n_pts).numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plt.cm.jet)</span>
<span id="cb3-46">    ax.set_facecolor(plt.cm.jet(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span>))</span>
<span id="cb3-47">    ax.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Energy density'</span>)</span>
<span id="cb3-48"></span>
<span id="cb3-49"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> plot_noise(noise, ax, test_grid, n_pts):</span>
<span id="cb3-50">    xx, yy, zz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> test_grid</span>
<span id="cb3-51">    log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> noise.log_prob(zz)</span>
<span id="cb3-52">    prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> log_prob.exp().cpu()</span>
<span id="cb3-53">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plot</span></span>
<span id="cb3-54">    ax.pcolormesh(xx.numpy(), yy.numpy(), prob.view(n_pts,n_pts).numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plt.cm.jet)</span>
<span id="cb3-55">    ax.set_facecolor(plt.cm.jet(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span>))</span>
<span id="cb3-56">    ax.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Noise density'</span>)</span>
<span id="cb3-57"></span>
<span id="cb3-58"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> format_ax(ax, range_lim):</span>
<span id="cb3-59">    ax.set_xlim(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>range_lim, range_lim)</span>
<span id="cb3-60">    ax.set_ylim(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>range_lim, range_lim)</span>
<span id="cb3-61">    ax.get_xaxis().set_visible(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb3-62">    ax.get_yaxis().set_visible(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb3-63">    ax.invert_yaxis()</span></code></pre></div>
</details>
</div>
</section>
<section id="訓練" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="訓練"><span class="header-section-number">3</span> 訓練</h2>
<div id="a0d10dd7" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> argparse</span>
<span id="cb4-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb4-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb4-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.distributions <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> D</span>
<span id="cb4-5"></span>
<span id="cb4-6">d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span></span>
<span id="cb4-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># if torch.cuda.is_available():</span></span>
<span id="cb4-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#     d = 'cuda'</span></span>
<span id="cb4-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># elif torch.backends.mps.is_available():</span></span>
<span id="cb4-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#     d = 'mps'</span></span>
<span id="cb4-11">device <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.device(d)</span>
<span id="cb4-12"></span>
<span id="cb4-13"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> Args:</span>
<span id="cb4-14">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb4-15">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.epoch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span></span>
<span id="cb4-16">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.batch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb4-17">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'8gaussians'</span></span>
<span id="cb4-18">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span></span>
<span id="cb4-19">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-3</span></span>
<span id="cb4-20">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.b1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span></span>
<span id="cb4-21">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.b2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.999</span></span>
<span id="cb4-22">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.resume <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb4-23"></span>
<span id="cb4-24">args <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Args()</span>
<span id="cb4-25"></span>
<span id="cb4-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ------------------------------</span></span>
<span id="cb4-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># I. MODELS</span></span>
<span id="cb4-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ------------------------------</span></span>
<span id="cb4-29">energy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> EBM(dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).to(device)</span>
<span id="cb4-30">noise <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> D.MultivariateNormal(torch.zeros(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).to(device), <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>torch.eye(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).to(device))</span>
<span id="cb4-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ------------------------------</span></span>
<span id="cb4-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># II. OPTIMIZERS</span></span>
<span id="cb4-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ------------------------------</span></span>
<span id="cb4-34">optim_energy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.optim.Adam(energy.parameters(), lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>args.lr, betas<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(args.b1, args.b2))</span>
<span id="cb4-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ------------------------------</span></span>
<span id="cb4-36"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># III. DATA LOADER</span></span>
<span id="cb4-37"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ------------------------------</span></span>
<span id="cb4-38">dataset, dataloader <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_data(args)</span>
<span id="cb4-39"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ------------------------------</span></span>
<span id="cb4-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># IV. TRAINING</span></span>
<span id="cb4-41"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ------------------------------</span></span>
<span id="cb4-42"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> main(args):</span>
<span id="cb4-43">    start_epoch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb4-44"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ----------------------------------------------------------------- #</span></span>
<span id="cb4-45">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> args.resume:</span>
<span id="cb4-46">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Resuming from checkpoint at ckpts/nce.pth.tar...'</span>)</span>
<span id="cb4-47">        checkpoint <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ckpts/nce.pth.tar'</span>)</span>
<span id="cb4-48">        energy.load_state_dict(checkpoint[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'energy'</span>])</span>
<span id="cb4-49">        start_epoch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> checkpoint[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'epoch'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb4-50"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ----------------------------------------------------------------- #</span></span>
<span id="cb4-51">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> epoch <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(start_epoch, start_epoch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> args.epoch):</span>
<span id="cb4-52">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i, x <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(dataloader):           </span>
<span id="cb4-53">            x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.to(device)</span>
<span id="cb4-54">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -----------------------------</span></span>
<span id="cb4-55">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  Generate samples from noise</span></span>
<span id="cb4-56">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -----------------------------</span></span>
<span id="cb4-57">            gen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> noise.sample((args.batch,))</span>
<span id="cb4-58">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -----------------------------</span></span>
<span id="cb4-59">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  Train Energy-Based Model</span></span>
<span id="cb4-60">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># -----------------------------</span></span>
<span id="cb4-61">            optim_energy.zero_grad()</span>
<span id="cb4-62"></span>
<span id="cb4-63">            loss_energy, acc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> value(energy, noise, x, gen)</span>
<span id="cb4-64"></span>
<span id="cb4-65">            loss_energy.backward()</span>
<span id="cb4-66">            optim_energy.step()  </span>
<span id="cb4-67"></span>
<span id="cb4-68">            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(</span>
<span id="cb4-69">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"[Epoch </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%d</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%d</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">] [Batch </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%d</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%d</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">] [Value: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%f</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">] [Accuracy:</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%f</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">]"</span></span>
<span id="cb4-70">                <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> (epoch, start_epoch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> args.epoch, i, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(dataloader), loss_energy.item(), acc)</span>
<span id="cb4-71">            )</span>
<span id="cb4-72"></span>
<span id="cb4-73">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Save checkpoint</span></span>
<span id="cb4-74">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Saving models...'</span>)</span>
<span id="cb4-75">        state <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb4-76">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'energy'</span>: energy.state_dict(),</span>
<span id="cb4-77">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'value'</span>: loss_energy,</span>
<span id="cb4-78">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'epoch'</span>: epoch,</span>
<span id="cb4-79">        }</span>
<span id="cb4-80">        os.makedirs(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ckpts'</span>, exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb4-81">        torch.save(state, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ckpts/nce.pth.tar'</span>)</span>
<span id="cb4-82"></span>
<span id="cb4-83">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># visualization</span></span>
<span id="cb4-84">        plot(dataset, energy, noise, epoch, device)</span>
<span id="cb4-85"></span>
<span id="cb4-86"></span>
<span id="cb4-87"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__name__</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'__main__'</span>:</span>
<span id="cb4-88">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(args)</span>
<span id="cb4-89">    main(args)</span></code></pre></div>
</div>
<p>大変軽量で，cpu でも５分ほどで学習できる（そのうちほとんどは画像の保存にかかる時間である）．しかし，mps では次のエラーを得る．</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb5-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">NotImplementedError:</span> The operator <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'aten::linalg_cholesky_ex.L'</span> is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">`</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">PYTORCH_ENABLE_MPS_FALLBACK</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>1<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">`</span> <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">to</span> use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.</span></code></pre></div>
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NCL/output_8gaussian.gif" class="img-fluid"></p>
<p>他のデータに関しても，次のように学習できる：</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NCL/output_pinwheel.gif" class="img-fluid figure-img"></p>
<figcaption><code>pinwheel</code> はそれぞれの羽の尾の部分が消えてしまっているように見える．</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NCL/output_rings.gif" class="img-fluid figure-img"></p>
<figcaption><code>rings</code> に関しては結構学習に苦労しているようだ．</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NCL/output_checkerboard.gif" class="img-fluid figure-img"></p>
<figcaption><code>checkerboard</code> も四角い形までは 50 epoch では再現が難しいのかもしれない．</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NCL/output_2spirals.gif" class="img-fluid figure-img"></p>
<figcaption><code>2spirals</code> は結構トポロジーを間違えている！</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NCL/long_rings.gif" class="img-fluid figure-img"></p>
<figcaption><code>rings</code> ロングバージョン．<code>epoch=150</code> としたが，内側２輪しか再現できていない．</figcaption>
</figure>
</div>
</section>


<div id="quarto-appendix" class="default"><section id="文献" class="level2 appendix" data-number="4"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">4</span> 文献</h2><div class="quarto-appendix-contents">

<p><a href="https://lifei.ai/">李飞氏</a> による <a href="https://github.com/lifeitech/nce/blob/master/model.py">実装</a> を参考にした．</p>



</div></section></div> ]]></description>
  <category>Deep</category>
  <category>Sampling</category>
  <category>Python</category>
  <guid>https://162348.github.io/posts/2024/Samplers/EBM2.html</guid>
  <pubDate>Fri, 02 Aug 2024 15:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Samplers/Files/NCL/thumb_8gaussians.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>正規化流</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Samplers/NF2.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="関連ページ" class="level3 unnumbered unlisted">
<h3 class="unnumbered unlisted anchored" data-anchor-id="関連ページ">関連ページ</h3>
<div id="listing-flow-listing" class="quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Deep,Sampling" data-listing-date-sort="1707836400000" data-listing-file-modified-sort="1727007848134" data-listing-date-modified-sort="1723993200000" data-listing-reading-time-sort="3" data-listing-word-count-sort="450">
<a href="../../../posts/2024/Samplers/NF.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_result.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
正規化流
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル４
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Deep,Sampling,P(X)" data-listing-date-sort="1707836400000" data-listing-file-modified-sort="1727007848139" data-listing-date-modified-sort="1724770800000" data-listing-reading-time-sort="4" data-listing-word-count-sort="794">
<a href="../../../posts/2024/Samplers/NF1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/linear/output.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ニューラル常微分方程式
</h5>
<div class="card-subtitle listing-subtitle">
シミュレーションなしの拡散モデルとしての連続正規化流
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Deep,Process,Sampling" data-listing-date-sort="1707836400000" data-listing-file-modified-sort="1727007848002" data-listing-date-modified-sort="1724338800000" data-listing-reading-time-sort="5" data-listing-word-count-sort="826">
<a href="../../../posts/2024/Samplers/Diffusion.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/DDPM_outputs.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
拡散模型
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル６
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>
<section id="real-nvp-dinh2017" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="real-nvp-dinh2017"><span class="header-section-number">1</span> Real NVP <span class="citation" data-cites="Dinh+2017">(Dinh et al., 2017)</span></h2>
<div id="a6e8370b" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import required packages</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> tv</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> normflows <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> nf</span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> matplotlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mpl_toolkits.mplot3d <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Axes3D</span>
<span id="cb1-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> matplotlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> cm</span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span></code></pre></div>
</div>
<div id="38109043" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set up model</span></span>
<span id="cb2-2"></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define 2D Gaussian base distribution</span></span>
<span id="cb2-4">base <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nf.distributions.base.DiagGaussian(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb2-5"></span>
<span id="cb2-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define list of flows</span></span>
<span id="cb2-7">num_layers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span></span>
<span id="cb2-8">flows <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb2-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(num_layers):</span>
<span id="cb2-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Neural network with two hidden layers having 64 units each</span></span>
<span id="cb2-11">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Last layer is initialized by zeros making training more stable</span></span>
<span id="cb2-12">    param_map <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nf.nets.MLP([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>], init_zeros<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb2-13">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add flow layer</span></span>
<span id="cb2-14">    flows.append(nf.flows.AffineCouplingBlock(param_map))</span>
<span id="cb2-15">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Swap dimensions</span></span>
<span id="cb2-16">    flows.append(nf.flows.Permute(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, mode<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'swap'</span>))</span>
<span id="cb2-17">    </span>
<span id="cb2-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct flow model</span></span>
<span id="cb2-19">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nf.NormalizingFlow(base, flows)</span>
<span id="cb2-20">device <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.device(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mps"</span>)</span>
<span id="cb2-21">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.to(device)</span></code></pre></div>
</div>
<div id="9430f9d1" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define target distribution</span></span>
<span id="cb3-2">target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nf.distributions.TwoMoons()</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot target distribution</span></span>
<span id="cb3-5">grid_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span></span>
<span id="cb3-6">xx, yy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.meshgrid(torch.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, grid_size), torch.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, grid_size))</span>
<span id="cb3-7">zz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([xx.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), yy.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb3-8">zz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> zz.to(device)</span>
<span id="cb3-9"></span>
<span id="cb3-10">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target.log_prob(zz).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb3-11">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb3-12">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb3-13"></span>
<span id="cb3-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plt.figure(figsize=(15, 15))</span></span>
<span id="cb3-15">plt.pcolormesh(xx, yy, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb3-16">plt.gca().set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb3-17">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/NF2_files/figure-html/cell-4-output-1.png" width="347" height="341" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="22c827ea" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot initial flow distribution</span></span>
<span id="cb4-2">model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="cb4-3">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.log_prob(zz).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb4-4">model.train()</span>
<span id="cb4-5">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb4-6">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb4-7"></span>
<span id="cb4-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plt.figure(figsize=(15, 15))</span></span>
<span id="cb4-9">plt.pcolormesh(xx, yy, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb4-10">plt.gca().set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb4-11">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/NF2_files/figure-html/cell-5-output-1.png" width="347" height="341" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Train model</span></span>
<span id="cb5-2">max_iter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4000</span></span>
<span id="cb5-3">num_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span></span>
<span id="cb5-4">show_iter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span></span>
<span id="cb5-5"></span>
<span id="cb5-6"></span>
<span id="cb5-7">loss_hist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([])</span>
<span id="cb5-8"></span>
<span id="cb5-9">optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.optim.Adam(model.parameters(), lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5e-4</span>, weight_decay<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-5</span>)</span>
<span id="cb5-10"></span>
<span id="cb5-11"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> it <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> tqdm(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(max_iter)<span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#, disable=True</span></span>
<span id="cb5-12">):</span>
<span id="cb5-13">    optimizer.zero_grad()</span>
<span id="cb5-14">    </span>
<span id="cb5-15">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get training samples</span></span>
<span id="cb5-16">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target.sample(num_samples).to(device)</span>
<span id="cb5-17">    </span>
<span id="cb5-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute loss</span></span>
<span id="cb5-19">    loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.forward_kld(x)</span>
<span id="cb5-20">    </span>
<span id="cb5-21">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Do backprop and optimizer step</span></span>
<span id="cb5-22">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span>(torch.isnan(loss) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> torch.isinf(loss)):</span>
<span id="cb5-23">        loss.backward()</span>
<span id="cb5-24">        optimizer.step()</span>
<span id="cb5-25">    </span>
<span id="cb5-26">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Log loss</span></span>
<span id="cb5-27">    loss_hist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.append(loss_hist, loss.to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).data.numpy())</span>
<span id="cb5-28">    </span>
<span id="cb5-29">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot learned distribution</span></span>
<span id="cb5-30">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (it <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> show_iter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb5-31">        model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="cb5-32">        log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.log_prob(zz)</span>
<span id="cb5-33">        model.train()</span>
<span id="cb5-34">        prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob.to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape))</span>
<span id="cb5-35">        prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb5-36"></span>
<span id="cb5-37">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plt.figure(figsize=(15, 15))</span></span>
<span id="cb5-38">        plt.pcolormesh(xx, yy, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb5-39">        plt.gca().set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb5-40">        plt.show()</span>
<span id="cb5-41">np.save(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'loss_history.npy'</span>, loss_hist)</span></code></pre></div>
<div id="e6fc4c0d" class="cell quarto-layout-panel" data-execution_count="6" data-layout-ncol="4" data-layout-nrow="2">

</div>
<div id="9b9296ff" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot loss</span></span>
<span id="cb6-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plt.figure(figsize=(10, 10))</span></span>
<span id="cb6-3">loss_hist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.load(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Files/loss_history.npy'</span>)</span>
<span id="cb6-4">plt.plot(loss_hist, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'loss'</span>)</span>
<span id="cb6-5">plt.legend()</span>
<span id="cb6-6">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/NF2_files/figure-html/cell-7-output-1.png" width="496" height="337" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="ff291ecb" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot target distribution</span></span>
<span id="cb7-2">f, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, sharey<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>))</span>
<span id="cb7-3"></span>
<span id="cb7-4">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target.log_prob(zz).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb7-5">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb7-6">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb7-7"></span>
<span id="cb7-8">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].pcolormesh(xx, yy, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb7-9"></span>
<span id="cb7-10">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb7-11">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_axis_off()</span>
<span id="cb7-12">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Target'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>)</span>
<span id="cb7-13"></span>
<span id="cb7-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot learned distribution</span></span>
<span id="cb7-15">model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="cb7-16">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.log_prob(zz).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb7-17">model.train()</span>
<span id="cb7-18">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb7-19">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb7-20"></span>
<span id="cb7-21">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].pcolormesh(xx, yy, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb7-22"></span>
<span id="cb7-23">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb7-24">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_axis_off()</span>
<span id="cb7-25">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Real NVP'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>)</span>
<span id="cb7-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plt.savefig("./Files/NF2.png")</span></span>
<span id="cb7-27">plt.subplots_adjust(wspace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>)</span>
<span id="cb7-28">plt.show()</span></code></pre></div>
</div>
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF2.png" class="img-fluid"></p>
</section>
<section id="neural-spline-flow-durkan2019" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="neural-spline-flow-durkan2019"><span class="header-section-number">2</span> Neural Spline Flow <span class="citation" data-cites="Durkan+2019">(Durkan et al., 2019)</span></h2>
<p>円周 <img src="https://latex.codecogs.com/png.latex?S%5E1"> 上の確率分布として，wrapped Normal 分布や <a href="https://en.wikipedia.org/wiki/Von_Mises_distribution">von Mises 分布</a>がある．</p>
<p>今回は後者を採用し，<img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E2"> 上で密度モデリングを試みる：</p>
<div id="210fda08" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set up target</span></span>
<span id="cb8-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> GaussianVonMises(nf.distributions.Target):</span>
<span id="cb8-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb8-4">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>().<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(prop_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.tensor(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.pi), </span>
<span id="cb8-5">                         prop_shift<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.tensor(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>np.pi))</span>
<span id="cb8-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.n_dims <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb8-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.99</span></span>
<span id="cb8-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.log_const <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.log(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.pi) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> np.log(np.i0(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb8-9">    </span>
<span id="cb8-10">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> log_prob(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x):</span>
<span id="cb8-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> torch.cos(x[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.log_const</span>
<span id="cb8-12"></span>
<span id="cb8-13">target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GaussianVonMises()</span>
<span id="cb8-14"></span>
<span id="cb8-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot target</span></span>
<span id="cb8-16">grid_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span></span>
<span id="cb8-17">xx, yy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.meshgrid(torch.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>, grid_size), torch.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>np.pi, np.pi, grid_size))</span>
<span id="cb8-18">zz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([xx.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), yy.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb8-19"></span>
<span id="cb8-20">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target.log_prob(zz).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb8-21">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb8-22">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb8-23"></span>
<span id="cb8-24">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>))</span>
<span id="cb8-25">plt.pcolormesh(yy, xx, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb8-26">plt.gca().set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb8-27">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/NF2_files/figure-html/cell-9-output-1.png" width="1164" height="930" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>今回は 12 層の Neural Spline Flow を採用し，２次元の Gaussian 分布に基底として採用する．</p>
<div id="52fe9d7d" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">base <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nf.distributions.UniformGaussian(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], torch.tensor([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.pi]))</span>
<span id="cb9-2"></span>
<span id="cb9-3">K <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span></span>
<span id="cb9-4"></span>
<span id="cb9-5">flow_layers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb9-6"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(K):</span>
<span id="cb9-7">    flow_layers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> [nf.flows.CircularAutoregressiveRationalQuadraticSpline(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span>, [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], num_bins<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>,</span>
<span id="cb9-8">                                                                           tail_bound<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.tensor([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.</span>, np.pi]),</span>
<span id="cb9-9">                                                                           permute_mask<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)]</span>
<span id="cb9-10"></span>
<span id="cb9-11">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nf.NormalizingFlow(base, flow_layers, target)</span>
<span id="cb9-12"></span>
<span id="cb9-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Move model on GPU if available</span></span>
<span id="cb9-14">device <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.device(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mps"</span>)</span>
<span id="cb9-15">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.to(device)</span></code></pre></div>
</div>
<div id="0d638753" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot model</span></span>
<span id="cb10-2">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.log_prob(zz.to(device)).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb10-3">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb10-4">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb10-5"></span>
<span id="cb10-6">plt.figure()</span>
<span id="cb10-7">plt.pcolormesh(yy, xx, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb10-8">plt.gca().set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb10-9">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/NF2_files/figure-html/cell-11-output-1.png" width="420" height="337" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="ff071cc4" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Train model</span></span>
<span id="cb11-2">max_iter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span></span>
<span id="cb11-3">num_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span></span>
<span id="cb11-4">show_iter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2500</span></span>
<span id="cb11-5"></span>
<span id="cb11-6"></span>
<span id="cb11-7">loss_hist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([])</span>
<span id="cb11-8"></span>
<span id="cb11-9">optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.optim.Adam(model.parameters(), lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5e-4</span>)</span>
<span id="cb11-10">scheduler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_iter)</span>
<span id="cb11-11"></span>
<span id="cb11-12"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> it <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> tqdm(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(max_iter)):</span>
<span id="cb11-13">    optimizer.zero_grad()</span>
<span id="cb11-14">    </span>
<span id="cb11-15">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute loss</span></span>
<span id="cb11-16">    loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.reverse_kld(num_samples)</span>
<span id="cb11-17">    </span>
<span id="cb11-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Do backprop and optimizer step</span></span>
<span id="cb11-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span>(torch.isnan(loss) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> torch.isinf(loss)):</span>
<span id="cb11-20">        loss.backward()</span>
<span id="cb11-21">        optimizer.step()</span>
<span id="cb11-22">    </span>
<span id="cb11-23">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Log loss</span></span>
<span id="cb11-24">    loss_hist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.append(loss_hist, loss.to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).data.numpy())</span>
<span id="cb11-25">    </span>
<span id="cb11-26">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot learned model</span></span>
<span id="cb11-27">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (it <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> show_iter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb11-28">        model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="cb11-29">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb11-30">            log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.log_prob(zz.to(device)).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb11-31">        model.train()</span>
<span id="cb11-32">        prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb11-33">        prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb11-34"></span>
<span id="cb11-35">        plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>))</span>
<span id="cb11-36">        plt.pcolormesh(yy, xx, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb11-37">        plt.gca().set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb11-38">        plt.show()</span>
<span id="cb11-39">    </span>
<span id="cb11-40">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Iterate scheduler</span></span>
<span id="cb11-41">    scheduler.step()</span>
<span id="cb11-42"></span>
<span id="cb11-43"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot loss</span></span>
<span id="cb11-44">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>))</span>
<span id="cb11-45">plt.plot(loss_hist, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'loss'</span>)</span>
<span id="cb11-46">plt.legend()</span>
<span id="cb11-47">plt.show()</span></code></pre></div>
</div>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="5">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 20.0%;justify-content: center;">
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_training0.png" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 20.0%;justify-content: center;">
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_training1.png" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 20.0%;justify-content: center;">
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_training2.png" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 20.0%;justify-content: center;">
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_training3.png" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 20.0%;justify-content: center;">
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_training4.png" class="img-fluid"></p>
</div>
</div>
</div>
<p>訓練は L4 で約１時間であった．</p>
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_training_loss.png" class="img-fluid"></p>
<div id="9fafb634" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2D plot</span></span>
<span id="cb12-2">f, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, sharey<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>))</span>
<span id="cb12-3"></span>
<span id="cb12-4">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target.log_prob(zz).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb12-5">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb12-6">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb12-7"></span>
<span id="cb12-8">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].pcolormesh(yy, xx, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb12-9">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb12-10"></span>
<span id="cb12-11">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_xticks(ticks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>np.pi, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>np.pi<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, np.pi<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, np.pi])</span>
<span id="cb12-12">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_xticklabels([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$-\pi$'</span>, <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'$-\frac{\pi}</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{2}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">$'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$0$'</span>, <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'$\frac{\pi}</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{2}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">$'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$\pi$'</span>],</span>
<span id="cb12-13">                      fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span>
<span id="cb12-14">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_yticks(ticks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>])</span>
<span id="cb12-15">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_yticklabels([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$-2$'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$-1$'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$0$'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$1$'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$2$'</span>],</span>
<span id="cb12-16">                      fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span>
<span id="cb12-17">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$\phi$'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>)</span>
<span id="cb12-18">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$x$'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>)</span>
<span id="cb12-19"></span>
<span id="cb12-20">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Target'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>)</span>
<span id="cb12-21"></span>
<span id="cb12-22">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.log_prob(zz.to(device)).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb12-23">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb12-24">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb12-25"></span>
<span id="cb12-26">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].pcolormesh(yy, xx, prob.data.numpy(), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'coolwarm'</span>)</span>
<span id="cb12-27">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb12-28"></span>
<span id="cb12-29">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_xticks(ticks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>np.pi, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>np.pi<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, np.pi<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, np.pi])</span>
<span id="cb12-30">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_xticklabels([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$-\pi$'</span>, <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'$-\frac{\pi}</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{2}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">$'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$0$'</span>, <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'$\frac{\pi}</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{2}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">$'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$\pi$'</span>],</span>
<span id="cb12-31">                      fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span>
<span id="cb12-32">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$\phi$'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>)</span>
<span id="cb12-33"></span>
<span id="cb12-34">ax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Neural Spline Flow'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>)</span>
<span id="cb12-35"></span>
<span id="cb12-36">plt.subplots_adjust(wspace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>)</span>
<span id="cb12-37"></span>
<span id="cb12-38">plt.show()</span></code></pre></div>
</div>
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_comparison.png" class="img-fluid"></p>
<div id="d66ec8f0" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3D plot</span></span>
<span id="cb13-2">fig <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>))</span>
<span id="cb13-3">ax1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fig.add_subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, projection<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'3d'</span>)</span>
<span id="cb13-4">ax2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fig.add_subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, projection<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'3d'</span>)</span>
<span id="cb13-5"></span>
<span id="cb13-6">phi <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>np.pi, np.pi, grid_size)</span>
<span id="cb13-7">z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>, grid_size)</span>
<span id="cb13-8"></span>
<span id="cb13-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># create the surface</span></span>
<span id="cb13-10">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.outer(np.ones(grid_size), np.cos(phi))</span>
<span id="cb13-11">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.outer(np.ones(grid_size), np.sin(phi))</span>
<span id="cb13-12">z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.outer(z, np.ones(grid_size))</span>
<span id="cb13-13"></span>
<span id="cb13-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Target</span></span>
<span id="cb13-15">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target.log_prob(zz).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb13-16">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb13-17">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb13-18"></span>
<span id="cb13-19">prob_vis <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(prob)</span>
<span id="cb13-20">myheatmap <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prob_vis.data.numpy()</span>
<span id="cb13-21"></span>
<span id="cb13-22">ax1._axis3don <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb13-23">ax1.plot_surface(x, y, z, cstride<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, rstride<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, facecolors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cm.coolwarm(myheatmap), shade<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb13-24"></span>
<span id="cb13-25">ax1.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Target'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.97</span>, pad<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb13-26"></span>
<span id="cb13-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Model</span></span>
<span id="cb13-28">log_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.log_prob(zz.to(device)).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).view(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.shape)</span>
<span id="cb13-29">prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(log_prob)</span>
<span id="cb13-30">prob[torch.isnan(prob)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb13-31"></span>
<span id="cb13-32">prob_vis <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(prob)</span>
<span id="cb13-33">myheatmap <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prob_vis.data.numpy()</span>
<span id="cb13-34"></span>
<span id="cb13-35">ax2._axis3don <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb13-36">ax2.plot_surface(x, y, z, cstride<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, rstride<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, facecolors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cm.coolwarm(myheatmap), shade<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb13-37"></span>
<span id="cb13-38">t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ax2.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Neural Spline Flow'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.97</span>, pad<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb13-39"></span>
<span id="cb13-40">plt.show()</span></code></pre></div>
</div>
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/NSF_result.png" class="img-fluid"></p>
</section>
<section id="glow-kingma-dhariwal2018" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="glow-kingma-dhariwal2018"><span class="header-section-number">3</span> Glow <span class="citation" data-cites="Kingma-Dhariwal2018">(Kingma and Dhariwal, 2018)</span></h2>
<p>今回は CIFAR-10 という手描き文字画像データセットを学習し，画像の生成を目指す．</p>
<p>この際には，<span class="citation" data-cites="Dinh+2017">(Dinh et al., 2017)</span> の multiscale architecture を採用し，基底分布も成分ごとにスケールが違う正規分布を用いる．</p>
<div id="807d7273" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set up model</span></span>
<span id="cb14-2"></span>
<span id="cb14-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define flows</span></span>
<span id="cb14-4">L <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span></span>
<span id="cb14-5">K <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span></span>
<span id="cb14-6">torch.manual_seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb14-7"></span>
<span id="cb14-8">input_shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>)</span>
<span id="cb14-9">n_dims <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.prod(input_shape)</span>
<span id="cb14-10">channels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span></span>
<span id="cb14-11">hidden_channels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span></span>
<span id="cb14-12">split_mode <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'channel'</span></span>
<span id="cb14-13">scale <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb14-14">num_classes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span></span>
<span id="cb14-15"></span>
<span id="cb14-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set up flows, distributions and merge operations</span></span>
<span id="cb14-17">q0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb14-18">merges <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb14-19">flows <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb14-20"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(L):</span>
<span id="cb14-21">    flows_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb14-22">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(K):</span>
<span id="cb14-23">        flows_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> [nf.flows.GlowBlock(channels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> (L <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> i), hidden_channels,</span>
<span id="cb14-24">                                     split_mode<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>split_mode, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>scale)]</span>
<span id="cb14-25">    flows_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> [nf.flows.Squeeze()]</span>
<span id="cb14-26">    flows <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> [flows_]</span>
<span id="cb14-27">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb14-28">        merges <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> [nf.flows.Merge()]</span>
<span id="cb14-29">        latent_shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (input_shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> (L <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> i), input_shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> (L <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> i),</span>
<span id="cb14-30">                        input_shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> (L <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> i))</span>
<span id="cb14-31">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb14-32">        latent_shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (input_shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> (L <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), input_shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> L,</span>
<span id="cb14-33">                        input_shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> L)</span>
<span id="cb14-34">    q0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> [nf.distributions.ClassCondDiagGaussian(latent_shape, num_classes)]</span>
<span id="cb14-35"></span>
<span id="cb14-36"></span>
<span id="cb14-37"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct flow model with the multiscale architecture</span></span>
<span id="cb14-38">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nf.MultiscaleFlow(q0, flows, merges)</span>
<span id="cb14-39">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.to(device)</span></code></pre></div>
</div>
<div id="2016fbfd" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare training data</span></span>
<span id="cb15-2">batch_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span></span>
<span id="cb15-3"></span>
<span id="cb15-4">transform <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tv.transforms.Compose([tv.transforms.ToTensor(), nf.utils.Scale(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">255.</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">256.</span>), nf.utils.Jitter(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">256.</span>)])</span>
<span id="cb15-5">train_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tv.datasets.CIFAR10(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'datasets/'</span>, train<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb15-6">                                 download<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transform)</span>
<span id="cb15-7">train_loader <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.utils.data.DataLoader(train_data, batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>batch_size, shuffle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb15-8">                                           drop_last<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb15-9"></span>
<span id="cb15-10">test_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tv.datasets.CIFAR10(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'datasets/'</span>, train<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,</span>
<span id="cb15-11">                                download<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transform)</span>
<span id="cb15-12">test_loader <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.utils.data.DataLoader(test_data, batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>batch_size)</span>
<span id="cb15-13"></span>
<span id="cb15-14">train_iter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">iter</span>(train_loader)</span></code></pre></div>
</div>
<div id="2d9214fd" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Train model</span></span>
<span id="cb16-2">max_iter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20000</span></span>
<span id="cb16-3"></span>
<span id="cb16-4">loss_hist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([])</span>
<span id="cb16-5"></span>
<span id="cb16-6">optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.optim.Adamax(model.parameters(), lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-3</span>, weight_decay<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-5</span>)</span>
<span id="cb16-7"></span>
<span id="cb16-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> tqdm(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(max_iter)):</span>
<span id="cb16-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">try</span>:</span>
<span id="cb16-10">        x, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">next</span>(train_iter)</span>
<span id="cb16-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">except</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">StopIteration</span>:</span>
<span id="cb16-12">        train_iter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">iter</span>(train_loader)</span>
<span id="cb16-13">        x, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">next</span>(train_iter)</span>
<span id="cb16-14">    optimizer.zero_grad()</span>
<span id="cb16-15">    loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.forward_kld(x.to(device), y.to(device))</span>
<span id="cb16-16"></span>
<span id="cb16-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span>(torch.isnan(loss) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> torch.isinf(loss)):</span>
<span id="cb16-18">        loss.backward()</span>
<span id="cb16-19">        optimizer.step()</span>
<span id="cb16-20"></span>
<span id="cb16-21">    loss_hist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.append(loss_hist, loss.detach().to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>).numpy())</span></code></pre></div>
</div>
<div id="4dea18cf" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>))</span>
<span id="cb17-2">plt.plot(loss_hist, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'loss'</span>)</span>
<span id="cb17-3">plt.legend()</span>
<span id="cb17-4">plt.savefig(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'fig1.png'</span>)</span>
<span id="cb17-5">plt.show()</span></code></pre></div>
</div>
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/Glow_training_loss.png" class="img-fluid"></p>
<p>2万イテレーションで1時間10分を要したが，cutting-edge な性能を出すには遥かに大きいモデルを 100 万イテレーションほどする必要があるという．</p>
<div id="69cdf5a8" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Model samples</span></span>
<span id="cb18-2">num_sample <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span></span>
<span id="cb18-3"></span>
<span id="cb18-4"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb18-5">    y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.arange(num_classes).repeat(num_sample).to(device)</span>
<span id="cb18-6">    x, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.sample(y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y)</span>
<span id="cb18-7">    x_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.clamp(x, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb18-8">    plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>))</span>
<span id="cb18-9">    plt.imshow(np.transpose(tv.utils.make_grid(x_, nrow<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>num_classes).cpu().numpy(), (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)))</span>
<span id="cb18-10">    plt.savefig(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'fig2.png'</span>)</span>
<span id="cb18-11">    plt.show()</span></code></pre></div>
</div>
<p><img src="https://162348.github.io/posts/2024/Samplers/Files/NF/Glow_output.png" class="img-fluid"></p>
</section>


<div id="quarto-appendix" class="default"><section id="文献" class="level2 appendix" data-number="4"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">4</span> 文献</h2><div class="quarto-appendix-contents">

<p><a href="https://evjang.com/">Eric Jang 氏</a> による <a href="https://github.com/ericjang/normalizing-flows-tutorial">チュートリアル</a> （や<a href="https://github.com/pierresegonne/VINF">その他のチュートリアル</a>）は，TensorFlow 1 を用いており，特に <code>tfb.Affine</code> はもうサポートされていない（<a href="https://github.com/tensorflow/probability/issues/448#issuecomment-555629330">対応表</a>）．</p>
<p><a href="https://github.com/VincentStimper/normalizing-flows?tab=readme-ov-file"><code>normflows</code> というパッケージ</a> <span class="citation" data-cites="Stimper+2023">(Stimper et al., 2023)</span> は PyTorch ベースの実装を提供しており，これを代わりに用いた．<a href="https://colab.research.google.com/github/VincentStimper/normalizing-flows/blob/master/examples/real_nvp_colab.ipynb">Real NVP</a>, <a href="https://colab.research.google.com/github/VincentStimper/normalizing-flows/blob/master/examples/paper_example_nsf_colab.ipynb">Neural Spline Flow</a>, <a href="https://colab.research.google.com/github/VincentStimper/normalizing-flows/blob/master/examples/glow_colab.ipynb">Glow</a> などのデモを公開している．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Dinh+2017" class="csl-entry">
Dinh, L., Sohl-Dickstein, J., and Bengio, S. (2017). <a href="https://openreview.net/forum?id=HkpbnH9lx">Density estimation using real <span>NVP</span></a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Durkan+2019" class="csl-entry">
Durkan, C., Bekasov, A., Murray, I., and Papamakarios, G. (2019). <a href="https://proceedings.neurips.cc/paper_files/paper/2019/file/7ac71d433f282034e088473244df8c02-Paper.pdf">Neural spline flows</a>. In H. Wallach, H. Larochelle, A. Beygelzimer, F. dAlché-Buc, E. Fox, and R. Garnett, editors, <em>Advances in neural information processing systems</em>,Vol. 32. Curran Associates, Inc.
</div>
<div id="ref-Kingma-Dhariwal2018" class="csl-entry">
Kingma, D. P., and Dhariwal, P. (2018). <a href="https://proceedings.neurips.cc/paper_files/paper/2018/file/d139db6a236200b21cc7f752979132d0-Paper.pdf">Glow: Generative flow with invertible 1x1 convolutions</a>. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, <em>Advances in neural information processing systems</em>,Vol. 31. Curran Associates, Inc.
</div>
<div id="ref-Stimper+2023" class="csl-entry">
Stimper, V., Liu, D., Campbell, A., Berenz, V., Ryll, L., Schölkopf, B., and Hernández-Lobato, J. M. (2023). <a href="https://doi.org/10.21105/joss.05361">Normflows: A PyTorch package for normalizing flows</a>. <em>Journal of Open Source Software</em>, <em>8</em>(86), 5361.
</div>
</div></section></div> ]]></description>
  <category>Deep</category>
  <category>Sampling</category>
  <category>Python</category>
  <guid>https://162348.github.io/posts/2024/Samplers/NF2.html</guid>
  <pubDate>Fri, 02 Aug 2024 15:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Samplers/Files/NF/Glow_output.png" medium="image" type="image/png" height="143" width="144"/>
</item>
<item>
  <title>スコアマッチング</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Samplers/EBM1.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="関連ページ" class="level3 unnumbered unlisted">
<h3 class="unnumbered unlisted anchored" data-anchor-id="関連ページ">関連ページ</h3>
<div id="listing-lst-listing" class="listing quarto-float quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Deep,Nature,Sampling" data-listing-date-sort="1711724400000" data-listing-file-modified-sort="1727007848003" data-listing-date-modified-sort="1722438000000" data-listing-reading-time-sort="5" data-listing-word-count-sort="880">
<a href="../../../posts/2024/Samplers/EBM.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/NCL/thumb_checkerboard.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
エネルギーベースモデル
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル５
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-03-30
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Deep,Sampling,Python" data-listing-date-sort="1722610800000" data-listing-file-modified-sort="1727007848004" data-listing-date-modified-sort="1724166000000" data-listing-reading-time-sort="11" data-listing-word-count-sort="2117">
<a href="../../../posts/2024/Samplers/EBM2.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/NCL/thumb_8gaussians.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
エネルギーベースモデルのノイズ対照学習
</h5>
<div class="card-subtitle listing-subtitle">
<code>PyTorch</code> によるハンズオン
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-03
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Deep,Sampling,P(X)" data-listing-date-sort="1707836400000" data-listing-file-modified-sort="1727007848139" data-listing-date-modified-sort="1724770800000" data-listing-reading-time-sort="4" data-listing-word-count-sort="794">
<a href="../../../posts/2024/Samplers/NF1.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/linear/output.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
ニューラル常微分方程式
</h5>
<div class="card-subtitle listing-subtitle">
シミュレーションなしの拡散モデルとしての連続正規化流
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-02-14
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</section>
<section id="sgm-score-based-generative-model" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="sgm-score-based-generative-model"><span class="header-section-number">1</span> SGM (Score-based Generative Model)</h2>
<section id="目標のデータ" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="目標のデータ"><span class="header-section-number">1.1</span> 目標のデータ</h3>
<div id="c0b335ec" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> make_swiss_roll</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> jax</span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> jax.numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> jnp</span>
<span id="cb1-7"></span>
<span id="cb1-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">try</span>:</span>
<span id="cb1-9">    <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> flax <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> linen <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> nn  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The Linen API</span></span>
<span id="cb1-10"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">except</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">ModuleNotFoundError</span>:</span>
<span id="cb1-11">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>pip install <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>qq flax</span>
<span id="cb1-12">    <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> flax <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> linen <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> nn  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The Linen API</span></span>
<span id="cb1-13"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> flax.training <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_state  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Useful dataclass to keep train state</span></span>
<span id="cb1-14"></span>
<span id="cb1-15"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">try</span>:</span>
<span id="cb1-16">    <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> optax  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Optimizers</span></span>
<span id="cb1-17"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">except</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">ModuleNotFoundError</span>:</span>
<span id="cb1-18">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>pip install <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>qq optax</span>
<span id="cb1-19">    <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> optax  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Optimizers</span></span>
<span id="cb1-20"></span>
<span id="cb1-21"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> functools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> partial</span>
<span id="cb1-22"></span>
<span id="cb1-23"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> IPython.display <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> clear_output</span></code></pre></div>
</div>
<div id="a84c1e33" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> sample_batch(size, noise<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>):</span>
<span id="cb2-2">    x, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> make_swiss_roll(size, noise<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>noise)</span>
<span id="cb2-3">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x[:, [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">10.0</span></span>
<span id="cb2-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> np.array(x)</span>
<span id="cb2-5"></span>
<span id="cb2-6"></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plt.figure(figsize=[16, 16])</span></span>
<span id="cb2-8">plt.scatter(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>sample_batch(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>).T, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>)</span>
<span id="cb2-9">plt.axis(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"off"</span>)</span>
<span id="cb2-10">plt.tight_layout()</span>
<span id="cb2-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plt.savefig("swiss_roll.png")</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/EBM1_files/figure-html/cell-3-output-1.png" width="566" height="374" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="モデルの定義" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="モデルの定義"><span class="header-section-number">1.2</span> モデルの定義</h3>
<div id="061722ed" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> Model(nn.Module):</span>
<span id="cb3-2">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@nn.compact</span></span>
<span id="cb3-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__call__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x):</span>
<span id="cb3-4"></span>
<span id="cb3-5">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Dense(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>)(x)</span>
<span id="cb3-6">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.softplus(x)</span>
<span id="cb3-7">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Dense(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>)(x)</span>
<span id="cb3-8">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.softplus(x)</span>
<span id="cb3-9">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Dense(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)(x)</span>
<span id="cb3-10"></span>
<span id="cb3-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> x</span></code></pre></div>
</div>
</section>
<section id="モデルの訓練" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="モデルの訓練"><span class="header-section-number">1.3</span> モデルの訓練</h3>
<div id="388848fc" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@jax.jit</span></span>
<span id="cb4-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> compute_loss(params, inputs):</span>
<span id="cb4-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  a function that computes jacobian by forward mode differentiation</span></span>
<span id="cb4-4">    jacobian <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> jax.jacfwd(Model().<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>, argnums<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-5"></span>
<span id="cb4-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># we use jax.vmap to vectorize jacobian function along batch dimension</span></span>
<span id="cb4-7">    batch_jacobian <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> jax.vmap(partial(jacobian, {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"params"</span>: params}))(inputs)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [batch, dim, dim]</span></span>
<span id="cb4-8"></span>
<span id="cb4-9">    trace_jacobian <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> jnp.trace(batch_jacobian, axis1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, axis2<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb4-10">    output_norm_sq <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> jnp.square(Model().<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"params"</span>: params}, inputs)).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-11"></span>
<span id="cb4-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> jnp.mean(trace_jacobian <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> output_norm_sq)</span></code></pre></div>
</div>
<div id="1ac35253" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@jax.jit</span></span>
<span id="cb5-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> train_step(state, batch, key):</span>
<span id="cb5-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Train for a single step."""</span></span>
<span id="cb5-4">    loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> compute_loss(state.params, batch)</span>
<span id="cb5-5">    grads <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> jax.grad(compute_loss, argnums<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)(state.params, batch)</span>
<span id="cb5-6">    state <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state.apply_gradients(grads<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>grads)</span>
<span id="cb5-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> state, loss</span>
<span id="cb5-8"></span>
<span id="cb5-9"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> create_train_state(rng, learning_rate):</span>
<span id="cb5-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Creates initial `TrainState`."""</span></span>
<span id="cb5-11">    net <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Model()</span>
<span id="cb5-12">    params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> net.init(rng, jnp.ones([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]))[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"params"</span>]</span>
<span id="cb5-13">    tx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> optax.adam(learning_rate)</span>
<span id="cb5-14">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> train_state.TrainState.create(apply_fn<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>net.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>, params<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>params, tx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tx)</span>
<span id="cb5-15"></span>
<span id="cb5-16"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> train_loop(key, train_step, nsteps):</span>
<span id="cb5-17">    key, subkey <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> jax.random.split(key)</span>
<span id="cb5-18">    state <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> create_train_state(subkey, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-3</span>)</span>
<span id="cb5-19">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">del</span> subkey  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Must not be used anymore.</span></span>
<span id="cb5-20">    loss_history <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb5-21">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(nsteps):</span>
<span id="cb5-22">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sample_batch(size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>)</span>
<span id="cb5-23">        key, subkey <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> jax.random.split(key)</span>
<span id="cb5-24">        state, loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_step(state, x, subkey)</span>
<span id="cb5-25">        loss_history.append(loss.item())</span>
<span id="cb5-26"></span>
<span id="cb5-27">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb5-28">            clear_output(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb5-29">            plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>])</span>
<span id="cb5-30">            plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb5-31">            plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mean loss = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%.3f</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> jnp.mean(jnp.array(loss_history[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>:])))</span>
<span id="cb5-32">            plt.scatter(jnp.arange(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(loss_history)), loss_history)</span>
<span id="cb5-33">            plt.grid()</span>
<span id="cb5-34"></span>
<span id="cb5-35">            plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb5-36">            xx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> jnp.stack(jnp.meshgrid(jnp.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>), jnp.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>)), axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).reshape(</span>
<span id="cb5-37">                <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb5-38">            )</span>
<span id="cb5-39">            scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Model().<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"params"</span>: state.params}, xx)</span>
<span id="cb5-40">            scores_norm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> jnp.linalg.norm(scores, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">ord</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, keepdims<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb5-41">            scores_log1p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (scores_norm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-9</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> jnp.log1p(scores_norm)</span>
<span id="cb5-42"></span>
<span id="cb5-43">            plt.quiver(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.T, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>scores_log1p.T, width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.002</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"green"</span>)</span>
<span id="cb5-44">            plt.xlim(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>)</span>
<span id="cb5-45">            plt.ylim(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span>)</span>
<span id="cb5-46">            plt.show()</span>
<span id="cb5-47"></span>
<span id="cb5-48">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> state</span>
<span id="cb5-49"></span>
<span id="cb5-50">state <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_loop(jax.random.PRNGKey(seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>), train_step, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/EBM1_files/figure-html/cell-6-output-1.png" width="1258" height="653" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="学習されたスコア" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="学習されたスコア"><span class="header-section-number">1.4</span> 学習されたスコア</h3>
<div id="cell-fig-learned-score" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plt.figure(figsize=[16, 16])</span></span>
<span id="cb6-2"></span>
<span id="cb6-3">xx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> jnp.stack(jnp.meshgrid(jnp.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>), jnp.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>)), axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb6-4">scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Model().<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"params"</span>: state.params}, xx)</span>
<span id="cb6-5">scores_norm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> jnp.linalg.norm(scores, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">ord</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, keepdims<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb6-6">scores_log1p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (scores_norm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-9</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> jnp.log1p(scores_norm)</span>
<span id="cb6-7"></span>
<span id="cb6-8">plt.quiver(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>xx.T, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>scores_log1p.T, width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.002</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"green"</span>)</span>
<span id="cb6-9">plt.scatter(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>sample_batch(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10_000</span>).T, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>)</span>
<span id="cb6-10">plt.axis(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"off"</span>)</span>
<span id="cb6-11">plt.tight_layout()</span>
<span id="cb6-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># plt.savefig("score_matching_swiss_roll.png")</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-learned-score" class="quarto-figure quarto-figure-center quarto-float anchored" height="374" width="566">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-learned-score-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://162348.github.io/posts/2024/Samplers/EBM1_files/figure-html/fig-learned-score-output-1.png" id="fig-learned-score" width="566" height="374" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-learned-score-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
図&nbsp;1
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="ssm-sliced-score-matching" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="ssm-sliced-score-matching"><span class="header-section-number">2</span> SSM (Sliced Score Matching)</h2>
</section>
<section id="jax-framework" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="jax-framework"><span class="header-section-number">3</span> JAX framework</h2>
<section id="はじめに" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="はじめに"><span class="header-section-number">3.1</span> はじめに</h3>
<p>Google の JAX (<a href="https://github.com/google/jax">GitHub</a>) とは，科学計算と機械学習のためのフレームワークである．</p>
<p>Autograd (<a href="https://github.com/hips/autograd">GitHub</a>) を用いて，Python のビルトイン関数や NumPy 関数を自動微分することができる．</p>
<p>今回は JAX エコシステムの一つである，深層学習のためのフレームワークである <a href="https://github.com/google/flax">Flax</a>，特に Linen モジュール (<a href="https://flax.readthedocs.io/en/latest/api_reference/flax.linen/index.html">docs</a> / <a href="https://github.com/google/flax/blob/main/flax/linen/README.md">GitHub</a>) を用いた．</p>
</section>
</section>


<div id="quarto-appendix" class="default"><section id="文献" class="level2 appendix" data-number="4"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">4</span> 文献</h2><div class="quarto-appendix-contents">

<p>コードは <span class="citation" data-cites="Murphy2023">(Murphy, 2023)</span> の <a href="https://github.com/probml/pyprobml/blob/master/notebooks/book2/24/score_matching_swiss_roll.ipynb">こちら</a> を参考にした．</p>
<p><a href="https://yang-song.net/blog/2021/score/">Yang Song</a> のコードも参考．</p>
<p><span class="citation" data-cites="Song+2019">(Song et al., 2019)</span> のコードは <a href="https://github.com/ermongroup/sliced_score_matching">このレポジトリ</a> で公開されている．</p>
<p><a href="https://uvadlc-notebooks.readthedocs.io/en/latest/index.html">UvA DL Tutorial</a> も参照．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Murphy2023" class="csl-entry">
Murphy, K. P. (2023). <em><a href="http://probml.github.io/book2">Probabilistic machine learning: Advanced topics</a></em>. MIT Press.
</div>
<div id="ref-Song+2019" class="csl-entry">
Song, Y., Garg, S., Shi, J., and Ermon, S. (2019). <a href="https://arxiv.org/abs/1905.07088"><span class="nocase">Sliced Score Matching: A Scalable Approach to Density and Score Estimation</span></a>. In.
</div>
</div></section></div> ]]></description>
  <category>Deep</category>
  <category>Python</category>
  <guid>https://162348.github.io/posts/2024/Samplers/EBM1.html</guid>
  <pubDate>Thu, 01 Aug 2024 15:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Samplers/Files/swiss_roll.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>拡散模型の実装</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Samplers/DDPM.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="ハイパーパラメーターの設定" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="ハイパーパラメーターの設定"><span class="header-section-number">1</span> ハイパーパラメーターの設定</h2>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbeta_0=10%5E%7B-4%7D"> から <img src="https://latex.codecogs.com/png.latex?%5Cbeta_T=0.02"> までを，<code>n_timesteps = 1000</code> 等分し，その間のダイナミクスを <code>hidden_dim = 256</code> 次元の CNN ８層で学習する．</p>
<div id="674f62fa" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>必要なパッケージの読み込み</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.nn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> nn</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.nn.functional <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> F</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-7"></span>
<span id="cb1-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span>
<span id="cb1-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> save_image, make_grid</span>
<span id="cb1-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span>
<span id="cb1-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.optim <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Adam</span>
<span id="cb1-12"></span>
<span id="cb1-13"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> math</span>
<span id="cb1-14"></span>
<span id="cb1-15">dataset_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'~/hirofumi/datasets'</span></span></code></pre></div>
</details>
</div>
<div id="2f066e53" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">DEVICE <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.device(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mps"</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># MacOS 上で実行しました</span></span>
<span id="cb2-2"></span>
<span id="cb2-3">dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MNIST'</span></span>
<span id="cb2-4">img_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)   <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CIFAR10"</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">28</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">28</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (width, height, channels)</span></span>
<span id="cb2-5"></span>
<span id="cb2-6">timestep_embedding_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span></span>
<span id="cb2-7">n_layers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span></span>
<span id="cb2-8">hidden_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span></span>
<span id="cb2-9">n_timesteps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span></span>
<span id="cb2-10">beta_minmax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2e-2</span>]</span>
<span id="cb2-11"></span>
<span id="cb2-12">train_batch_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span></span>
<span id="cb2-13">inference_batch_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span></span>
<span id="cb2-14">lr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5e-5</span></span>
<span id="cb2-15">epochs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb2-16"></span>
<span id="cb2-17">seed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1234</span></span>
<span id="cb2-18"></span>
<span id="cb2-19">hidden_dims <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [hidden_dim <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> _ <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n_layers)]</span>
<span id="cb2-20">torch.manual_seed(seed)</span>
<span id="cb2-21">np.random.seed(seed)</span></code></pre></div>
</div>
<div id="13cfcf19" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>データセットの読み込み</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> MNIST, CIFAR10</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision.transforms <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> transforms</span>
<span id="cb3-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.utils.data <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DataLoader</span>
<span id="cb3-4"></span>
<span id="cb3-5"></span>
<span id="cb3-6">transform <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb3-7">        transforms.ToTensor(),</span>
<span id="cb3-8">])</span>
<span id="cb3-9"></span>
<span id="cb3-10">kwargs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'num_workers'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pin_memory'</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>}  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 今回は軽量だし worker number は 0 にする</span></span>
<span id="cb3-11"></span>
<span id="cb3-12"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'CIFAR10'</span>:</span>
<span id="cb3-13">    train_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CIFAR10(dataset_path, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transform, train<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, download<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb3-14">    test_dataset  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CIFAR10(dataset_path, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transform, train<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, download<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb3-15"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb3-16">    train_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MNIST(dataset_path, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transform, train<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, download<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb3-17">    test_dataset  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MNIST(dataset_path, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>transform, train<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, download<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb3-18"></span>
<span id="cb3-19">train_loader <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataLoader(dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_dataset, batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_batch_size, shuffle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs)</span>
<span id="cb3-20">test_loader  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataLoader(dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>test_dataset,  batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>inference_batch_size, shuffle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs)</span></code></pre></div>
</details>
</div>
</section>
<section id="モデル定義" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="モデル定義"><span class="header-section-number">2</span> モデル定義</h2>
<section id="タイムステップ-t-の位置埋め込み" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="タイムステップ-t-の位置埋め込み"><span class="header-section-number">2.1</span> タイムステップ <img src="https://latex.codecogs.com/png.latex?t"> の位置埋め込み</h3>
<p><span class="citation" data-cites="Ho+2020">(Ho et al., 2020)</span> ではトランスフォーマー <span class="citation" data-cites="Vaswani+2017">(Vaswani et al., 2017)</span> 同様の sinusoidal positional encoding を用いて <code>timestep_embedding_dim = 256</code> 次元の潜在表現を得て，タイムステップ <img src="https://latex.codecogs.com/png.latex?t"> の情報をデータに統合する．</p>
<p>そのタイムステップが統合されたデータが，同一に CNN に与えられ，その CNN のパラメータが学習される．</p>
<p>こうすることで <code>n_timesteps = 1000</code> の別々の NN を訓練するより遥かに効率的な学習が可能である．</p>
<div id="14db3abc" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> SinusoidalPosEmb(nn.Module):</span>
<span id="cb4-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, dim):</span>
<span id="cb4-3">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>().<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb4-4">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dim</span>
<span id="cb4-5"></span>
<span id="cb4-6">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x):</span>
<span id="cb4-7">        device <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.device</span>
<span id="cb4-8">        half_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb4-9">        emb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> math.log(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (half_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-10">        emb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(torch.arange(half_dim, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>device) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>emb)</span>
<span id="cb4-11">        emb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x[:, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> emb[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, :]</span>
<span id="cb4-12">        emb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat((emb.sin(), emb.cos()), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> emb</span></code></pre></div>
</div>
</section>
<section id="ニューラルネットワークの構成" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="ニューラルネットワークの構成"><span class="header-section-number">2.2</span> ニューラルネットワークの構成</h3>
<p><span class="citation" data-cites="Ho+2020">(Ho et al., 2020)</span> では U-Net <span class="citation" data-cites="Ronneberger+2015">(Ronneberger et al., 2015)</span> アーキテクチャを用いているが，ここでは同じ次元の CNN を <code>n_layers=8</code> 層重ねて作ることとする．</p>
<div id="83d3e3c7" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> ConvBlock(nn.Conv2d):</span>
<span id="cb5-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb5-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Conv2D Block</span></span>
<span id="cb5-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            Args:</span></span>
<span id="cb5-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                x: (N, C_in, H, W)</span></span>
<span id="cb5-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            Returns:</span></span>
<span id="cb5-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                y: (N, C_out, H, W)</span></span>
<span id="cb5-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb5-9"></span>
<span id="cb5-10">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, in_channels, out_channels, kernel_size, activation_fn<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, drop_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span>,</span>
<span id="cb5-11">                    stride<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'same'</span>, dilation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, groups<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, bias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, gn<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, gn_groups<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>):</span>
<span id="cb5-12">        </span>
<span id="cb5-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> padding <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'same'</span>:</span>
<span id="cb5-14">            padding <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kernel_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> dilation</span>
<span id="cb5-15"></span>
<span id="cb5-16">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(ConvBlock, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(in_channels, out_channels, kernel_size,</span>
<span id="cb5-17">                                            stride<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>stride, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>padding, dilation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dilation,</span>
<span id="cb5-18">                                            groups<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>groups, bias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>bias)</span>
<span id="cb5-19"></span>
<span id="cb5-20">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.activation_fn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.SiLU() <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> activation_fn <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb5-21">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.group_norm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.GroupNorm(gn_groups, out_channels) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> gn <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb5-22">        </span>
<span id="cb5-23">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x, time_embedding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, residual<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>):</span>
<span id="cb5-24">        </span>
<span id="cb5-25">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> residual:</span>
<span id="cb5-26">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># in the paper, diffusion timestep embedding was only applied to residual blocks of U-Net</span></span>
<span id="cb5-27">            x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> time_embedding</span>
<span id="cb5-28">            y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x</span>
<span id="cb5-29">            x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(ConvBlock, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).forward(x)</span>
<span id="cb5-30">            y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> x</span>
<span id="cb5-31">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb5-32">            y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(ConvBlock, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).forward(x)</span>
<span id="cb5-33">        y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.group_norm(y) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.group_norm <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> y</span>
<span id="cb5-34">        y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.activation_fn(y) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.activation_fn <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> y</span>
<span id="cb5-35">        </span>
<span id="cb5-36">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> y</span></code></pre></div>
</div>
</section>
<section id="デコーダーの定義" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="デコーダーの定義"><span class="header-section-number">2.3</span> デコーダーの定義</h3>
<div id="f49be930" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> Denoiser(nn.Module):</span>
<span id="cb6-2">    </span>
<span id="cb6-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, image_resolution, hidden_dims<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>], diffusion_time_embedding_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>, n_times<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>):</span>
<span id="cb6-4">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(Denoiser, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb6-5">        </span>
<span id="cb6-6">        _, _, img_C <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image_resolution</span>
<span id="cb6-7">        </span>
<span id="cb6-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.time_embedding <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SinusoidalPosEmb(diffusion_time_embedding_dim)</span>
<span id="cb6-9">        </span>
<span id="cb6-10">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.in_project <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ConvBlock(img_C, hidden_dims[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], kernel_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>)</span>
<span id="cb6-11">        </span>
<span id="cb6-12">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.time_project <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Sequential(ConvBlock(diffusion_time_embedding_dim, hidden_dims[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], kernel_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, activation_fn<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>),ConvBlock(hidden_dims[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], hidden_dims[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], kernel_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb6-13">        </span>
<span id="cb6-14">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.convs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.ModuleList([ConvBlock(in_channels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>hidden_dims[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], out_channels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>hidden_dims[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], kernel_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)])</span>
<span id="cb6-15">        </span>
<span id="cb6-16">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> idx <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(hidden_dims)):</span>
<span id="cb6-17">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.convs.append(ConvBlock(hidden_dims[idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], hidden_dims[idx], kernel_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, dilation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>((idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>),activation_fn<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, gn<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, gn_groups<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>))                                </span>
<span id="cb6-18"></span>
<span id="cb6-19">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.out_project <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ConvBlock(hidden_dims[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], out_channels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>img_C, kernel_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb6-20">        </span>
<span id="cb6-21">        </span>
<span id="cb6-22">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, perturbed_x, diffusion_timestep):</span>
<span id="cb6-23">        y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> perturbed_x</span>
<span id="cb6-24">        </span>
<span id="cb6-25">        diffusion_embedding <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.time_embedding(diffusion_timestep)</span>
<span id="cb6-26">        diffusion_embedding <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.time_project(diffusion_embedding.unsqueeze(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).unsqueeze(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))</span>
<span id="cb6-27">        </span>
<span id="cb6-28">        y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.in_project(y)</span>
<span id="cb6-29">        </span>
<span id="cb6-30">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.convs)):</span>
<span id="cb6-31">            y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.convs[i](y, diffusion_embedding, residual <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb6-32">            </span>
<span id="cb6-33">        y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.out_project(y)</span>
<span id="cb6-34">            </span>
<span id="cb6-35">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> y</span>
<span id="cb6-36">    </span>
<span id="cb6-37">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Denoiser(image_resolution<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>img_size,</span>
<span id="cb6-38">                 hidden_dims<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>hidden_dims, </span>
<span id="cb6-39">                 diffusion_time_embedding_dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>timestep_embedding_dim, </span>
<span id="cb6-40">                 n_times<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_timesteps).to(DEVICE)</span></code></pre></div>
</div>
</section>
<section id="エンコーダーの定義" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="エンコーダーの定義"><span class="header-section-number">2.4</span> エンコーダーの定義</h3>
<div id="ea3d3141" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> Diffusion(nn.Module):</span>
<span id="cb7-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, model, image_resolution<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>], n_times<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, beta_minmax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2e-2</span>], device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda'</span>):</span>
<span id="cb7-3">    </span>
<span id="cb7-4">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(Diffusion, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb7-5">    </span>
<span id="cb7-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.n_times <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n_times</span>
<span id="cb7-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.img_H, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.img_W, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.img_C <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image_resolution</span>
<span id="cb7-8"></span>
<span id="cb7-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model</span>
<span id="cb7-10">        </span>
<span id="cb7-11">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># define linear variance schedule(betas)</span></span>
<span id="cb7-12">        beta_1, beta_T <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> beta_minmax</span>
<span id="cb7-13">        betas <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.linspace(start<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>beta_1, end<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>beta_T, steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_times).to(device) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># follows DDPM paper</span></span>
<span id="cb7-14">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.sqrt_betas <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.sqrt(betas)</span>
<span id="cb7-15">                                     </span>
<span id="cb7-16">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># define alpha for forward diffusion kernel</span></span>
<span id="cb7-17">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.alphas <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> betas</span>
<span id="cb7-18">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.sqrt_alphas <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.sqrt(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.alphas)</span>
<span id="cb7-19">        alpha_bars <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cumprod(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.alphas, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb7-20">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.sqrt_one_minus_alpha_bars <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.sqrt(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>alpha_bars)</span>
<span id="cb7-21">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.sqrt_alpha_bars <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.sqrt(alpha_bars)</span>
<span id="cb7-22">        </span>
<span id="cb7-23">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.device <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> device</span>
<span id="cb7-24">    </span>
<span id="cb7-25">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> extract(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, a, t, x_shape):</span>
<span id="cb7-26">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb7-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            from lucidrains' implementation</span></span>
<span id="cb7-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                https://github.com/lucidrains/denoising-diffusion-pytorch/blob/beb2f2d8dd9b4f2bd5be4719f37082fe061ee450/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py#L376</span></span>
<span id="cb7-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb7-30">        b, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t.shape</span>
<span id="cb7-31">        out <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a.gather(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, t)</span>
<span id="cb7-32">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> out.reshape(b, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>((<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(x_shape) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)))</span>
<span id="cb7-33">    </span>
<span id="cb7-34">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> scale_to_minus_one_to_one(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x):</span>
<span id="cb7-35">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># according to the DDPMs paper, normalization seems to be crucial to train reverse process network</span></span>
<span id="cb7-36">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb7-37">    </span>
<span id="cb7-38">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> reverse_scale_to_zero_to_one(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x):</span>
<span id="cb7-39">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> (x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span></span>
<span id="cb7-40">    </span>
<span id="cb7-41">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> make_noisy(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x_zeros, t): </span>
<span id="cb7-42">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># perturb x_0 into x_t (i.e., take x_0 samples into forward diffusion kernels)</span></span>
<span id="cb7-43">        epsilon <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn_like(x_zeros).to(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.device)</span>
<span id="cb7-44">        </span>
<span id="cb7-45">        sqrt_alpha_bar <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.extract(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.sqrt_alpha_bars, t, x_zeros.shape)</span>
<span id="cb7-46">        sqrt_one_minus_alpha_bar <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.extract(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.sqrt_one_minus_alpha_bars, t, x_zeros.shape)</span>
<span id="cb7-47">        </span>
<span id="cb7-48">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Let's make noisy sample!: i.e., Forward process with fixed variance schedule</span></span>
<span id="cb7-49">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#      i.e., sqrt(alpha_bar_t) * x_zero + sqrt(1-alpha_bar_t) * epsilon</span></span>
<span id="cb7-50">        noisy_sample <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x_zeros <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> sqrt_alpha_bar <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> epsilon <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> sqrt_one_minus_alpha_bar</span>
<span id="cb7-51">    </span>
<span id="cb7-52">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> noisy_sample.detach(), epsilon</span>
<span id="cb7-53">    </span>
<span id="cb7-54">    </span>
<span id="cb7-55">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x_zeros):</span>
<span id="cb7-56">        x_zeros <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.scale_to_minus_one_to_one(x_zeros)</span>
<span id="cb7-57">        </span>
<span id="cb7-58">        B, _, _, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x_zeros.shape</span>
<span id="cb7-59">        </span>
<span id="cb7-60">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (1) randomly choose diffusion time-step</span></span>
<span id="cb7-61">        t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randint(low<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, high<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.n_times, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(B,)).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">long</span>().to(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.device)</span>
<span id="cb7-62">        </span>
<span id="cb7-63">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (2) forward diffusion process: perturb x_zeros with fixed variance schedule</span></span>
<span id="cb7-64">        perturbed_images, epsilon <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.make_noisy(x_zeros, t)</span>
<span id="cb7-65">        </span>
<span id="cb7-66">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (3) predict epsilon(noise) given perturbed data at diffusion-timestep t.</span></span>
<span id="cb7-67">        pred_epsilon <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model(perturbed_images, t)</span>
<span id="cb7-68">        </span>
<span id="cb7-69">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> perturbed_images, epsilon, pred_epsilon</span>
<span id="cb7-70">    </span>
<span id="cb7-71">    </span>
<span id="cb7-72">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> denoise_at_t(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x_t, timestep, t):</span>
<span id="cb7-73">        B, _, _, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x_t.shape</span>
<span id="cb7-74">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:</span>
<span id="cb7-75">            z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn_like(x_t).to(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.device)</span>
<span id="cb7-76">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb7-77">            z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros_like(x_t).to(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.device)</span>
<span id="cb7-78">        </span>
<span id="cb7-79">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># at inference, we use predicted noise(epsilon) to restore perturbed data sample.</span></span>
<span id="cb7-80">        epsilon_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model(x_t, timestep)</span>
<span id="cb7-81">        </span>
<span id="cb7-82">        alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.extract(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.alphas, timestep, x_t.shape)</span>
<span id="cb7-83">        sqrt_alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.extract(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.sqrt_alphas, timestep, x_t.shape)</span>
<span id="cb7-84">        sqrt_one_minus_alpha_bar <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.extract(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.sqrt_one_minus_alpha_bars, timestep, x_t.shape)</span>
<span id="cb7-85">        sqrt_beta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.extract(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.sqrt_betas, timestep, x_t.shape)</span>
<span id="cb7-86">        </span>
<span id="cb7-87">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># denoise at time t, utilizing predicted noise</span></span>
<span id="cb7-88">        x_t_minus_1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> sqrt_alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (x_t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>alpha)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>sqrt_one_minus_alpha_bar<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>epsilon_pred) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> sqrt_beta<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>z</span>
<span id="cb7-89">        </span>
<span id="cb7-90">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> x_t_minus_1.clamp(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb7-91">                </span>
<span id="cb7-92">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> sample(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, N):</span>
<span id="cb7-93">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># start from random noise vector, x_0 (for simplicity, x_T declared as x_t instead of x_T)</span></span>
<span id="cb7-94">        x_t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn((N, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.img_C, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.img_H, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.img_W)).to(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.device)</span>
<span id="cb7-95">        </span>
<span id="cb7-96">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># autoregressively denoise from x_T to x_0</span></span>
<span id="cb7-97">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#     i.e., generate image from noise, x_T</span></span>
<span id="cb7-98">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> t <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.n_times<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>):</span>
<span id="cb7-99">            timestep <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor([t]).repeat_interleave(N, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">long</span>().to(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.device)</span>
<span id="cb7-100">            x_t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.denoise_at_t(x_t, timestep, t)</span>
<span id="cb7-101">        </span>
<span id="cb7-102">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># denormalize x_0 into 0 ~ 1 ranged values.</span></span>
<span id="cb7-103">        x_0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.reverse_scale_to_zero_to_one(x_t)</span>
<span id="cb7-104">        </span>
<span id="cb7-105">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> x_0</span>
<span id="cb7-106">    </span>
<span id="cb7-107">    </span>
<span id="cb7-108">diffusion <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Diffusion(model, image_resolution<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>img_size, n_times<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_timesteps, </span>
<span id="cb7-109">                      beta_minmax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>beta_minmax, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>DEVICE).to(DEVICE)</span>
<span id="cb7-110"></span>
<span id="cb7-111">optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Adam(diffusion.parameters(), lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>lr)</span>
<span id="cb7-112">denoising_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.MSELoss()</span></code></pre></div>
</div>
</section>
<section id="エンコーディングの様子" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="エンコーディングの様子"><span class="header-section-number">2.5</span> エンコーディングの様子</h3>
<div id="c7cc5714" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> count_parameters(model):</span>
<span id="cb8-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(p.numel() <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> p <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> model.parameters() <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> p.requires_grad)</span>
<span id="cb8-3"></span>
<span id="cb8-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Number of model parameters: "</span>, count_parameters(diffusion))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of model parameters:  4870913</code></pre>
</div>
</div>
<div id="21f9f267" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="cb10-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> batch_idx, (x, _) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(test_loader):</span>
<span id="cb10-3">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.to(DEVICE)</span>
<span id="cb10-4">    perturbed_images, epsilon, pred_epsilon <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> diffusion(x)</span>
<span id="cb10-5">    perturbed_images <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> diffusion.reverse_scale_to_zero_to_one(perturbed_images)</span>
<span id="cb10-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">break</span></span>
<span id="cb10-7"></span>
<span id="cb10-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> show_image(x, idx):</span>
<span id="cb10-9">    fig <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.figure()</span>
<span id="cb10-10">    plt.imshow(x[idx].transpose(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).transpose(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).detach().cpu().numpy())</span></code></pre></div>
</div>
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">show_image(perturbed_images, idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb11-2">show_image(perturbed_images, idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb11-3">show_image(perturbed_images, idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span></code></pre></div>
<div id="fig-encoding" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-encoding-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-encoding" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-encoding-1" class="quarto-figure quarto-figure-center quarto-float anchored" width="341" height="337">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-encoding-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://162348.github.io/posts/2024/Samplers/DDPM_files/figure-html/fig-encoding-output-1.png" id="fig-encoding-1" data-ref-parent="fig-encoding" width="341" height="337" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-encoding-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a)
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-encoding" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-encoding-2" class="quarto-figure quarto-figure-center quarto-float anchored" width="341" height="337">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-encoding-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://162348.github.io/posts/2024/Samplers/DDPM_files/figure-html/fig-encoding-output-2.png" id="fig-encoding-2" data-ref-parent="fig-encoding" width="341" height="337" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-encoding-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b)
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-encoding" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-encoding-3" class="quarto-figure quarto-figure-center quarto-float anchored" width="341" height="337">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-encoding-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://162348.github.io/posts/2024/Samplers/DDPM_files/figure-html/fig-encoding-output-3.png" id="fig-encoding-3" data-ref-parent="fig-encoding" width="341" height="337" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-encoding-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c)
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-encoding-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
図&nbsp;1
</figcaption>
</figure>
</div>
</section>
</section>
<section id="モデル訓練" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="モデル訓練"><span class="header-section-number">3</span> モデル訓練</h2>
<div id="ae49a6e5" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Start training DDPMs..."</span>)</span>
<span id="cb12-2">model.train()</span>
<span id="cb12-3"></span>
<span id="cb12-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> time</span>
<span id="cb12-5"></span>
<span id="cb12-6">start_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time()</span>
<span id="cb12-7"></span>
<span id="cb12-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> epoch <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(epochs):</span>
<span id="cb12-9">    noise_prediction_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb12-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> batch_idx, (x, _) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> tqdm(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(train_loader), total<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train_loader)):</span>
<span id="cb12-11">        optimizer.zero_grad()</span>
<span id="cb12-12"></span>
<span id="cb12-13">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.to(DEVICE)</span>
<span id="cb12-14">        </span>
<span id="cb12-15">        noisy_input, epsilon, pred_epsilon <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> diffusion(x)</span>
<span id="cb12-16">        loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> denoising_loss(pred_epsilon, epsilon)</span>
<span id="cb12-17">        </span>
<span id="cb12-18">        noise_prediction_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> loss.item()</span>
<span id="cb12-19">        </span>
<span id="cb12-20">        loss.backward()</span>
<span id="cb12-21">        optimizer.step()</span>
<span id="cb12-22">        </span>
<span id="cb12-23">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\t</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Epoch"</span>, epoch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"complete!"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\t</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Denoising Loss: "</span>, noise_prediction_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> batch_idx)</span>
<span id="cb12-24">    </span>
<span id="cb12-25">total_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> start_time</span>
<span id="cb12-26"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Finish!! Total time: "</span>, total_time)</span></code></pre></div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled" title="注">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
注
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>この訓練コードも，前述の <code>train_loader</code> の定義が <code>if __name__ == '__main__':</code> と同じ <code>if</code> ブロックに入れる必要がある．</p>
<p>さもなくば，並列処理が実行できず，訓練には大変な時間がかかる．<sup>1</sup></p>
<p>そこでここでは別の Python ファイル (<a href="https://colab.research.google.com/drive/15IkmB8yijkfV7mRZieZkrD1oXDDHDrA5?usp=sharing">Google Colab</a>) で実行して，結果を読み込むこととする．</p>
<div id="06ec42b3" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="cb13-2"></span>
<span id="cb13-3">generated_images <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Files/generated_images1.pt"</span>, map_location<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.device(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>))</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/gx/6w78f6997l5___173r25fp3m0000gn/T/ipykernel_6810/3728020930.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  generated_images = torch.load("Files/generated_images1.pt", map_location=torch.device('cpu'))</code></pre>
</div>
</div>
<p>GPU に乗った状態で読み込まれることに注意．</p>
</div>
</div>
</div>
</section>
<section id="データ生成" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="データ生成"><span class="header-section-number">4</span> データ生成</h2>
<div id="2a1511b6" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="cb15-2"></span>
<span id="cb15-3"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb15-4">    generated_images <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> diffusion.sample(N<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>inference_batch_size)</span></code></pre></div>
</div>
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>):</span>
<span id="cb16-2">    show_image(generated_images, idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>i)</span></code></pre></div>
<div id="fig-generation1" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-generation1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-generation1" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-generation1-1" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-generation1-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://162348.github.io/posts/2024/Samplers/DDPM_files/figure-html/fig-generation1-output-1.png" data-ref-parent="fig-generation1" width="341" height="337" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-generation1-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) 生成された画像
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-generation1" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-generation1-2" class="quarto-figure quarto-figure-center quarto-float anchored" width="341" height="337">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-generation1-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://162348.github.io/posts/2024/Samplers/DDPM_files/figure-html/fig-generation1-output-2.png" id="fig-generation1-2" data-ref-parent="fig-generation1" width="341" height="337" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-generation1-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b)
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-generation1" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-generation1-3" class="quarto-figure quarto-figure-center quarto-float anchored" width="341" height="337">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-generation1-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://162348.github.io/posts/2024/Samplers/DDPM_files/figure-html/fig-generation1-output-3.png" id="fig-generation1-3" data-ref-parent="fig-generation1" width="341" height="337" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-generation1-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c)
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-generation1" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-generation1-4" class="quarto-figure quarto-figure-center quarto-float anchored" width="341" height="337">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-generation1-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://162348.github.io/posts/2024/Samplers/DDPM_files/figure-html/fig-generation1-output-4.png" id="fig-generation1-4" data-ref-parent="fig-generation1" width="341" height="337" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-generation1-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(d)
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-generation1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
図&nbsp;2
</figcaption>
</figure>
</div>
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>):</span>
<span id="cb17-2">    show_image(generated_images, idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>i)</span></code></pre></div>
<div id="fig-generation2" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-generation2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-generation2" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-generation2-1" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-generation2-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://162348.github.io/posts/2024/Samplers/DDPM_files/figure-html/fig-generation2-output-1.png" data-ref-parent="fig-generation2" width="341" height="337" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-generation2-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) 生成された画像
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-generation2" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-generation2-2" class="quarto-figure quarto-figure-center quarto-float anchored" width="341" height="337">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-generation2-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://162348.github.io/posts/2024/Samplers/DDPM_files/figure-html/fig-generation2-output-2.png" id="fig-generation2-2" data-ref-parent="fig-generation2" width="341" height="337" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-generation2-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b)
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-generation2" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-generation2-3" class="quarto-figure quarto-figure-center quarto-float anchored" width="341" height="337">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-generation2-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://162348.github.io/posts/2024/Samplers/DDPM_files/figure-html/fig-generation2-output-3.png" id="fig-generation2-3" data-ref-parent="fig-generation2" width="341" height="337" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-generation2-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c)
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-generation2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
図&nbsp;3
</figcaption>
</figure>
</div>
<div id="cell-fig-generation3" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">show_image(generated_images, idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-generation3" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-generation3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://162348.github.io/posts/2024/Samplers/DDPM_files/figure-html/fig-generation3-output-1.png" width="341" height="337" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-generation3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
図&nbsp;4: 生成された画像
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="モデル評価" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="モデル評価"><span class="header-section-number">5</span> モデル評価</h2>
<div id="b93bcb59" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> draw_sample_image(x, postfix):</span>
<span id="cb19-2">  </span>
<span id="cb19-3">    plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>))</span>
<span id="cb19-4">    plt.axis(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"off"</span>)</span>
<span id="cb19-5">    plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Visualization of </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(postfix))</span>
<span id="cb19-6">    plt.imshow(np.transpose(make_grid(x.detach().cpu(), padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, normalize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>), (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)))</span></code></pre></div>
</div>
<div id="d4c9c590" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">draw_sample_image(perturbed_images, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Perturbed Images"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/DDPM_files/figure-html/cell-19-output-1.png" width="611" height="631" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="86b75c78" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">draw_sample_image(generated_images, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Generated Images"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/DDPM_files/figure-html/cell-20-output-1.png" width="611" height="631" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="a763cff1" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">draw_sample_image(x[:inference_batch_size], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Ground-truth Images"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Samplers/DDPM_files/figure-html/cell-21-output-1.png" width="611" height="631" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>



<div id="quarto-appendix" class="default"><section id="参考" class="level2 appendix" data-number="6"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">6</span> 参考</h2><div class="quarto-appendix-contents">

<p>本稿は，<a href="https://velog.io/@mskang/about">Minsu Jackson Kang 氏</a> による <a href="https://github.com/Jackson-Kang/Pytorch-Diffusion-Model-Tutorial">チュートリアル</a> を参考にした．</p>



</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Ho+2020" class="csl-entry">
Ho, J., Jain, A., and Abbeel, P. (2020). <a href="https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html"><span>Denoising Diffusion Probabilistic Models</span></a>. In <em>Advances in neural information processing systems</em>,Vol. 33.
</div>
<div id="ref-Ronneberger+2015" class="csl-entry">
Ronneberger, O., Fischer, P., and Brox, T. (2015). <a href="https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28">U-net: Convolutional networks for biomedical image segmentation</a>. In N. Navab, J. Hornegger, W. M. Wells, and A. F. Frangi, editors, <em>Medical image computing and computer-assisted intervention – MICCAI 2015</em>, pages 234–241. Cham: Springer International Publishing.
</div>
<div id="ref-Vaswani+2017" class="csl-entry">
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., … Polosukhin, I. (2017). <a href="https://papers.nips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html">Attention is all you need</a>. In <em>Advances in neural information processing systems</em>,Vol. 30.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><code>kwargs = {'num_workers': 5, 'pin_memory': True, 'prefetch_factor': 2}</code> でも１エポック 12 分以上なので，40 時間以上はかかる．さらにこの場合エポック 18 で <code>RuntimeError: Shared memory manager connection has timed out</code> を得たため，<code>num_workers=0</code> とせざるを得なかった．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Deep</category>
  <category>Sampling</category>
  <category>Python</category>
  <guid>https://162348.github.io/posts/2024/Samplers/DDPM.html</guid>
  <pubDate>Thu, 01 Aug 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title>非線型な次元縮約法の概観</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Kernels/Manifold.html</link>
  <description><![CDATA[ 





<section id="関連ページ" class="level1 unnumbered unlisted">
<h1 class="unnumbered unlisted">関連ページ</h1>
<div id="listing-kernel-listing" class="quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Statistics,Kernel,Probability,Bayesian" data-listing-date-sort="1723388400000" data-listing-file-modified-sort="1723638288620" data-listing-date-modified-sort="1723561200000" data-listing-reading-time-sort="6" data-listing-word-count-sort="1067">
<a href="../../../posts/2024/Kernels/HierarchicalModel.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Kernels/Images/MM.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title" data-anchor-id="関連ページ">
階層モデル再論
</h5>
<div class="card-subtitle listing-subtitle">
多変量解析から機械学習へ
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-12
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Deep" data-listing-date-sort="1722178800000" data-listing-file-modified-sort="1723479691530" data-listing-date-modified-sort="1723388400000" data-listing-reading-time-sort="2" data-listing-word-count-sort="385">
<a href="../../../posts/2024/Kernels/NCL.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Kernels/Images/contrastive_repr4.jpeg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
表現学習と非線型独立成分分析
</h5>
<div class="card-subtitle listing-subtitle">
「データ理解」に向けた深層潜在変数モデル
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-07-29
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Kernel" data-listing-date-sort="1723215600000" data-listing-file-modified-sort="1727007847870" data-listing-date-modified-sort="1723302000000" data-listing-reading-time-sort="3" data-listing-word-count-sort="582">
<a href="../../../posts/2024/Kernels/Kernel.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Kernels/Images/Gibbs.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
カーネル法の概観
</h5>
<div class="card-subtitle listing-subtitle">
半正定値カーネルから距離学習まで
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-10
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
</section>
<section id="はじめに" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> はじめに</h1>
<p>多様体学習とは，非線型な次元削減手法のことをいう．</p>
<section id="多様体仮説" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="多様体仮説"><span class="header-section-number">1.1</span> 多様体仮説</h2>
<p>「多様体」の名前の由来は，「高次元データは低次元の部分多様体としての構造を持つ」という <strong>多様体仮説</strong> <span class="citation" data-cites="Fefferman+2016">(Fefferman et al., 2016)</span> である．<sup>1</sup></p>
<p>特に多様体学習と呼ばれる際は，知識発見やデータ可視化を重視する志向がある．</p>
<p>一方で自己符号化器などによる表現学習では，種々の下流タスクに有用な表現を得るための分布外汎化が重視される，と言えるだろう．</p>
</section>
<section id="距離学習との関係" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="距離学習との関係"><span class="header-section-number">1.2</span> 距離学習との関係</h2>
<p><a href="../../../posts/2024/Kernels/NCL.html#sec-NCL4RL">近年，対照学習による表現学習が注目されている</a>．このアプローチには，目的関数にサンプル間の類似度に関する事前情報を含めやすいという美点がある．</p>
<p>このような表現学習法は <strong>距離学習</strong> (metric learning) とも呼ばれている．</p>
<p>多くの多様体学習手法や，<img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5Ed"> への埋め込み手法は，なんらかの意味でサンプル間の類似度を保存する埋め込みを求めている <span class="citation" data-cites="Agrawal+2021">(Agrawal et al., 2021)</span>．</p>
<p>この意味で，「距離学習」というキーワードは，表現学習と多様体学習の交差点を意味していると言えるだろう．</p>
</section>
<section id="例細胞間の類似度" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="例細胞間の類似度"><span class="header-section-number">1.3</span> 例：細胞間の類似度</h2>
<p>現代のシークエンサー NGS (Next Generation Sequencer) では，単一の細胞が保持している mRNA の全体 scRNA-seq (single-cell RNA sequencing) を調べることができ，このような場合は極めて高次元のデータが大量に得られることになる．</p>
<p>例えば COVID-19 重症患者の末梢免疫の状態を調べるために末梢血単核細胞 PBMC<sup>2</sup> から scRNA-seq を行った例 <span class="citation" data-cites="Wilk+2020">(Wilk et al., 2020)</span> では，全部で <img src="https://latex.codecogs.com/png.latex?n=44,721"> の細胞のデータが，<img src="https://latex.codecogs.com/png.latex?p=26361"> 次元のスパースなベクトルを扱っている．<sup>3</sup></p>
</section>
</section>
<section id="多次元尺度法-mds" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> 多次元尺度法 (MDS)</h1>
<section id="概要" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="概要"><span class="header-section-number">2.1</span> 概要</h2>
<p>多次元尺度法 (MDS: Multi-Dimensional Scaling) <span class="citation" data-cites="Torgenson1952">(Torgerson, 1952)</span>, <span class="citation" data-cites="Kruskal1964">(Kruskal, 1964)</span> は，元のデータの「（非）類似度」を保存したままの低次元表現を探索する手法群である．</p>
<p>後続の手法はいずれも高次元データ <img src="https://latex.codecogs.com/png.latex?%5C%7By_i%5C%7D_%7Bi=1%7D%5En%5Csubset%5Cmathbb%7BR%7D%5Ep"> を所与とするが，MDS は本質的には類似度行列 <img src="https://latex.codecogs.com/png.latex?D%5Cin%20M_n(%5Cmathbb%7BR%7D)"> が与えられていればよく，解析対象は必ずしも <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5Ep">-値のデータである必要はない．</p>
<p>類似度行列 <img src="https://latex.codecogs.com/png.latex?D"> が与えられたのちは，埋め込み <img src="https://latex.codecogs.com/png.latex?%5C%7Bz_i%5C%7D_%7Bi=1%7D%5En%5Csubset%5Cmathbb%7BR%7D%5Ed"> の要素間の類似度が <img src="https://latex.codecogs.com/png.latex?D"> に近くなるように埋め込みを学習する．</p>
</section>
<section id="pca-としての-mds" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="pca-としての-mds"><span class="header-section-number">2.2</span> PCA としての MDS</h2>
<p>特にデータ <img src="https://latex.codecogs.com/png.latex?%5C%7Bx_i%5C%7D_%7Bi=1%7D%5En%5Csubset%5Cmathbb%7BR%7D%5Ep"> 間の Euclid 距離を <img src="https://latex.codecogs.com/png.latex?D"> とし，埋め込み <img src="https://latex.codecogs.com/png.latex?%5C%7Bz_i%5C%7D_%7Bi=1%7D%5En%5Csubset%5Cmathbb%7BR%7D%5Ed"> の間の経験共分散が <img src="https://latex.codecogs.com/png.latex?D"> に Hilbert-Schmidt ノルムに関して最小化することを <span class="citation" data-cites="Torgenson1952">(Torgerson, 1952)</span> は考えた．</p>
<p>これは <a href="../../../posts/2024/FunctionalAnalysis/SVD.html"><span class="citation" data-cites="Eckart-Young1936">(<span>Eckart and Young, 1936</span>)</span> の定理</a> を通じて <a href="../../../posts/2024/Kernels/HierarchicalModel.html#sec-PCA">PCA</a> に一致する，線型な次元縮約法となる．</p>
<p><span class="citation" data-cites="Torgenson1952">(Torgerson, 1952)</span> のアプローチは <strong>計量</strong>多次元尺度法と呼ばれ，一般のデータに適用可能な <span class="citation" data-cites="Kruskal1964">(Kruskal, 1964)</span> のアプローチは<strong>非計量</strong>多次元尺度法と対照される．<sup>4</sup></p>
</section>
<section id="kruskal1964-stress" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="kruskal1964-stress"><span class="header-section-number">2.3</span> <span class="citation" data-cites="Kruskal1964">(Kruskal, 1964)</span> Stress</h2>
<p>前述の通り，<img src="https://latex.codecogs.com/png.latex?D"> は Euclid 距離に基づくとは限らないし，そもそもデータはベクトルなど構造化されているものでなくても良い．</p>
<p>このような一般的な場面で <img src="https://latex.codecogs.com/png.latex?%5C%7Bz_i%5C%7D_%7Bi=1%7D%5En%5Csubset%5Cmathbb%7BR%7D%5Ed"> 間の類似度の <img src="https://latex.codecogs.com/png.latex?D"> との「近さ」を図る尺度として，Kruskal の Stress-1 <span class="citation" data-cites="Kruskal1964">(Kruskal, 1964)</span> がよく用いられる： <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D(E):=%5Csqrt%7B%5Cfrac%7B%5Csum_%7Bi_1%3Ci_2%7D%5Cleft(z_%7Bi_1i_2%7D-d_%7Bi_1i_2%7D%5Cright)%5E2%7D%7B%5Csum_%7Bi_1%3Ci_2%7Dd_%7Bi_1i_2%7D%5E2%7D%7D.%0A"></p>
<p>勾配法を用いた最適化ベースの推論手法が使えるが，この目的関数に関しては SMACOF (Scaling by Majorizing a Complementary Function) <span class="citation" data-cites="deLeeuw1977">(de Leeuw, 1977)</span> という凸最適化アルゴリズムが提案されており，<a href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.smacof.html"><code>scikit-learn</code> にも実装されている</a>．</p>
</section>
<section id="sammon1969-stress" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="sammon1969-stress"><span class="header-section-number">2.4</span> <span class="citation" data-cites="Sammon1969">(Sammon, 1969)</span> Stress</h2>
<p><span class="citation" data-cites="Sammon1969">(Sammon, 1969)</span> は探索的データ解析の文脈から，データの「構造」をよく保つために，<img src="https://latex.codecogs.com/png.latex?z_%7Bi_1i_2%7D"> の値が小さい場合は小さな変化も重視してくれるようにスケーリングを調整する新たなストレス関数を提案した：</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B1%7D%7B%5Csum_%7Bi_1%3Ci_2%7Dz_%7Bi_1i_2%7D%7D%5Csum_%7Bi_1%3Ci_2%7D%5Cfrac%7B%5Cleft(z_%7Bi_1i_2%7D-d_%7Bi_1i_2%7D%5Cright)%5E2%7D%7Bz_%7Bi_1i_2%7D%7D.%0A"></p>
<p>係数 <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B1%7D%7B%5Csum_%7Bi_1%3Ci_2%7Dz_%7Bi_1i_2%7D%7D"> の存在は，勾配法による推論を効率的にする．</p>
</section>
<section id="sec-MDU" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="sec-MDU"><span class="header-section-number">2.5</span> 多次元展開法 (MDU)</h2>
<p>多次元展開法 (MDU: Multi-Dimensional Unfolding) は，個人の選考順位データに対処するために <span class="citation" data-cites="Coombs1950">(Coombs, 1950)</span> が提唱した，多次元尺度法 (MDS) の拡張である <span class="citation" data-cites="足立浩平2000">(足立浩平, 2000)</span>．</p>
<p>MDU ではさらに一般的な行列 <img src="https://latex.codecogs.com/png.latex?D"> を取ることができる．というのも，MDS では暗黙のうちに行と列は同一物であり，<img src="https://latex.codecogs.com/png.latex?D"> の対角成分は全て一定であるが，MDU では行と列で別の対象を取ることができる．</p>
<p>例えば，個体 <img src="https://latex.codecogs.com/png.latex?i"> が項目 <img src="https://latex.codecogs.com/png.latex?j"> をどれくらい好むか？を <img src="https://latex.codecogs.com/png.latex?D"> と取り，行と列を同一の平面上に <a href="https://en.wikipedia.org/wiki/Biplot">バイプロット</a> <span class="citation" data-cites="Gabriel1971">(Gabriel, 1971)</span>, <span class="citation" data-cites="Gower2004">(Gower, 2004)</span> する．</p>
</section>
<section id="理想点推定" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="理想点推定"><span class="header-section-number">2.6</span> <a href="../../../posts/2024/TransDimensionalModels/IdealPoint.html">理想点推定</a></h2>
<p>特に政治科学の分野で用いられる多次元展開手法であり，<img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5Ed%5C;(d%5Cle3)"> に埋め込むことが考えられる．</p>
<p>その際は <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5Ed"> 上への観測に至るまでの階層モデル（潜在変数モデル）を立てて，全体を MCMC により推定する方法が，<span class="citation" data-cites="Martin-Quinn2002">(Martin and Quinn, 2002)</span> 以来中心的である．</p>
<p><span class="citation" data-cites="Imai2016">(Imai et al., 2016)</span>，<span class="citation" data-cites="三輪洋文2017">(三輪洋文, 2017)</span> は変分 EM アルゴリズムにより推定している．</p>
</section>
<section id="力指向グラフ展開-fdl-se" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="力指向グラフ展開-fdl-se"><span class="header-section-number">2.7</span> 力指向グラフ展開 (FDL / SE)</h2>
<p><a href="https://ja.wikipedia.org/wiki/力学モデル_(グラフ描画アルゴリズム)">力学モデルによるグラフ描画法</a> (Force-directed layout / Spring Embedder) <span class="citation" data-cites="Tutte1963">(Tutte, 1963)</span>, <span class="citation" data-cites="Eades1984">(Eades, 1984)</span>, <span class="citation" data-cites="Kamada-Kawai1989">(Kamada and Kawai, 1989)</span> は，グラフの頂点を質点，辺をバネに見立てて，グラフを <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E2"> 上に展開する方法である．</p>
<p>超大規模集積回路 (VLSI) の設計問題と両輪で発展してきた <span class="citation" data-cites="Fisk+1967">(Fisk et al., 1967)</span>, <span class="citation" data-cites="Quinn-Breuer1979">(Quinn and Breuer, 1979)</span>．</p>
<p>このグラフ埋め込み法はポテンシャルエネルギーをストレスと見立てた MDS とみなせる．</p>
</section>
</section>
<section id="sec-Isomap" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Isomap</h1>
<p>MDS 法の難点の１つに，データがある部分多様体上に存在する場合，その部分多様体上の測地距離を尊重できないという点がある．</p>
<p>このデータの部分多様体構造を尊重した測地距離をグラフにより捉え，MDS を実行する手法が Isomap <span class="citation" data-cites="Tenenbaum+2000">(Tenenbaum et al., 2000)</span> である．</p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="Isomap：データの多様体構造を尊重した MDS">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Isomap：データの多様体構造を尊重した MDS
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>データを頂点とした <img src="https://latex.codecogs.com/png.latex?K">-近傍グラフを構成する．</li>
<li>測地距離を，このグラフ上の最短距離として近似する．</li>
<li>こうして得た近似測地距離を用いて MDS を行う．</li>
</ol>
</div>
</div>
<p>ステップ２においては Dijkstra 法を用いることができ，高速な計算が可能である．</p>
<p>しかし Isomap はデータの摂動に極めて弱いことが topological instability として知られている <span class="citation" data-cites="Balasubramanian-Schwartz2002">(Balasubramanian and Schwartz, 2002)</span>．</p>
<p>この安定性をカーネル法に外注する Robust Kernel Isomap <span class="citation" data-cites="Choi-Choi2007">(Choi and Choi, 2007)</span> も提案されている．</p>
</section>
<section id="最大分散展開-mvu" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> 最大分散展開 (MVU)</h1>
<section id="カーネル-pca-kpca-scholkopf1998" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="カーネル-pca-kpca-scholkopf1998"><span class="header-section-number">4.1</span> <a href="../../../posts/2023/KernelMethods/KernelMethods4Mathematicians.html#sec-KPCA">カーネル PCA</a> (kPCA) <span class="citation" data-cites="Scholkopf+1998">(Schölkopf et al., 1998)</span></h2>
<p>カーネル法の見地からは，従来の PCA は線型な核を用いた場合のカーネル主成分分析だったと相対化される．</p>
<p>しかし，少なくとも RBF カーネルを用いた場合は <span class="citation" data-cites="Weinberger+2004">(Weinberger et al., 2004)</span>，次元縮約の代わりにより高次元な空間に埋め込みがちである．</p>
</section>
<section id="半正定値埋め込み" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="半正定値埋め込み"><span class="header-section-number">4.2</span> 半正定値埋め込み</h2>
<p>カーネル PCA を次元縮約のために用いたものが <strong>半正定値埋め込み</strong> (semidefinite embedding) または <strong>最大分散展開</strong> (MVU: Maximum Vairance Unfolding) <span class="citation" data-cites="Weinberger+2004">(Weinberger et al., 2004)</span> である．</p>
<p>これは，カーネル PCA による埋め込みの中でも，元データ <img src="https://latex.codecogs.com/png.latex?y"> と埋め込み <img src="https://latex.codecogs.com/png.latex?z"> の間で <img src="https://latex.codecogs.com/png.latex?%0A%5C%7Cz_i-z_j%5C%7C_2=%5C%7Cy_i-y_j%5C%7C_2,%5Cqquad(i,j)%5Cin%20G%0A"> を <img src="https://latex.codecogs.com/png.latex?K">-近傍 <img src="https://latex.codecogs.com/png.latex?G"> に関して満たすような埋め込みの中で， <img src="https://latex.codecogs.com/png.latex?%0A%5Cmax_%7Bz%5Cin%5Cmathbb%7BR%7D%5Ed%7D%5Csum_%7Bi,j%7D%5C%7Cz_i-z_j%5C%7C_2%5E2%0A"> を最大にするものを求めることを考える．</p>
<p>幸い，これを満たすカーネル関数は半正定値計画によって解くことができ，このカーネル関数によるカーネル PCA 法が MVU である．</p>
</section>
</section>
<section id="局所線型埋め込み-lle" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> 局所線型埋め込み (LLE)</h1>
<section id="はじめに-1" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="はじめに-1"><span class="header-section-number">5.1</span> はじめに</h2>
<p>ここまでの手法は畢竟，類似度行列 <img src="https://latex.codecogs.com/png.latex?Y"> に関して，kPCA は特徴空間上でのスペクトル分解，Isomap はデータのなす <img src="https://latex.codecogs.com/png.latex?K">-近傍グラフ上でのスペクトル分解を考えている．</p>
<p>これに対して，スパースなスペクトル分解を用いることで，データの局所的構造がさらに尊重できることが，<strong>局所線型埋め込み</strong> (LLE: Local Linear Embedding) <span class="citation" data-cites="Roweis-Saul2000">(Roweis and Saul, 2000)</span> として提案された．</p>
<p>この方法は Isomap よりデータの摂動に関して頑健であることが知られている．</p>
</section>
<section id="アルゴリズム" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="アルゴリズム"><span class="header-section-number">5.2</span> アルゴリズム</h2>
<p>この方法では，データ多様体の接空間に注目する．</p>
<p>まず，各点をその <img src="https://latex.codecogs.com/png.latex?K">-近傍点の線型結合で表す方法を，次のように学習する： <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BW%7D=%5Cmin_%7BW%7D%5Csum_%7Bi=1%7D%5En%5Cleft(x_i-%5Csum_%7Bj=1%7D%5Enw_%7Bij%7Dx_j%5Cright)%5E2,%5Cqquad%5Coperatorname%7Bsubject%20to%7D%5Cbegin%7Bcases%7Dw_%7Bij%7D=0&amp;x_i,x_j%5C,%5Ctext%7B%E3%81%AF%7D%5C,K%5Ctext%7B-%E8%BF%91%E5%82%8D%E3%81%A7%E3%81%AA%E3%81%84%7D%5C%5C%5Csum_%7Bj=1%7D%5ENw_%7Bij%7D=1&amp;%5Ctext%7B%E4%BB%BB%E6%84%8F%E3%81%AE%7D%5C,i%5Cin%5BN%5D%5C,%5Ctext%7B%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%7D%5Cend%7Bcases%7D%0A"> こうして得た <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7BW%7D"> はスパース行列になる．この <img src="https://latex.codecogs.com/png.latex?W"> を通じて，局所構造を保った低次元埋め込みを構成する： <img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7BZ%7D=%5Coperatorname*%7Bargmin%7D_Z%5Csum_%7Bi=1%7D%5En%5Cleft%5C%7Cz_i-%5Csum_%7Bj=1%7D%5En%5Cwidehat%7Bw%7D_%7Bij%7Dz_j%5Cright%5C%7C_2%5E2.%0A"></p>
<p>この最適化問題は，<img src="https://latex.codecogs.com/png.latex?I_n-W"> の <a href="../../../posts/2024/FunctionalAnalysis/SVD.html">特異値分解</a> に帰着する．</p>
</section>
<section id="hessian-埋め込み-he" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="hessian-埋め込み-he"><span class="header-section-number">5.3</span> Hessian 埋め込み (HE)</h2>
<p>Hessian Eigenmaps <span class="citation" data-cites="Donoho-Grimes2003">(Donoho and Grimes, 2003)</span> は微分幾何学的見方を推し進め，Hessian からの情報を取り入れた局所線型埋め込みの変種である．</p>
</section>
<section id="接空間配置-tsa" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="接空間配置-tsa"><span class="header-section-number">5.4</span> 接空間配置 (TSA)</h2>
<p>Tangent Space Alignment <span class="citation" data-cites="Zhang-Zha2004">(Zhang and Zha, 2004)</span> はより明示的に接空間の構造に注目する．</p>
</section>
</section>
<section id="sec-LE" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> スペクトル埋め込み (SE / LE)</h1>
<p>Laplacian Eigenmaps または Spectral Embedding <span class="citation" data-cites="Mikhali-Partha2001">(Belkin and Niyogi, 2001)</span> は，データ点の <img src="https://latex.codecogs.com/png.latex?K">-近傍グラフ <img src="https://latex.codecogs.com/png.latex?(Y,E)"> 上で <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D(Z):=%5Csum_%7B(i,j)%5Cin%20E%7DW_%7Bij%7D%5C%7Cz_i-z_j%5C%7C_2%5E2,%5Cqquad%20W_%7Bij%7D:=%5Cexp%5Cleft(-%5Cfrac%7B%5C%7Cy_i-y_j%5C%7C_2%5E2%7D%7B2%5Csigma%5E2%7D%5Cright)%0A"> を最小化する埋め込み <img src="https://latex.codecogs.com/png.latex?Z"> を求める方法である．</p>
<p>この目的関数 <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D(Z)"> は実は，<img src="https://latex.codecogs.com/png.latex?K">-近傍グラフ <img src="https://latex.codecogs.com/png.latex?(Y,E)"> の Laplacian 行列 <img src="https://latex.codecogs.com/png.latex?L"> に関して <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D(Z)=2%5Coperatorname%7BTr%7D(Z%5E%5Ctop%20LZ)%0A"> とも表せる．</p>
<p>この量は，<img src="https://latex.codecogs.com/png.latex?Z"> をグラフ上の関数と見た際の Dirichlet 汎函数になっており，グラフ上の関数としての「滑らかさ」の尺度となっている．</p>
<p>最も滑らかであるような <img src="https://latex.codecogs.com/png.latex?Z"> を学習することで，データの局所構造を最も反映した埋め込みが得られる，というアイデアである．</p>
</section>
<section id="t-分布型確率的近傍埋め込み-t-sne" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> <img src="https://latex.codecogs.com/png.latex?t">-分布型確率的近傍埋め込み (t-SNE)</h1>
<section id="概要-1" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="概要-1"><span class="header-section-number">7.1</span> 概要</h2>
<p>SNE <span class="citation" data-cites="Hinton-Roweis2002">(Hinton and Roweis, 2002)</span> では，<img src="https://latex.codecogs.com/png.latex?K">-近傍グラフを用いた Isomap を，ハードな帰属からソフトな帰属へ，確率分布を用いて軟化する．</p>
<p>t-SNE <span class="citation" data-cites="Maaten-Hinton2008">(van der Maaten and Hinton, 2008)</span> では SNE が Gauss 核を用いていたところを Laplace 核（<img src="https://latex.codecogs.com/png.latex?t">-分布）を用いることで，より分散した表現を得ることを目指す．</p>
</section>
<section id="sec-SNE" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="sec-SNE"><span class="header-section-number">7.2</span> 確率的近傍埋め込み <span class="citation" data-cites="Hinton-Roweis2002">(SNE, Hinton and Roweis, 2002)</span></h2>
<p>ハイパーパラメータ <img src="https://latex.codecogs.com/png.latex?%5Csigma_i"> を残して， <img src="https://latex.codecogs.com/png.latex?%0Ap_%7Bj%7Ci%7D:=%5Cfrac%7B%5Cexp%5Cleft(-%5Cfrac%7B%5Clvert%20x_i-x_j%5Crvert%5E2%7D%7B2%5Csigma_i%5E2%7D%5Cright)%7D%7B%5Csum_%7Bk%5Cneq%20i%7D%5Cexp%5Cleft(-%5Cfrac%7B%5Clvert%20x_i-x_k%5Crvert%5E2%7D%7B2%5Csigma_i%5E2%7D%5Cright)%7D%0A"> と定める．</p>
<p>この <img src="https://latex.codecogs.com/png.latex?(p_%7Bj%7Ci%7D)"> と，潜在空間における帰属確率 <img src="https://latex.codecogs.com/png.latex?%0Aq_%7Bj%7Ci%7D:=%5Cfrac%7Be%5E%7B-%5Clvert%20z_i-z_j%5Crvert%5E2%7D%7D%7B%5Csum_%7Bk%5Cneq%20i%7De%5E%7B-%5Clvert%20z_i-z_k%5Crvert%5E2%7D%7D%0A"> と一致するように埋め込みを学習する．すなわち，訓練目標は <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D:=%5Csum_%7Bi=1%7D%5En%5Coperatorname%7BKL%7D(p_%7B-%7Ci%7D,q_%7B-%7Ci%7D)=%5Csum_%7Bi,j=1%7D%5Enp_%7Bj%7Ci%7D%5Clog%5Cfrac%7Bp_%7Bj%7Ci%7D%7D%7Bq_%7Bj%7Ci%7D%7D%0A"> と定める．</p>
<p>この目的関数は凸ではなく，SGD で訓練可能であるが特殊なノイズスケジュールなどのテクニックがある．<sup>5</sup></p>
<p>SNE は，ある事前分布を課したスペクトル埋め込みとも見れる <span class="citation" data-cites="Carreira-Perpinan2010">(Carreira-Perpiñan, 2010)</span>．</p>
</section>
<section id="目的関数の対称化" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="目的関数の対称化"><span class="header-section-number">7.3</span> 目的関数の対称化</h2>
<p><img src="https://latex.codecogs.com/png.latex?p_%7Bi%7Cj%7D,q_%7Bi%7Cj%7D"> ではなく，結合分布 <img src="https://latex.codecogs.com/png.latex?p_%7Bij%7D,q_%7Bij%7D"> を用いることで，目的関数を対称化することができる．</p>
<p>このとき，目的関数の勾配は次のようになる： <img src="https://latex.codecogs.com/png.latex?%0A%5Cnabla_%7Bz_i%7D%5Cmathcal%7BL%7D(Z)=2%5Csum_%7Bj=1%7D%5En(z_j-z_i)(p_%7Bij%7D-q_%7Bij%7D).%0A"></p>
</section>
<section id="t-分布の導入" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="t-分布の導入"><span class="header-section-number">7.4</span> <img src="https://latex.codecogs.com/png.latex?t">-分布の導入</h2>
<p>t-SNE <span class="citation" data-cites="Maaten-Hinton2008">(van der Maaten and Hinton, 2008)</span> は <img src="https://latex.codecogs.com/png.latex?p_%7Bj%7Ci%7D"> の定義に Gauss 核を用いていたところを，Cauchy 分布の密度（Poisson 核）に置き換えたものである： <img src="https://latex.codecogs.com/png.latex?%0Aq_%7Bij%7D=%5Cfrac%7B%5Cfrac%7B1%7D%7B1+%5Clvert%20z_i-z_j%5Crvert%5E2%7D%7D%7B%5Csum_%7Bk%3Cl%7D%5Cfrac%7B1%7D%7B1+%5Clvert%20z_k-z_l%5Crvert%5E2%7D%7D.%0A"></p>
<p>このことにより，元々遠かったデータ点を引き寄せ過ぎてしまうこと (crowding problem) を回避できる．</p>
<p>勾配は <img src="https://latex.codecogs.com/png.latex?%0A%5Cnabla_%7Bz_i%7D%5Cmathcal%7BL%7D(Z)=4%5Csum_%7Bj=1%7D%5En(z_j-z_i)(p_%7Bij%7D-q_%7Bij%7D)%5Cfrac%7B1%7D%7B1+%5Clvert%20z_i-z_j%5Crvert%5E2%7D%0A"> で与えられ，対称化された SNE に，<img src="https://latex.codecogs.com/png.latex?z_i,z_j"> の距離に従って調整する因子が追加された形になっている．</p>
</section>
<section id="実装" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="実装"><span class="header-section-number">7.5</span> 実装</h2>
<p>t-SNE は <img src="https://latex.codecogs.com/png.latex?O(n%5E2)"> であるが，埋め込みの次元数が <img src="https://latex.codecogs.com/png.latex?d=2"> などの低次元であるとき，これを <img src="https://latex.codecogs.com/png.latex?O(n%5Clog%20n)"> にまで加速する実装が知られている <span class="citation" data-cites="vanderMaaten2014">(Maaten, 2014)</span>．</p>
</section>
<section id="敏捷な埋め込み-ee" class="level2" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="敏捷な埋め込み-ee"><span class="header-section-number">7.6</span> 敏捷な埋め込み (EE)</h2>
<p>t-SNE はハイパーパラメータ <img src="https://latex.codecogs.com/png.latex?%5Csigma_i%5E2"> の設定に敏感である上に訓練が局所解にトラップされるなど不安定で，またデータ内のノイズに弱いことが知られている <span class="citation" data-cites="Wattemnerg+2016">(Wattenberg et al., 2016)</span>．</p>
<p><strong>敏捷な埋め込み</strong> (EN: Elastic Net) <span class="citation" data-cites="Carreira-Perpinan2010">(Carreira-Perpiñan, 2010)</span> という，より安定的でノイズに頑健な手法が目的関数を修正することで得られている．</p>
</section>
<section id="largevis" class="level2" data-number="7.7">
<h2 data-number="7.7" class="anchored" data-anchor-id="largevis"><span class="header-section-number">7.7</span> LargeVis</h2>
<p>LargeVis <span class="citation" data-cites="Tang+2016">(Tang et al., 2016)</span> は t-SNE の計算量を軽減させるために，<img src="https://latex.codecogs.com/png.latex?K">-近傍グラフの計算に近似手法である <strong>ランダム射影木</strong> <span class="citation" data-cites="DasGupta-Freud2008">(Dasgupta and Freund, 2008)</span> を導入する．</p>
</section>
<section id="umap" class="level2" data-number="7.8">
<h2 data-number="7.8" class="anchored" data-anchor-id="umap"><span class="header-section-number">7.8</span> UMAP</h2>
<p>UMAP (Uniform Manifold Approximation and Projection) <span class="citation" data-cites="McInnes+2018">(McInnes et al., 2018)</span> は t-SNE より高速で，大域的構造をより尊重する手法として提案された．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://pair-code.github.io/understanding-umap/"><img src="https://162348.github.io/posts/2024/Kernels/Images/UMAPvSNE.png" class="img-fluid figure-img" alt="UMAP and t-SNE applied to the Fashion MNIST dataset; tap to visit https://pair-code.github.io/understanding-umap/"></a></p>
<figcaption>UMAP and t-SNE applied to the Fashion MNIST dataset; tap to visit https://pair-code.github.io/understanding-umap/</figcaption>
</figure>
</div>
</section>
<section id="モデルベース手法" class="level2" data-number="7.9">
<h2 data-number="7.9" class="anchored" data-anchor-id="モデルベース手法"><span class="header-section-number">7.9</span> モデルベース手法</h2>
<p>t-SNE, VargeVis, UMAP はいずれも確率を導入しているが，完全にモデルベースの発想をしているわけではない．</p>
<p><span class="citation" data-cites="Saul2020">(Saul, 2020)</span> はこれらの手法を <a href="../../../posts/2024/Kernels/HierarchicalModel.html">潜在変数モデル</a> として定式化し，データサイズに合わせて EM アルゴリズムをはじめとした推定手法を議論している．</p>
</section>
</section>
<section id="拡散写像" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> 拡散写像</h1>
<section id="はじめに-2" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="はじめに-2"><span class="header-section-number">8.1</span> はじめに</h2>
<p><strong>拡散埋め込み</strong> (Diffusion Map) <span class="citation" data-cites="Coifman+2005">(Coifman et al., 2005)</span> では，データ上に乱歩を定めることでデータ多様体の局所構造を捉える．</p>
<p>この方法は Isomap 3 でグラフを用いて測地距離を近似したよりも，頑健なアルゴリズムを与える．</p>
</section>
<section id="phate" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="phate"><span class="header-section-number">8.2</span> PHATE</h2>
<p>PHATE (Heat Diffusion for Affinity-based Transition Embedding) <span class="citation" data-cites="Moon+2019">(Moon et al., 2019)</span> は DEMaP (Denoised Embedding Manifold Preservation) という情報理論に基づく距離を定義し，データの局所構造を捉える．</p>
</section>
</section>
<section id="自己組織化写像-som" class="level1" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> 自己組織化写像 (SOM)</h1>
<p>Self-organizing Map <span class="citation" data-cites="Kohonen1982">(Kohonen, 1982)</span>, <span class="citation" data-cites="Kohonen2013">(Kohonen, 2013)</span> は，ニューラルネットワークのダイナミクスを利用した，クラスタリングベースの次元縮約法である．</p>
<section id="ivis" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="ivis"><span class="header-section-number">9.1</span> IVIS</h2>
<p>IVIS <span class="citation" data-cites="Szubert+2019">(Szubert et al., 2019)</span> は <a href="../../../posts/2024/Kernels/Kernel.html#sec-triplet-loss">三つ子損失を取り入れたシャムネットワーク</a> による距離学習に基づく次元縮約法である．</p>
</section>
</section>
<section id="mapper" class="level1" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> Mapper</h1>
<p>Mapper <span class="citation" data-cites="Singh+2007">(Singh et al., 2007)</span> は，距離空間 <img src="https://latex.codecogs.com/png.latex?E"> 上のデータ <img src="https://latex.codecogs.com/png.latex?%5C%7Bx_i%5C%7D%5Csubset%20E"> を，関数 <img src="https://latex.codecogs.com/png.latex?f:E%5Cto%5Cmathbb%7BR%7D"> が定める分解を用いてグラフとして図示する方法である．<img src="https://latex.codecogs.com/png.latex?f"> は <strong>filter function</strong> と呼ばれる．</p>
<p>他手法とは違い，出力が <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5Ed"> への埋め込みではなく，グラフである点に注意．</p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="Mapper アルゴリズム^[このアルゴリズムは Morse 理論における概念である Reeb グラフの拡張と見れる．[@Oudot2016] のスライドや [@Schnider2024] の講義資料も参照．]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Mapper アルゴリズム<sup>6</sup>
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>値の空間 <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D"> 上の開被覆 <img src="https://latex.codecogs.com/png.latex?(I_i)"> の引き戻し <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BU%7D:=(f%5E%7B-1%7D(I_i))"> として誘導されるグラフを，連結成分のみからなるように細分して <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BV%7D=(U_i)_%7Bi%5Cin%20I%7D"> を得る．</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BV%7D"> の <a href="https://en.wikipedia.org/wiki/Nerve_complex">神経複体</a> <img src="https://latex.codecogs.com/png.latex?%0AN(%5Cmathcal%7BV%7D):=%5Cleft%5C%7BJ%5Coverset%7B%5Ctext%7Bfinite%7D%7D%7B%5Csubset%7DI%5C,%5Cmiddle%7C%5C,%5Cbigcap_%7Bj%5Cin%20J%7DU_j%5Cne%5Cemptyset%5Cright%5C%7D%0A"> またはその近傍グラフを出力とする．</li>
</ol>
</div>
</div>
<p><span class="citation" data-cites="Emerson+2023">(Escolar et al., 2023)</span> では特許のデータを用い，各企業を技術空間 <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E%7B430%7D"> 内に埋め込んだ後，mapper によりグラフ化したところ，企業の独自戦略が可視化できるという：</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/0LQpJiecCvw?si=I-6R3dn8EAAG8xs1" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Mapper アルゴリズムは filter function <img src="https://latex.codecogs.com/png.latex?f"> の選択が重要になるが，これにハイパーパラメータを導入し <span class="citation" data-cites="Oulhaj+2024">(Oulhaj, Carrière, et al., 2024)</span>，さらにニューラルネットワークで推定する方法 Deep Mapper <span class="citation" data-cites="Oulhaj+2024DeepMapper">(Oulhaj, Ishii, et al., 2024)</span> が，分子モデリングと創薬に応用されている．</p>
</section>




<div id="quarto-appendix" class="default"><section id="終わりに" class="level1 appendix" data-number="11"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">11</span> 終わりに</h2><div class="quarto-appendix-contents">

<p>結局機械学習が日々の統計的営みに与えた最大のインパクトは，ニューラルネットワークや生成モデル自体というより，高精度な非線型表現学習であると言えるかもしれない．</p>
<p>例えば <span class="citation" data-cites="Hoffmann+2019">(Hoffman et al., 2019)</span> は <a href="../../../posts/2024/Samplers/NF.html#sec-NF-Bayes">IAF</a> <span class="citation" data-cites="Kingma+2016">(Kingma et al., 2016)</span> を用いて目標分布を学習し，学習された密度 <img src="https://latex.codecogs.com/png.latex?q"> で変換後の分布から MCMC サンプリングをすることで効率がはるかに改善することを報告した．実際，フローによる変換を受けた後は対象分布は正規分布に近くなることから，MCMC サンプリングを減速させる要因の多くが消滅していることが期待される．</p>
<p>多くの他の統計的な困難も，良い表現学習された空間上（あるいはカーネル空間上）で実行することで回避することができるということになるかもしれない．これが最初に SVM が機械学習に与えた希望の形であったし，ニューラルネットワークに対する飽くなき理論的興味の源泉でもある．データの視覚化や探索的データ解析の意味では，よき潜在表現を必要としているのは人間も然りである．</p>
</div></section><section id="文献" class="level1 appendix" data-number="12"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">12</span> 文献</h2><div class="quarto-appendix-contents">

<p><span class="citation" data-cites="Yao2011">(Yao, 2011)</span> は LLE, Laplacian Eigenmaps, カーネル PCA, Diffusion Maps の関連性を扱っている講義スライドである．</p>
<p><span class="citation" data-cites="Wattemnerg+2016">(Wattenberg et al., 2016)</span> はインタラクティブに t-SNE の性質を理解できるウェブページである．<a href="https://pair-code.github.io/understanding-umap/">Understanding UMAP</a> も同様にして，UMAP と t-SNE の比較を与えている．</p>
<p><span class="citation" data-cites="Murphy2022">(Murphy, 2022)</span> 第20章は次元縮約という題で，PCA, FA から自己符号化器，多様体学習を解説している．<span class="citation" data-cites="Burges2010">(Burges, 2010)</span> が同じテーマのしばらく前のサーベイである．</p>
<p>多様体学習に関しては <span class="citation" data-cites="本武陽一2017">(本武陽一, 2017)</span> も注目．</p>
<p>PCA は Kosambi-Karhunen-Loéve 変換ともいう <span class="citation" data-cites="Bishop-Bishop2024">(Bishop and Bishop, 2024, p. 497)</span>．PCA からとにかくスペクトルとの関連が深い．</p>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Agrawal+2021" class="csl-entry">
Agrawal, A., Ali, A., and Boyd, S. (2021). <a href="https://doi.org/10.1561/2200000090">Minimum-distortion embedding</a>. <em>Foundations and Trends<span></span> in Machine Learning</em>, <em>14</em>(3), 211–378.
</div>
<div id="ref-Balasubramanian-Schwartz2002" class="csl-entry">
Balasubramanian, M., and Schwartz, E. L. (2002). <a href="https://doi.org/10.1126/science.295.5552.7a">The isomap algorithm and topological stability</a>. <em>Science</em>, <em>295</em>(5552), 7–7.
</div>
<div id="ref-Mikhali-Partha2001" class="csl-entry">
Belkin, M., and Niyogi, P. (2001). <a href="https://proceedings.neurips.cc/paper_files/paper/2001/file/f106b7f99d2cb30c3db1c3cc0fde9ccb-Paper.pdf">Laplacian eigenmaps and spectral techniques for embedding and clustering</a>. In T. Dietterich, S. Becker, and Z. Ghahramani, editors, <em>Advances in neural information processing systems</em>,Vol. 14. MIT Press.
</div>
<div id="ref-Bishop-Bishop2024" class="csl-entry">
Bishop, C. M., and Bishop, H. (2024). <em><a href="https://link.springer.com/book/10.1007/978-3-031-45468-4">Deep learning: Foundations and concepts</a></em>. Springer Cham.
</div>
<div id="ref-Burges2010" class="csl-entry">
Burges, C. J. C. (2010). <a href="https://doi.org/10.1561/2200000002">Dimension reduction: A guided tour</a>. <em>Foundations and Trends<span></span> in Machine Learning</em>, <em>2</em>(4), 275–365.
</div>
<div id="ref-Carreira-Perpinan2010" class="csl-entry">
Carreira-Perpiñan, M. Á. (2010). The elastic embedding algorithm for dimensionality reduction. In <em>Proceedings of the 27th international conference on international conference on machine learning</em>, pages 167–174. Madison, WI, USA: Omnipress.
</div>
<div id="ref-Choi-Choi2007" class="csl-entry">
Choi, H., and Choi, S. (2007). <a href="https://doi.org/10.1016/j.patcog.2006.04.025">Robust kernel isomap</a>. <em>Pattern Recognition</em>, <em>40</em>(3), 853–862.
</div>
<div id="ref-Coifman+2005" class="csl-entry">
Coifman, R. R., Lafon, S., Lee, A. B., Maggioni, M., Nadler, B., Warner, F., and Zucker, S. W. (2005). <a href="https://doi.org/10.1073/pnas.0500334102">Geometric diffusions as a tool for harmonic analysis and structure definition of data: Diffusion maps</a>. <em>Proceedings of the National Academy of Sciences</em>, <em>102</em>(21), 7426–7431.
</div>
<div id="ref-Coombs1950" class="csl-entry">
Coombs, C. H. (1950). <a href="https://psycnet.apa.org/doi/10.1037/h0060984"><span class="nocase">Psychological Scaling without a Unit of Measurement</span></a>. <em>Psychological Review</em>, <em>57</em>(3), 145–158.
</div>
<div id="ref-DasGupta-Freud2008" class="csl-entry">
Dasgupta, S., and Freund, Y. (2008). <a href="https://doi.org/10.1145/1374376.1374452">Random projection trees and low dimensional manifolds</a>. In <em>Proceedings of the fortieth annual ACM symposium on theory of computing</em>, pages 537–546. New York, NY, USA: Association for Computing Machinery.
</div>
<div id="ref-deLeeuw1977" class="csl-entry">
de Leeuw, J. (1977). <em>Applications of convex analysis to multidimensional scaling</em>. UCLA: Department of Statistics. Retrieved from <a href="https://escholarship.org/uc/item/7wg0k7xq">https://escholarship.org/uc/item/7wg0k7xq</a>
</div>
<div id="ref-Donoho-Grimes2003" class="csl-entry">
Donoho, D. L., and Grimes, C. (2003). <a href="https://doi.org/10.1073/pnas.1031596100">Hessian eigenmaps: Locally linear embedding techniques for high-dimensional data</a>. <em>Proceedings of the National Academy of Sciences</em>, <em>100</em>(10), 5591–5596.
</div>
<div id="ref-Eades1984" class="csl-entry">
Eades, P. (1984). <a href="https://www.cs.ubc.ca/~will/536E/papers/Eades1984.pdf"><span class="nocase">A Heuristic for Graph Drawing</span></a>. <em>Congress Numerantium</em>, <em>42</em>(11), 149–160.
</div>
<div id="ref-Eckart-Young1936" class="csl-entry">
Eckart, C., and Young, G. (1936). <a href="https://doi.org/10.1007/BF02288367">The approximation of one matrix by another of lower rank</a>. <em>Psychometrika</em>, <em>1</em>(3), 211–218.
</div>
<div id="ref-Emerson+2023" class="csl-entry">
Escolar, E. G., Hiraoka, Y., Igami, M., and Ozcan, Y. (2023). <a href="https://doi.org/10.1016/j.respol.2023.104821">Mapping firms’ locations in technological space: A topological analysis of patent statistics</a>. <em>Research Policy</em>, <em>52</em>(8), 104821.
</div>
<div id="ref-Fefferman+2016" class="csl-entry">
Fefferman, C., Mitter, S., and Narayanan, H. (2016). <a href="https://doi.org/10.1090/jams/852">Testing the manifold hypothesis</a>. <em>Journal of the American Mathematical Society</em>, <em>29</em>, 983–1049.
</div>
<div id="ref-Fisk+1967" class="csl-entry">
Fisk, C. J., Caskey, D. L., and West, L. E. (1967). <a href="https://doi.org/10.1109/PROC.1967.6027">ACCEL: Automated circuit card etching layout</a>. <em>Proceedings of the IEEE</em>, <em>55</em>(11), 1971–1982.
</div>
<div id="ref-Gabriel1971" class="csl-entry">
Gabriel, K. R. (1971). <a href="http://www.jstor.org/stable/2334381">The biplot graphic display of matrices with application to principal component analysis</a>. <em>Biometrika</em>, <em>58</em>(3), 453–467.
</div>
<div id="ref-Gower2004" class="csl-entry">
Gower, J. C. (2004). <a href="http://www.jstor.org/stable/20441132">The geometry of biplot scaling</a>. <em>Biometrika</em>, <em>91</em>(3), 705–714.
</div>
<div id="ref-Hinton-Roweis2002" class="csl-entry">
Hinton, G. E., and Roweis, S. (2002). <a href="https://proceedings.neurips.cc/paper_files/paper/2002/file/6150ccc6069bea6b5716254057a194ef-Paper.pdf">Stochastic neighbor embedding</a>. In S. Becker, S. Thrun, and K. Obermayer, editors, <em>Advances in neural information processing systems</em>,Vol. 15. MIT Press.
</div>
<div id="ref-Hoffmann+2019" class="csl-entry">
Hoffman, M., Sountsov, P., Dillon, J. V., Langmore, I., Tran, D., and Vasudevan, S. (2019). <a href="https://arxiv.org/abs/1903.03704">NeuTra-lizing bad geometry in hamiltonian monte carlo using neural transport</a>. In <em>Symposium on advances in approximate bayesian inference</em>.
</div>
<div id="ref-Imai2016" class="csl-entry">
Imai, K., Lo, J., and Olmsted, J. (2016). <a href=""><span class="nocase">Fast Estimation of Ideal Points with Massive Data</span></a>. <em>American Political Science Review</em>, <em>110</em>(4), 631–656.
</div>
<div id="ref-Kamada-Kawai1989" class="csl-entry">
Kamada, T., and Kawai, S. (1989). <a href="https://doi.org/10.1016/0020-0190(89)90102-6">An algorithm for drawing general undirected graphs</a>. <em>Information Processing Letters</em>, <em>31</em>(1), 7–15.
</div>
<div id="ref-Kingma+2016" class="csl-entry">
Kingma, D., Salimans, T., Jozefowicz, R., Chen, X., Sutskever, I., and Welling, M. (2016). <a href="https://proceedings.neurips.cc/paper_files/paper/2016/file/ddeebdeefdb7e7e7a697e1c3e3d8ef54-Paper.pdf">Improved variational inference with inverse autoregressive flow</a>. In D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett, editors, <em>Advances in neural information processing systems</em>,Vol. 29. Curran Associates, Inc.
</div>
<div id="ref-Kohonen1982" class="csl-entry">
Kohonen, T. (1982). <a href="https://doi.org/10.1007/BF00337288">Self-organized formation of topologically correct feature maps</a>. <em>Biological Cybernetics</em>, <em>43</em>(1), 59–69.
</div>
<div id="ref-Kohonen2013" class="csl-entry">
Kohonen, T. (2013). <a href="https://doi.org/10.1016/j.neunet.2012.09.018">Essentials of the self-organizing map</a>. <em>Neural Networks</em>, <em>37</em>, 52–65.
</div>
<div id="ref-Kruskal1964" class="csl-entry">
Kruskal, J. B. (1964). <a href="https://doi.org/10.1007/BF02289565">Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis</a>. <em>Psychometrika</em>, <em>29</em>(1), 1–27.
</div>
<div id="ref-vanderMaaten2014" class="csl-entry">
Maaten, L. van der. (2014). <a href="http://jmlr.org/papers/v15/vandermaaten14a.html">Accelerating t-SNE using tree-based algorithms</a>. <em>Journal of Machine Learning Research</em>, <em>15</em>(93), 3221–3245.
</div>
<div id="ref-Martin-Quinn2002" class="csl-entry">
Martin, A. D., and Quinn, K. M. (2002). <a href="http://www.jstor.org/stable/25791672">Dynamic ideal point estimation via markov chain monte carlo for the u.s. Supreme court, 1953–1999</a>. <em>Political Analysis</em>, <em>10</em>(2), 134–153.
</div>
<div id="ref-McInnes+2018" class="csl-entry">
McInnes, L., Healy, J., Saul, N., and Großberger, L. (2018). <a href="https://doi.org/10.21105/joss.00861">UMAP: Uniform manifold approximation and projection</a>. <em>Journal of Open Source Software</em>, <em>3</em>(29), 861.
</div>
<div id="ref-Moon+2019" class="csl-entry">
Moon, K. R., Dijk, D. van, Wang, Z., Gigante, S., Burkhardt, D. B., Chen, W. S., … Krishnaswamy, S. (2019). <a href="https://doi.org/10.1038/s41587-019-0336-3">Visualizing structure and transitions in high-dimensional biological data</a>. <em>Nature Biotechnology</em>, <em>37</em>(12), 1482–1492.
</div>
<div id="ref-Murphy2022" class="csl-entry">
Murphy, K. P. (2022). <em><a href="https://probml.github.io/pml-book/book1.html">Probabilistic machine learning: An introduction</a></em>. MIT Press.
</div>
<div id="ref-Oudot2016" class="csl-entry">
Oudot, S. (2016). <em><a href="https://geometrica.saclay.inria.fr/team/Steve.Oudot/courses/EMA/Slides_Reeb_Mapper.pdf">Reeb graph and mapper</a></em>.
</div>
<div id="ref-Oulhaj+2024" class="csl-entry">
Oulhaj, Z., Carrière, M., and Michel, B. (2024). <a href="https://arxiv.org/abs/2402.12854">Differentiable mapper for topological optimization of data representation</a>.
</div>
<div id="ref-Oulhaj+2024DeepMapper" class="csl-entry">
Oulhaj, Z., Ishii, Y., Ohga, K., Yamazaki, K., Wada, M., Umeda, Y., … Kurihara, H. (2024). <a href="https://arxiv.org/abs/2402.19177">Deep mapper graph and its application to visualize plausible pathways on high-dimensional distribution with small time-complexity</a>.
</div>
<div id="ref-Quinn-Breuer1979" class="csl-entry">
Quinn, N., and Breuer, M. (1979). <a href="https://doi.org/10.1109/TCS.1979.1084652">A forced directed component placement procedure for printed circuit boards</a>. <em>IEEE Transactions on Circuits and Systems</em>, <em>26</em>(6), 377–388.
</div>
<div id="ref-Roweis-Saul2000" class="csl-entry">
Roweis, S. T., and Saul, L. K. (2000). <a href="https://doi.org/10.1126/science.290.5500.2323">Nonlinear dimensionality reduction by locally linear embedding</a>. <em>Science</em>, <em>290</em>(5500), 2323–2326.
</div>
<div id="ref-Sammon1969" class="csl-entry">
Sammon, J. W. (1969). <a href="https://doi.org/10.1109/T-C.1969.222678">A nonlinear mapping for data structure analysis</a>. <em>IEEE Transactions on Computers</em>, <em>C-18</em>(5), 401–409.
</div>
<div id="ref-Saul2020" class="csl-entry">
Saul, L. K. (2020). <a href="https://doi.org/10.1073/pnas.1916012117">A tractable latent variable model for nonlinear dimensionality reduction</a>. <em>Proceedings of the National Academy of Sciences</em>, <em>117</em>(27), 15403–15408.
</div>
<div id="ref-Schnider2024" class="csl-entry">
Schnider, P. (2024). <em><a href="https://ti.inf.ethz.ch/ew/courses/TDA24/index.html">Introduction to topological data analysi</a></em>.
</div>
<div id="ref-Scholkopf+1998" class="csl-entry">
Schölkopf, B., Smola, A., and Müller, K.-R. (1998). <a href="https://doi.org/10.1162/089976698300017467">Nonlinear component analysis as a kernel eigenvalue problem</a>. <em>Neural Computation</em>, <em>10</em>(5), 1299–1319.
</div>
<div id="ref-Singh+2007" class="csl-entry">
Singh, G., Memoli, F., and Carlsson, G. (2007). <a href="https://doi.org//10.2312/SPBG/SPBG07/091-100
"><span class="nocase">Topological Methods for the Analysis of High Dimensional Data Sets and 3D Object Recognition </span></a>. In M. Botsch, R. Pajarola, B. Chen, and M. Zwicker, editors, <em>Eurographics symposium on point-based graphics</em>. The Eurographics Association.
</div>
<div id="ref-Szubert+2019" class="csl-entry">
Szubert, B., Cole, J. E., Monaco, C., and Drozdov, I. (2019). <a href="https://doi.org/10.1038/s41598-019-45301-0">Structure-preserving visualisation of high dimensional single-cell datasets</a>. <em>Scientific Reports</em>, <em>9</em>(1), 8914.
</div>
<div id="ref-Tang+2016" class="csl-entry">
Tang, J., Liu, J., Zhang, M., and Mei, Q. (2016). <a href="https://doi.org/10.1145/2872427.2883041">Visualizing large-scale and high-dimensional data</a>. In <em>Proceedings of the 25th international conference on world wide web</em>, pages 287–297. Republic; Canton of Geneva, CHE: International World Wide Web Conferences Steering Committee.
</div>
<div id="ref-Tenenbaum+2000" class="csl-entry">
Tenenbaum, J. B., Silva, V. de, and Langford, J. C. (2000). <a href="https://doi.org/10.1126/science.290.5500.2319"><span class="nocase">A Global Geometric Framework for Nonlinear Dimensionality Reduction</span></a>. <em>Science</em>, <em>290</em>(5500), 2319–2323.
</div>
<div id="ref-Torgenson1952" class="csl-entry">
Torgerson, W. S. (1952). <a href="https://doi.org/10.1007/BF02288916">Multidimensional scaling: I. Theory and method</a>. <em>Psychometrika</em>, <em>17</em>(4), 401–419.
</div>
<div id="ref-Tutte1963" class="csl-entry">
Tutte, W. T. (1963). <a href="https://doi.org/10.1112/plms/s3-13.1.743"><span class="nocase">How to Draw a Graph</span></a>. <em>Proceedings of the London Mathematical Society</em>, <em>s3-13</em>(1), 743–767.
</div>
<div id="ref-Maaten-Hinton2008" class="csl-entry">
van der Maaten, L., and Hinton, G. (2008). <a href="http://jmlr.org/papers/v9/vandermaaten08a.html">Visualizing data using t-SNE</a>. <em>Journal of Machine Learning Research</em>, <em>9</em>(86), 2579–2605.
</div>
<div id="ref-Wattemnerg+2016" class="csl-entry">
Wattenberg, M., Viégas, F., and Johnson, I. (2016). <a href="https://doi.org/10.23915/distill.00002">How to use t-SNE effectively</a>. <em>Distill</em>.
</div>
<div id="ref-Weinberger+2004" class="csl-entry">
Weinberger, K. Q., Sha, F., and Saul, L. K. (2004). <a href="https://doi.org/10.1145/1015330.1015345">Learning a kernel matrix for nonlinear dimensionality reduction</a>. In <em>Proceedings of the twenty-first international conference on machine learning</em>, page 106. New York, NY, USA: Association for Computing Machinery.
</div>
<div id="ref-Wilk+2020" class="csl-entry">
Wilk, A. J., Rustagi, A., Zhao, N. Q., Roque, J., Martı́nez-Colón, G. J., McKechnie, J. L., … Blish, C. A. (2020). <a href="https://doi.org/10.1038/s41591-020-0944-y">A single-cell atlas of the peripheral immune response in patients with severe COVID-19</a>. <em>Nature Medicine</em>, <em>26</em>(7), 1070–1076.
</div>
<div id="ref-Wu-Fischer2020" class="csl-entry">
Wu, T., and Fischer, I. (2020). <a href="https://openreview.net/forum?id=HJloElBYvB">Phase transitions for the information bottleneck in representation learning</a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Yao2011" class="csl-entry">
Yao, Y. (2011). <em><a href="https://www.math.pku.edu.cn/teachers/yaoy/Spring2011/">Mathematics of data – laplacian, diffusion, and hessian LLE</a></em>.
</div>
<div id="ref-Young-Hausholder1938" class="csl-entry">
Young, G., and Householder, A. S. (1938). <a href="https://doi.org/10.1007/BF02287916">Discussion of a set of points in terms of their mutual distances</a>. <em>Psychometrika</em>, <em>3</em>(1), 19–22.
</div>
<div id="ref-Zhang-Zha2004" class="csl-entry">
Zhang, Z., and Zha, H. (2004). <a href="https://doi.org/10.1137/S1064827502419154">Principal manifolds and nonlinear dimensionality reduction via tangent space alignment</a>. <em>SIAM Journal on Scientific Computing</em>, <em>26</em>(1), 313–338.
</div>
<div id="ref-三輪洋文2017" class="csl-entry">
三輪洋文. (2017). <a href="https://doi.org/10.14854/jaes.33.1_41">Twitter データによる日本の政治家・言論人・政党・メディアのイデオロギー位置の推定</a>. <em>選挙研究</em>, <em>33</em>(1), 41–56.
</div>
<div id="ref-岡田謙介-加藤淳子2016" class="csl-entry">
岡田謙介, and 加藤淳子. (2016). <a href="https://doi.org/10.2333/jbhmk.43.155">政治学における空間分析と認知空間</a>. <em>行動計量学</em>, <em>43</em>(2), 155–166.
</div>
<div id="ref-本武陽一2017" class="csl-entry">
本武陽一. (2017). <em>高次元データセットに潜む幾何構造と深層学習 : その解析と大自由度力学系への応用</em> (PhD thesis). 東京大学. Retrieved from <a href="https://repository.dl.itc.u-tokyo.ac.jp/records/48134">https://repository.dl.itc.u-tokyo.ac.jp/records/48134</a>
</div>
<div id="ref-足立浩平2000" class="csl-entry">
足立浩平. (2000). <a href="https://doi.org/10.2333/jbhmk.27.12">計量多次元展開法の変量モデル</a>. <em>行動計量学</em>, <em>27</em>(1), 12–23.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><span class="citation" data-cites="本武陽一2017">(本武陽一, 2017)</span> も注目．↩︎</p></li>
<li id="fn2"><p>(Peripheral Blood Mononuclear Cell)↩︎</p></li>
<li id="fn3"><p>なお，<span class="citation" data-cites="Wilk+2020">(Wilk et al., 2020)</span> では最初の 50 の主成分がプロットされている．↩︎</p></li>
<li id="fn4"><p><span class="citation" data-cites="岡田謙介-加藤淳子2016">(岡田謙介 and 加藤淳子, 2016)</span> 参照．大変入門に良い日本語文献である．計量的多次元尺度法は <strong>主座標分析</strong> (PCoA: Principal Coordinate Analysis) <span class="citation" data-cites="Young-Hausholder1938">(Young and Householder, 1938)</span> とも呼ばれる．↩︎</p></li>
<li id="fn5"><p>どうやら相転移境界が近いため，アニーリングが必要？<span class="citation" data-cites="Wu-Fischer2020">(Wu and Fischer, 2020)</span>．<span class="citation" data-cites="Murphy2022">(Murphy, 2022, p. 700)</span> 20.4.10.1節も参照．↩︎</p></li>
<li id="fn6"><p>このアルゴリズムは Morse 理論における概念である Reeb グラフの拡張と見れる．<span class="citation" data-cites="Oudot2016">(Oudot, 2016)</span> のスライドや <span class="citation" data-cites="Schnider2024">(Schnider, 2024)</span> の講義資料も参照．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Deep</category>
  <category>Nature</category>
  <category>Statistics</category>
  <category>Geometry</category>
  <guid>https://162348.github.io/posts/2024/Kernels/Manifold.html</guid>
  <pubDate>Mon, 29 Jul 2024 15:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Kernels/Images/UMAPvSNE.png" medium="image" type="image/png" height="93" width="144"/>
</item>
<item>
  <title>表現学習と非線型独立成分分析</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Kernels/NCL.html</link>
  <description><![CDATA[ 





<section id="関連ページ" class="level2 unnumbered unlisted">
<h2 class="unnumbered unlisted anchored" data-anchor-id="関連ページ">関連ページ</h2>
<div id="listing-kernel-listing" class="quarto-listing quarto-listing-container-grid">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Kernel" data-listing-date-sort="1723215600000" data-listing-file-modified-sort="1727007847870" data-listing-date-modified-sort="1723302000000" data-listing-reading-time-sort="3" data-listing-word-count-sort="582">
<a href="../../../posts/2024/Kernels/Kernel.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Kernels/Images/Gibbs.svg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
カーネル法の概観
</h5>
<div class="card-subtitle listing-subtitle">
半正定値カーネルから距離学習まで
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-08-10
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Deep,Nature,Statistics,Geometry" data-listing-date-sort="1722265200000" data-listing-file-modified-sort="1727007847871" data-listing-date-modified-sort="1723647600000" data-listing-reading-time-sort="3" data-listing-word-count-sort="597">
<a href="../../../posts/2024/Kernels/Manifold.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Kernels/Images/UMAPvSNE.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
非線型な次元縮約法の概観
</h5>
<div class="card-subtitle listing-subtitle">
最古にして最難のタスクと多様体学習
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-07-30
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Deep,Nature,Sampling" data-listing-date-sort="1711724400000" data-listing-file-modified-sort="1727007848003" data-listing-date-modified-sort="1722438000000" data-listing-reading-time-sort="5" data-listing-word-count-sort="880">
<a href="../../../posts/2024/Samplers/EBM.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://162348.github.io/posts/2024/Samplers/Files/NCL/thumb_checkerboard.gif" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
エネルギーベースモデル
</h5>
<div class="card-subtitle listing-subtitle">
深層生成モデル５
</div>
<div class="card-attribution card-text-small end">
<div class="listing-date">
2024-03-30
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
</section>
<section id="表現学習とは何か" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="表現学習とは何か"><span class="header-section-number">1</span> 表現学習とは何か？</h2>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="表現学習５つのアプローチ">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
表現学習５つのアプローチ
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>教師あり学習による表現学習</li>
<li>生成による表現学習</li>
<li>自己教師あり表現学習</li>
<li>ノイズ対照による表現学習</li>
<li>独立成分分析による表現学習</li>
</ol>
</div>
</div>
<p>極めて高精度な分類器が完成してすぐのころ，分類タスクが極めて上手なニューラルネットワークは他の下流タスクでも良い成績が観察され，最初に考えられた方法が１であった（<a href="../../../posts/2024/Kernels/Kernel.html#sec-distance-learning">距離学習</a>でも同様）．</p>
<p>一方でこのスキームではすぐにドメインシフトと転移学習が問題になった．</p>
<p>これを克服するのが２の方法である．高精度なデータを生成できる深層潜在模型が学習された場合，その潜在変数は現実の何らかの表象になっているだろう，というアイデアは analysis-by-synthesis <span class="citation" data-cites="Roberts1963">(Roberts, 1963)</span>, <span class="citation" data-cites="Lee-Mumford2003">(Lee and Mumford, 2003)</span> とも呼ばれている．</p>
<p>この方法は，文字のストローク（トメ，ハネ）が集まった構造に注目するなど，データの生成過程がある程度明らかなものでは特に性能が良い <span class="citation" data-cites="Lake+2015">(Lake et al., 2015)</span>．</p>
<p><a href="../../../posts/2024/Kernels/Deep4.html#sec-beta-VAE"><img src="https://latex.codecogs.com/png.latex?%5Cbeta">-VAE</a> <span class="citation" data-cites="Higgins+2017">(Higgins et al., 2017)</span> や BiGAN <span class="citation" data-cites="Donahue+2017">(Donahue et al., 2017)</span> はその例であるが，ImageNet などの大規模データに対する分類や分割のタスクで十分な性能はまだ見られていないという．</p>
</section>
<section id="生成から雑音除去へ" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="生成から雑音除去へ"><span class="header-section-number">2</span> 生成から雑音除去へ</h2>
<p>２よりも表現学習として良い性質を持つのが３である．</p>
<p>生成のためには大変多くの特徴量が必要であるが，下流タスクに重要なのはその一部のみに限る．このような場合，<a href="../../../posts/2024/Kernels/Deep4.html#sec-denoising-autoencoder">Denoising Autoencoder</a> <span class="citation" data-cites="Vincent+2008">(Vincent et al., 2008)</span> のように「データにノイズを印加してこれを戻すのに必要な知識は何か？」を問うことが極めて普遍的な力を持つ．</p>
<p>雑音除去と同様に，表現学習に極めて有効なタスクがマスク除去 <span class="citation" data-cites="Devlin+2019">(Devlin et al., 2019)</span> である．これは画像領域にも応用されている：BEiT <span class="citation" data-cites="Bao+2022">(Bao et al., 2022)</span>．<strong>masked autoencoder</strong> <span class="citation" data-cites="He+2022">(He et al., 2022)</span> が現在の state of the art であるようである．</p>
</section>
<section id="sec-NCL4RL" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="sec-NCL4RL"><span class="header-section-number">3</span> 対照学習による表現学習</h2>
<p>ノイズ対照学習に基づいた方法が第４勢力として登場（再興）してきている．multiview representation learning とも呼ばれる．</p>
<section id="sec-NCL" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="sec-NCL"><span class="header-section-number">3.1</span> ノイズ対照学習 (NCL)</h3>
<p>この方法では，雑音やマスク除去とは違った方法で，「真のデータをノイズと見分ける」という予測問題として表現学習を解く．<sup>1</sup></p>
<p>この方法は最初自然言語処理で大きな成功を収めた <span class="citation" data-cites="Mnih-Kavukcuoglu2013">(Mnih and Kavukcuoglu, 2013)</span>．例えば word2vec <span class="citation" data-cites="Mikolov2013">(Mikolov, Chen, et al., 2013)</span>, <span class="citation" data-cites="Mikolov2013b">(Mikolov, Sutskever, et al., 2013)</span> も NCL に基づく．</p>
<p>一方で前述の通り，BART や GPT などの現代の言語モデルは，ノイズ対照の先へ行き，デノイジングやデマスキングによる表現学習を行っている．</p>
<p>しかし NCL には，雑音・マスク除去と違い，ある程度どのようなデータを「似ている」とするかの制御が効くという美点がある．これを <a href="../../../posts/2024/Kernels/Kernel.html#sec-distance-learning"><strong>距離学習</strong></a> ともいう．<sup>2</sup></p>
<p>発展した対照学習法，例えば CPC (Contrastive Predictive Coding) <span class="citation" data-cites="Oord+2019">(Oord et al., 2019)</span> は，言語，音声，画像，３次元空間での強化学習など，多くの領域で有力な代替を提供するようである．</p>
<p>また CLIP <span class="citation" data-cites="Radford+2019">(Radford et al., 2019)</span> では，データのモーダリティを超えて，言語と画像の関係について大規模に事前学習をさせることが可能になっている．</p>
</section>
<section id="sec-CPC" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="sec-CPC"><span class="header-section-number">3.2</span> 対照的予測符号化 (CPC) <span class="citation" data-cites="Oord+2019">(Oord et al., 2019)</span></h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/contrastive_repr4.jpeg" class="img-fluid figure-img"></p>
<figcaption>Contrastive Predictive Coding <span class="citation" data-cites="Oord+2019">(Oord et al., 2019)</span></figcaption>
</figure>
</div>
<p>まずエンコーダー <img src="https://latex.codecogs.com/png.latex?z_t=g_%7B%5Ctext%7Benc%7D%7D(x_t)"> を作る．続いて，自己回帰モデル <img src="https://latex.codecogs.com/png.latex?g_%7B%5Ctext%7Bar%7D%7D"> を用いて <img src="https://latex.codecogs.com/png.latex?z_%7B1:t%7D"> を要約して予測しようとする．</p>
<p>この段階で潜在表現 <img src="https://latex.codecogs.com/png.latex?c_t=g_%7B%5Ctext%7Bar%7D%7D(z_%7B1:t%7D)"> が作られることを期待するのであるが，直接 <img src="https://latex.codecogs.com/png.latex?p(x%7Cc)"> を予測しようとしてしまうと，必ずしも有用な潜在表現 <img src="https://latex.codecogs.com/png.latex?c"> が得られるとは限らない．</p>
<p>そこで，距離 <img src="https://latex.codecogs.com/png.latex?k"> だけ離れたデータ <img src="https://latex.codecogs.com/png.latex?x_%7Bt+k%7D"> の尤度比 <img src="https://latex.codecogs.com/png.latex?%0Af_k(x_%7Bt+k%7D,c_t)%5C,%5Cpropto%5C,%5Cfrac%7Bp(x_%7Bt+k%7D%7Cc_t)%7D%7Bp(x_%7Bt+k%7D)%7D%0A"> を， <img src="https://latex.codecogs.com/png.latex?%0Af_k(x_%7Bt+k%7D,c_t)=%5Cexp%5Cleft(z_%7Bt+k%7D%5E%5Ctop%20W_kc_t%5Cright)%0A"> の形で予測しようとし，この荷重 <img src="https://latex.codecogs.com/png.latex?W_k"> の推定を考える．</p>
<p>これは，表現学習においては予測 <img src="https://latex.codecogs.com/png.latex?p(x%7Cc)"> が至上命題であるわけではなく，<img src="https://latex.codecogs.com/png.latex?x"> と <img src="https://latex.codecogs.com/png.latex?c"> の相互情報量が近ければ十分であるために用意された，表現学習のための代理目標（<strong>InfoMax</strong> <span class="citation" data-cites="Linsker1988">(Linsker, 1988)</span> ともいう）であり，<strong>InfoNCE 損失</strong> または <a href="../../../posts/2024/Kernels/Kernel.html#sec-triplet-loss"><img src="https://latex.codecogs.com/png.latex?n">-ペア損失</a> <span class="citation" data-cites="Sohn2016">(Sohn, 2016)</span> とも呼ばれる．<sup>3</sup></p>
<p>このモデルに対しては，GAN 様の敵対的生成であるノイズ対照学習の損失を用いることができる．<span class="citation" data-cites="Oord+2019">(Oord et al., 2019)</span> では，エンコーダとして残差接続を持つ strided convolutional layer が，自己回帰モデルとして GRU (Gated Recurrent Unit) <span class="citation" data-cites="Cho+2014">(Cho et al., 2014)</span> という RNN の変種が使われている．</p>
<p>こうして推定された <img src="https://latex.codecogs.com/png.latex?(z_t,c_t)"> は，<img src="https://latex.codecogs.com/png.latex?x_%7B1:t%7D"> までのヒストリを見た要約が欲しい場合は <img src="https://latex.codecogs.com/png.latex?c_t"> を，そうでない場合は <img src="https://latex.codecogs.com/png.latex?z_t"> を，データ <img src="https://latex.codecogs.com/png.latex?x_t"> の潜在表現として使える．</p>
</section>
<section id="対照的言語-画像事前学習-clip-radford2019" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="対照的言語-画像事前学習-clip-radford2019"><span class="header-section-number">3.3</span> 対照的言語-画像事前学習 (CLIP) <span class="citation" data-cites="Radford+2019">(Radford et al., 2019)</span></h3>
<p>ノイズ対照学習に基づくアプローチの美点は，別のモーダリティを持つデータを統合しやすい点にある．</p>
<p>これを用いて，言語と画像の関係について大規模に事前学習をさせたのが OpenAI の <a href="https://openai.com/index/clip/">CLIP</a> <span class="citation" data-cites="Radford+2019">(Radford et al., 2019)</span> である．</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://162348.github.io/posts/2024/Kernels/Images/CLIP.png" class="img-fluid figure-img"></p>
<figcaption>画像に対する種々のノイズ対照学習法がどのようなノイズと対照させるか <span class="citation" data-cites="Murphy2023">(Murphy, 2023, p. 1055)</span></figcaption>
</figure>
</div>
<p><a href="../../../posts/2024/Kernels/Kernel.html#sec-deep-metric-learning">対照学習による深層距離学習において重要なのは，正のノイズと負のノイズを各サンプル <img src="https://latex.codecogs.com/png.latex?x"> に対してどう作るか？である</a> <span class="citation" data-cites="Tian+2020WhatMakes">(Tian, Sun, et al., 2020)</span>．</p>
<p>SimCLR <span class="citation" data-cites="Chen+2020SimCLR">(Chen et al., 2020)</span> は，<img src="https://latex.codecogs.com/png.latex?x"> に対する変換（ランダムなトリミング，リサイズ，並行移動など）を学習し，データ拡張によって正のノイズと負のノイズを作る．</p>
<p>CMC (Contrastive Multiple Coding) <span class="citation" data-cites="Tian+2020">(Tian, Krishnan, et al., 2020)</span> は，<img src="https://latex.codecogs.com/png.latex?x"> の輝度 (luma) と彩度 (chroma) を取り出して正のノイズと負のノイズとする．</p>
<p>SupCon (Supervised Contrastive Learning) <span class="citation" data-cites="Khosla+2020">(Khosla et al., 2020)</span> は画像に対するラベルングが得られるとき，これを教師的に用いて正のノイズと負のノイズを作る．これは <a href="../../../posts/2024/Kernels/Kernel.html#sec-NCA">近傍成分分析 (NCA)</a> <span class="citation" data-cites="Goldberger+2004">(Goldberger et al., 2004)</span> と対照学習を組み合わせた発想であり，実際後続の分類タスクがうまく，ロバストになるという．</p>
</section>
<section id="非対照学習" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="非対照学習"><span class="header-section-number">3.4</span> 非対照学習</h3>
<p>Vision Transformer (ViT) で用いられる DINO (Self-Distilation with no Labels) <span class="citation" data-cites="Caron+2021">(Caron et al., 2021)</span> などは，負のノイズを使わず，正のノイズのみを使った表現学習法である．</p>
<p>BYOL (Bootstrap Your Own Latent) <span class="citation" data-cites="Grill+2020">(Grill et al., 2020)</span> も負のノイズを使わない手法であるが，目的関数には似ているノイズを寄せるための項しかなく，深層表現が退化しない理由はどうやら学習ダイナミクスの方にあるという．</p>
<p>Barlow Twins <span class="citation" data-cites="Zbontar+2021">(Zbontar et al., 2021)</span> では，正のノイズとの間の，各特徴量に関する相関係数行列 <img src="https://latex.codecogs.com/png.latex?C"> から定まる <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D:=%5Csum_%7Bi=1%7D%5Ep(1-C_%7Bii%7D)%5E2+%5Clambda%5Csum_%7Bi%5Cne%20j%7DC_%7Bij%7D%5E2%0A"> を目的関数とする．</p>
<p>第二項の存在により，負のノイズがなくとも表現が縮退することが回避される．この方法は，HSIC <span class="citation" data-cites="Gretton+2007">(Gretton et al., 2007)</span> などのカーネル独立性検定法を，表現学習に応用している形とみれる．</p>
</section>
</section>
<section id="独立成分分析による表現学習" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="独立成分分析による表現学習"><span class="header-section-number">4</span> 独立成分分析による表現学習</h2>
<p>表現学習の１つの目標である <strong>disentangle</strong> とは，要因ごとにデータ内の変動を説明して分離することをいう．</p>
<p>これを達成するには，データやモデルに追加の仮定が必要な場合が多い <span class="citation" data-cites="Locatello+2020">(Locatello et al., 2020)</span>．どのような状況で安定した disentanglement が可能であるかについて，独立成分分析の知見，特に指数型分布族と識別可能性の概念を通じて理解する試みがある <span class="citation" data-cites="Khemakhem+2020">(Khemakhem et al., 2020)</span>, <span class="citation" data-cites="Roeder+2021">(Roeder et al., 2021)</span>, <span class="citation" data-cites="Halva+2021">(Hälvä et al., 2021)</span>．</p>
<p>特に，独立成分分析が目指すように，現実に何らかの意味で則した方法でデータの潜在表現を得ることが，表現学習で最も好ましい，あるべき disentanglement であるとするならば，「深層模型がいつ識別可能になるか？」は基本的な問題だというべきだろう <span class="citation" data-cites="Khemakhem+2020">(Khemakhem et al., 2020)</span>．<sup>4</sup></p>
<p>このような立場を <strong>因果的表現学習</strong> (causal representation learning) ともいう．<sup>5</sup></p>
<p>VAE などの深層生成モデル，ノイズ対照学習，独立成分分析などはいずれも，多層の階層モデルを学習するという点では共通しており，１つの分野の発見が他に資することが多い．</p>
</section>
<section id="sec-identifiability" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="sec-identifiability"><span class="header-section-number">5</span> 深層潜在モデルの識別可能性</h2>
<p>仮に追加に観測されている変数 <img src="https://latex.codecogs.com/png.latex?u"> が存在して，事前分布 <img src="https://latex.codecogs.com/png.latex?p_%5Ctheta(z%7Cu)"> は <img src="https://latex.codecogs.com/png.latex?z"> 上で積の形に分解し，指数型分布族に属するとする．すなわち，潜在変数は <img src="https://latex.codecogs.com/png.latex?U"> で条件づければ互いに独立であるとする．この仮定が識別可能性の鍵となる <span class="citation" data-cites="Hyvarinen+2019">(Hyvarinen et al., 2019)</span>．</p>
<p><img src="https://latex.codecogs.com/png.latex?u"> はタイムスタンプや前時点での観測，信頼できないラベルなどがありえる <span class="citation" data-cites="Hyvarinen-Morioka2016">(Hyvärinen and Morioka, 2016)</span>．</p>
<p>観測 <img src="https://latex.codecogs.com/png.latex?X"> と潜在変数 <img src="https://latex.codecogs.com/png.latex?Z"> に対して，<img src="https://latex.codecogs.com/png.latex?%5Ctheta=(f,T,%5Clambda)"> をパラメータとして <img src="https://latex.codecogs.com/png.latex?%0Ap_%5Ctheta(x,z%7Cu)=p_f(x%7Cz)p_%7BT,%5Clambda%7D(z%7Cu),%0A"> <img src="https://latex.codecogs.com/png.latex?%0AX=f(Z)+%5Cepsilon,%5Cqquad%20%5Cepsilon%5Csim%20p_%5Cepsilon(%5Cepsilon).%0A"> という形のモデルは，<img src="https://latex.codecogs.com/png.latex?p_%7BT,%5Clambda%7D"> が十分統計量 <img src="https://latex.codecogs.com/png.latex?T"> とパラメータ <img src="https://latex.codecogs.com/png.latex?%5Clambda"> を持つ指数型分布族である限り，いくつかの正則性条件を満たせば識別可能になる：</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="[@Khemakhem+2020 定理１]">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="citation" data-cites="Khemakhem+2020">(Khemakhem et al., 2020 定理１)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p>次の４条件が成り立つ場合，パラメータ <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> は，ある線型変換 <img src="https://latex.codecogs.com/png.latex?A"> に対して <img src="https://latex.codecogs.com/png.latex?%0AT%5Ccirc%20f%5E%7B-1%7D=A%5Ccirc%20%5Cwidetilde%7BT%7D%5Ccirc%5Cwidetilde%7Bf%7D%5E%7B-1%7D+c%0A"> の違いを除いて識別可能である：</p>
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?p_%5Cepsilon"> の特性関数は殆ど至る所零にならない．</li>
<li><img src="https://latex.codecogs.com/png.latex?f"> は単射である．</li>
<li>十分統計量 <img src="https://latex.codecogs.com/png.latex?%5C%7BT_%7Bi,j%7D%5C%7D_%7Bi%5Cin%5Bn%5D,j%5Cin%5Bk%5D%7D"> は殆ど至る所可微分で，任意の測度正集合上に線型独立な関数を定める．</li>
<li>ある点 <img src="https://latex.codecogs.com/png.latex?u%5E0,%5Ccdots,u%5E%7Bnk%7D"> が存在して，行列 <img src="https://latex.codecogs.com/png.latex?(%5Clambda(u%5E1)%5C;%5Ccdots%5C;%5Clambda(u%5E%7Bnk%7D))-(%5Clambda(u%5E0)%5C;%5Ccdots%5C;%5Clambda(u%5E0))"> は可逆：</li>
</ol>
</div>
</div>
<p>加えて，モデルが真の分布を含む場合，変分下界の最大化は上述の線型変換 <img src="https://latex.codecogs.com/png.latex?A"> の違いを除いて <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> の一致推定に成功する．</p>
</section>
<section id="非線型独立成分分析" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="非線型独立成分分析"><span class="header-section-number">6</span> 非線型独立成分分析</h2>
<p>非線型独立成分分析は，ある独立な成分からなる潜在変数 <img src="https://latex.codecogs.com/png.latex?%0Ap(z)=%5Cprod_%7Bi=1%7D%5Edp_i(z_i)%0A"> に対して，観測がこの非線型変換 <img src="https://latex.codecogs.com/png.latex?x=f(z)"> であると仮定し，データ生成過程を特定しようとする営みである．</p>
<p>これは上のモデルの <img src="https://latex.codecogs.com/png.latex?%5Cepsilon=0"> とした場合に他ならない．</p>
<p>つまるところ，従来からの深層生成モデリングのうち，統計的に特別な意味を持つものが非線型独立成分分析と捉えることもできるはずである．すなわち，生成モデルと非線型独立成分分析は，モデルの骨子自体は共通で，その適用目的が違うに過ぎない（<a href="../../../posts/2024/Samplers/Sampling.html#sec-sampling-as-synthesis">この稿</a> も参照）．</p>
<p>ただし，統計モデルと見る以上は識別可能性が肝要である．しかし近年の ICA は，識別可能性を緩めた形 5 で得ることに成功しており，これにより深層生成モデルとの同一視が進むことになる <span class="citation" data-cites="Hyvarinen+2019">(Hyvarinen et al., 2019)</span>, <span class="citation" data-cites="Khemakhem+2020">(Khemakhem et al., 2020)</span>．</p>
</section>
<section id="vae-の識別可能性" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="vae-の識別可能性"><span class="header-section-number">7</span> VAE の識別可能性</h2>
<p>これにより，VAE などの深層生成モデルをより統計的に意味のあるものとすることができる．上述の定理により識別可能性を確保した VAE を iVAE (identifiable VAE) <span class="citation" data-cites="Khemakhem+2020">(Khemakhem et al., 2020)</span> と呼ぶ．</p>
<p>また逆の方向には，非線型 ICA モデルを変分ベイズや確率的勾配降下法により推定することができる．</p>
<p>また <span class="citation" data-cites="Kivva+2021">(Kivva et al., 2021)</span>, <span class="citation" data-cites="Kivva+2022">(Kivva et al., 2022)</span>, <span class="citation" data-cites="Lopez+2024">(Lopez et al., 2024)</span> によると，VAE の事前分布が特定の混合分布の形を持つならば，補助変数 <img src="https://latex.codecogs.com/png.latex?u"> が存在しない場合でも，VAE は識別可能な因果グラフを与えるという．</p>
</section>
<section id="sec-InfoMax" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="sec-InfoMax"><span class="header-section-number">8</span> InfoMax</h2>
<p>CPC 3.2 が目指したように，元データの情報量を最大限保った潜在表現を獲得することが，後続タスクにおいて有利になるだろう．</p>
<p>実は，生物の脳の認識様式もこれに沿っていると考えられ，視覚神経に関する研究を起源として <strong>効率的符号化仮説</strong> (Efficient Coding Hypothesis) <span class="citation" data-cites="Barlow1961">(H. B. Barlow, 1961)</span>, <span class="citation" data-cites="Barlow1972">(H. B. Barlow, 1972)</span> または情報処理分野において <strong>情報量最大化仮説</strong> (InfoMax) <span class="citation" data-cites="Linsker1988">(Linsker, 1988)</span>, <span class="citation" data-cites="Bell-Sejnowski1995">(Bell and Sejnowski, 1995)</span> と呼ばれている．</p>
<p>この仮説は視覚の研究における vision as inverse graphics <span class="citation" data-cites="Romaszko+2017">(Romaszko et al., 2017)</span> / analysis by synthesis <span class="citation" data-cites="Kersten+2004">(Kersten et al., 2004)</span>, <span class="citation" data-cites="Yuille-Kersten2006">(Yuille and Kersten, 2006)</span> から，一般に脳が外界モデルを獲得するプロセスに拡張され，<strong>ベイズ脳仮説</strong> <span class="citation" data-cites="Doya+2006">(Doya et al., 2006)</span> とも呼ばれる <span class="citation" data-cites="島崎秀昭2019">(島崎秀昭, 2019)</span>．</p>
<p>情報理論においては，information bottleneck principle <span class="citation" data-cites="Tishby+2000">(Tishby et al., 2000)</span>, <span class="citation" data-cites="Tishby-Zaslavsky2015">(Tishby and Zaslavsky, 2015)</span> としても継承されている．</p>
</section>



<div id="quarto-appendix" class="default"><section id="参考文献" class="level2 appendix" data-number="9"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">9</span> 参考文献</h2><div class="quarto-appendix-contents">

<p><span class="citation" data-cites="Hyvarinen-Morioka2016">(Hyvärinen and Morioka, 2016)</span>, <span class="citation" data-cites="Hyvarinen-Morioka2017">(Hyvarinen and Morioka, 2017)</span>, <span class="citation" data-cites="Hyvarinen+2019">(Hyvarinen et al., 2019)</span> は深層潜在モデルが識別可能になるための条件を示した非線型 ICA の論文である．</p>
<p>Efficient coding 仮説と InfoMax については，<span class="citation" data-cites="島崎秀昭2019">(島崎秀昭, 2019)</span> が大変良い日本語文献である．</p>
<blockquote class="blockquote">
<p>例えばハエの視覚細胞を用いた実験で神経細胞の非線形な応答関数が外界の視覚刺激の分布に適応し，出力が一様に分布することで神経細胞のダイナミックレンジが効率よく使用されていることが示されている <span class="citation" data-cites="Laughlin1981">(Laughlin, 1981)</span>, <span class="citation" data-cites="Brenner+2000">(Brenner et al., 2000)</span>．このように非線形器を外界の分布に適応させる過程を学習と呼ぶ． <span class="citation" data-cites="島崎秀昭2019">(島崎秀昭, 2019)</span></p>
</blockquote>




</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Bao+2022" class="csl-entry">
Bao, H., Dong, L., Piao, S., and Wei, F. (2022). <a href="https://openreview.net/forum?id=p-BhZSz59o4"><span>BE</span>iT: <span>BERT</span> pre-training of image transformers</a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Barlow1961" class="csl-entry">
Barlow, H. B. (1961). <a href="https://doi.org/10.7551/mitpress/9780262518420.003.0013"><span class="nocase">Possible Principles Underlying the Transformations of Sensory Messages</span></a>. In <em><span>Sensory Communication</span></em>. The MIT Press.
</div>
<div id="ref-Barlow1972" class="csl-entry">
Barlow, H. B. (1972). <a href="https://doi.org/10.1068/p010371">Single units and sensation: A neuron doctrine for perceptual psychology?</a> <em>Perception</em>, <em>1</em>(4), 371–394.
</div>
<div id="ref-Bell-Sejnowski1995" class="csl-entry">
Bell, A. J., and Sejnowski, T. J. (1995). <a href="https://doi.org/10.1162/neco.1995.7.6.1129"><span class="nocase">An Information-Maximization Approach to Blind Separation and Blind Deconvolution</span></a>. <em>Neural Computation</em>, <em>7</em>(6), 1129–1159.
</div>
<div id="ref-Brenner+2000" class="csl-entry">
Brenner, N., Bialek, W., and de Ruyter van Steveninck, R. (2000). <a href="https://doi.org/10.1016/S0896-6273(00)81205-2">Adaptive rescaling maximizes information transmission</a>. <em>Neuron</em>, <em>26</em>(3), 695–702.
</div>
<div id="ref-Caron+2021" class="csl-entry">
Caron, M., Touvron, H., Misra, I., Jegou, H., Mairal, J., Bojanowski, P., and Joulin, A. (2021). <a href="https://doi.org/10.1109/ICCV48922.2021.00951">Emerging properties in self-supervised vision transformers</a>. In <em>2021 IEEE/CVF international conference on computer vision (ICCV)</em>, pages 9630–9640.
</div>
<div id="ref-Chen+2020SimCLR" class="csl-entry">
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G. (2020). <a href="https://proceedings.mlr.press/v119/chen20j.html">A simple framework for contrastive learning of visual representations</a>. In H. D. III and A. Singh, editors, <em>Proceedings of the 37th international conference on machine learning</em>,Vol. 119, pages 1597–1607. PMLR.
</div>
<div id="ref-Cho+2014" class="csl-entry">
Cho, K., Merriënboer, B. van, Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., and Bengio, Y. (2014). <a href="https://doi.org/10.3115/v1/D14-1179">Learning phrase representations using <span>RNN</span> encoder<span>–</span>decoder for statistical machine translation</a>. In A. Moschitti, B. Pang, and W. Daelemans, editors, <em>Proceedings of the 2014 conference on empirical methods in natural language processing (<span>EMNLP</span>)</em>, pages 1724–1734. Doha, Qatar: Association for Computational Linguistics.
</div>
<div id="ref-Devlin+2019" class="csl-entry">
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2019). <a href="https://aclanthology.org/N19-1423/">BERT: Pre-training of deep bidirectional transformers for language understanding</a>. In <em>Proceedings of the 2019 conference of the north american chapter of the association for computational linguistics: Human language technologies</em>,Vol. 1, pages 4171–4186.
</div>
<div id="ref-Donahue+2017" class="csl-entry">
Donahue, J., Krähenbühl, P., and Darrell, T. (2017). <a href="https://openreview.net/forum?id=BJtNZAFgg">Adversarial feature learning</a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Doya+2006" class="csl-entry">
Doya, K., Ishii, S., Pouget, A., and Rao, R. P. N. (2006). <em><a href="https://doi.org/10.7551/mitpress/9780262042383.001.0001"><span class="nocase">Bayesian Brain: Probabilistic Approaches to Neural Coding </span></a></em>. The MIT Press.
</div>
<div id="ref-Elias1955" class="csl-entry">
Elias, P. (1955). <a href="https://doi.org/10.1109/TIT.1955.1055126">Predictive coding–i</a>. <em>IRE Transactions on Information Theory</em>, <em>1</em>(1), 16–24.
</div>
<div id="ref-Goldberger+2004" class="csl-entry">
Goldberger, J., Hinton, G. E., Roweis, S., and Salakhutdinov, R. R. (2004). <a href="https://proceedings.neurips.cc/paper_files/paper/2004/file/42fe880812925e520249e808937738d2-Paper.pdf">Neighbourhood components analysis</a>. In L. Saul, Y. Weiss, and L. Bottou, editors, <em>Advances in neural information processing systems</em>,Vol. 17. MIT Press.
</div>
<div id="ref-Gretton+2007" class="csl-entry">
Gretton, A., Fukumizu, K., Teo, C., Song, L., Schölkopf, B., and Smola, A. (2007). <a href="https://proceedings.neurips.cc/paper_files/paper/2007/file/d5cfead94f5350c12c322b5b664544c1-Paper.pdf">A kernel statistical test of independence</a>. In J. Platt, D. Koller, Y. Singer, and S. Roweis, editors, <em>Advances in neural information processing systems</em>,Vol. 20. Curran Associates, Inc.
</div>
<div id="ref-Grill+2020" class="csl-entry">
Grill, J.-B., Strub, F., Altché, F., Tallec, C., Richemond, P., Buchatskaya, E., … Valko, M. (2020). <a href="https://proceedings.neurips.cc/paper_files/paper/2020/file/f3ada80d5c4ee70142b17b8192b2958e-Paper.pdf">Bootstrap your own latent - a new approach to self-supervised learning</a>. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, <em>Advances in neural information processing systems</em>,Vol. 33, pages 21271–21284. Curran Associates, Inc.
</div>
<div id="ref-Halva+2021" class="csl-entry">
Hälvä, H., Le Corff, S., Lehéricy, L., So, J., Zhu, Y., Gassiat, E., and Hyvarinen, A. (2021). <a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/0cdbb4e65815fbaf79689b15482e7575-Paper.pdf">Disentangling identifiable features from noisy data with structured nonlinear ICA</a>. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P. S. Liang, and J. W. Vaughan, editors, <em>Advances in neural information processing systems</em>,Vol. 34, pages 1624–1633. Curran Associates, Inc.
</div>
<div id="ref-He+2022" class="csl-entry">
He, K., Chen, X., Xie, S., Li, Y., Dollár, P., and Girshick, R. (2022). Masked autoencoders are scalable vision learners. In <em>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR)</em>, pages 16000–16009.
</div>
<div id="ref-Higgins+2017" class="csl-entry">
Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Botvinick, M., … Lerchner, A. (2017). <a href="https://openreview.net/forum?id=Sy2fzU9gl">Beta-<span>VAE</span>: Learning basic visual concepts with a constrained variational framework</a>. In <em>International conference on learning representations</em>.
</div>
<div id="ref-Hyvarinen-Morioka2017" class="csl-entry">
Hyvarinen, A., and Morioka, H. (2017). <a href="https://proceedings.mlr.press/v54/hyvarinen17a.html"><span class="nocase">Nonlinear ICA of Temporally Dependent Stationary Sources</span></a>. In A. Singh and J. Zhu, editors, <em>Proceedings of the 20th international conference on artificial intelligence and statistics</em>,Vol. 54, pages 460–469. PMLR.
</div>
<div id="ref-Hyvarinen+2019" class="csl-entry">
Hyvarinen, A., Sasaki, H., and Turner, R. (2019). <a href="https://proceedings.mlr.press/v89/hyvarinen19a.html">Nonlinear ICA using auxiliary variables and generalized contrastive learning</a>. In K. Chaudhuri and M. Sugiyama, editors, <em>Proceedings of the twenty-second international conference on artificial intelligence and statistics</em>,Vol. 89, pages 859–868. PMLR.
</div>
<div id="ref-Hyvarinen-Morioka2016" class="csl-entry">
Hyvärinen, A., and Morioka, H. (2016). Unsupervised feature extraction by time-contrastive learning and nonlinear ICA. In <em>Proceedings of the 30th international conference on neural information processing systems</em>, pages 3772–3780. Red Hook, NY, USA: Curran Associates Inc.
</div>
<div id="ref-Kersten+2004" class="csl-entry">
Kersten, D., Mamassian, P., and Yuille, A. (2004). <a href="https://doi.org/10.1146/annurev.psych.55.090902.142005">Object perception as bayesian inference</a>. <em>Annual Review of Psychology</em>, <em>55</em>(Volume 55, 2004), 271–304. Journal Article.
</div>
<div id="ref-Khemakhem+2020" class="csl-entry">
Khemakhem, I., Kingma, D., Monti, R., and Hyvarinen, A. (2020). <a href="https://proceedings.mlr.press/v108/khemakhem20a.html">Variational autoencoders and nonlinear ICA: A unifying framework</a>. In S. Chiappa and R. Calandra, editors, <em>Proceedings of the twenty third international conference on artificial intelligence and statistics</em>,Vol. 108, pages 2207–2217. PMLR.
</div>
<div id="ref-Khosla+2020" class="csl-entry">
Khosla, P., Teterwak, P., Wang, C., Sarna, A., Tian, Y., Isola, P., … Krishnan, D. (2020). <a href="https://proceedings.neurips.cc/paper_files/paper/2020/file/d89a66c7c80a29b1bdbab0f2a1a94af8-Paper.pdf">Supervised contrastive learning</a>. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, <em>Advances in neural information processing systems</em>,Vol. 33, pages 18661–18673. Curran Associates, Inc.
</div>
<div id="ref-Kivva+2022" class="csl-entry">
Kivva, B., Rajendran, G., Ravikumar, P. K., and Aragam, B. (2022). <a href="https://openreview.net/forum?id=UeG3kt_Ebg2">Identifiability of deep generative models under mixture priors without auxiliary information</a>. In <em>UAI 2022 workshop on causal representation learning</em>.
</div>
<div id="ref-Kivva+2021" class="csl-entry">
Kivva, B., Rajendran, G., Ravikumar, P., and Aragam, B. (2021). <a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/966aad8981dcc75b5b8ab04427a833b2-Paper.pdf">Learning latent causal graphs via mixture oracles</a>. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P. S. Liang, and J. W. Vaughan, editors, <em>Advances in neural information processing systems</em>,Vol. 34, pages 18087–18101. Curran Associates, Inc.
</div>
<div id="ref-Lake+2015" class="csl-entry">
Lake, B. M., Salakhutdinov, R., and Tenenbaum, J. B. (2015). <a href="https://doi.org/10.1126/science.aab3050">Human-level concept learning through probabilistic program induction</a>. <em>Science</em>, <em>350</em>(6266), 1332–1338.
</div>
<div id="ref-Laughlin1981" class="csl-entry">
Laughlin, S. (1981). <a href="https://doi.org/doi:10.1515/znc-1981-9-1040">A simple coding procedure enhances a neuron’s information capacity</a>. <em>Zeitschrift f<span>ü</span>r Naturforschung C</em>, <em>36</em>(9-10), 910–912.
</div>
<div id="ref-Lee-Mumford2003" class="csl-entry">
Lee, T. S., and Mumford, D. (2003). <a href="https://doi.org/10.1364/JOSAA.20.001434">Hierarchical bayesian inference in the visual cortex</a>. <em>J. Opt. Soc. Am. A</em>, <em>20</em>(7), 1434–1448.
</div>
<div id="ref-Linsker1988" class="csl-entry">
Linsker, R. (1988). <a href="https://doi.org/10.1109/2.36"><span class="nocase">Self-Organization in a Perceptual Network</span></a>. <em>Computer</em>, <em>21</em>(3), 105–117.
</div>
<div id="ref-Locatello+2020" class="csl-entry">
Locatello, F., Bauer, S., Lucic, M., Raetsch, G., Gelly, S., Schölkopf, B., and Bachem, O. (2020). <a href="http://jmlr.org/papers/v21/19-976.html">A sober look at the unsupervised learning of disentangled representations and their evaluation</a>. <em>Journal of Machine Learning Research</em>, <em>21</em>(209), 1–62.
</div>
<div id="ref-Lopez+2024" class="csl-entry">
Lopez, R., Huetter, J.-C., Hajiramezanali, E., Pritchard, J. K., and Regev, A. (2024). <a href="https://proceedings.mlr.press/v236/lopez24a.html">Toward the identifiability of comparative deep generative models</a>. In F. Locatello and V. Didelez, editors, <em>Proceedings of the third conference on causal learning and reasoning</em>,Vol. 236, pages 868–912. PMLR.
</div>
<div id="ref-Mikolov2013" class="csl-entry">
Mikolov, T., Chen, K., Corrado, G., and Dean, J. (2013). <em><a href="https://arxiv.org/abs/1301.3781">Efficient estimation of word representations in vector space</a></em>.
</div>
<div id="ref-Mikolov2013b" class="csl-entry">
Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., and Dean, J. (2013). <a href="https://proceedings.neurips.cc/paper_files/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf">Distributed representations of words and phrases and their compositionality</a>. In C. J. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, editors, <em>Advances in neural information processing systems</em>,Vol. 26. Curran Associates, Inc.
</div>
<div id="ref-Mnih-Kavukcuoglu2013" class="csl-entry">
Mnih, A., and Kavukcuoglu, K. (2013). <a href="https://proceedings.neurips.cc/paper_files/paper/2013/file/db2b4182156b2f1f817860ac9f409ad7-Paper.pdf">Learning word embeddings efficiently with noise-contrastive estimation</a>. In C. J. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, editors, <em>Advances in neural information processing systems</em>,Vol. 26. Curran Associates, Inc.
</div>
<div id="ref-Murphy2023" class="csl-entry">
Murphy, K. P. (2023). <em><a href="http://probml.github.io/book2">Probabilistic machine learning: Advanced topics</a></em>. MIT Press.
</div>
<div id="ref-Oord+2019" class="csl-entry">
Oord, A. van den, Li, Y., and Vinyals, O. (2019). <a href="https://arxiv.org/abs/1807.03748">Representation learning with contrastive predictive coding</a>.
</div>
<div id="ref-Radford+2019" class="csl-entry">
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I. (2019). <em><a href="https://github.com/openai/gpt-2?tab=readme-ov-file">Language models are unsupervised multitask learners</a></em>.
</div>
<div id="ref-Rao-Ballard1999" class="csl-entry">
Rao, R. P. N., and Ballard, D. H. (1999). <a href="https://doi.org/10.1038/4580">Predictive coding in the visual cortex: A functional interpretation of some extra-classical receptive-field effects</a>. <em>Nature Neuroscience</em>, <em>2</em>(1), 79–87.
</div>
<div id="ref-Roberts1963" class="csl-entry">
Roberts, L. G. (1963). <em>Machine perception of three-dimensional solids</em> (PhD thesis). Massachusetts Institute of Technology. Retrieved from <a href="http://hdl.handle.net/1721.1/11589">http://hdl.handle.net/1721.1/11589</a>
</div>
<div id="ref-Roeder+2021" class="csl-entry">
Roeder, G., Metz, L., and Kingma, D. (2021). <a href="https://proceedings.mlr.press/v139/roeder21a.html">On linear identifiability of learned representations</a>. In M. Meila and T. Zhang, editors, <em>Proceedings of the 38th international conference on machine learning</em>,Vol. 139, pages 9030–9039. PMLR.
</div>
<div id="ref-Romaszko+2017" class="csl-entry">
Romaszko, L., Williams, C. K. I., Moreno, P., and Kohli, P. (2017). <a href="https://doi.org/10.1109/ICCVW.2017.115">Vision-as-inverse-graphics: Obtaining a rich 3D explanation of a scene from a single image</a>. In <em>2017 IEEE international conference on computer vision workshops (ICCVW)</em>, pages 940–948.
</div>
<div id="ref-Sohn2016" class="csl-entry">
Sohn, K. (2016). <a href="https://proceedings.neurips.cc/paper_files/paper/2016/file/6b180037abbebea991d8b1232f8a8ca9-Paper.pdf">Improved deep metric learning with multi-class n-pair loss objective</a>. In D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett, editors, <em>Advances in neural information processing systems</em>,Vol. 29. Curran Associates, Inc.
</div>
<div id="ref-Tian+2020" class="csl-entry">
Tian, Y., Krishnan, D., and Isola, P. (2020). Contrastive multiview coding. In A. Vedaldi, H. Bischof, T. Brox, and J.-M. Frahm, editors, <em>Computer vision – ECCV 2020</em>, pages 776–794. Cham: Springer International Publishing.
</div>
<div id="ref-Tian+2020WhatMakes" class="csl-entry">
Tian, Y., Sun, C., Poole, B., Krishnan, D., Schmid, C., and Isola, P. (2020). <a href="https://proceedings.neurips.cc/paper_files/paper/2020/file/4c2e5eaae9152079b9e95845750bb9ab-Paper.pdf">What makes for good views for contrastive learning?</a> In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, <em>Advances in neural information processing systems</em>,Vol. 33, pages 6827–6839. Curran Associates, Inc.
</div>
<div id="ref-Tishby+2000" class="csl-entry">
Tishby, N., Pereira, F. C., and Bialek, W. (2000). <a href="https://arxiv.org/abs/physics/0004057">The information bottleneck method</a>.
</div>
<div id="ref-Tishby-Zaslavsky2015" class="csl-entry">
Tishby, N., and Zaslavsky, N. (2015). <a href="https://doi.org/10.1109/ITW.2015.7133169">Deep learning and the information bottleneck principle</a>. In <em>2015 IEEE information theory workshop (ITW)</em>, pages 1–5.
</div>
<div id="ref-Vincent+2008" class="csl-entry">
Vincent, P., Larochelle, H., Bengio, Y., and Manzagol, P.-A. (2008). <a href="https://doi.org/10.1145/1390156.1390294">Extracting and composing robust features with denoising autoencoders</a>. In <em>Proceedings of the 25th international conference on machine learning</em>, pages 1096–1103. New York, NY, USA: Association for Computing Machinery.
</div>
<div id="ref-Yuille-Kersten2006" class="csl-entry">
Yuille, A., and Kersten, D. (2006). <a href="https://doi.org/10.1016/j.tics.2006.05.002"><span class="nocase">Vision as Bayesian Inference: Analysis by Synthesis?</span></a> <em>Trends in Cognitive Sciences</em>, <em>10</em>(7), 301–308.
</div>
<div id="ref-Zbontar+2021" class="csl-entry">
Zbontar, J., Jing, L., Misra, I., LeCun, Y., and Deny, S. (2021). <a href="https://proceedings.mlr.press/v139/zbontar21a.html">Barlow twins: Self-supervised learning via redundancy reduction</a>. In M. Meila and T. Zhang, editors, <em>Proceedings of the 38th international conference on machine learning</em>,Vol. 139, pages 12310–12320. PMLR.
</div>
<div id="ref-島崎秀昭2019" class="csl-entry">
島崎秀昭. (2019). <a href="https://doi.org/10.3902/jnns.26.72">ベイズ統計と熱力学から見る生物の学習と認識のダイナミクス</a>. <em>日本神経回路学会誌</em>, <em>26</em>(3), 72–98.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>予測符号化 (<a href="https://en.wikipedia.org/wiki/Predictive_coding">predictive coding</a>) <span class="citation" data-cites="Elias1955">(Elias, 1955)</span> は従来からデータ圧縮の原理であると同時に，認知科学において，脳のメンタルモデルとしても有名である <span class="citation" data-cites="Rao-Ballard1999">(Rao and Ballard, 1999)</span>．↩︎</p></li>
<li id="fn2"><p><span class="citation" data-cites="Murphy2023">(Murphy, 2023, p. 1056)</span> 第32.3.4.2節も参照．↩︎</p></li>
<li id="fn3"><p>相互情報量は<img src="https://latex.codecogs.com/png.latex?I(x;c)=%5Csum%20p(x,c)%5Clog%5Cfrac%7Bp(x%7Cc)%7D%7Bp(x)%7D"> と表される．密度比の推定が成功していれば，相互情報量は殆ど変わらない．↩︎</p></li>
<li id="fn4"><p>The advantage of the new framework over typical deep latent-variable models used with VAEs is that we actually recover the original latents, thus providing principled disentanglement. <span class="citation" data-cites="Khemakhem+2020">(Khemakhem et al., 2020)</span> Section 6．↩︎</p></li>
<li id="fn5"><p><span class="citation" data-cites="Murphy2023">(Murphy, 2023, p. 1060)</span> 33.4.1節も参照．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Deep</category>
  <guid>https://162348.github.io/posts/2024/Kernels/NCL.html</guid>
  <pubDate>Sun, 28 Jul 2024 15:00:00 GMT</pubDate>
  <media:content url="https://162348.github.io/posts/2024/Kernels/Images/contrastive_repr4.jpeg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>VAE：変分自己符号化器</title>
  <dc:creator>司馬博文 </dc:creator>
  <link>https://162348.github.io/posts/2024/Kernels/VAE.html</link>
  <description><![CDATA[ 





<div class="hidden">
<p>A Blog Entry on Bayesian Computation by an Applied Mathematician</p>
<p>$$</p>
<p>$$</p>
</div>
<section id="vae-kingma-welling2014" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="vae-kingma-welling2014"><span class="header-section-number">1</span> VAE <span class="citation" data-cites="Kingma-Welling2014">(D. Kingma and Welling, 2014)</span></h2>
<section id="導入" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="導入"><span class="header-section-number">1.1</span> 導入</h3>
<p><code>PyTorch</code> を用いることで詳細を省略し，VAE の構造を概観することとする．</p>
<div id="3f7ccce7" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.nn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> nn</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span>
<span id="cb1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> save_image, make_grid</span></code></pre></div>
</div>
<p>今回は，MNIST データセットを用い，隠れ次元 400 を通じて潜在次元 200 まで圧縮する．</p>
<div id="b9e88711" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">dataset_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'~/hirofumi/datasets'</span></span>
<span id="cb2-2"></span>
<span id="cb2-3">DEVICE <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.device(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mps"</span>)</span>
<span id="cb2-4"></span>
<span id="cb2-5">batch_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb2-6"></span>
<span id="cb2-7">x_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">784</span></span>
<span id="cb2-8">hidden_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span></span>
<span id="cb2-9">latent_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span></span>
<span id="cb2-10"></span>
<span id="cb2-11">lr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-3</span></span>
<span id="cb2-12"></span>
<span id="cb2-13">epochs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span></span></code></pre></div>
</div>
<div id="ad1f1ca3" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> MNIST</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision.transforms <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> transforms</span>
<span id="cb3-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.utils.data <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DataLoader</span>
<span id="cb3-4"></span>
<span id="cb3-5"></span>
<span id="cb3-6">mnist_transform <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb3-7">        transforms.ToTensor(),</span>
<span id="cb3-8">])</span>
<span id="cb3-9"></span>
<span id="cb3-10">kwargs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'num_workers'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pin_memory'</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>} </span>
<span id="cb3-11"></span>
<span id="cb3-12">train_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MNIST(dataset_path, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>mnist_transform, train<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, download<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb3-13">test_dataset  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MNIST(dataset_path, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>mnist_transform, train<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, download<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb3-14"></span>
<span id="cb3-15">train_loader <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataLoader(dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_dataset, batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>batch_size, shuffle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs)</span>
<span id="cb3-16">test_loader  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataLoader(dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>test_dataset,  batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>batch_size, shuffle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs)</span></code></pre></div>
</div>
<p>PyTorch の <a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">Dataset と DataLoader</a> は，訓練やテスト用のデータセットの簡単なアクセスと，それに対する iterable オブジェクトを提供する．</p>
<div class="callout callout-style-default callout-important no-icon callout-titled" title="M2 Mac 上での実行">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
M2 Mac 上での実行
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>まず，次のようにして仮想環境を用意する：</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb4-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">python3</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-m</span> venv VAE</span>
<span id="cb4-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">source</span> VAE/bin/activate</span>
<span id="cb4-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install torch</span></code></pre></div>
<p>M2 Mac では Metal Performance Shaders (MPS) という Apple の GPU アクセラレーション技術が利用可能で，PyTorch 1.12 からはこれをサポートしている．</p>
<div id="b8aef1e6" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb5-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(torch.__version__)</span>
<span id="cb5-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(torch.backends.mps.is_available())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2.4.0
True</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled" title="DataLoader worker (pid(s) 9044) exited unexpectedly">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
DataLoader worker (pid(s) 9044) exited unexpectedly
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>上記のエラーは，<code>DataLoader</code> が並列処理によりデータを読み込むことに失敗したことを意味する．</p>
<p>メモリ不足も考えられるが，<code>num_workers=0</code> として単一プロセスで実行することでもエラーが抑えられる．</p>
<p>今回は軽量な計算であるから，これで良いということである．</p>
</div>
</div>
</div>
</section>
<section id="モデルの定義" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="モデルの定義"><span class="header-section-number">1.2</span> モデルの定義</h3>
<section id="エンコーダー" class="level4" data-number="1.2.1">
<h4 data-number="1.2.1" class="anchored" data-anchor-id="エンコーダー"><span class="header-section-number">1.2.1</span> エンコーダー</h4>
<p>エンコーダーはデータを受け取り，２層の全結合隠れ層を通じて，「平均」と「対数分散」の名前がついた計 400 次元の潜在表現を得る．</p>
<div id="d81950e8" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="annotated-cell-4" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-4-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> Encoder(nn.Module):</span>
<span id="annotated-cell-4-2">    </span>
<span id="annotated-cell-4-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, input_dim, hidden_dim, latent_dim):</span>
<span id="annotated-cell-4-4">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(Encoder, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="annotated-cell-4-5"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-4" data-target-annotation="1">1</button><span id="annotated-cell-4-6" class="code-annotation-target">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.FC_input <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(input_dim, hidden_dim)</span>
<span id="annotated-cell-4-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.FC_input2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(hidden_dim, hidden_dim)</span>
<span id="annotated-cell-4-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.FC_mean  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(hidden_dim, latent_dim)</span>
<span id="annotated-cell-4-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.FC_var   <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(hidden_dim, latent_dim)</span>
<span id="annotated-cell-4-10">        </span>
<span id="annotated-cell-4-11">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.LeakyReLU <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.LeakyReLU(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>)</span>
<span id="annotated-cell-4-12">        </span>
<span id="annotated-cell-4-13">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.training <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="annotated-cell-4-14">        </span>
<span id="annotated-cell-4-15">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x):</span>
<span id="annotated-cell-4-16">        h_       <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.LeakyReLU(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.FC_input(x))</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-4" data-target-annotation="2">2</button><span id="annotated-cell-4-17" class="code-annotation-target">        h_       <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.LeakyReLU(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.FC_input2(h_))</span>
<span id="annotated-cell-4-18">        mean     <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.FC_mean(h_)</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-4" data-target-annotation="3">3</button><span id="annotated-cell-4-19" class="code-annotation-target">        log_var  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.FC_var(h_)</span>
<span id="annotated-cell-4-20">        </span>
<span id="annotated-cell-4-21">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> mean, log_var</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-4" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-4" data-code-lines="6" data-code-annotation="1"><a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear"><code>nn.Linear</code></a> は PyTorch による全結合層 <img src="https://latex.codecogs.com/png.latex?y=xA%5E%5Ctop+b"> の実装である．</span>
</dd>
<dt data-target-cell="annotated-cell-4" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-4" data-code-lines="17" data-code-annotation="2">ここまで２層の全結合層にデータを通して，最終的な出力<code>h_</code>を得ており，次の段階で最終的な潜在表現を得る．</span>
</dd>
<dt data-target-cell="annotated-cell-4" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-4" data-code-lines="19" data-code-annotation="3">最後の隠れ層の出力<code>h_</code>に関して平均と対数分散という名前のついた最終的な出力を，やはり全結合層を通じて得る（最終層なので活性化なし）．</span>
</dd>
</dl>
</div>
</div>
</section>
<section id="デコーダー" class="level4" data-number="1.2.2">
<h4 data-number="1.2.2" class="anchored" data-anchor-id="デコーダー"><span class="header-section-number">1.2.2</span> デコーダー</h4>
<div id="75cb2125" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="annotated-cell-5" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> Decoder(nn.Module):</span>
<span id="annotated-cell-5-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, latent_dim, hidden_dim, output_dim):</span>
<span id="annotated-cell-5-3">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(Decoder, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="annotated-cell-5-4">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.FC_hidden <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(latent_dim, hidden_dim)</span>
<span id="annotated-cell-5-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.FC_hidden2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(hidden_dim, hidden_dim)</span>
<span id="annotated-cell-5-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.FC_output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Linear(hidden_dim, output_dim)</span>
<span id="annotated-cell-5-7">        </span>
<span id="annotated-cell-5-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.LeakyReLU <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.LeakyReLU(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>)</span>
<span id="annotated-cell-5-9">        </span>
<span id="annotated-cell-5-10">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x):</span>
<span id="annotated-cell-5-11">        h     <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.LeakyReLU(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.FC_hidden(x))</span>
<span id="annotated-cell-5-12">        h     <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.LeakyReLU(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.FC_hidden2(h))</span>
<span id="annotated-cell-5-13">        </span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-5" data-target-annotation="1">1</button><span id="annotated-cell-5-14" class="code-annotation-target">        x_hat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.sigmoid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.FC_output(h))</span>
<span id="annotated-cell-5-15">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> x_hat</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-5" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-5" data-code-lines="14" data-code-annotation="1">最後の出力は，エンコーダーとは違い，シグモイド関数を通して確率分布<code>x_hat</code>とする．</span>
</dd>
</dl>
</div>
</div>
</section>
<section id="モデル" class="level4" data-number="1.2.3">
<h4 data-number="1.2.3" class="anchored" data-anchor-id="モデル"><span class="header-section-number">1.2.3</span> モデル</h4>
<p>VAE はエンコーダーとデコーダーを連結し，１つのニューラルネットワークとして学習する．</p>
<div id="e12d6c1a" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="annotated-cell-6" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-6-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> Model(nn.Module):</span>
<span id="annotated-cell-6-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, Encoder, Decoder):</span>
<span id="annotated-cell-6-3">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(Model, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="annotated-cell-6-4">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Encoder <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Encoder</span>
<span id="annotated-cell-6-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Decoder <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Decoder</span>
<span id="annotated-cell-6-6">        </span>
<span id="annotated-cell-6-7">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> reparameterization(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, mean, var):</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-6" data-target-annotation="1">1</button><span id="annotated-cell-6-8" class="code-annotation-target">        epsilon <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn_like(var).to(DEVICE)</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-6" data-target-annotation="2">2</button><span id="annotated-cell-6-9" class="code-annotation-target">        z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> var<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>epsilon</span>
<span id="annotated-cell-6-10">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> z</span>
<span id="annotated-cell-6-11">        </span>
<span id="annotated-cell-6-12">                </span>
<span id="annotated-cell-6-13">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x):</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-6" data-target-annotation="3">3</button><span id="annotated-cell-6-14" class="code-annotation-target">        mean, log_var <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Encoder(x)</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-6" data-target-annotation="4">4</button><span id="annotated-cell-6-15" class="code-annotation-target">        z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.reparameterization(mean, torch.exp(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> log_var))</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-6" data-target-annotation="5">5</button><span id="annotated-cell-6-16" class="code-annotation-target">        x_hat            <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Decoder(z)</span>
<span id="annotated-cell-6-17">        </span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-6" data-target-annotation="6">6</button><span id="annotated-cell-6-18" class="code-annotation-target">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> x_hat, mean, log_var</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-6" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-6" data-code-lines="8" data-code-annotation="1">これは <strong>サンプリングイプシロン</strong> と呼ばれる値である．</span>
</dd>
<dt data-target-cell="annotated-cell-6" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-6" data-code-lines="9" data-code-annotation="2">ここで reparametrization trick を行っている．</span>
</dd>
<dt data-target-cell="annotated-cell-6" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-6" data-code-lines="14" data-code-annotation="3">入力 <code>x</code> があったならば，まずエンコーダーに通して <code>mean</code>, <code>log_var</code> を得る．</span>
</dd>
<dt data-target-cell="annotated-cell-6" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-6" data-code-lines="15" data-code-annotation="4">元々 <code>log_var</code> の名前の通り対数分散として扱うこととしていたので，２で割り指数関数に通すことで標準偏差を得る．この平均と標準偏差について reparametrization trick を実行し，デコーダーに繋ぐ．</span>
</dd>
<dt data-target-cell="annotated-cell-6" data-target-annotation="5">5</dt>
<dd>
<span data-code-cell="annotated-cell-6" data-code-lines="16" data-code-annotation="5">デコーダーではデータの潜在表現 <code>z</code> を受け取り，デコードしたものを <code>x_hat</code> とする．</span>
</dd>
<dt data-target-cell="annotated-cell-6" data-target-annotation="6">6</dt>
<dd>
<span data-code-cell="annotated-cell-6" data-code-lines="18" data-code-annotation="6">返り値は，デコーダーの出力 <code>x_hat</code> だけでなく，潜在表現 <code>mean</code>, <code>log_var</code> も含むことに注意．</span>
</dd>
</dl>
</div>
</div>
<div id="64d271d4" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="annotated-cell-7" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-7-1">encoder <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Encoder(input_dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>x_dim, hidden_dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>hidden_dim, latent_dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>latent_dim)</span>
<span id="annotated-cell-7-2">decoder <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Decoder(latent_dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>latent_dim, hidden_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> hidden_dim, output_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x_dim)</span>
<span id="annotated-cell-7-3"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="1">1</button><span id="annotated-cell-7-4" class="code-annotation-target">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Model(Encoder<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>encoder, Decoder<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>decoder).to(DEVICE)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-7" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="4" data-code-annotation="1"><code>.to(DEVICE)</code> により，モデルを M2 Mac の MPS デバイス上に移送している．</span>
</dd>
</dl>
</div>
</div>
</section>
</section>
<section id="sec-VAE-training" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="sec-VAE-training"><span class="header-section-number">1.3</span> モデルの訓練</h3>
<p>最適化には Adam <span class="citation" data-cites="Kingma-Ba2017">(D. P. Kingma and Ba, 2017)</span> を用い，バイナリ交差エントロピー（BCE）を用いる．これは <a href="https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss"><code>nn.BCELoss</code></a> に実装がある．</p>
<div id="2851ab92" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.optim <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Adam</span>
<span id="cb7-2"></span>
<span id="cb7-3">BCE_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.BCELoss()</span>
<span id="cb7-4"></span>
<span id="cb7-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> loss_function(x, x_hat, mean, log_var):</span>
<span id="cb7-6">    reproduction_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.functional.binary_cross_entropy(x_hat, x, reduction<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sum'</span>)</span>
<span id="cb7-7">    KLD      <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> log_var <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> mean.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">pow</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> log_var.exp())</span>
<span id="cb7-8"></span>
<span id="cb7-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> reproduction_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> KLD</span>
<span id="cb7-10"></span>
<span id="cb7-11"></span>
<span id="cb7-12">optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Adam(model.parameters(), lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>lr)</span></code></pre></div>
</div>
<p>ここでの損失関数は，真のデータ <code>x</code> をデコーダーが復元できているかを交差エントロピーで測った <code>reproduction_loss</code> と，潜在表現がどれだけ <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BN%7D_d(0,I_d),d=200"> に近いかを KL 乖離度で測った <code>KLD</code> の和で定義されている．<sup>1</sup></p>
<p><a href="../../../posts/2024/Kernels/Deep4.html#sec-objective">VAE の標準的な目的関数</a> とは違う形をしていることに注意．</p>
<div class="callout callout-style-default callout-important no-icon callout-titled" title="訓練の実行">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
訓練の実行
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="f5852a87" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="annotated-cell-18" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-18-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> time</span>
<span id="annotated-cell-18-2"></span>
<span id="annotated-cell-18-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Start training VAE..."</span>)</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-18" data-target-annotation="1">1</button><span id="annotated-cell-18-4" class="code-annotation-target">model.train()</span>
<span id="annotated-cell-18-5"></span>
<span id="annotated-cell-18-6">start_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time()</span>
<span id="annotated-cell-18-7"></span>
<span id="annotated-cell-18-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> epoch <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(epochs):</span>
<span id="annotated-cell-18-9">    overall_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="annotated-cell-18-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> batch_idx, (x, _) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(train_loader):</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-18" data-target-annotation="2">2</button><span id="annotated-cell-18-11" class="code-annotation-target">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.view(batch_size, x_dim)</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-18" data-target-annotation="3">3</button><span id="annotated-cell-18-12" class="code-annotation-target">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.to(DEVICE)</span>
<span id="annotated-cell-18-13"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-18" data-target-annotation="4">4</button><span id="annotated-cell-18-14" class="code-annotation-target">        optimizer.zero_grad()</span>
<span id="annotated-cell-18-15"></span>
<span id="annotated-cell-18-16">        x_hat, mean, log_var <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model(x)</span>
<span id="annotated-cell-18-17">        loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> loss_function(x, x_hat, mean, log_var)</span>
<span id="annotated-cell-18-18">        </span>
<span id="annotated-cell-18-19">        overall_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> loss.item()</span>
<span id="annotated-cell-18-20">        </span>
<span id="annotated-cell-18-21">        loss.backward()</span>
<span id="annotated-cell-18-22">        optimizer.step()</span>
<span id="annotated-cell-18-23">        </span>
<span id="annotated-cell-18-24">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\t</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Epoch"</span>, epoch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"complete!"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\t</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Average Loss: "</span>, overall_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (batch_idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>batch_size))</span>
<span id="annotated-cell-18-25"></span>
<span id="annotated-cell-18-26">total_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> start_time</span>
<span id="annotated-cell-18-27"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Finish!! Total time: "</span>, total_time)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-18" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-18" data-code-lines="4" data-code-annotation="1"><code>PyTorch</code> のモデルオブジェクトを訓練モードにするメソッド．Dropout や Batch Normalization 層がある場合は，これにより訓練時の挙動を示すようになる．</span>
</dd>
<dt data-target-cell="annotated-cell-18" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-18" data-code-lines="11" data-code-annotation="2">事前に定めた <code>batch_size</code> に従ってバッチを展開．</span>
</dd>
<dt data-target-cell="annotated-cell-18" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-18" data-code-lines="12" data-code-annotation="3">データを GPU に移動．</span>
</dd>
<dt data-target-cell="annotated-cell-18" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-18" data-code-lines="14" data-code-annotation="4">勾配をゼロに初期化するとのこと．</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Start training VAE...
    Epoch 1 complete!   Average Loss:  174.45440591089314
    Epoch 2 complete!   Average Loss:  129.366964569856
    Epoch 3 complete!   Average Loss:  116.69913125065213
    Epoch 4 complete!   Average Loss:  112.35357475675605
    Epoch 5 complete!   Average Loss:  109.92540430339629
    Epoch 6 complete!   Average Loss:  108.33972220954195
    Epoch 7 complete!   Average Loss:  107.14160705668301
    Epoch 8 complete!   Average Loss:  106.20647785371452
    Epoch 9 complete!   Average Loss:  105.42789199446995
    Epoch 10 complete!  Average Loss:  104.9622272798414
    Epoch 11 complete!  Average Loss:  104.39062490218072
    Epoch 12 complete!  Average Loss:  103.96445004369261
    Epoch 13 complete!  Average Loss:  103.49826466963168
    Epoch 14 complete!  Average Loss:  103.10589126408598
    Epoch 15 complete!  Average Loss:  102.75672558104654
    Epoch 16 complete!  Average Loss:  102.47924416671015
    Epoch 17 complete!  Average Loss:  102.25440002543301
    Epoch 18 complete!  Average Loss:  102.09212112961707
    Epoch 19 complete!  Average Loss:  101.80551883347245
    Epoch 20 complete!  Average Loss:  101.61719139646807
    Epoch 21 complete!  Average Loss:  101.45744191164962
    Epoch 22 complete!  Average Loss:  101.27843764672892
    Epoch 23 complete!  Average Loss:  101.1599205544397
    Epoch 24 complete!  Average Loss:  101.04871442638773
    Epoch 25 complete!  Average Loss:  100.8713441999687
    Epoch 26 complete!  Average Loss:  100.73917756808223
    Epoch 27 complete!  Average Loss:  100.68475770163815
    Epoch 28 complete!  Average Loss:  100.58486650928631
    Epoch 29 complete!  Average Loss:  100.44012970836812
    Epoch 30 complete!  Average Loss:  100.39852615687604
Finish!! Total time:  130.87328815460205</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="モデルの評価" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="モデルの評価"><span class="header-section-number">1.4</span> モデルの評価</h3>
<p>テスト用データの最初のバッチについて処理し，入力データと出力データを見比べてみる．</p>
<div id="2fb148db" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="annotated-cell-9" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-9-1">model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="annotated-cell-9-2"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-9" data-target-annotation="1">1</button><span id="annotated-cell-9-3" class="code-annotation-target"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="annotated-cell-9-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> batch_idx, (x, _) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(tqdm(test_loader)):</span>
<span id="annotated-cell-9-5">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.view(batch_size, x_dim)</span>
<span id="annotated-cell-9-6">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.to(DEVICE)</span>
<span id="annotated-cell-9-7">        </span>
<span id="annotated-cell-9-8">        x_hat, _, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model(x)</span>
<span id="annotated-cell-9-9"></span>
<span id="annotated-cell-9-10"></span>
<span id="annotated-cell-9-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">break</span></span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-9" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-9" data-code-lines="3" data-code-annotation="1">勾配評価を無効化するコンテクストマネージャーで，メモリの使用を節約できるという．</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>  0%|          | 0/100 [00:00&lt;?, ?it/s]  0%|          | 0/100 [00:00&lt;?, ?it/s]</code></pre>
</div>
</div>
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb10-2"></span>
<span id="cb10-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> show_image(x, idx):</span>
<span id="cb10-4">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.view(batch_size, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">28</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">28</span>)</span>
<span id="cb10-5"></span>
<span id="cb10-6">    fig <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.figure()</span>
<span id="cb10-7">    plt.imshow(x[idx].cpu().numpy())</span>
<span id="cb10-8"></span>
<span id="cb10-9">show_image(x, idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb10-10">show_image(x_hat, idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span></code></pre></div>
<div id="fig-reconstruction" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-reconstruction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-reconstruction" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-reconstruction-1" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-reconstruction-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://162348.github.io/posts/2024/Kernels/VAE_files/figure-html/fig-reconstruction-output-1.png" data-ref-parent="fig-reconstruction" width="341" height="337" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-reconstruction-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) 左がテストデータ，右がその VAE による復元
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-reconstruction" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-reconstruction-2" class="quarto-figure quarto-figure-center quarto-float anchored" width="341" height="337">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-reconstruction-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://162348.github.io/posts/2024/Kernels/VAE_files/figure-html/fig-reconstruction-output-2.png" id="fig-reconstruction-2" data-ref-parent="fig-reconstruction" width="341" height="337" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-reconstruction-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b)
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-reconstruction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
図&nbsp;1
</figcaption>
</figure>
</div>
<p>左が入力で右が出力である．</p>
</section>
<section id="データの生成" class="level3" data-number="1.5">
<h3 data-number="1.5" class="anchored" data-anchor-id="データの生成"><span class="header-section-number">1.5</span> データの生成</h3>
<p>ここで，エンコーダを取り外してデコーダーからデータを生成する．</p>
<p>損失関数（第 1.3 節）には，潜在空間におけるデータを標準正規分布に近付けるための項が入っていたため，データの潜在表現は極めて標準正規分布に近いとみなすことにする．</p>
<p>すると，潜在表現と同じ次元の正規乱数から，データセットに極めて似通ったデータが生成できるだろう．</p>
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb11-2">    noise <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn(batch_size, latent_dim).to(DEVICE)</span>
<span id="cb11-3">    generated_images <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> decoder(noise)</span>
<span id="cb11-4"></span>
<span id="cb11-5">save_image(generated_images.view(batch_size, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">28</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">28</span>), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'generated_sample.png'</span>)</span>
<span id="cb11-6"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>):</span>
<span id="cb11-7">    show_image(generated_images, idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>i)</span></code></pre></div>
<div id="fig-generation" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-generation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-generation" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-generation-1" class="quarto-figure quarto-figure-center quarto-float anchored" width="341" height="337">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-generation-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://162348.github.io/posts/2024/Kernels/VAE_files/figure-html/fig-generation-output-1.png" id="fig-generation-1" data-ref-parent="fig-generation" width="341" height="337" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-generation-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a)
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-generation" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-generation-2" class="quarto-figure quarto-figure-center quarto-float anchored" width="341" height="337">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-generation-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://162348.github.io/posts/2024/Kernels/VAE_files/figure-html/fig-generation-output-2.png" id="fig-generation-2" data-ref-parent="fig-generation" width="341" height="337" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-generation-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b)
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-generation" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-generation-3" class="quarto-figure quarto-figure-center quarto-float anchored" width="341" height="337">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-generation-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://162348.github.io/posts/2024/Kernels/VAE_files/figure-html/fig-generation-output-3.png" id="fig-generation-3" data-ref-parent="fig-generation" width="341" height="337" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-generation-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c)
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-generation" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-generation-4" class="quarto-figure quarto-figure-center quarto-float anchored" width="341" height="337">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-generation-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://162348.github.io/posts/2024/Kernels/VAE_files/figure-html/fig-generation-output-4.png" id="fig-generation-4" data-ref-parent="fig-generation" width="341" height="337" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-generation-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(d)
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-generation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
図&nbsp;2
</figcaption>
</figure>
</div>
</section>
</section>
<section id="vq-vae-vandenoord2017" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="vq-vae-vandenoord2017"><span class="header-section-number">2</span> VQ-VAE <span class="citation" data-cites="vandenOord+2017">(van&nbsp;den&nbsp;Oord et al., 2017)</span></h2>
<section id="導入-1" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="導入-1"><span class="header-section-number">2.1</span> 導入</h3>
<div id="259a14eb" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">DEVICE <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.device(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mps"</span>)</span>
<span id="cb12-2"></span>
<span id="cb12-3">batch_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span></span>
<span id="cb12-4">img_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>)</span>
<span id="cb12-5"></span>
<span id="cb12-6">input_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span></span>
<span id="cb12-7">hidden_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span></span>
<span id="cb12-8">latent_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span></span>
<span id="cb12-9">n_embeddings<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span></span>
<span id="cb12-10">output_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span></span>
<span id="cb12-11">commitment_beta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span></span>
<span id="cb12-12"></span>
<span id="cb12-13">lr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2e-4</span></span>
<span id="cb12-14"></span>
<span id="cb12-15">epochs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span></span>
<span id="cb12-16"></span>
<span id="cb12-17">print_step <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span></span></code></pre></div>
</div>
<div id="0d6d277d" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torchvision.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> CIFAR10</span>
<span id="cb13-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torchvision.transforms <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> transforms</span>
<span id="cb13-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.utils.data <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DataLoader</span>
<span id="cb13-4"></span>
<span id="cb13-5"></span>
<span id="cb13-6">mnist_transform <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> transforms.Compose([</span>
<span id="cb13-7">        transforms.ToTensor(),</span>
<span id="cb13-8">])</span>
<span id="cb13-9"></span>
<span id="cb13-10">kwargs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'num_workers'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pin_memory'</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>} </span>
<span id="cb13-11"></span>
<span id="cb13-12">train_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CIFAR10(dataset_path, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>mnist_transform, train<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, download<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb13-13">test_dataset  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CIFAR10(dataset_path, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>mnist_transform, train<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, download<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb13-14"></span>
<span id="cb13-15">train_loader <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataLoader(dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_dataset, batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>batch_size, shuffle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs)</span>
<span id="cb13-16">test_loader  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataLoader(dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>test_dataset,  batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>batch_size, shuffle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Files already downloaded and verified
Files already downloaded and verified</code></pre>
</div>
</div>
</section>
<section id="モデルの定義-1" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="モデルの定義-1"><span class="header-section-number">2.2</span> モデルの定義</h3>
<section id="エンコーダー-1" class="level4" data-number="2.2.1">
<h4 data-number="2.2.1" class="anchored" data-anchor-id="エンコーダー-1"><span class="header-section-number">2.2.1</span> エンコーダー</h4>
<p>VQ-VAE は画像への応用を念頭に置いているため，エンコーダーには <a href="../../../posts/2024/Kernels/Deep.html#sec-CNN">CNN アーキテクチャ</a> を採用する．</p>
<div id="e00a07a8" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> Encoder(nn.Module):</span>
<span id="cb15-2">    </span>
<span id="cb15-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, input_dim, hidden_dim, output_dim, kernel_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), stride<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>):</span>
<span id="cb15-4">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(Encoder, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb15-5">        </span>
<span id="cb15-6">        kernel_1, kernel_2, kernel_3, kernel_4 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kernel_size</span>
<span id="cb15-7">        </span>
<span id="cb15-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.strided_conv_1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Conv2d(input_dim, hidden_dim, kernel_1, stride, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb15-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.strided_conv_2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Conv2d(hidden_dim, hidden_dim, kernel_2, stride, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb15-10">        </span>
<span id="cb15-11">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.residual_conv_1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Conv2d(hidden_dim, hidden_dim, kernel_3, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb15-12">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.residual_conv_2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Conv2d(hidden_dim, hidden_dim, kernel_4, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb15-13">        </span>
<span id="cb15-14">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.proj <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Conv2d(hidden_dim, output_dim, kernel_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb15-15">        </span>
<span id="cb15-16">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x):</span>
<span id="cb15-17">        </span>
<span id="cb15-18">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.strided_conv_1(x)</span>
<span id="cb15-19">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.strided_conv_2(x)</span>
<span id="cb15-20">        </span>
<span id="cb15-21">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> F.relu(x)</span>
<span id="cb15-22">        y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.residual_conv_1(x)</span>
<span id="cb15-23">        y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>x</span>
<span id="cb15-24">        </span>
<span id="cb15-25">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> F.relu(y)</span>
<span id="cb15-26">        y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.residual_conv_2(x)</span>
<span id="cb15-27">        y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>x</span>
<span id="cb15-28">        </span>
<span id="cb15-29">        y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.proj(y)</span>
<span id="cb15-30">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> y</span></code></pre></div>
</div>
</section>
</section>
</section>



<div id="quarto-appendix" class="default"><section id="参考文献" class="level2 appendix" data-number="3"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">3</span> 参考文献</h2><div class="quarto-appendix-contents">

<p>本稿は，<a href="https://velog.io/@mskang/about">Minsu Jackson Kang 氏</a> による <a href="https://github.com/Jackson-Kang/Pytorch-VAE-tutorial">チュートリアル</a> を参考にした．</p>
<p>VAE には数々の変種があるが，その PyTorch による簡単な実装は <a href="https://antixk.netlify.app/">Anand K Subramanian</a> の <a href="https://github.com/AntixK/PyTorch-VAE">このレポジトリ</a> にリストアップされている．</p>
<p>VAE の潜在表現は <a href="https://ja.wikipedia.org/wiki/T分布型確率的近傍埋め込み法">t-SNE</a> などを用いて可視化でき，<span class="citation" data-cites="Murphy2023">(Murphy, 2023, p. 635)</span> の例などでも，潜在空間において手書き数字がクラスごとによく分離されていることが確認できる．</p>



</div></section><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Kingma-Ba2017" class="csl-entry">
Kingma, D. P., and Ba, J. (2017). <a href="https://arxiv.org/abs/1412.6980">Adam: A method for stochastic optimization</a>.
</div>
<div id="ref-Kingma-Welling2014" class="csl-entry">
Kingma, D., and Welling, M. (2014). <a href="https://openreview.net/forum?id=33X9fd2-9FyZd">Auto-encoding variational bayes</a>. In <em>International conference on learning representations</em>,Vol. 2.
</div>
<div id="ref-Murphy2023" class="csl-entry">
Murphy, K. P. (2023). <em><a href="http://probml.github.io/book2">Probabilistic machine learning: Advanced topics</a></em>. MIT Press.
</div>
<div id="ref-vandenOord+2017" class="csl-entry">
van&nbsp;den&nbsp;Oord, A., Vinyals, O., and Kavukcuoglu, K. (2017). <a href="https://papers.nips.cc/paper_files/paper/2017/hash/7a98af17e63a0ac09ce2e96d03992fbc-Abstract.html">Neural discrete representation learning</a>. In <em>Advances in neural information processing systems</em>,Vol. 30.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>なお，<code>mean.pow(2)</code> は Julia の <code>mean.^2</code> に同じ．↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Deep</category>
  <category>Sampling</category>
  <category>Python</category>
  <guid>https://162348.github.io/posts/2024/Kernels/VAE.html</guid>
  <pubDate>Sat, 27 Jul 2024 15:00:00 GMT</pubDate>
</item>
</channel>
</rss>
